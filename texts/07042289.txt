1738

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 7, JULY 2015

Iterative Vessel Segmentation of Fundus Images
Sohini Roychowdhury∗ , Member, IEEE, Dara D. Koozekanani, Member, IEEE, and Keshab K. Parhi, Fellow, IEEE

Abstract—This paper presents a novel unsupervised iterative
blood vessel segmentation algorithm using fundus images. First, a
vessel enhanced image is generated by tophat reconstruction of the
negative green plane image. An initial estimate of the segmented
vasculature is extracted by global thresholding the vessel enhanced
image. Next, new vessel pixels are identified iteratively by adaptive
thresholding of the residual image generated by masking out the
existing segmented vessel estimate from the vessel enhanced image.
The new vessel pixels are, then, region grown into the existing vessel, thereby resulting in an iterative enhancement of the segmented
vessel structure. As the iterations progress, the number of false
edge pixels identified as new vessel pixels increases compared to
the number of actual vessel pixels. A key contribution of this paper
is a novel stopping criterion that terminates the iterative process
leading to higher vessel segmentation accuracy. This iterative algorithm is robust to the rate of new vessel pixel addition since it
achieves 93.2–95.35% vessel segmentation accuracy with 0.9577–
0.9638 area under ROC curve (AUC) on abnormal retinal images
from the STARE dataset. The proposed algorithm is computationally efficient and consistent in vessel segmentation performance
for retinal images with variations due to pathology, uneven illumination, pigmentation, and fields of view since it achieves a vessel
segmentation accuracy of about 95% in an average time of 2.45,
3.95, and 8 s on images from three public datasets DRIVE, STARE,
and CHASE_DB1, respectively. Additionally, the proposed algorithm has more than 90% segmentation accuracy for segmenting
peripapillary blood vessels in the images from the DRIVE and
CHASE_DB1 datasets.
Index Terms—Accuracy, computational complexity, fundus image, iterative algorithm, morphological reconstruction, stopping
criterion, vessel segmentation.

I. INTRODUCTION
ETINAL blood vessel (vasculature) segmentation using
fundus photographs has played a vital role in assessing the
severity of retinal pathologies that can lead to acquired blindness such as retinopathy of prematurity [1], glaucoma, vein occlusions, and diabetic retinopathy (DR) [2]. According to research
statistics in the year 2011, retinal pathologies such as DR affect

R

Manuscript received May 9, 2014; revised December 23, 2014; accepted
January 19, 2015. Date of publication February 13, 2015; date of current version
June 16, 2015. This work was supported in part under a grant from the Institute
for Engineering and Medicine at the University of Minnesota and in part by an
unrestricted departmental grant from Research to Prevent Blindness Inc, New
York, NY, USA. Asterisk indicates corresponding author.
∗ S. Roychowdhury is with the Department of Electrical and Computer Engineering, University of Washington, Bothell, WA 98011 USA (e-mail: roych@
uw.edu).
D. D. Koozekanani is with the Department of Ophthalmology, University of
Minnesota, Minneapolis, MN 55455 USA (email: dkoozeka@umn.edu).
K. K. Parhi is with the Department of Electrical & Computer Engineering, University of Minnesota, Minneapolis, MN 55455, USA (email:
parhi@umn.edu).
This paper contains supplemental material available online at http://
ieeexplore.ieee.org (File size: 1MB).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2015.2403295

over 4.2 million Americans each year, while glaucoma affects
about 2.3 million Americans annually [3]. Automated blood
vessel segmentation algorithms can be very useful in screening patients that are affected by such retinal complications and
require follow-up [4]. Also, automated blood vessel segmentation systems can be useful in determining variations in the
blood vessels based on the vessel branching patterns, vessel
width, tortuosity, and vessel density as the pathology progresses
in patients [5]. Such evaluations will help to enhance the resourcefulness of the present-day retinal therapeutics and guide
research toward analyzing patients for hypertension [6], variability in retinal vessel diameters due to a history of cold hands
and feet [7], and flicker responses [8]. Some existing automated
detection systems for nonproliferative DR detection, such as in
[9] and [10], require masking of the blood vessels to ensure that
the blood vessels are not mistaken for red lesions that are caused
by DR. Additionally, proliferative DR (PDR) detection systems
[11] require analysis of the vessel parameters for detecting neovascularization, vessel beading, and intraretinal microvascular
abnormalities. Thus, an accurate vessel segmentation algorithm
that is robust to image variability and that has low computational
complexity is desirable for such automated real-time detection
and screening systems.
All existing algorithms for automated segmentation of blood
vessels using fundus images can be broadly categorized as supervised and unsupervised methods. A comprehensive survey
on existing retinal vessel segmentation algorithms and publicly
available datasets has been presented in [12]. Also, a comparative analysis of the two categories of vessel segmentation algorithms has been presented in [13]. In the supervised category
of algorithms, classifiers such as the k-nearest neighbor [14],
Gaussian mixture model (GMM) [15], support vector machine
(SVM) [16], neural networks [17], decision trees [18], and AdaBoost [19] have been applied to classify vessel pixels from the
nonvessels. The unsupervised algorithms mostly apply matched
filtering [20], line detectors [21], morphological transformations
[22]–[24], model-based methods [25]–[27], or multiscale vessel
segmentation methods [28]–[30]. While most supervised vessel
classification methods are dependent on the training data and
sensitive to false edges, the existing unsupervised methods are
computationally complex, and hence, they are not viable for
real-time portable DR screening systems such as [9]. Most of
the existing approaches such as the ones in [15], [21], and [26]
perform well on healthy retinal images but have low segmentation accuracy in images with pathology. Thus, there is a need for
a general method with low computational complexity and high
segmentation accuracy for normal as well as pathological fundus
images. In this paper, we propose an iterative vessel segmentation algorithm that segments the major vessels first, followed
by addition of finer vessel branches by adaptive thresholding
in iterative steps. This iterative approach has high segmentation
accuracy for vasculature in normal and abnormal retinal images.

0018-9294 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

ROYCHOWDHURY et al.: ITERATIVE VESSEL SEGMENTATION OF FUNDUS IMAGES

Also, the proposed method has lower computational complexity
than most existing supervised and unsupervised approaches.
Key contributions of this paper include a novel iterative blood
vessel segmentation algorithm, where vasculature estimates are
identified by adding new pixels iteratively using adaptive global
thresholding, and a novel stopping criterion to terminate the
iterative vessel addition process, thereby reducing the number
of false edge pixels in the segmented image. The proposed vessel segmentation algorithm is robust to both image variability
and interobserver variability in the ground-truth. For healthy
and pathological images from the STARE dataset [20], the proposed method achieves an average segmentation accuracy in
the range of 93.32–95.6% for three sets of manually marked
ground-truth. The analysis of automated vessel segmentation
performance with respect to multiple ground-truth sets has not
been presented in any of the existing works so far. Additionally,
we identify vessel segmentation accuracy in the peripapillary
region as another important metric; this metric is well suited
for images with abnormalities such as PDR, glaucoma, and retinal occlusions. The peripapillary blood vessels contain vessels
within 1-optic disc diameter centered at the papilla [11]. It is
shown that the proposed approach provides robust and high
vessel segmentation accuracy in the peripapillary region when
compared to well-known existing algorithms.
The organization of this paper is as follows. The proposed
method and materials are described in Section II. In section III,
the experimental results are presented and compared with existing methods, for normal and abnormal retinal images, and for
peripapillary vessel extraction. Finally, in Section IV, discussion
and significant conclusions are presented.
II. METHOD AND MATERIALS
The principal idea behind iterative vessel segmentation is that
in a vessel enhanced image, the bright and large vessels overshadow the thinner fine vessel branches. In such a situation,
global thresholding would extract only the large prominent vessels, while the finer vessel branches would remain unsegmented.
Thus, to include these fine vessels into the segmented vasculature estimate, iterative adaptive global thresholding is proposed.
For every color fundus photograph, a vessel enhanced image
is obtained by morphological tophat reconstruction of the negative green plane image. The brightest pixels from this vessel
enhanced image are extracted as the major portions of the vasculature, or major vessels. A residual image is then generated by
masking these major vessels from the vessel enhanced image
followed by contrast adjustment and adaptive thresholding in
an iterative manner to uncover new vessel pixels and add them
to the existing vessel estimate. This method of iterative vessel
addition and a novel stopping criterion for estimating the best
segmented vasculature are presented in this section. The segmentation performance of the proposed algorithm is evaluated
using three publicly available datasets with different resolutions
and FOVs. The proposed algorithm has been implemented in
MATLAB environment on a laptop with Intel Core i3 processor, 2.6 GHz and 2-GB RAM.
A. Data
The following datasets have been manually annotated for the
blood vessel regions for analyzing the performance of blood
vessel segmentation algorithms.

1739

1) STARE [20] dataset contains 20 images with 35◦ FOV of
size [605 × 700] pixels that are manually annotated by two
independent human observers. Here, ten images represent
patients with retinal abnormalities (STARE Abnormal).
The other ten images represent normal retina (STARE
Normal).
2) DRIVE [31] dataset contains 40 images with 45◦ FOV of
size [584 × 565] pixels. This dataset is separated by its
authors into a training set (DRIVE Train) and a test set
(DRIVE Test) with 20 images in each set. The DRIVE
Train set of images are annotated by one human observer,
while the DRIVE Test dataset is annotated by two independent human observers.
3) CHASE_DB1 [32] dataset contains 28 images with 30◦
FOV of size [960 × 999] pixels corresponding to two images per patient (one image per eye) for 14 children. Each
image is annotated by two independent human observers
[18].
The automated vessel segmentation performance is evaluated
on the images from DRIVE Test, STARE, and CHASE_DB1
datasets with respect to three sets of manually marked groundtruths. The ground-truth O1 and O2 are referred to the manual
annotations by first and second human observer, respectively.
The annotations by the second human observer contain more fine
vessels than the first human observer. Additionally, to analyze
interobserver variability, ground-truth O3 = O1 ∪ O2 is formed
as the union of all regions in the ground-truth images of O1
and O2 .

B. Proposed Method
As a preprocessing stage, the green plane of each fundus
image is scaled in [0,1] (I). A fundus mask (g) is utilized to
remove the dark background region from the photographs to
focus attention on the retinal region only. The fundus masks
for DRIVE, STARE, and CHASE_DB1 datasets are generated
as centered elliptical regions with diameters of [[521 × 520],
[550 × 650], and 860 × 869 pixels, respectively.
In the scaled green plane image (I), the red regions corresponding to the blood vessel segments appear as dark pixels
with intensities close to 0. To focus attention on the blood vessel regions, image I is inverted to make the red regions appear
the brightest, followed by superposition of the mask g, resulting
in image Iv . Iv is then subjected to contrast enhancement followed by morphological tophat transformation. Twelve linear
structuring elements each of length 21 pixels and 1-pixel width
and angles incremented by 15◦ from 0 through 180◦ are used to
generate tophat reconstructions from Iv [18], [22]. The length of
21 pixels for the linear structuring element is chosen to approximately fit the diameter of the biggest vessels in the images [18].
For each pixel location, the reconstructed pixel with the highest
intensity is selected, thereby resulting in tophat reconstructed
vessel enhanced image T .
The major vessels (V0 ) are extracted by thresholding image T
for pixels greater than “p” : p ∈ [0, 1], and retaining the regions
with area greater than 200 pixels. An optimal value of “p = 0.5”
is selected to minimize error in the final segmented vessel. The
process of optimally estimating the major vessels is presented in
Section II-C. The major vessels (V0 ) are the segmented vessel

1740

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 7, JULY 2015

TABLE I
DEFINITION OF NOTATION
Notation

Meaning

V
Vf
T
p
Vt

Manually marked vessel image.
Final segmented vasculature.
Tophat transformed vessel enhanced image.
Threshold pixel intensity in [0, 1] to extract major vessels.
Binary image representing vasculature estimated in iteration t.
V 0 represents the major vessels at t = 0.
Residual image obtained by removing the pixels in the
existing vessel estimate (V t ) from T .
Thresholded residual image from R t using threshold φ 1 (t).
This contains the new vessel pixels identified in iteration t.
Base image to fill gaps between the new vessel pixels and
the existing vessel estimate. It is the union of vessel pixels
in V R t and V t added to image T .
Vasculature at iteration t + 1 obtained from region grown
base image (B t ) with an adaptive threshold φ 2 (t).
Change in segmented vessel estimate in iteration “t” defined
as the difference between number of pixels in V t and V 0
divided by the total number of image pixels.
For m = [1, 2, 3], the first-, second-, and third-order derivatives
of C t computed using backward difference method.
Error in number of vessel pixels between V t and manually
marked vessels V divided by the total number of pixels.
For m = [1, 2, 3], the first-, second-, and third-order derivatives
of E t computed using backward difference method.
Quality of the segmented vessel estimate V t in iteration
“t” defined as the ratio between the number of actual
vessel pixels and the number of false edge pixels.

Rt
VR t
Bt

Vt + 1
Ct

C tm
Et
E tm
Qt

estimate (Vt ) at iteration t = 0. Next, the following steps are
iteratively performed.
For each iteration t, the pixels from the existing vessel estimate Vt are removed from image T , and the remaining image is
contrast enhanced resulting in residual image Rt . This image
Rt is thresholded at pixel value φ1 (t) to extract a binary image
VR t containing new vessel regions that have an area of at least
10 pixels. Here, the pixel threshold value φ1 (t) varies with “t,”
the iteration number. However, it is desirable for the segmented
vessel to have a continuous structure, and hence, it is imperative
to fill any gaps or holes between the existing vessel estimate Vt
and the newly identified vessel pixels in VR t . Thus, the pixels
in Vt and VR t are added to vessel enhanced image T , followed
by rescaling the pixels in [0, 255], resulting in base image Bt .
This image Bt is then region grown with a threshold pixel value
(φ2 (t)) that is a function of the iteration number. The image
obtained at the end of the region grow operation [33] is the new
iterative vessel estimate (Vt+1 ).
The iterative addition of the newly identified vessel regions to
the existing vessel estimate is continued till a stopping criterion
is met. The notations and their definitions used in this iterative
algorithm are defined in Table I.
For an image from the DRIVE dataset, the iterative vessel estimates are shown in Fig. 1 for ten iterations, i.e.,
t = [1, 2, . . . , 10]. The proposed iterative segmentation algorithm is given in Algorithm 1. For the example shown in Fig. 1,
the best segmented vasculature is estimated at iteration t = 4.
For postprocessing, the regions in the best vessel estimate
with area less than 20 pixels are discarded, and the remaining
vessel regions are median filtered with a [3 × 3] filter.

Fig. 1. Iterative vessel segmentation algorithm on an image with 45◦ FOV. (a)
Green plane image (I). (b) Vessel enhanced image by tophat reconstruction (T ).
(c) Major vessels extracted from T (V 0 ). (d) Residual image R 0 with pixels from
V 0 removed from image T . (e) New vessel pixels identified by thresholding R 0
(V R 0 ). (f) Base image B 0 obtained by combining pixels in V R 0 and V 0 on
image T . (g) V 1 extracted after region growing. (h) Final vasculature estimate
obtained after four iterations (V f ). (i) Manually marked vasculature (V ). (j)
Vessel estimates extracted after each iteration t = 3 to t = 10 by repeating
steps (d) to (g) iteratively. A stopping criterion is required to stop the iteration
at t = 4 to prevent oversegmentation.

It is important to note that Algorithm 1 relies on two threshold
parameters that impact the accuracy of the final vessel estimate.
These two threshold parameters φ1 (t) and φ2 (t) affect the quality of new vessel pixels that are added to the existing vessel
estimate. The other important feature in the iterative vessel segmentation algorithm is the estimation of the iteration number
(tf ) at which the best vessel estimate with the highest segmentation accuracy occurs. To determine tf , a stopping criterion is
introduced. The methods for estimating the adaptive thresholds
φ1 (t) and φ2 (t) and stopping criterion are given below.
1) Thresholds for Vessel Addition: In each iteration step
“t,” new vessels are identified from the iterative residual image in VR t using pixel threshold φ1 (t). Here, we initialize
φ1 (t) = 1 − (0.05 ∗ t). As the algorithm progresses to combine the new vessel pixels (VR t ) to the existing vessel estimate
(Vt ), a region grow operation [33] is performed by scaling the
image (VR t ∪ Vt ) + T in [0, 255], using a seed pixel value of
255, and a threshold pixel value φ2 (t). The threshold function
φ2 (t) that would result in significantly high accuracy for vessel

ROYCHOWDHURY et al.: ITERATIVE VESSEL SEGMENTATION OF FUNDUS IMAGES

1741

t = 10. Also, Algorithm 1 requires a stopping criterion to stop
the iterative vessel addition process at iteration number tf where
a segmentation vasculature with highest accuracy exists. This
stopping criterion can be determined by analyzing the quality
of segmented vessel estimates in every iteration.
The initial vessel segment V0 contains the major portions of
the blood vessels, and hence, it is free from false edge pixels.
In each iteration, new pixels are added to the existing blood
vessels. While actual vessel pixels are added in each iteration,
pixels corresponding to false edges also get introduced into the
segmented vessel structure. Using the manually marked vessels
V and the iterative vessel estimate Vt in each iteration t, the
criteria for any pixel (i, j) to be a true positive (tpt ), true negative
(tnt ), false positive (f pt ), and false negative (f nt ) are defined in
(2)–(5). The total number of pixels that are true positives (T Pt ),
true negatives (T Nt ), false positives (F Pt ), and false negatives
(F Nt ) in each image are then computed using (6)–(9)

Algorithm 1: Iterative Vessel Segmentation (I, g)
Input: I ∈ [0, 1], g ∈ [0, 1]
Output: Vf
Preprocessing:
Iv ← contrast adjust((1 − I) ◦ g)
T ← tophat reconstruction(Iv )
V0 ← [(T > p), and area > 200]
Iterations:
t = 0, stop ← “No,” stop ∈ [“Yes,” “No”],
while [stop← “No” ] do
∀(i, j), Rt (i, j) = {[T (i, j) − Vt (i, j)]|Rt (i, j) ≥ 0}.
VR t ← [Rt > φ1 (t), and area > 10]
Bt ← scale ({VR t ∪ Vt } + T ∈ [0, 255])
Vt+1 ← region grow (Bt , seed = 255,
threshold = φ2 (t))
t←t+1
stop ← Stopping criterion (Vt , Vt−1 )
end while
tf ← t
Vf ← Vt f
return Vf

For the binary image Vt , in iteration t, we define
∀(i, j), i ∈ [1, 2, . . . , n1 ], j ∈ [1, 2, . . . , n2 ]
tpt (i, j) = 1, if [V (i, j) = 1, Vt (i, j) = 1]

(2)

tnt (i, j) = 1, if [V (i, j) = 0, Vt (i, j) = 0]

(3)

f pt (i, j) = 1, if [V (i, j) = 0, Vt (i, j) = 1]

(4)

f nt (i, j) = 1, if [V (i, j) = 1, Vt (i, j) = 0]

(5)

n2
n1 


Fig. 2. Estimation of threshold function φ 2 (t) for region growing. (a) Highest
mean vessel segmentation accuracy (AC C l ) versus the threshold function parameters [α, k]. (b) Mean iteration number (tl ) corresponding to highest AC C l
versus threshold function parameters [α, k] on the DRIVE Train set of images.

tpt (i, j) = T Pt ,

i=1 j =1
n1 
n2


φ2 (t) = 205 + α ∗ (t − 1)k ,
k ∈ [0, 0.2, , . . . , 3].

α ∈ [1, 2, . . . , 6],

tnt (i, j) = T Nt

(6)

i=1 j =1

f pt (i, j) = F Pt ,

i=1 j =1

segmentation is obtained by one-time training using the 20
images from the DRIVE Train dataset. We consider φ2 (t) given
by

n2
n1 


n1 
n2


f nt (i, j) = F Nt . (7)

i=1 j =1

The sum of all pixels in binary image Vt represents the total
number of T Pt and F Pt pixels in Vt
⇒

n2
n1 


Vt (i, j) = T Pt + F Pt .

(8)

Also, n1 · n2 = T Pt + T Nt + F Pt + F Nt .

(9)

i=1 j =1

(1)

Each of the 20 images were subjected to vessel segmentation
for all the 6 × 16 combinations of “α” and “k” values in (1) and
[t = 1, 2, . . . , 10] iterations. For every image (l = [1, . . . , 20]),
and for each combination of [α, k], the highest segmentation
accuracy (ACC l ) was achieved at iteration number tl . The mean
ACC l and the corresponding mean tl versus [α, k] are shown
in Fig. 2(a) and (b), respectively. Since, a low mean iteration
number implies higher segmentation speed for the algorithm,
the goal was to select a threshold function that generates the
highest mean vessel segmentation accuracy in less iterations.
We observe that the highest mean ACCl occurs for α = 1, k =
1.8, with the mean iteration number tl = 4. Thus, the threshold
function φ2 (t) for Algorithm 1 was estimated as φ2 (t) = 205 +
(t − 1)1.8 .
2) Stopping Criterion Design: In Fig. 1, we observe that the
best vessel estimate occurs at some iteration between t = 0 to

For a fundus image with [n1 · n2 ] pixels, the metrics identifying the quality of segmented vessel (Qt ), the change in vessel
estimate Ct , and error in the vessel estimate Et are defined in
(10)–(13). In (12), we observe that Et has two nonzero components, one due to the F Nt pixels and the other due to F Pt
pixels. The vessel segmentation accuracy ACCt increases as
Et decreases as described by (13). Thus, the iteration tf corresponding to minimum Et f will ensure a segmented vessel
estimate with highest accuracy
n 1 n 2
T Pt
i=1
j =1 [tpt (i, j)]
=
Deﬁne : Qt = n 1 n 2
F Pt
i=1
j =1 [f pt (i, j)]

(10)

n2
n1 
1 
Ct =
{Vt (i, j) − V0 (i, j)} (11)
n1 · n2 i=1 j =1

1742

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 7, JULY 2015

trends in regions when Q is high and Q is low are analyzed in
(14)–(16). The curve Ct always has a nondecreasing trend (15)
Ct+1 − Ct =

n2
n1 
1 
{Vt+1 (i, j) − Vt (i, j)} . (14)
n1 · n2 i=1 j =1

Since new vessel pixels are added in each iteration
n1 
n2


Vt+1 (i, j) ≥

i=1 j =1

n1 
n2


Vt (i, j) ⇒ Ct+1 − Ct ≥ 0(15)

i=1 j =1

⇒ Ct always has nondecreasing trend.
NowEt+1 − Et =
Fig. 3. Stopping criterion for the iterative algorithm. If the number of iteration
“t” is less than 3, or if the sign of the C t1 , C t2 , C t3 are not all nonnegative, then
iterations are continued.

n2
n1 
1 
[|V (i, j) − Vt+1 (i, j)|
n1 · n2 i=1 j =1

−|V (i, j) − Vt (i, j)|].
⇒ Using (12), Et+1 − Et

Et =

n2
n1 
1 
|V (i, j) − Vt (i, j)|
n1 · n2 i=1 j =1

(12)

⇒ Et =

j =1 [f pt (i, j)

+ f nt (i, j)]
T P t + T N t + F P t + F Nt

= 1 − ACCt .

n2
n1 
1 
[f pt+1 (i, j)
n1 · n2 i=1 j =1

+ f nt+1 (i, j) − f pt (i, j) − f nt (i, j)].(16)

n 1 n 2
i=1

=

(13)

Intuitively, Ct can be modeled as an odd-degree polynomial,
and Et can be modeled as an even-degree polynomial. The
goal of segmentation is to stop at the iteration with least error
to maximize the vessel segmentation accuracy. However, Et
requires knowledge of the manual annotated image and is not
known. Therefore, Et cannot be used as a parameter in the
stopping criteria. However, an analysis of the trends in Ct and
Et based on known images demonstrates a correlation between
these parameters. This allows us to derive a stopping criterion
using Ct . Later in the section, we propose to stop the iterations
when the first three derivatives of Ct are nonnegative. This is
illustrated in Fig. 3.
For trend analysis of the curves Ct and Et , a theoretical
example is shown in Fig. 4, where curves Cx and Ex are odd
and even functions of the same repeated root, respectively. Ex
is a function of fourth degree repeated root, and hence, we
analyze the trends of the first three derivatives of Ex and Cx
computed using backward difference rule as “x” varies from
1 to 20 in intervals of 1. We observe that although Ex and
Cx are both functions of repeated roots at x = 10.5, the first
three derivatives of both Ex and Cx become nonnegative, i.e.,
[Ex1 , Ex2 , Ex3 ] ≥ 0, [Cx1 , Cx2 , Cx3 ] ≥ 0, for [x ≥ 12]. The region
from x = 9 to x = 12 has very small variations in Cx and Ex .
Also, in Fig. 4, three significant regions exist corresponding to
high, medium, and low quality of segmented vessel pixels (Q).
The region with high Q corresponds to the early iterations when
the number of actual vessel pixels identified are more than the
noisy false edge pixels (T Pt >> F Pt ). The region with low Q
corresponds to iterations when the number of false edge pixels
being added exceed the actual vessel pixels (T Pt << F Pt ).
The third significant region is when Q is medium and change
in iterative vessel estimates is significantly small. The curve

However, for Et , we consider two separate cases to analyze
the trends of Et in high Q and low Q regions. In case 1 with
high Q, T Pt >> F Pt . Here, the number of false vessel pixels in
Vt (F Pt ) are very small compared to the number of true vessel
pixels (T Pt ) added in consecutive iterations (17). Also, for each
image, the sum of vessel pixels in the manually marked image
remains constant, i.e., T Pt + F Nt = constant (18). Hence in
the high Q region, Et has a nonincreasing trend (19). In case
2 with low Q, T Pt << F Pt . Here, the number of false vessel
pixels in Vt (F Pt ) are significantly larger than the true vessel
pixels (T Pt ) (20). We observe that Et has a nondecreasing trend
in this region (21)
Case 1: High Q, [T Pt >> F Pt ].
Iteratively, T Pt+1 ≥ T Pt , F Pt+1 ≈ F Pt
⇒ T P t + F Nt =

n1 
n2


V (i, j) = constant.

(17)
(18)

i=1 j =1

Using (17) and (18), F Nt+1 ≤ F Nt .
From(16), ⇒ Et+1 − Et ≤ 0
⇒ Et has nonincreasing trend.

(19)

Case 2: Low Q, [T Pt << F Pt ].
Iteratively, F Pt+1 ≥ F Pt , T Pt+1 ≈ T Pt
⇒ F Nt+1 ≈ F Nt .

(20)

From (16), ⇒ Et+1 − Et ≥ 0
⇒ Et has nondecreasing trend.

(21)

From the experimental standpoint, we observe that for all the
test images, the best fit polynomial for Ct is of degree 3, and the
best fit polynomial for Et is of degree 4. Thus, the first, second,
and third derivatives must exist for both curves Ct and Et . Let
these derivatives be denoted by Ctm and Etm , for m = [1, 2, 3],

ROYCHOWDHURY et al.: ITERATIVE VESSEL SEGMENTATION OF FUNDUS IMAGES

1743

Fig. 4. Theoretical example for curves corresponding to the iterative change in blood vessels C x and iterative error incurred E x . The repeated root for curves
E x , C x occurs in the region with medium Q. As iterations proceed beyond the repeated root, the first three derivatives of E x and C x become nonnegative.

respectively. These derivatives are computed iteratively using
the backward difference rule as

n2
n1 


m −1
Etm = Etm −1 − Et−1
, m = [1, 2, 3]
m −1
Ctm = Ctm −1 − Ct−1
, m = [1, 2, 3].

(22)

V (i, j) ≈

n2
n1 


i=1 j =1

i

j =1

Vt ∗ +1 (i, j)

n2
n1 


Vt ∗ +2 (i, j)

i=1 j =1

Vt ∗ +3 (i, j) ≥

i=1 j =1

Further, from Fig. 4, we observe that the iterative change
in Ct and Et are significantly small in the medium Q region
than the high and low Q regions. This is intuitive since in the
medium Q region, fine vessel branches are detected and added
to the existing vessel estimate. However, as soon as the noisy
false edge regions, which are significantly larger in area when
compared to the fine vessel branches, start getting identified and
added to the vessel estimates, the change in Ct and Et become
considerably large, and this is when the low Q region begins.
Based on this observation, a stopping criterion is designed for
Algorithm 1 using the following property.
Property 1: Assume Ct , Et exist for t = [1, 2, . . . , 10..], and
they can be approximated as Ct ≈ Λ0 (t − t∗ )3 + Λ1 , and Et ≈
Ω0 (t − t∗ )4 + Ω1 , where Λ0 , Λ1 , Ω0 , Ω1 are constants. If the
region with medium Q exists for at least three consecutive iterative steps (i.e., the change in the iterative vessel estimates are
very small for at least three iterations), then the iteration tf at
which the first instance of [Ct1f ≥ 0, Ct2f ≥ 0, Ct3f ≥ 0] occurs
will result in the best segmented vessel estimate.
Proof: Let the region medium Q exist for at least three consecutive iterations starting at iteration t∗ such that beyond the
(t∗ + 3)th iteration, the quality of pixel addition deteriorates,
i.e., the number false positive pixels added as vessels increases.
Then,
t∗

Vt ∗ +1 (i, j) ≈

i=1 j =1

If Ct0 = Ct , Et0 = Et , then

n2
n1 


n2
n1 


n2
n1 


Vt ∗ +2 (i, j).

(23)

i=1 j =1

While transitioning from medium Q to low Q region, both Ct
and Et have nondecreasing trends
⇒ Ct ∗ ≈ Ct ∗ +1 ≈ Ct ∗ +2 , Ct ∗ +3 ≥ Ct ∗ +2
⇒ Et ∗ ≈ Et ∗ +1 ≈ Et ∗ +2 , Et ∗ +3 ≥ Et ∗ +2

(24)

Using (24) and (22), we have
⇒ Ct1∗ +1 = 0, Ct1∗ +2 = 0, Ct1∗ +3 ≥ 0
⇒ Et1∗ +1 = 0, Et1∗ +2 = 0, Et1∗ +3 ≥ 0
⇒

Ct2∗ +2

=

0, Ct2∗ +3

(25)

≥0

⇒ Et2∗ +2 = 0, Et2∗ +3 ≥ 0

(26)

⇒ Ct3∗ +3 ≥ 0, Et3∗ +3 ≥ 0.

(27)

Combining (24)–(27) at t∗ + 3, we have
[Ct1∗ +3 ≥ 0, Ct2∗ +3 ≥ 0, Ct3∗ +3 ≥ 0]
[Et1∗ +3

≥

0, Et2∗ +3

≥

0, Et3∗ +3

(28)

≥ 0].

For iterations t > t∗ + 3, the number of false edge pixels that
are identified and added becomes higher than the number of
actual vessel pixels, which in turn reduces the accuracy of the
segmented vessel estimate. Thus, for Algorithm 1, tf = t∗ + 3
is the iteration at which the best segmented vasculature with
highest accuracy can be estimated.


1744

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 7, JULY 2015

Fig. 5. Vessel estimate curves C t and E t for a particular image from (a) DRIVE Test, and (b) STARE, respectively. The stopping iterations are (a) tf = 5, (b)
tf = 4. (a) Three consecutive derivatives for E t and C t become nonnegative at the same iteration step. (b) Iteration for three consecutive nonnegative derivatives
corresponding to C t and E t are different.

Even though our assumption that Ct and Et have repeated
root at same iteration number (with constant terms removed)
does not hold, the proposed stopping criterion still works well.
In general, Ct behaves like an odd-degree polynomial. Thus, it
may behave like a fifth-degree polynomial instead of third. This
may require stopping at the iteration where first five derivatives
are nonnegative. However, the proposed stopping criterion still
leads to high accuracy due to two reasons. First, Ct is approximately constant in the entire medium Q region. Constant Ct
over few iterations means fewer new vessels are added. Second, the medium Q region often spans a few iterations. Thus,
stopping at any iteration in this region leads to similar accuracy. This is illustrated using sample images chosen from the
datasets: DRIVE Test and STARE in Fig. 5. In Fig. 5(a), the
three consecutive derivatives of Ct and Et become nonnegative
at the same iteration number; however, in Fig. 5(b), Ct and Et
do not represent polynomials for the same repeated root, and
hence, the first three derivatives of Ct become nonnegative in
iteration t = 4, while the derivatives of Et become nonnegative
at t = 6. However, since iterations t = [4, 5, 6] lie in the medium
Q region, where the change in iterative vessel estimates is very
small, the accuracy of the segmented vessel in iteration t = 4 is
similar to the accuracy of the vessel estimate at t = 6.
Based on (28) from Property 1, the stopping criterion for Algorithm 1 is defined as the iteration when the first three derivatives of curve Ct become nonnegative. It is important to note
that this iterative process continues for at least three iterations
to obtain the first three derivatives for Ct .
C. Limiting Conditions
The proposed vessel segmentation algorithm is limited in its
performance of estimating fundus vasculature with high accu-

racy by one primary and two secondary constraints. The primary
constraint is the major vessel estimate (V0 ) at the beginning of
the iterative process. The two secondary constraints govern the
rate at which new vessels are iteratively added using functions
φ1 (t) and φ2 (t).
First, we analyze the error propagation and limiting conditions posed by the major vessel estimate. The proposed iterative
segmentation process is based on the inherent assumption that
V0 has no false positives. However, if a large number of false
positive pixels are introduced in major vessels, then the error
in segmented vasculature propagates through the iterations, resulting in low segmentation specificity and accuracy of the final
vessel estimate. The estimation of the major vessels is dependent
on the thresholding pixel intensity value p ∈ [0, 1] for extracting
the major vessels from image T , i.e., V0 = [T > p, area > 200].
If “p” is set to a very low pixel intensity, then most of the regions in the image are estimated as the major vessels, thereby
introducing more false positives than true positive pixels in V0
as shown in (29). In such situations, the trend of curve Et in (16)
becomes consistently nondecreasing in (30). This implies that
the iterative process will only decrease the accuracy of the final
segmented vessel estimate when compared to the major vessel
estimate (since Et = 1 − ACCt ). However, if “p” is set to a
very high pixel intensity, then very few regions are estimated
as major vessels, and almost no false positives are introduced
in the estimate V0 . As the iterative process begins, the first
few iterations add major vessel pixels followed by fine vessel
pixels added in subsequent iterations. Hence, the number of iterations before the stopping criterion is met increases. Thus, a
low value of “p” introduces large errors in the segmented vessel
estimate, while a large value of “p” increases the time complexity of the process. Further analysis shows that for all the test
datasets, p ∈ [0.4 − 0.7] ensures maximum accuracy in the final

ROYCHOWDHURY et al.: ITERATIVE VESSEL SEGMENTATION OF FUNDUS IMAGES

1745

Fig. 6. (a) ROC curves for blood vessel segmentation on DRIVE test, STARE, and CHASE_DB1 datasets with respect to ground-truth O 1 . (b) Variation in mean
segmentation accuracy by varying the thresholds. Highest ACC is achieved for the DRIVE Test, STARE, and CHASE_DB1 datasets with k = [1.4, 1.6, 1.6],
respectively.

segmented vasculature without significant increase in the number of iterations
If F P0 >> T P0 >> F N0
Et =

(29)

1
[F Pt+1 − F Pt + F Nt+1 − F Nt ].
n1 · n2

Since F Pt+1 − F Pt >> F Nt+1 − F Nt
Et+1 − Et ≥ 0, Et has nondecreasing trend.

(30)

Next, we analyze the limiting conditions due to the rate of
new vessel addition using functions φ1 (t), φ2 (t) to analyze the
receiver operating characteristic curves (ROC). While a low rate
of vessel addition increases the number of iterations, a high rate
of vessel addition introduces large number of false positives
before the stopping criterion is met. The performance metrics
that are used to evaluate the final segmentation performance
are: pixel-based sensitivity (SEN), specificity (SPEC), accuracy
(ACC) of vessel segmentation, time taken to achieve the segmented vasculature, and area under the ROC curves (AUC).
For this analysis, the rate at which new vessels are added iteratively is varied by changing φ1 (t), φ2 (t) as (31), (32), and applying the stopping criterion for that particular choice of threshold
functions
If k = [1, 1.1, 1.2, . . . , 3]

III. EXPERIMENTAL EVALUATION AND RESULTS
The performance of the proposed vessel segmentation algorithm is evaluated using the segmented vasculature and the
manually marked ground-truth O1 , O2 , and O3 . To assess the
overall performance of vessel segmentation by the proposed
iterative method, we performed the following three sets of experimental evaluations. In the first experiment, the segmentation
performance metrics were compared to the existing methods. In
the second experiment, abnormal images with bright and red
lesions from the STARE Abnormal dataset were analyzed for
segmentation performance. In the third experiment, segmentation performance of the peripapillary vessel pixels was analyzed.

(31)
A. Vessel Segmentation Performance

φ1 (t) = 0.905 − 0.005[10k(t − 1) − 9t]
φ2 (t) = 205 + (t − 1)k .

are 30◦ FOV images centered at the papilla. For these images,
if [1 ≤ k ≤ 1.4], rate of new vessel addition is very small, resulting in low segmentation SEN and ACC. For k > 2.4, the
rate of change in vessel estimates becomes very high causing
the medium Q region to be limited to less than three consecutive
iterations, thereby increasing the number of false edge pixels in
the final segmented vessel estimate. Thus, for the test images,
rate of vessel addition obtained by k ∈ [1.4 − 2.2] in (31) and
(32) results in high segmentation ACC.

(32)

The ROC curves for all the three datasets with respect to
ground-truth O1 are shown in Fig. 6(a). In Fig. 6(b), the variations in mean ACC by varying the thresholds as given in (31)
and (32) are shown. Here, we observe that the images from the
DRIVE and STARE datasets maintain significantly high ACC
as k varies in the range [1 ≤ k ≤ 2.2]. For k > 2.2, the rate of
change in vessel estimates becomes significantly high, such that
Ct does not maintain a medium Q region for three consecutive
iterations or more. This causes the iterative process to pick up
a lot of false positive pixels before stopping, thus reducing the
segmentation ACC. The images from the CHASE_DB1 dataset

The interobserver variability in the ground-truths is assessed
by analyzing the segmentation performance metrics of the proposed vessel segmentation algorithm with respect to the groundtruths O1 , O2 , and O3 are given in Table II. Here, we observe
that the STARE dataset has high interobserver variability in the
segmentation performance metrics due to the wide variety of
pathological images in it. Next, the performance and computational complexity of the proposed blood vessel segmentation
algorithm with respect to ground-truth O1 in comparison with
existing vessel segmentation methods is shown in Table III.
Most existing methods analyze the automated segmentation
performance with ground-truth O1 . The implementation time
complexity of the method in [30] is taken from [21] and the

1746

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 7, JULY 2015

TABLE II
PERFORMANCE OF THE PROPOSED METHOD ON THE TEST DATASETS
Data

Ground-Truth

AUC

ACC

SEN

SPEC

O1
O2
O3
O1
O2
O3
O1
O2
O3
O1
O2
O3
O1
O2
O3

0.9672
0.9640
0.9613
0.9673
0.9601
0.9617
0.9706
0.9621
0.9642
0.9638
0.9577
0.9596
0.9623
0.9600
0.9620

0.9494 (0.005)
0.9507 (0.006)
0.9442 (0.006)
0.9560 (0.0095)
0.9384 (0.0131)
0.9332 (0.0125)
0.9586 (0.0061)
0.9382 (0.0131)
0.9368 (0.0073)
0.9535 (0.017)
0.9387 (0.008)
0.9320 (0.02)
0.9467 (0.0076)
0.9454 (0.008)
0.9455 (0.007)

0.7395 (0.062)
0.7601 (0.0581)
0.7305 (0.0525)
0.7317 (0.053)
0.7498 (0.06)
0.7552 (0.052)
0.7571 (0.0088)
0.7310 (0.0559)
0.7568 (0.05)
0.7062 (0.100)
0.7586 (0.05)
0.7161 (0.073)
0.7615 (0.0516)
0.7514 (0.0442)
0.7653 (0.05)

0.9782 (0.0073)
0.9772 (0.01)
0.9787 (0.0076)
0.9842 (0.0069)
0.9801 (0.075)
0.9719 (0.0076)
0.9877 (0.0035)
0.9844 (0.0067)
0.9819 (0.009)
0.9808 (0.026)
0.9795 (0.008)
0.9705 (0.015)
0.9575 (0.003)
0.9622 (0.006)
0.9579 (0.004)

DRIVE Test

STARE

STARE Normal

STARE Abnormal

CHASE_DB1

Time(s)

2.45 (0.3196)

3.9587 (0.2732)

4.0387 (0.2865)

3.8786 (0.2476)

7.9138 (0.6774)

Segmentation time is recorded per image. Mean performance metrics and their standard deviation is given in ().

TABLE III
COMPARATIVE PERFORMANCE OF PROPOSED MODEL WITH EXISTING WORKS ON THE DRIVE TEST AND STARE DATASETS WITH RESPECT
TO GROUND-TRUTH O 1
Test Data:
Method
Supervised
Niemeijer et al. [14]
Staal et al. [31]
Soares et al. [15]
Ricci and Perfetti [16]
Marin et al. [17]
Fraz et al. [18]
Roychowdhury et al. [13]
Unsupervised
Hoover et al. [20]
Jiang and Mojon [34]
Mendonca and Campilho [22]
Lam and Yan [26]
Al-Diri et al. [35]
Lam et al. [27]
Budai et al.(2010)[28]
Budai et al.(2013)[29]
Perez et al. [30]
Miri et al. [24]
Nguyen et al. [21]
Proposed

DRIVE

Test

ACC

SPEC

SEN

AUC

Time

ACC

SPEC

SEN

AUC

Time

System

0.969
0.977
0.978
0.972
0.98
0.981
0.983

0.689
0.719
0.733
0.775
0.706
0.74
0.725

0.93
0.952
0.961
0.963
0.958
0.974
0.962

15 min
∼3 min
∼90 s
∼100 s
3.11 s

0.952
0.948
0.965
0.952
0.953
0.951

0.981
0.975
0.939
0.982
0.976
0.973

0.697
0.72
0.903
0.694
0.755
0.772

0.961
0.967
0.968
0.977
0.976
0.969

15 min
∼3 min
∼90 s
∼100 s
6.7 s

1.0 GHz, 1-GB RAM
2.17 GHz, 1-GB RAM
2.13 GHz, 2-GB RAM
2.27 GHz, 4-GB RAM
2.6 GHz, 2-GB RAM

0.90
0.976
0.955
0.968
0.987
0.967
0.976
0.978

0.83
0.734
0.728
0.759
0.644
0.644
0.715
0.739

0.932
0.961
0.967

8-36 s
2.5 min
11 min
13 min
11 s
∼5 s
∼2 min
∼50 s
2.5 s
2.45 s

0.9275
0.901
0.944
0.947
0.957
0.938
0.938
0.926
0.932
0.956

0.81
0.90
0.973
0.968
0.975
0.982
0.944
0.984

0.65
0.857
0.699
0.752
0.651
0.58
0.769
0.732

0.75
0.929
0.939
0.974
0.967

5 min
8–36 s
3 min
8 min
13 min
16 s
∼6 s
∼2 min
2.5 s
3.95 s

Sun SPARCstation 20
600 MHz PC
3.2 GHz, 980-MB RAM
1.83 GHz, 2-GB RAM
1.2 GHz
1.83 GHz, 2-GB RAM
2.0 GHz, 2-GB SDRAM
2.3 GHz,4-GB RAM
Parallel Cluster
3 GHz, 1-GB RAM
2.4 GHz, 2-GB RAM
2.6 GHz, 2-GB RAM

Methods
0.942
0.944
0.946
0.959
0.945
0.948
0.952
Methods
0.891
0.945
0.947
0.949
0.957
0.925
0.943
0.941
0.949

STARE

Segmentation time is recorded per image.

method in [29] is implemented on our MATLAB system for
comparative analysis.
From Table III, we observe that the proposed iterative vessel segmentation approach outperforms all the existing methods except for the supervised approach by Ricci and Perfetti
[16] and Roychowdhury et al. [13] on the DRIVE Test dataset,
and the unsupervised Lam et al. [27] method on the STARE
dataset. In the method by Ricci and Perfetti [16], SVM classifiers were separately trained using 20 000 manually segmented
randomly chosen pixels from the DRIVE and STARE datasets.
This method is computationally more complex due to the use
of the SVM classifier, and the classifier may need retraining for
new datasets. The supervised method by Roychowdhury et al.
[13] uses GMM classifiers trained on the DRIVE Train dataset,

and hence, it is more trained to segment vessel pixels in the
DRIVE Test dataset than the STARE dataset. Also, from Table III, we observe that the AUC of the supervised methods is
comparable to that of the proposed method. This is indicative
of the robustness of the stopping criterion design with varying
threshold functions [φ1 (t), φ2 (t)].
B. Abnormal Image Analysis
Existing works in [16], [22], [26], [27], and [36] have shown
that robustness of a vessel segmentation algorithm depends on
the segmentation performance on abnormal retinal images with
red lesions such as microaneurysms or hemorrhages and bright
lesions such as exudates or cotton-wool spots. Vessel segmentation from two images with significant red and bright lesions from

ROYCHOWDHURY et al.: ITERATIVE VESSEL SEGMENTATION OF FUNDUS IMAGES

1747

TABLE IV
SEGMENTATION PERFORMANCE ON THE STARE ABNORMAL DATASET WITH
RESPECT TO GROUND-TRUTH O 1

TABLE V
PERIPAPILLARY VESSEL ANALYSIS
O1

Method
Method

ACC

AUC

Time

0.9211
0.9352
0.9426
0.9425
0.9287
0.9510
0.9474
0.9556
0.9453
0.9535

0.7590
0.9343
0.9571
0.9187
0.9392
0.9707
0.9596
0.9638

5 min
8–36 s
3 min
3 min
90 s
8 min
13 min
8.36 s
3.87 s

O2

O3

0.914(0.02)
0.912(0.01)
0.910 (0.02)
0.915(0.02)

0.919(0.02)
0.917(0.01)
0.915(0.02)
0.926(0.02)

0.901(0.02)
0.899(0.02)
0.898(0.02)
0.904(0.02)

0.863(0.03)
0.920(0.02)
STARE

0.866(0.02)
0.923(0.02)

0.846(0.03)
0.903(0.02)

0.805(0.04)
0.804(0.05)
0.832(0.03)

0.719(0.06)
0.724(0.05)
0.757(0.06)

0.663(0.06)
0.671(0.05)
0.709(0.05)

0.768(0.03)
0.818(0.03)
CHASE_DB1

0.718(0.04)
0.774(0.06)

0.705(0.04)
0.747(0.06)

0.839(0.02)

0.848(0.01)

0.843(0.03)

0.904(0.03)

0.905(0.04)

0.889(0.03)

DRIVE Test
Hoover et al. [20]
Jiang and Mojon [34]
Mendonca and Campilho [22]
Soares et al. [15]
Vermeer et al. [25]
Marin et al. [17]
Lam and Yan [26]
Lam et al. [27]
Roychowdhury et al. [13]
Proposed

Segmentation time is recorded per image.

the STARE Abnormal dataset have been analyzed by a number
of existing methods [15], [17], [26], [27]. In Table IV, we compare the segmentation performance of all known methods with
the proposed approach on the ten images from the STARE Abnormal dataset with respect to ground-truth O1 . We observe that
the proposed method outperforms all other methods except the
perceptive transform based method by Lam et al. [27]. However, the computational complexity of the proposed approach
is lower than most existing methods. From Table III, we observe that although the unsupervised method by Nguyen et al.
[21] has the lowest computational complexity on the STARE
dataset (segmentation time of 2.5 s/image), it suffers from false
positive detection around the optic disc region and over detection in pathological images, thereby having lower segmentation
performance metrics when compared to the proposed method.
C. Peripapillary Vessel Analysis
In retinal fundus images, the blood vessels in and around
the optic disc are referred to as the peripapillary blood vessels.
Many retinal abnormalities such as PDR, glaucoma, central retinal vein occlusion, and cilio-retinal artery occlusion can lead to
changes in the blood vessel structure mainly in the peripapillary region. For instance, neovascularization at the disc caused
due to PDR is evident if new blood vessels are visible within
1-optic disc diameter (1-DD) centered at the papilla [11]. Thus,
the performance of the proposed vessel segmentation system for
extracting the peripapillary blood vessels in normal and abnormal images is analyzed here. For this purpose, the images from
the DRIVE, STARE, and CHASE_DB1 dataset were manually
annotated for the optic disc boundary and optic nerve head in
each image, and then, a mask was created centered at the optic
nerve head with 1-DD radius to extract the peripapillary region.
The first 19 images from the STARE vessel segmentation dataset
contain the peripapillary region, and hence, peripapillary vessel
detection was performed on these 19 images only.
The segmented vessel images of the DRIVE dataset using the
Marin et al. method [17]1 , Soares et al. method [15]2 , Jiang and

Supervised
Marin et al. [17]
Soares et al. [15]
Staal et al. [31]
Roychowdhury et al. [13]
Unsupervised
Jiang et al. [34]
Proposed
Supervised
Marin et al. [17]
Soares et al. [15]
Roychowdhury et al. [13]
Unsupervised
Hoover et al. [20]
Proposed
Supervised
Roychowdhury et al. [13]
Unsupervised
Proposed

ACC and the standard deviation is given in ().

Mojon method [34], and Staal et al. method [31]3 are downloaded from the respective websites for comparison. The segmented vessel images from the STARE dataset are compared to
the segmentation results produced by the Marin et al. method
[17], Soares et al. method [15], and Hoover et al. method [20].4
We analyze the performance of peripapillary vessel segmentation for the three datasets with respect to the three sets of
ground-truths O1 , O2 , and O3 in Table V. We know that fundus images with smaller FOV, such as images from STARE and
CHASE DB1 datasets, capture a more detailed view of the fine
blood vessels when compared to the images with larger FOV
(images from DRIVE dataset). From Table V, we observe that
the proposed vessel segmentation method has significantly better peripapillary vessel segmentation performance with respect
to the three sets of ground-truths in the images with smaller
FOV than on the images with larger FOV.
IV. DISCUSSION AND CONCLUSION
In this paper, we have proposed an unsupervised iterative
blood vessel segmentation algorithm using fundus images and
tested it on three public datasets of DRIVE, STARE, and
CHASE_DB1. This algorithm iteratively extracts vessel pixels
from a morphological vessel enhanced image from the negative
green plane from each fundus image. The algorithm initiates
with an initial estimate of the major portions of the blood vessels. Next, iteratively new vessel pixels are added to the existing
vessel estimate by adaptive global thresholding until a stopping
criterion is met. The proposed iterative segmentation algorithm
is computationally simple, general, and faster than all supervised
and unsupervised algorithms developed so far.

1 Available

at http://www.uhu.es/retinopathy/eng/bd.php
at http://sourceforge.net/apps/mediawiki/retinal/index.php?title=
Segmentation_results
2 Available

3 Available

at http://www.isi.uu.nl/Research/Databases/DRIVE/browser.php

4 Available at http://www.parl.clemson.edu/ahoover/stare/probing/index.html

1748

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 7, JULY 2015

The proposed algorithm depends on three limiting constraints
that include the initial major vessel estimate and two threshold functions that determine the rate at which vessel estimates
change iteratively. The ROC curves that are constructed by varying these threshold functions demonstrate that the stopping criterion is robust to change in the adaptive threshold values since
an average AUC of 0.96 is achieved across the three datasets for
three sets of manual annotations. Also, the proposed algorithm
relies on the first three derivatives of the change in iterative
vessel estimates to identify a novel stopping criterion that terminates the iterative vessel addition process while ensuring high
accuracy of the segmented vasculature. Future efforts may be
directed toward the analysis of the first five orders of derivatives
for the change in iterative vessel estimates to develop a stopping
criterion for high-resolution fundus images.
The proposed vessel segmentation algorithm is very effective
in abnormal retinal images with large red or bright lesions in
close vicinity of the main vasculature, since the algorithm will
stop before the iteration in which the large lesion regions are
identified and added to the existing vessel estimate. However,
this algorithm has one limitation. In retinal images with small
microaneurysms close to the vasculature, the microaneurysms
will be included as a part of the vasculature due to the region
grow operation. Future work will be directed toward combining
the proposed method with decision making approaches to further enhance the segmentation performance on abnormal retinal
images with such small lesions close to the vasculature.
The most significant features of the proposed segmentation algorithm is that it provides segmented vessels with high accuracy
for peripapillary blood vessel extraction. It achieves greater than
90% peripapillary vessel segmentation accuracy for the DRIVE
and CHASE_DB1 dataset and greater than 77% accuracy for the
STARE dataset with respect to both human observers. Thus, the
proposed segmentation algorithm can be useful for automated
algorithms that detect the density, tortuosity, or width of these
peripapillary vessels for severity analysis of pathologies such as
vein occlusions and glaucoma.
Unlike some methods that are fine tuned to handle abnormal retinal images in [27], the proposed vessel segmentation
algorithm is generalizable, and robust against false edges, uneven illumination and pigmentation. The high speed, computational simplicity, and data independence of the proposed method
makes it ideal for automated vessel pathology analysis for future research problems that analyze changes in the retinal vessel
width [5], [7], [8]. Future work will be directed toward combining the proposed algorithm with DR screening systems such as
[9] and to detect neovascularization in the peripapillary region.
Redesigning the proposed method for vessel segmentation on
wide field images with greater than 200◦ FOV is a topic that
requires further study.
REFERENCES
[1] C. M. Wilson et al., “Computerized analysis of retinal vessel width
and tortuosity in premature infants,” Investigative Ophthalmol. Vis. Sci.,
vol. 49, no. 8, pp. 3577–3585, 2008.
[2] A. Karperien et al., “Automated detection of proliferative retinopathy
in clinical practice,” Clin. Ophthalmol. (Auckland, NZ), vol. 2, no. 1,
p. 109–122, 2008.

[3] CDC. (2011, Mar. 23). Diabetic retinopathy. Atlanta, GA: National for
chronic disease prevention and health promotion [Online]. Available:
http://www.cdc.gov/visionhealth/pdf/factsheet.pdf
[4] M. D. Abramoff et al., “Retinal imaging and image analysis,” IEEE Trans.
Med. Imag., vol. 3, pp. 169–208, Jan. 2010.
[5] H. M. Pakter et al., “Computer-assisted methods to evaluate retinal vascular caliber: What are they measuring?” Investigative Ophthalmol. Vis.
Sci., vol. 52, no. 2, pp. 810–815, 2011.
[6] K. Kotliar et al., “Microstructural alterations of retinal arterial blood column along the vessel axis in systemic hypertension,” Investigative Ophthalmol. Vis. Sci., vol. 51, no. 4, pp. 2165–2172, 2010.
[7] A. Kochkorov et al., “Short-term retinal vessel diameter variability in
relation to the history of cold extremities,” Investigative Ophthalmol. Vis.
Sci., vol. 47, no. 9, pp. 4026–4033, 2006.
[8] E. Nagel et al., “Age, blood pressure, and vessel diameter as factors
influencing the arterial retinal flicker response,” Investigative Ophthalmol.
Vis. Sci., vol. 45, no. 5, pp. 1486–1492, 2004.
[9] S. Roychowdhury et al., “Dream: Diabetic retinopathy analysis using
machine learning,” IEEE J. Biomed. Health Informat., vol. 18, no. 5,
pp. 1717–1728, Sep. 2014.
[10] T. Teng et al., “Progress towards automated diabetic ocular screening: A
review of image analysis and intelligent systems for diabetic retinopathy,”
Med. Biol. Eng. Comput., vol. 40, pp. 2–13, 2002.
[11] K. Goatman et al., “Detection of new vessels on the optic disc using retinal
photographs,” IEEE Trans. Med. Imag., vol. 30, no. 4, pp. 972–979, Apr.
2011.
[12] M. Fraz et al., “Blood vessel segmentation methodologies in retinal images-a survey,” Comput. Methods Prog. Biomed., vol. 108,
pp. 407–433, 2012.
[13] S. Roychowdhury et al., “Blood vessel segmentation of fundus images by
major vessel extraction and sub-image classification,” IEEE J. Biomed.
Health Informat., 2014, to be published.
[14] M. Niemeijer et al., “Comparative study of retinal vessel segmentation
methods on a new publicly available database,” Proc. Med. Imag. SPIE,
vol. 5370, pp. 648–656, 2004.
[15] J. Soares et al., “Retinal vessel segmentation using the 2-D Gabor wavelet
and supervised classification,” IEEE Trans. Med. Imag., vol. 25, no. 9,
pp. 1214–1222, Sep. 2006.
[16] E. Ricci and R. Perfetti, “Retinal blood vessel segmentation using line
operators and support vector classification,” IEEE Trans. Med. Imag.,
vol. 26, no. 10, pp. 1357–1365, Oct. 2007.
[17] D. Marin et al., “A new supervised method for blood vessel segmentation in retinal images by using gray-level and moment invariants-based
features,” IEEE Trans. Med. Imag., vol. 30, no. 1, pp. 146–158, Jan. 2011.
[18] M. Fraz et al., “An ensemble classification-based approach applied to
retinal blood vessel segmentation,” IEEE Trans. Biomed. Eng., vol. 59,
no. 9, pp. 2538–2548, Jun. 2012.
[19] C. Lupascu et al., “Fabc: Retinal vessel segmentation using adaboost,”
IEEE Trans. Inform. Technol. Biomed., vol. 14, no. 5, pp. 1267–1274,
Sep. 2010.
[20] A. Hoover et al., “Locating blood vessels in retinal images by piecewise
threshold probing of a matched filter response,” IEEE Trans. Med. Imag.,
vol. 19, pp. 203–210, Mar. 2000.
[21] U. T. V. Nguyen et al., “An effective retinal blood vessel segmentation
method using multi-scale line detection,” Pattern Recogn., vol. 46, no. 3,
pp. 703–715, Mar. 2013.
[22] A. Mendonca and A. Campilho, “Segmentation of retinal blood vessels by
combining the detection of centerlines and morphological reconstruction,”
IEEE Trans. Med. Imag., vol. 25, no. 9, pp. 1200–1213, Aug. 2006.
[23] F. Zana and J.-C. Klein, “Segmentation of vessel-like patterns using mathematical morphology and curvature evaluation,” IEEE Trans. Image Process., vol. 10, no. 7, pp. 1010–1019, Jul. 2001.
[24] M. Miri and A. Mahloojifar, “Retinal image analysis using curvelet transform and multistructure elements morphology by reconstruction,” IEEE
Trans. Biomed. Eng., vol. 58, no. 5, pp. 1183–1192, May 2011.
[25] K. A. Vermeer, et al., “A model based method for retinal blood vessel
detection,” Comput. Biol. Med., vol. 34, no. 3, pp. 209–219, 2004.
[26] B. Lam and H. Yan, “A novel vessel segmentation algorithm for pathological retina images based on the divergence of vector fields,” IEEE Trans.
Med. Imag., vol. 27, no. 2, pp. 237–246, Feb. 2008.
[27] B. Lam et al., “General retinal vessel segmentation using regularizationbased multiconcavity modeling,” IEEE Trans. Med. Imag., vol. 29, no. 7,
pp. 1369–1381, Mar. 2010.
[28] A. Budai et al., “Multiscale blood vessel segmentation in retinal fundus
images,” in Proc. Bildverarbeitung fr die Med., Mar. 2010, pp. 261–265.

ROYCHOWDHURY et al.: ITERATIVE VESSEL SEGMENTATION OF FUNDUS IMAGES

[29] A. Budai et al., “Robust vessel segmentation in fundus images,” Int. J.
Biomed. Imag., vol. 2013, 2013.
[30] M. Palomera-Perez et al., “Parallel multiscale feature extraction and region growing: Application in retinal blood vessel detection,” IEEE Trans.
Inform. Technol. Biomed., vol. 14, no. 2, pp. 500–506, Mar. 2010.
[31] J. Staal et al., “Ridge-based vessel segmentation in color images of the
retina,” IEEE Trans. Med. Imag., vol. 23, no. 4, pp. 501–509, Apr. 2004.
[32] K. U. Research. (2011, Jan.). Chase_db1 [Online]. Available:
http://blogs.kingston.ac.uk/retinal/chasedb1/
[33] R. C. Gonzalez and R. E. Woods, Digital Image Processing, 2nd ed.
Boston, MA, USA: Addison-Wesley, 1992.
[34] X. Jiang and D. Mojon, “Adaptive local thresholding by verificationbased multithreshold probing with application to vessel detection in retinal images,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 25, no. 1,
pp. 131–137, Jan. 2003.
[35] B. Al-Diri et al., “An active contour model for segmenting and measuring
retinal vessels,” IEEE Trans. Med. Imag., vol. 28, no. 9, pp. 1488–1497,
Sep. 2009.
[36] R. Perfetti et al., “Cellular neural networks with virtual template expansion
for retinal vessel segmentation,” IEEE Trans. Circuits Syst. II, Exp Briefs,
vol. 54, no. 2, pp. 141–145, Feb. 2007.

Sohini Roychowdhury (M’15) received the M.S. degree from Kansas State University, Manhattan, KS,
USA, in 2010, and the Ph.D. degree from the University of Minnesota, Minneapolis, MN, USA, in 2014,
in electrical and computer engineering.
She is currently an Assistant Professor in the Department of Electrical Engineering at the University
of Washington, Bothell, WA, USA. Her research interests include medical image processing, signal processing, pattern recognition, machine learning, and
artificial intelligence.

Dara D. Koozekanani (M’14) received the Ph.D.
degree in biomedical engineering in 2001, and the
M.D. degree in 2003 from Ohio State University,
Columbus, OH, USA. His research dissertation involved the application of computer vision techniques
to the analysis of optical coherence tomography images. He completed the ophthalmology residency at
the University of Wisconsin, Madison, WI, USA, in
2007, and completed a surgical retinal fellowship at
the Medical College of Wisconsin, Madison, in 2009.
He is currently an Assistant Professor of ophthalmology on the clinical faculty at the University of Minnesota, Minneapolis, MN,
USA. He sees patients with a variety of surgical and medical retinal diseases.
His research interests include the application of ophthalmic imaging technologies and automated analysis of those images.

1749

Keshab K. Parhi (S’85–M’88–SM’91–F’96) received the B.Tech. degree from the Indian Institute of
Technology, Kharagpur, India, in 1982, the M.S.E.E.
degree from the University of Pennsylvania, Philadelphia, PA, USA, in 1984, and the Ph.D. degree from
the University of California, Berkeley, CA, USA, in
1988.
He has been with the University of Minnesota,
Minneapolis, MN, USA, since 1988, where he is currently a Distinguished McKnight University Professor and Edgar F. Johnson Professor in the Department
of Electrical and Computer Engineering. He has published more than 550 papers,
has authored the textbook VLSI Digital Signal Processing Systems (New York,
NY, USA: Wiley, 1999) and coedited the reference book Digital Signal Processing for Multimedia Systems (New York, NY, USA: Marcel Dekker, 1999).
His research interests include VLSI architecture design and implementation
of signal processing, communications and biomedical systems, error control
coders and cryptography architectures, high-speed transceivers, secure computing, and molecular computing. He is also currently working on intelligent
classification of biomedical signals and images, for applications such as seizure
prediction and detection, schizophrenia classification, biomarkers for mental
disorder, brain connectivity, and diabetic retinopathy screening.
Dr. Parhi received numerous awards including the 2013 Distinguished Alumnus Award from IIT, Kharagpur, the 2013 Graduate/Professional Teaching
Award from the University of Minnesota, the 2012 Charles A. Desoer Technical Achievement Award from the IEEE Circuits and Systems Society, the
2004 F. E. Terman Award from the American Society of Engineering Education, the 2003 IEEE Kiyo Tomiyasu Technical Field Award, the 2001 IEEE W.
R. G. Baker Prize Paper Award, and the Golden Jubilee medal from the IEEE
Circuits and Systems Society in 2000. He has served on the editorial boards of
the IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS, I and II, VLSI Systems,
Signal Processing, Signal Processing Letters, and Signal Processing Magazine,
and served as the Editor-in-Chief of the IEEE TRANSACTIONS ON CIRCUITS AND
SYSTEMS I (2004–2005 term), and currently serves on the Editorial Board of the
Springer Journal of Signal Processing Systems. He has served as the Technical
Program Cochair of the 1995 IEEE VLSI Signal Processing Workshop and the
1996 ASAP Conference, and as the General Chair of the 2002 IEEE Workshop
on Signal Processing Systems. He was a Distinguished Lecturer for the IEEE
Circuits and Systems Society during 1996–1998. He served as an Elected Member of the Board of Governors of the IEEE Circuits and Systems Society from
2005 to 2007.

