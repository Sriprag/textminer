IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 1, JANUARY 2016

15

Separable Common Spatio-Spectral Patterns
for Motor Imagery BCI Systems
Amirhossein S. Aghaei∗ , Member, IEEE, Mohammad Shahin Mahanta, Student Member, IEEE,
and Konstantinos N. Plataniotis, Fellow, IEEE

Abstract—Objective: Feature extraction is one of the most important steps in any brain–computer interface (BCI) system. In
particular, spatio-spectral feature extraction for motor-imagery
BCIs (MI-BCI) has been the focus of several works in the past
decade. This paper proposes a novel method, called separable common spatio-spectral patterns (SCSSP), for extraction of discriminant spatio-spectral EEG features in MI-BCIs. Methods: Assuming a binary classification problem, SCSSP uses a heteroscedastic
matrix-variate Gaussian model for the multiband EEG rhythms,
and seeks the spatio-spectral features whose variance is maximized for one brain task and minimized for the other task. Therefore, SCSSP can be considered as a spatio-spectral generalization of the conventional common spatial patterns (CSP) algorithm.
Results: The experimental results on two-class and multiclass
motor-imagery data from publicly available BCI Competition
datasets demonstrate that the proposed computationally efficient
method competes closely with filter-bank CSP (FBCSP), and can
even outperform the FBCSP if enough training data are available.
Furthermore, SCSSP provides us with a simple measure for ranking the discriminant power of extracted spatio-spectral features,
which is not possible in FBCSP. Conclusion: The matrix-variate
Gaussian assumption allows the SCSSP method to jointly process
the EEG data in both spatial and spectral domains. As a result,
compared to the similar solutions in the literature such as FBCSP,
the proposed SCSSP method requires significantly lower computations. Significance: The proposed computationally efficient spatiospectral feature extractor is particularly suitable for applications
in which the computational power is limited, such as emerging
wearable mobile BCI systems.
Index Terms—Brain–computer interface (BCI), common spatial patterns, matrix-variate Gaussian, spatio-spectral features,
separability.

I. INTRODUCTION
RAIN–COMPUTER interface (BCI) systems aim to provide a nonmuscular channel for the brain to control external devices using electrical activities of the brain. These
BCIs can be used in various applications, such as controlling a
wheelchair or neuroprosthesis for disabled individuals, navigation in virtual environment, and assisting healthy individuals in
performing highly demanding tasks or controlling devices such
as quadcopters in 2-D/3-D space [2]–[10]. A comprehensive

B

Manuscript received August 22, 2015; revised September 14, 2015; accepted
September 28, 2015. Date of publication September 28, 2015; date of current
version December 17, 2015. Asterisk indicates corresponding author
∗ A. S. Aghaei is with the Edward S. Rogers Sr. Department of Electrical
and Computer Engineering, University of Toronto, Toronto M5S 3G4, Canada
(e-mail: aghaei@ece.utoronto.ca).
M. S. Mahanta and K. N. Plataniotis are with the Edward S. Rogers Sr.
Department of Electrical and Computer Engineering, University of Toronto.
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2015.2487738

review of such applications is provided by Yuan and He [11].
Motor-imagery BCI systems in particular are based on decoding
imagination of motor tasks, e.g., to control the movement of a
wheelchair, or a mouse curser on computer screen, and move it
to the right/left directions by imagining right/left hand movement. During the past decade, there has been a growing interest
in utilization of electroencephalogram (EEG) signals for noninvasive motor-imagery BCI (MI-BCI) systems, due to their low
cost, ease of use, and widespread availability.
The EEG signal recorded during motor imagination exhibits
task-specific features in both spatial domain and spectral (or
frequency) domains [12]–[15]. Several spatial and spectral processing methods have been used in the literature to extract the
most discriminant features from these EEG signals. The common spatial patterns (CSP) algorithm is one of the most successful solutions which has been widely used in MI-BCIs [13], [16],
[17]. CSP was first used in BCIs with two-class problem, such
as left hand versus right hand movement. Given a set of training
data, this algorithm tries to find spatial filters that maximize
the variance for one class, while minimizing the variance of the
other class. In the case of left/right hand movement, this criterion very well matches the characteristics of EEG signals, since
during the hand movement imagination, the power of ipsilateral
channels is maximized (event-related synchronization), while
the power of contralateral channels is minimized (even-related
desynchronization) [12], [18], [19].
Despite its power in extracting spatial features, CSP completely ignores the spectral characteristics of the EEG signal.
Several variants of CSP have been proposed in the literature to
resolve this problem [20]–[29]. The work in [20], called common spatio-spectral patterns (CSSP) method, applies CSP to
the first-order time delayed version of the EEG data to incorporate the information in the frequency domain. The work in
[21], extends the CSSP solution by utilizing higher order finite
impulse response (FIR) filters that provide more degrees of freedom for extraction of spectral features. To jointly optimize both
the FIR spectral filter and the CSP module, various iterative
procedures have been designed in the literature that alternate
between optimization of the spatial and spectral filters. These
methods include spectrally weighted CSP [26], which utilizes a
criterion similar to CSP to optimize the FIR filter coefficients,
and the more recent methods of iterative spatio-spectral patterns learning (ISSPL) [22] and discriminative filter-bank CSP
(DFBCSP) [27]. Similarly, spatio-spectral iterative procedures
have been utilized to maximize the mutual information between
the features and the classes, and hence, minimization of the
Bayes classification error [23], [28]. However, these iterative

0018-9294 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

16

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 1, JANUARY 2016

Fig. 1. System model for spatio-spectral feature extraction schemes in (a) Filter-bank common spatial pattern (FBCSP), and (b) Separable common spatio-spectral
pattern (SCSSP) methods. Note that FBCSP algorithm utilized in this paper does not deploy the mutual information based feature selector of [25].

methods impose a significantly high computational complexity
on the training stage.
The work in [24] provides a probabilistic Bayesian framework to find the optimized frequency bands and the corresponding spatial filters. Also, a recent work [29] has utilized a
relatively high-dimensional (and hence, computationally expensive) eigen-decomposition on regularized covariances of concatenated time-delayed data to ensure a joint spatio-spectral
optimization of the features. Yet, the most computationally efficient algorithm is the filter-bank CSP (FBCSP) [25], which
uses a bank of Nf bandpass filters to obtain the EEG rhythms
in different frequency bands, and then, deploys a separate CSP
module for each frequency band to extract spatial features from
each EEG rhythm [see Fig. 1(a)].
The FBCSP method has been highly successful for feature
extraction from motor imagery data in BCI Competition IV,
where it has achieved the highest performance for Dataset 2a
and Dataset 2b [25]. Despite its high performance, the FBCSP
method suffers from a number of shortcomings as follows. 1)
FBCSP has a high computational cost at the training phase since
it requires a separate feature extractor for each spectral band,
each of which requires calculation of generalized eigenvectors
for spatial covariance matrices. This issue can be restrictive in
applications that require frequent retraining of the BCI system
(e.g., adaptive scenarios) or the ones that require the training
to be performed on a low power mobile/wearable device. 2)
Since each spectral band is treated independently, possible correlations between different EEG rhythms are ignored by the
FBCSP method, which in turn causes redundancy in the extracted feature set. 3) FBCSP does not provide any measure
for comparing discriminant power of the features obtained from
different spectral bands. Although the CSP features within each
band are sorted based on their discriminant power, it is not
possible to sort the features across different bands.1
1 It is noteworthy that the argument here is regarding the FBCSP feature
extractor, which is composed of bandpass filtering followed by CSP feature

We propose a novel algorithm that simultaneously processes
the EEG rhythmic activities in both spatial and spectral domains, and extracts the most discriminant spatio-spectral features across all the frequency bands. Using a matrix-variate
Gaussian model for spatio-spectral EEG patterns, we develop
a bilinear feature extractor, called separable common spatiospectral patterns (SCSSP), which has the following advantages
compared to the FBCSP method: First, the SCSSP has significantly less computational cost for training since it requires
training of only two CSP-type modules instead of Nf modules in FBCSP. Second, the features are extracted based on joint
analysis of both spatial and spectral characteristics of the signal.
Therefore, correlations between different spectral bands can be
exploited for feature extraction. Third, a measure is provided to
rank the discriminatory power of extracted spatio-spectral features, which enables us to directly perform dimensionality reduction without any need to deploy a separate subsequent feature
extraction/selection module, such as the one suggested in [25].
The rest of this paper is organized as follows: Section II
provides the system model and introduces the matrix-variate
Gaussian model used throughout this paper. The proposed
SCSSP method is discussed in Section III-A. Section III-B
briefly compares the SCSSP with the state of the art FBCSP
method to provide the reader with a better understanding of
the similarities and the differences between these two solutions.
Multiclass extension of the SCSSP method is discussed in Section III-C. Section IV studies the performance of the SCSSP
method in different experimental setups. Finally, the summary
and concluding remarks are presented in Section V.

extraction, as shown in Fig. 1(a). The work in [25] suggests the use of a separate
feature selector to estimate the discriminance power of the extracted features,
using the mutual information criteria; however, such feature selection is not
an integral part of the FBCSP algorithm and can be substituted with any other
feature selector/extractor that suits this purpose. Therefore, this feature selection
stage that sorts the features from different frequency bands based on the mutual
information criterion is not employed in this paper.

AGHAEI et al.: SCSSP FOR MOTOR IMAGERY BCI SYSTEMS

17

II. SYSTEM MODEL
The processing pipeline for the proposed SCSSP method is
presented in Fig. 1(b). Consider an EEG epoch with Nt time
samples from Nch channels.2 The EEG signal is first passed
through a set of Nf bandpass filters. This process extracts Nf
rhythmic activities from each EEG channel, where each rhythm
has a length of Nt samples. These extracted rhythms form a
three dimensional tensor, as shown in Fig. 1(b), which consists
of Nt matrices of size Nf × Nch . Each of these matrices represents a spatio-spectral EEG pattern at a certain time instant.
The proposed SCSSP method operates on these matrix-variate
patterns, denoted by X ∈ RN f ×N c h , in order to extract the most
discriminant features for classification.
Using a heteroscedastic matrix-variate Gaussian model [30]
for X, we provide a mathematical framework that allows us to
take into account the joint characteristics of the spatial and spectral features. Let f (X|Ωi ) denote the conditional probability of
X under class Ωi . The matrix-variate Gaussian model is defined
as
X|Ωi ∼ N (Mi , Φi , Ψi ),

1≤i≤C

(1)

where C is the total number of classes, Mi denotes the class
mean, Φi is the spectral covariance, also called column-wise or
left covariance, and Ψi is the spatial covariance, also called rowwise or right covariance. Since X is obtained from bandpass
filtering of the EEG signal, all classes have zero mean, i.e.,
Mi = 0 for 1 ≤ i ≤ C. Therefore, the discriminant information
is contained in the second-order statistics of the data, defined as
follows


(2)
Φi = tr−1 (Ψi ) ∗ EX|Ω i XXT


Ψi = tr−1 (Φi ) ∗ EX|Ω i XT X .
(3)
Let x = vec(X) be the vectorized representation of X obtained from concatenation of its columns, and Σi be the covariance matrix of x under Ωi . The model in (1) implies that
x|Ωi ∼ N (0, Σi ), 1 ≤ i ≤ C, where Σi = Ψi ⊗ Φi . Furthermore, any bilinear operation of the form WL XWR is equivalent
to the linear operation WT x = (WR ⊗ WL )T x.

The next theorem provides the solution for (4).
Theorem 1: Let x = vec(X), where X ∈ RN f ×N c h has a
matrix-variate Gaussian distribution as given by (1). Then, the
solution to (4) is given as follows: W = WR ⊗ WL , and
−1


Λ = (ΛR ⊗ΛL) ΛR ⊗ ΛL + (IN c h − ΛR ) ⊗ IN f − ΛL
where IK is the identity matrix of size K and the matrices ΛR ,
WR , ΛL , and WL are, respectively, the solutions to generalized
eigenvalue problems for spatial and spectral covariances
Ψ1 WR = (Ψ1 + Ψ2 ) WR ΛR

(5)

Φ1 WL = (Φ1 + Φ2 ) WL ΛL .

(6)

Proof. The proof is provided in Appendix A.

Using this theorem, we can break the generalized eigenvalue
problem of (4) into two lower dimensional problems presented
in (5) and (6). Note that WL provides the spectral transformation
matrix, whereas WR provides the spatial transformation matrix.
These two transformations will be simultaneously applied to the
matrix-variate data X.
To provide a better insight into the result of Theorem 1, let
λk , 1 ≤ k ≤ Nf Nch , denote the diagonal entries of Λ sorted in
descending order. Theorem 1 implies each λk corresponds to a
pair of eigenvalues from ΛL and ΛR as follows:
λk =

λL ,l[k ] λR ,j [k ]

Consider a binary classification problem, i.e., Ωi ∈ {Ω1 , Ω2 }.
Based on the properties of matrix-variate Gaussian model, and
following the general goal of the CSP approach, we look for
a bilinear operation on X, which simultaneously diagonalizes
both Σ1 and Σ2 . In other words, we look for transformation
matrices WL and WR , which are the solutions to the following
generalized eigenvalue problem:
Σ1 W = (Σ1 + Σ2 ) WΛ,
where

W = WR ⊗ WL , and

(4)

Σi = Ψi ⊗ Φi .

2 In this paper, scalars, vectors, and matrices are, respectively, shown in regular
lowercase/uppercase (e.g., a or A), boldface lowercase (e.g., a), and boldface
uppercase (e.g., A). Trace of A is denoted by tr(A). Also, the Kronecker
product of the matrices A and B is denoted as A ⊗ B.

(7)

Here, λL ,l[k ] and λR ,j [k ] are the corresponding eigenvalues
in ΛL and ΛR , with 1 ≤ l[k] ≤ Nf and 1 ≤ j[k] ≤ Nch .3
Also, the eigenvectors corresponding to λk are expressed as
wk = wR ,j [k ] ⊗ wL ,l[k ] , where wR ,j [k ] and wL ,l[k ] are the
eigenvectors in WR and WL corresponding to λR ,j [k ] and
λL ,l[k ] , respectively. Based on these results, the following algorithm will be used for extracting the “d” most discriminant
spatio-spectral features.
1) Assuming that Ni training samples Xi,n , 1 ≤ n ≤ Ni , are
available for each class Ωi , estimate the spectral covariance and spatial covariance of the data, using4
Φ̂ i =

III. SEPARABLE COMMON SPATIO-SPECTRAL PATTERNS
A. Definition and Methodology

λL ,l[k ] λR ,j [k ]
.
+ (1 − λL ,l[k ] )(1 − λR ,j [k ] )

Ψ̂ i =

1

Ni


Nch Ni

n =1

Xi,n XTi,n

(8)

Ni
1 
XT Xi,n .
Nf Ni n =1 i,n

(9)

2) Solve the generalized eigenvalue problems in (5) and (6)
for the estimated spatial and spectral covariances.
3) Using (7), calculate the eigenvalues λk and sort them in
descending order to determine the indices l[k] and j[k].
3 The indices l[k] and j[k] are determined as follows. Let λ
L , p and λR , q
be the eigenvalues of Λ L and Λ R , respectively, where 1 ≤ p ≤ N f and 1 ≤
q ≤ N c h . First, take all the possible pairs of λL , p and λR , q , and form the
corresponding λ values using (7). Then, sort these resulting values in descending
order and denote them by λk , where λ1 ≥ λ2 ≥ · · · ≥ λN f N c h . For each λk ,
the corresponding value of index p will be denoted by l[k], and the corresponding
value of index q will be denoted by j[k].
4 Note that in Section II, the temporal length of each EEG epoch was denoted
by N t . Therefore, N i equals N t times the total number of training EEG epochs
for class Ω i .

18

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 1, JANUARY 2016

4) Extract the d most discriminant features by calculating
yk =

w LT , l [k ] Xw R , j [k ]

k ∈ {1, N f N c h , 2, (N f N c h − 1), . . . ,

d
2

, (N f N c h −

(10)
d
2

+ 1)}.

Note that d is an even number here, similar to the CSP.
5) Calculate the normalized power of features over the length
of epoch, in logarithmic scale, as follow:


var (yk )
zk = log
(11)
Σk var (yk )
where var(yk ) function calculates the variance or power
of yk over Nt samples, and Σk var(yk ) represents the total
power of the d features.
6) Construct the feature vector z = [z1 , zN f N c h , . . . ]T ∈
Rd×1 as the output of the SCSSP algorithm.
In the aforementioned algorithm, the values of λk can be
considered as a measure to determine the discriminant power of
feature yk , as follows. Similar to the conventional CSP method,
λk ranges between zero and one. Values close to zero or one
correspond to high discriminant features, whereas values close
to 12 correspond to low discriminant features. In other words,
the pair of features [y1 , yN f N c h ]T provide the most discriminant power. Similarly, the features corresponding to k = 2 and
k = (Nf Nch − 1) are the second most discriminant features,
and so on. Thus, the pairs of extracted spatio-spectral features
in z are sorted according to their discriminant power in descending order. These features are then passed to a classifier to
determine the Ω̂. In our experimental studies, we consider two
simple possible choices for the classifier: (a) naive Bayes Parzen
window (NBPW) classifier [25] and (b) linear minimum mean
distance classifier [16].
B. Comparative Discussion on the Theoretical Assumptions of
FBCSP and SCSSP
Consider the matrix-variate data X at the output of the bandpass filter bank, and denote the f th row vector of X by xf ,
where 1 ≤ f ≤ Nf . Also, let x = [x1 , . . . , xN f ] denote the
row-vector that is generated from the row-wise concatenation
of the elements in X, i.e., x = (vec(XT ))T . The class conditional covariance matrix of each row-vector xf will be represented by Ψfi , and the class conditional covariance matrix of x

is represented by Σi .
Recall that in the FBCSP approach, each row-vector xf is
processed independently from the other rows, using the projecf
containing the generalized eigenvectors of Ψf1
tion matrix WR
f
f
and Ψ1 + Ψ2 . The projected feature pairs are then sorted in
descending order of significance. Finally, the log-power of the
resulting features are calculated during the epoch length and
form the f th row of the output feature matrix. If we compare
this approach with SCSSP’s approach, the following differences
can be pointed out.
The separability assumption in the matrix-variate Gaussian
model, which is used by the SCSSP, implies that the covariance
matrix of each row-vector xf is equal, up to a scale, to the
covariance matrix of other row vectors. As a result, the SCSSP
only looks for one spatial filtering matrix WR , which will be

commonly applied to all the row vectors in X. In contrast, the
FBCSP method assumes that each row-vector xf has a unique
covariance matrix, and hence, looks for a unique spatial filtering
f
for each row.
matrix WR
The other important difference between FBCSP and SCSSP
is in the spectral processing of the data. FBCSP assumes that
different EEG rhythms in different frequency bands are independent from each other, and thus, independently processes
each rhythm. However, the SCSSP calculates the class conditional spectral covariance matrix Φi and uses this information together with the information from the spatial covariance
matrix Ψi for extraction of the most discriminant spatio-spectral
features. Note that owing to the matrix-variate Gaussianity assumption, the SCSSP assumes all EEG channels have the same
spectral covariance matrices, up to a scale, and hence, calculates
a common spectral covariance matrix for all channels.
In order to further clarify these points, consider the row vector
x = [x1 , . . . , xN f ], which contains all the elements of X. The
FBCSP method assumes a block-diagonal structure for the class
conditional covariance of x as follows:
⎡ 1
⎤
Ψi 0 · · · 0
⎢ 0 Ψ2i
0 ⎥

⎢
⎥
(12)
Σi = ⎢ ..
⎥
..
⎣ .
⎦
.
0

0

Nf

Ψi

whereas the SCSSP assumes the following block-wise structure
⎡
⎤
φ1,1 Ψi φ1,2 Ψi · · · φ1,N f Ψi
⎢ φ2,1 Ψi φ2,2 Ψi · · · φ2,N f Ψi ⎥

⎢
⎥
(13)
Σi = ⎢
⎥
..
..
⎣
⎦
.
.
φN f ,1 Ψi φN f ,2 Ψi · · · φN f ,N f Ψi
where φm ,n represents the (m, n)th element of the spectral
covariance matrix Φ.
It is noteworthy that both assumption in (12) and (13) are
restrictive models for the spatio-spectral covariance of the data.
The FBCSP completely ignores the off-diagonal blocks of the

Σi , while trying to provide an accurate estimate for the diagonal blocks. In contrast, the SCSSP takes into account the

off-diagonal blocks of Σi by making the simplifying assump
tion that all the blocks in Σi are up to a scale equal to each
other, where the scaling factor is determined by the elements of
spectral covariance matrix.
For further clarification, note that FBCSP uses Nf ∗ Nch ∗

(Nch + 1)/2 parameters to estimate the covariance matrix Σi ,
whereas the SCSSP uses Nf ∗ (Nf + 1)/2 + Nch ∗ (Nch +
1)/2 parameters. In our experimental setups Nch > Nf > 1;
therefore, the FBCSP always uses more parameters compared
to SCSSP (ref. Tables VI and VII for the numerical values). Similarly, the number of weighting coefficients used for extraction of
EEG features is also larger for FBCSP in comparison with the
SCSSP. Indeed, FBCSP uses Nf ∗ Nch coefficients, whereas
SCSSP uses Nf + Nch coefficients.5 Therefore, SCSSP
5 For multiclass extension of FBCSP/SCSSP, where C > 2, the aforementioned values will be multiplied by a factor of C , as explained in Section III-C.

AGHAEI et al.: SCSSP FOR MOTOR IMAGERY BCI SYSTEMS

can be viewed as a more restrictive regularizer compared to
the FBCSP method.
C. Multiclass Extension of the SCSSP Method
Although SCSSP is derived for a binary classification scenario, there exist several solutions to utilize a binary feature extractor in a multiclass scenario, such as the divide-and-conquer,
pairwise, and one-versus-rest (OVR) strategies reviewed in [25].
Since OVR has been shown to provide best performance for
FBCSP [25], we utilize OVR strategy for multiclass extension
of SCSSP too.6 Consider the training phase of the SCSSP, and
let Ωi be the set of all motor-imagery tasks excluding the ith
task Ωi . Starting from i = 1, SCSSP finds the bilinear trans(i)
(i)
formation matrices WL and WR to extract d0 features that
provide high discriminance power for classification of Ωi versus Ωi . This procedure is repeated for i ∈ {1, . . . , C}, which
results in a set of C spectral transformation matrices, and C
spatial transformation matrices.
Now, consider the testing phase, and let X ∈ RN f ×N c h represent a test sample. The matrix X will be passed through
C pairs of joint spatio-spectral transformation matrices, i.e.,
(i)
(i)
Ti = {WL , WR }, i ∈ {1, . . . , C} to generate a set of d0 ∗ C
features. The most discriminant features in this set consists of
the first pair of discriminant features obtained from each Ti ,
which forms a set of 2 ∗ C features. Similarly, the second pair
of features from each Ti form the next 2 ∗ C discriminant features, and so on. Therefore, in the resulting feature vector, the
first 2 ∗ C features will correspond to the most discriminant
group of features, and similarly the nth group of 2 ∗ C features
represent the nth most discriminant features.
To classify the extracted features in the multiclass scenario,
the following two approaches are used. For the NBPW classifier,
the OVR approach of [25] is utilized, where C binary NBPW
classifiers are deployed to estimate the posterior probability of
each class versus the rest of classes, and the one with the highest
probability is selected as the classifier’s output. For the linear
minimum mean distance classifier, all the C sets of features
extracted from different choices of one class versus the rest of
classes are concatenated to form a feature vector, which is then
passed to the classifier. The classifier’s output in this case will be
the label of the class whose mean has the minimum Euclidean
distance with the classifier’s input feature vector.
IV. EXPERIMENTAL ANALYSIS
In this section, we will study the performance of the proposed
SCSSP method in both two-class and multiclass motor-imagery
scenarios and compare it with the conventional FBCSP method.
For these studies, we use Dataset V from BCI competition III
[31] and Dataset 2a from BCI competition IV [32].7 As suggested by the providers of the former dataset, we will also study
6 It should be noted that possible extensions of SCSSP to multiclass scnearios
requires a comprehensive future study.
7 In this paper, we consider the state of the art FBCSP algorithm as the baseline
solution for our experimental studies. However, interested readers are referred
to [25] for comparative analysis of FBCSP and CSP algorithms.

19

the effect of surface Laplacian (SL) filtering and channel selection (CS) on the performance of the SCSSP method. The
surface Laplacian method can be viewed as a high-pass spatial filter that removes the nonlocalized signal components as
well as the interference from neighboring areas caused by volume conduction [33], [34]. The CS is a strategy to reduce the
dimensionality of the EEG signal by only selecting the most informative EEG channels. In our experiments, CS is performed
by selecting the centroparietal channels located over the motor
cortex.
Since the main focus in this paper is on design of the feature
extraction step, we will not consider any separate feature selection after the SCSSP or FBCSP, and will directly pass the output
of the SCSSP or FBCSP to the classifier. Recall that one of the
main motivations behind the design of the SCSSP method is to
develop a feature extraction method that can effectively sort the
extracted spatio-spectral features based on their discriminance
power.
Therefore, the following processing steps will be considered
for implementation of the SCSSP and FBCSP methods. First,
the multichannel EEG signal will be passed through an optional
stage of SL filtering or CS. The resulting signal will then be
passed through a bank of bandpass filters, to generate the multiband EEG rhythms. At the next step, either SCSSP method or
the FBCSP method will be applied to this multiband EEG data
to extract a set of discriminant spatio-spectral features. These
extracted features will then be directly passed to a classifier.
The classifiers studied in this paper are the NBPW classifier,
as suggested by [25], and the simple linear minimum mean
distance (Lin) classifier [16]. This procedure results in a total
of 16 = 2 × 2 × 2 × 2 different combinations for feature extraction and classification, namely SL(Yes/No), CS(Yes/No),
FBCSP/SCSSP, and NBPW/Lin.
A. Experiment Setup
1) BCI Competition III, Dataset V (Exp. 1): The goal of this
experiment is to classify the following mental imagery tasks: left
hand movement (Ω1 ), right hand movement (Ω2 ), and generation of words beginning with a random letter (Ω3 ). This dataset
contains EEG of three normal subjects recorded in four sessions.
Each session consists of sequential 15 second trials of the three
tasks. The first three sessions will be used for training/crossvalidation purposes, whereas the last session is only used as
unseen data for competition, i.e., testing phase. The raw EEG
used in our studies is recorded using 32-electrode Biosemi system at 512-Hz sampling rate. The BCI algorithm is required to
 every 0.5 second, using only the
provide the estimated label Ω
last second of EEG recording. The performance measure for this
competition is correct classification rate (CCR) of the overall
system, defined as the ratio of number of successfully classified
samples over the total number of samples. The chance of random
classification in this experiment is Prand = 1/C = 0.33. The
winning algorithm for this competition in the literature used SL
and CS followed by short-time Fourier transformation, and classifies the extracted features using linear discriminant analysis

20

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 1, JANUARY 2016

(LDA) [35]. It achieves an average performance of 62.72% at
the classifier output.8
2) BCI Competition IV, Dataset 2a (Exp. 2): The goal of this
experiment is to classify the following motor-imagery tasks: left
hand (Ω1 ), right hand (Ω2 ), both feet (Ω3 ), and tongue (Ω4 )
movement. This dataset contains EEG recordings of nine normal subjects recorded in two sessions. The signals are recorded
using 22 Ag/AgCl electrodes at 250-Hz sampling rate. Each
session consists of six runs, each of which includes 48 trials
of length 3 second, yielding a total of 288 trials per session.
The first session will be used for training/cross-validation and
the second session is only used as unseen data for testing phase.
This dataset also contains three electrooclugram (EOG) channel
recordings that are provided for subsequent application of artifact processing methods and shall not be used for classification.
The competition requires the BCI algorithms to provide a continuous classification output for each sample in the form of the
 The performance measure for this competiestimated label Ω.
tion is the kappa coefficient (κ) of the overall system [36], which
is defined as: κ = (CCR − Prand )/(1 − Prand ). Here, Prand is the
probability of random classification, i.e., Prand = 1/C = 0.25
for this experiment. Note that the measure κ is normalized such
that κ = 0 for a random classifier. The winning algorithm for
this competition in the literature is the FBCSP-NBPW method.
Table I presents the parameters used to implement the processing steps and extract the spatio-spectral feature matrix
XN f ×N c h . It should be noted that in each experiment, the epoch
length and frequency range used by the winning algorithm in
the original competition are adopted in this paper to provide a
fair comparison between alternative solutions.
3) Comparative Note on the Datasets in Exp. 1 and Exp. 2:
Although both databases in Exp. 1 and Exp. 2 contain EEG
data from motor-imagery tasks, these two datasets are significantly different in terms of the availability of the training data.
In Exp. 1, each trial is of length 15 second, which is significantly
longer than the 3 second trial length in Exp. 2. In the context of
motor-imagery tasks, the training trial length is of great importance. When the training trials are longer, the subjects will have
enough time to concentrate on the desired motor-imagery task
and produce stable brain rhythms that can be reliably used for
training. Furthermore, the training data in Exp. 1 is collected
during three sessions, whereas Exp. 2 only includes one session
of EEG recording for training. It is well known in the context
of motor-imagery BCIs that the EEG characteristics exhibit intersession variations, which need to be taken into account while
training the BCI algorithm [37].
Since motor-imagery BCI systems are mostly designed for
long-term utilization by the user, it is usually assumed that
the BCI algorithm has access to a training dataset with long
enough trials, which are collected over at least two different
recording sessions. From this perspective, the training dataset in
Exp. 1 can be considered as a typical dataset for motor-imagery
applications, whereas the training set in Exp. 2 is an extreme
8 Using a post-processing strategy, called mental tasks transitions detector, the

work in [35] improves this performance to 68.65%. However, analysis of the
effect of post-processing methods on FBCSP and SCSSP algorithms is outside
the scope of this paper. Therefore, to have a fair comparison, the performance
of all methods at the classifier’s output is studied in this paper.

case where only one recording session with very short trials is
available for training the algorithms. We have included Exp. 2
in our analysis to study the robustness of different algorithms in
the extreme conditions.
Finally, note that SL filter requires the exact locations of EEG
sensors. The dataset in Exp. 1 includes the exact coordinates of
the sensors, using the standard 10–10 system. In contrast, the
dataset in Exp. 2 only contains the approximate relative locations
of the sensors. We have mapped these approximate locations to
the following closest standard locations: Fz, FC3, FC1, FCz,
FC2, FC4, C5, C3, C1, Cz, C2, C4, C6, CP3, CP1, CPz, CP2,
CP4, P1, Pz, P2, POz. The effect of this approximate mapping
will be discussed later in the experimental results.
B. Epoch Segmentation
Both FBCSP and SCSSP methods operate on the epochs of
EEG data [ref. Fig. 1(a)–(b)] and treat the feature set extracted
from each epoch as one sample used for training or testing purposes. In testing phase, the EEG epochs are extracted by truncating the data with rectangular windows of length T seconds,
where T = 1 for Exp. 1 and T = 2 for Exp. 2. These epochs are
extracted every 0.5 second in Exp. 1 and every 0.1 s in Exp. 2;
hence every two consecutive epochs have a 50% (or 12 T ) overlap
9
in Exp. 1 and a 95% (or 19
20 T ) overlap in Exp. 2, respectively.
In training phase, a very similar procedure is used and the only
restriction is to make sure that the training epochs in each trial
are extracted from the time period that correspond to execution
of motor-imagery tasks, explained as follows.
1) In Exp. 1, each trial lasts for approximately 15 second;
therefore, approximately a total of 29 training epochs
are extracted from each trial. Each of the three training sessions lasts for almost 4 min; therefore, a total of
1392(= 29 ∗ 16 ∗ 3) epochs will be extracted for training
purposes.
2) In Exp. 2, each trial lasts for only 3 second, and the FBCSP
method only uses the time interval from t = 0.5 until
t = 2.5 second. To have a fair comparison, we have used
the same time interval for the SCSSP method as well. The
training session has 288 trials; therefore, a total of 288
epochs will be extracted for training purposes.10
C. Results for Two-Class Scenario (Left Hand Versus Right
Hand)
Since both SCSSP and FBCSP methods are originally designed for two-class scenarios (ref. Section III-A), we first focus on the binary classification problem of classifying left hand
movement imagination versus right hand movement imagination. The results for multiclass extensions of the SCSSP and
FBCSP methods will be presented in Section IV-D.
1) Cross-Validation Results: The performance of BCI algorithms highly depends on the dimensionality of the feature space
9 Note that in Exp. 2, dataset providers have marked some test trials as artifactcontaminated, which are excluded from our analysis.
10 The aforementioned numbers of training epochs (i.e., 1392 and 288) are
rough estimates. For each subject, a few training trials are contaminated by
artifacts that are excluded from the training set (these trials are pre-marked in
both datasets).

AGHAEI et al.: SCSSP FOR MOTOR IMAGERY BCI SYSTEMS

21

TABLE I
PARAMETERS USED FOR FEATURE EXTRACTION ALGORITHMS IN EXP. 1 AND EXP. 2

Note that the parameters used for implementation of SL filter are similar to the ones chosen in [31].

at the classifier’s input, denoted by d. To determine the optimal
value of d, denoted by dopt , for each feature extraction scheme,
we perform cross-validation on the training data. In case of
Exp. 1, since we have access to three different training sessions,
a threefold cross-validation is performed to make sure that for
each validation run the BCI system has access to two distinct
sessions for training and one session for analyzing the performance. This strategy is helpful in making sure that intersession
variations of the EEG data are taken into account during the
validation.
The dataset in Exp. 2, however, only contains one training session, which prevents us from adopting the same cross-validation
strategy as Exp. 1. Therefore, we chose to perform a 5 × 5-fold
randomized cross-validation strategy. In this strategy, the training data will be randomized five times. After each randomization, the data will be divided into five folds. In each validation
run, four of these folds will be used for training the BCI algorithm and the remaining fold will be used for analyzing the
resulting performance. This procedure results in five validation
runs for each randomization, which leads to a total of 25 = 5 × 5
validation runs.
To determine dopt for each feature extraction method, the
overall performance of the BCI is calculated for all possible
values of d during each validation run. Thus, for each d, we
have a total of three performance results in Exp. 1 and 25 results
in Exp. 2. For each d, these performance results are averaged
over all validation runs, and their corresponding standard error
over these runs are calculated. The value of d that results in the
maximum average performance is the dopt .
The validation results for Exp. 1 and Exp. 2 are presented
in Fig. 2(a) and (c), respectively. These results are presented
in groups of size 4, in the following order: FBCSP-NBPW,
FBCSP-Lin, SCSSP-NBPW, and SCSSP-Lin. In each figure,
the first group of results correspond to the case where no SL
or CS is applied. Similarly, the next groups correspond to other
possible combinations of SL and CS. For each method, the
average validation performance over all the subjects, together
with its corresponding standard error, are presented.

Despite the fact that SCSSP has less computational cost compared to FBCSP, Fig. 2(a) shows that for all combinations of
SL and CS in Exp. 1, SCSSP-NBPW outperforms FBCSPNBPW and SCSSP-Lin either outperforms or closely competes
with FBCSP-Lin. In Exp. 2, however, Fig. 2(c) illustrates that
SCSSP cannot compete with FBCSP-based methods. In order
to describe this difference between Exp. 1 and Exp. 2, recall that
the most important difference between these two experiments is
the availability of training data. Considering these differences
discussed in Section IV-A3, the cross-validation results reveal
that the performance competency and computational cost efficiency of the SCSSP are achieved at the cost of requiring more
training samples, compared to the FBCSP.
Based on our discussions in Section III-B, the higher sensitivity of the SCSSP to the number of training samples can be
explained as follows. The FBCSP only focuses on the diagonal block matrices of Σi  matrices, as defined in (12), whereas
SCSSP aims to provide an estimate of both diagonal and offdiagonal block matrices of Σi  matrices, as defined in (13).
Therefore, when the number of training samples is extremely
small, SCSSP cannot reliably estimate Σi  , and consequently,
does not succeed in extracting discriminant features from the
EEG data. The high performance of the SCSSP method in Exp. 1
shows that the matrix-variate Gaussian model deployed by
SCSSP algorithm can very well describe the statistical characteristics of the EEG signals; however, reliable estimation of
its parameters requires access to a large training set.
These results suggest that in order to benefit from the low
computational cost and high performance of the SCSSP, we
need to provide this algorithm with enough training samples.
This condition is not restrictive in most motor-imagery BCI applications, since these BCIs are generally designed for long-term
utilization, which guarantees access to large enough training
sets. In such cases, SCSSP can reliably estimate signal parameters, which allows for reducing the computational cost while
improving the performance of the BCI system.
2) Test (Competition) Results: The average test performance
over all the subjects for unseen competition data in Exp. 1 and

22

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 1, JANUARY 2016

Fig. 2. Comparison of the average performance in two-class motor-imagery classification scenarios (Left hand versus Right hand movement) in Exp. 1 and
Exp. 2. The performance results for SCSSP-based and FBCSP-based solutions in (a) validation phase of Exp. 1, (b) testing phase of Exp. 1, (c) validation phase
of Exp. 2, and (d) testing phase of Exp. 2 are presented, respectively. For validation results, the average performance of each method over all the subjects and all
validation runs, together with its corresponding standard error, is plotted. For more clarity, the results are illustrated in four groups, depending on whether or not
the SL and CS are applied to the EEG data. Note that the performance measure is the CCR in Experiment-1, and the Kappa coefficient (κ) in Experiment-2.

Exp. 2 is presented in Fig. 2(b) and (d). The different methods
are categorized in groups of size four, depending on whether or
not the SL and CS are applied to the data, similar to Fig. 2(a)
and (c). For each method and each subject, the value of dopt
obtained from the validation phase is used to set the feature space
dimensionality in the test phase, and then, the feature extractor
and classifier are retrained by the whole training dataset. Since
the training/testing procedure has only been performed once in
this phase, the results do not include any standard error analysis.
These results show a trend similar to the cross-validation
results. In Exp. 1, SCSSP-based methods outperform FBCSPbased methods when no CS is performed and closely compete
with FBCSP-based methods in the presence of CS. In Exp. 2, the
SCSSP cannot compete with other methods due to the lack of
access to sufficient training information for reliable estimation
of model parameters.

3) Effect of SL and CS: Comparison of the average performances in Fig. 2 shows that combination of SL with SCSSP has
different effects on the classification performance depending
on whether or not CS has been applied, as follows. When
CS is applied, the SL slightly improves the performance of
SCSSP-based methods in both Exp. 1 and Exp. 2. However,
when there is no CS, the SL can degrade the performance of
SCSSP-based methods.
It can be seen that the FBCSP-Lin method achieves its highest
performance when both SL and CS are deployed, whereas
SCSSP-Lin achieves its highest performance when it is applied
to the raw data, with only one exception which is the test phase
of Exp. 2. In case of the FBCSP-Lin method, the combination
of SL and CS helps to manually reduce the dimensionality of
the space in which the spatial covariances Ψfi are calculated,
without losing the local information relevant to the motor cortex

AGHAEI et al.: SCSSP FOR MOTOR IMAGERY BCI SYSTEMS

23

Fig. 3. Comparison of average performance in multiclass motor-imagery classification scenarios in Exp. 1 and Exp. 2. The performance results for SCSSP-based
and FBCSP-based solutions in (a) validation phase of Exp. 1, (b) testing phase of Exp. 1, (c) validation phase of Exp. 2, and (d) testing phase of Exp. 2 are
presented, respectively. For validation results, the average performance of each method over all the subjects and all validation runs, together with its corresponding
standard error, is plotted.

area. This dimensionality reduction improves the accuracy of
the spatial covariance estimation for each band, which in turn
improves the performance of the system.
In the case of SCSSP, however, it is not necessarily desired
to reduce the dimensionality of the data in the spatial domain
while having the same dimensionality in the spectral domain.
The main reason for this effect is as follows. The SCSSP only
calculates one common spatial covariance matrix for all the
bands. As a result, SCSSP treats different rows of the matrix
X ∈ RN f ×N c h as extra training samples for calculation of the
covariance matrix. In other words, SCSSP method has access to
Nf ∗ Ni training samples for estimation of Ψi , whereas FBCSP
has only access to Ni samples for estimation of each Ψfi . On the
other hand, SCSSP requires to estimate the common spectral
covariance matrix Φi by treating different columns of X as extra training samples, which leads to a total of Nch ∗ Ni samples.
As a consequence, any reduction in the number of EEG chan-

nels results in a significant reduction in the number of training
samples for Φi .
In other words, in SCSSP, the CS results in higher accuracy
for spatial covariance estimation at the cost of reducing the
accuracy for spectral covariance estimation. The experimental
results suggest that these two opposite effects almost cancel out
each other and there is marginal change in the performance of
SCSSP-based methods when CS and SL are utilized together
with the SCSSP, as opposed to when SCSSP is directly applied
to the raw data. Note that as long as CS does not deteriorate the
overall performance, it might still be beneficial since it reduces
the computational cost of the feature extraction.
D. Results for Multiclass Scenario
Using the OVR strategy described in Section III-C, this section examines the performance of both SCSSP and FBCSP

24

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 1, JANUARY 2016

TABLE II
CROSS-VALIDATION PERFORMANCE RESULTS FOR DIFFERENT ALGORITHMS IN EXPERIMENT-1

For each method and each subject, the optimal dimension (d opt ) is presented together with the corresponding average correct classification rate ± standard error over all the validation
runs. Note that d opt = N f ∗ d csp ∗ C for FBCSP-based methods and d opt = d scssp ∗ C for SCSSP-based methods, where 2 ≤ d csp ≤ N c h and 2 ≤ d scssp ≤ N f ∗ N c h .

TABLE III
CROSS-VALIDATION PERFORMANCE RESULTS FOR DIFFERENT ALGORITHMS IN EXPERIMENT-2

For each method and each subject, the optimal dimension (d opt ) is presented at the bottom row, whereas the top row presents the corresponding average correct classification rate
± standard error over all the validation runs. Note that d opt = N f ∗ d csp ∗ C for FBCSP-based methods and d opt = d scssp ∗ C for SCSSP-based methods, where 2 ≤ d csp ≤ N c h
and 2 ≤ d scssp ≤ N f ∗ N c h .

AGHAEI et al.: SCSSP FOR MOTOR IMAGERY BCI SYSTEMS

25

TABLE IV
TEST PERFORMANCE RESULTS FOR DIFFERENT ALGORITHMS IN EXP. 1

methods in multiclass motor-imagery scenarios (C = 3 in
Exp. 1 and C = 4 in Exp. 2).
1) Cross-Validation Results: Fig. 3(a) and (c) present the
average validation performance over all the subjects, together
with its corresponding standard error, in Exp. 1 and Exp. 2,
respectively. Similar to the results presented in Section IV-C1, in
the multiclass scenario the SCSSP-based methods outperform
FBCSP-based algorithms in Exp. 1 while providing a better
computational efficiency. Also, similar to the two-class scenario,
in the multiclass case SCSSP cannot compete with FBCSP in
Exp. 2 due to small size of training set (ref. Section IV-C1).
For completeness of the reported results, we have provided
detailed results of validation phase for each participant in
Tables II and III. These results are presented in groups of size
4, in the following order: FBCSP-NBPW, FBCSP-Lin, SCSSPNBPW, and SCSSP-Lin. In each table, the first group of results
correspond to the case where no SL or CS is applied. Similarly,
the next groups correspond to other possible combinations of SL
and CS. These results reveal that despite the high variations of
the performances between different subjects, the relative performance of different methods is consistent among all the subjects.
2) Test (Competition) Results: Fig. 3(b) and (d) present the
average test performance over all the subjects for unseen competition data in Exp. 1 and Exp. 2, respectively. These results
have a trend similar to the two-class results in Section IV-C2,
except for the fact that in Exp. 1 SCSSP-based methods can no
longer outperform FBCSP-based ones when no CS is applied.
However, it should be noted that even in these cases SCSSP is
still closely following FBCSP’s performance while providing a
significant reduction in the computational cost.
For the reader’s reference, the corresponding detailed results
are provided in Tables IV and V. Similar to the validation results
in Section IV-D1, these test results show a consistent relative
performance among all the subjects.

Fig. 4. Validation performance for the SCSSP-based and FBCSP-based
methods versus the number of features extracted by the feature extraction
method in the validation phase for the first subject in (a) Experiment-1 and
(b) Experiment-2.

E. Effect of Feature Space Dimensionality
In this section, we study the effect of number of extracted
features on the performance of SCSSP-NBPW and SCSSP-Lin
algorithms, and compare them with the FBCSP-NBPW and
FBCSP-Lin solutions. The results for the first subjects in Exp. 1
and Exp. 2 are shown in Fig. 4. Similar trends are observed
for other subjects as well. These results correspond to the case
where no SL or CS is applied to the EEG.
The results of Exp. 1 in Fig. 4(a) show that SCSSP-Lin outperforms FBCSP-Lin when d < 200 and closely follows its
performance with a marginal gap when d > 200. In contrast,
SCSSP-NBPW has much lower performance than SCSSP-Lin

26

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 1, JANUARY 2016

TABLE V
TEST PERFORMANCE RESULTS FOR DIFFERENT ALGORITHMS IN EXPERIMENT-2

The average Kappa coefficient (κ) for each subject and the total average over all the subjects are reported.

TABLE VI
RUN TIME FOR TRAINING FBSCP AND SCSSP ALGORITHMS IN EXP. 1

but still outperforms FBCSP-NBPW. Note that the performance
of SCSSP-Lin method peaks at a relatively low dimension,
which shows that SCSSP has been able to capture the discriminant information of the data in a small number of features. In
Exp. 2, where the training set is extremely limited, SCSSP-based
solutions cannot compete with the FBCSP-based ones. This significant difference between the two experiments is mostly due to
the lack of training data in Exp. 2, as discussed in Section IV-C1.
F. Run Time
Tables VI and VII provide the average runtimes for training
SCSSP versus FBCSP in Exp. 1 and Exp. 2. The reported times
are in milliseconds and are based on executing the corresponding MATLAB codes on a system with eight X5355 processors
and 8-GB memory. For each experiment, the amount of time
required for training each of the subjects during the validation
phase has been calculated, and the resulting execution times are
averaged over all validation runs and reported in Table VI. To
have a fair comparison, the reported times only correspond to
the amount of time required for calculation of transformation
matrices in the FBCSP and SCSSP methods through eigendecomposition of spatial/spectral covariance matrices, and they
do not include the time required for executing the SL, Bandpass
filtering, covariance estimation, and classification since these
steps are common in both FBCSP and SCSSP.

This table illustrates the significant difference between the
running time for the FBCSP and SCSSP. Indeed, the proposed
SCSSP algorithm is approximately five times faster than FBCSP
in Exp. 1, and seven times faster in Exp. 2. Note that the use
of CS changes the dimensionality of the input data, and hence,
the computational cost of the FBCSP/SCSSP. In fact, SCSSP
involves only two generalized eigen decompositions (i.e., one
for spectral covariance and one for spatial covariance); whereas
FBCSP requires a total of Nf generalized eigen decompositions
(i.e., one for each frequency band).
It is noteworthy that the difference between the runtimes of
FBCSP and SCSSP is crucially important in various applications, such as the following. (a) Adaptive Scenarios: In many
applications, the statistical properties of EEG changes over time,
e.g., during long data collection sessions or across different
sessions (ref. [37]). A widely used solution for such scenarios is
to utilize adaptive methods to continuously track these changes
and accordingly update the feature extractor. For such solutions,
it is critically important to reduce the computational cost of the
training phase in each update. Although neither FBCSP nor SCSSP are adaptive solutions, they can be modified to be used as a
basis for an adaptive algorithm. In such cases, the computational
cost of feature extractor’s training dictates the overall computational cost of the system. (b) Mobile/Wearable Scenarios:
Motor-imagery BCI systems are mostly expected to be used in
daily life applications where the processing is done in a portable
device. Besides, during the past few years there has been a
growing interest in processing of EEG signals in mobile phones
or tablets for various applications, such as mediation, learning,
vigilance monitoring, etc. In such cases, the processing power is
essentially restricted, which necessitates the use of computationally efficient methods. Indeed, in the aforementioned scenarios
and many other similar applications, matrix-variate treatment
of the EEG data provides a promising framework that has the

AGHAEI et al.: SCSSP FOR MOTOR IMAGERY BCI SYSTEMS

27

TABLE VII
RUN TIME FOR TRAINING FBSCP AND SCSSP ALGORITHMS IN EXP. 2

potential to be utilized in various types of BCI algorithms (e.g.,
ref. [38] and [39]).

In this section, we will prove that
Σ1 W = (Σ1 + Σ2 ) WΛ

(16)

where

V. CONCLUSION
This paper proposed a new feature extraction method based on
a heteroscedastic matrix-variate Gaussian model for the multiband EEG rhythms. In the proposed approach, EEG is first
passed through a bank of bandpass filters to extract different
bands of EEG rhythms. The resulting signal is then passed
through a joint spatio-spectral feature extractor, called SCSSP,
which directly operates on matrix-variate data.
SCSSP’s main advantage over FBCSP is that SCSSP jointly
processes the data in both spectral and spatial domains, and
hence, can sort the extracted features across both domains;
whereas FBCSP cannot sort the features that are extracted from
different frequency bands. As a result, SCSSP does not require
a separate subsequent dimensionality reduction stage, and its
output can directly be passed to the classifier. The second
advantage of SCSSP is its relatively low computational cost.
The aforementioned advantages come at the cost that SCSSP
requires a relatively larger training set, compared to the FBCSP.
Unlike Exp. 1, SCSSP cannot compete with the FBCSP in Exp. 2
since the amount of training information is extremely limited
due to: 1) short length of each trial (3 versus 15 seconds), 2)
single session data collection, and 3) limited number of training
samples (288 versus 1392 epochs). One possible solution is to
use multisubject regularization.
The appropriate length for training trials depends on several
factors, such as 1) subject’s ability in controlling motor
activities, 2) subject’s previous experience with BCIs, and
3) presence of real-time feedback. Furthermore, although in
longer training trials, the user has more time to concentrate and
produce reliable training samples, if the trial length is unreasonably long, the subject might lose concentration toward the end
of trial and generate noisy patterns. Further studies are needed
to analyze these effects, which are beyond the scope of this
paper.
APPENDIX A
PROOF OF THEOREM 1
Let Σi = Ψi ⊗ Φi for i ∈ {1, 2} and W = WR ⊗ WL ,
where WR and WL satisfy the following equations:
Ψ1 WR = (Ψ1 + Ψ2 ) WR ΛR

(14)

Φ1 WL = (Φ1 + Φ2 ) WL ΛL .

(15)

−1


Λ = (ΛR ⊗ΛL) ΛR ⊗ ΛL + (IN c h − ΛR ) ⊗ IN f − ΛL
.
Based on (14), it can be easily shown that WR jointly diagonalizes both Ψ1 and Ψ2 . Similarly, WL jointly diagonalizes
both Φ1 and Φ2 . Therefore, we have
(1)

(2)

Ψ1 WR = WR ΛR , Ψ2 WR = WR ΛR
(1)

(2)

Φ1 WL = WL ΛL , Φ1 WL = WL ΛL
(i)

(17)
(18)

(i)

where ΛR and ΛL are the corresponding diagonal eigenvalue
matrices. By substituting (17)–(18) into (14)–(15), we have




(1)
(1)
(2)
(1)
(1)
(2)
ΛR = ΛR + ΛR ΛR , ΛL = ΛL + ΛL ΛL
(19)
or equivalently
(1)



(2)




(2)

−1

(1)

(2)

−1

(1)

(2)

−1

(1)

(2)

−1

ΛL + ΛL

ΛL
ΛL

(2)

ΛR + ΛR

ΛR

(1)

(1)

ΛR + ΛR

ΛR



ΛL + ΛL

= ΛR

(20)

= IN c h − ΛR

(21)

= ΛL

(22)

= IN f − ΛL .

(23)

Using these definitions, the left-hand side of (16) can be
expanded as follows:
Σ1 W = (Ψ1 ⊗ Φ1 ) (WR ⊗ WL ) = (Ψ1 WR ) ⊗ (Φ1 WL )

 

(1)
(1)
= WR ΛR ⊗ WL ΛL


(1)
(1)
(24)
= (WR ⊗ WL ) ΛR ⊗ ΛL .
Similarly, the right-hand side of (16) can be expanded


(1)
(1)
(Σ1 + Σ2 ) WΛ = (WR ⊗ WL ) ΛR ⊗ ΛL Λ


(2)
(2)
+ (WR ⊗ WL ) ΛR ⊗ ΛL Λ
= (WR ⊗ WL )


(1)
(1)
(2)
(2)
· ΛR ⊗ ΛL + ΛR ⊗ ΛL Λ. (25)

28

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 1, JANUARY 2016

Therefore, (24) is equal to (25) when


−1
(1)
(1)
(1)
(1)
(2)
(2)
Λ = ΛR ⊗ ΛL
ΛR ⊗ ΛL + ΛR ⊗ ΛL

(26)

−1


= (ΛR ⊗ ΛL ) ΛR ⊗ ΛL + (IN c h − ΛR ) ⊗ IN f − ΛL
(27)
(i)

(i)

where (27) is obtained by first substituting ΛR and ΛL matrices into (26) with the right-hand sides of the two equations in (19), and then, using the four equalities provided
by (20)–(23).
REFERENCES
[1] A. Aghaei et al., “Separable common spatio-spectral pattern algorithm for
classification of EEG signals,” in Proc. IEEE Int. Conf. Acoustics, Speech
Signal Process., 2013, pp. 988–992.
[2] D. Huang et al., “Electroencephalography (EEG)-based brain-computer
interface (BCI): A 2-D virtual wheelchair control based on eventrelated desynchronization/ synchronization and state control,” IEEE Trans.
Neural Syst. Rehabil. Eng., vol. 20, no. 3, pp. 379–388, May 2012.
[3] G. Muller-Putz et al., “EEG-based neuroprosthesis control: A step towards
clinical practice,” Neurosci. Lett., vol. 382, no. 1-2, pp. 169–174, 2005.
[4] R. Scherer et al., “An asynchronously controlled EEG-based virtual keyboard: Improvement of the spelling rate,” IEEE Trans. Biomed. Eng.,
vol. 51, no. 6, pp. 979–984, Jun. 2004.
[5] G. Pfurtscheller et al., “Walking from thought,” Brain Res., vol. 1071,
no. 1, pp. 145–152, 2006.
[6] A. D. Gerson et al., “Cortically coupled computer vision for rapid image
search,” IEEE Trans. Neural Syst. Rehabil. Eng., vol. 14, no. 2, pp. 174–
179, Jun. 2006.
[7] L. C. Parra et al., “Spatiotemporal linear decoding of brain state,” IEEE
Signal Process. Mag., vol. 25, no. 1, pp. 107–115, 2008.
[8] A. S. Royer et al., “ EEG control of a virtual helicopter in 3-dimensional
space using intelligent control strategies,” IEEE Trans. Neural Syst. Rehabil. Eng., vol. 18, no. 6, pp. 581–589, Dec. 2010.
[9] A. J. Doud et al., “ Continuous three-dimensional control of a virtual
helicopter using a motor imagery based brain-computer interface,” PloS
one, vol. 6, no. 10, p. e26322, 2011.
[10] K. LaFleur et al., “Quadcopter control in three-dimensional space using
a noninvasive motor imagery-based brain–computer interface,” J. Neural
Eng., vol. 10, no. 4, p. 046003, 2013.
[11] H. Yuan and B. He, “ Brain–computer interfaces using sensorimotor
rhythms: Current state and future perspectives,” IEEE Trans. Biomed.
Eng., vol. 61, no. 5, pp. 1425–1435, May 2014.
[12] G. Pfurtscheller and F. H. Lopes da Silva, “ Event-related EEG/MEG
synchronization and desynchronization: Basic principles,” Clin. Neurophysiol., vol. 110, no. 11, pp. 1842–1857, 1999.
[13] H. Ramoser et al., “Optimal spatial filtering of single trial EEG during
imagined hand movement,” IEEE Trans. Rehabil. Eng., vol. 8, no. 4,
pp. 441–446, Dec. 2000.
[14] G. Pfurtscheller and C. Neuper, “Motor imagery and direct brain-computer
communication,” Proc. IEEE, vol. 89, no. 7, pp. 1123–1134, Jul.
2001.
[15] K. J. Miller et al., “ Spectral changes in cortical surface potentials during
motor movement,” J. Neurosci., vol. 27, no. 9, pp. 2424–2432, 2007.
[16] K. Fukunaga, Introduction to Statistical Pattern Recognition, 2nd ed. San
Diego, CA, USA: Academic, 1990.
[17] B. Blankertz et al., “ Optimizing spatial filters for robust EEG singletrial analysis,” IEEE Signal Process. Mag., vol. 25, no. 1, pp. 41–56,
2008.
[18] C. Neuper and G. Pfurtscheller, “ Event-related dynamics of cortical
rhythms: Frequency-specific features and functional correlates,” Int. J.
Psychophysiol., vol. 43, no. 1, pp. 41–58, 2001.
[19] G. Pfurtscheller et al., “ Mu rhythm (de)synchronization and EEG singletrial classification of different motor imagery tasks,” NeuroImage, vol.
31, no. 1, pp. 153–159, 2006.
[20] S. Lemm et al., “ Spatio-spectral filters for improving the classification of
single trial EEG,” IEEE Trans. Biomed. Eng., vol. 52, no. 9, pp. 1541–
1548, Sep. 2005.

[21] G. Dornhege et al., “ Combined optimization of spatial and temporal filters
for improving brain-computer interfacing,” IEEE Trans. Biomed. Eng.,
vol. 53, no. 11, pp. 2274–2281, Nov. 2006.
[22] W. Wu et al., “ Classifying single-trial EEG during motor imagery by
iterative spatio-spectral patterns learning (ISSPL),” IEEE Trans. Biomed.
Eng., vol. 55, no. 6, pp. 1733–1743, Jun. 2008.
[23] H. Zhang et al., “ Optimum spatio-spectral filtering network for braincomputer interface,” IEEE Trans. Neural Netw., vol. 22, no. 1, pp. 52–63,
Jan. 2011.
[24] H.-I. Suk and S.-W. Lee, “A novel Bayesian framework for discriminative
feature extraction in brain-computer interfaces,” IEEE Trans. Pattern Anal.
Mach. Intell., vol. 35, no. 2, pp. 286–299, Feb. 2013.
[25] K. K. Ang et al., “ Filter bank common spatial pattern algorithm on BCI
competition IV datasets 2a and 2b,” Front. Neurosci., Mar. 2012.
[26] R. Tomioka et al., “ Spectrally weighted common spatial pattern algorithm
for single trial EEG classification,” Dept. Math. Eng., Univ. Tokyo, Tokyo,
Japan, Tech. Rep, vol. 40, 2006.
[27] H. Higashi and T. Tanaka, “ Simultaneous design of FIR filter banks and
spatial patterns for EEG signal classification,” IEEE Trans. Biomed. Eng.,
vol. 60, no. 4, pp. 1100–1110, Apr. 2013.
[28] J. Meng et al., “ Simultaneously optimizing spatial spectral features based
on mutual information for EEG Classification,” IEEE Trans. Biomed. Eng.,
vol. 62, no. 1, pp. 227–240, Jan. 2015.
[29] F. Qi, Y. Li, and W. Wu, “ RSTFC: A novel algorithm for spatio-temporal
filtering and classification of single-trial EEG,” IEEE Trans. Neural Netw.
Learn. Syst., 2015, doi:10.1109/TNNLS.2015.2402694.
[30] A. Gupta and D. Nagar, Matrix Variate Distributions. London, U.K.:
Chapman & Hall, 1999.
[31] J. Millan, “On the need for on-line learning in brain-computer interfaces,” in Proc. Int. Joint Conf. Neural Netw., Jul. 2004, vol. 4, pp. 2877–
2882.
[32] M. Tangermann et al., “Review of the BCI competition IV,” Front. Neurosci., Jul. 2012.
[33] F. Cincotti et al., “The use of EEG modifications due to motor imagery
for brain-computer interfaces,” IEEE Trans. Neural Syst. Rehabil. Eng.,
vol. 11, no. 2, pp. 131–133, Jun. 2003.
[34] P. L. Nunez and R. Srinivasan, Electric fields of the brain : the neurophysics
of EEG, 2nd ed. New York, NY, USA: Oxford Univ. Press, 2006.
[35] F. Galán et al., “Using mental tasks transitions detection to improve spontaneous mental activity classification,” Med. Bio. Eng. Comput., vol. 45,
no. 6, pp. 603–609, 2007.
[36] A. Schlogl et al., Toward Brain-Computer Interfacing. Cambridge, MA,
USA: MIT Presss, 2007.
[37] M. Krauledat, “ Analysis of nonstationarities in EEG signals for improving
brain-computer interface performance,” Ph.D. dissertation, Berlin Institute
of Technology, 2008.
[38] M. S. Mahanta et al., “Regularized LDA based on separable scatter matrices for classification of spatio-spectral EEG patterns,” in Proc. IEEE Int.
Conf. Acoustics, Speech Signal Process., 2013, pp. 1237–1241.
[39] R. Tomioka and K.-R. Müller, “A regularized discriminative framework
for EEG analysis with application to brain–computer interface,” NeuroImage, vol. 49, no. 1, pp. 415–432, 2010.

Amirhossein S. Aghaei (S’06–M’14) is currently
a Post-Doctoral Fellow with the Department of
Electrical and Computer Engineering, University of
Toronto, Toronto, Canada. His research interests are
machine learning, pattern recognition, data analytics, statistical signal processing, and biomedical engineering. He received his Ph.D. and M.A.Sc degrees
from the Department of Electrical and Computer Engineering at the University of Toronto, in 2008 and
2013 respectively, and received his B.Sc. degree in
Electrical Engineering from Iran University of Science and Technology, Tehran, Iran, in 2006.

AGHAEI et al.: SCSSP FOR MOTOR IMAGERY BCI SYSTEMS

Mohammad Shahin Mahanta (S’09) is a research
engineer with Interaxon, Inc. His interests include statistical signal processing and machine learning, with
particular emphasis on analysis of biomedical signals.
He received his Ph.D. and M.A.Sc. degrees in electrical and computer engineering from the University of
Toronto, Toronto, Canada, in 2015 and 2009 respectively, and had received a B.Sc. degree in electrical
engineering from Sharif University of Technology,
Tehran, Iran, in 2007.

29

Konstantinos N. Plataniotis (S’93–M’95–SM’03–
F’12) is currently a Professor and the Bell Canada
Chair of Multimedia with the Department of Electrical and Computer Engineering, University of
Toronto, Toronto, ON, Canada. His research interests
include statistical signal processing, knowledge and
digital media design, multimedia systems, biometrics, image and signal processing, biomedical signal
processing, and pattern recognition. Among his publications in these fields are the recent books WLAN
Positioning Systems (2012) and Multilinear Subspace
Learning: Reduction of Multidimensional Data (2013).
Prof. Plataniotis received the IEEE Canada Engineering Educator Award for
contributions to engineering education and inspirational guidance of graduate
students. He is a registered Professional Engineer in Ontario and a Fellow of
the Engineering Institute of Canada. He has served as the Editor-in-Chief of the
IEEE Signal Processing Letters and the Technical Cochair of the 2013 IEEE
International Conference in Acoustics, Speech, and Signal Processing. He is the
IEEE Signal Processing Society Vice President for Membership (2014–2016)
and the General Chair of the forthcoming 2018 IEEE International Conference
on Image Processing.

