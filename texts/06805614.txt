IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 8, AUGUST 2014

2223

High-Order Statistics of Microtexton for HEp-2
Staining Pattern Classification
Xian-Hua Han∗ , Member, IEEE, Jian Wang, Gang Xu, Member, IEEE, and Yen-Wei Chen, Member, IEEE

Abstract—This study addresses the classification problem of the
HEp-2 cell using indirect immunofluorescent (IIF) image analysis,
which can indicate the presence of autoimmune diseases by finding
antibodies in the patient serum. Generally, the method used for
IIF analysis remains subjective, and depends too heavily on the
experience and expertise of the physician. Recently, studies have
shown that it is possible to identify the cell patterns using IIF image analysis and machine learning techniques. However, it still has
large gap in recognition rates to the physical experts’ one. This
paper explores an approach in which the discriminative features
of HEp-2 cell images in IIF are extracted and then, the patterns of
the HEp-2 cell are identified using machine learning techniques.
Motivated by the progress in the research field of computer vision, as a result of which small local pixel pattern distributions
can now be highly discriminative, the proposed strategy employs
a parametric probability process to model local image patches
(textons: microstructures in the cell image) and extract the higherorder statistics of the model parameters for the image description.
The proposed strategy can adaptively characterize the microtexton
space of HEp-2 cell images as a generative probability model, and
discover the parameters that yield a better fitting of the training
space, which would lead to a more discriminant representation for
the cell image. The simple linear support vector machine is used
for cell pattern identification because of its low computational cost,
in particular for large-scale datasets. Experiments using the open
HEp-2 cell dataset used in the ICIP2013 contest validate that the
proposed strategy can achieve a much better performance than the
widely used local binary pattern (LBP) histogram and its extensions, rotation invariant co-occurrence LBP, and pairwise rotation
invariant co-occurrence LBP, and that the achieved recognition
error rate is even very significantly below the observed intralaboratory variability.
Index Terms—HEp-2 cell, high-order statistics, microtexton,
mixture model of Gaussian, parametric probability model.

I. INTRODUCTION
NDIRECT immunofluorescence (IIF) is widely utilized as a
diagnostic tool via image analysis, which can reveal the presence of autoimmune diseases by finding antibodies in the patient
serum. In IIF, the human larynx carcinoma (HEp-2) substrate,

I

Manuscript received December 13, 2013; revised March 18, 2014; accepted
April 21, 2014. Date of publication April 25, 2014; date of current version
July 15, 2014. This work was supported in part by the Grant-in Aid for Scientific Research from the Japanese MEXT under Grant 2430076 and in part
by the R-GIRO Research fund from Ritsumeikan University. Asterisk indicates
corresponding author.
∗ X.-H. Han is with the College of Information Science and Engineering, Ritsumeikan University, Kasatsu-shi 525-8577, Japan (e-mail: hanxhua@
fc.ritsumei.ac.jp).
J. Wang, G. Xu, and Y.-W. Chen are with the College of Information Science
and Engineering, Ritsumeikan University, Kasatsu-shi 525-8577, Japan (e-mail:
wlockon@yahoo.com; xu@3dmedia.co.jp; chen@is.ritsumei.ac.jp).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org
Digital Object Identifier 10.1109/TBME.2014.2320294

which bonds with serum antibodies, thus forming a molecular
complex, is applied, and recognition of the HEp-2 cell pattern
can then be used to identify antinuclear autoantibodies (ANA).
Since it is effective for diagnosing autoimmune diseases [7], [8],
the demand for applying IIF image analysis in diagnostic tests is
increasing. However, the practical image analysis method for IIF
still remains subjective, which not only need a highly specialized
and experienced technician or physician to achieve acceptable
diagnostic results, but also too much of the physician’s time.
Furthermore, because the physician is provided with insufficient
quantitative information and the IIF images differ according to
the different illumination conditions and reading systems, there
exists an almost 10% variance in the results of the simple task of
positive/negative intensity recognition, and more than 20% variance in the classification of the staining pattern [14]. Motivated
by this fact, recent research efforts have been directed toward
the development of a computer-aided-diagnosis (CAD) system
for supporting the IIF diagnostic procedure, which focus mainly
on image acquisition [40], segmentation [19], [20], [31], fluorescence intensity classification [39], and staining cell pattern
recognition [13], [17], [18], [31], [36], [38]. In this study, we
explore primarily the identification of the HEp-2 staining cell
pattern in IIF images using the progressive techniques developed
in the computer vision and machine learning fields. Several attempts to achieve automatic recognition of the HEp-2 staining
pattern have been made. Perner et al. [31] proposed extracting
the texture and statistics features for cell image representation,
and combined this with a decision tree model for HEp-2 cell image classification. This approach can achieve an approximately
75% recognition rate. Soda et al. [38] investigated a multiple
expert system in which an ensemble of classifiers was combined
in a fusion way to label the patterns of single cells. In their study,
the wavelet method was used to extract features and select the effective statistics and spectral measurements from those that were
extracted. However, research in the field of IIF image analysis
is still in its early stages, and there is still great potential for improving the performance of the HEp-2 staining cell recognition
further. In addition, although several approaches have been proposed, they have usually been developed and tested on different
private datasets under varying conditions, such as image acquisition according to different criteria, different staining patterns,
and so on. Therefore, it is difficult to compare the effectiveness of different approaches because they were evaluated over
different datasets.
In this study, we aim to achieve automatic recognition of six
HEp-2 staining patterns in an open HEp-2 dataset, which was
recently released for the second HEp-2 cells classification contest at ICIP2013. In the first HEp-2 cells classification contest,

0018-9294 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

2224

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 8, AUGUST 2014

Fig. 1. Proposed adaptive microtexton space model for HEp-2 cell image recognition. The upper row shows the learning procedure for the model parameters in
GMM. The lower row shows the extraction of image features based on the learned GMM model and HEp-2 staining pattern recognition.

which took place at ICIP2012, it was shown that the local binary pattern (LBP) and its extended versions, such as rotation
invariant co-occurrence LBP (RICLBP) [29] for cell image representation, can achieve a promising HEp-2 cell classification
performance [14]. In addition, in the second HEp-2 cells classification contest at ICIP2013, it was proved that the combination
of another extended LBP version, pairwise rotation invariant cooccurrence LBP (PRICoLBP) [34], and bag-of-features (BOF)
[23] with a Sift descriptor [28] achieves the best recognition
results. LBP [16], [43], [45] characterizes each 3×3 local patch
(microstructure) into a binary series by comparing the surrounding pixel intensity with that of the center one, which sets the bit
of a surrounding pixel as 1 if its intensity is larger than the
center one; otherwise as 0. Then, we can obtain an eight-bit binary series from a 0–255 LBP value for each focused pixel (the
center pixel). The image representation can be extracted as the
histogram of the LBP value in a cell image. However, the LBP
value retains the information only when the surrounding pixel
intensity is greater than that of the center one, and then, the quantitative difference between them is lost as a result of the binary
coding in LBP. Therefore, it is possible for quite different local
structures (patches) to be represented as the same LBP value,
which means the LBP is very limited in terms of representing the
local structure given the fixed approximate quantization of the
feature space as a binary pattern. In addition, local binary pattern
(local structure) distribution is commonly represented using a
histogram, and hence, is restricted to the use of low-order statistics. In contrast to these previous works, in our study, we propose
characterizing the local structure (microtexton) of HEp-2 cell
images adaptively as a Gaussian mixture model (GMM) [12]
[6], and we explore the texton high-order statistics for cell image representation. Within the assumed model, we can achieve

data-driven partitioning of the texton space using parametric
mixture models with parameters learned using training data to
represent the distribution of the local textons extracted from an
image. The extracted weighted histogram (distribution) of the
local descriptor (here, microtexton) [26], which is widely used
as image representation for generic image classification, represents the mean probabilities of all the textons belonging to the
previously learned models, and includes only low-order statistics, which can be called zeroth-order statistics. Furthermore,
in order to represent the image more efficiently, we explore the
high-order statistics of the microtexton in the learned model,
which are the deviation (gradient) statistics of the mean and
variance parameters of GMM and also can be called the first
and second statistics. The concatenated vector of the simple histogram and the deviation statistics in the learned model is used
for image representation. Therefore, the coding of vectors is intrinsically adapted to the recognition task, and the computations
involved remain very simple despite their strength. Using the
high-order coded vector of adaptive texton space, we simply
apply a linear support vector machine (SVM) [9], instead of the
nonlinear one widely used for classification to achieve acceptable results, for HEp-2 cell recognition. The flowchart of our
proposed strategy is shown in Fig. 1.
Our primary contributions are fourfold: 1) a method is proposed that uses the microstructures (microtextons) directly as
local descriptors, instead of an approximate quantization, such
as LBP, that leads to significant information loss; 2) the characterization of the microtexton as a GMM, which can adaptively achieve data-driven partitioning of microtexton space, is
examined; 3) a method for extracting not only low-order (distribution of the microtexton) but also high-order statistics (gradient of the mean and variance of the learned GMM) for image

HAN et al.: HIGH-ORDER STATISTICS OF MICROTEXTON FOR HEP-2 STAINING PATTERN CLASSIFICATION

2225

TABLE I
CELL IMAGE NUMBER FOR DIFFERENT STAINING PATTERNS AND DIFFERENT INTENSITY TYPES
Homogeneous

Speckled

Nucleolar

Centromere

NuMem

Golgi

1087
1407

1457
1374

934
1664

1387
1364

943
1265

347
377

Positive
Intermediate

representation, which is significantly more discriminant for classification, is described; and 4) Experimental validation that the
proposed high-order statistics can greatly improve the recognition performance as compared with the conventional LBP and
its extensions, RICLBP and PRICoLBP representation, is presented. Experimental results for the open HEp-2 cell dataset
used at the ICIP2013 contest show that the variability of the
recognition performance achieved by our proposed strategy is
even significantly less than the observed intralaboratory variability for both positive and intermediate intensity cell types.
This paper is organized as follows. In Section II, medical
context used in our experiments is described. In Section III,
the basic microtexton space for local structure representation,
and the characterized texton space modeled with a mixture
Gaussian are introduced. In Section IV, the high-order statistics of parameter models and the implementation of the coded
vector in the learned adaptive texton space are described. Experimental results and conclusions are given in Sections V and VI,
respectively.
II. MEDICAL CONTEXT
In ANA tests, the HEp-2 substrateis, in general, applied, and
both fluorescence intensity and staining pattern need to be classified, which is a challenging task that affects the reliability of IIF
diagnosis. For classifying fluorescent intensity, the guidelines
established by the Center for Disease Control and Prevention in
Atlanta, Georgia (CDC) [15] suggest semi-quantitative scoring
be performed independently by two physician IIF experts. The
score ranges from 0 to 4+ according to the intensity: negative
(0), very subdued fluorescence (1+), defined pattern but diminished fluorescence (2+), less brilliant green (3+), and brilliant
green or maximal fluorescence (4+). The values are relative
to the intensity of a negative and a positive control. The cell
with positive intensity allows the physician to check the correctness of the preparation process, whereas that with negative
intensity represents the auto-fluorescence level of the slide under examination. To reduce the variability of multiple readings,
Rigon et al. [35] recently proposed classifying the fluorescence
intensity into three classes, named negative, intermediate, and
positive, by statistically analyzing the variability between several physicians’ fluorescence intensity classification.
The open ICIP2013 HEp-2 dataset includes two intensity
types of HEp-2 cells, intermediate and positive, and the purpose
of the research is to recognize the staining pattern given the
intensity types (intermediate or positive). The studied staining
patterns primarily include six classes:
1) Homogeneous: characterized by a diffuse staining of the
interphase nuclei and staining of the chromatin of mitotic cells.

2) Speckled: characterized by a granular nuclear staining of
the interphase cell nuclei, which then consists of fine and coarse
speckled patterns.
3) Nucleolar: characterized by clustered large granules in the
nucleoli of interphase cells that tend toward homogeneity, with
fewer than six granules per cell.
4) Centromere: characterized by several discrete speckles
(40–60) distributed throughout the interphase nuclei and characteristically found in the condensed nuclear chromatin during
mitosis as a bar of closely associated speckles.
5) Golgi: also called the Golgi apparatus, is one of the first organelles to be discovered and observed in detail. It is composed
of stacks of membrane-bound structures known as cisternae.
6) NuMem: Abbreviated from nuclear membrane, characterized as a fluorescent ring around the cell nucleus and are
produced by antigp210 and antip62 antibodies.
In the open ICIP2013 HEp-2 cell dataset, there are more than
10 000 images, each showing a single cell, which were obtained
from 83 training IIF images by cropping the bounding box of
the cell. The detailed information about the different staining
patterns is shown in Table I, and some example images for all
six staining patterns of the positive intensity type are shown in
Fig. 2. Using the provided HEp-2 cell images and their corresponding patterns, we can extract the features that are effective
for image representation, and learn a classifier (or a mapping
function) using the extracted features of cell images and the
corresponding staining patterns. Using the constructed classifier (the mapping function), the staining pattern can automatically be predicted given any HEp-2 cell image. In the classification procedure, the method used to extract the discriminant
feature for cell image representation has a significant effect on
the recognition performance. Next, we describe in detail the
feature extraction strategy for cell image representation.
III. BASIC MICROSTRUCTURE SPACE
Studies in the computer vision field have shown that texture
analysis can be implemented on the processed images and the
statistics of microstructures by using the learned distribution of
filter bank (a number of filters or wavelets) responses [24], [33],
[37]. Recent research [32], [42] showed that it is possible to discriminate between textures using pixel neighborhoods as small
as a 3×3 pixel region. Awate et al. [4] explored nonparametric
neighborhood statistics and manifested promising performance
for texture segmentation. Pietikinen et al. [32], [42] showed
that despite the global structure of the textures, very good discrimination can be achieved by exploiting the distributions of
such pixel neighborhoods. Therefore, the exploitation of these
microstructures for representing images in the distributions of
local descriptors has gained much attention and has led to

2226

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 8, AUGUST 2014

Fig. 2.

Example images of six HEp-2 staining patterns of the positive intensity type.

Fig. 3.

Example of the basic LBP operator.

state-of-the-art performances [1], [4], [5], [41] for different
classification and segmentation problems in computer vision.
The system proposed by Foggia [13] and the recognition system submitted in [14] for HEp-2 staining patterns achieved
an improved recognition performance. In these studies, the
statistics of microstructures (local binary pattern-LBP) was
also investigated, and it was proved that it is possible to recognize the HEp-2 staining patterns automatically. However,
these methods suffer from several important limitations, such
as the use of fixed quantization of the input vector for pruning volumes in the feature space, and the restricted use of
low-order statistics with a feature histogram. In our proposed
strategy, we characterize the feature space as an adaptive parametric probability model, as described in this section, and extract the high-order statistics of the microstructures (microtextons) based on the constructed parametric model presented in
Section IV.
Next, we first introduce the basic local-structure representation using local binary pattern and the differential vector
between the surrounding pixels and the center one, called
the microtexton, and then, adaptively characterize the microtexton space as a parametric probability process using a
GMM.

A. Local Binary Pattern
The local binary pattern operator is an image operator that
transforms an image into an array of integer labels describing
the small-scale appearance of the image. These labels or their
statistics, most commonly the histogram, are then used for further image analysis. Given an image I, let us denote the ith pixel
intensity Ii at (xi , yi ) and its surrounding pixel intensities in a
3 × 3 region by Iij (j = 0, 1, . . . , 7). The LBP operator sets the
threshold of the difference between Ii and Iij as 0 or 1 (binary),
and the eight binary numbers are combined as a decimal number
for labeling the ith pixel. Fig. 3 shows a specific example of
extracting the LBP value of a focused pixel. The derived binary
numbers are called local binary patterns or LBP codes. Mathematically, the resulting LBP of the ith pixel at (xi , yi ) can be
expressed in decimal form as
LBP(xi , yi ) =

7


T (Iij − Ii )2j

(1)

j =0

where the function T (z) is a threshold function, defined as

1, if z ≥ 0
T (z) =
(2)
0, if z < 0

HAN et al.: HIGH-ORDER STATISTICS OF MICROTEXTON FOR HEP-2 STAINING PATTERN CLASSIFICATION

Fig. 5.
codes.

2227

PCA coefficients’ scatter of the differential vector from three LBP

Fig. 4. Examples of LBP codes for two very different local structures, and
two similar local structures.

By the definition above, the LBP operator is invariant to
the monotonic gray-scale transformations, which preserves the
pixel intensity order in local neighborhoods. The histogram of
LBP labels can be exploited as a texture descriptor. In addition,
in some works, the general LBP was extended to co-occurrence
of LBP (CoLBP) [27] and the improved LBP, pairwise rotation
invariant co-occurrence LBP (PRICoLBP) [34] for integrating
the relation between different local patterns, which yield more
promising performances than the conventional LBP. However,
LBP code and its extended versions quantize each different
intensity between the surrounding pixels and the center one
into only two intensity levels, 0 or 1, which means that it is
possible to code two very different local structures into one and
the same LBP value, and two similar local structures into very
different LBP values, as shown in Fig. 4. Therefore, the LBP
operator and its extensions are very limited for representing the
local structures of images, and thus, the formed histogram of the
global image also is not sufficiently discriminatory for image
classification purposes.
B. Microtexton for Local Structure Representation
The texton representation for local structures also focuses on all possible 3×3 patches in an image, i.e., xa =
(xc , x1 , x2 , . . . , x8 ), where xc denotes the intensity of the center pixel and the rest denote those of its 8-neighbours. In order
to remove variance to monotonic changes in gray levels, we
subtract the intensity of the center pixel from the rest as in
LBP, and use the differential vector, i.e., x = (x1 − xc , x2 −
xc , . . . , x8 − xc ), for the local structure representation, named
a microtexton, which is an eight-dimensional vector. As introduced in the previous section, LBP quantizes each element
into two intensity levels, and then, the possible LBP value for
combining all eight elements is in the range [0, 255] in decima-

tion. However, representing the local structures with only two
quantized levels for each element is not sufficiently exact, and
thus, much of the discriminant information required for image
classification is lost. An example of the scatter plot of the first
and second component coefficient analyzed from the microtexton space is shown in Fig. 5, where the three different colors
show three different LBP codes. In Fig. 5, it can clearly be seen
that some similar texton features (dense scatter points) can be
coded as different LBP values, and very different texton features (the left side of Fig. 5) can be represented by the same
LBP value. The intuitive way to reduce the reconstruction error
is to increase the quantization intensity levels, such as by uniformly quantizing each element in texton vectors into three or
four intensity levels, and to obtain the possible existing pattern
by combining the quantized level in the eight elements of texton features. However, detailed quantization will exponentially
increase the possible number of the processed local patterns,
such as 38 = 6561 and 48 = 65 536 for three and four quantization levels, respectively, for each element, which results in an
extremely high-dimensional feature for image representation.
In addition, for the images of a specific application, such as
the HEp-2 cell images, some quantized representative textons
maybe never appear in any cell image, and at the same time the
detailed variation in other quantized features can include very
discriminative features. Fig. 6(a)shows a scatter plot of 5000
samples of two elements extracted from texton features randomly selected from 50 positive type cell images. It can clearly
be seen that some quantized regions in the uniform quantization, the partitions of which are represented by the dashed
line, contain almost no samples, and more than half (9) of the
16 regions are ineffective for extracting the microtexton statistics for image representation. Therefore, this study proposes
characterizing the microtexton of HEp-2 cell images adaptively
as a GMM [12] and exploring the high-order texton statistics
for cell image representation. Within the assumed model, we
can achieve data-driven partitioning of the texton space using

2228

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 8, AUGUST 2014

spectively, and N (X/μk , Σk ) is the Gaussian distribution with
mean and covariance μk and Σk , respectively.
Given the training texton space samples, we can adaptively
learn the prior parameters λ = {wk , μk , Σk , k = 1, . . . , K} of
GMM using the expectation maximization (EM) strategy [10],
[44] by maximizing the likelihood of the GMM of the training
samples, which is equivalent to minimizing the (negative) loglikelihood as
L(λ) = −

T

t=1

ln

K


wk N (xt /μk , Σk ).

(4)

k =1

The EM strategy [10], [44] iterates until reaching a predefined
iteration number or no (small) change occurs in the aforementioned objective function. Then, we can achieve the parameters
λ = {wk , μk , Σk , k = 1, . . . , K} in GMM for fitting the training texton samples. Fig. 6(b) shows a simple model fit to the
texton space using GMM. It can clearly be seen that the GMM
with the learned parameters can model the texton space samples
better than the uniformly quantized space shown in Fig. 6(a).
IV. HIGH-ORDER STATISTICS OF ADAPTIVE TEXTON MODEL

Fig. 6. (a) Uniformly quantized texton space; (b) texton space adaptively
learned using the generative probability model (GMM).

parametric mixture models, to represent the distribution of the
vectors, and learn the parameters from the training cell images.
C. Adaptive Space Modeled by Mixture Gaussian
Let us denote the microtexton space samples, which are randomly selected from training images, by X = [x1 , x2 , . . . , xT ],
where xi ∈ R8 and T is the sample number. Assuming the
micro-texton space samples have probability distribution as in
a GMM [44], we can formulate
P (X/λ) =

K


wk N (X/μk , Σk )

(3)

k =1

where λ is the parameters for formulating the probability
function, in the GMM with K-components, denoted by λ =
{wk , μk , Σk , k = 1, . . . , K}. wk , μk , and Σk are the mixture
weight, mean vector, and covariance matrix of Gaussian k, re-

In the previous section, we described how the GMM is used
for modeling training texton space samples, which are randomly
selected from all images that possibly appear in a specific application. Therefore, the learned model parameters are generic
to the texton space extracted from all types of images. For the
texton samples of a given image, the GMM with the learned
prior parameters will include some deviation. Therefore, it is
possible to use the distribution of the learned model and the
deviation of the first- and second-order parameters of the texton
space samples as the features for the given image. The deviation
statistics (also called high-order statistics or the Fisher vector)
can be described in the underlying principle, the Fisher kernel
[2], [21], and are given by the gradient of the log-likelihood of
the data based on the learned model [3], [11]. It was proven in
[2] that the utility of the Fisher kernel as the kernel machine in
a discriminative classification model, which is inherently nonlinear, is equivalent to that of a linear kernel machine using the
normalized deviation statistics as the feature vector. Therefore,
the benefit of the explicit formulation for the Fisher vector is that
a linear classifier can be used very efficiently. Next, we give a
detailed description of our method for extracting the high-order
statistics (Fisher vector) given the microtexton of an image.
A. Coded Vector With Higher Order Statistics
As introduced in Section III, we model the texton space of
cell images as a GMM, and learn the adaptive parameters λ =
k = 1, . . . , K of a generative probability model
wk , μk , Σk ,
P (X/λ) = K
k =1 wk N (X/μk , Σk ) using texton samples randomly selected from all types of cell images. Each Gaussian
represents a representative texton word of the texton prototypes
(vocabulary): wk encodes the relative frequency of texton word
k, μk the mean of the texton word, and Σk the variation around
the mean. Given the texton samples X = {xt , t = 1, . . . , T } of
any HEp-2 cell image, our objective is to modify the generative model learned from training cell images to fit them better,

HAN et al.: HIGH-ORDER STATISTICS OF MICROTEXTON FOR HEP-2 STAINING PATTERN CLASSIFICATION

2229

Given any texton sample xt in the dataset X of a cell image, the occupancy probability for the kth Gaussian can be
formulated as
wk P (k/xt , λ)
.
γt (k) = K
k =1 wk P (k/xt , λ)

(5)

In order to avoid enforcing explicitly the constraints in (5), we
take a new relative parameter αk to adopt soft-max formalism
k)
. After reparametrization
[22] for defining wk =  Kexp(α
exp(α )
j=1

j

using αk , the straightforward deduction of the gradient for the
parameter λ = αk , μk , Σk , k = 1, . . . , K can be formulated as
∂P (X|λ) 
=
[γt (k) − wk ]
∂αk
t=1

(6)

xd − μd
∂P (X|λ) 
=
γt (k)[ t d 2 k ]
d
∂μk
(σk )
t=1

(7)

(xdt − μdk )2
1
∂P (X|λ) 
=
γ
(k)[
− d]
t
d
d
3
∂σk
(σk )
σk
t=1

(8)

T

T

T

Fig. 7. Comparison of recognition performances of our proposed strategy and
the state-of-the-art methods [14], [34]. (a) For “Positive” intensity type. (b) For
“Intermediate” intensity type.

Fig. 8. Comparison of recognition performances with different orders of
statistics and microtexton size 3×3 for classifying different HEp-2 cell pattern in the “Positive” and “Intermediate” type dataset.

which entails extracting the gradient of the generative model
to the parameter λ = wk , μk , Σk , k = 1, . . . , K. For computational convenience,
 we assume that the weights are subject to
the constraint: K
k =1 wk = 1, and using a D-dimensional texton space, we assume the covariance matrix is diagonal, denoted
by σk = diag(Σk ).

where the superscript d denotes the dth dimension of the input
vector xt , and αk , μk , and Σk reflect the weight, mean, and variance, respectively, of the kth component in the learned model.
Therefore, given a dataset X, the gradients for the parameters
αk , μk , and Σk can be considered as the zeroth-order, first-order,
and second-order statistics. In addition, from the above equation, it is obvious that the gradient for αk represents the average
prior-weight-subtracting (wk ) probability of the data set X belonging to the kth component, which is similar to the histogram
of the microtexton and widely used for image representation
[26]. By introducing the gradient for the mean and variance of
the learned model, it is expected to be more discriminant for
image representation. The final feature for image representation
is just the concatenation of the partial derivative with respect to
all the parameters, which also can be called the Fisher vector.
After obtaining the gradients, the remaining issue is the computation of the diagonal of the Fisher information matrix F. Let
us denote the diagonal element of F to the parameters αk , μdk ,
and σkd by fα k , fμ dk and fσ kd , and can approximate them as
T wk
2T w k
fα k = T wk , fμ dk = (σ
d 2 and fσ d = (σ d ) 2 . Then, the normalk
k)
k
ized Fisher vector can be computed by multiplying the gradients
and the root inverse of the corresponding Fisher elements for
each sample:
T
1 
[γt (k) − wk ]
ǦX
αk = √
wk t=1

 d

T
xt − μdk
1 
ǦX
=
γ
(k)
√
t
μ dk
wk t=1
σkd
ǦX
σ kd



T
1 
1 (xdt − μdk )2
=√
γt (k) √
−1 .
wk t=1
(σkd )2
2

(9)

(10)

(11)

The final Fisher vector is the concatenation of the gradiX
X
ent ǦX
α , Ǧμ d , and Ǧσ d for all d = 1, 2, . . . , D dimensions of
k

k

2230

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 8, AUGUST 2014

TABLE II
CONFUSION MATRIX FOR CLASSIFYING DIFFERENT HEP-2 CELL PATTERNS IN THE “POSITIVE” AND “INTERMEDIATE”
TYPE DATASET USING OUR PROPOSED STRATEGY WITH MICROTEXTON SIZE 3×3
%
Homogeneous
Speckled
Nucleolar
Centromere
NuMem
Golgi
%
Homogeneous
Speckled
Nucleolar
Centromere
NuMem
Golgi

Homogeneous

Speckled

Nucleolar

Centromere

NuMem

Golgi

96.42
1.54
0.10
0
2 93.61
0.06
0.54
5.06
0.54
0.84
94.97
1.60
0.28
1.65
1.52
96.07
3.25
0.35
0
0
1.38
3.62
5.21
0.53
(a) Confusion matrix for “Positive” intensity type
Homogeneous
Speckled
Nucleolar
Centromere
78.81
8.55
5.20
0.87
6.46
78.55
7.88
2.58
3.67
7.61
76.97
0.75
0.52
1.31
2.23
95.41
7.07
3.16
6.91
0.15
5.19
5.19
12.99
5.19
(b) Confusion matrix for “Intermediate” intensity type

1.57
0.65
0.07
0
96.36
1.70

0.37
0.082
1.98
0.47
0.04
87.55

NuMem
5.33
3.88
5.17
0.26
81.20
1.30

Golgi
1.24
0.65
5.82
0.26
0.50
70.13

the input feature (texton) vector, and k = 1, 2, . . . , K Gaussian
components, and then, is of dimension (2D + 1)K.
To avoid dependence on the sample size, we normalize the
resulting Fisher vector by the sample (microtexton) size ex1
X
tracted from any given image: ǦX
λ = T Ǧλ . With the Fisher
vector for an image representation, we can use a linear classifier, such as a linear SVM, to achieve an acceptable recognition
performance.
V. EXPERIMENTS
Using HEp-2 cell images of two types of intensity (Intermediate and Positive), we validated the recognition performance
achieved by applying our proposed strategy and the conventional
local binary pattern (LBP) and its extended versions, RICLBP
[30] and the recently developed PRICoLBP [34], which have
been proven to yield the best recognition performance for the
cell dataset [14]. In the open HEp-2 cell database, each pattern
has a different number of available cell images, as shown in
Table I. It can be seen that the “Golgi” pattern has much fewer
available cell images than the other patterns. Thus, in our experiment, we randomly selected 600 cell images from the five
patterns, excluding “Golgi” and 300 from “Golgi” as training
images, and the remainder were used as testing images for both
“Positive” and “Intermediate” intensity types. The linear SVM
was used as the classifier because of its effectiveness as compared with other classifiers, such as K-nearest neighbor, and its
efficiency as compared with a nonlinear SVM, which requires
much more time to classify a sample. In addition, for LBP and
its extended RICLBP and PRICoLBP histograms, we preprocessed them using the square root operation for classification
with a linear SVM
√ √
√
(12)
P = [p1 , p2 , . . . , pL ] = [ p1 , p2 , . . . , pL ]
where P = [p1 , p2 , . . . , pL ] is the raw histogram of LBP or
PRICoLBP with dimension L, and P is the normalized feature for linear SVM. It has been shown that preprocessing of
the LBP, RICLBP, or PRICoLBP histogram in a linear classification model is equivalent to applying a nonlinear kernel, the

Fig. 9. Recognition rates of the proposed strategy using different number of
GMM components over HEp-2 cell datasets. (a) For “Positive” intensity type.
(b) For “Intermediate” intensity type.

Helinger kernel [25], for the raw histogram, and is expected to
produce more promising results with the efficient linear SVM. In
PRICoLBP, we used different radii (1 or 2) of neighbors and different template numbers (1 or 2: two configurations, a or b), denoted as PRICoLBP r1t1, PRICoLBP r1t2a, PRICoLBP r1t2b,
PRICoLBP r2t1, PRICoLBP r2t2a, and PRICoLBP r2t2b,

HAN et al.: HIGH-ORDER STATISTICS OF MICROTEXTON FOR HEP-2 STAINING PATTERN CLASSIFICATION

2231

Fig. 10. Comparative results between KNN and SVM classifiers; (a) the computational time; (b) accuracies for “Positive”; (c) accuracies for “Intermediate”.
(a)The computational time. (b) Accuracies for “Positive” type. (c) Accuracies for “Intermediate” type.

respectively, for feature extraction. Our proposed strategy using
the microtexton and the local descriptor, SIFT [28] [23] (instead
of texton, called “GMM Sift”), which is widely used for generic
object recognition in computer vision, was combined with linear
SVM without any preprocessing for cell pattern recognition.
The above procedure was repeated 20 times, and the final results are the average recognition performance of the
20 runs, calculated as the percentages of properly classified
cell images for all test samples. The comparitive recognition
rates for both “Positive” and “Intermediate” intensity types using the nonsqrt or sqrt LBP, PRICoLBP (denoted as “Without Sqrt” and “With Sqrt”) with different parameters, and the
proposed strategy with the proposed microtexton (3×3) or the
widely used SIFT descriptor (denoted as “GMM Sift”) are
shown in Fig. 7. It can be clearly seen that our proposed strategy
can outperform LBP, RICLBP, and PRICoLBP with different
parameters and the modeling strategy of “Sift” descriptors for
both “Positive” and “Intermediate” intensity types.
Next, the effectiveness of the statistics with different orders
(the zeroth, the first, and second orders) is validated by the recognition performances for “Positive” and ‘Intermediate’ intensity
types shown in Fig. 8, where it can be seen that the concatenated

vector of all statistics can achieve the best results for both types
(“Positive” type with 128 Gaussian components; “Intermediate”
with 32 Gaussian components). In addition, it can clearly be seen
that our proposed strategy even with only low-order statistics
(zeroth-order, denoted by “order0”) can markedly improve the
recognition rates of HEp-2 cell patterns as compared to the LBP
histogram, and achieves better or comparable results with only
one-order statistics as compared to RICLBP and PRICoLBP features. Fig. 8 demonstrates that high-order are more discriminant
than low-order statistics, and the concatenation of all, which
will be used for the following experiments, can achieve the best
recognition rates. Table II(a) and (b) are the confusion tables
of the detailed information for cell recognized patterns shown
in Table II(a) and II(b) for “Positive” and “Intermediate” types,
respectively. The tables show that the recognition rates for the
five HEp-2 cell patterns, excluding “Golgi” can achieve a better
than 95% performance rate for the “Positive”, and more than
75% performance for “Intermediate” type.
In the following, we show the effect of the GMM component
number (K described in Section III) and the microtexton size.
As the GMM component number increases, the vector length increases proportionally. Although lower numbers of components

2232

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 8, AUGUST 2014

Fig. 11. “Accuracy”-“Reject rate” curve for different HEp-2 staining patterns.
(a) For “Positive” intensity type. (b) For “Intermediate” intensity type.

lead to a compact representation, larger numbers usually lead to
better quantization of the space and hence representations that
are more discriminant. The average recognition rates for the two
types of HEp-2 dataset are shown in Fig. 9 with different numbers of components and different microtexton sizes. Using 3 ×
3 microtexton, we observe that the performance for the “Positive” intensity type increases with the number of components,
and can achieve an average rate of 95.5% with 128 components
and 92.95% with 16 components, which is much better than the
intra-laboratory rate. However, for the “Intermediate” intensity
type, the proposed strategy with only a lower number of components, 32 in 3 × 3 microtexton, can achieve the best performance rate, 80.95%, which decreases slightly (by 1–2%) when
the number is increased to 64 and 128. One possible reason for
this phenomenon is that the intensity magnitude is very low in
the “Intermediate” type, which leads to a lower signal-to-noise
ratio (SNR). If we increase the component number in GMM for

modeling the microtexton, it is possible that some components
model only the noise information, which results in a decrease in
the performance as the number of components increases. Further, we vary the microtexton size (i.e., from 3 × 3 to 5 × 5,
7 × 7) for extracting the high-order statistics, and conducted
HEp-2 staining pattern recognition under the same experimental conditions. The comparative results are also shown in Fig. 9
for both “Positive” and “Intermediate” types. It is obvious that
the using of larger size microtexton for “Positive” type only
has tiny improvement (i.e., less than 0.5 % for most cases), and
most recognition accuracies with 7 × 7 microtexton even have
little decreasing compared to the ones of 5 × 5 microtexton.
However, for “Intermediate” type, the performances with larger
size microtextons can manifest a great improvement compared
to 3 × 3 microtexton; the recognition accuracies with 5 × 5, 7
× 7 sizes and 128 Gaussian components can reach 89.56% and
90.62% from about 80% with 3 × 3 microtexton. In addition, the
recognition performances with K-nearest neighborhood (KNN)
are also given in Fig. 9 for comparison, which show much lower
accuracies than SVM classifier. However, since KNN classifier
needs to calculate the distance with all samples in database, it
is time-consuming; our used linear SVM can be more efficient
after learn the classification model in training procedure. The
compared computational time is shown in Fig. 10(a), and the
compared recognition rates for each staining pattern with KNN
and SVM classifiers using 7 × 7 microtexton are given in
Fig. 10(b) and (c) for “Positive” and “Intermediate” types,
respectively.
To explore the confidence score of each of the samples to be
classified as different HEp-2 cell patterns, we plotted the “Reject
rate”–“Accuracy” curves for all HEp-2 patterns. For example,
there are N test samples in total, of which N1 samples belong to
the ith HEp-2 pattern. With our learned system, there exist M
samples that are classified as the ith HEp-2 pattern, of which
M1 samples are correctly classified. The “Accuracy” (Acc) and
“Reject rate” (RR) for the ith HEp-2 pattern can be calculated
as
N − M1
M1
; RR =
.
(13)
Acc =
M
N
The “Reject rate”–“Accuracy” curves for all patterns are
shown in Fig. 11(a) and (b), respectively, for the “Positive”
and “Intermediate” intensity types. For the Speckled, Nucleolar, Centromere, and NuMem patterns, the accuracy rate reaches
almost 100% with only 10% “Reject rates”, and the other patterns also have a greater than 80% accuracy rate with only 20%
“Reject rates” in the “Positive” intensity type. A greater than
75% accuracy rate with 20% “Reject rates” can be achieved
for five patterns, excluding “Golgi” in the “Intermediate” intensity type, which also proves the effectiveness of our proposed
strategy for HEp-2 staining pattern recognition.
VI. CONCLUSION
In this paper, we proposed an approach for classifying HEp2 staining cells automatically using IIF image analysis, which
can indicate the presence of autoimmune diseases by finding
antibodies in the patient serum. Studies on HEp-2 cell pattern

HAN et al.: HIGH-ORDER STATISTICS OF MICROTEXTON FOR HEP-2 STAINING PATTERN CLASSIFICATION

recognition have shown that LBP and its extension version,
RICLBP, PRICoLBP for image representation, can produce
promising classification accuracy rates. However, there is still a
lot of room for improvement. We know that LBP only quantizes
a local patch (microstructure) into a binary series by comparing
the surrounding pixel intensity with that of the center pixel, and
the quantitative difference is then lost as a result of the binary
coding in LBP. Therefore, it is possible that very different local
structures (patch) will be represented by the same LBP value,
which means the LBP is very limited in terms of representing
the local structure given the fixed approximate quantization of
the feature space as binary patterns. In addition, in general, local binary pattern (local structure) distributions are represented
by histograms, and hence, are restricted to the use of low-order
statistics. In this study, the local structure was represented directly as the differential vector between the surrounding pixels
and the center one, called the microtexton, and modeled as a
parametric probability process using GMM. The proposed strategy can adaptively characterize the microtexton space of HEp-2
cell images, and learn the parameters for fitting the training
space better, which leads to a more discriminant representation
of the cell image. Furthermore, we also extract the higher-order
statistics for the model parameters, which is more discriminant
for image representation and can be combined with a linear
classifier (such as a linear SVM). Experiments using the open
HEp-2 cell dataset of the ICIP2013 contest validated that the
proposed strategy can achieve a much better performance than
the widely used LBP and its extensions, RICLBP, PRICoLBP
for image representation, and the achieved recognition error rate
was even very significantly below the observed intralaboratory
variability.
REFERENCES
[1] T. Ahonen, A. Hadid, and M. Pietikainen, “Face description with local
binary patterns: Application to face recognition,” IEEE J. Pattern Anal.
Mach. Intell., vol. 28, no. 12, pp. 2037–2041, Dec. 2006.
[2] S. Amari and H. Nagaoka, “Methods of information geometry,” in Translations of Mathematical Mono-Graphs, vol. 191. Oxford, U.K.: Oxford
Univ. Press, 2000.
[3] O. Aran and L. Akarun, “A multi-class classification strategy for Fisher
scores: Application to signer independent sign language recognition,”
Pattern Recognit., vol. 43, no. 5, pp. 1776–1788, 2010.
[4] S. Awate, T. Tasdizen, and R. Whitaker, “Unsupervised texture segmentation with nonparametric neighborhood statistics,” in Proc. Eur. Conf.
Comput. Vis., 2006, pp. 497–507.
[5] J. Chen, S. Shan, C. He, G. Zhao, M. Pietikainen, X. Chen, and W. Gao,
“Wld: A robust local image descriptor,” IEEE J. Pattern Anal. Mach.
Intell., vol. 32, no. 9, pp. 1705–1720, Sep. 2010.
[6] B. Christopher, Pattern Recognition and Machine Learning. New York,
NY, USA: Springer-Verlag.
[7] K. Conrad, R. Humbel, M. Meurer, and Y. Shoenfeld, Autoantigens and
Autoantibodies: Diagnostic Tools and Clues to Understanding Autoimmunity. Lengerich, Germany: Pabst Science Publishers, 2000.
[8] K. Conrad, W. Schoessler, F. Hiepe, and M. J. Fritzler, Utoantibodies
in Systemic Autoimmune Diseases. Lengerich, Germany: Pabst Science
Publishers, 2002.
[9] N. Cristianini and J. Shawe-Taylor, An Introduction to Support Vector
Machines and Other Kernel-Based Learning Methods. Cambridge, U.K.:
Cambridge Univ. Press, 2000.
[10] A. Dempster, N. Laird, and D. Rubin, “Maximum likelihood from incomplete data via the em algorithm,” J. Roy. Statist. Soc.: Series B, vol. 39,
no. 1, pp. 1–38, 1997.

2233

[11] U. Dick and K. Kersting, “Fisher kernels for relational data,” Proc. 17th
Eur. Conf. Mach. Learn., 2006, vol. 4212, pp. 114–125.
[12] I. Dinov, “Expectation maximization and mixture modeling tutorial,”
California Digital Library, Statistics Online Computational Resource,
2008. Retrieved from: http://escholarship.org/uc/item/1rb70972
[13] P. Foggia, G. Percannella, P. Soda, and M. Vento, “Early experiences in
mitotic cells recognition on hep-2 slides,” in Proc. IEEE 23rd Int. Symp.
Comput.-Based Med. Syst., 2010, pp. 38–43.
[14] P. Foggia, G. Percannella, P. Soda, and M. Vento, “Benchmarking hep-2
cells classification methods,” IEEE Trans. Med. Imag., vol. 32, no. 10,
pp. 1878–1889, Oct. 2013.
[15] C. for Disease Control, “Quality assurance for the indirect immunofluorescence test for autoantibodies to nuclear antigen (if-ana): approved
guideline,” NCCLS I/LA2-A, vol. 16, no. 11, 1996.
[16] D. He and L. Wang, “Texture unit, texture spectrum, and texture analysis,”
IEEE Trans. Geosci. Remote Sens., vol. 28, no. 4, pp. 509–512, Jul. 1990.
[17] R. Hiemann, T. Buttner, T. Krieger, D. Roggenbuck, U. Sack, and K.
Conrad, “Automatic analysis of immunofluorescence patterns of hep-2
cells,” Ann. New York Acad. Sci., vol. 1109, no. 1, pp. 358–371, 2007.
[18] R. Hiemann, T. Buttner, T. Krieger, D. Roggenbuck, U. Sack, and K.
Conrad, “Challenges of automated screening and differentiation of nonorgan specific autoantibodies on hep-2 cells,” Autoimmunity Rev., vol. 9,
no. 1, pp. 17–22, 2009.
[19] Y.-L. Huang, C.-W. Chung, T.-Y. Hsieh, and Y.-L. Jao, “Outline detection
for the hep-2 cells in indirect immunofluorescence images using watershed
segmentatio,” in Proc. IEEE Int. Conf. Sens. Netw., Ubiquit. Trustworthy
Computing, 2008, pp. 423–427.
[20] Y.-L. Huang, Y.-L. Jao, T.-Y. Hsieh, and C.-W. Chung, “Adaptive automatic segmentation of hep-2 cells in indirect immunofluorescence images,” in Proc. IEEE Int. Conf. Sens. Netw., Ubiquit. Trustworthy Comput.,
2008, pp. 418–422.
[21] T. Jaakkola and D. Haussler, “Exploiting generative models in discriminative classifiers,” in Proc. Neural Inform. Process. Syst., pp. 487–493,
1998.
[22] J. Krapac, J. Verbeek, and F. Jurie, “Modeling spatial layout with fisher
vectors for image categorization,” in Proc. Int. Conf. Comput. Vis., pp.
1487–1494, 2011.
[23] S. Lazebnik, C. Schmid, and J. Ponce, “Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories,” in Proc.
Comput. Vis. Pattern Recognit., 2006, pp. 2169–2178.
[24] T. Leung, and J. Malik, “Representing and recognizing the visual appearance of materials using three-dimensional textons,” Int. J. Comput. Vis.,
vol. 43, pp. 29–44, 2001.
[25] T. Leung, and J. Malik, “Effects of image retrieval from image database
using linear kernel and hellinger kernel mapping of svm,” Int. J. Scientif.
Eng. Res., vol. 4, pp. 1487–1494, 2013.
[26] L. Liu, L. Wang, and X. Liu, “In defense of soft-assignment coding,” in
Proc. IEEE Int. Conf. Comput. Vis., 2011, pp. 2486–2493.
[27] W. Louis and K. N. Plataniotis, “Co-occurrence of local binary patterns
features for frontal face detection in surveillance applications,” EURASIP
J. Image Video Process., vol. 2011, pp. 1–17, 2011.
[28] D. Lowe, “Distinctive image features from scale-invariant keypoints,” Int.
J. Comput. Vis., vol. 60, no. 2, pp. 91–110, 2004.
[29] R. Nosaka and K. Fukui, “Hep-2 cell classification using rotation invariant
co-occurrence among local binary patterns,” Pattern Recognit., vol. 47,
pp. 2428–2436, 2013.
[30] R. Nosaka, C. H. Suryanto, and K. Fukui, “Rotation invariant cooccurrence among adjacent LBPs,” Int. Workshop Comput. Vis. Local
Binary Pattern Variants (LBP2012), Part I, LNCS 7728, pp. 15-25, 2012.
[31] P. Perner, H. Perner, and B. Muller, “Mining knowledge for hep-2
cell image classification,” J. Artif. Intell. Med., vol. 26, pp. 161–173,
2002.
[32] M. Pietikinen, A. Hadid, G. Zhao, and T. Ahonen, Computer Vision Using
Local Binary Patterns. New York, NY, USA: Springer-Verlag, 2011.
[33] V. K. Pothos, C. Theoharatos, E. Zygouris, and G. Economou,
“Distributional-based texture classification using non-parametric statistics,” Pattern Anal. Appl., vol. 2, pp. 117–129, 2008.
[34] X. Qi, R. Xiao, L. Zhang, and J. Guo, “Pairwise rotation invariant cooccurrence local binary pattern,” in Proc. 12th Eur. Conf. Comput. Vis.,
2012, pp. 158–171.
[35] A. Rigon, P. Soda, D. Zennaro, G. Iannello, and A. Afeltra, “Indirect immunofluorescence in autoimmune diseases: Assessment of digital images
for diagnostic purpose,” Cytometry B (Clin. Cytometry), vol. 72, no. 3,
pp. 472–477, 2007.

2234

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 8, AUGUST 2014

[36] U. Sack, S. Knoechner, H. Warschkau, U. Pigla, F. Emmrich, and M. Kamprad, “Computer-assisted classification of hep-2 immunofluorescence patterns in autoimmune diagnostics,” Autoimmunity Rev., 2, pp. 298–304,
2003.
[37] X. W. S. D. Han, W. B. Tao, “Texture segmentation using independentscale component-wise Riemannian-covariance gaussian mixture model in
kl measure based multi-scale nonlinear structure tensor space,” Pattern
Recognit., vol. 3, pp. 503–518, 2011.
[38] P. Soda and G. Iannello, “Aggregation of classifiers for staining pattern
recognition in antinuclear autoantibodies analysis,” IEEE Trans. Inf. Technol. Biomed., vol. 13, no. 3, pp. 322–329, May. 2009.
[39] P. Soda, G. Iannello, and M. Vento, “A multiple experts system for classifying fluorescence intensity in antinuclear autoantibodies analysis,” Pattern
Anal. Appl., vol. 12, no. 3, pp. 215–226, 2009.
[40] P. Soda, A. Rigon, A.Afeltra, and G. Iannello, “Automatic acquisition of
immunofluorescence images: Algorithms and evaluation,” in Proc. 19th
IEEE Int. Symp. Comput. Based Med. Syst., 2006, pp. 386–390.
[41] X. Tan and B. Triggs, “Enhanced local texture feature sets for face recognition under difficult lighting conditions,” IEEE Trans. Image Process.,
vol. 19, no. 6, pp. 1635–1650, Jun. 2010.
[42] M. Varma and A. Zisserman, “Texture classification: Are filter banks
necessary?” in Proc. Comput. Vis. Pattern Recognit., 2003, pp. 691–698.
[43] X. Wang, T. X. Han, and S. Yan, “An hog–lbp human detector with partial
occlusion handling,” in Proc. Int. Conf. Comput. Vis., 2009, pp. 32–39.
[44] L. Xu and M. Jordan, “On convergence properties of the em algorithm
for gaussian mixtures,” Neural Comput., vol. 9, no. 1, pp. 129–151,
1996.
[45] G. Zhao, and M. Pietikainen, “Local binary pattern descriptors for dynamic
texture recognition,” Pattern Recognit., pp. 211–214, 2006.

Xian-Hua Han (M’11) received the B.E. degree from
ChongQing University, ChongQing, China, in 1999
and the M.E. degree from ShanDONG University, JiNan, China, in 2002, and the D.E. degree from the
University of Ryukyus, Okinawa, Japan, in 2005.
She is currently an Associate Professor at
Ritsumeikan University, Kusatsu, Japan. Her current
research interests include image processing and analysis, machine learning, computer vision and pattern
recognition. She is a Member of the IEICE.

Jian Wang received the B.E. degree from QingDao
University, QingDao, China, in 2012. He is currently
working toward the Master’s degree at Ritsumeikan
University, Kusatsu, Japan.
His current research interests include image processing and analysis, and human–computer interface.

Gang Xu (M’86) received the Ph.D. degree from
Osaka University, Osaka, Japan, in 1989.
He was then a Visiting Researcher at ATR till
1990, when he returned to Osaka University as an Assistant Professor. In 1996, he became a tenured Associate Professor in Department of Computer Science,
Ritsumeikan University, Kusatsu, Japan. He was a
Visiting Researcher at Robotics Lab, Harvard University, Cambridge, MA, USA, in 1994, at Microsoft
Research China in 1999, and at Motorola Australian
Research Centre in 2000. Since 2001, he has been
a Full Professor in Ritsumeikan University. In 2000, he founded 3D MEDiA
Company Ltd. and has served as the CEO since then. His research interests include image-based 3-D metrology, 3-D object recognition for industrial robots,
and underlying techniques for pattern recognition in general. He authored and
coauthored Epipolar Geometry in Stereo, Motion and Object Recognition: A
Unified Approach (Norwell, MA, USA: Kluwer Academic Publishers, 1996),
3D Vision (Tokyo, Japan: Kyoritsu Shuppan in Japanese, 1999), and 3D CG
from Photographs (Tokyo, Japan: Kindai Kagakusha in Japanese, 2001).

Yen-Wei Chen (M’96) received the B.E. degree from
Kobe University, Kobe, Japan, in 1985, and the M.E.
and D.E. degrees from Osaka University, Osaka,
Japan, in 1987 and 1990, respectively.
From 1991 to 1994, he was a Research Fellow
with the Institute of Laser Technology, Osaka. From
October 1994 to March 2004, he was an Associate
Professor and a Professor with the Department of
Electrical and Electronics Engineering, University of
the Ryukyus, Okinawa, Japan. He is currently a Professor with the College of Information Science and
Engineering, Ritsumeikan University, Kusatsu, Japan, and a Professor with
the Institute for Computational Science and Engineering, Ocean University of
China, Shandong, China. He is an Overseas Assessor of the Chinese Academy
of Science and Technology, an Associate Editor of the International Journal of
Image and Graphics, an Editorial Board Member of the International Journal
of Knowledge-Based Intelligent Engineering Systems and an Editorial Board
Member of the International Journal of Information. His research interests include intelligent signal and image processing, radiological imaging, and soft
computing. He has published more than 100 research papers in these fields. He
is a Member of the IEICE Japan and the IEE Japan.

