IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 1, JANUARY 2015

29

Evaluation of Healthy EEG Responses for Spelling
Through Listener-Assisted Scanning
Petar Horki, Daniela S. Klobassa, Christoph Pokorny, and Gernot R. Müller-Putz, Member, IEEE

Abstract—We investigated whether listener-assisted scanning,
an alternative communication method for persons with severe motor and visual impairments but preserved cognitive skills, could
be used for spelling with EEG. To that end spoken letters were
presented sequentially, and the participants made selections by
performing motor execution/imagery or a cognitive task. The motor task was a brisk dorsiflexion of both feet, and the cognitive task
was related to working memory and perception of human voice.
The motor imagery task yielded the most promising results with
respect to letter selection accuracy, albeit with a large variation
in individual performance. The cognitive task yielded significant
(p = 0.05) albeit moderate results. Closer inspection of grand average ERPs for the cognitive task revealed task-related modulation
of a late negative component, which is novel in the auditory BCI
literature. Guidelines for further development are presented.
Index Terms—Assistive technology, brain–computer interfaces,
electroencephalography.

I. INTRODUCTION
HEN Jean–Dominique Bauby woke up following a massive brain stem stroke, he found himself physically paralyzed with only residual head and eye movements. Despite
his condition, the so-called locked-in syndrome, he wrote “The
Diving Bell and the Butterfly” [1]. How did he manage to communicate a whole book? He used the listener-assisted scanning
method, where messages or letter choices are presented to a person in a sequential fashion until a selection is made. To select
a letter of the alphabet, repeatedly recited by a caregiver, he
blinked with his eyelid.
Persons transitioning from locked-in to complete locked-in
state often find themselves unable to communicate due to loss
of voluntary muscle control. For such persons with severe motor

W

Manuscript received December 15, 2013; revised April 14, 2014; accepted
March 13, 2014. Date of publication June 30, 2014; date of current version
December 30, 2014. This work was supported by the European ICT Programme
Project FP7-247919 (DECODER) and the “Land Steiermark” Project ABT0822-T-7/2013-17 (EEG@Wachkoma).
P. Horki is with the Institute for Knowledge Discovery, Laboratory for
Brain-Computer Interfaces, Graz University of Technology, Graz 8010, Austria
(e-mail: petar.horki@tugraz.at)
D. S. Klobassa was with the Institute for Knowledge Discovery, Laboratory
for Brain-Computer Interfaces, Graz University of Technology, Graz 8010, Austria. She is now with the Department of General Pediatrics, Medical University
of Graz, Graz 8036, Austria (e-mail: daniela.klobassa@medunigraz.at).
C. Pokorny was with the Institute for Knowledge Discovery, Laboratory for
Brain-Computer Interfaces, Graz University of Technology, Graz 8010, Austria.
He is now with the Institute for Theoretical Computer Science, Graz University
of Technology, Graz 8010 Austria (e-mail: christoph.pokorny@tugraz.at)
G. R. Müller-Putz is with the Institute for Knowledge Discovery, Laboratory
for Brain-Computer Interfaces, Graz University of Technology, Graz 8010,
Austria (e-mail: gernot.mueller@tugraz.at).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org
Digital Object Identifier 10.1109/JBHI.2014.2328494

and visual impairments but preserved cognitive skills, a brain–
computer interface (BCI) might provide alternative means of
communication [2], thus increasing their quality of life [3]. The
majority of reported BCIs are based on electroencephalography
(EEG), mainly due to following three reasons: first, it has a
high temporal resolution [4]; second, it is widely available; and
third, it is applicable in persons with metal implants. Whereas
different BCIs for spelling applications based on changes of
oscillatory components have been proposed [5]–[10], we will
focus on auditory based ones, as it was shown that a patient in
the completely locked-in state has lost all afferent pathways but
the auditory system [11].
An auditory BCI for spelling applications can be realized by
utilizing the spatial features of auditory cues [12], [13]. However, it is an open research question to what extent behaviorally
nonresponsive patients can process these spatial features. In a
recent study using oddball design [14], preattentive processing
of different features of auditory cues (i.e., location, pitch, intensity, duration, and complexity [15]) was investigated in nonresponsive patients. The main result was that pitch and intensity
deviants could be discriminated by almost all patients, whereas
other deviants could be discriminated only in some patients.
Whereas these results, given the small number of participants
involved, should be interpreted with caution, it is reasonable
to assume that some patients might benefit from an auditory
BCI for spelling applications independent of spatial features of
auditory cues—a listener-assisted BCI for spelling applications
[16].
Does it make sense to pursue a listener-assisted BCI for
spelling applications? At first glance, the answer might be no
since the oddball experimental design, as employed in stateof-the-art auditory BCIs for spelling applications, is contingent
upon random presentation of items. However, random presentation of letters of the alphabet is difficult to process, which
causes the evoked responses in EEG to diminish [17]. In spite
of this problem, several lines of evidence suggest that a listenerassisted BCI for spelling applications might be feasible: first
[18], demonstrated that a periodic protocol can outperform the
standard oddball protocol within the context of an visual BCI;
second [19], demonstrated gaze-independent spelling based on
rapid serial visual presentation; and third [20], enhanced the
performance of an auditory attention-based brain–computer interfaces by employing an active mental task.
Another approach would be to employ a linear scanning protocol based on sensorimotor rhythm-based selection. Such an
approach was already demonstrated in a multichoice visual [21]
and a binary auditory [22] paradigm, but it is unclear whether it
is feasible for multichoice auditory paradigm.

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

30

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 1, JANUARY 2015

Our aim is to investigate whether listener-assisted scanning
could be used for spelling with EEG. Our hypothesis is that
when spoken letters are presented sequentially, the participants
can communicate the intended letter by performing a mental
task. To test this hypothesis, we evaluate whether the intended
letter can be detected through induced and evoked EEG responses associated with different mental tasks. The results of
this evaluation will form the basis of a listener-assisted BCI for
spelling applications and guide its further development.
II. METHODS
A. Subjects
Eleven healthy subjects (5 male, 6 female; 22 to 29 year
old, mean age 26) participated in this experiment. They were recruited through university public notice boards (i.e., newsgroup,
forum). Participants gave informed consent prior to the beginning of the experiments and received monetary compensation
afterward. Half of the participants had no previous exposure
to EEG experiments. The experiment was undertaken in accordance with the Declaration of Helsinki.
B. Recording
The EEG was recorded with 29 active electrodes (g.tec, Guger
Technologies, Graz, Austria) overlying the frontal, central, and
parietal scalp areas. In detail, the electrodes were placed at
positions AFz, F3, F1, Fz, F2, F4, FC2, FC1, FCz, FC4, C5,
C3, C1, Cz, C2, C4, C6, CP3, CP1, CPz, CP2, CP4, P3, P1, Pz,
P2, P4, and POz according to the international 10/20 electrode
system. The EEG electrodes were referenced to the left ear lobe
with the ground electrode placed on the right ear lobe. The
electrodes were integrated into a standard EEG cap (Easycap
GmbH, Herrsching, Germany) with an interelectrode distance of
2.5 cm and connected to EEG amplifiers (g.tec, Graz, Austria).
The electrooculogram (EOG) was recorded with three active electrodes (g.tec, Guger Technologies, Graz, Austria), positioned above the nasion, and below the outer canthi of the eyes.
The electromyogram (EMG) was recorded with four electrodes
from both legs (musculus tibialis anterior). The EEG amplifiers
were set up with a band-pass filter between 0.5 and 100 Hz, and
a notch filter at 50 Hz. The EEG and EOG were sampled with
512 Hz, the EMG with 2000 Hz. Participants were seated in an
electrically shielded room.
C. Stimuli
Spoken letters of the English alphabet, generated by a textto-speech program (AT&T Natural Voices, AT&T, USA), were
presented sequentially in alphabetical order through a right head
phone for one of several predefined words. Presenting acoustic
cues through one ear only, keeps the other ear free for incoming
communication from surroundings. The task irrelevant acoustic
cues (i.e., cues specifying the target letter, pause, report) were
presented in either male or female voice, balanced across all the
subjects.
Stimulus onset asynchrony was set to 550 ms, including a
50 ms pause. Thus, it took 14.3 s for a single presentation of

the whole alphabet. For each target letter, indicated through a
verbal cue, the alphabet was repeated one to three times, for a
total of two to four alphabet presentations, followed by a short
break of random length (i.e., 4 to 6 s).
D. Experimental Paradigm
The experimental paradigm is depicted in Fig. 1. For the
investigation the predefined words “brain,” “power,” “husky,”
and “magic”—had to be spelled in copy spelling mode. They
were chosen because their letters are distributed across the whole
alphabet range. Each word was spelled letter by letter within a
single run. Runs were separated by short break of 1–2 min to
avoid fatigue.
The participants were instructed verbally to perform one of
the following tasks whenever a target letter was presented: 1)
brisk feet motor execution (ME), 2) brisk feet imagery (MI), 3)
discrimination of the target voice’s gender and comparison to
the following repetition (i.e., whether the target voice’s gender
has changed or it remained the same, reporting through single/double button press with index finger of the right hand in a
dedicated time window) as a cognitive task (COG), and 4) mental repetition of the target letter as a control condition (auditory
evoked potentials, AEP). The participants were also verbally
instructed to avoid any movements.
We balanced the order of motor (ME, MI) and nonmotor
conditions (COG, AEP). ME condition always preceded the
MI condition. The COG and AEP conditions were pseudorandomized. We randomized the order of words, and balanced the
voice of presentation (male/female). Participants received no
feedback.
E. Data Analysis
EEG analysis was performed separately for motor and nonmotor mental tasks using MATLAB 2009a (MathWorks, USA)
and EEGLAB version 11 [23]. The analysis consisted of preprocessing, feature extraction, and classification.
1) Preprocessing: The data were high-pass filtered (thirdorder butterworth filter) with cutoff frequency at 1 Hz, and
segmented into consecutive epochs of 0.5 s. Bad channels and
prominent artifacts (i.e., swallowing, electrode cable movements, etc.) were identified by visual inspection and removed.
Following these steps, binary Infomax independent component
analysis (ICA) by Sigurd Enghoff [24], based on the MATLAB
version of Scott Makeig and collaborators, was used to separate
EEG and EOG signals into independent components [25]. Independent components (ICs) representing eye movements, eye
blinks, and muscle activity were identified by visual inspection
using methods described in [26] and removed. The remaining
components were multiplied by the mixing matrix produced by
the ICA algorithm to reconstruct cleaned EEG.
a) Feature extraction–motor tasks: For motor tasks analysis, we defined a single epoch as 1 s following onset of a spoken
letter. The epochs were band-pass filtered (third-order Butterworth filter) between 8 and 30 Hz. Common spatial patterns
(CSP, [27]–[29]) method was used to compute most discriminative features for classification.

HORKI et al.: EVALUATION OF HEALTHY EEG RESPONSES FOR SPELLING THROUGH LISTENER-ASSISTED SCANNING

31

Fig. 1. Experimental paradigm: the four predefined words (i.e., “brain,” “power,” “husky,” and “magic”) had to be spelled in copy spelling mode. To that end,
spoken letters of the English alphabet, generated by a text-to-speech program, were presented sequentially in alphabetical order through a right head phone. The
participants were instructed to perform one of the following tasks whenever a spoken target letter was presented: i) brisk feet motor execution (ME), ii) brisk feet
motor imagery (MI), iii) discrimination of the target voice’s gender and comparison to the following repetition (COG), and iv) mental repetition of the target letter
(AEP). Participants received no feedback. The task irrelevant acoustic cues (i.e., cues specifying the target letter, pause, report) were presented in either male or
female voice, balanced across all the subjects.

Discriminative feature vectors were obtained for a fixed time
segment (one second post letter onset) extracted from a balanced
number of target and randomly chosen nontarget epochs of the
initial run. Four feature vectors (first two and last two) were
preselected, and downsampled to 32 equally spaced samples.
The size of the feature vector used for subsequent classification
was 128 (i.e., four CSP feature vectors by 32 time points).
For percentage of power decrease (ERD) and power increase
(ERS) analysis, we defined a single epoch as 1 s preceding
and 5 s following onset of a spoken letter. To that end, a timefrequency map for frequency bands between 4 and 40 Hz (35
overlapping bands using a band width of 2 Hz) was calculated
([30]) for one orthogonal Laplacian derivation overlying Cz.
Logarithmic band power features, calculated by band-pass filtering, squaring, and subsequently averaging over the trials, were
used to assess changes in the frequency domain. To determine
the statistical significance of the ERD/ERS values, a t-percentile
bootstrap algorithm with a significance level of p = 0.05 was
applied.
b) Feature extraction–nonmotor tasks: For nonmotor task
analysis, we defined a single epoch as 1000 ms following onset
of a spoken letter, baseline corrected to preceding 250 ms. The
epochs were band-pass filtered (third-order Butterworth filter)
between 1 and 7 Hz, downsampled to 32 equally spaced samples,
and the features were extracted from nine preselected electrodes
(F3, Fz, F1, C3, Cz, C1, P3, Pz, P1). The size of the feature vector

Fig. 2. Shown here is the binary discrimination accuracy for all subjects
and for different conditions, calculated as the percentage of correctly classified
target/nontarget epochs in outer folds of the nested cross validation. Balanced
number of target and nontarget epochs was used. In subject 7, ME condition
was discarded due to movement artifacts, that could not be removed with the
artifact rejection. ME/MI . . . brisk feet motor execution/imagery; COG . . .
discrimination of the target voice’s gender and comparison to the following
repetition; AEP . . . mental repetition of the letter.

used for subsequent classification was 288 (i.e., 9 channels by
32 time points).
3) Classification: To avoid over fitting, we used Bayesian
linear discriminant analysis (BLDA, [31]) as a classifier, and
nested cross validation.

32

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 1, JANUARY 2015

Fig. 3. Shown here is letter selection accuracy, calculated as the percentage of correctly “guessed” letters (i.e., letters with highest classifier probability within a
sequence). The x-axis indicates whether single sequences (i.e., for x = 1), sequence pairs (i.e., for x = 2) or sequence triplets (i.e., x = 3) were used to accumulate
the classifier probability. Mean values and upper limits of one standard deviation (marked by an asterisk) are displayed in lower right corner for all subjects,
together with the type-I error. ME / MI . . . brisk feet motor execution/imagery; COG . . . discrimination of the target voice’s gender and comparison to the
following repetition; AEP . . . mental repetition of the letter; α ∗ . . . type-I error.

Each inner cross validation (five-fold with ten repetitions) was
repeated five times with randomly selected nontarget epochs
(i.e., to balance the number of target and nontarget epochs),
followed by an evaluation on the outer fold.
Three outer folds were employed, constructed to allow for the
evaluation of both binary (i.e., target versus nontarget) as well
as letter selection accuracy. The three outer folds were obtained
by pseudorandomly splitting the data into roughly three equal
parts as follows:
1) First outer fold was created by randomly choosing within
trial sequence-triples. Given there was a total of 20 trials
(i.e., letters to spell) within a condition, this resulted in
approximately six sequence-triplets constructed from a
total of 18 sequences.
2) Second outer fold was created by randomly choosing
within trial sequence-pairs, resulting in approximately six
sequence-pairs constructed from a total of 12 sequences.
3) Third outer fold was created from the remaining sequences
(varying number due to artifact rejection).
For the motor tasks, we discarded the initial run used for CSP
filters calculation.
4) Evaluation: Outer cross-validation folds were used to estimate both the binary discrimination accuracy (i.e., on a balanced number of target versus nontarget epochs) as well as
to estimate the letter selection accuracies (i.e., on sequencetriplets, -pairs, and single sequences). The reported values are
means over the three outer folds, with each outer fold evaluated
five times with repeated inner cross validation.

The binary discrimination accuracy (accbin ) is the percentage
of correctly classified target (TP) and correctly classified nontarget epochs (TN) in each outer fold as in (1), averaged over
all outer fold evaluations. The target/nontarget epoch pairs were
selected from same sequences
acc bin =

TP + TN
.
#epochs

(1)

We analyzed classification performance across subjects
and conditions with repeated measures analysis of variance
(ANOVA). The independent variable was binary discrimination accuracy, and the factor was condition (4 levels). Further
analysis was done with a Bonferroni corrected paired t-tests.
The letter selection accuracy is the percentage of correctly
“guessed” letters (i.e., letters with highest classifier probability
within a sequence). Note that for sequence-pairs and triplets,
the classifier probability was accumulated over two and three
sequences, respectively.
III. RESULTS
The results of binary discrimination accuracy for all subjects
across different conditions are shown in Fig. 2. In subject 7,
ME condition was discarded due to movement artifacts, that
could not be removed with the artifact rejection, resulting in
an overestimate of the classification accuracy. The mean and
standard deviation are 71% ± 11% for ME, 66% ± 12% for MI,
63% ± 3% for COG, and 51% ± 3% for AEP condition (the

HORKI et al.: EVALUATION OF HEALTHY EEG RESPONSES FOR SPELLING THROUGH LISTENER-ASSISTED SCANNING

33

Fig. 4. Percentage of power decrease (ERD, orange) and power increase
(ERS, blue) relative to a reference interval (one second pre cue) for motor
execution (ME, left) and motor imagery (MI, right) condition in one subject.
One orthogonal Laplacian derivation overlying Cz was used for both conditions.
Only significant (p = 0.05, t-percentile bootstrap algorithm) power changes are
shown. The CUE corresponds to the onset of target letter voice presentation.
TABLE I
ANOVA RESULT FOR CLASSIFICATION PERFORMANCE
Effect

DFn

DFd

P

Cond

3

27

0.00018

The factor condition is abbreviated
as Cond. F is the value of the fstatistic, with degrees of freedom
DFn and DFd.

upper 95% confidence limit of a chance result was estimated to
be 60% [32]).
Table I shows the results of the ANOVA for classification performance, showing a significant effect for Condition (p < 0.01).
The classification performance for the ME, MI, and COG condition was significantly higher than for the AEP condition (paired
t-test, Bonferroni adjusted alpha levels: α < 0.01 for ME, MI;
α < 0.05 for COG). No significant (p < 0.05) difference was
found when comparing the ME, MI, and COG classification
performance between each other.
The results of letter selection accuracy for all subjects across
different conditions, and varying number of sequences used to
accumulate the classifier probability, are shown in Fig. 3. Notable is a large variation in individual performance, with best
performing participants achieving 88% for ME, 83% for MI,
and 57% for COG. The upper limit of the letter selection accuracy chance level was estimated to be 11% (see evaluation).
The nonmonotonic trend visible for the lower performing participants, as well as the mean for the AEP condition, could be
explained by a lack of an underlying signal benefiting from
an increased signal-to-noise ratio. The AEP condition yielded,
same as in binary discrimination, random results only and thus
will not be analyzed any further. Also shown in Fig. 3 are the
corresponding mean and standard deviation. The type I error
(i.e., α) when repeatedly testing with accumulating probabilities was estimated as α∗ = 1 − (1 − α)k , with α = 1/26 (i.e.,
number of letter choices in a trial) and k = 1, 2, 3.
In Fig. 5, selection accuracy is reevaluated with increased
time windows for ME, MI, and COG conditions, respectively.
To that end, letter selections immediately before and after the
target letter (i.e., 1.5 s time window being equivalent to the target

Fig. 5. From top to bottom: selection accuracy for ME, MI, and COG condition
and for varying time resolutions (i.e., 1.5 s time window equals the target
letter plus one letter before and one letter after, etc.). The increasing time
windows simulate a decreased rate of presentation. Pooled accuracy is obtained
as percentage of all correct selections (i.e., from all of the sequence-triplets,
sequence pairs, and single sequences).

letter plus one letter before and one letter after; 2.5 s time window being equivalent to the target letter plus two letters before
and two letters after) are counted as correct. Pooled accuracy
is obtained as percentage of all correct selections (i.e., a single
percentage accuracy estimated from all of the sequence-triplets,
sequence-pairs, and single sequences). Notable is a large increase in pooled accuracy for the ME and MI conditions in the

34

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 1, JANUARY 2015

Fig. 6. Grand averaged event-related potentials (ERPs) at electrode Pz for multiple subjects, and for the COG and AEP condition. Equal number of target and
nontarget epochs was averaged.

top performing subjects, and a modest increase for the COG
condition.
The ERD and ERS relative to a reference interval (one second
preceding the onset of a spoken target letter) for ME and MI
conditions are exemplified in Fig. 4 for one subject. Visible is
alpha and beta ERD during and beta ERS following the brisk feet
motor execution/imagery. In both motor condition the ERD/S
patterns are similar, albeit weaker in the MI condition.
In Fig. 6, grand average ERPs for equal number target and
nontarget responses for the COG condition, averaged over multiple subjects at the Pz electrode position, are shown. Taskdependent modulation of early negative (around 200 ms), late
positive (around 500 ms), and subsequent late negative (up to
1000 ms) component is visible.
IV. DISCUSSION
The goal of this paper was to investigate whether induced
and evoked EEG responses could enable spelling independent
of muscular output through listener-assisted scanning. To that
end, the results for the motor and for the COG conditions are
analyzed to derive guidelines for the further development.
The motor conditions yielded the most promising results with
respect to letter selection accuracy (see Figs. 3 and 5), albeit with
a large variation in individual performance. Closer inspection of
error distribution revealed peaks immediately before and after
the target letter, indicating that the current rate of presentation
(i.e., one letter pronounced every 0.5 s) might be too fast for
sensorimotor rhythm-based selection. Indeed, reevaluation of
selection accuracy with increased time windows (see Fig. 5,
middle), simulating a decreased rate of presentation, led to a
notable increase in performance, with pooled selection accuracy
(i.e., estimated from all of the sequence triplets, sequence pairs,
and single sequences) almost doubling for the MI condition in
the top performing subjects.
Thus, the foremost guideline for further development of sensorimotor rhythm-based selection is to reduce the rate of presentation, e.g., by employing group presentation of letters and
hierarchical selection.
Close inspection of grand average ERPs (see Fig. 6) for target and nontarget responses in the COG and AEP conditions,
revealed modulation of several components in the COG condition: first, mismatch negativity (MMN), reflecting the preattentive change detection on the level of auditory sensory memory

[33]; second, late positive component (LPC) [20], reflecting
the switch of attention onto the new information; and third,
late negative component, possibly reflecting reorientation back
to the task-relevant information (reorienting negativity, RON)
[33]. The absence of the aforementioned components in the AEP
condition indicates that these modulations are task dependent
for the COG condition. Whereas task dependent modulation
of MMN and LPC is consistent with the BCI literature [20],
modulation of RON is a novelty.
The COG condition yielded significant (p = 0.05), albeit
moderate results with respect to binary discrimination (mean
and standard deviation 63% ± 3%) and letter selection accuracy
(57% for the top performing participant). While the classification accuracies for the COG condition may not seem very
encouraging on the first sight, they are, in contrast to the AEP
condition, accompanied by a strong physiological response (see
Fig. 6). Furthermore, a monotonically increasing trend with an
increase in signal-to-noise ratio can be observed on average
(see Fig. 6). Given the evidence of task-dependent modulation
of ERP components evident in Fig. 6, moderate results for the
COG condition are likely caused by an insufficient number of
sequences used to accumulate the classifier probability. Contrary to motor imagery task, reevaluation of selection accuracy
with increased time windows has not led to a notable increase
in performance, indicating that the current rate of presentation
is not too fast. In fact, the rate of presentation could further be
increased, allowing for additional sequences within a trial that
could be used to accumulate the classifier probability. Thus,
the foremost guideline for further development of ERP-based
selection is to increase the number of sequences used to accumulate the classifier probability, e.g., by increasing the rate of
presentation through partially overlapping stimuli. Notably, this
issue could possibly be handled without necessarily increasing
the presentation rate—the definitive method is to be determined
experimentally.
The current paradigm tried to strike a balance between time
requirements for induced (i.e., sensorimotor rhythm) and evoked
(i.e., ERPs) responses in EEG associated with different mental
tasks. As such, the primary goal was not to achieve a high,
task-specific maximum information transfer rate, but to allow
for an unbiased comparison between the different mental tasks.
The use of different mental (i.e., motor and nonmotor) tasks
was motivated by highly individually specific requirements in
disabled or able-bodied persons [34]–[36]. We assumed intact

HORKI et al.: EVALUATION OF HEALTHY EEG RESPONSES FOR SPELLING THROUGH LISTENER-ASSISTED SCANNING

cognitive abilities allowing one to understand the task requirements through verbal instructions, to attend auditory stimuli
(i.e., human voice) while retaining information in working memory, and to perform the mental tasks. Whereas it is an open
research question to what extent behaviorally nonresponsive
patients possess these abilities, there are several case studies
([37], [38]) proving their presence at least in some individuals.
One of the weaknesses of this study is that all the 11 subjects
studied were healthy volunteers and none suffered from the
lock-in-syndrome. Extrapolation of research results obtained
on healthy individuals to those with lock-in-syndrome and ALS
is obviously fraught with risk.
V. CONCLUSION
We investigated whether induced and evoked EEG responses
associated with motor and nonmotor mental tasks could enable spelling independent of muscular output through listenerassisted scanning, and found the most promising results with
motor related tasks. We also found that a single cognitive task,
related to working memory and perception of human voice, can
modulate ERP components (i.e., MMN, LPC, and RON) reflecting three different stages of selective attention. These findings,
as well as the recent reports that the selective attention to spoken
words in auditory scanning is perceived as intuitive and easy to
use in untrained participants [39], form a solid basis for further
development of an EEG-based listener-assisted BCI for spelling
applications.
ACKNOWLEDGMENT
The authors would like to thank C. Breitwieser and
M. Billinger for advice and assistance in the development of
aspects of the software used in this paper. This paper only reflects the authors’ views and funding agencies are not liable.
REFERENCES
[1] J. D. Bauby, The Diving Bell and the Butterfly. Paris, France: Éditions
Robert Laffont, 1997.
[2] N. Birbaumer, N. Ghanayim, T. Hinterberger, I. Iversen, B. Kotchoubey,
A. Kübler, J. Perelmouter, E. Taub, and H. Flor, “A spelling device for
the paralysed,” Nature, vol. 98, pp. 297–298, 1999.
[3] T. Matuz, N. Birbaumer, M. Hautzinger, and A. Kübler, “Coping with
amyotrophic lateral sclerosis: An integrative view,” J. Neurology, Neurosurgery Psychiatry, vol. 81, no. 8, pp. 893–898, 2010.
[4] E. Niedermeyer and F. H. Lopes da Silva, Electroencephalography: Basic Principles, Clinical Applications and Related Fields. Baltimore, MD,
USA: William and Wilkins, 1999.
[5] J. R. Wolpaw, N. Birbaumer, D. J. McFarland, G. Pfurtscheller, and T. M.
Vaughan, “Brain-computer interfaces for communication and control,”
Clinical Neurophysiol., vol. 113, no. 6, pp. 767–791, 2002.
[6] R. Scherer, G. R. Müller, C. Neuper, B. Graimann, and G. Pfurtscheller,
“An asynchronously controlled EEG-based virtual keyboard: Improvement of the spelling rate,” IEEE Trans. Biomed. Eng., vol. 51, no. 6,
pp. 979–984, Jun. 2004.
[7] A. Kübler, F. Nijboer, J. Mellinger, T. M. Vaughan, H. Pawelzik,
G. Schalk, D. J. McFarland, N. Birbaumer, and J. R. Wolpaw, “Patients
with ALS can use sensorimotor rhythms to operate a brain-computer interface,” Neurology, vol. 64, no. 10, pp. 1775–1777, 2005.
[8] J. R. Millán, R. Rupp, G. R. Müller-Putz, R. Murray-Smith,
C. Giugliemma, M. Tangermann, C. Vidaurre, F. Cincotti, A. Kübler, R.
Leeb, C. Neuper, K. R. Müller, and D. Mattia, “Combining brain-computer
interfaces and assistive technologies: State-of-the-art and challenges,”
Front. Neurosci., vol. 4, no. 161, 2010. DOI: 10.3389/fnins.2010.00161.

35

[9] A. Kübler, “Brain-computer interfacing: Science fiction has come true,”
Brain, vol. 136, no. 6, pp. 2001–2004, 2013.
[10] L. Naci, M. M. Monti, D. Cruse, A. Kübler, B. Sorger, R. Goebel, B.
Kotchoubey, and A. M. Owen, “Brain-computer interfaces for communication with nonresponsive patients,” Ann. Neurol., vol. 72, no. 3, pp. 312–
323, 2012.
[11] A. R. Murguialday, J. Hill, M. Bensch, S. Martens, S. Halder, F. Nijboer,
B. Schoelkopf, N. Birbaumer, and A. Gharabaghi, “Transition from the
locked in to the completely locked-in state: A physiological analysis,”
Clin. Neurophysiol., vol. 122, no. 5, pp. 925–933, 2011.
[12] J. Höhne, M. Schreuder, B. Blankertz, and M. Tangermann, “A novel
9-class auditory ERP paradigm driving a predictive text entry system,”
Frontiers Neurosci., vol. 5, 2011. DOI: 10.3389/fnins.2011.00099.
[13] M. Schreuder, T. Rost, and M. Tangermann, “Listen, you are writing!
speeding up online spelling with a dynamic auditory BCI,” Frontiers
Neurosci., vol. 5, 2011. DOI: 10.3389/fnins.2011.00112.
[14] S. Veser, A. Markl, and B. Kotchoubey, “Detecting pre-attentive processing in non-responsive patients,” presented at the TOBI Workshop,
Würzburg, Germany, 2012.
[15] R. Näätänen, S. Pakarinen, T. Rinne, and R. Takegata, “The mismatch
negativity (MMN): Towards the optimal paradigm,” Clin. Neurophysiol.,
vol. 115, no. 1, pp. 140–144, 2004.
[16] C. Pokorny, D. Klobassa, G. Pichler, H. Erlbeck, R. Real, A. Kübler,
D. Lesenfants, D. Habbal, Q. Noirhomme, M. Risetti, D. Mattia, and G.
Müller-Putz, “The auditory P300-based single-switch brain-computer interface: Paradigm transition from healthy subjects to minimally conscious
patients,” Artif. Intell. Med., vol. 59, pp. 81–90, 2013.
[17] M. D. Comerchero and J. Polich, “P3a and P3b from typical auditory and
visual stimuli,” Clin. Neurophysiol., vol. 110, no. 1, pp. 24–30, 1999.
[18] M. Salvaris, C. Cinel, L. Citi, and R. Poli, “Novel protocols for P300based brain-computer interfaces,” IEEE Trans. Neural Syst. Rehabil. Eng.,
vol. 20, no. 1, pp. 8–17, Jan. 2012.
[19] L. Acqualagna and B. Blankertz, “Gaze-independent BCI-spelling using
rapid serial visual presentation (RSVP),” Clin. Neurophysiol., vol. 124,
no. 5, pp. 901–908, 2013.
[20] H. Xu, D. Zhang, M. Ouyang, and B. Hong, “Employing an active mental task to enhance the performance of auditory attention-based braincomputer interfaces,” Clin. Neurophysiol., vol. 124, no. 1, pp. 83–90,
2013.
[21] E. V. Friedrich, D. J. McFarland, C. Neuper, T. M. Vaughan, P. Brunner,
and J. R. Wolpaw, “A scanning protocol for a sensorimotor rhythm-based
brain-computer interface,” Biological Psychol., vol. 80, no. 2, pp. 169–
175, 2009.
[22] G. R. Müller-Putz, C. Pokorny, D. S. Klobassa, and P. Horki, “A singleswitch BCI based on passive and imagined movements,” Int. J. Neural
Syst., vol. 23, 1250037, 2013.
[23] A. Delorm and S. Makeig, “EEGLAB: An open source toolbox for analysis
of single-trial EEG dynamics including independent component analysis,”
J. Neurosci. Methods, vol. 134, no. 1, pp. 9–21, 2004.
[24] S. Enghoff, “Moving ICA and time-frequency analysis in event-related
EEG studies of selective attention,” Ph.D. dissertation, Dept. Phys., Technical Univ. Denmark, Kongens Lyngby, Denmark, 1999.
[25] S. Makeig, A. J. Bell, T. P. Jung, and T. J. Sejnowski, “Independent
component analysis of electroencephalographic data,” Adv. Neural Inform.
Process. Syst., vol. 8, pp. 145–151, 1996.
[26] B. W. McMenamin, A. J. Shackman, J. S. Maxwell, D. R. Bachhuber,
A. M. Koppenhaver, L. L. Greischar, and R. J. Davidson, “Validation
of ICA-based myogenic artifact correction for scalp and source-localized
EEG,” Neuroimage, vol. 49, no. 3, pp. 2416–2432, 2010.
[27] J. Müller-Gerking, G. Pfurtscheller, and H. Flyvbjerg, “Designing optimal
spatial filters for single-trial EEG classification in a movement task,” Clin.
Neurophysiol., vol. 110, no. 5, pp. 787–798, 1999.
[28] H. Ramoser, J. Müller-Gerking, and G. Pfurtscheller, “Optimal spatial
filtering of single trial EEG during imagined hand movement,” IEEE
Trans. Rehabil. Eng., vol. 8, no. 4, pp. 441–446, Dec. 2000.
[29] B. Blankertz, G. Dornhege, M. Krauledat, K. R. Müller, and G. Curio,
“The non-invasive Berlin brain-computer interface: Fast acquisition of
effective performance in untrained subjects,” Neuroimage, vol. 37, no. 2,
pp. 539–550, 2007.
[30] B. Graimann, “Movement-related patterns in ECoG and EEG: Visualization and detection,” Ph.D. dissertation, Faculty Electr. Inf. Eng., Institut für
Human-Computer Interfaces, Graz Univ. Technol., Graz, Austria, 2002.
[31] U. Hoffmann, J. M. Vesin, T. Ebrahimi, and K. Diserens, “An efficient
P300-based brain-computer interface for disabled subjects,” J. Neurosci.
Methods, vol. 167, no. 1, pp. 115–125, 2008.

36

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 1, JANUARY 2015

[32] G. R. Müller-Putz, R. Scherer, C. Brunner, R. Leeb, and G. Pfurtscheller,
“Better than random? A closer look on BCI results,” Int. J. Bioelectromagnetism,” vol. 10, no. 1, pp. 52–55, 2008.
[33] L. Munka, and S. Berti, “Examining task-dependencies of different attentional processes as reflected in the P3a and reorienting negativity components of the human event-related brain potential,” Neurosci. Lett., vol.
396, no. 3, pp. 177–181, 2006.
[34] E. V. Friedrich, R. Scherer, and C. Neuper, “The effect of distinct mental
strategies on classification performance for brain-computer interfaces,”
Int. J. Psychophysiol., vol. 84, no. 1, pp. 86–94, 2012.
[35] I. Daly, M. Billinger, J. Laparra-Hernández, F. Aloise, M. L. Garcı́a,
J. Faller, R. Scherer, G. Müller-Putz, “On the control of brain-computer
interfaces by users with cerebral palsy,” Clin. Neurophysiol., vol. 124,
no. 9, pp. 1787–1797, 2013.
[36] J. Faller, C. Vidaurre, E. V. C. Friedrich, U. Costa, and E. Opisso, “Automatic adaptation to oscillatory EEG activity in spinal cord injury and
stroke patients,” presented at the TOBI Workshop, Würzburg, Germany,
2012.
[37] A. M. Owen, M. R. Coleman, M. Boly, M. H. Davis, S. Laureys, and J. D.
Pickard, “Detecting awareness in the vegetative state,” Science, vol. 313,
no. 5792, p. 1402, 2006.
[38] M. M. Monti, A. Vanhaudenhuyse, M. R. Coleman, M. Boly, J. D. Pickard,
L. Tshibanda, A. M. Owen, and S. Laureys, “Willful modulation of brain
activity in disorders of consciousness,” New England J. Med., vol. 362,
no. 7, pp. 579–589, 2010.
[39] L. Naci, R. Cusack, V. Z. Jia, and A. M. Owen, “The brain’s silent messenger: Using selective attention to decode human thought for brain-based
communication,” J. Neurosci., vol. 33, no. 22, pp. 9385–9393, 2013.

Petar Horki received the B.Sc. and M.Sc. degrees in telematics from the Graz
University of Technology, Graz, Austria, where he is currently working toward
the Ph.D. degree.
He is a Member of the Laboratory for Brain-Computer Interfaces (BCI-Lab),
Graz University of Technology since 2009.

Daniela S. Klobassa received the M.Sc. degree in psychology from the Karl
Franzens University of Graz, Graz, Austria, and the M.D. degree from the Medical University of Graz, Graz, Austria.
She was a Research Associate at the Laboratory for Brain-Computer Interfaces (BCI-Lab), Graz University of Technology and is now Research Associate
at the Department of Pediatrics, Medical University of Graz.

Christoph Pokorny received the B.Sc. and M.Sc. degrees in telematics in
2006 and 2009, respectively, from the Graz University of Technology, Graz,
Austria, where he is currently working toward the Ph.D. degree at the Institute
for Knowledge Discovery.
His research interests include signal processing, electrical engineering and
brain–computer interfaces (BCIs) for nonresponsive patients.

Gernot R. Müller-Putz (M’13) received the Ph.D. degree in electrical engineering from Graz University of Technology, Graz, Austria, in 1994.
In 2000, he worked on noninvasive electroencephalogram-based (EEG)
brain–computer interfacing (BCI) for the control of neuroprosthetic devices
at Graz University of Technology. He is currently the Head of the Institute for
Knowledge Discovery, Graz University of Technology. He is also the Head of
the Laboratory for Brain-Computer Interfaces (BCI-Lab) at Graz University of
Technology. In 2008, he received the “venia docendi” for medical informatics at
the Faculty of Computer Science, Graz University of Technology. His research
interests include EEG-based neuroprosthesis control, hybrid BCI systems, the
human somatosensory system, and assistive technology.

