IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 5, SEPTEMBER 2015

1757

Prediction of Heart Failure Decompensation Events
by Trend Analysis of Telemonitoring Data
J. Henriques, P. Carvalho, S. Paredes, T. Rocha, J. Habetha, M. Antunes, and J. Morais

Abstract—This paper aims to assess the predictive value of physiological data daily collected in a telemonitoring study in the early
detection of heart failure (HF) decompensation events. The main
hypothesis is that physiological time series with similar progression
(trends) may have prognostic value in future clinical states (decompensation or normal condition). The strategy is composed of two
main steps: a trend similarity analysis and a predictive procedure.
The similarity scheme combines the Haar wavelet decomposition,
in which signals are represented as linear combinations of a set
of orthogonal bases, with the Karhunen–Loève transform, that
allows the selection of the reduced set of bases that capture the
fundamental behavior of the time series. The prediction process
assumes that future evolution of current condition can be inferred
from the progression of past physiological time series. Therefore,
founded on the trend similarity measure, a set of time series presenting a progression similar to the current condition is identified
in the historical dataset, which is then employed, through a nearest neighbor approach, in the current prediction. The strategy is
evaluated using physiological data resulting from the myHeart telemonitoring study, namely blood pressure, respiration rate, heart
rate, and body weight collected from 41 patients (15 decompensation events and 26 normal conditions). The obtained results suggest,
in general, that the physiological data have predictive value, and
in particular, that the proposed scheme is particularly appropriate
to address the early detection of HF decompensation.
Index Terms—Haar wavelet, heart failure (HF) decompensation,
telemonitoring, time-series prediction, trend analysis.

I. INTRODUCTION
PPROXIMATELY 45% of all deaths in Europe are due to
cardiovascular disease (CVD) and more than 20% of all
European citizens suffer from a chronic CVD, such as myocardial infarction, arrhythmias, and congestive heart failure (HF)
[1]. Among these, HF has become a major public health concern
and the cause of considerable morbidity and mortality [2]. In

A

Manuscript received June 23, 2014; revised August 19, 2014; accepted
September 10, 2014. Date of publication September 17, 2014; date of current version September 1, 2015. This work was supported in part by FP7
European project myHeart - IST-2002-507816 and iCIS (CENTRO-07-ST24FEDER-002003).
J. Henriques and P. Carvalho are with Departamento de Engenharia Informática, Universidade de Coimbra, Coimbra 3030-290, Portugal (e-mail: jh@
dei.uc.pt; carvalho@dei.uc.pt).
S. Paredes and T. Rocha are with the Departamento de Engenharia Informática
e de Sistemas, Instituto Politécnico de Coimbra, Coimbra 3045-601, Portugal
(e-mail: sparedes@isec.pt; teresa@isec.pt).
J. Habetha is with the Philips Research Laboratories, Eindhoven 5656 AE,
The Netherlands (e-mail: joerg.habethag@philips.com).
M. Antunes is with Centro de Cirurgia Cardio Toracica, Centro Hospitalar e Universitário de Coimbra, Coimbra 3000-075, Portugal (e-mail: antunes.
cct.chuc@sapo.pt).
J. Morais is with the Serviço de Cardiologia, Centro Hospitalar Leiria Pombal,
Leiria 2410-197, Portugal (e-mail: joaomorais@hsaleiria.min-saude.pt).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2358715

fact, HF is a growing epidemic for which, despite clinical advances, mortality rates continues to be high.
The progression of chronic HF originates recurrent hospitalizations (acute decompensation events), and even though the
symptoms are reduced, the patient’s cardiac function continually
deteriorates [3]. Although the development of new therapeutic
approaches can prolong life and shorten hospital stay [4], these
patients will require rehospitalization and have, unfortunately,
a poor prognosis [5]. Approximately 20–30% patients are readmitted after 30 days and nearly 50% are readmitted within the
next six months. Moreover, with the aging of the population,
this tendency will continue to increase [5]. As a consequence,
understanding the HF epidemiology [6] and the identification of
the key risk factors and their significance and association with
the outcomes is of major importance.
A. Telemonitoring Systems
The use of preventive solutions based on telemonitoring services, enabling professionals to continuously access and evaluates symptoms and status progression, offers a huge potential in the context of HF management. Basically, telemonitoring involves the transfer of physiological data and symptoms
from patients at home (anytime and anywhere) to health-care
providers. This allows more frequent assessment of a patient’s
HF status and earlier recognition of hemodynamic deterioration than would be possible in common clinical practice. In
effect, remote monitoring allows professionals to play a proactive role in daily care by implementing more effective and
personalized therapies. Theoretically, the adjustment of treatments and actions prior to the development of symptoms or
decompensation can be potentially applied, thus preventing
hospitalizations.
Telemonitoring effectiveness has been evaluated in several
studies, involving measurement of symptoms and physiological
data by means of portable and/or wearable and nonintrusive devices (such as weight, blood pressure, electrocardiogram, and
bioimpedance). The starting point is that, among patients recently discharged after an admission for HF, telemonitoring
will contribute to decrease the number of rehospitalization over
a specified period of time. Although some studies have shown
contradictory results, i.e., telemonitoring is not helpful in reducing cardiac events and rehospitalizations, [7], [8] recent trials
and metaanalyses have suggested that telemonitoring support
may provide better clinical outcomes than usual care, with a
reduction in mortality and hospital admissions [9], [10]. In the
same context, other studies have confirmed that both HF hospitalization and all-cause mortality are positively affected by
telemonitoring [11]–[13].

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

1758

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 5, SEPTEMBER 2015

B. Prediction of HF Decompensation
The main assumption for using telemonitoring systems in
prediction of early decompensation is that patient’s status progression can be reflected on the physiological data continuously
collected by such systems. Physiological indicators of the development of decompensation include, among others, changes
in filling pressures, in the body weight, in the heart rate, and the
presence of arrhythmias [14].
Several studies have observed an increase in the body weight,
associated with an increase in body fluids, before the development of an acute decompensation HF event [15]. However,
while HF guidelines recommend body weight gain as a way to
monitor the progression of decompensation, they also recognize
its strong limitations, such as poor sensitivity [16].
Changes in pressures are also a physiological marker that is
often used to assess the worsening of HF. In effect, blood pressure variations are an indicator as well as a cause of decompensation [14]. In particular, high blood pressure (hypertension)
is among the top most factors associated with cardiovascular
diseases, which can lead to the development of myocardial infarction and HF, among others.
Heart rate variability and intrathoracic impedance are other
means of monitoring hemodynamic changes [17]. Intrathoracic
impedance has shown a high potential to assess daily changes in
fluid status and pulmonary volume. In a recent study intrathoracic impedance has been correlated with pulmonary artery diastolic pressures [18] and with serum NT-proBNP concentrations
(a prohormone valuable in the diagnosis of HF). On the other
hand, it was noted that some parameters extracted with the heart
rate variability were persistently lower in the patients who were
hospitalized or died [19]. Applied to a retrospective dataset, the
same parameters have suggested a sensitivity value for detecting
hospitalization near to 70%.
A recent study has employed a combination of several physiological parameters, namely arrhythmias computed from the
ECG, in the identification of patients at higher risk of subsequent
HF hospitalization [20]. An algorithm based on parameters extracted from the ECG together with fluid index, activity, and
heart rate variability parameters have shown capability to discriminate between patients who had a negative diagnosis from
those with increased risk of HF hospitalization.

C. Similarity and Trend Analysis
The main hypothesis assumed here is that hemodynamic
changes, able to characterize the occurrence of a given event,
can be captured by variations of biosignals evolution (trends).
Thus, supported on several studies that have confirmed the potential of individual physiological data, this study combines
simultaneously a set of physiological signals in a global prediction scheme. It should be noted that the real goal is not to
prove, through an exhaustive validation, the performance and
superiority of the predictor. The major goal consists in showing
the potential of trends analysis (extracted from physiological
signals) in the early detection of HF. Besides this, the dataset
used in this study has a reduced number of events (15 HF

decompensation and 26 normal conditions), thus impairing a
significant validation.
This study focuses on signals that have clinical potential
value, and at the same time, are available in the myHeart dataset
(used in the validation of the present strategy). Moreover, an
additional restriction was considered: the biosignals should be
easily collected in a nonintrusive form, on a daily basis. As a
result the heart rate, respiration rate, body weight, and blood
pressure are employed. Due to the aforementioned constraints,
ECG and intrathoracic impedance were not considered in
this study.
From the research and methodological perspectives two major
issues are addressed: 1) how different variations (trends) can be
captured and compared and 2) how these variations can be used
in the prediction process (decompensation or normal condition).
In terms of the variation assessment, the objective is to estimate significant clinical trends, based on current physiological measurements. Although there is no consistent accepted
definition for trend, it is usually regarded as a nonrandom (deterministic) smooth function representing short-term/long-term
movement or systematic variations in a time series. In the clinical field, a trend can be defined as a consistent, unidirectional
change in the value of a variable (biosignal), thus related with
patient’s status evolution.
There are available many methods for trend extraction, which
differ in their complexity and interpretability, as well as in the
methodologies they use [21]. Given their characteristics, the
application of wavelets has been recognized as an adequate tool
for time-series analysis, and in particular, for trend extraction.
In effect, using the wavelet transform, two types of coefficients
are obtained, namely wavelet and scaling coefficients [22]. The
first are related to changes in averages over specific scales,
whereas scaling coefficients are associated with averages on a
specified scale. Since the scale that is associated with scaling
coefficients is usually rather large, the information captured by
these coefficients agrees with the notion of trend. Thus, the key
idea behind trend analysis using wavelets that is used in this
study explores the association of the scaling coefficients with
the trend.
The assessment of similarity between time series is a central concept in knowledge discovery and generally consists of
evaluating the similitude between two different time series.
Two main groups of algorithms can be identified: time domain
and transform-based methods. The former work directly with
the raw signals (eventually with some preprocessing) and the
main goal is to derive a measure (scalar) based on the comparison of the original time series. Euclidean distance for signals with the same length and dynamic time warping technique
for signals with different lengths, are well-known examples of
such algorithms [23], [24]. Due to the high dimensionality of
time series, most of the approaches perform dimension reduction on original data (transformed-based methods). This second
group includes, among others, discrete Fourier transform [25]
and singular value decomposition [26]. Other authors used the
principal component analysis (or Karhunen–Loève transform)
[25], while others applied methods based on discrete wavelet
transform [27].

HENRIQUES et al.: PREDICTION OF HEART FAILURE DECOMPENSATION EVENTS BY TREND ANALYSIS OF TELEMONITORING DATA

In the context of this study, the time–frequency analysis methods included in the second group of algorithms assume a particular interest. The transformation of a signal from 1-D time
domain to 2-D time–frequency domain can reveal more details,
and thus, helps to characterize it [28], [29]. This transform produces features that describe properties of the time series both
at various locations and at numerous time granularities (detail
levels), which is particularly important when dealing with the
trend similarity assessment problem. In particular, the specific
Haar wavelet was used in the proposed trend similarity search
scheme. A major drawback that has been pointed to the Haar
wavelet relates with the bases functions that are not smooth, that
is, are not continuously differentiable. As a result, this wavelet
approximates any signal by a ladder-like structure that may not
be adequate for smooth functions. However, in the particular
case of this study, the final goal is to identify the main characteristics of the signal, that is, the main trends or behavior (possibly
in some specific time regions). Thus, this inconvenience is not
significant in the present context.
D. Proposed Work
The major goal of this study is to assess the predictive value
of telemonitoring physiological data, collected in a daily basis
in the HF decompensation. Given their clinical potential four
signals will be employed: body weight, respiration rate, heart
rate, and blood pressure. The proposed solution does not assume
any particular scenario (type of patients, clinical therapies, etc).
Although these variables were used, the strategy is perfectly
feasible in case a subset of these physiological variables is employed or even using a different set of variables.
The methodology is based on a trend similarity measure, followed by a predictive procedure. The similarity scheme combines the Haar wavelet decomposition, in which signals are
represented as linear combinations of a set of orthogonal bases,
with the Karhunen–Loève transform (KLT), which allows for
the optimal reduction of that set of bases. The trend similarity
measure is then indirectly calculated by means of the coefficients obtained in both time-series description. The prediction
strategy assumes that trends of physiological data common to
patients with similar disease progression may have prognostic
value in the prediction process. Therefore, using an approach
similar to the k-nearest neighbor (k − N N ), an estimation of
the biosignal’s future values is performed, supported on a set of
similar time series previously identified in the historical dataset.
The structure of this study is as follows: Section II introduces the trend similarity measure and the prediction scheme.
Section III presents and discusses HF decompensation results
using data collected during the myHeart telemonitoring study.
Finally, in Section IV, some conclusions are drawn.
II. METHODS
A. Global Scheme
The concept behind the prediction approach is illustrated
in Fig. 1. The current telemonitoring data X(t) (biosignals
daily collected) is used in the prediction of HF decompensation

Fig. 1.

1759

Proposed approach for the prediction of decompensation events.

events, supported on the historical dataset. The process starts
by defining the historic patterns Pi that describe the dynamic of
the clinical events to be detected. These patterns can be knowledge driven, based on clinical evidence, through the definition
of specific behaviors (such as trends, offsets and sudden variations). Alternatively, data-driven approaches can be applied in
a knowledge extraction procedure: through a pattern discovery
process, clustering techniques can be employed, grouping data
into subclasses that reflects similar patterns (decompensation or
normal condition).
In this study, data resulting from the myHeart telemonitoring study [30] was employed. The records are composed of
biosignals collected on a daily basis, in particular, before the
occurrence of one event, together with its prediction (decompensation HF and normal condition). As a consequence, the
patterns, i.e., the trend evolution of biosignals that leads to a
decompensation event can be straightforwardly obtained from
the biosignals that precede such event.
It is assumed that the specific patient’s condition is represented by the biosignals collected before the event, designated
here as template X(t) ∈ Rn ,N , where n is the number of signals
and N the time duration (days). Using this template and from
a trend similarity analysis procedure, the most M similar conditions (patterns) are identified in the historical dataset. From
these, the corresponding subsequent existence of a decompensation event can be directly obtained (known past values from
historical dataset), and used in a prediction mechanism to estimate the evolution of the current template (decompensation or
normal condition).
B. Trend Similarity Measure
The proposed methodology for evaluating the trend similarity between two physiological time series combines the Haar
wavelet decomposition, in which signals are represented as linear combinations of a set of orthogonal bases, with the KLT,
that allows for the optimal reduction of that set of bases. This
strategy involves several steps, as illustrated in Fig. 2.
The key idea of the scheme is to apply the discrete Haar
wavelet for the description of the current template X(t). Based
on the localization property of the wavelet bases, and using
a reducing operation, the bases that significantly reflect the
dynamical patterns of the template are chosen. The coefficients used to describe the signal and the template as linear

1760

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 5, SEPTEMBER 2015

During this process a parameter has to be predefined, ε ∈ R+ ,
that specifies the accuracy of the approximation. In effect, the
number of bases (J) considered in the reducing process, is
determined such that the L2 norm error, (3), is minimized.



 
(3)
 < ε.
X(t) − X(t)
2

Step 4 (Signal Description): The signal Y (t) ∈ R1,N , to be
compared with the template X(t), is initially described as a
linear combination of the basis functions ϕj (t), used in the
description of the template.
Fig. 2.

Scheme for the trend similarity evaluation.

Y (t) =

J


αj ϕj (t).

(4)

j =1

combinations of such reduced bases are then used to assess the
trend similarity between the template and the signal.
1) Main Steps: Six steps are identified in this process. Moreover, in order to simplify the description and without loss of
generality, the signal is assumed to be univariate, i.e., n = 1.
Step 1 (Vertical shift removal): To eliminate vertical offsets,
the template signal X(t) is first modified as X(t) = X(t) − X,
where X is the mean value of the template X(t).
Step 2 (Wavelet decomposition of the template): In a second step, a discrete wavelet transform process is applied to
the template signal X(t), which is decomposed in terms of an
approximation of the original sequence, plus a set of details.
Considering that the length of the signal is N , the original signal can be represented by means of (1), the set of N bases
functions ϕj (t) ∈ R1,N .
X(t) =

N


ϕj (t).

(1)

j =1

J

j =1

αj =

< Y (t), ϕj (t) >
.
< ϕj (t), ϕj (t) >

(5)

Step 5 (Similarity measure): Based on coefficients’ distance:
The proposed similarity measure is indirectly computed from
the coefficients of the reduced set of wavelet bases. In particular, the proposed similarity measure between template X(t)
and the signal Y (t) is based on the distance between the two
vectors of coefficients Γ = [1, . . . , 1] and Ω = [α1 , . . . , αJ ],
D (X(t), Y (t))  DE (Γ, Ω). Although several types of distances could be used, the Euclidean distance is used here, as
given by the following equation:

 J

D(X(t), Y (t))  DE (Γ, Ω) = 
(1 − αj )2 .
(6)
j =1

The basis functions ϕj (t) are orthogonal and incorporate
the coefficients dj ∈ R such that, ϕj (t) = dj ψa,b (t), being
ψa,b (t) ∈ R1,N a specific Haar wavelet basis.
Step 3 (Optimal bases reduction): When using a wavelet
transform, the reduction of the original set of bases is typically determined by the level of decomposition. Several studies
have been conducted to determine the optimal level of decomposition, mainly based on energy and/or entropy concepts. Here,
the level of decomposition in the wavelet transform procedure
is converted into the selection of the wavelets bases that allows
a given level of accuracy in the representation of the signal.
Moreover, using this approach, a lower dimensional space is
obtained, preserving the main properties (trends) of the original
time series.
Therefore, in order to reduce the number of wavelet bases,
the KLT is applied. The KLT basis functions are obtained as
the eigenvectors (also known as principal components) of the
covariance matrix composed of the wavelet bases. The best
approximation (in terms of L2 norm error) of the signal X(t) is
achieved considering the bases corresponding to the first highest
J eigenvalues of the covariance matrix

X(t)
=

Since the bases are orthogonal, the coefficients αj ∈ R always exist and are given by the following equation, where the
operator < a, b > is the dot product.

ϕj (t).

(2)

This distance is straightforwardly converted to a similarity
measure (SΩ ), such that SΩ ∈ [0. .1], according to the following
equation:
SΩ (X(t), Y (t)) = e−D E (Γ,Ω) .

(7)

Step 6 (Trend similarity measure): Based on coefficients’
signs: Furthermore, as previously mentioned, the main goal is
to compare the evolution of two specific signal (trends). Thus,
by using the sign of the coefficients αj , i.e., sign(αj ) a simple
and efficient similarity strategy can be implemented. In fact,
one of the advantages of the similarity measure based on coefficients’ signs is its interpretability. Regardless of its exact value,
a positive value for the coefficients obtained in (4), (αj > 0),
reveals that signal and template present the same behavior, i.e.,
the same evolution (or trend) corresponding to the respective
basis ϕj (t). In case of a negative value (αj < 0), it means that
the signal and template have opposite trends (with respect to
the basis ϕj (t)). Therefore, a straightforward similarity measure can be established by taking into consideration the signs of
the coefficients. As a result, the trend measure proposed here,
(ST ), is described by the following equation, where nps stands
for number of positive signs.
ST (X(t), Y (t))  ST (Γ, Ω) =

nps (Ω)
.
J

(8)

HENRIQUES et al.: PREDICTION OF HEART FAILURE DECOMPENSATION EVENTS BY TREND ANALYSIS OF TELEMONITORING DATA

If all coefficients (αj , j = 1, . . . , J), have positive signs,
it means that the template and the signal present the same
trend. Thus the nps(Ω) = J and the trend similarity measure
ST (Γ, Ω) = 1. In an opposite situation, if all coefficients have
negative signs, the signal presents a completely opposite trend.
In this case, ST (Γ, Ω) = 0, since nps(Ω) = 0. For an intermediary case, nps(Ω) ∈ [0 . . . J], the similarity measure ST (Γ, Ω)is
in range[0. .1].
It should be noted that using this strategy the range of possible
values for the similarity measure is limited to a predefined set.
In effect, this range determines the number of distinct values,
given by (J + 1). As an example, for J = 4, the number of
possible similarity measures is 5 = J + 1, determined by all
possible number of positive signs, {0, 1, 2, 3, 4}.
2) Multivariable Trend Similarity: Although the trend similarity measure was derived for an univariate scenario (n = 1),
it can be easily extended to a multivariable case (n > 1). If the
number of time series (biosignals) is higher than 1, the trend
similarity between two biosignals composed of n time series
X(t) ∈ Rn ,N and Y(t) ∈ Rn ,N , can be computed assuming a
combination of the individual similarity between signals Xi (t)
and Yi (t). In the simplest case the multivariable similarity and
the trend similarity, respectively, (7) and (8), can be considered as the average of the individual trends, as given by (9)
and (10).
SΩ (X, Y) 

1
SΩ (Xi (t), Yi (t))
n i=1

ST (X, Y) 

1  nps (Ωi )
.
n i=1
J

n

(9)

n

(10)

where Ωi ∈ R1,J i = 1, . . . , n identifies the coefficients that
result from the description of the signal Yi (t), (4), using the
bases that describe the signal Xi (t), (2).
3) Illustrative Example: The following two examples illustrate this trend similarity idea. In both examples, a template X(t)
is considered, as depicted in Fig. 3, approximately described as

X(t)
=

3


ϕj (t) = 2.69ψ1,1 (t) + 1.75ψ0,0 + 1.49ψ2,3 (t).

Fig. 3. Signal approximation using the Haar WaveletKLT decomposition
scheme. (a) Actual signal and approximation (dashed line). (b) Specific wavelet
bases used in the approximation.

ε, and thus, the number of bases), it should be noted that this is
not the main focus of the proposed scheme. Effectively, the final
goal is to identify the main characteristics of the signal, that is,
the main trends or behavior.
In this particular case, the most important basis is ϕ1 (t) =
2.69ψ1,1 (largest coefficient). This means that the highest variation in the signal occurs between the instants [33, 64], as can be
confirmed by inspecting Fig. 3(a). Moreover, the second basis,
ϕ2 (t) = 1.75ψ0,0 , is the one that reflects the contribution of the
complete signal. Since the coefficient has a positive value, it can
be concluded that the signal presents a global positive variation,
that is, the mean of the first half, instants [1, 32], is higher than
the mean of the second half, instants [33, 64]. Finally, a similar
conclusion can be drawn for the third basis, ϕ3 (t) = 1.49ψ2,3 .
In fact, in the corresponding time region, instants [49, 64], the
signal presents a significant variation from a higher to a lower
value, and thus, the coefficient has a positive sign.
The first signal to be compared, Y1 (t), is described as (12)
and shown in Fig. 4. In the second, Fig. 5, the same template,
X(t), is compared with the signal Y2 (t), described as (13).
Y1 (t) =

j =1

3


αj ϕj (t) = 0.29ϕ1 (t) + 0.42ϕ2 (t) + 0.49ϕ3 (t)

j =1

(11)
The bases ψa,b (t) are particular Haar wavelet basis functions, corresponding to specific details and approximations. Using this Haar wavelet decomposition and establishing a predefined level of precision (threshold ε), an optimal bases reduction
is achieved. In this particular case, setting ε = 0.90 (roughly
meaning that the signal should be approximated with a level
of confidence of 90%), three bases were obtained considering
the previously presented procedure, (11). These bases are not
determined based on a specific level of decomposition, but are
chosen as those that best represent the signal (in terms of the L2
norm approximation error) among all decomposition levels.
As can be seen in Fig. 3, the main characteristics of the signal
are captured using only three bases. Although it is possible to
obtain small approximation errors (by increasing the threshold

1761

(12)
Y2 (t) =

3


αj ϕj (t) = −0.93ϕ1 (t) − 0.49ϕ2 (t) + 0.21ϕ3 (t).

j =1

(13)
In the first case, all the coefficients αj (j = 1, 2, 3) are positive, thus having the same sign as the coefficients of the template
(all equal to 1). From this simple statement, it can be concluded
that template and signal present the same behavior, i.e., the
same temporal trend (as can be observed in Fig. 4(a). As result
the similarity measure, defined as (8), is ST (Γ, Ω) = 1. In the
second example, it is observed that the first two coefficients are
negative and the third is positive. Thus, it may be concluded

1762

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 5, SEPTEMBER 2015

Fig. 6.

Fig. 4. Comparision of the two signals. (a) Signals to be compared, (b) first
basis, (c) second basis, and (d) third basis.

Fig. 5. Comparision of the two signals. (a) Signals to be compared, (b) first
basis, (c) second basis, and (d) third basis.

that, in global terms, they do not present the same behavior (this
can be observed for some intervals of the signal in Fig. 5(a).
The similarity measure is in this case ST (Γ, Ω) = 1/3.
In conclusion, the key principle is that two signals are similar
if they present the same behavior (trend), or in other words, if
their coefficients have the same sign.
C. Prediction Strategy
Basically, the prediction strategy is inspired in a case-based
reasoning principle. The main hypothesis is that the “future”
evolution of similar conditions, with the current template X(t),
can be used in the prediction of the current condition. Fig. 6 illus-

Scheme proposed for the prediction of decompensation events.

trates the idea behind the proposed prediction approach. From
the trend similarity analysis process,the set of the M
	 most
similar conditions (patterns) X(t) ≡ Xm (t) ∈ Rn ,N , m =
1, . . . , M are identified. From these, the occurrence of a subsequent decompensation/normal event can be recognized (known
values from historical dataset). Then, the known “future” evolution Z(t) ≡ {Zm (t)} , m = 1, . . . , M , with Zm (t) = {1, 0}
(decompensation or normal condition, respectively) used in a
prediction mechanism to estimate the evolution of the current
template, Z(t).
The prediction mechanism implemented here assumes that
a new prediction is computed by a majority vote scheme of
the M predictions, being assigned to the class most common
among the M patterns. This is equivalent to the (k − N N ), one
of the simplest machine learning algorithms. In effect, if the
number of patterns (M ) is equal to the number of neighbors
(k) and the distance between the cases are computed through
the proposed similarity measure, the methods are equivalent. In
the simplest case, if k = M = 1, the HF prediction is simply
obtained considering the pattern that presents the highest similarity measure (the nearest neighbor). However, this methodology presents some drawbacks. Since trend similarity values are
restricted to a finite set of values (number of positive signs), (8),
the probability that several patterns present the same similarity
measure is considerable (which is particularly true when J is
low). Hence, a modification of the (k − N N ) is proposed here:
together with the M -nearest patterns, the method also takes into
account the similarity measure of such patterns. Thus the prediction, i.e., the decision between decompensation and normal
condition is given by the following equation:


 mD
mN
 ST i 
ST i
,
with (mD + mN = M ).
Z(t) = max
mD i=1 mN
i=1
(14)
The decision is taken by computing the maximum between
the averages of the similarity measures (ST i ) corresponding to
the subset of the M patterns that will evolve to a decompensation
event (mD), and the similarities corresponding to those that will
evolve to a normal condition (mN ). In case of mD = 0, i.e., no
decompensations events, the prediction is directly obtained as
Z(t) = 0, i.e., normal condition (a similar conclusion is valid

HENRIQUES et al.: PREDICTION OF HEART FAILURE DECOMPENSATION EVENTS BY TREND ANALYSIS OF TELEMONITORING DATA

Fig. 7.

Prediction using a nearest neighbor approach for k = M = 1, 3, 4.

for mN = 0). Fig. 7 illustrates the process of computing the
prediction for k = M = 1, 3, 4.
Although the k = 4 circumstance can leads to a draw, the decision considers the comparison (maximum value) between the
means of the similarities corresponding to the decompensation
events (ST 1 and ST 4 ) and that corresponding to the normal conditions (ST 2 and ST 3 ). This can be obtained as follows directly
from (14):


ST 1 + ST 4 ST 2 + ST 3
,
Z(t) = max
.
(15)
2
2
D. Evaluation Methods
Regarding the validation strategy, a leave-one-out crossvalidation approach was followed. Cross validation is a statistical method for evaluating the models performance by dividing
the available data into two types of partitions: 1) training data
partitions, used for generating the model and 2) testing data partitions, used for validating the resulting models. In this particular
case, the scarcity of the dataset (only 16 decompensations in a
total of 41 events) has justified the option for a single sample in
each partition (leave-one-out cross validation) [31]. Moreover, it
is important to note that the prediction scheme does not require
the computation of an explicit model (such as a regressive one
or a machine learning classifier). In effect, what is involved is a
trend similarity analysis followed by a nearest neighbor process:
Each case is compared with all the others (through a similarity
measure), being the most similar neighbors used directly in the
prediction process.
III. RESULTS
A. myHeart Telemonitoring Study
The myHeart vision (FP7-IST-2002–507816) is a home telemonitoring system aimed at the supervision of HF patients,
enabling intervention when appropriate. This is done by monitoring physiological body signs with wearable technology,
processing the measured data and giving recommendations to
the patient and professional users of the system. Using the
measured data to give user feedback, the system “closes the
loop” of measurement and therapy [30].

1763

This system was used in a clinical observational study carried
out with 148 patients from six clinical centers in Germany and
Spain. The trial had an enrolment phase of 9 months with 12
months of patient follow up. During the clinical study, patients
were requested to daily measure (during the morning period
approximately at the same hour), weight, blood pressure, and,
using a vest, the heart rate, and bioimpedance. Also the heart
rate, respiration rate, and activity were monitored during the
night by means of a bed sensor. Moreover, they were requested
to complete two questionnaires of symptoms and mood/general
well-being each day. From the 148 patients recruited, 102
(69%) were considered analyzable, that is, with more than
30 days of telemonitoring measurements. Additionally, HF related events were recorded. Six cardiologists have analyzed the
data, identifying which patients had experienced a decompensation event requiring hospitalization (16 patients) and which patients had not (25 patients). The included patients were in NYHA
class II, predominantly male (70%) and over 60 years old
(63.8 ± 12 years old).
In this study, considering the restriction described in
Section I-D, four biosignals are used in the prediction strategy: body weight (BW), blood pressure (BP), respiration rate
(RR), and heart rate (HR). These variables, daily collected, were
preprocessed, namely through noise-reduction: removing of outliers and linear interpolation techniques to deal with some missing values. In practice, the prediction strategy works by means
of a sliding window scheme. In effect, the daily current measurements, together with the ones performed in the previous
days, are used to update the evolution of the trends, which are
then compared with the historical dataset to support the prediction mechanism. Since the strategy is reevaluated every day, a
sliding window scheme is, in practice, employed.
B. Evaluation Metrics
In order to assess the performance of the prediction scheme,
the sensitivity or recall (SE) and the specificity (SP), are usually
considered. Although there are cases where it is important to
favor one in detriment of the other, in general, it is important
to balance between the two. Several alternatives can be used,
namely the Fmeasure and the geometric mean (Gmean), respectively, (16) and (17), that are used in this study.
2 × TP
2 × TP + FP + FN
√
= SE × SP.

Fm easure =

(16)

Gm ean

(17)

In the aforementioned equations, TP (true positives) represents the annotated decompensation events in the historical
database that were identified by the prediction algorithm, FN
(false negatives) corresponds to the annotated decompensation
events that were not detected, TN (true negatives) corresponds to
events that were not annotated in the database and were correctly
identified, and finally, FP (false positives) denotes the number of
decompensation events that were not annotated in the database,
but that were incorrectly identified by the prediction scheme.

1764

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 5, SEPTEMBER 2015

TABLE I
PREDICTIVE VALUE OF INDIVIDUAL VARIABLES

C. Comparison With Other Similarity Measures
To compare the performance of the proposed strategy, two
other well-known methods for time-series similarity were employed: linear correlation and Euclidean distance. Given two
discrete time series of length N, X(t) = {x(1), . . . , x(N )} and
Y (t) = {y(1), . . . , y(N )}, the linear correlation coefficient,
SC ∈ R, sometimes referred as Pearson’s correlation coefficient, evaluates the strength of a linear relationship between
them. It is computed by (18), where X and Y are, respectively,
the mean values of time series X(t) and Y (t).
N
t=1 (x(t) − X)(y(t) − Y)

.
SC (X(t), Y (t)) = 
N
N
2
2
(x(t)
−
X)
(y(t)
−
Y)
t=1
t=1
(18)
This correlation value (SC ) is a number in the range [−1, 1].
In case of SC = +1, a perfect positive linear relationship (correlation) occurs; in case of SC = −1, a perfect negative linear
relationship (anticorrelation) occurs; in case of SC = 0 (zero),
there is no correlation (uncorrelated). The Euclidean distance,
DE ∈ R+
0 , is defined as

N

DE ( X(t), Y (t) ) = 
(x(t) − y(t))2 .
(19)
t=1

To obtain a similarity measure in the range SE ∈ [0 . . . 1], the
DE is transformed by means of the following equation, similarly
as (7):
−D E (X (t),Y (t))

SE = e

.

(20)

For the multivariable case, a global similarity measure was
obtained from the average of the individual similarities, (18)
and (20), analogous to (9) and (10).
D. Parameters and Experimental Setup
In the prediction scheme, the following three parameters have
to be specified.
N : The duration of the template, i.e., the number of days
considered relevant before the occurrence of an event—(1).
ε: The threshold that specifies the approximation error—(3).
This threshold indirectly determines the number of wavelet
bases (J)—(2).
M : The number of patterns (or neighbors) considered in the
prediction mechanism—(14).
With respect to the choice of the number of days before an
event N, the well-known rule-of-thumb method in the diagnosis of worsening HF states that an increase in the body weight
of 1.36 kg in one day and 2.27 kg in three days is an appropriate threshold for generating alarms [15]. Moreover, several
studies have evaluated the time period of changes that is relevant in physiological parameters, preceding a decompensation
event. These results can be summarized as follows [17], [32]:
1) dyspnoea and oedema: 6 to 12 days [33]; 2) weight gain:
7 to 11 days, [34], [35]; 3) intrathoracic impedance: approximately 15 days, [36]; 4) heart rate variability: approximately
16 days, [37]; and 5) hemodynamic monitor: 4 to 7 days [38]. As
consequence, three values were considered here: N = 4, 8, 16.

BW
BP
HR
RR

SE

SP

Gmean

0.361
0.390
0.536
0.344

0.814
0.536
0.514
0.502

0.542
0.457
0.525
0.415

Three main reasons can justify this choice: 1) first, by the
above literature values; 2) second, according to the clinical
partners of myHeart project, one or two weeks is considered
adequate for the required prediction; and 3) finally, the decomposition wavelet scheme is simplified in case N = 2i , i ∈ R+ .
Thus, for i = 2, 3, 4, the resulting values are N = 4, 8, 16, that
are in accordance with literature values and clinical evidence
of myHeart.
With respect to the parameters ε and M , all possible combinations were carried out: M = 1, . . . , N and J = 1, . . . , N . It
should be noted that, although the value of J is not free since it
results from the specification of the threshold ε, in the present
experiments, the value of J was considered independently. This
procedure, without compromising the validity of the results, enables to establish directly the number of bases (J), and therefore,
to clearly show the effect of its variation.
E. Predictive Value of Individual Variables
In an initial phase, the predictive power of individual variables was assessed using the proposed strategy. Through the
conducted experiments, it was possible to acquire a better understanding of the data in general (e.g., in order to understand
the potential role of specific measurement in the prediction of
decompensation events), as well in their combination. Table I
presents the obtained results (SE-sensitivity, SP-specificity, and
Gmean) when a single variable classifier approach is employed.
From the analysis of these results, two variables can be highlighted: body weight and the heart rate. The first presents the
highest Gmean, the second the highest sensitivity (and a good
compromise with the specificity). In any case, it can be observed
that a single variable presents severe limitations in the detection
of HF decompensation. These results are in accordance with the
literature. For instance, the predictive value of the body weight
presents a high specificity (81.4%) and a low sensitivity (36.1%)
[39]. Moreover, the performance of the scheme improves when
all variables were combined, justifying the decision for a multivariable scheme.
F. Predictive Value of Multivariable Scheme
In order to assess the performance of the proposed strategy, three groups of results are presented. The first aims to
present and compare, in a global way, the performance measures, namely the Fmeasure and the Gmean, when the four
similarity measures are used. The second and the third group
present through an illustrative example, respectively, the similarity analysis and the prediction (nearest neighbor) process.

HENRIQUES et al.: PREDICTION OF HEART FAILURE DECOMPENSATION EVENTS BY TREND ANALYSIS OF TELEMONITORING DATA

1765

TABLE II
N = 4: FMEASURE AND GMEAN VALUES
Fmeasure

M= 1
M= 2
M= 3
M= 4
mean
± std

∗

SΩ

J

0.606
0.666
0.666
0.514
0.613
± 0.07

2
3
3
4

ST
0.780
0.731
0.777
0.666
0.739
± 0.05

J

∗

1
2
1
1

Gmean
SC

SE

SΩ

0.666
0.606
0.533
0.533
0.584
± 0.06

0.628
0.529
0.571
0.628
0.589
± 0.04

0.670
0.698
0.690
0.580
0.662
± 0.05

J

∗

2
3
3
4

ST

J∗

SC

SE

0.800
0.750
0.815
0.722
0.772
± 0.04

1
3
1
1

0.714
0.670
0.616
0.616
0.654
± 0.04

0.683
0.600
0.632
0.683
0.650
± 0.04

TABLE III
N = 8: FMEASURE AND GMEAN VALUES
Fmeasure
SΩ
M = 1 0.682
M = 2 0.714
M = 3 0.650
M = 4 0.636
M = 5 0.636
M = 6 0.651
M = 7 0.652
M = 8 0.651
mean 0.659
± std ± 0.0265

J∗

ST

J∗

4
4
4
4
4
4
5
4

0.717
0.736
0.684
0.687
0.647
0.666
0.600
0.571
0.664
± 0.056

8
7
6
6
8
7
6
6

Gmean
SC

SE

SΩ

0.571 0.555 0.700
0.555 0.500 0.724
0.571 0.540 0.674
0.545 0.540 0.620
0.545 0.555 0.620
0.500 0.555 0.648
0.466 0.514 0.648
0.500 0.514 0.648
0.532 0.534 0.660
± 0.038 ± 0.022 ± 0.036

J∗

ST

J∗

4
4
4
4
4
4
4
4

0.748
0.771
0.722
0.741
0.703
0.714
0.670
0.648
0.715
± 0.040

8
7
2
2
8
7
6
6

SC

SE

0.632 0.612
0.612 0.561
0.632 0.591
0.618 0.591
0.618 0.612
0.583 0.612
0.561 0.580
0.591 0.580
0.606 0.592
± 0.025 ± 0.018

Fig. 8. Template approximation with the waveletKLT transform, N = 8.
(a) Blood pressure. (b) Heart rate. (c) Body weight. (d) Respiration rate. All
values are normalized.

TABLE IV
N = 16: FMEASURE AND GMEAN VALUES
Fmeasure

M= 1
M= 2
M= 3
M= 4
M= 5
M= 6
M= 7
M= 8
M= 9
M = 10
M = 11
M = 12
M = 13
M = 14
M = 15
M = 16
mean
± std

Gmean

SΩ

J∗

ST

J∗

SC

SE

SΩ

J∗

ST

J∗

SC

SE

0.628
0.666
0.666
0.666
0.615
0.615
0.625
0.606
0.615
0.615
0.608
0.608
0.604
0.541
0.482
0.578
0.609
±0.046

3
3
2
2
14
14
2
2
14
14
11
11
10
16
8
14

0.666
0.666
0.666
0.647
0.666
0.645
0.645
0.687
0.600
0.480
0.480
0.500
0.521
0.476
0.400
0.400
0.571
±0.103

7
7
4
4
4
2
2
2
2
16
2
2
2
16
2
2

0.666
0.600
0.578
0.500
0.514
0.470
0.424
0.424
0.424
0.322
0.322
0.333
0.333
0.344
0.357
0.357
0.435
±0.109

0.645
0.625
0.562
0.562
0.562
0.516
0.516
0.516
0.533
0.533
0.533
0.571
0.571
0.571
0.571
0.592
0.561
±0.037

0.683
0.722
0.714
0.714
0.670
0.670
0.689
0.670
0.618
0.620
0.612
0.632
0.600
0.529
0.576
0.620
0.647
±0.054

3
3
2
2
3
2
2
2
2
5
5
5
9
8
8
8

0.722
0.724
0.714
0.703
0.722
0.707
0.707
0.741
0.670
0.574
0.574
0.587
0.600
0.559
0.500
0.500
0.644
±0.085

7
7
4
4
4
2
2
2
2
16
2
2
2
16
2
2

0.698
0.624
0.620
0.561
0.580
0.547
0.512
0.512
0.512
0.433
0.433
0.447
0.447
0.461
0.474
0.474
0.521
±0.078

0.707
0.689
0.636
0.636
0.636
0.600
0.600
0.600
0.616
0.616
0.616
0.648
0.648
0.648
0.648
0.663
0.638
±0.030

1) Global Performance Results: Tables II, III, and IV show
the values obtained for the Fmeasure and Gmean, for N =
4, 8, 16, using the four similarity measures: 1) based on the coefficients’ distance, (SΩ )—(7); 2) based on the coefficients’ signs,
(ST )—(8); 3) linear correlation, (SC )—(18); and 4) Euclidean
distance, (SE )—(20). Moreover, as referred, the number of similar patterns in the prediction mechanism was changed according
to M = 1, . . . , N . For the similarity measures SΩ and ST , the

Fig. 9. Comparison with a time series retrieved from historical dataset,
N = 8. (a) Blood pressure. (b) Heart rate. (c) Body weight. (d) Respiration
rate.

number of bases was also changed according to J = 1, . . . , N
(note that SC and SE do not depend on J). Additionally, for
each M , the number of bases that achieve the highest Fmeasure
and Gmean (J ∗ ) is also presented in the tables.
2) Similarity Process (Illustrative Example): In order to illustrate the similarity measures, and how their behavior can affect
the global prediction scheme, the different similarity measures
(SΩ , ST , SC , and SE ) are evaluated in the comparison of a
template X(t), shown in Fig. 8, with a time series Y(t), shown
in Fig. 9. For the similarity measures SΩ and ST , the number
of bases used in the waveletKLT transformation was J = 2, en
abling to obtain the approximated signals X(t)
= {Xi (t)} and

Y(t) = {Yi (t)}, i = 1, . . . , 4.
The resulting similarity measures are quantified in Table V.
In this procedure all physiological data are normalized.

1766

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 5, SEPTEMBER 2015

TABLE V
COMPARISON OF SIMILILARITY MEASURES
SΩ

ST

SC

SE

BP
HR
BW
RR

0.693
0.619
0.008
0.386

1.0
1.0
0.0
0.5

0.419
0.667
−0.824
−0.323

0.241
0.373
0.084
0.266

Mean

0.426

0.625

−0.015

0.241

Fig. 10. Prediction process (nearest neighbor) using: (a) trend similarity measure S T , (b) linear correlation S C . (◦—Normal condition; •—HF decompensation; ⊕—same similarity measure for mD and mN).

3) Prediction Process (Illustrative Example): Finally, the decision of the prediction process is illustrated in Fig. 10. The
figures depict the classification of all 41 cases, using the proposed nearest neighbor approach. As mentioned, this result is
supported on the similarity measures computed between each
case (template) and the most similar examples identified in
the historical dataset. In this particular example, the number
of patterns used in the prediction is M = 2, being the decision
based on the similarities computed to the decompensation events
(ST i , i ∈ mD) and to the normal conditions (ST i , i ∈ mN ),
according to (14).
G. Discussion
1) Global Performance Results: From the analysis of
Tables II, III, and IV, supported on the Fmeasure and Gmean
values, it can be observed that, in global terms, independently
from the similarity measure, the propose strategy presents, in al-

most all cases, satisfactory predictive values. This was the main
hypothesis to be assessed in this study, and in effect, for all similarity measures, it is possible to obtain acceptable performance
values, suggesting that the similarity between physiological time
series may have prognostic value in the prediction of decompensation events. In particular, the most significant values for
each similarity measure were the following.
SΩ : Fmeasure = 0.714 and Gmean = 0.724, corresponding to
N = 8, M = 2, J = 4. The sensitivity and the specificity
are, respectively, 0.937 and 0.560 (see Table III).
ST : Fmeasure = 0.780 and Gmean = 0.800, corresponding to
N = 4, M = 1, J = 1. The sensitivity and the specificity
are, respectively, 1.000 and 0.640 (see Table II).
SC : Fmeasure = 0.666 and Gmean = 0.714, corresponding
to N = 4, M = 1. The sensitivity and the specificity are,
respectively, 0.812 and 0.600 (see Table IV).
SE : Fmeasure = 0.645 and Gmean = 0.707, corresponding
to N = 16, M = 1. The sensitivity and the specificity are,
respectively, 0.620 and 0.800 (see Table IV).
The best result was achieved using the similarity measure
based on the signs of the coefficients (ST ) (Fmeasure = 0.780
and Gmean = 0.800). The second best result was also obtained with the same similarity measure (Fmeasure = 0.736
and Gmean = 0.771, corresponding to a sensitivity and specificity of 0.875 and 0.680, M = 2, J = 7; see Table III).
Although the use of the similarity SΩ enables to obtain, in
certain circumstances, better performances (N = 8 and N = 16
for high values of M), the employment of ST shows, in general,
superior performances. The use of the similarities SC and SE
achieves, in general, poor results. Moreover, a deterioration in
performance results using the correlation measure (SC ) can be
observed for simultaneous high values of N and M. In effect,
the lowest performance value (Fmeasure = 0.322 and Gmean
= 0.430) is obtained for SC , N = 16, M = 10.
With respect to the number of bases (J), it is interesting
to observe that the best score was obtained with J = 1, i.e.,
only one wavelet basis, corroborating one of the key ideas of
this study: the progression of physiological data (trend) can be
appropriately extracted by means of the proposed waveletKLT
scheme, and thus, contribute to the improvement of the general
prediction strategy. However, in average, the number of bases
that enables to achieve the best results is higher. In effect, as can
be observed for N = 4, the mode (maximum number of occurrences of a specific value) is J = 3 and J = 1, respectively, for
the SΩ and ST measures; for N = 8, the mode is J = 4 and
J = 6, respectively, for the SΩ and ST measures; for N = 16,
the mode is J = 14 and J = 2, respectively, for the SΩ and
ST measures. Therefore, it is not possible to detect a clear pattern that can justify an adequate number of J. In any case, the
number of bases for the similarity measure based on the coefficients’ distance (SΩ ) is visibly higher than those required for
the similarity based on coefficients’ signs (ST ).
Considering the number of patterns to be retrieved from the
historical dataset (M ), i.e., the number of neighbors employed
in the prediction process, the obtained results suggest that lower
numbers are preferable. In effect, the best scores were achieved
for M = 1 and M = 2.

HENRIQUES et al.: PREDICTION OF HEART FAILURE DECOMPENSATION EVENTS BY TREND ANALYSIS OF TELEMONITORING DATA

In terms of mean values, considering all possible number of
neighbors (M ) in the prediction process, the results were
SΩ : Fmeasure = 0.659 and Gmean = 0.660, (N = 8);
ST : Fmeasure = 0.739 and Gmean = 0.772, (N = 4);
SC : Fmeasure = 0.584 and Gmean = 0.654, (N = 4);
SE : Fmeasure = 0.589 and Gmean = 0.650, (N = 4).
Therefore, these values suggest that the number of days before an event (N ) equal to N = 4 or N = 8 are appropriate
values. In effect, in all cases, the average values decrease with
the number of days considered. For example, the average values for the similarity measure ST considering the Fmeasure are
0.739, 0.664, and 0.571, respectively, for N = 4, 8, 16. In conclusion, the early detection of a decompensation event is easily
performed close to the occurrence of the event. This is perfectly
reasonable with the clinical evidence, since the uncertainty increases with prediction horizon.
In conclusion, independently from the similarity measure
considered, the proposed predictive strategy achieves acceptable
performance scores (Fmeasure and Gmean), thus suggesting
the validity of the main hypothesis of this study. In particular, the best results (individual and average) are obtained when
the similarity measure based on coefficients’ signs (ST ) is employed. Moreover, the results suggest that the number of bases
(J) considered in the trend approximation (waveletKLT scheme)
should be low, as well as the number of patterns (M )considered
in the prediction process (nearest neighbor). In case a value of N
has to be chosen, given the acceptable values for Fmeasure and
Gmean, the conducted tests suggest that N = 8 is an adequate
choice, i.e., it is possible to recognize changes in physiological
data approximately one week before a decompensation event.
2) Comparison of Results: Despite the importance of evaluating the performance of the proposed algorithm with respect to
other state of the art methods, it is observed that this is a challenging task due to the fact that distinct variables and conditions
have been applied to derive the reported results.
A typical method to address the HF prediction has been based
on body weight variation, given its association with body fluid
retention. Zhang et al. [39], in the context of TEN-HMS study
involving 168 patients, obtained a sensitivity of 20.4% and a
specificity of 89.4% (Gmean = 0.427) computed 14 days prior to
a HF event. Blair et al. [40], in the ambit of the EVEREST study
considering 3764 patients, determined that a weight gain higher
than 2 Kg over 48–72 h was 97% specific, but only 9% sensitive
(Gmean = 0.295) for early detection of HF decompensation.
The relationship between daily changes in fluid status
and pulmonary volume has been assessed using intrathoracic
impedance. In a study comprising 33 patients, Yu et al. [36]
developed an algorithm able to detect HF decompensation at
approximately two weeks before hospital admission with a sensitivity of 76.9%. Ypenburg et al. [41], involving 115 patients,
obtained a sensitivity and a specificity of 60% and 73%, respectively, (Gmean = 0.661). Soga et al. [42], in a study comprising
123 patients, attained a sensitivity and a specificity of 89.5%
and 73.0%, respectively (Gmean = 0.808).
Studies involving multiparameter algorithms have also been
reported. In the context of HEARTFAID study involving 49 patients, body weight, blood pressure, heart and respiration rates,

1767

as well as specific characteristics of the patient, were used in
a decision tree classifier, attaining a sensitivity of 63.4% in the
prediction of decompensation events [43].
Thus, keeping in mind that results are not directly compared,
it is possible to observe that the performances obtained by the
proposed prediction scheme are in accordance with the literature. Moreover, the performance of the multivariable scheme
enables to improve considerably the results provided by the individual variables, outperforming almost all results found in the
literature.
3) Similarity Process (Illustrative Example): In order to find
some evidence that can justify the superior results of the proposed similarity measure, a template X(t) was considered,
shown in Fig. 8, and was compared with a time series Y(t)
using the four similarity measures (SΩ , ST , SC , and SE ).
First of all, as can be observed from Fig. 8, although only
two bases are employed, J = 2, the waveletKLT scheme is able
to capture the main dynamics (trend) of the biosignals (blood
pressure, heart rate, body weight, and respiration rate).
The comparison of each one of these biosignals is shown
in Fig. 9 and quantified in Table V. From these results, some
inferences can be performed, that might justify the better results
for the similarity ST . On one hand, the similarities SE and SΩ
are defined based on the Euclidean distance that uses raw data,
and the coefficients resulting from waveletKLT approximation,
respectively. Therefore, they might not be appropriate to capture
the trend of a signal. On the other hand, the similarities SC and
ST are actually linked with the concept of trend analysis. The
first is a correlation measure and enables to achieve continuous
values in the range [−1, . . . , 1]. The similarity measure based
of coefficients’ signs (ST ) is limited to a finite set of values
(in this case, three values, {0, 0.5, 1}, since J = 2). Therefore,
although this can be seen as a rough approximation, actually
it accurately accomplishes its main role: to capture the main
progression (trend) of the biosignal and to enable an easy and
effective comparison between the biosignals.
For the respiration rate [see Fig. 9(d)], the similarity measures
are 0.386, 0.500, −0.323, and 0.266, for SΩ , ST , SC , and SE ,
respectively. As can be observed, the signals X4 (t) and Y4 (t)
present the same trend (decreasing) in the first four days and
opposite trends in the last four days. This is exposed by
ST = 0.5. For the correlation coefficient, the similarity results
in SC = −0.323 revealing that signals, in overall, present opposite behavior (negative correlation value).
4) Prediction Process (Illustrative Example): The discrimination capacity is now evaluated when the similarity measures
associated with the trend concept (ST and SC ) are employed
in the prediction mechanism. These particular experiments correspond to the results presented in Table, line 2, i.e., N = 8,
M = 2.
As can be observed in Fig. 10, the distribution resulting from
the use of the ST similarity (top), suggests a higher discrimination between the two classes (HF decompensation and normal
condition) when compared with the use of the SC similarity
(bottom). Therefore, this apparent superior discrimination of
ST similarity might justify the results of its use in the prediction
mechanism. Namely, for these particular examples, the perfor-

1768

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 5, SEPTEMBER 2015

mances achieved confirm this higher discrimination capability:
Fmeasure = 0.736 and Gmean = 0.771 (ST similarity) and
Fmeasure = 0.555 and Gmean = 0.612 (SC similarity).
However, when using the ST similarity, it should be noted
that for some cases [symbol ⊕ in Fig. 10(a)], a decision may not
be possible. In effect, since M = 2 and the number of possible
similarity measures (ST ) is fixed by J, the decision between a
decompensation event or a normal condition can not be reached
(drawn) using (14).
IV. CONCLUSION
The optimal management of patients with HF should incorporate strategies to detect the onset of worsening indications, in
order to implement appropriate therapies to avoid decompensations and subsequent hospital readmissions.
This paper investigated the predictive value of a set of physiological data, daily collected by means of a telemonitoring study.
The main hypothesis is that the progression of these variables
(trends) can be used in the early detection of decompensation
events. With this aim, a predictive scheme was implemented,
combining four specific biosignals (body weight, blood pressure, heart, and respiration rates), being composed of two main
steps: a similarity analysis and a prediction process.
With respect to the similarity analysis, a simple measure able
to evaluate the trend similarity between physiological signals
was proposed. It combines the Haar wavelet decomposition with
the KLT, enabling to represent the signal by means of a reduced
set of bases. The prediction process is founded on a case-based
reasoning process. By means of the similarity analysis procedure, a set of signals presenting a dynamics similar to the current
condition is retrieved from the available historical dataset. This
set is then employed, through a nearest neighbor approach, in
the prediction of the current condition (decompensation event
or normal condition).
The validity of the scheme was assessed considering the data
collected in the myHeart telemonitoring study. Although it can
be argued that the number of patients was limited (41), the obtained results suggest that the collected physiological data can
be applied in the early detection of decompensation episodes.
In particular, the best result was achieved using the trend similarity measure proposed in this study, based on coefficient’s
signs of the waveletKLT approximation (Fmeasure = 0.780 and
Gmean = 0.800).
In parallel, other studies have confirmed the high potential
of other physiological variables in the detection of HF decompensation. Among these, the intrathoracic impedance (showing
a high potential to assess daily changes in fluid status and pulmonary volume) and parameters derived from the ECG (providing key information to diagnose alterations in the cardiac condition) are usually referred. Therefore, although the influence
of such variables was not evaluated in this study, it is strongly
believed that they will contribute to improve the performance
of the proposed prediction scheme. This is, unquestionably, a
direction for future research.
Nevertheless, the prediction of decompensation events in HF
patients remains a challenge, and the search for the optimal
diagnostic approach, able to improve the outcome of these pa-

tients is an open topic of research. Although many different
evidence-based indications are known and available in the literature, more systematic studies are required to determine the
best algorithms, as well as the correct selection and combination
of the variables before a common strategy can be implemented.
The use of telemonitoring services, integrating these algorithms
with a continuous monitoring of the adequate variables, will
empower professionals to play a proactive role in daily care,
by implementing more effective and personalized interventions.
Theoretically, the adjustment of treatments and actions prior to
the development of a decompensation can be potentially applied,
thus preventing hospitalizations.
REFERENCES
[1] J. Mackay and G. Mensah, Eds., The Atlas of Heart Disease and Stroke.
Geneva, Switzerland: World Health Organization, 2004.
[2] J. McMurray and M. Pfeffer, “Heart failure,” Lancet, vol. 365,
pp. 1877–1889, 2005.
[3] M. Gheorghiade, L. DeLuca, G. Fonarow, G. Filippatos, M. Metra, and
G. Francis, “Pathophysiologic targets in the early phase of acute heart
failure syndromes,” Amer. J. Cardiol., vol. 96, pp. 11G–17G, 2005.
[4] G. Giamouzis, S. Agha, O. Ekundayo, I. Abanb, T. Lovec, C. Danielb, J.
Butlera, and A. Ahmed, “Incident coronary revascularization and subsequent mortality in chronic heart failure: a propensity-matched study,” Int.
J. Cardiol., vol. 140, no. 1, pp. 55–59, 2010.
[5] G. Giamouzis, A. Kalogeropoulos, V. Georgiopoulou, S. Laskar, A. Smith,
S. Dunbar, F. Triposkiadis, and J. Butler, “Hospitalization epidemic in
patients with heart failure: Risk factors, risk prediction, knowledge gaps,
and future rections,” J. Cardiac Failure, vol. 17, no. 1, pp. 54–75, 2011.
[6] F. Triposkiadis, G. Karayannis, G. Giamouzis, J. Skoularigis,
L. Louridas, and J. Butler, “The sympathetic nervous system in heart
failure. Physiology, pathophysiology, and clinical implications,” J. Amer.
College Cardiol., vol. 54, no. 19, pp. 1747–1762, 2009.
[7] S. Chaudhry, J. Mattera, J. Curtis, J. Spertus, J. Herrin, Z. Lin, C. Phillips,
B. Hodshon, L. Cooper, and H. Krumholz, “Telemonitoring in patients
with heart failure,” N. Engl. J. Med., vol. 363, pp. 2301–2309, 2010.
[8] F. Koehler, S. Winkler, M. Schieber, U. Sechtem, K. Stangl, M. Böhm, H.
Boll, G. Baumann, M. Honold, K. Koehler, and G. Gelbrich, “Telemedical
interventional monitoring in heart failure investigators, impact of remote
telemedical management on mortality and hospitalizations in ambulatory
patients with chronic heart failure: The telemedical interventional monitoring in heart failure study,” Circulation, vol. 123, pp. 1873–80, 2011.
[9] J. Polisena, K. Tran, K. Cimon, B. Hutton, S. McGill, K. Palmer, and
R. Scott, “Home telemonitoring for congestive heart failure: A systematic
review and meta-analysis,” J. Telemed. Telecare, vol. 16, pp. 68–76, 2010.
[10] C. Klersy, A. De Silvestri, G. Gabutti, F. Regoli, and A. Auricchio, “A
meta-analysis of remote monitoring of heart failure patients,” J. Amer.
Coll. Cardiol., vol. 54, pp. 1683–1694, 2009.
[11] A. Mortara, “Telemonitoring in patients with heart failure—Lessons
from recent randomised multicentre trials,” Eur. Cardiol., vol. 8, no. 2,
pp. 84–87, 2012.
[12] A. Hasan and P. VincePaul, “Telemonitoring in chronic heart failure,” Eur.
Heart J., vol. 32, pp. 1457–1464, 2011.
[13] J. Cleland, A. Louis, A. Rigby, U. Janssens, and A. Balk, “Noninvasive
home telemonitoring for patients with heart failure at high risk of recurrent
admission and death,” J. Amer. Coll. Cardiol., vol. 45, pp. 1654–1664,
2005.
[14] M. Joseph, M. Cedars, G. Ewald, E. Geltman, and D. Mann, “Acute
decompensated heart failure,” Texas Heart Inst J., vol. 36, no. 6, pp. 510–
520, 2009.
[15] S. Chaudhry, Y. Wang, J. Concato, T. Gill, and H. Krumholz, “Patterns
of weight change preceding hospitalization for heart failure,” Circulation,
vol. 116, pp. 1549–1554, 2007.
[16] W. Abraham, S. Compton, G. Haas, B. Foreman, R. Canby, R. Fishel, S.
McRae, G. Toledo, S. Sarkar, and D. Hettrick, “Intrathoracic impedance
vs daily weight monitoring for predicting worsening heart failure events:
Results of the fluid accumulation status trial (fast),” Congest. Heart Fail.,
vol. 17, no. 2, pp. 51–55, Mar. 2011.
[17] E. Wolfel, “Can we predict and prevent the onset of acute decompensated
heart failure?” Circulation, vol. 116, pp. 1526–1529, 2007.
[18] M. Vanderheyden, R. Houben, S. Verstreken, M. Ståhlberg, P. Reiters,
and R. Kessels, “Continuous monitoring of intrathoracic impedance and

HENRIQUES et al.: PREDICTION OF HEART FAILURE DECOMPENSATION EVENTS BY TREND ANALYSIS OF TELEMONITORING DATA

[19]

[20]

[21]

[22]

[23]
[24]
[25]
[26]
[27]
[28]
[29]
[30]
[31]
[32]

right ventricular pressures in patients with heart failure,” Circ. Heart Fail.,
vol. 3, pp. 370–377, 2010.
P. Adamson, A. Smith, W. Abraham, K. Kleckner, R. Stadler, A. Shih,
and M. Rhodes, “InSync III model8042 and attain OTW model4193 clinical trial investigators. Continuous autonomic assessment in patients with
symptomatic heart failure: Prognostic value of heart rate variability measured by an implanted cardiac resynchronisation device,” Circulation,
vol. 110, pp. 2389–2394, 2004.
D. Whellan, K. Ousdigian, S. Al-Khatib, W. Pu, S. Sarkar, C. Porter,
B. Pavri, and C. O’Connor, “Combined heart failure device diagnostics
identify patients at higher risk of subsequent heart failure hospitalization,”
J. Amer. Coll. Cardiol, vol. 55, pp. 1803–1810, 2010.
T. Alexandrov, S. Bianconcini, E. Dagum, P. Maass, and T. McElroy, “A
review of some modern approaches to the problem of trend extraction,”
Center Ind. Math., Univ. Bremen, Bremen, Germany, Research report
series (Statistics #2008–3), Mar. 28, 2008.
T. Rocha, S.Paredes, P. Carvalho, and J. Henriques, “An effective wavelet
strategy for the trend prediction of physiological time series with application to pHealth systems,” presented at the IEEE 5th Annu. Int. EMBS
Conf., Osaka, Japan, 2013.
T. Liao, “Clustering of time series data - a survey,” Pattern Recog.,
vol. 38, pp. 1857–1874, 2005.
T. Li, Q. Li, S Shu, and M. Ogihara, “A survey on wavelet applications
in data mining,” ACM SIGKDD Explorations Newslett., vol. 4, no. 2,
pp. 46–49, 2002.
R. Agrawal, C. Faloutsos, and A. Swami, “Efficient similarity search in
sequence databases,” in Proc. Int. Conf. Found. Data Org. Algorithms,
1993, pp. 69–84.
K. Yang and C. Shahabi, “A PCA-based similarity measure for multivariate
time series,” in Proc. 2nd ACM Int. Workshop Multimedia Databases,
2004, pp. 65–74.
I. Popivanov and R. Miller, “Similarity search over time-series data using
wavelets,” in Proc. 18th Int. Conf. Data Eng., vol. 212, 2002, pp. 212–221.
R. Carreño and M. Vuskovic, “Wavelet transform moments for feature
extraction from temporal signals,” in Proc. Int. Conf. Informat. Control,
Autom. Robot., 2005, pp. 71–78.
H. Liu and H. Motoda, Feature Extraction, Construction and Selection: A
Data Mining Perspective, Boston, MA, USA: Kluwer, 1998.
J. Habetha, “MyHeart - A new approach for remote monitoring and management of cardiovascular diseases,” presented at the IEEE Engineering
in Medicine and Biology Society Conf., New York, NY, USA, 2006.
P. Refaeilzadeh, L. Tang, and H. Liu, “Crossvalidation,” in Encyclopedia
of Database Systems. New York, NY, USA: Springer, 2009, pp. 532–538.
K. Adams, J. Lindenfeld, J. Arnold, D. Baker, D. Barnard, K. Baughman,
J. Boehmer, P. Deedwania, S. Dunbar, U. Elkayam, M. Gheorghiade, J.
Howlett, M. Konstam, M. Kronenberg, B. Massie, M. Mehra, A. Miller, D.
Moser, J. Patterson, R. Rodeheffer, J. Bernstein, M. Silver, R. Starling, L.
Stevenson, and L. Wagoner, “Executive summary: Heart failure society of
America 2006 comprehensive heart failure practice guidelines,” J. Card.
Fail., vol. 12, pp. 10–38, 2006.

1769

[33] G. Schiff, S. Fung, T. Speroff, and R. McNutt, “Decompensated heart
failure: Symptoms, patterns of onset, and contributing factors,” Amer.
J. Med., vol. 114, pp. 625–630, 2003.
[34] A. Webel, S. Frazier, D. Moser, and T. Lennie, “Daily variability in dyspnea, edema and body weight in heart failure patients,” Eur. J. Cardiovasc.
Nursing, vol. 6, pp. 60–65, 2007.
[35] J. Lewin, M. Ledwidge, C. O’Loughlin, C. McNally, and K. McDonald,
“Clinical deterioration in established heart failure: what is the value of
BNP and weight gain in aiding diagnosis?” Eur. J. Heart Fail., vol. 7,
pp. 953–957, 2005.
[36] C. Yu, L. Wang, E. Chau, R. Chan, S. Kong, M. Tang, J. Christensen, and C.
Lau, “Intrathoracic impedance monitoring in patients with heart failure:
Correlation with fluid status and feasibility of early warning preceding
hospitalization,” Circulation, vol. 5, no. 112, pp. 841–848, 2005.
[37] P. Adamson, A. Smith, W. Abraham, K. Kleckner, R. Stadler, A. Shih,
and M. Rhodes, “For the InSync III Model 8042 and attain OTW lead
model 4193 clinical trial investigators. Continuous autonomic assessment
in patients with symptomatic heart failure: Prognostic value of heart rate
variability measured by an implanted cardiac resynchronization device,”
Circulation, vol. 110, pp. 2389–2394, 2004.
[38] P Adamson, A. Magalski, F. Braunschweig, M. Bohm, D. Reynolds,
D. Steinhaus, A. Luby, C. Linde, L. Ryden, B. Cremers, T. Takle, and
T. Bennett, “Ongoing right ventricular hemodynamics in heart failure:
Clinical value of measurements derived from an implantable monitoring
system,” J. Amer. Coll. Cardiol., vol. 41, pp. 565–571, 2003.
[39] J. Zhang, K. Goode, P. Cuddihy, and J. Cleland, “Predicting hospitalization due to worsening heart failure using daily weight measurement:
Analysis of the trans-European network-home-care management system
(TEN-HMS) study,” Eur. J. Heart Fail., vol. 11, pp. 420–427, 2009.
[40] J. E. Blair, S. Khan, M. Konstam, K. Swedberg, F. Zannad, J. Burnett, L.
Grinfeld, A. Maggioni, J. Udelson, C. Zimmer, J. Ouyang, C. Chen, and M.
Gheorghiade, “Weight changes after hospitalization for worsening heart
failure and subsequent re-hospitalization and mortality in the EVEREST
trial,” Eur. Heart J., vol. 30, pp. 1666–1673, 2009.
[41] C. Ypenburg, J. Bax, E. Wall, M. Schalij, and L. Erven, “Intra-thoracic
impedance monitoring to predict decompensated heart failure,” Amer. J.
Cardiol, vol. 99, pp. 554–557, 2007
[42] Y. Soga, K. Ando, T. Arita, M. Hyodo, M. Goya, M. Iwabuchi, and
M. Nobuyoshi, “Efficacy of fluid assessment based on intra-thoracic
impedance monitoring in patients with systolic heart failure,” Circ. J.,
vol. 75, pp. 129–134, 2001.
[43] A. Candelieri, D. Conforti, F. Perticone, A. Sciacqua, K. Kawecka-Jaszcz,
and K. Styczkiewicz, “Early detection of decompensation conditions in
heart failure patients with knowledge discover: The HEARTFAID approaches,” Comput. Cardiol., vol. 35, pp. 893–896, 2008.

Author’s photographs and biographies not available at the time of publication.

