IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 1, JANUARY 2016

43

Learning Recurrent Waveforms Within EEGs
Austin J. Brockmeier∗ , Member, IEEE, and José C. Prı́ncipe, Fellow, IEEE

Abstract— Goal: We demonstrate an algorithm to automatically
learn the time-limited waveforms associated with phasic events that
repeatedly appear throughout an electroencephalogram. Methods:
To learn the phasic event waveforms we propose a multiscale modeling process that is based on existing shift-invariant dictionary
learning algorithms. For each channel, waveforms at different temporal scales are learned based on the assumption that only a few
waveforms occur in any window of the time-series, but the same
waveforms reoccur throughout the signal. Once the waveforms are
learned, the timing and amplitude of the phasic event occurrences
are estimated using matching pursuit. To summarize the waveforms learned across multiple channels and subjects, we analyze
their frequency content, their similarity to Gabor–Morlet wavelets,
and perform shift-invariant k-means to cluster the waveforms. A
prototype waveform from each cluster is then tested for differential spatial patterns between different motor imagery conditions.
Results: On multiple human EEG datasets, the learned waveforms
capture key characteristics of signals they were trained to represent, with a consistency in waveform morphology and frequency
content across multiple training sections and initializations. On
multichannel datasets, the spatial amplitude patterns of the waveforms are also consistent and can be used to distinguish different
modalities of motor imagery. Conclusion: We explored a methodology that can be used for modeling the recurrent waveforms in EEG
traces. Significance: The methodology automatically identifies the
most frequent phasic event waveforms in EEG, which could then
be used as features for automatic evaluation and comparison of
EEG during sleep, pathology, or mentally engaging tasks.
Index Terms—Biomedical signal processing, clustering, dictionary learning, electroencephalogram (EEG), sparse coding.

I. INTRODUCTION
MPLIFIED voltage recordings across the human scalp
reveal a diversity of spatiotemporal oscillations and patterns [1]–[5] commonly referred to as brain waves. The electroencephalogram (EEG) records a mixture of the electrical
activity of the brain along with potentials arising from eye and
face muscles and movements. The interesting portion of the
signal is the superposition of the potentials generated from the
electrochemical activity in the neocortex [5], [6]. Research has
demonstrated that signal characteristics, such as certain frequencies, spatial locations, and phasic event waveforms are indicative

A

Manuscript received February 10, 2015; revised September 1, 2015 and
November 2, 2015; accepted November 3, 2015. Date of publication November
3, 2015; date of current version December 17, 2015. This work was supported
by the Defense Advanced Research Projects Agency under Contract N6600110-C-2008.
* A. J. Brockmeier was with the Department of Electrical and Computer
Engineering, University of Florida, Gainesville, FL 32611 USA. He is now
with the Department of Electrical Engineering and Electronics, University of
Liverpool, Liverpool, L69 3GJ, U.K. (e-mail: ajbrockmeier@gmail.com).
J. C. Prı́ncipe is with the Department of Electrical and Computer Engineering,
University of Florida.
This paper has supplementary downloadable material available at http://
ieeexplore.ieee.org.
Color versions of one or more of the figures in this paper are available
online at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2015.2499241

of an individual’s cognitive state, the presence or presentation
of stimuli, or neural pathology. Many distinct signatures appear
as brief, time-limited, oscillations [7], or phasic events [8] such
as alpha waves [1], [9], and sleep spindles. Some signatures are
ubiquitous and evident to experts from the raw EEG traces, while
other patterns such as evoked potentials [1], [2], [10] are timelocked to stimulus presentation. A commonality among these
signatures is their nonstationarity: even narrow-band rhythms
are time-varying in frequency and amplitude [11], and many
waveforms are phasic events that occur transiently.
Due to their nonstationary nature and the superposition of
transient and brief oscillatory events, EEGs require careful consideration for analytic examination. Signal processing tools are
only appropriate when the underlying assumptions that they are
based on are met [12], [13]. Time-frequency analysis, such as
multitaper analysis [14] or wavelet decompositions [15], has
been the standard tool for exploratory analysis of neural potential signals and is well suited for locally stationary brain
rhythms [16], but these representations are not able to separate
signals emanating from different sources.
Neural activity from distinct spatial sources occurs simultaneously in the brain. Each source may have distinct time-frequency
patterns or waveforms, but in the EEG recordings these patterns
are all mixed. By analogy, brainwaves are like an audio recording
from a busy social event—say a cocktail party—where conversations are occurring simultaneously. Can the individual sources
be identified from these seemingly chaotic signals? The cocktail
party analogy strikes a chord with the blind source separation
community, which has proposed the use of spatial independent
component analysis (ICA) and associated techniques to disentangle distinct sources in multichannel EEG [17]–[21]. The
utility of these techniques is based on the topological organization of the cortex. As the neural circuitry for distinct modalities
are spatially isolated they can be associated with unique source
signals that are then “mixed” together in the scalp recordings.
The blind source separation problem is then to “demix” the signals using spatial filters that isolate the signal components from
each of the underlying sources.
In the case of a single recording channel, spatial filtering
is impossible, but it is possible to decompose the signal into
components with distinct time-frequency characteristics. Ideally, each component would be strictly composed of waveforms
with similar morphology: a component dedicated to ripples,
another to alpha waves, a third to EEG spikes, and so on.1
Linear filtering is inadequate for morphological separation as
it can only segregate signals by frequency. Nonlinear filtering
by matching pursuit (MP) [24] has been shown to successively
1 Morphological component analysis has been applied to denoising and separation tasks for images [22], [23], which in essence are single-channel 2-D
signals.

0018-9294 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

44

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 1, JANUARY 2016

separate components with different underlying morphology in
EEG [25]–[30], and has been adapted to multichannel recordings [27], [31].
MP is based on the assumptions that any portion of the timeseries signal can be approximated using relatively few elements
from a “dictionary” of component waveforms. For instance,
this dictionary may be a set of Gabor–Morlet wavelets (sinusoids with Gaussian envelopes) [32] and Dirac delta functions
appearing at different translations. Each instance of waveform,
its amplitude, and timing are referred to as an atom, and together
they form an atomic decomposition of the signal [33]. Using the
correct basis allows a meaningful representation of the signal
using relatively few atoms.
Instead of leaving the dictionary as a design choice, which
must be predefined, the waveforms can be learned directly from
the data based on the higher-order statistics of the signal [34],
using techniques known as dictionary learning or sparse coding [35]–[39]. An alternative to dictionary learning is to apply
ICA directly to time-embedded vectors from a single channel [40]–[42]: a technique that has been shown to be successful in learning the constituent waveforms on EEG and other
biomedical signals. In either sparse coding or single-channel
ICA, waveforms can be learned from patches (windows) of
signals, but these dictionaries will contain copies of similar
waveforms at many different shifts. Shift-invariant dictionary
learning, also known as convolutional sparse coding, proposes
to learn only a few explicit waveforms and represent the rest of
the dictionary by translating these waveforms [43]–[51]. These
approaches avoid estimating redundant copies of the same waveform at different shifts. However, some of these approaches
neglect the phase information and only learn the magnitude
spectrum of the waveforms. For EEG, it is important to maintain the phase information to investigate phasic events such as
evoked potentials. Although there is yet no natural way to incorporate shift-invariance into single channel ICA, it will preserve
waveform shape, with a sign ambiguity, and the redundancy issues of single-channel ICA can be alleviated by using a post-hoc
waveform selection. A greedy approach for waveform subset selection was previously proposed [52] and evaluated on synthetic
data.
Shift-invariant dictionary learning has been fruitfully applied
to EEG for the detection of evoked potentials [53]. We emphasize that the estimated dictionary (set of waveforms) are datadependent descriptors of the signal and that learning a small
dictionary guarantees that any approximation reuses the same
set of waveforms. This can be contrasted with a decomposition
using a predefined dictionary, which is not constrained on the
number of unique waveforms to use. A comparison of a predefined to a learned dictionary on a segment of EEG is shown
in Fig. 1. Learning a small dictionary also allows different signals (or the conditions that generated them) to be compared
by contrasting the sets of learned waveforms. For instance, the
waveform shape could be compared across different conditions
such as ages or neuropathy.
In the rest of this study, we focus on adapting existing shiftinvariant dictionary learning algorithms to the problem of estimating multiscale dictionaries of EEG waveforms. Specifically,

Fig. 1. Comparison of two different sparse decompositions of a novel EEG
segment using the same number of atoms. (A) Predefined Gabor–Morlet wavelet
dictionary, which explains 82% of the variance of the test portion of the signal. (B) Dictionary learned on a disjoint section of the same recording using
single-channel ICA and waveform subset selection, which explains 72% of the
variance, but reuses the same 16 waveforms repeatedly throughout the decomposition, whereas the predefined dictionary uses different subsets.

we combine shift-invariant dictionary learning algorithms with
a multistage modeling approach. The multistage modeling approach avoids the difficulties involved in estimating many waveforms of different lengths at once. The results in the main body
use the MP with SVD update [47], [54], [55], but the supplementary material (available at http://ieeeexplore.ieee.org) contains
results using single-channel ICA with a post-hoc waveform selection algorithm [52] and a comparison of these two algorithms
on synthetic data. Another synthetic example is used to illustrate
the difference between decompositions using learned dictionaries versus using a predefined Gabor–Morlet dictionary.
Multiple publicly available human EEG datasets are used to
demonstrate and empirically verify the consistency of the estimation. We try to highlight how the learned waveforms can
be used to characterize and distinguish EEGs under different
conditions or from different subjects. We consider only single channel models, and run the waveform estimation on all
the channels independently and in parallel. Then, in posthoc
analysis, we determine if the waveforms are consistently estimated across multiple subjects and spatial locations, and organize them into clusters using shift-invariant k-means [56].
Additionally, we examine the spatial amplitude patterns associated with the cluster prototypes using a model-based approach
for investigating global spatial patterns across the scalp [57]. The
spatial patterns are then used to classify the segments of EEG
during motor imagery on a single-trial basis [58]. The MATLAB code for the described methodology is available online at
http://cnel.ufl.edu/ajbrockmeier/eeg/.

BROCKMEIER AND PRÍNCIPE: LEARNING RECURRENT WAVEFORMS WITHIN EEGS

45

B. Model Estimation

Fig. 2. Depiction of the assumed model and the signal flow. The observed
signal is assumed to be linearly synthesized by convolving the sparse source
with time-limited waveforms; the resulting components are added together.
Nonlinear analysis separates the signal back into its constituent components.

II. MODEL AND ESTIMATION METHOD
In this section, we introduce the sparsely excited multipleinput single-output (MISO) system, discuss generative models,
introduce the least-squares framework with nonnegativity constraints on the sparse sources, mention the single-channel ICA
with waveform subset selection, and finally discuss a multistage
subset deflation approach to learn waveforms across multiple
scales.
A. Multiple-Input Single-Output Model
We assume the signal of interest is formed by a linear MISO
system where each sparse source excites a distinct waveform
to form a component [59]. The signal is a uniform mixture of
these components. Fig. 2 depicts an example system and the
relationships among the signal, sources, and components.
Let x(t) be a combination of P component signals
{yp (t)}p , p ∈ {1, . . . , P } observed in the presence of noise e(t).
Overall, this is a multiple-input single-output (MISO) linear
system with sparse inputs. Each component yp (t) has a unique
waveform ap (t) and sparse source sp (t) consisting of a weighted
train of delta functions:
x(t) = e(t) + x̂(t) = e(t) +

sp (t) =

yp (t)

(1)

p=1


yp (t) =

P


∞

−∞



sp (t − u)ap (u)du

αp,i δ(t − τp,i ) p = 1, . . . , P.

(2)
(3)

i

The summation of the components is a noise-free signal x̂(t).
The atomic representation of x̂(t) consists of a set of source
indices, amplitudes, and timings {(pi , αi , τi )}i . Using this set,
the model signal can be rewritten as:
 ∞
αi δ(t − τi − u)ap i (u)du.
(4)
x̂(t) =
i

−∞

Similarly, each component signals can be described by the impulse response of the filter ap (t) and the set of excitation times
and amplitudes {(αj , τj )}j ∈Ip where Ip = {i : pi = p}.

Stochastically, the sparse source signals activation times can
be described by a point process; a realization of a point process
is a train of Dirac delta functions. In the model above, a marked
point process is required that also describes the amplitude of
the impulses [60]. A marked point process is fully described
by a joint distribution over both the timing and amplitude of
the impulses. With a distribution over the noise, a complete
generative model can be posed, but solving it is intractable [60]
and approximations are necessary.
For simplicity, we do not utilize a full generative model.
Instead, we assume a maximum likelihood approach where the
atomic representation {(pi , αi , τi )}Li=1 and the sparse inputs
{sp (t)}, p ∈ {1, . . . , P } are fixed and let the user select L and
P and the duration of each waveforms model parameters. We
assume uncorrelated white noise and optimize the parameters
to minimize the mean squared error.
In the case of correlated noise, the noise covariance can be
additionally estimated and used to whiten the signal [60]. This is
important if the waveforms of interest are sufficiently different
from the colored noises—such as action potentials [61], [62] or
evoked potentials [63]. However, in the case of action potentials
(spike trains) and evoked potentials, the estimation can start
with an initial template for each waveform. We assume no prior
information on the shape or frequency, and assume the model
will account for all signal correlation.
C. Source Estimation
Even though each component is a linear convolution of the
source and waveform, linear filtering is inadequate to separate
the original components from the combination if the waveforms’
frequency responses overlap. There are two regimes in which it
is possible to resolve the inputs to a MISO system from a single
output: spectrally disjoint waveforms (corresponding to sparsity in the frequency domain) or sufficiently sparse input (corresponding to temporally disjoint input). In the former case, linear
band-pass filtering is sufficient. In the latter case, recovering the
sparse source as a train of Dirac deltas requires an overcomplete
basis of the signal: shifted versions of the underlying waveforms
appearing at each time-shift. With an overcomplete basis, linear
analysis is not meaningful [64], and sparsity constraints on the
sources are necessary to recover them. The resulting problems
can be relaxed to convex optimization problems or solved using
iterative algorithms [65]. MP [24] provides a greedy approximation to solve the sparsity constrained problem.
D. Least Squares Estimation
Assuming a signal plus white noise model and that the number
of waveforms P and source excitations L are known, the blind
system identification problem can be posed as a least-squares
optimization over A = {ap (t)}Pp=1 and S = {(pi , αi , τi )}Li=1 :

2
 ∞
L





min J(A, S) = x(t) −
αi
δ(t − τi )ap i (u)du .
A,S


−∞
i=1
2
(5)

46

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 1, JANUARY 2016

Jointly solving for both A and S is difficult because the source
estimates are intrinsically linked to the waveforms. It is necessary to perform an alternating optimization.
Assuming A is fixed, a greedy optimization of S can be
made using MP. At each iteration of MP, the atom (consisting
of the timing, amplitude, and waveform index) that explains the
most energy remaining in the residual of the signal is selected.
The residual signal is updated by removing this single-atom
reconstruction. This updated residual is used as the input to the
next iteration.
Given the atomic decomposition S = {(pi , αi , τi )}Li=1 , either
the sources or the individual components can be computed via
(3) or (2), respectively. Then the sources are fixed, and the set
of waveforms A is updated via least squares.
The alternating optimization between time-series MP and
least squares updates has been proposed as a general tool for
shift-invariant dictionary learning [47], [54], [55]. It is the timeseries extension of the popular dictionary learning algorithm
K-SVD [66]. For conciseness, we refer to it as MP-SVD.
1) MP-SVD: For practical digital implementation, we consider the case when the time series (1) is discretely sampled, and
the convolution operators are replaced by finite summations. In
this framework, we only allow integer shifts, but this approximation can be avoided using continuous basis pursuit [50]. Let
a denote an M -length waveform and Tτ (a) denote the translation of the waveform to begin at time τ . Correspondingly,
let Wτ (x) denote the windowing function that extracts an M length window from signal x starting at time τ . (Here, we have
used a Tukey window [67], which is also known as a tapered cosine window, with parameter of 0.1.) Using these notations, the
objective function can be written in terms of vectors as follows:

min

{a p }Pp = 1 ,{(p i ,α i ,τ i )}Li= 1


2
L





αi Tτ i (ap i ) .
x −


i=1

(6)

2

To update the waveforms, we first assume we have an estimate
of the components using the current waveforms. Let x(p) denote
the signal consisting only of the estimate of the pth component
and the error signal


x(p) = e + yp = x −

yq

(7)

waveform are equivalent
2





 (p)

vi Tτ i (a)
arg min min x −

v 
a=1

i:p i =p

(9)

2


2
arg min min Xp − avT F = max aT Xp XpT a.
a=1

a=1

v

(10)

The updated waveform is selected as the eigenvector of the matrix Xp XpT corresponding to the largest eigenvalue. This eigenvector is also the primary singular vector of the columns of the
Xp corresponding to the best rank-1 approximation [68]. Assuming these were the correct timings, this update minimizes
the reconstruction cost for these patches.
2) Nonnegative Amplitude Constraint: In the case of
nonoscillatory waveforms in EEG, it is worthwhile to preserve
the polarity of the waveforms. This can be done by allowing
only nonnegative amplitudes during the MP and the waveform
update:

2
(11)
arg min min Xp − avT F .
a=1

v≥0

Unlike the unconstrained case, there is no analytic solution to
this problem [69]. However, let XP = σ1 avT be the rank-1
SVD, if v is strictly positive then it is the solution to (11). If
not, then a local minima can be found by alternating between
v ← max(0, (1 − λ)v + XpT a)
a← 

Xp v

(12)
(13)

vT XpT Xp v

where max enforces the elements to be nonnegative and λ is the
step size of a proximal gradient update [70]. The nonnegative
amplitude constraint with step size of λ = 1 is used in the rest
of this study.
3) Waveform Initialization: The nonlinear least-squares cost
function (5) may have many local optima. From different initializations, it is unlikely to estimate the same waveforms. It
is possible to initialize the waveforms from a predefined set of
wavelets, and then “optimize” them further. However, to avoid
biasing the waveforms to any particular shape, we initialize the
waveforms as random vectors with entries independently drawn
from the normal distribution. Ideally, the optimized waveforms
across multiple initializations should be similar.

q ∈{1,...,P }\p

E. Single-Channel ICA With Greedy Subset Selection


where yp = j ∈Ip αj Tτ j (ap ) and Ip = {i : pi = p}. Only the
patches when the waveform is active are needed to update the
waveform. These patches are collected into a matrix:


Xp = Wτ j (x(p) )

j ∈Ip

.

(8)

Treating the amplitudes as a nuisance parameter (the previous
estimates are ignored) and assuming that none of the patches
overlap the following optimization problems for the optimal

Single-channel ICA is an alternative approach to least squares
estimation that avoids the explicit estimation of the sources during learning. Instead, the sparse sources’ statistical properties
are used in the filter estimation [71]. Single-channel ICA uses
windows of the time series as the input vectors to ICA [34]. Previous studies [41], [42] have demonstrated that the fixed point
algorithm FastICA [72] can efficiently estimate the waveforms
in a multiple-input-single-output model. Essentially, FastICA
estimates the waveforms using a nonlinear feedforward network without explicit estimation of the sources [52]. The main
drawback of single-channel ICA is that many of the waveforms

BROCKMEIER AND PRÍNCIPE: LEARNING RECURRENT WAVEFORMS WITHIN EEGS

are redundant—they are the same waveform appearing at different shifts—and others are artifacts caused by the multiunit ICA
estimation constraints.
To solve these problems, we use a greedy subset selection
algorithm to choose a nonredundant subset of the estimated
waveforms with the goal of minimizing the reconstruction error [52]. The first step in the greedy algorithm is to approximate
the training signal using MP with each waveform individually.
Herein, we enforce nonnegativity constraints during MP, and
since ICA is invariant to polarity, we use both the waveform
and its negation as candidate waveforms. The resulting approximations are treated as the basis vectors for approximating the
same signal using orthogonal matching pursuit (OMP) [73]. At
each iteration, OMP includes the basis vector which minimizes
the reconstruction error. The algorithm is terminated when the
number of included basis vectors equals the number of desired
waveforms. The waveforms corresponding to the included basis
vectors form the selected subset. This post-hoc subset selection algorithm can be applied to find a signal-specific subset
of a larger shift-invariant dictionary. In particular, we use it to
transform a dictionary of Gabor–Morlet wavelets into a much
smaller data-dependent model (examples are included in the
supplementary material). When a training portion of the signal is used to select the subset, this approach can be seen as
an compromise between using predefined dictionaries and fully
adaptive dictionaries.
F. Multistage Waveform Estimation
In EEGs, waveforms may have widely different time-scales.
This motivates learning a multiscale waveform dictionary, which
can be difficult to achieve in a single optimization. To address
this, we propose a multistage approach to simplify the estimation
of multiple waveforms at different scales. It consists of a subset
deflation approach that greedily estimates a set of waveforms at
each stage. After convergence, multiple passes of MP are run to
remove the contribution of the waveforms before the resulting
residual is passed as the input signal to the next stage. We use a
coarse-to-fine approach where longer waveforms are estimated
before shorter waveforms. While this approach is ad hoc, it is
well suited for EEG where low-frequency/long duration signals
explain more of the variance in the signal.
Before estimation, the user must select the parameters of the
sparsely excited multiple-input-single-input model. Most importantly, the user must select the number of waveforms and
their length. These choices will depend on the time-scales of
interest and the application. The other important choice is the
assumed rate of the sources, which determines the number of
atoms, that is, the number of waveform occurrences used in
approximation/decomposition. Only the total number of occurrences for each scale needs to be set as the particular number of
occurrences of each waveform is based on how often it is used
in the MP-based decomposition. Since the modeling is based on
sparse sources, the total number of occurrences should be kept
relatively low.
Multiple models with different waveform lengths, numbers of
waveforms, and approximations with different number of atoms
can be trained and compared using model selection criterion. To

47

compare models, we assume the background activity is white
noise with constant variance. We show an example of using the
Bayesian information criterion (BIC) to select the number of
waveforms in the supplementary material.
III. WAVEFORM META-ANALYSIS
When different shift-invariant dictionaries are learned across
multiple sections, channels, and subjects there is a need to summarize the characteristics of the large number of resulting waveforms. To do this, we fit the waveforms using parametric models
and perform shift-invariant vector quantization on the waveforms to group them into clusters. For multichannel datasets,
we use a prototypical waveform to represent each cluster and
analyze the waveform’s ability to differentiate between known
conditions using its spatial amplitude patterns.
A. Gabor Fit of Waveforms
We see how well each waveform is modeled by real-valued
Gabor–Morlet wavelets of varying frequency, bandwidth, and
phase: gf ,φ,σ (t) = exp(−t2 /(2σ 2 )) cos(2πf t + φ), where f, φ
are the frequency and phase, and σ is the standard deviation
of the temporal envelope. In lieu of an uniform sampling over
the space of these parameters [31], we use a logarithmic scaling over frequency and temporal envelope, and three phases
[0, π/4, π/2]. Any time shift is accounted for by performing the
matching using maximum absolute cross-correlation
	∞
| −∞ g(τ )h(τ − t)dτ |
.
(14)
c(g, h) = max
t
gh
The discrete time version of the above can be computed efficiently by using the discrete Fourier transform.
To characterize the frequency content of waveforms that
match Gabor–Morlet wavelets, we compute the peak frequency
and 3 dB bandwidth from the power spectral density (PSD) of
each waveform. To get a robust estimate of the PSD, we use
multitaper analysis [14], [16]. Specifically, the waveforms are
zero-padded to a specified length, which controls the frequency
resolution, and projected onto a small number of discrete prolate
spherical sequences. The magnitude of the Fourier transform is
computed for each projection and a uniform average is taken to
provide the multitaper estimate. Using the resulting peak frequency avoids the bias caused by the grid of center frequencies
used in constructing the set of wavelets.
B. Average Cross-Correlation Between Waveform Sets
For a measure of similarity between two sets of waveforms,
we propose to use the average cross-correlation. Specifically,
if G is a set of |G| waveforms (|G| indicating the number of
elements in G) and H is a set of |H| waveforms, we compute
the average cross-correlation c̄(G, H) as
⎫
⎧
⎬
⎨ 1 
1 
max c(g, h),
max c(g, h)
(15)
max
g ∈G
⎭
⎩ |G|
h∈H
|H|
g ∈G

h∈H

where c(g, h) is the maximum correlation for waveforms
g(t) and h(t), which is normalized so that the zero-lag
autocorrelation is 1.

48

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 1, JANUARY 2016

C. Shift-Invariant Vector Quantization
Clustering is useful to organize a set of waveforms into groups
without a predefined criterion such as frequency or bandwidth.
Standard clustering algorithms developed for data represented
as vectors are inappropriate for shift-invariant waveforms since
they are ignorant of the shifts necessary to align the waveforms.
One option is to represent each waveform by its power spectral density. An obvious drawback of using the power spectral
density to represent the waveform is that it discards the phase
spectrum of the waveform. Alternatively, one can use clustering
algorithms that directly use the maximum cross-correlation between normalized waveforms, such as the 1-D case of circular
invariant k-means [56]. In this algorithm, each cluster mean is
associated with a new shift-invariant waveform, formed as the
average of all the aligned waveforms in the cluster.
As with standard k-means [74] the user must select the number of centers. As shift-invariant k-means optimizes the minimal mean-squared error of each waveform to its cluster center,
it is straightforward to use this error to guide model selection.
Various criteria can be used for this, in particular, Calinski–
Harabasz’s criterion [75], which uses the inter/intracluster variance ratio (pseudo F-score) and was previously used for circularinvariant k-means [56]. However, the set of waveforms may not
consist of separate clusters, but instead, the set may exhibit
smooth variations across the continuous space of waveforms.2
Nonetheless, shift-invariant k-means can be used as vector quantization rather than cluster identification, where increasing the
number of clusters gives a finer grained view of the space. For
illustrative purposes, we use a manageable set of nine clusters.
D. Spatial Amplitude Patterns
In multichannel records, we identify the spatial amplitude
patterns associated with the occurrence of each waveform [58].
We use the timing of a waveform’s occurrences based solely on
the activation times on the channel it originated from. Given the
set of timings, we assume the spatiotemporal pattern is timelocked, and we record the vector of cross-correlations with the
waveform on the other channels at each time point. These timings can be taken from the atomic decomposition of the single
channel obtained from MP. Alternatively, they may be obtained
by greedily choosing the most significant (in terms of amplitude) instances of cross-correlation while avoiding times that
are within a fixed window of previous estimates. This is a faster
approximation since each waveform amplitude patterns are estimated independently.
Let xm , m ∈ {1, . . . , M } denote a channel of a M -channel
EEG recording, and let x denote the channel from which waveform a (with duration N ) was estimated. This is the “anchor”
channel and each temporal alignment is based solely on it. Let
Tk denote the set of k timings. The spatial amplitude vectors are
found via
τ k = argmaxτ :|τ −τ  |> N ,

∀τ  ∈Tk −1 
x , Tτ a

k
vm
= 
xm , Tτ  a m = 1, . . . , M.

(16)
(17)

2 To better visualize the full space, one option is to implement a shift-invariant
versions of Kohonen’s self-organizing map.

Let V = [v1 , v2 , . . . , vk ] be a matrix where each column is the
spatial amplitude vectors of a different occurrence of the waveform. The primary spatial pattern of the waveform corresponds
to eigenvector of V V T with the largest eigenvalue.
The rationale for using a channel-anchored approach is
twofold: first, the timings are maximized for the channel from
which the waveform is estimated—if a waveform is completely
localized, then using the rest of the channels would bias the
timing estimation; and second, the nonnegativity of the amplitude can be preserved on the original channel while allowing
the polarity to flip on other channels. The latter point is especially important depending on the type of channel referencing
used. For instance, if channels correspond to electrode differences then many waveforms may have different polarities. The
channel-anchored approach is an alternative to using multichannel MPs [27] that find the timing using an equal contribution of
all the channels.
IV. CASE STUDY 1: SPECIFICITY AND CONSISTENCY
The first group of datasets we use is publicly available from
the Department of Epileptology, University Hospital of Bonn.
The details of the recording are available in the original publication [76]. This set contains five EEG datasets with varying
characteristics including “intracortical EEG,” recorded by depth
electrodes targeting the hippocampal formations. Each of the
datasets contain 100 23.6 s segments recorded at 173.61 Hz.
Segments are not necessarily from the same channel nor the
same subject; they were cut out of continuous multichannel
recordings to avoid artifacts.
The datasets denoted by A and B are from five healthy volunteers recorded using the standard 10–20 EEG montage. In
dataset A, the subjects were awake and relaxed with eyes open,
and in dataset B the subjects have their eyes closed. Datasets C,
D, and E are presurgical recordings used for diagnosis from five
subjects who had resections of one of the hippocampal formations for the control of seizures. Dataset D was recorded from
the epileptogenic zone, and dataset C was recorded from the
contralateral hippocampus. Both of these datasets are seizure
free, whereas dataset E contains segments from all implanted
electrodes during sessions exhibiting ictal spikes.
The multistage modeling consisted of four stages with four
waveforms each. In each stage, the waveform had discrete
lengths of 200, 100, 80, and 40, corresponding to approximately
1150, 576, 460, and 230 ms, respectively. The multistage estimation process used four passes of nonoverlapping MP to remove
the model approximation before the next stage of waveform
estimation. For multitaper analysis, we used four tapers and a
sequence length of 2000, resulting in a frequency resolution of
less than 0.1 Hz.
The waveforms estimated using the first 25 sections of each
dataset are shown in Fig. 3. The specificity of the waveform
shape and frequency content in the different datasets is evident: on dataset B, where the subjects’ eyes were closed, all
four waveforms at the longest scale correspond to alpha waves;
sharp positive waves were estimated from dataset D; and on
dataset E oscillatory waveforms in the theta and beta range were
estimated. Similar results were obtained when single-channel

BROCKMEIER AND PRÍNCIPE: LEARNING RECURRENT WAVEFORMS WITHIN EEGS

Fig. 3. Case Study 1: Waveforms estimated across the five single-channel ongoing EEG datasets at four different scales. Waveforms are scaled to maximum
absolute amplitude, those with thicker and lighter coloring matched Gabor–
Morlet wavelets with cross-correlation above 0.8, those with peak frequency
noted matched with cross-correlation above 0.5.

ICA was used to estimate the waveforms and are included in
supplementary material along with example segments of each
dataset and signal approximations based on both models. The
supplementary material also contains results obtained using subset selection on a dictionary of Gabor–Morlet wavelets.
The specificity of the waveforms to the datasets by their
frequency content was assessed for waveforms that matched
Gabor–Morlet wavelets. The best matches between the estimated waveforms and Gabor–Morlet wavelets were computed
across four disjoint sets of 25 contiguous sections and four
Monte Carlo runs. A scatter plot of the waveforms peak frequency and Q-values is shown for each dataset in Fig. 4. The
distribution of parameters appears consistent with the similarity
of datasets’ recording location/conditions: dataset A has many
high-Q waveforms above 20 Hz, in dataset B these are absent
and replaced by waveforms near 10 Hz (alpha waves), datasets
C and D have similar distributions, and dataset E has many
low-Q waveforms with frequency above 20 Hz corresponding.
To further analyze the specificity of the waveforms for the different conditions, we computed the average cross-correlation—
maximized across shifts—between sets of waveforms across
the sections and Monte Carlo runs. The averages across all four
scales are shown in Table I.
To further assess the consistency of the waveform estimation,
especially the variation across multiple Monte Carlo initializations, we experimented with the number of sections used
in training the shift-invariant waveforms. For each dataset, we
compared the average cross-correlation between waveforms estimated across Monte Carlo initialization to that of waveforms
estimated on different sections; the results are shown in Fig. 5.
For all datasets and number of sections, the cross-correlation
between different initializations is higher than between

49

different subjects as determined by a one-tailed sign test (pvalue of 0.031, effect size of 0.83).
We also calculated the average cross-correlation between the
waveforms estimated on different datasets. In this case, the assessment was done only on the first scale. A one-tailed Wilcoxon
rank sum test was used to determine that the correlation among
different initialization is higher than between different sections
(p-value of 0.00033 and effect size of 0.88 ) and between different subjects (p-value of 0.00397 and effect size of 0.84) for
all number of sections used for training. Average, standard deviation error bars, and the cross-correlation values are plotted
against the number of training sections in Fig. 6.
This analysis was done using the particular model described
above. The model complexity can be justified by using BIC.
Specifically, we fix the number of stages and waveform lengths,
and find the number of waveforms to minimize BIC; 3 or 4
waveforms per scale was optimal on all subjects. The plot of
BIC versus number of waveforms, and the waveforms themselves, are included in supplementary material. We found the
estimated waveform shapes to be consistent when the number
of waveforms or atoms was varied, both for the MP-SVD and
single-channel ICA dictionary learning algorithms and when the
greedy subset selection algorithm is applied to a Gabor–Morlet
wavelet dictionary. The waveforms and a comparison of the approximations using different number of atoms are also included
in the supplementary material.
V. CASE STUDY 2: MULITCHANNEL, MULTIPLE SUBJECTS
For the second group of datasets, we used the BCI competition III dataset IV(a) [77], provided by Fraunhofer FIRST, Intelligent Data Analysis Group (Klaus–Robert Müller, Benjamin
Blankertz), and Campus Benjamin Franklin of the Charité–
University Medicine Berlin, Department of Neurology, Neurophysics Group (Gabriel Curio). Healthy human subjects
performed visually cued segments of left hand, right hand, and
right foot motor imagery while seated. Each cue lasted 3.5 s
and periods of rest in between had pseudorandom lengths between 1.75 and 2.25 s. For each subject, one continuous record
was provided per subject along with the timings and labels of
right hand and foot cues, with 140 trials of each. The provided
recordings were downsampled to 100 Hz.
We filtered each channel using a high-pass (0.5 Hz) and lowpass (35 Hz) first-order Butterworth filter. Noisy channels were
removed from analysis on two subjects: channel 2 on “aa” and
118 on “ay.” Each record was broken up into four equal length
sections. The first section was used in the estimation of waveforms, the remaining sections were kept for testing the decomposition and statistical analysis of the spatial extent between
the different classes of motor imagery. The multistage modeling parameters were set similarly to the single-channel case:
four stages with four waveforms each with waveform lengths of
200, 100, 80, and 40, which correspond to 2, 1, 0.8, and 0.4 s,
respectively.
The results that follow are based on using the MP-SVD dictionary learning algorithm. A complementary version of each
result using single-channel ICA is included in the supplementary

50

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 1, JANUARY 2016

Fig. 4. Case Study 1: Distribution of peak frequency and Q-value (peak frequency divided by bandwidth) for the subset of waveforms that matched Gabor–Morlet
wavelets (cross-correlation ≥ 0.8). Points correspond to waveforms estimated at four scales from four disjoint sets of 25 contiguous sections across four Monte
Carlo runs (maximum number of points in a plot is 256). Bottom row shows a histogram of peak frequencies for waveforms.

TABLE I
CROSS-CORRELATION BETWEEN WAVEFORMS OF DIFFERENT SUBJECTS
Subset that match Gabor–Morlet wavelets

A
B
C
D
E

A

B

C

D

E

1.00
0.72
0.66
0.73
0.72

0.72
1.00
0.43
0.51
0.44

0.66
0.43
1.00
0.64
0.48

0.73
0.51
0.64
1.00
0.59

0.72
0.44
0.48
0.59
1.00

0.68
0.60
0.75
1.00
0.60

0.53
0.53
0.57
0.60
1.00

All waveforms
A
B
C
D
E

1.00
0.66
0.67
0.68
0.53

0.66
1.00
0.60
0.60
0.53

0.67
0.60
1.00
0.75
0.57

material. In both cases, after estimation of the waveforms at a
particular scale, four passes of MP were run and the model approximation removed. Each pass included enough atoms such
that, given the waveform length, the approximation should cover
the signal. An example of the decomposition using different
numbers of approximation passes is also shown in the supplementary material.
We assessed the oscillatory characteristics of the estimated
waveforms by matching them to Gabor–Morlet wavelets and
calculating their PSD using multitaper analysis with four tapers
and a sequence length of 2000. The peak frequency and 3 dB
bandwidth were recorded from those that matched a wavelet
with a cross-correlation above 0.8. A Q-value for each matching
waveform was computed as the peak frequency divided by the
bandwidth.Fig. 7 shows a scatter plot of the waveforms’ peak
frequency and Q-values across all channels and subjects. The
Q-values are especially high near 10 Hz corresponding to alpha
waves.
We used cluster analysis to collectively characterize the waveforms estimated across the multiple channels and subjects. For
each scale, we ran shift-invariant k-means (with k = 9 clusters)
on the set of waveforms estimated across different channels and

Fig. 5. Case Study 1: Scatter plot of cross-correlation between Monte Carlo
initializations versus between sections. The correlation between runs is always
higher than the correlation between different sections.

Fig. 6. Case Study 1: Comparison of cross-correlation between waveforms
in the first scale estimated on different Monte Carlo initialization, disjoint sets
of sections, and between the five datasets. Stars and asterisks indicate that
the correlation between different initialization runs is significantly higher than
correlation between different sections and between different subjects.

subjects. The cluster centroids are shown in Fig. 8. All of the
waveforms in each cluster were also compared to Gabor–Morlet
wavelets. Most clusters had very few waveforms matching, but
notable exceptions are clusters 1.5, 1.6, and 1.7 (that is the fifth,
sixth, and seventh largest clusters in the first scale) that seem to
correspond to alpha waves. In comparison, many more of the
waveforms estimated by single-channel ICA matched Gabor–
Morlet wavelets (results shown in the supplementary material).

BROCKMEIER AND PRÍNCIPE: LEARNING RECURRENT WAVEFORMS WITHIN EEGS

51

Fig. 7. Case study 2: Scatter plot of peak frequency and Q-value, defined as
the peak frequency divided by bandwidth, of waveforms that matched Gabor–
Morlet wavelets.

Fig. 9. Case study 2: Cluster descriptors for waveforms with a 1 s duration.
Each subplot shows the cluster centroid, prototypical waveform, electrode distribution shown on an unfolded scalp map where the color intensity indicates
the number of subjects with waveforms originating from that electrode, and the
power spectral density over all waveforms in the cluster.

Fig. 8. Case study 2: Cluster centroid waveforms and scatter plot of peak
frequency and Q-value for waveforms that matched Gabor–Morlet wavelets.
A unique cluster index, the number of waveforms the cluster contains, and the
percentage of waveforms that match Gabor–Morlet wavelets is listed to the right
of each cluster centroid waveform.

For each cluster of waveforms, we compute the average power
spectral density, and choose a prototypical waveform to represent the cluster. The first step in choosing the prototype was to
remove waveforms estimated on channels that were flagged
as noisy in any of the other subjects; this ensured that the
same channel for all subjects could be used for the channelanchored approach described in Section III-D. The maximum
cross-correlation (14) between all pairs of remaining waveforms
in the cluster was computed. Cross-correlations less than 0.5
were set to 0, and the waveform that had the largest average
cross-correlations to the other waveforms was selected as the
cluster prototype.

Descriptors of the clusters in terms of the distribution of
channels the waveforms originated from, the average spectral
density, and subject distribution are shown in Fig. 9 for waveforms with a duration of 1 s. The cluster descriptors for the other
scales are shown in the supplementary material. The prototype
waveforms for the clusters exhibit a variety of morphologies.
Waveforms for clusters 2.1–2.5 correspond to bandpass filters.
Cluster 2.1 is the largest cluster at this scale, with a frequency
range of 4–8 Hz (theta) and distribution across the scalp. Cluster
2.3 has a peak frequency of 11 Hz and waveforms from most
subjects were estimated from electrodes over the sensorimotor
cortex. Cluster 2.5 has a peak frequency of 9.65 Hz and originated predominantly from the frontal cortex. Cluster 2.8 has a
peak frequency in 12.35 Hz and originates near the motor cortex
for most subjects.
Finally, we assessed the discrimination between the spatial
amplitude patterns of the estimated waveforms during different
motor imagery modalities. Fisher’s linear discriminant analysis

52

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 1, JANUARY 2016

(LDA) was applied to the training data for each waveform and
subject. This was done by collecting the spatial amplitude vectors per class, computing the class conditional means, removing the common mean, and computing a common covariance.
We found the covariance matrices to be ill-conditioned (LDA
requires a matrix inversion), so we added a scaled identity matrix for regularization and robustness [78], choosing a relatively
high regularization of 0.75 relative to the dimension-normalized
trace of the covariance matrix. The linear discriminant weights
were computed from amplitudes in the same section as the waveform estimation (35 trials per class). The spatial patterns in the
remaining sections (total of 105 trials per class) were used for
testing. The feature value is the inner product between the linear discriminant and the amplitude patterns for each occurrence
during the two types of motor imagery (the mean was removed
and amplitude patterns occurring in the same trial were averaged). Classification was done based on the sign of the output.
A two-tailed Wilcoxon rank sum test was used to determine if
the medians of the resulting values differed between the classes
for each cluster and subject. The statistical significance cutoff
was set at 0.05 and a Bonferroni correction was applied to the
resulting p-values to accommodate for multiple testing of the
36 clusters: the original p-value needed to be less than 0.00139
to be deemed significant.
The single-trial classification accuracy for significant subjectwaveform pairs are shown along with the discriminant vector
(spatial weights) in Fig. 10. Subject “al” had the most discriminating patterns and is often reported to have the highest
single-trial classification rate in other cross-validation experiments. The highest classification rate occurred for waveforms
with peak frequency of 11 to 13 Hz (prototypes for clusters
2.4, 2.5, and 2.8), within the range of mu rhythms associated
with motor imagery. The differential spatial amplitude patterns
for the prototype of cluster 2.3 (peak frequency of 11 Hz, also
within the mu range) was deemed significant on four of the
five waveforms. This analysis highlights the possibility of using shift-invariant dictionary learning as an automatic feature
engineering tool for classifying the segments of EEGs.
VI. RELATION TO OTHER WORK
Learning the recurrent waveforms in EEG is a macroscopic
version of the modeling used for spike sorting; however, we are
not aided by any prior knowledge on the shape of the waveforms,
which makes the problem even more difficult than spike sorting.
Recent improvements in spike sorting methodologies are based
on allowing overlaps [61] and continuous shifts of waveforms
via approximations of translation operators [60]. It is possible
to improve the MP approximations used herein by allowing
continuous shifts.
The data-dependent decomposition, which shift-invariant dictionary learning provides, resembles the empirical mode decomposition (EMD). EMD is a model-free time-series analysis
technique [79] that has been applied to EEG [80]. The iterative
process of EMD is also similar to the multiscale approach we
have used. The benefits of our approach versus EMD are the estimate of the sources, in terms of the atomic decomposition, and
the learned waveforms, which can be used on novel segments
of the signal.

Fig. 10. Case study 2: Prototype waveforms, power spectral density, and spatial weight pattern corresponding to linear discriminate analysis between the
spatial amplitudes during two classes of motor imagery. In the color version
available online, purple and orange correspond to different signs of the weights.
The amplitude patterns were based on the originating electrode of the prototype waveform, which is circled on the originating subject. For a significant
waveform/subject pair, the percent accuracy over the testing set is listed. The
training/testing split was 70/210.

Learning waveforms and then analyzing their spatial extent
is complementary to spatial ICA, which finds spatially distinct
sources and then analyzes their time-frequency content or uses
a bank of band-passes filters to first separate the signals before
computing spatial ICA [19]. Working in the time domain enable
time-series decompositions to separate morphologically distinct
waveforms that may overlap in frequency before assessing their
spatial patterns.

BROCKMEIER AND PRÍNCIPE: LEARNING RECURRENT WAVEFORMS WITHIN EEGS

VII. CONCLUSION
With time-frequency analysis, it is difficult to separate components in EEG corresponding to waveforms with unique morphology. Previous studies have shown atomic decompositions
obtained by MP using dictionaries of waveforms to be useful
for this purpose [25], [27]–[30]. However, these methods do not
learn any model of the signal, and atomic decompositions on
disjoint sections are allowed to use completely different waveforms.
We model each component of an EEG channel as a convolution of a waveform with a sparse source, where the sparsity is
based on the assumption that in any given window only a few of
the sources are active. To learn this model, we apply algorithms
that learn data-dependent shift-invariant dictionaries [47], [53]–
[55]. The modeling constrains the same waveforms to reoccur
throughout the recording, with the shape of each waveform
adapted to the characteristics of the signal. Since only a small
number of waveforms are learned for each channel, the waveforms serve as data-dependent features and are useful for comparing channels, subjects, or conditions.
The results demonstrate that the estimation is consistently
able to learn waveforms that are specific to the morphology
of the signal. Waveforms estimated during different conditions
were distinguished both by their shape and frequency content.
For the multichannel datasets, the waveforms estimated over
different portions of the scalp differed in morphology and their
frequency content showed recognizable localizations. We highlighted how the spatial extent of the waveforms could be used
to distinguish between different types of motor imagery.
Automatically learning recurrent waveforms directly from
single-channel signals is a general unsupervised modeling approach. Coupled with appropriate meta-analysis such as clustering and spatial analysis, this method allows a researcher to
gain a better understanding of the phasic events and oscillations
inherent in EEG signals. For instance, this methodology can be
applied to analyze EEG segments with a large presence of phasic events such as EEGs during sleep or deep brain recordings
from the hippocampus.
ACKNOWLEDGMENT
The authors would like to thank S. Burke, A. Gunduz,
A. Maurer, and G. Philips for their insights.
REFERENCES
[1] E. D. Adrian and B. H. Matthews, “The Berger rhythm: Potential changes
from the occipital lobes in man,” Brain, vol. 57, no. 4, pp. 355–385, 1934.
[2] L. Ciganek, “The EEG response (evoked potential) to light stimulus in
man,” Electroencephalogr. Clin. Neurophysiol., vol. 13, no. 2, pp. 165–
172, 1961.
[3] G. Buzsáki and A. Draguhn, “Neuronal oscillations in cortical networks,”
Science, vol. 304, no. 5679, pp. 1926–1929, 2004.
[4] T. Sejnowski and O. Paulsen, “Network oscillations: Emerging computational principles,” J. Neurosci., vol. 26, no. 6, pp. 1673–1676, 2006.
[5] G. Buzsáki et al., “The origin of extracellular fields and currents—EEG,
ECoG, LFP and spikes,” Nature Rev. Neurosci., vol. 13, no. 6, pp. 407–
420, 2012.
[6] P. Nunez and R. Srinivasan, Electric Fields of the Brain: The Neurophysics
of EEG. New York, NY, USA: Oxford Univ. Press, 2006.
[7] X. Wang, “Neurophysiological and computational principles of cortical
rhythms in cognition,” Physiol. Rev., vol. 90, no. 3, pp. 1195–1268, 2010.

53

[8] W. J. Freeman, Mass Action in the Nervous System. New York, NY, USA:
Academic, 1975.
[9] H. Berger, “Über das elektrenkephalogramm des menschen,” Eur. Arch.
Psychiatry Clin. Neurosci., vol. 87, no. 1, pp. 527–570, 1929.
[10] L. A. Farwell and E. Donchin, “Talking off the top of your head: Toward
a mental prosthesis utilizing event-related brain potentials,” Electroencephalogr. Clin. Neurophysiol., vol. 70, no. 6, pp. 510–523, 1988.
[11] W. J. Freeman, “Origin, structure, and role of background EEG activity. Part 1. Analytic amplitude,” Clin. Neurophysiol., vol. 115, no. 9,
pp. 2077–2088, Sep. 2004.
[12] J. Gross, “Analytical methods and experimental approaches for electrophysiological studies of brain oscillations,” J. Neurosci. Methods,
vol. 228, pp. 57–66, 2014.
[13] J. C. Principe and A. J. Brockmeier, “Representing and decomposing
neural potential signals,” Curr. Opin. Neurobiol., vol. 31, pp. 13–17, 2015.
[14] D. J. Thomson, “Spectrum estimation and harmonic analysis,” Proc. IEEE,
vol. 70, no. 9, pp. 1055–1096, Sep. 1982.
[15] M. Unser and A. Aldroubi, “A review of wavelets in biomedical applications,” Proc. IEEE, vol. 84, no. 4, pp. 626–638, Apr. 1996.
[16] B. Babadi and E. Brown, “A review of multitaper spectral analysis,” IEEE
Trans. Biomed. Eng., vol. 61, no. 5, pp. 1555–1564, May 2014.
[17] S. Makeig et al., “Independent component analysis of electroencephalographic data,” in Adv. Neural Inf. Process. Syst., D. Touretzky et al., Eds.,
Cambridge, MA, USA: MIT Press, 1996, no. 8, pp. 145–151.
[18] S. Makeig et al., “Dynamic brain sources of visual evoked responses,”
Science, vol. 295, no. 5555, p. 690, 2002.
[19] J. Anemüller et al., “Complex independent component analysis of
frequency-domain electroencephalographic data,” Neural Netw., vol. 16,
no. 9, pp. 1311–1323, 2003.
[20] M. Zibulevsky and Y. Y. Zeevi, “Extraction of a source from multichannel data using sparse decomposition,” Neurocomputing, vol. 49, no. 1,
pp. 163–173, 2002.
[21] A. Delorme et al., “Independent EEG sources are dipolar,” PLoS ONE,
vol. 7, no. 2, p. e30135, 02 2012.
[22] M. Elad et al., “Simultaneous cartoon and texture image inpainting using morphological component analysis (MCA),” Appl. Comput. Harmon.
Anal., vol. 19, no. 3, pp. 340–358, 2005.
[23] J. Bobin et al., “Morphological component analysis: An adaptive thresholding strategy,” IEEE Trans. Image Process., vol. 16, no. 11, pp. 2675–
2681, Nov. 2007.
[24] S. Mallat and Z. Zhang, “Matching pursuits with time-frequency dictionaries,” IEEE Trans. Signal Process., vol. 41, no. 12, pp. 3397–3415,
Dec. 1993.
[25] P. Durka and K. Blinowska, “Analysis of EEG transients by means of
matching pursuit,” Annu. Biomed. Eng., vol. 23, no. 5, pp. 608–611, 1995.
[26] P. J. Durka et al., “Stochastic time-frequency dictionaries for matching pursuit,” IEEE Trans. Signal Process., vol. 49, no. 3, pp. 507–510,
Mar. 2001.
[27] P. Durka et al., “Multichannel matching pursuit and EEG inverse solutions,” J. Neurosci. Methods, vol. 148, no. 1, pp. 49–59, Oct. 2005.
[28] K. Blinowska, “Methods for localization of time-frequency specific activity and estimation of information transfer in brain,” Int. J. Bioelectromagn.,
vol. 10, no. 1, pp. 2–16, 2008.
[29] C. G. Bénar et al., “Pitfalls of high-pass filtering for detecting epileptic
oscillations: A technical note on “false” ripples,” Clin. Neurophysiol.,
vol. 121, no. 3, pp. 301–310, 2010.
[30] N. Jmail et al., “A comparison of methods for separation of transient
and oscillatory signals in EEG,” J. Neurosci. Methods, vol. 199, no. 2,
pp. 273–289, 2011.
[31] R. Kuś et al., “Multivariate matching pursuit in optimal Gabor dictionaries: Theory and software with interface for EEG/MEG via Svarog,”
Biomed. Eng. Online, vol. 12, no. 1, p. 94, 2013.
[32] D. Gabor, “Theory of communication. Part 1: The analysis of information,” J. Inst. Elect. Eng.-Part III: Radio Commun. Eng., vol. 93, no. 26,
pp. 429–441, 1946.
[33] S. S. Chen et al., “Atomic decomposition by basis pursuit,” SIAM J. Sci.
Comput., vol. 20, no. 1, pp. 33–61, 1998.
[34] A. Bell and T. Sejnowski, “Learning the higher-order structure of a natural
sound,” Network: Comput. Neural, vol. 7, no. 2, pp. 261–266, 1996.
[35] B. Olshausen et al., “Emergence of simple-cell receptive field properties
by learning a sparse code for natural images,” Nature, vol. 381, no. 6583,
pp. 607–609, 1996.
[36] B. A. Olshausen and D. J. Field, “Sparse coding with an overcomplete
basis set: A strategy employed by V1?” Vision Res., vol. 37, no. 23,
pp. 3311–3325, 1997.
[37] M. Lewicki, “Efficient coding of natural sounds,” Nature Neurosci.,
vol. 5, no. 4, pp. 356–363, 2002.

54

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 1, JANUARY 2016

[38] J. Mairal et al., “Online learning for matrix factorization and sparse
coding,” J. Mach. Learn. Res., vol. 11, pp. 19–60, 2010.
[39] I. Tosic and P. Frossard, “Dictionary learning,” IEEE Signal Process.
Mag., vol. 28, no. 2, pp. 27–38, Mar. 2011.
[40] C. James and D. Lowe, “Extracting multisource brain activity from a single
electromagnetic channel,” Artif. Intell. Med., vol. 28, no. 1, pp. 89–104,
2003.
[41] M. Davies and C. James, “Source separation using single channel ICA,”
Signal Process., vol. 87, no. 8, pp. 1819–1832, 2007.
[42] F. Lucena et al., “Statistical coding and decoding of heartbeat intervals,”
PLoS ONE, vol. 6, no. 6, p. e20227, 06 2011.
[43] T. Virtanen, “Separation of sound sources by convolutive sparse coding,”
in Proc. ISCA Tutorial Res. Work. Stat. Percept. Audio Process., pp. 55,
2004.
[44] T. Blumensath and M. Davies, “Sparse and shift-invariant representations
of music,” IEEE Trans. Audio, Speech, Language Process., vol. 14, no. 1,
pp. 50–57, Jan. 2006.
[45] E. Smith and M. Lewicki, “Efficient auditory coding,” Nature, vol. 439,
no. 7079, pp. 978–982, 2006.
[46] R. Grosse et al., “Shift-invariant sparse coding for audio classification,”
in Proc. 23rd Conf. Uncert. Artif. Intell., pp. 149–158, 2007.
[47] B. Mailhé et al., “Shift-invariant dictionary learning for sparse representations: Extending K-SVD,” presented at the 16th Eur. Signal Process.
Conf., Lausanne, Switzerland, 2008.
[48] B. Mailhé et al., “Dictionary learning for the sparse modelling of atrial
fibrillation in ECG signals,” in Proc. IEEE Int. Conf. Acoust. Speech Signal
Process., 2009, pp. 465–468.
[49] D. C. Balcan and M. S. Lewicki, “Point coding: Sparse image representation with adaptive shiftable-kernel dictionaries,” in Proc. Signal Process.
Adaptive Sparse Structured Representations, 2009.
[50] C. Ekanadham et al., “Recovery of sparse translation-invariant signals
with continuous basis pursuit,” IEEE Trans. Signal Process., vol. 59,
no. 10, pp. 4735–4744, Oct. 2011.
[51] Q. Barthelemy et al., “Shift & 2D rotation invariant sparse coding
for multivariate signals,” IEEE Trans. Signal Process., vol. 60, no. 4,
pp. 1597–1611, Apr. 2012.
[52] A. J. Brockmeier and J. C. Principe, “Explicit versus implicit source
estimation for blind multiple input single output system identification,”
in Proc. IEEE Int. Conf. Acoust. Speech Signal Process., 2015, pp. 2140–
2144.
[53] Q. Barthélemy et al., “Multivariate temporal dictionary learning for EEG,”
J. Neurosci. Methods, vol. 215, no. 1, pp. 19–28, 2013.
[54] M. Aharon, “Overcomplete dictionaries for sparse representation of signals,” Ph.D. dissertation, Faculty of Computer Science, Technion-Israel
Inst. Technol., Haifa, Israel, 2006.
[55] J. Thiagarajan et al., “Shift-invariant sparse representation of images
using learned dictionaries,” in Proc. IEEE Workshop Mach. Learn. Signal
Process., Oct. 2008, pp. 145–150.
[56] D. Charalampidis, “A modified k-means algorithm for circular invariant
clustering,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 27, no. 12,
pp. 1856–1865, Dec. 2005.
[57] Y. Ruiz et al., “A method to study global spatial patterns related to
sensory perception in scalp EEG,” J. Neurosci. Methods, vol. 191, no. 1,
pp. 110–118, Aug. 2010.
[58] A. J. Brockmeier et al., “Locating spatial patterns of waveforms during
sensory perception in scalp EEG,” in Proc. Annu. Int. Conf. IEEE Eng.
Med. Bio. Soc., Sep. 2012, pp. 2531–2534.
[59] M. Lewicki and T. Sejnowski, “Coding time-varying signals using sparse,
shift-invariant representations,” Adv. Neural Inf. Process. Syst., vol. 11,
pp. 730–736, 1999.
[60] C. Ekanadham et al., “Recovery of sparse translation-invariant signals
with continuous basis pursuit,” IEEE Trans. Signal Process., vol. 59,
no. 10, pp. 4735–4744, Oct. 2011.
[61] J. W. Pillow et al., “A model-based spike sorting algorithm for removing correlation artifacts in multi-neuron recordings,” PLoS ONE, vol. 8,
no. 5, p. e62123, 2013.
[62] C. Ekanadham et al., “A unified framework and method for automatic
neural spike identification,” J. Neurosci. Methods, vol. 222, pp. 47–55,
2014.
[63] J. C. de Munck et al., “A maximum-likelihood estimator for trial-totrial variations in noisy MEG/EEG data sets,” IEEE Trans. Biomed. Eng.,
vol. 51, no. 12, pp. 2123–2128, Dec. 2004.
[64] M. Zibulevsky and B. A. Pearlmutter, “Blind source separation by sparse
decomposition in a signal dictionary,” Neural Comput., vol. 13, no. 4,
pp. 863–882, 2001.
[65] J. A. Tropp, “Greed is good: Algorithmic results for sparse approximation,” IEEE Trans. Inf. Theory, vol. 50, no. 10, pp. 2231–2242, Oct. 2004.

[66] M. Aharon et al., “K-SVD: An algorithm for designing overcomplete
dictionaries for sparse representation,” IEEE Trans. Signal Process.,
vol. 54, no. 11, pp. 4311–4322, Nov. 2006.
[67] F. Harris, “On the use of windows for harmonic analysis with the discrete
Fourier transform,” Proc. IEEE, vol. 66, no. 1, pp. 51–83, Jan. 1978.
[68] C. Eckart and G. Young, “The approximation of one matrix by another of
lower rank,” Psychometrika, vol. 1, no. 3, pp. 211–218, 1936.
[69] N. Gillis and A. Kumar, “Exact and heuristic algorithms for seminonnegative matrix factorization,” SIAM J. Matrix Anal. Appl., vol. 36,
no. 4, pp. 1404–1424, 2015.
[70] N. Parikh and S. Boyd, “Proximal algorithms,” Found. Trends Optim.,
vol. 1, no. 3, pp. 127–239, 2014.
[71] O. Shalvi and E. Weinstein, “New criteria for blind deconvolution
of nonminimum phase systems (channels),” IEEE Trans. Inf. Theory,
vol. 36, no. 2, pp. 312–321, Mar. 1990.
[72] A. Hyvarinen, “Fast and robust fixed-point algorithms for independent
component analysis,” IEEE Trans. Neural Netw., vol. 10, no. 3, pp. 626–
634, May 1999.
[73] Y. Pati et al., “Orthogonal matching pursuit: Recursive function approximation with applications to wavelet decomposition,” in Proc. Conf. Rec.
26th Asilomar Conf. Signals Syst. Comput., 1993, pp. 40–44.
[74] S. Lloyd, “Least squares quantization in PCM,” IEEE Trans. Inf. Theory,
vol. 28, no. 2, pp. 129–137, Mar. 1982.
[75] T. Caliński and J. Harabasz, “A dendrite method for cluster analysis,”
Commun. Statist.-Theory, vol. 3, no. 1, pp. 1–27, 1974.
[76] R. G. Andrzejak et al., “Indications of nonlinear deterministic and finitedimensional structures in time series of brain electrical activity: Dependence on recording region and brain state,” Phys. Rev. E, vol. 64, no. 6,
p. 061907, 2001.
[77] B. Blankertz et al., “The BCI competition III: Validating alternative
approaches to actual BCI problems,” IEEE Trans. Neural Syst. Rehabil.
Eng., vol. 14, no. 2, pp. 153–159, Jun. 2006.
[78] J. H. Friedman, “Regularized discriminant analysis,” J. Amer. Statist. Assoc., vol. 84, no. 405, pp. 165–175, 1989.
[79] N. Huang et al., “The empirical mode decomposition and the Hilbert
spectrum for nonlinear and non-stationary time series analysis,” Proc.
Roy. Soc. London Ser. A, vol. 454, no. 1971, pp. 903–995, 1998.
[80] B. Mijović et al., “Source separation from single-channel recordings by
combining empirical-mode decomposition and independent component
analysis,” IEEE Trans. Biomed. Eng., vol. 57, no. 9, pp. 2188–2196,
Sep. 2010.
Austin J. Brockmeier (S’05–M’15) received the
B.S. degree in computer engineering from the University of Nebraska–Lincoln, Lincoln, NE, USA, in
2009 while attending the Peter Kiewit Institute in
Omaha, NE, USA. He received the Ph.D. degree in
electrical engineering from the University of Florida
in Gainesville, FL, USA, in 2014.
He is currently a Research Associate in the Department of Electrical Engineering and Electronics,
University of Liverpool, U.K. His research interests include signal and information processing, machine learning, and diverse applications of exploratory data analysis including
biomedicine and public health.

José C. Prı́ncipe (M’83–SM’90–F’00) received the
Ph.D. degree in electrical engineering from the University of Florida, Gainesville, FL, USA, in 1979.
He was a Professor at the University of Aveiro,
Portugal, from 1980 to 1987. He is currently a
BellSouth, Distinguished Professor of Electrical and
Biomedical Engineering, University of Florida where
he is the Founding Director of the University of
Florida Computational NeuroEngineering Laboratory. His research interests include advanced signal
processing and machine learning, brain–machine interfaces, and the modeling and applications of cognitive systems.
He is a Fellow of the ABME and AIBME. He is the past Editor-in-Chief
of the IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, the past Chair of
the Technical Committee on Neural Networks of the IEEE Signal Processing
Society, the Past-President of the International Neural Network Society, and
received the IEEE EMBS Career Award and the IEEE Neural Network Pioneer
Award.

