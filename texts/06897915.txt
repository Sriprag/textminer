986

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

A Novel ECG Data Compression Method Using
Adaptive Fourier Decomposition With Security
Guarantee in e-Health Applications
JiaLi Ma, TanTan Zhang, and MingChui Dong

Abstract—This paper presents a novel electrocardiogram (ECG)
compression method for e-health applications by adapting an adaptive Fourier decomposition (AFD) algorithm hybridized with a
symbol substitution (SS) technique. The compression consists of
two stages: first stage AFD executes efficient lossy compression
with high fidelity; second stage SS performs lossless compression
enhancement and built-in data encryption, which is pivotal for
e-health. Validated with 48 ECG records from MIT-BIH arrhythmia benchmark database, the proposed method achieves averaged
compression ratio (CR) of 17.6–44.5 and percentage root mean
square difference (PRD) of 0.8–2.0% with a highly linear and robust PRD-CR relationship, pushing forward the compression performance to an unexploited region. As such, this paper provides
an attractive candidate of ECG compression method for pervasive
e-health applications.
Index Terms—Adaptive Fourier decomposition (AFD), data encryption, electrocardiogram (ECG) compression, e-health, information security.

I. INTRODUCTION
HE ubiquitous deployment of the body sensor network
(BSN) and vigorous advance of information and communication technology (ICT) have dramatically fostered the e-health
development. With the aid of low cost portable or wearable
embedded-link devices, e-health provides the accessibility to
monitor and diagnose human wellness remotely and flexibly. In
implementing and improving pervasive e-health, bioinformatics
plays an important role through the management of biomedical
information acquisition, processing, storage, transmission, integration, and retrieval. Particularly, the storage, transmission, and
retrieval of massive bioinformation should meet several compulsory requirements: 1) high efficiency for rapid transmission
and prompt retrieval; 2) strict information security to guarantee users’ privacy; 3) high data fidelity to preserve the pathological information; and 4) affordable cost for the sustainable
storage.

T

Manuscript received October 9, 2013; revised June 13, 2014 and August 21,
2014; accepted September 5, 2014. Date of publication September 12, 2014;
date of current version May 7, 2015. This work was supported by the research
committee of University of Macau under Grant MYRG2014-00060-FST and
Science and Technology Development Fund (FDCT) of Macau Government
under Grant 016/2012/A1.
The authors are with Electrical and Computer Engineering Department,
Faculty of Science and Technology, University of Macau, Macau 999078,
China (e-mail: jimohanqiu@hotmail.com; tandyzhang11@hotmail.com; mcdong@umac.mo).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2357841

Yet, vast amount of biosignals generated by the long-term
e-health pose a huge threat and unaffordable burden to the
source-limited mobile devices regarding cost-effective storage,
economical rapid transmission, and timely retrieval feedback.
To address this problem, an e-health-oriented biosignals compression technique comes into play.
During the past several decades, various methods have been
proposed for electrocardiogram (ECG) compression, among
which lossy methods are preferred to lossless methods in pursuit of high compression ratio (CR) [1]. Existing ECG compression schemes can be roughly classified into direct, transform, and parameter extraction methods [2], where the first
two types are prevalent due to their reversibility. For transform
methods, the original signal is first decomposed by means of a
linear orthogonal transformation, and then, the expansion coefficients are properly encoded for further compression. The commonly used transform methods include Fourier transform [3],
Hermite transform [4], [5], discrete cosine transform (DCT) [6],
[7], Walsh transform [8], Karhunen–Loeve transform [9], and
wavelet transform [10]–[17].
Despite their performance in data volume reduction, several
challenges arise accordingly. First, most transform methods require preprocessing (i.e., wave detection and/or beat segmentation) before compression, which leads to increased computation and might degrade the compression performance once
incorrect preprocessing occurs. Second, the expansion basis is
predetermined in general, which would limit the compression
performance intrinsically. Third, since the compressed ECG signals still expose some of the crucial ECG features [18], [19],
there exist risks of information disclosure and malicious abuse
by an unauthorized person with knowledge of the compression
mechanism.
Tackling these bottleneck problems, this paper presents a
novel transform compression method based on an adaptive
Fourier decomposition (AFD) algorithm hybridized with a symbol substitution (SS) technique. AFD has already been exploited
and validated for signals decomposition in Hardy H 2 and Hilbert
L2 space [20]. This study is the first attempt to adapt the AFD
algorithm for real-valued ECG compression. Unlike most transform methods, AFD relieves the requirement of preprocessing
and generates input-dependent basis adaptively to achieve high
efficiency and fidelity. Afterwards, the AFD compression results
are encoded losslessly using a SS technique to enhance CR while
maintain the reconstruction quality. Here, SS also serves the purpose of built-in encryption simultaneously. In all, the proposed
method provides an alternative for ECG compression with high

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

MA et al.: NOVEL ECG DATA COMPRESSION METHOD USING ADAPTIVE FOURIER DECOMPOSITION WITH SECURITY GUARANTEE

Fig. 1.

987

Compression and decompression procedures of the proposed method.

compression efficiency, reconstruction fidelity, and information
security.
Rest of this paper is organized as follows. Section II introduces the proposed method in detail. In Section III, the method
is validated by employing MIT-BIH arrhythmia benchmark
database and the results are listed out. Comparisons and discussions are given in Section IV and V, respectively. Finally,
Section VI concludes this paper.
II. METHOD
AFD is the generalization of the conventional Fourier decomposition method combined with the greedy algorithm to
expand input signal into a series of monocomponents in the
modified Takenaka–Malmquist (TM) system [20]. By pursuing maximal energy gain in each decomposition iteration, AFD
generates tailor-made input-dependent basis adaptively. Hence,
several advantageous features are highlighted in AFD: 1) fast
convergence in both energy and point-wise sense; 2) efficient
computing time; and 3) robustness [20]. Benefit from these merits, AFD possesses wide applicability for multifarious signals
decomposition as well as the potential for efficient data compression in e-health oriented applications.
Fig. 1 depicts the procedures of ECG compression and decompression using the proposed method. The compression consists of two stages. The first stage carries out Hardy projection
and AFD lossy compression, followed by the lossless encoding
using the SS technique in the second stage. Here, SS fulfills
built-in data encryption simultaneously to guarantee information security of the compression results. For the decompression,
it is the inverse process of compression and possesses quite low
computation complexity with simple calculations.
A. Mathematical Foundation of AFD Algorithm
AFD is based on the modified TM system {Bn } as follows:

n −1
1 − |an |2  z − ak
1
, n = 1, 2, . . . (1)
Bn (z) = √
1 − āk z
2π 1 − ān z
k =1

where an is a complex number adaptively selected inside the
open unit disk D(D = {z ∈ C : |z| < 1}), C denotes the complex plane, and z is the boundary of D defined as z = exp(it),
t ∈ [0, 2π). For any {an } sequence in D, the modified TM system {Bn } is proved to be orthogonal. In particular, taking all

an ’s to be 0 gives rise to a Fourier system. The modified TM
system distinguishes itself in selecting an adaptively according
to input signals rather than utilizing prescribed {an } sequence
in the traditional TM system. Hence, the system is capable of
catering to various kinds of signals including ECG signals.
AFD conducts expansion of signals from H 2 and L2 space
into weighted Bn components. For real-valued signal G decomposition, it should be first projected into H 2 space to get the
corresponding projection signal G+ . Afterwards G+ will be
decomposed as
G+ (z) =

∞


Cp Bp (z)

(2)

p=1

where Cp is the pth coefficient of basis Bp . A complete expansion includes the calculation of coefficient Cp and the selection
of ap in basis Bp under the principle of greedy algorithm [20].
Since AFD endeavors to obtain the maximal energy gain at each
iteration, a set of evaluators {ea } consisting of the elementary
functions in the following equation are employed to facilitate
computation and evaluate energy gain during decomposition.

1 − |a|2
1
, a ∈ D.
(3)
ea (z) = B1 (z) = √
2π 1 − āz
.
The first expansion starts with representation of G+ as G1 ,
and C1 is obtained by calculating inner product between G1 and
ea 1 in the following equation:
√ 
C1 = G1 , ea 1  = 2π 1 − |a1 |2 G1 (a1 ) , a1 ∈ D (4)
where a1 is selected according to the maximal projection principle (MPP) as in (5) that, for any G1 ∈ H 2 there exists a1 in
D such that energy |C1 |2 is maximal.
a1 = arg max(|C1 |2 ) = arg max(| G1 , ea  |2 )
= arg max{2π(1 − |a|2 · |G1 (a)|2 ), a ∈ D}.

(5)

Here, the result after the first decomposition is
G1 = G1 , ea 1  ea 1 + r1

(6)

where r1 is the intermediate remainder and is used for deduction
of G2 = r1 (1 − ā1 z)/(z − a1 ), which is still in H 2 . Then, call
the same process to decompose G2
G2 = G2 , ea 2  ea 2 + r2

(7)

988

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

where a2 is selected under the MPP as well. Until now, the
original item G1 has been decomposed into two weighted basis
components as
G1 = G1 , ea 1  B1 + G2 , ea 2  B2 + r2

z − a1
.
1 − ā1 z

(8)

Similarly, rewrite r2 to get G3 = r2 (1 − ā2 z)/(z − a2 ) and
carry on the third decomposition. After N times iterations (N
denotes the decomposition times), G1 can be derived as
G1 =

N


Gk , ea k  Bk + GN +1

k =1

=

N


N

z − ak
1 − āk z

k =1

Ck Bk + R

(9)

k =1

where R is the total remainder after N times decomposition and
ak is selected according to the MPP as
ak = arg max(|Ck |2 ) = arg max(| Gk , ea  |2 )
= arg max{2π(1 − |a|2 · |Gk (a)|2 ), a ∈ D}.

(10)

The reconstruction of G+ is denoted as G+
r , which is obtained
by omitting the total remainder R in (9). Afterwards, G+
r is back
projected to obtain the reconstruction of original real-valued
signal Gr using


N
+
Gr = 2Re(Gr ) − C0 = 2Re
Ck Bk − C0 (11)

Fig. 2.

Implementation procedures of AFD for real-valued ECG compression.

k =1

where C0 is the zeroth Fourier coefficient of G.
From (9) and (11), it is clear that the difference between G
and Gr is induced by the remainder R. As decomposition times
N increases, R becomes smaller and the difference between G
and Gr reduces as well. In addition, with the increase of signal
frequency, more decomposition times are required under the
same criterion of R.
B. AFD Implementation and Modification
Fig. 2 illustrates the implementation procedures of AFD for
real-valued ECG compression in detail. First, the input realvalued signal G is projected to H 2 space for projection G+ . A
group of {a} set consisting complex points in unit disk D is
generated to form evaluators set {ea } in (3). Second, the decomposition of G+ starts based on the modified TM system in
(1). During each decomposition, the MPP is conformed in the
selection of an as in (10) with the aid of evaluators to generate
input-dependent basis consecutively and adaptively. Since MPP
helps to obtain the maximal energy gain throughout decomposition, only a few decomposition terms are required to reconstruct
the input signal effectively. Afterwards, a group of coefficients
Cn and basis Bn are obtained as the compression results. In other
words, for N decomposition times, 2N parameters are attained
after AFD compression. Finally, these compression items are
weighted summed and back projected to get the reconstructed
real-valued signal as in (11).
Since {an } sequence is adaptively generated according to input signals, it is of much interest to see the distributions of an

Fig. 3. {an } sequence distribution of 24 ECG records in open unit disk D
(distinct by colored shapes).

in ECG compression. A total of 24 random ECG records from
MIT-BIH arrhythmia benchmark database are employed for investigation. It is found that almost all the an ’s of 24 records
are distributed near the edge of D as shown in Fig. 3. This
phenomenon implies that the generated {a} set with uniform

MA et al.: NOVEL ECG DATA COMPRESSION METHOD USING ADAPTIVE FOURIER DECOMPOSITION WITH SECURITY GUARANTEE

989

is only replaced by a simplified symbol without changing its
absolute value. In all, the adapted SS technique caters to the
demand of further lossless compression with low complexity.
It is noteworthy that with a predefined number of elements in
{an } sequence, the number of components contained in {a} set
(denoted as Na ) determines the compression efficiency of SS.
The decrease of Na will increase the compression efficiency. In
extreme case, if Na is equal to one, only one bit is demanded
for the substitution.
D. Built-in Data Encryption
Fig. 4. {a} set with different distributions in open unit disk D. (a) Uniformly
distributed set. (b) Modified nonuniformly distributed set.

distribution will result in unnecessary extra storage and computation as most points in inner disk will not be selected in
{an } sequence. To address this problem, a strategy of generating nonuniformly distributed {a} set in D is exploited. In
implementation, a layered structure with two different distributions in {a} set is adapted. Parameters din and dout represent
the shortest distance between adjacent points in inner disk {y ∈
<
D|0 <
= |y| = 0.95} and outer circle {y ∈ D|0.95 < |y| < 1}, respectively. Longer distance din is set in the inner disk and shorter
distance dout is chosen in outer circle of D. Fig. 4 illustrates
two differently distributed {a} sets intuitively. The modified
nonuniformly distributed {a} set in Fig. 4(b) is much more efficient and practical than the original uniformly distributed one
in Fig. 4(a).
C. Lossless Encoding With SS Technique
After AFD compression, though the number of parameters
are much less than input samples, these parameters still occupy
large space in storage and transmission since {an } are complex
numbers with long decimal places. To solve such problems, a lot
of techniques have been proposed to encode the decomposition
results, such as set partitioning in hierarchical trees [1], [13],
[14], entropy encode [7], [21]–[23], etc. In this paper, the SS
technique [19] is adapted for {an } encoding due to its simplicity
and comprehensibility. The basic concept of SS is to represent
symbol of long bits with symbol of short bits.
From Fig. 4(b), it can be seen that {a} set is fixed if both
din and dout are determined. Based on this, the SS technique
is adapted to represent an with its sequence number in the
fixed {a} set to achieve lossless compression of {an } sequence.
The idea can be illustrated by the following example. Suppose a sequence {a1 , a2 , . . . , a10 } is selected out from the
set {a1 , a2 , . . . , a128 } in which each a occupies long decimal
places. The direct storage of {an } sequence by reserving only
two decimal places requires more than 10 × 16 bits (15 bits for
decimal places and 1 for signs) with extra rounding error accordingly. Nevertheless, by using the SS technique only 10 × 7
bits (128 = 27 ) are involved to represent the {an } sequence,
resulting in a volume reduction of up to 56.25% compared with
the direct storage. More importantly, SS is lossless since {an }

Apart from shrink of data volume, a critical issue in data
compression is the offered privacy level of compressed signals,
especially for e-health applications. Though the compressed
signals are somewhat coded, data security is still challenged
once the compression technique is disclosed. As a result, data
encryption should be imposed on the compressed signals. Yet,
few compression methods take information security into consideration or they require extra encryption mechanism, which
could be conventional mechanisms (e.g., Advanced Encryption
Standard, Data Encryption Standard) or dedicated encryption
methods (e.g., [17] and [18]) to code the compressed signals.
In [17], an ECG encryption algorithm is presented and 25%
data are required for encryption, whereas in [18] only 1%
data are encrypted. Nevertheless, excess computation and errors will be brought in. In the proposed method, SS serves the
purpose of lossless compression and built-in data encryption
simultaneously.
During compression, SS encodes {an } sequence referring
to the encoding table of {a} set. A correct encoding table is
essential for accurate signal reconstruction; otherwise, the compressed results become indecipherable and useless. In e-health
system, each user is facilitated with an encoding table provided
by the server, and the table is secreted to realize data encryption.
Furthermore, data security among users is independent since the
table is randomly generated by permutation and varies from user
to user.
Assume the number of elements in {a} set is 1024 (Na =
1024), and an ECG segment is compressed with 33 decompositions (N = 33). Thus, a random permutation of {a} set will
result in Na ! = 1024! encoding tables. Once the compressed
signal is disclosed, the possibility of finding the right table is
1/1024!, which approaches zero. A brute-force attack needs to
search NaN = 102433 combinations before accessing the correct reconstructed signal, and the possibility of success attack is
1/102433 ≈ 4.57 × 10−100 , which is close to zero as well.
III. EXPERIMENTS
A. Experiment Settings
All 48 ECG records of lead I in full length taken from
MIT-BIH arrhythmia benchmark database are employed in the
experiments. These ECG signals are sampled at frequency of
360 Hz with resolution of 11 bits. Each record is separated
into contiguous and nonoverlapping windows for compression.
The window size should be well designed to meet the practical

990

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

requirements of buffer delay time, which is crucial in real-time
applications. Based on the e-health proposed in [5] and [24], a
length of 2000 instances per window is selected and the buffer
delay time is about 5.5 s accordingly. For applications requiring
shorter delay time, a smaller window size should be chosen.
Unlike the segmentation in most transform compression methods, here is merely to select a length of samples without the
need of ECG preprocessing such as beat/wave detections. To
ensure accuracy, the values in following tables are obtained via
averaging the results from each window for individual record.
B. Performance Measure
With respect to compression evaluation, there are three major
concerns, i.e., compression efficiency, reconstruction quality,
and computation complexity [25]. The aforementioned three
factors are correlated and should be considered inclusively in
practical implementation.
1) Compression Efficiency: The compression efficiency is
evaluated by CR and compressed data rate (CDR). CR measures the ratio between bits of original signal bo and bits of
reconstructed signal br as indicated in (12). CDR can be derived
from CR under fixed sampling frequency Fs and resolution Res
as shown in (13). Larger CR and smaller CDR are desired for
higher compression efficiency.
CR =

bo
br

(12)

Fs × Res
.
(13)
CR
2) Reconstruction Quality: For reconstruction quality assessment, there are mainly two types of indices, the diagnostic and
mathematical. The diagnostic criteria such as mean-opinion
score and weighted diagnostic distortion [26] can directly reflect the diagnostic distortion induced by compression. However, they are not widely used since the calculations are complicated or time consuming. The mathematical criteria evaluate
the energy difference between original and reconstructed signals
and are extensively accepted for less computation despite their
poor relationship with diagnostic distortion. For the sake of fair
and thorough comparison with other methods, several prevalent
mathematical indices are employed in this paper.
1) Root mean square (RMS) error defined in the following
equation measures the difference between the original signal f and reconstructed signal g with signal length L.

(f − g)2
.
(14)
RMS =
L−1
CDR =

2) Percentage RMS difference (PRD) defined in the following equation is more related to reconstruction quality than
RMS.
	
(f − g)2
× 100%.
(15)
PRD =
f2
Both PRDN and PRDB are the normalized versions of
PRD by subtracting mean value fm and baseline, respectively, from the original signal as in (16) and (17). The

TABLE I
NONUNIFORMLY DISTRIBUTED {a} SET
BCL (bits)
9
10
11
12

d i n {0 <
= |y | <
= 0.95}

d o u t {0.95 < |y | < 1}

0.09
0.14
0.1
0.1

0.045
0.01875
0.015
0.01

subtraction of offsets makes PRDN and PRDB free from
the effects of dc-level and baseline values. The detailed relationship between PRD, PRDN, and PRDB can be found
in [27].
	
(f − g)2
PRDN =
× 100%
(16)
(f − fm )2
	
(f − g)2
× 100%.
(17)
PRDB =
(f − baseline)2
3) Signal to noise ratio (SNR) is represented as


(f − fm )2
SNR = 10 × lg
.
(f − g)2

(18)

4) Quality score (QS) reflects the tradeoff between compression efficiency and reconstruction quality as shown in the
following equation:
QS =

CR
.
PRD

(19)

C. Parameter Optimization
In the proposed compression method, Na and the decomposition times N determine the compression performance. Hence,
the values of Na and N should be set appropriately to obtain
an optimum performance. The hints of parameter optimization
are offered here when applying the method for ECG compression. According to the mathematical foundation in Section II-A,
as the increase of Na and N, R reduces and the reconstruction
quality becomes better but the compression efficiency drops
as a compromise. To achieve a proper tradeoff between quality and efficiency, several sets of ECG records from MIT-BIH
arrhythmia benchmark database are randomly selected to aid
the investigation. First, a series of nonuniformly distributed {a}
sets with different Na are generated and the parameter settings of
din and dout are shown in Table I. Since the binary code length
(BCL) of Na is what really matters rather than Na itself, Table I
only lists out the BCL of each {a} set. Under the changed BCL,
a group of relationships of PRD and CR against various N are
obtained and plotted in Fig. 5. For better understanding, y-axis
on left side in the figure is the value of (100-PRD)%, which can
directly reflect the fidelity of reconstructed signals. High CR and
high fidelity are desirable. We can see that with the increase of
N, CR decreases and the fidelity improves regardless of the BCL
value of Na . This scenario is consistent with the generic tradeoff
between CR and fidelity in data compression. For each fixed N,
CR will decline in accord with the growing BCL from 9 bits to

MA et al.: NOVEL ECG DATA COMPRESSION METHOD USING ADAPTIVE FOURIER DECOMPOSITION WITH SECURITY GUARANTEE

991

TABLE II
COMPRESSION RESULTS OF ALL 48 ECG RECORDS (N = 33, CR = 25.64)
Record

Fig. 5.

Relationships of PRD and CR against various N and BCL of N a .

12 bits. In general, the optimization strategy is to minimize both
BCL and N to maximize CR under a specified fidelity. Given a
fidelity requirement of higher than 99% as highlighted in Fig. 5,
the optimized BCL and N are 10 and 33, respectively. These
optimized values are utilized in the following experiments.
D. Experimental Results
Experimental results of all 48 ECG records with the optimized
Na and N are listed in Table II. For all the signals, CR after two
stages compression is equal to 25.64 and the enhancement of
CR is calculated up to 23% with the SS technique, meanwhile
the fidelity is retained since SS compression is lossless. The
achieved PRD is 1.05% on average with a standard deviation of
0.57%, which reveals that the proposed method is suitable for a
variety of ECG signals.
Since the listed mathematical measurements in Table II fail
to reflect the reconstruction quality in clinical aspects, several
record examples are given in Fig. 6 for visual validation, including typical record 119, record 213 with the worst PRD, and
record 232 with worst-case PRDN in Table II. For each record,
waveforms of the original, reconstructed, and error signals are
depicted with length of 2000 samples, and the former two signals are separated deliberately for easy inspection. We observe
that in Fig. 6(a), only 25 decomposition items are required to
reconstruct record 119 with tiny distortion and high CR. While
for record 213 in Fig. 6(b), CR is sacrificed in pursuit of better reconstruction with N = 55. The main reason is that record
213 has higher heart rate (110 bpm) than most other signals.
The detailed explanation will be given in Section V. In Fig. 6(c),
the reconstructed signal well preserves the diagnostic features
in the original signal despite of poor PRDN, which is supposed
to be the result of noise smoothing. Altogether, the results shown
previously validate the high efficiency and fidelity of the proposed method.
In Table III, the extended results with various N are listed.
With an increase in N, the compression efficiency is reduced
and the reconstruction quality is enhanced. As N is 22, the averaged PRD is 1.71% and the achieved CR is up to 38.46. QS
is an index to quantify the overall compression performance,
considering both compression efficiency and error rate [25].
A high and stable QS represents a good compression perfor-

100
101
102
103
104
105
106
107
108
109
111
112
113
114
115
116
117
118
119
121
122
123
124
200
201
202
203
205
207
208
209
210
212
213
214
215
217
219
220
221
222
223
228
230
231
232
233
234
Averaged
Std.

PRD (%)

PRDN (%)

RMS

SNR

0.57
0.51
0.81
0.91
1.19
0.91
1.03
2.58
0.61
1.42
0.72
0.84
0.60
0.54
0.86
2.26
0.62
2.00
1.17
0.51
1.41
0.60
0.85
1.00
0.54
0.33
2.22
0.64
0.51
1.18
1.21
0.61
1.64
2.90
0.82
1.25
1.49
1.20
0.97
0.64
0.62
1.03
0.97
1.24
0.89
0.75
1.78
0.63
1.05
0.57

16.18
12.87
22.26
14.40
22.20
15.51
13.86
14.89
18.71
15.73
19.45
18.73
6.85
26.97
11.84
15.51
11.23
22.81
10.77
9.92
16.82
8.60
9.63
12.01
12.99
7.70
23.80
16.96
7.65
11.57
24.53
12.33
26.42
24.50
9.34
27.13
14.23
12.09
14.16
10.41
23.68
11.98
26.65
17.07
14.83
29.48
15.90
11.57
16.14
6.01

0.12
0.11
0.18
0.20
0.26
0.20
0.23
0.57
0.13
0.31
0.16
0.16
0.13
0.12
0.18
0.42
0.12
0.37
0.22
0.10
0.27
0.11
0.17
0.22
0.12
0.08
0.50
0.14
0.11
0.26
0.27
0.14
0.37
0.61
0.18
0.28
0.34
0.24
0.20
0.14
0.14
0.21
0.21
0.27
0.20
0.17
0.39
0.15
0.22
0.12

15.71
17.75
12.82
16.73
12.85
16.07
17.07
16.45
14.40
15.96
14.07
14.40
23.27
11.06
18.47
16.09
18.94
12.61
19.31
20.02
15.37
21.28
20.29
18.35
17.68
22.23
12.21
15.28
22.30
18.68
11.95
18.12
11.25
11.95
20.56
11.01
16.84
18.29
16.90
19.60
12.28
18.37
11.17
15.22
16.48
10.23
15.87
18.68
16.30
3.34

mance. As seen in Table III, QS’s against different N are all
around 30, which reflects the linear PRD-CR relationship and
the robustness for varying compression efficiency. Table III also
gives the computation time with different N to assess the computation complexity of the proposed method. For processing
5.5 s of ECG signals, the compression time is less than 0.5 s,
while the decompression time is within dozen of milliseconds.
As mentioned in [20], the complexity of AFD is comparable
with discrete Fourier transform, thus it is believed that the algorithm is adequate to satisfy the complexity requirement in the
specified application environment [5], [24]. From Table III, we
also observe that with the increase of N, PRD decreases and

992

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

TABLE III
PERFORMANCE OF 48 ECG RECORDS WITH DIFFERENT N
N
CR
CDR (bps)
PRD (%)
PRDN (%)
RMS
SNR
QS
Comp. time (s)∗
Decomp. time (s)∗
∗

22

25

30

33

38

47

38.46
102.96
1.71
25.74
0.36
12.01
29.08
0.337
0.011

33.85
117.00
1.47
22.34
0.31
13.35
29.38
0.345
0.013

28.21
140.40
1.18
18.10
0.25
15.27
30.01
0.384
0.015

25.64
154.44
1.05
16.14
0.22
16.30
30.51
0.411
0.016

22.27
177.84
0.91
13.89
0.19
17.61
30.36
0.471
0.018

18.00
219.96
0.80
12.19
0.17
19.05
29.46
0.498
0.023

Operated on Pentium 1.7 GHz 512M RAM CPU.

TABLE IV
COMPARISON WITH [7] FOR RECORD 100, 117, AND 119
Algorithm
S. J. Lee et al. [7]
S. J. Lee et al. [7]
Proposed
Proposed
S. J. Lee et al. [7]
S. J. Lee et al. [7]
S. J. Lee et al. [7]
S. J. Lee et al. [7]
S. J. Lee et al. [7]
Proposed
Proposed
S. J. Lee et al. [7]
S. J. Lee et al. [7]
S. J. Lee et al. [7]
Proposed

Parameter

Record

CR

PRD (%)

50% window size
20% window size
N = 55
N = 36
80% window size
50% window size
40% window size
30% window size
20% window size
N = 51
N = 34
50% window size
40% window size
20% window size
N = 36

100
100
100
100
117
117
117
117
117
117
117
119
119
119
119

9.6
23
15.4
23.5
7
10.4
12.6
16.5
24.43
16.59
24.88
8.5
10.3
19.31
23.50

0.44
1.94
0.29
0.51
0.34
0.42
0.43
0.61
1.17
0.41
0.60
0.44
0.59
2.05
1.09

Fig. 6. Waveforms of original, reconstructed, and error signals. (a) Record
119 (N = 25, CR = 39.21, PRD = 1.61%, PRDN = 14.78%). (b) Record
213 (N = 55, CR = 17.58, PRD = 1.66%, PRDN = 14.01%). (c) Record 232
(N = 33, CR = 29.53, PRD = 0.75%, PRDN = 29.48%).

the computing time rises, which indicates the tradeoff between
complexity and reconstruction quality.
IV. COMPARISON
The proposed method is compared with other known ECG
compression methods in two scenarios. One is the particular
comparison with method in [7] and the other is to benchmark
with the state-of-the-art methods.
Since the method presented in [7] is one of the latest works for
e-health and is based on transform as well, we have implemented
the algorithm and made a fair comparison with it using identical
indices. The compression results of 48 ECG records listed in
Table II are superior to that in [7]. With the typical records
100, 117, and 119, the comparison results are given in Table IV
in detail. For the same record, the proposed method exhibits
lower PRD while maintaining similar or even higher CR. As

Fig. 7.

Comparison of PRD-CR curve with other methods.

[7] targets at real-time applications, we also studied the delay
time for both methods and obtained comparable results. For
instance, in compressing a cycle of 290 samples from record
111, the proposed method and that in [7] achieve a delay of
0.861 and 0.932 s, respectively.
Benchmarking with the state-of-the-art compression methods
in [7], [14]–[16], [22], and [28], this study succeeds in relaxing the tradeoff between PRD and CR by developing a novel
compression method based on AFD. Fig. 7 plots the PRD-CR

MA et al.: NOVEL ECG DATA COMPRESSION METHOD USING ADAPTIVE FOURIER DECOMPOSITION WITH SECURITY GUARANTEE

993

TABLE V
EVALUATION FACTORS OF ECG SIGNALS WITH DIFFERENT HEART RATES
Heart Rate Range
< 60
60–100
> 100

PRD (%)

PRDN (%)

PRDB (%)

RMS

SNR

0.64
1.04
1.87

14.88
15.81
20.58

8.36
10.84
18.34

0.14
0.22
0.41

17.58
16.31
13.94

TABLE VI
COMPRESSION PERFORMANCE OF RECORD 213 WITH DIFFERENT N
N

Fig. 8.

Reconstruction error under different heart rates.

relations of different compression methods cited from transactions on biomedical engineering. The method in [28] is a direct
compression method and [7], [14]–[16], and [22] are transform
compression methods, in which [7] is based on DCT, [14]–
[16] are based on discrete wavelet transform, and [22] is based
on wavelet packets. In Fig. 7, the averaged results of 48 ECG
records, dataset 1 (consisting 10 min of data from record 100,
101, 102, 103, 107, 109, 111, 115, 117, 118, and 119), and
dataset 2 (consisting 1 min of data from record 104, 107, 111,
112, 115, 116, 117, 118, 119, 201, 207, 208, 209, 212, 213, 214,
228, 231, and 232) are collected separately, which are distinct
with line styles. It is obvious that this study pushes forward
the compression performance to an unexploited region, where
lower PRD and higher CR are achieved. Typically, CR is around
20, while PRD is less than 1%. When CR even reaches as high
as 40, PRD is kept less than 2%. Moreover, the feature of linear
PRD-CR relationship makes the proposed method superior to
the state-of-the-art.
V. DISCUSSION: EFFECT OF HEART RATE
Seen from the experimental results in Section III-D, record
213 with higher heart rate displays the highest PRD. The reason is that the decomposition times N is selected for the vast
majority of ECG signals with normal heart rates and unsuitable
for record 213, inducing higher PRD. As a result, higher N is
required for PRD reduction. In order to quantitatively discuss
the effect of heart rate on compression performance, test vectors
of 5-min ECG signals from 48 records are selected for investigation. These signals are categorized into three groups in terms
of heart rate, i.e., less than 60 bpm, 60–100 bpm, and more
than 100 bpm. Afterwards, these signals are compressed with
the optimized parameters, and the performance of each group
is shown in Fig. 8 and Table V. With the growth of heart rate,
the reconstruction error becomes more apparent. Especially for
higher heart rate signals, the values of PRD, PRDN, and PRDB
are extremely larger than the other two groups. In conclusion,
ECG signals with larger heart rates achieve much worse reconstruction quality than signals with normal or lower heart rates
when the decomposition times is fixed.

CR
PRD (%)

33

36

40

46

53

25.64
2.90

23.50
2.56

21.15
2.27

18.39
1.99

15.97
1.72

One possible solution to mitigate the heart rate effect is to
increase N and PRD falls correspondingly, yet at the cost of
compression efficiency reduction. The detailed performance of
record 213 with different N is listed in Table VI. As N is larger
than 46, PRD is less than 2%, while CR drops to 18.39.
The results of record 213 inspire us to set up personalized
parameters for users with different heart rates. In embedded
e-health applications, the optimized parameters N and Na are
set as the initial values, which are suitable for most users. At
the beginning of use, users are required to input their heart
rates, after that the system will make adjustment according to
the input values. For those with extremely high heart rates, the
decomposition order will be accordingly increased to guarantee
the reconstruction quality comprehensively.
VI. CONCLUSION
A novel ECG compression method for e-health applications
using an AFD algorithm hybridized with the SS technique is
presented. The contributions include: 1) first investigation of
applying the AFD algorithm to ECG compression; 2) using
SS to realize lossless compressing and built-in data encryption;
3) achieving linear and robust PRD-CR relationship and pushing forward the compression performance. Validated with 48
ECG records from MIT-BIH arrhythmia benchmark database,
the proposed method outperforms the prior works, being an attractive candidate for effective and efficient data compression
in e-health.
REFERENCES
[1] A. Alesanco and J. Garcia, “Automatic real-time ECG coding methodology guaranteeing signal interpretation quality,” IEEE Trans. Biomed.
Eng., vol. 55, no. 11, pp. 2519–2527, Nov. 2008.
[2] S. M. S. Jalaleddine, C. G. Hutchens, R. D. Strattan, and W. A. Coberly,
“ECG data compression techniques—A unified approach,” IEEE Trans.
Biomed. Eng., vol. 37, no. 4, pp. 329–343, Apr. 1990.
[3] B. R. S. Reddy and I. S. N. Murthy, “ECG data compression using Fourier
descriptors,” IEEE Trans. Biomed. Eng., vol. 33, no. 4, pp. 428–434,
Apr. 1986.
[4] P. Laguna, R. Jane, S. Olmos, N. V. Thakor, H. Rix, and P. Caminal,
“Adaptive estimation of QRS complex by the Hermite model for classification and ectopic beat detection,” Med. Biol. Eng. Comput., vol. 34,
no. 1, pp. 58–68, 1996.

994

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

[5] J. L. Ma, Y. L. Cui, and M. C. Dong, “An effective low-complexity multivital-signs compression technique for embedded-link e-home healthcare,”
in Proc. IEEE Int. Conf. Med. Biol., Jul. 2013, pp. 1177–1181.
[6] N. Ahmed, P. J. Milne, and S. G. Harris, “Electrocardiographic data compression via orthogonal transforms,” IEEE Trans. Biomed. Eng., vol. 22,
no. 6, pp. 484–487, Nov. 1975.
[7] S. J. Lee, J. Kim, and M. Lee, “A real-time ECG data compression and
transmission algorithm for an e-health device,” IEEE Trans. Biomed. Eng.,
vol. 58, no. 9, pp. 2448–2455, Sep. 2011.
[8] W. S. Kuklinski, “Fast Walsh transform data compression algorithm: ECG
applications,” Med. Biol. Eng. Comput., vol. 21, no. 4, pp. 465–472,
Jul. 1983.
[9] S. Olmos, M. Millan, J. Garcia, and P. Laguna, “ECG data compression
with the Karhunen-Loeve transform,” in Proc. Comput. Cardiol., 1996,
pp. 253–256.
[10] M. L. Hilton, “Wavelet and wavelet packet compression of electrocardiograms,” IEEE Trans. Biomed. Eng., vol. 44, no. 5, pp. 394–402, May
1997.
[11] A. Djohan, T. Q. Nguyen, and W. J. Tompkins, “ECG compression using
discrete symmetric wavelet transform,” in Proc. Int. Conf. IEEE Med.
Biol., Sep. 1995, pp. 167–168.
[12] J. Chen and S. Itoh, “A wavelet transform-based ECG compression method
guaranteeing desired signal quality,” IEEE Trans. Biomed. Eng., vol. 45,
no. 12, pp. 1414–1419, Dec. 1998.
[13] S. C. Tai, C. C. Sun, and W. C. Yan, “A 2-D ECG compression method
based on wavelet transform and modified SPIHT,” IEEE Trans. Biomed.
Eng., vol. 52, no. 6, pp. 999–1008, Jun. 2005.
[14] Z. Lu, D. Y. Kim, and W. A. Pearlman, “Wavelet compression of ECG
signals by the set partitioning in hierarchical trees algorithm,” IEEE Trans.
Biomed. Eng., vol. 47, no. 7, pp. 849–856, Jul. 2000.
[15] B. A. Rajoub, “An efficient coding algorithm for the compression of ECG
signal using the wavelet transform,” IEEE Trans. Biomed. Eng., vol. 49,
no. 4, pp. 355–362, Apr. 2002.
[16] C. T. Ku, K. C. Hung, T. C. Wu, and H. S. Wang, “Wavelet-based ECG
data compression system with linear quality control scheme,” IEEE Trans.
Biomed. Eng., vol. 57, no. 6, pp. 1399–1409, Jun. 2010.
[17] F. Sufi, S. Mahmoud, and I. Khalil, “A wavelet based secured ECG distribution technique for patient centric approach,” in Proc. Int. Summer
School Symp. Med. Devices Biosens., 2008, pp. 301–304.
[18] T. Ma, P. L. Shrestha, M. Hempel, D. Peng, H. Sharif, and H. H. Chen,
“Assurance of energy efficiency and data security for ECG transmission
in BASNs,” IEEE Trans. Biomed. Eng., vol. 59, no. 4, pp. 1041–1048,
Apr. 2012.
[19] F. Sufi, Q. Fang, I. Khalil, and S. S. Mahmoud, “Novel methods of faster
cardiovascular diagnosis in wireless telecardiology,” IEEE J. Sel. Areas
Commun., vol. 27, no. 4, pp. 537–552, May 2009.
[20] T. Qian, L. M. Zhang, and Z. X. Li, “Algorithm of adaptive Fourier
decomposition,” IEEE Trans. Signal Process., vol. 59, no. 12, pp. 5899–
5906, Dec. 2011.
[21] R.S.H. Istepanian and A. A. Petrosian, “Optimal zonal wavelet-based ECG
data compression for a mobile telecardiology system,” IEEE Trans. Inf.
Technol. Biomed., vol. 4, no. 3, pp. 200–211, Sep. 2000.
[22] M. Blanco-Velasco, “Wavelet packets feasibility study for the design of an
ECG compressor,” IEEE Trans. Biomed. Eng., vol. 54, no. 4, pp. 766–769,
Apr. 2007.
[23] B. Huang, Y. Wang, and J. Chen, “2-D compression of ECG signals using
ROI mask and conditional entropy coding,” IEEE Trans. Biomed. Eng.,
vol. 56, no. 4, pp. 1261–1263, Apr. 2009.
[24] J. L. Ma and M. C. Dong, “R&D of versatile distributed e-home healthcare
system for cardiovascular disease monitoring and diagnosis,” in Proc.
IEEE Int. Conf. Biomed. Health Informat., Jun. 2014, pp. 444–447.
[25] C. M. Fira and L. Goras, “An ECG signals compression methods and
its validation using NNs,” IEEE Trans. Biomed. Eng., vol. 55, no. 4,
pp. 1319–1326, Apr. 2008.
[26] Y. Zigel, A. Cohen, and A. Katz, “The weighted diagnostic distortion
(WDD) measure for ECG signal compression,” IEEE Trans. Biomed. Eng.,
vol. 47, no. 11, pp. 1422–1430, Nov. 2000.

[27] H. H. Chou, Y. J. Chen, Y. C. Shiau, and T. S. Kuo, “An effective and
efficient compression algorithm for ECG signals with irregular periods,”
IEEE Trans. Biomed. Eng., vol. 53, no. 6, pp. 1198–1205, Jun. 2006.
[28] C. C. Sun and S. C. Tai, “Beat-based ECG compression using gain-shape
vector quantization,” IEEE Trans. Biomed. Eng., vol. 52, no. 11, pp. 1882–
1888, Nov. 2005.

JiaLi Ma received the B.Sc. degree in electronics
and information engineering from Tianjin University,
Tianjin, China, in 2011. She is currently working toward the M.Sc. degree in electrical and computer engineering at the University of Macau, Macao, China.
Her research interests include construction of
embedded-link e-health systems, bioinformation
management, and biomedical signals compression in
e-health applications.

TanTan Zhang received the B.Sc. degree in electrical engineering and automation from Fuzhou University, Fuzhou, China, in 2008 and the M.Sc. degree
in electrical and electronics engineering (now electrical and computer engineering) from the University of
Macau, Macao, China, in 2010, where he is currently
working toward the Ph.D. degree in electrical and
computer engineering. His current research interests
include the design of ultra-low power circuits and
systems for biomedical applications, specializing in
smart CMOS temperature sensors, CMOS pressure
sensors, and ultra-low power analog design techniques.

MingChui Dong received the M.Sc. degree from the
Department of Automation from Tsinghua University, Beijing, China in 1975.
He was a Visiting Scholar in the Electrical
and Electronics Engineering Department, Rome University, Rome, Italy in 1981. He was an Invited
Full Professor in Yantai University, China and an
Associate Professor in Department of Automation,
Tsinghua University. He joined the University of
Macau, Macao, China, in 1998 and he was the Executive Director of the Institute of Systems and Computer
Engineering (INESC-Macau) from 2003 to 2012. He is currently a Full Professor and the Ph.D. Supervisor of the Department of Electrical and Computer
Engineering, University of Macau.
His main research interests include artificial intelligence (AI) and its application in biomedical engineering, CIMS, fault diagnosis, AI in vision-to-text,
voice-to-text machine translation, etc.

