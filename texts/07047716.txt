IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 2, MARCH 2016

655

Privacy-Preserving Patient-Centric Clinical Decision
Support System on NaÄ±Ìˆve Bayesian Classification
Ximeng Liu, Student Member, IEEE, Rongxing Lu, Member, IEEE,
Jianfeng Ma, Le Chen, and Baodong Qin

Abstractâ€”Clinical decision support system, which uses advanced data mining techniques to help clinician make proper decisions, has received considerable attention recently. The advantages
of clinical decision support system include not only improving diagnosis accuracy but also reducing diagnosis time. Specifically, with
large amounts of clinical data generated everyday, naÄ±Ìˆve Bayesian
classification can be utilized to excavate valuable information to improve a clinical decision support system. Although the clinical decision support system is quite promising, the flourish of the system
still faces many challenges including information security and privacy concerns. In this paper, we propose a new privacy-preserving
patient-centric clinical decision support system, which helps clinician complementary to diagnose the risk of patientsâ€™ disease in a
privacy-preserving way. In the proposed system, the past patientsâ€™
historical data are stored in cloud and can be used to train the naÄ±Ìˆve
Bayesian classifier without leaking any individual patient medical
data, and then the trained classifier can be applied to compute the
disease risk for new coming patients and also allow these patients
to retrieve the top-k disease names according to their own preferences. Specifically, to protect the privacy of past patientsâ€™ historical
data, a new cryptographic tool called additive homomorphic proxy
aggregation scheme is designed. Moreover, to leverage the leakage
of naÄ±Ìˆve Bayesian classifier, we introduce a privacy-preserving topk disease names retrieval protocol in our system. Detailed privacy
analysis ensures that patientâ€™s information is private and will not
be leaked out during the disease diagnosis phase. In addition, performance evaluation via extensive simulations also demonstrates
that our system can efficiently calculate patientâ€™s disease risk with
high accuracy in a privacy-preserving way.
Index Termsâ€”Clinical decision support system (CDSS), naÄ±Ìˆve
Bayesian classifier, patient centric, privacy preserving.

Manuscript received August 18, 2014; revised December 25, 2014; accepted
February 17, 2015. Date of publication February 24, 2015; date of current
version March 3, 2016. This work was supported by the Key Program of
NSFC-Guangdong Union Foundation under Grant U1135002; the Key Program
of NSFC under Grant U1405255; the National Natural Science Foundation of
China under Grant 61402109 and Grant 61370078; the support of Nanyang
Technological University under Grant NTU-SUG (M4081196) and MOE Tier
1 (M4011177).
X. Liu is with the School of Telecommunication Engineering, Xidian University, Xiâ€™an 710071, China, and also with the School of Electrical and Electronics Engineering, Nanyang Technological University, 639798 Singapore (e-mail:
snbnix@gmail.com).
R. Lu and L. Chen are with the School of Electrical and Electronics
Engineering, Nanyang Technological University, 639798 Singapore (e-mail:
rxlu@ntu.edu.sg; chenle0213@gmail.com).
J. Ma is with the School of Computer Science and Technology, Xidian University, Xiâ€™an 710071, China (e-mail: jfma@mail.xidian.edu.cn).
B. Qin is with School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail:
qinbaodong@sjtu.edu.cn).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2015.2407157

I. INTRODUCTION
EALTHCARE industry, extensively distributed in the
global scope to provide health services for patients, has
never faced such a massive amounts of electronic data or experienced such a sharp growth rate of data today. As stated
by the Institute for Health Technology Transformation (iHT2 ),
U.S. health care data alone reached 150 exabytes (1018 bytes)
in 2011 and would soon reach zettabyte (1021 bytes) scale and
even yottabytes (1024 bytes) in the future [1]. However, if no
appropriate technique is developed to find great potential economic values from big healthcare data, these data might not only
become meaningless but also require a large amount of space
to store and manage. Over the past two decades, the miraculous
evolution of data mining technique has imposed a major impact
on the revolution of humanâ€™s lifestyle by predicting behaviors
and future trends on everything, which can convert stored data
into meaningful information. These techniques are well suitable for providing decision support in the healthcare setting. To
speed up the diagnosis time and improve the diagnosis accuracy, a new system in healthcare industry should be workable to
provide a much cheaper and faster way for diagnosis. Clinical
decision support system (CDSS), with various data mining techniques being applied to assist physicians in diagnosing patient
diseases with similar symptoms, has received a great attention
recently [2]â€“[4]. NaÄ±Ìˆve Bayesian classifier, one of the popular
machine learning tools, has been widely used recently to predict various diseases in CDSS [27]. Despite its simplicity, it is
more appropriate for medical diagnosis in healthcare than some
sophisticated techniques [6], [7].

H

The CDSS with naÄ±Ìˆve Bayesian classifier has offered many
advantages over the traditional healthcare systems and opens
a new way for clinicians to predict patientâ€™s diseases. However, its flourish still hinges on understanding and managing the
information security and privacy challenges, especially during
the patient disease decision phase. One of the main challenges
is how to keep patientâ€™s medical data away from unauthorized
disclosure. The usage of medical data can be of interest for a
large variety of healthcare stakeholders. For example, an online direct-to-consumer service provider offers individual risk
prediction for patientâ€™s disease. Without good protection of patientâ€™s medical data, patient may feel afraid that his medical
data will be leaked and abused, and refuse to provide his medical data to CDSS for diagnosis. Therefore, it is crucial to protect
patientâ€™s medical data. However, keeping medical dataâ€™s privacy
are not sufficient to push forward the whole CDSS into flourish.
Service providerâ€™s classifier, which is used to predict patientâ€™s
disease, cannot be exposed to third parties since the classifier

2168-2194 Â© 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

656

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 2, MARCH 2016

is considered as service providerâ€™s own asset. Otherwise, the
third parties can abuse the classifier to predict patientâ€™s disease, which could damage service providerâ€™s profit. Therefore,
besides preserving the privacy of patientâ€™s medical data, how to
protect service providerâ€™s privacy is also crucial for the CDSS.
In this paper, to address the privacy issues lying in the CDSS,
we propose a privacy-preserving patient-centric clinical decision support system, called PPCD, which is based on naÄ±Ìˆve
Bayesian classification to help physician to predict disease risks
of patients in a privacy-preserving way. Specifically, the main
contributions of this paper are fourfold.
First, we propose a secure and PPCD, which allows service
provider to diagnose patientâ€™s disease without leaking any patientâ€™s medical data. In PPCD, the past patientâ€™s historical medical data can be used by service provider to train the naÄ±Ìˆve
Bayesian classifier. Then, service provider can use the trained
classifier to diagnose patientâ€™s diseases according to his symptoms in a privacy-preserving way. Finally, patients can retrieve
the diagnosed results according to his own preference privately
without compromising the service providerâ€™s privacy.
Second, since individual historical medical data will disclose
patientâ€™s sensitive medical data to service provider, to minimize
patientâ€™s privacy disclosure, we also introduce a new aggregation technique called additive homomorphic proxy aggregation (AHPA) scheme, which allows service provider to build
naÄ±Ìˆve Bayesian classifier without leaking any individual historical medical data. Even the service provider and cloud platform
(CP) collude, no party can get any information about the individual historical medical data except for the owner himself, and
only the aggregated data can be accessed by the service provider.
Third, to cater for patient-centric diagnosis result retrieval,
we present a privacy-preserving top-k disease names retrieval
protocol (TOP-K), which allows patients to retrieve diagnosed
disease names according to their preferences. Within the TOP-K,
service provider learns nothing about patientâ€™s symptom information used for diagnosis and patient also cannot get anything
about naÄ±Ìˆve Bayesian classifier. Note that although privacypreserving top-k protocol was studied in [8], yet both computation cost and communication overhead about privacy-preserving
top-k protocol in [8] are expensive, which make it unsuitable
for PPCD. Compared with the privacy-preserving top-k protocol, our proposed TOP-K is much more efficient in terms of
computation cost and communication overhead.
Finally, to validate the efficiency of the proposed PPCD, we
also develop a custom simulator built in Java. Extensive simulation demonstrates that our PPCD can efficiently help patient
to diagnose the disease with high predict success rate and it also
minimizes privacy disclosure without overburdening the whole
system.
The remainder of this paper is organized as follows: In
Section II, we describe some preliminaries, which serve as the
basis of our PPCD. In Section III, we formalize the system
model, the privacy requirements, and identify our design goal.
In Section IV, we present our PPCD, followed by privacy analysis and performance evaluation in Section V and Section VI,
respectively. In Section VII, we also discuss some related works.
Finally, we draw our conclusions in Section VIII.

TABLE I
DEFINITIONS AND NOTATIONS IN PPCD
Symbol

Definition

P Kc
SKc
pk a
sk a
E P K c (Â·)
D S K c (Â·)
[Â·] p k P
C1 , C2 , . . . , Cn d
A1 , A2 , . . . , An s
(i)
Xj

User câ€™ public key of Paillier encryption scheme
User câ€™ private key of Paillier encryption scheme
User aâ€™ public key of AHPR scheme
User aâ€™ private key of AHPR scheme
Paillier encryption function
Paillier decryption function
Ciphertext of AHPR scheme
n d disease classes in the system
n s symptom attributes in the system
j -th symptom of patient i

(i)

Yj
I DC i
P (C i = 1)
P (C i = 0)
 (i)
X
 (i)
Y
 (i)
X

j -th disease of patient i
Disease name of class C i
The probability for getting disease C i
The probability for not getting disease C i

Ti
a Â·b

Encrypted tuple E p k c (P (C i )), E p k c (I D C i )
Multiplication between a and b over cyclic group

pkP
(c )

Symptom vector of patient i
Disease vector of patient i
Encrypted symptom vector by public key pk P

II. PRELIMINARIES
In this section, we outline the naÄ±Ìˆve Bayesian classifier [9],
Paillier homomorphic encryption [10], and secure multiplication
(SM) protocol [11], which will serve as the basis of the proposed
PPCD. Before that we first use Table I to list main notations used
in the whole paper.
A. NaÄ±Ìˆve Bayesian Classifier
NaÄ±Ìˆve Bayesian classifier [9] is a very attractive classifier,
which has been proved to be effective in many practical applications, including text classification [12], [13], medical diagnosis
[14], [15], and systems performance management [16]. Here,
we briefly review the naÄ±Ìˆve Bayesian classifier as follows.
There are f classes which are denoted as C1 , C2 , . . . , Cf .
 =
Each sample is represented by n-dimensional vector X
{X1 , . . . , Xn }, depicting n measured values of the n attributes
 beA1 , . . . , An , respectively. The classifier needs to predict X
longs to the class with the highest a posteriori probability, i.e.,
 is predicted to lie in the class Ci if and only if there exists i,
X
such that
 > P (Cj |X),

P (Ci |X)
for all 1 â‰¤ j â‰¤ f, j = i.
By Bayesâ€™s theorem
 =
P (Ci |X)

 i )P (Ci )
P (X|C

P (X)

 is the same for all classes, only
we can see that P (X)

P (X|Ci )P (Ci ) needs to be maximized. In order to eval i )P (Ci ), the naive assumption on class condiuate P (X|C
tional independence is made. This presumes that the values
of all attributes are conditionally independent of one another,

LIU et al.: PRIVACY-PRESERVING PATIENT-CENTRIC CLINICAL DECISION SUPPORT SYSTEM ON NAIÌˆVE BAYESIAN CLASSIFICATION

657

mathematically meaning
 i) â‰ˆ
P (X|C

n


P (Xk |Ci ).

k =1

The probabilities P (X1 |Ci ), P (X2 |Ci ), . . . , P (Xn |Ci ) can
easily be estimated from the training set. In all, the classifier
 is Ci if and only Ci has maxipredicts that the class label of X
 j )P (Cj ), (1 â‰¤

mized the value P (X|Ci )P (Ci ) among P (X|C
j â‰¤ f ).
B. Paillier Homomorphic Encryption
In order to achieve PPCD, we will adopt Paillier homomorphic encryption [10] as one of the building blocks. We briefly
review the steps involved in Paillier homomorphic encryption
as follows.
Key Generation: Given the security parameter k and two
large prime numbers p and q, where |p| = |q| = k, compute N = pq and Î» = lcm(p âˆ’ 1, q âˆ’ 1). Define a function
âˆ—
L(x) = xâˆ’1
N , then choose a generator g âˆˆ ZN 2 and calculate
Î»
2 âˆ’1
Î¼ = (L(g modN )) . Then, the public key is denoted as
pk = (N, g) and the corresponding private key is sk = (Î», Î¼).
Encryption: Given a message m âˆˆ ZN , choose a random
number r âˆˆ Zâˆ—N . The ciphertext can be calculate as I =
Epk (m) = g m Â· rN mod N 2 .
Decryption: Given a ciphertext I, the message can be recovered from the ciphertext by calculating m = Dsk (I) =
L(I Î» modN 2 ) Â· Î¼ mod N .
Assume both Epk (x) = g x Â· r1N modN 2 and Epk (y) = g y Â·
N
r2 modN 2 are encrypted under the same public key pk. The
Paillier encryption has the following properties.
1) Additive Homomorphism: Given two ciphertexts Epk (x)
and Epk (y), it has Dsk (Epk (x) Â· Epk (y)) = Dsk (g x r1N Â·
g y r2N modN 2 = g x+y r1N r2N modN 2 ) = x + y.
2) Scalar-Multiplicative Homomorphism: Given constant
number c âˆˆ ZN and a ciphertext Epk (x), it has
Dsk (Epk (x)c ) = Dsk (g cx (r1c )N modN 2 ) = c Â· x.
3) Self-Blinding: Given a ciphertext Epk (x), it is efficient
to recover the plaintext of the ciphertext by calculating
Dsk (Epk (x) Â· (r	 )N ) = Dsk (g x (r1 r	 )N modN 2 ) = x.
Note that for the given x âˆˆ ZN , Epk (âˆ’x) = Epk (x)N âˆ’1 .
C. SM Protocol
Because Paillier encryption only supports additive homomorphism, which cannot achieve multiplication of the plaintext, we
also use SM protocol described in [11] as a building block to
design our PPCD. Two parties (called Alice and Bob) will be
involved in this protocol for execution. Consider Bob has two
encrypted data Epk (x) and Epk (y), Alice has a secret key sk.
If Epk (x) and Epk (y) are directly sent to Alice for decryption,
it will damage the other partyâ€™s interests (see Section IV-C for
detailed explanation). The goal of SM protocol is to calculate
Epk (x Â· y) without leaking x and y to each other. The overall
steps of SM protocol are shown as follows.

Fig. 1.

System model under consideration.

Step 1: Bob selects two random numbers rx , ry âˆˆ ZN , calculates x	 = Epk (x) Â· Epk (rx ) and y 	 = Epk (y) Â· Epk (ry ), sends
x	 and y 	 to Alice.
Step 2: Alice decrypts x	 and y 	 by using the secret key sk, and
multiplies them as h = Dsk (x	 ) Â· Dsk (y 	 ). Then, Alice encrypts
h by using pk and denotes it as h	 = Epk (h), and sends h	 to
Bob. It can be easily verified that h = (x + rx )(y + ry ).
Step 3: Bob first calculates s1 = Epk (x)N âˆ’r y , s2 =
Epk (y)N âˆ’r x , and s3 = Epk (rx Â· ry )N âˆ’1 . Then, Bob calculates
the following formula to gain the encrypted x Â· y:
h	 Â· s1 Â· s2 Â· s3 = Epk (h âˆ’ ry Â· xâˆ’ rx Â· y âˆ’rx Â· ry ) = Epk (x Â· y).
III. SYSTEM MODEL, PRIVACY REQUIREMENTS,
AND DESIGN GOAL
In this section, we formalize the system model, privacy requirements, and identity our design goals.
A. System Model
In our system, we mainly focus on how to securely train
naÄ±Ìˆve Bayesian classifier and use the classifier to clinical decide patientsâ€™ disease without leaking their private information.
Specifically, we define the system model by dividing PPCD into
five parties: Trusted authority (TA), Cloud Platform (CP), data
provider (DP), processing unit (PU), and undiagnosed patient
(PA). The overall system model of our PPCD can be found in
Fig. 1.
1) Trusted Authority: TA is the indispensable entity, which
is trusted by all entities involved in the system, who is in charge
of distributing and managing all the private keys involve in the
system.
2) Cloud Platform: CP contains unlimited storage space,
which can store and manage all the data in the system. Other
parties who have limited storage space can outsource their data
to CP for storing. In addition, CP has some computation abilities
to perform some calculations over the stored data.
3) Data Provider: DP can provide historical medical data
that contain patientsâ€™ symptoms and confirmed diseases, which
are used for training naÄ±Ìˆve Bayesian classifier. All these data are
outsourced to CP for storing.

658

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 2, MARCH 2016

4) Processing Unit (PU, Representing as Service Provider
in the Previous Section): PU can be a company or hospital,
which can provide online direct-to-consumer service and offer
individual risk prediction for various diseases based on clientâ€™s
symptoms. PU uses historical medical data to construct naÄ±Ìˆve
Bayesian classifier and then use the model to predict the disease
risk of undiagnosed patients.
5) Undiagnosed Patient (PA): PA has some symptom information, which is collected during doctor visits or directly provided by patient (e.g., blood pressure, heart rate, weight, etc).
The symptoms can be sent to PU for diseases diagnosis.
B. Privacy Requirements
Privacy is crucial for the success of patientâ€™s diseases diagnosis. In our privacy model, we consider DP is trustable, which
provides correct historical medical data. The internal party PU
is considered as curious-but-honest, which is interested in DPâ€™s
individual historical medical data and PAâ€™s medical data, but
strictly follows the protocols executed in the system. Both CP
and PA are also curious-but-honest parties in this system. PA is
curious about PUâ€™s classifier, while CP is curious about all the
other partiesâ€™ data in the system. Moreover, an external adversary is interested in all data transmitted in the system by eavesdropping. Therefore, in order to prevent both internal party from
information leakage and external adversary from eavesdropping,
the following privacy requirements should be satisfied in PPCD.
1) DPâ€™s Privacy: DPâ€™s historical medical data contain confirmed case records of patientâ€™s symptoms and confirmed
diseases. These historical medical data can be used to train
naÄ±Ìˆve Bayesian classifier. These individual data contain
some sensitive information, which are highly related to
patientâ€™s privacy. It cannot be directly exposed to untrust
parties during the transmission and storage. Otherwise,
DP will not provide its own data to the other parties due
to the privacy information leakage. Therefore, privacy of
DP should be preserved in our system.
2) PUâ€™s Privacy: PU uses historical medical data to train
naÄ±Ìˆve Bayesian classifier and gets conditional probabilities about the classifier. These probabilities are considered
as an asset of PU, which cannot directly be sent to patients
or leaked to other parties during the disease diagnosis.
3) PAâ€™s Privacy: PA contains some symptom data, which are
sensitive and cannot directly expose to other parities. In
addition, the diagnosis results are also highly sensitive
information, which cannot be leaked to other parties. If
needed, PA can let the authorized person (authorized clinician) disclose the diagnosis results for further processing.

Fig. 2.

Overall procedure of PPCD.

disclosed to PU, CP, and unauthorized parties in the patientâ€™s medical decision. It will let patient unwillingly
provide its own data to CDSS. In addition, PU is always
a profit company, which prevents his own data from leaking to other parties in the system. Therefore, the proposed
system should achieve the privacy of PA and PU simultaneously.
2) The Proposed System Should Achieve Computation Efficiency: The patient always has limited computational resources, which cannot support overburden computation.
To support patient-centric diagnosis results retrieval from
CP in time, the proposed system should consider computation efficiency. Therefore, it is important to allow PA to
retrieve diagnosis results in realtime.
IV. PROPOSED PPCD SYSTEM
In this section, we present our PPCD system for predicting
patientâ€™s disease risk, which mainly consists of the following
three phases: privacy-preserving training naÄ±Ìˆve Bayesian classifier (Phase A), privacy-preserving computing patient of disease
risk (Phase B), privacy-preserving retrieving top-k diagnosed
results (Phase C). The overall procedure of PPCD is listed in
Fig. 2.
A. Privacy-Preserving Training NaÄ±Ìˆve Bayesian Classifier

C. Design Goals
In order to achieve the secure medical decision for UP under
the aforementioned model, our system design will fulfill privacy
and performance guarantees as follows.
1) The Proposed System Should Achieve Privacy-Preserving
Requirements: As stated above, if CDSS does not consider the privacy requirements, patientâ€™s highly sensitive
information (symptom and disease information) will be

In this phase, DP should provide his historical medical data to
PU for training naÄ±Ìˆve Bayesian classifier and these data should
be sent to CP for storage. We first construct a new cryptographic
tool called AHPA scheme to securely aggregate the message to
solve the collusion problem between PU and CP. Then, we use
the tool to train naÄ±Ìˆve Bayesian classifier privately.
1) AHPA Scheme: Our AHPA scheme is based on ElGamal encryption scheme [17], [18] and contains the following

LIU et al.: PRIVACY-PRESERVING PATIENT-CENTRIC CLINICAL DECISION SUPPORT SYSTEM ON NAIÌˆVE BAYESIAN CLASSIFICATION

six algorithms: KeyGen, Rekeygen, Encrypt, Decrypt, Reencrypt&Agg, and Redecrypt.
a) KeyGen: The algorithm is run by TA to generate public key
and private key for DP i and PU. Choose two cyclic groups G
and GT of prime order N . Let g be a generator of group G and
compute X = e(g, g). For each DP i, chooses ai,1 , ai,2 âˆˆ ZN ,
and computes e(g, g)a i , 1 and g a i , 2 . Denote DP iâ€™s public key as
pka i = {e(g, g)a i , 1 , g a i , 2 } and private key ska i = {ai,1 , ai,2 },
respectively. PUâ€™s public key and private key can be computed
in the same way and be denoted as pkP = {e(g, g)p 1 , g p 2 } and
skP = {p1 , p2 }, respectively.
b) Rekeygen: The algorithm is run by TA to generate the reencryption key. This key can be generated by DP iâ€™s private key ai ,
PUâ€™s public key g p 2 , and a random number ri	 selected by TA,
	
	
i.e., ska i â†’P = (g p 2 )a i , 1 g r i = g a i , 1 p 2 g r i . Moreover, TA generates a private R for PU to allow PU to decrypt the aggregated
message. R is generated by using ri	 , DPâ€™s random number g r i ,
and PUâ€™s private key p2 , where


R = e(g, g)

r i r i	 p âˆ’1
2

.

(i)

{Ai,1 , Ai,2 } = {g r i , e(g, g)x Â· e(g, g)a i , 1 r i }, where ri is a
random number from ZN .
d) Decrypt: [x(i) ]pk a i can be decrypted by using DP iâ€™s private
key ska i
Ai,2
Â· e(g, g)
e(g, g)
=
e(g, Ai,1 )a i , 1
e(g, g r i )a i , 1

ai , 1 ri

(i)

= e(g, g)x .

Similar to other works in [19] and [20], x(i) is a finite and
relatively small number, DP can compute discrete logarithm of
(i)
e(g, g)x in base e(g, g) to retrieve x(i) .
e) Reencrypt&Agg: This algorithm is executed by CP. The
algorithm can be processed as follows.
1) For each DP i, the ciphertext in DP iâ€™s domain
[x(i) ]pk a i can be reencrypted into PUâ€™s domain
by ska i â†’P . That is, the ciphertext [x(i) ]pk a i
can be converted into [x(i) ]pk p = {Bi,1 , Bi,2 } =
	
(i)
{ e(g, g ) a i , 1 p 2 r i e( g, g )r i r i , e(g, g)x Â· e(g, g)a i , 1 r i },
where Bi,1 can be computed by e(ska i â†’p , A1 ) =
	
	
e(g a i , 1 p 2 g r i , g r i ) = e(g, g)a i , 1 p 2 r i e(g, g)r i r i .
2) For all i = 1, . . . , l, CP calculates the aggregated ciphertext by using [x(i) ]pk p
CTAgg = {CT1 , CT2 },
where
CT1 =

l


Bi,1 = e(g, g)p 2

l
i= 1

ai , 1 ri

l

e(g, g)

i= 1

r i r i	

i=1

CT2 =

l


l

Bi,2 = e(g, g)

i= 1

x( i )

f) Redecrypt: This algorithm is executed by PU. PU can decrypt the aggregated ciphertext CTAgg by using skP


l

= e(g, g)



i= 1

x( i )

l

Â· e(g, g)

i= 1

ai , 1 ri

r i r i	 p âˆ’1
2

.

l

x(i) is a finite and relatively small number, which can be
obtained by calculating discrete logarithm.
2) Privacy-Preserving Training NaÄ±Ìˆve Bayesian Classifier:
In this section, we show how to train naÄ±Ìˆve Bayesian classifier
privately by using AHPA.
 (i) = (X (i) , . . . , Xn(i)s ) represent patient iâ€™s symptom
Let X
1
 (i) = (Y (i) , . . . , Yn(i)
vector, while Y
d ) denotes iâ€™s corresponding
1
disease vector, where ns is the number of symptom categories
involved in the system, nd is the number of disease categories
involved in the system. In these historical data, if patient i has
(i)
(i)
the jth symptom, then Xj = 1, and Xj = 0 otherwise. If
i=1

(i)

patient i has tth disease, then Yt = 1, and Yt = 0 otherwise.
For each symptom, each DP uses his own public key pki to
(i)
encrypt the historical symptom [Xj ]pk i and confirmed diseases
(i)

[Yt ]pk i , and then sends them to CP to store. Note that all the
symptoms should be normalized into binary before encryption,
(i)
	(i)
	(i)
that is, Xj should be converted to (X1 , . . . , Xn 	 ) instead,
(i)

where Xj

	(i)

	(i)

is numeric, X1 , . . . , Xn 	

are binary, n	 is the

(i)
Xj .

value range of
For example, the attribute temperature X
ranges from 35.5 to 41.5 â—¦ C, which should be converted into
(X1 , . . . , X51 ). If DP iâ€™s X (i) = 35.5 â—¦ C, then the converted
	(i)
	(i)
attributes X1 = 1, and Xj = 0, where j = 2 . . . 51.
Once all the historical medical data have been outsourced,
CP first uses Reencrypt&Agg algorithm to transfer the ci(i)
phertext from DPâ€™s domain [Xj ]pk i into CPâ€™s domain
(i)
 (i) =
[X ]pk , then aggregates the encrypted symptom data X
j

pk p

p

(i)
(i)
	 =
([X1 ]pk p , . . . , [Xn s ]pk p ) into one encrypted vector X
pk p
([X1	 ]pk p , . . . , [Xn	 s ]pk p ) by calculating

[Xj	 ]pk P â† Reencrypt&Agg([Xj ]pk P , . . . , [Xj ]pk P )
(1)

(l)

where l is the number of the historical medical data. In addition,
	
	
	
the aggregated disease vector Y
pk P = ([Y1 ]pk P , . . . , [Yn d ]pk P )
can be calculated in the same way, where
[Yj	 ]pk P â† Reencrypt&Agg([Yj

(1)

(l)

]pk P , . . . , [Yj ]pk P ).

After performing aggregation, CP sends [X1	 ]pk P , . . . , [Xn	 s ]pk P
and [Y1	 ]pk P , . . . , [Yn	 d ]pk P to PU. PU uses its own private key
skP to decrypt these encrypted elements and gets the vectors
 	 = (Y 	 , . . . , Y 	 ). Note that l is the
 	 = (X 	 , . . . , X 	 ) and Y
X
ns
nd
1
1
total number of the historical medical data stored in the CP, then
PU can calculate
PÌ‚ (Aj = 1|Ct = 1) =

i=1

l is the number of DP.



(i)

CT2 Â· R
e(g, g) x Â· e(g, g) a i , 1 r i e(g, g)


âˆ’1 =
	 âˆ’1
(CT1 )p 2
e(g, g) a i , 1 r i e(g, g) r i r i p 2

(i)

c) Encrypt: This algorithm is executed by DP i. Let x(i) âˆˆ ZN
be the message, which can be encrypted under DP iâ€™s public
key pka i . Then, the ciphertext can be calculated as [x(i) ]pk a i =

x( i )

659

PÌ‚ (Ct = 1) =

Xj	
Xj	
,
PÌ‚
(A
=
1|C
=
0)
=
j
t
Yt	
l âˆ’ Yt	

Yt	
l âˆ’ Yt	
, PÌ‚ (Ct = 0) =
l
l

660

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 2, MARCH 2016

PÌ‚ (Aj = 0|Ct = 1) = 1 âˆ’ PÌ‚ (Aj = 1|Ct = 1)
PÌ‚ (Aj = 0|Ct = 0) = 1 âˆ’ PÌ‚ (Aj = 1|Ct = 0).
These PÌ‚ (Fj |Ct )(j = 1, . . . , ns ; t = 1, . . . , nd ) should be
kept privately by PU as its own asset. It is worth noticing
that the AHPA scheme can only encrypt integer, while conditional probability cannot be directly used to calculate patientâ€™s disease risk. To address the issue, all the conditional
probabilities should be expanded into integers by calculating
P (Ct = 1) = C 	 PÌ‚ (Ct = 1). For example, if PÌ‚ (C1 = 1) =
0.38 and PÌ‚ (C1 = 0) = 0.48, both PÌ‚ (C1 = 1) and PÌ‚ (C1 = 0)
can be expanded into P (C1 = 1) = 38 and P (C1 = 0) = 48
by using C 	 = 100. Note that this expansion will not effect
the relationship between the probabilities. The probability of
PÌ‚ (Aj |Ct = 1), PÌ‚ (Aj |Ct = 0) and PÌ‚ (Ct = 0) should be expanded in the same way by using C 	 .
B. Privacy-Preserving Computing Patient of Disease Risk
In the rest of the paper, all the data are correlated with a
specific PA, and we denote the specific PA as c. Because (c) will
always appear in the notation, without special explanation, all
the data represent câ€™s data and we will drop (c) from expression,
(c)
for example, we transform X1 into X1 in order to keep the
notation uncluttered.
Suppose c has ns measured symptoms called X1 , . . . , Xn s ,
he encrypts these symptoms as EP K c (Xj )(j = 1, . . . , ns ) and
sends them to PU via CP. Once these encrypted symptoms are
received, PU cannot decrypt the câ€™s encrypted symptoms since
he has not gotten câ€™s private key SKc . PU can use the Bayesâ€™s
theorem to calculate patientâ€™s probability of having disease (The
detail description of Bayesâ€™s theorem can be found in [21]). For
every diseases t, PU uses P (Aj |Ct ) to calculate
EP K c (P (Aj = Xj |Ct = 1))
= EP K c (Xj P (Aj = 1|Ct = 1)
+(1 âˆ’ Xj )P (Aj = 0|Ct = 1))
= EP K c (Xj )P (A j =1|C t =1)
Â·Epk c (1 âˆ’ Xj )P (A j =0|C t =1) .

(1)

With the same method, CP can calculate EP K c (P (Aj =
X|Ct = 0)). Next, CP calculates
KÌ‚t,1 = EP K c (

ns


P (Aj = Xj |Ct = 1) Â· P (Ct = 1)). (2)

j =1

The calculation
 ins (2) can be achieved by using SM protocol. DeP (Aj = Xj |Ct = 1) Â· P (Ct = 1), then we
note HÌ‚t,1 = nj =1
have KÌ‚t,1 = EP K c (HÌ‚t,1 ). In addition, PU uses câ€™s public key
to encrypt disease name IDt and denotes it as
Ë† t,1 ).
GÌ‚t,1 = EP K c (ID
Furthermore, PU can compute KÌ‚t,0 , GÌ‚t,0  in the similar way,
where
Ë† t,0 )
KÌ‚t,0 = EP K c (HÌ‚t,0 ), GÌ‚t,0 = EP K c (ID

Fig. 3.

Running procedure of PMAXn .

 s
with HÌ‚t,0 = nj =1
P (Aj = Xj |Ct = 0) Â· P (Ct = 0) and
Ë†
IDt,0 = 0. In some cases, CP may know the disease names
according to the order sorting of the ciphertext even without
decryption (some background knowledges). Once some
encrypted disease names are retrieved, the privacy about this
patient will be leaked to CP. In order to protect patientâ€™s privacy,
all the ciphertexts should be permuted before outsourcing. This
procedure is described as follows.
PU first randomly permutes KÌ‚t,Ï€ d (e) , GÌ‚t,Ï€ d (e) e={0,1}
by using permutation Ï€d . Then, PU uses permutation Ï€ to permute and denote them as {TÌ‚a,b } =
{KÌ‚Ï€ (t),Ï€ d (e) , GÌ‚Ï€ (t),Ï€ d (e) }e={0,1},t={1,...,n } , and then sends
them to CP for storing, where b = Ï€d (e), a = Ï€(t).
C. Privacy-Preserving Retrieving Top-k Diagnosed Results
When these diagnosed results {TÌ‚a,b }a={1,Â·Â·Â·,n },b={0,1} have
been computed, CP needs to find the encrypted top-k diagnosis
results and sends them back to PA. This procedure can be divided
into two steps.
Step1: CP needs to judge whether PA suffers from some
specific diseases according to probabilities, that is, if HÌ‚a,1 â‰¥
Ë† a,1 ), otherwise, denote
HÌ‚a,0 , denote EP K c (IDa ) = EP K c (ID
Ë† a,0 ).
EP K c (IDa ) = EP K c (ID
Step 2: CP needs to select top-k possible disease
names according to diagnosis probabilities, that is, select
EP K c (ID	1 ), . . . , EP K c (ID	k ) from EP K c (ID1 ), . . . , EP K c
(IDn d ) where its corresponding H1	 , . . . , Ht	 are top-k probabilities among H1 , . . . , Hn d .
In order to finish these two steps, three protocols should be designed called Privacy-preserving maximum protocol (PMAX),
privacy-preserving maximum out of n protocol (PMAXn ),
and privacy-preserving top-k disease names retrieval protocol
(TOP-K), respectively. CP can securely achieve Step 1 by running PMAX and Step 2 can be finished by executing TOP-K,
where PMAXn is designed as basic component of TOP-K. Here,
we describe these three protocols as follows.
1) Privacy-Preserving Maximum Protocol: PMAX allows
CP
to
get
a
new
ciphertext
tuple
TU =
EP K c (HU ), EP K c (IDU ) from two different ciphertext tuples TA = EP K c (HA ), EP K c (IDA ) and TB =
EP K c (HB ), EP K c (IDB ), where HU = max(HA , HB ) and

LIU et al.: PRIVACY-PRESERVING PATIENT-CENTRIC CLINICAL DECISION SUPPORT SYSTEM ON NAIÌˆVE BAYESIAN CLASSIFICATION

661

Then, PA will check the relationship between M and 2L .
If M > 2L , PA denotes Î± = 0 and calculates D2	 =
EP K c (0), D3	 = EP K c (0).
If M < 2L , PA denotes Î± = 1 and calculates D2	 = C2 Â·
N
rÌ‚1 , D3	 = C3 Â· rÌ‚2N , where rÌ‚1 and rÌ‚2 are randomly selected from
ZN .
Encrypt Î± as EP K c (Î±). PA sends EP K c (Î±), D2	 , and D3	 back
to CP.
Step 3 (@ CP): After receiving EP K c (Î±), D2	 , and D3	 , CP
will do the following calculations according to s: if s = 1, CP
calculates
EP K c (HU ) = EP K c (HA ) Â· D2	 Â· EP K c (Î±)N âˆ’r

âˆ—
âˆ—

EP K c (IDU ) = EP K c (IDA ) Â· D3	 Â· EP K c (Î±)N âˆ’rÌ‚ .
IDU correspond to disease name. By runnning PMAX, CP
can get the new ciphertext tuple TU ; however, he cannot judge
whether the origin of TU comes from TA or TB . We give the
specific construction of the CP as
Step 1 (@ CP ): 1) CP converts EP K c (HA ), EP K c (HB ) into
EP K c (HA	 ), EP K c (HB	 ) by calculating
EP K c (HA	 ) = EP K c (1) Â· EP K c (HA )2 = EP K c (2HA + 1)
EP K c (HB	 ) = EP K c (HB )2 = EP K c (2 Â· HB ).
It is worth noting that if HA â‰¥ HB and HA â‰¥ 0 and
HB â‰¥ 0, we have HA	 > HB	 . 2) CP chooses random values
R, r3 , râˆ— , rÌ‚âˆ— âˆˆ ZN and tosses a random coin s âˆˆ {0, 1}. If
s = 1, CP computes
C1 = EP K c (HA	 )R Â· EP K c (HB	 )N âˆ’R Â· g 2 r3N mod N 2
L

=

EP	 K c (R(HA	

âˆ’

HB	 )

L

+ 2 ).

(4)

C3 = EP K c (IDB ) Â· EP K c (IDA )N âˆ’1 Â· EP K c (rÌ‚âˆ— )mod N 2
(5)

If s = 0, CP computes:
C1 = EP K c (HB	 )R Â· EP K c (HA	 )N âˆ’R Â· g 2 r3N mod N 2
(6)

(7)

(8)

where |L| = |RC 	 |, C 	 is the expansion value which is introduced in Section IV. The goal of using 2L is to make the value
R(HA	 âˆ’ HB	 ) + 2L positive all the time.
After computation, CP sends C1 , C2 , C3 to PA.
Step 2 (@ PA): Once C1 , C2 , C3 are received, PA decrypts
C1 by using his own private key SKc as
M = DS K c (C1 ).

EP K c (HU ) = EP K c (HA ) Â· D2	 Â· EP K c (Î±)N âˆ’r

âˆ—

= EP K c (HA ) Â· EP K c (0) Â· EP K c (0)N âˆ’r
EP K c (IDU ) = EP K c (IDA ) Â· D3	 Â· EP K c (Î±)N âˆ’rÌ‚

âˆ—

âˆ—
âˆ—

= EP K c (IDA ).
If s = 1 and HA	 < HB	 , then Î± = 1 and D2	 =
EP K c (HB âˆ’ HA + râˆ— ) and D3	 = EP K c (IDB âˆ’ IDA + rÌ‚âˆ— ).
The EP K c (HU ) and EP K c (IDU ) can be calculated as follows:
âˆ—

âˆ—

Â· EP K c (1)N âˆ’r = EP K c (HB )
EP K c (IDU ) = EP K c (IDA ) Â· D3	 Â· EP K c (Î±)N âˆ’rÌ‚

C3 = EP K c (IDA ) Â· EP K c (IDB )N âˆ’1 Â· EP K c (rÌ‚âˆ— )mod N 2
= EP K c (IDA âˆ’ IDB + rÌ‚âˆ— ).

It can be easily verified that HU is the maximum one between
HA and HB .
The correctness of PMAX: The correctness of the protocol
can be seen as follows.
If s = 1 and HA	 > HB	 , then Î± = 0 and D2	 = EP K c (0) and
	
D3 = EP K c (0). The EP K c (HU ) and EP K c (IDU ) can be calculated as follows:

= EP K c (HA ) Â· EP K c (HB âˆ’ HA + râˆ— )

C2 = EP K c (HA ) Â· EP K c (HB )N âˆ’1 Â· EP K c (râˆ— )mod N 2
= EP K c (HA âˆ’ HB + râˆ— ).

âˆ—

EP K c (IDU ) = EP K c (IDB ) Â· D3	 Â· EP K c (Î±)N âˆ’rÌ‚ .

EP K c (HU ) = EP K c (HA ) Â· D2	 Â· EP K c (Î±)N âˆ’r
L

= EP	 K c (R(HB	 âˆ’ HA	 ) + 2L ).

âˆ—

= EP K c (IDA ) Â· EP K c (0) Â· EP K c (0)N âˆ’rÌ‚

C2 = EP K c (HB ) Â· EP K c (HA )N âˆ’1 Â· EP K c (râˆ— )mod N 2

= EP K c (IDB âˆ’ IDA + rÌ‚âˆ— ).

EP K c (HU ) = EP K c (HB ) Â· D2	 Â· EP K c (Î±)N âˆ’r

= EP K c (HA )
(3)

= EP K c (HB âˆ’ HA + râˆ— ).

If s = 0, CP calculates

âˆ—

= EP K c (IDA ) Â· EP K c (IDB âˆ’ IDA + rÌ‚âˆ— ) Â·
âˆ—

EP K c (1)N âˆ’rÌ‚ = EP K c (IDB ).
When s = 0, EP K c (HU ) and EP K c (IDU ) can be calculated
in the same way. From the correctness verification, we can see
that the protocol can indeed get maximum tuple from the two
encrypted tuples.
2) Privacy-Preserving Maximum Out of n Protocol: The
goal of PMAXn is to allow CP to get a new ciphertext tuple
TU with maximum HU from the n encrypted tuples T1 , . . . , Tn .
Neither plaintext information nor ciphertext relationship will be
leaked to both CP and PA during running this protocol. The

662

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 2, MARCH 2016

specific construction of PMAXn is proposed in Algorithm 1. CP
first initializes the set Sb with the n encrypted tuples, where
these n tuples are the input of this algorithm. The set is used to
store the candidate encrypted tuples. Another set Sa will also be
used to store the intermediate result of the maximum encrypted
tuple between T2j and T2j +1 from the set Sb . After comparison, Sa is assigned to Sb . This procedure will be executed until
there is only one encrypted tuple leave in Sb . The tuple is with
maximum probability among the n encrypted tuples. It is worth
noting that the algorithm should check whether the number of
tuples in Sb is odd or not before executing PMAX. If the cardinality of Sb is odd, the algorithm should add one extra tuple
EP K c (0), EP K c (0) to Sb before running PMAX. The overall
procedure of PMAXn is listed in Fig. 3.
3) Privacy-Preserving Top-k Disease Names Retrieval Protocol (TOP-K): We will design TOP-K, which allows PA to get
top-k disease results from CP. The specific construction of TOPK is listed in Algorithm 2. First, CP initializes a set Sa	 , which
is used to store intermediate result. This algorithm will run for
k loops. For each loop, PMAXn will be executed to allow CP
to get the maximum tuple TMAX from set Sa	 . Then, for every
element that belongs to Sa	 , choose random numbers Rj âˆˆ ZN
and calculate
Vj = (EP K c (HMAX ) Â· EP K c (Hj )N âˆ’1 )R j
= EP K c (Rj (HMAX âˆ’ Hj )).
Then, CP uses permutation Ï€i to permute these Vj and denotes these permuted data as VÏ€ i (j ) , and then sends them to PA.
Once these tuples are received, PA will calculate AÏ€ i (j ) and
BÏ€ i (j ) according to the decryption results of VÏ€ i (j ) . CP uses
Ï€iâˆ’1 to get Aj and Bj . By running SM protocol, EP K c (Hj )
and PI D j can be updated by Bj and Aj , respectively. By using
(10), the maximum probability of disease name can be added
to PI D j j =1,...,n d . Moreover, by using (11) the plaintext of
maximum diagnosed probability can be clear to 0, then go on
to find next-maximum probability tuple. After finishing TOPK, PA can get encrypted disease names PI D j j =1,...,n d . Using
private key SKc , PA can only get top-k probability of disease
names. Other disease names are cleaned to 0.
In order to achieve Step 1 in Phase C, CP first needs to judge
whether PA suffers from some specific diseases t by running the
PMAX as follows: Tt = P M AX(TÌ‚t,0 , TÌ‚t,1 ) (t = 1, . . . , nd ).
After getting Tt (t = 1, . . . , nd ), TOP-K should find top-k disease names, the process is implemented in Step 2 of Phase C.
Notice that there are only k real disease names in ID	 and other
nd âˆ’ k disease names are 0. All the calculations executed by
CP can also be run by PU. This is because that the relationship
among the ciphertexts will not be exposed by running TOP-K.
The Necessity of TOP-K in Phase C
The trivial solution of Phase C is quite simple; directly send
all these encrypted diagnosis results back to the PA. The PA
Ë† a,b . Then,
simply decrypts these vectors and gets HÌ‚a,b , ID
the patient can get nd tuples Ha , IDa  by comparing Ha,0
Ë† H .
and Ha,1 , where Ha = max(HÌ‚a,0 , HÌ‚a,1 ) and IDa = ID
a
Next, the patient will rank all the probability Ha by himself
to get top-k probability values and its corresponding disease

names. This idea is simple, however, it may leak PUâ€™s privacy.
For example, if patient only has one symptom (for simplicity,
we suppose X1 = 1), the patient encrypts this symptom vector
as EP K c (X) = (EP K c (1), EP K c (0), . . . , EP K c (0)) and sends
it to PU for diagnosis. PU can use the encrypted symptom
vector to compute EP K c (P (A1 = X1 |Ct = 1)P (Ct = 1)) and
EP K c (P (A1 = X1 |Ct = 0)P (Ct = 0)). After diagnosis, the
patientâ€™s encrypted diagnosis vector can be permuted and sent
back to CP. Once the encrypted diagnosis vectors are received,
patient can use the private key SKc to decrypt these encrypted values as P (A1 = X1 |Ct = 1)P (Ct = 1), IDt  and
P (A1 = X1 |Ct = 1)P (Ct = 0), IDt  (k = 1, . . . , nd ). Due
to P (Ct = 1) = 1 âˆ’ P (Ct = 0), the patient can easily know
all the P (Aj = X1 |Ct = 1) and P (Aj = X1 |Ct = 0). It cannot satisfy privacy requirements defined in Section III-B. In
practical scenarios, patient only cares about his diagnosis results
rather than diagnosed probability Ht,1 and Ht,0 . In this case, CP
only needs to send the encrypted top-k diagnosed disease names
back to PA. The key idea in Phase C of our proposed PPCD is
to retrieve encrypted top-k diagnosis results from the universal
encrypted diagnosis result set without leaking probability HÌ‚a,1
and HÌ‚a,0 to PA.
V. PRIVACY ANALYSIS
In this section, we analyze our proposed PPCD to check
whether it can achieve the privacy requirements illustrated in
Section III-B.

LIU et al.: PRIVACY-PRESERVING PATIENT-CENTRIC CLINICAL DECISION SUPPORT SYSTEM ON NAIÌˆVE BAYESIAN CLASSIFICATION

663

A. Privacy of Phase A

B. Privacy of Phase B

Because the Phase A of the PPCD is depended on AHPA
scheme, we first analyze the privacy of the AHPA, and then show
our Phase A of PPCD can protect PDâ€™s privacy simultaneously.
1) Privacy of AHPA: The AHPA scheme is based on traditional El-Gamal encryption scheme [17]. Here, we analyze that
our AHPA can protect PDâ€™s privacy, even CP and PU collude. By
using the Encrypt algorithm of AHPA, x(i) can be encrypted. The
(i)
original ciphertext are formed as {g r i , e(g, g)x e(g, g)a i , 1 r i }.
The security of the original ciphertext can be reduced to the
following hard problem: given {g a , e(g, g)r }, it is still hard
to distinguish whether e(g, g)ar is equal to e(g, g)z or not,
where z âˆˆ Zp . This assumption is harder than DBDH assumption (given g a , g b , g c , it is hard to distinguish whether e(g, g)abc
is equal to e(g, g)z ). This is because give e(g, g)ab , it is still
hard to get g a and g b . If CP gets the original ciphertext, even
CP and PU collude, CP or PU cannot get x(i) without knowing
ai,1 (ai,1 is DP iâ€™s private key which is kept privately by DP i).
Once the original ciphertext is sent to CP, CP uses ska i â†’P
to convert ciphertext in iâ€™s domain into PUâ€™s domain. However,
PU cannot decrypt the individual converted ciphertext [x(i) ]pk p
only using his own private key, or even with re-encryption key
	
ska i â†’P . It is because e(g, g)r i r i are introduced to [x(i) ]pk p during the re-encryption. In order to get the plaintext, PU needs
	
	
to get g r i in order to compute e(g, g)r i r i . However, PU can	
not get g r i only by giving DP iâ€™s public key e(g, g)a i , 1 , the
	
re-encryption key g a a , 1 p 2 g r i , and PUâ€™s private key p2 (given
e(g, g)a i , 1 , it is hard to compute g a i , 1 ). When encrypted message from all the DP i are aggregated, PU can successfully
get the aggregated message by using R and his own private
key p2 .
2) Privacy of Phase A: In order to train naÄ±Ìˆve Bayesian classifier, all the historical medical data should be sent to PU for
processing. However, these data cannot be sent to PU directly
because of the external adversary. In order to protect historical medical data from eavesdropping during the transmission,
all the individual historical medical data should be encrypted
by using AHPA scheme with DPâ€™s public key. Because only
DP holds his own private key, other parties cannot decrypt the
ciphertext without DPâ€™s public key. Once the encrypted historical medical data are received, CP uses the reencryption key
to transfer the ciphertext in DP iâ€™s domain into PUâ€™s domain.
Then, CP aggregates these historical medical data into one encrypted vectors. It is because the individual data contain some
sensitive information which is related to patientâ€™s privacy. Even
if the CP and PU are colluded, i.e, CP directly sends encrypted
historical medical data or transferred encrypted historical medical data to PU without aggregation, PU still cannot get the
DP iâ€™s medical data due to the privacy of AHPA scheme (see
Section V-A2 for detailed privacy analysis). Once received the
aggregated encrypted vector, PU can decrypt it and train the
naÄ±Ìˆve Bayesian classifier. Because of the aggregation technique,
PU cannot know individual DP iâ€™s historical medical data by
only using aggregated medical data. Therefore, the individual
historical medical data are privacy preserving and Phase A satisfies the privacy requirements.

In order to compute disease risk of the patient, PAâ€™s symptom information should be sent to PU for prediction. To prevent external adversary from eavesdropping, all the symptom
information should be transmitted as encrypted form. External
adversary cannot decrypt the ciphertext without PAâ€™s private
key. In addition, PU cannot get the plaintext of the PAâ€™s symptom information. In order to predict PAâ€™s disease risk by using
the naÄ±Ìˆve Bayesian classifier, some calculations must be done
over the ciphertext. Thanks to additive homomorphism property of Paillier encryption [10], EP K c (1 âˆ’ Xj ) can be easily calculated. The EP K c (Xj ). EP K c (P (Aj = Xj |Ct = 1))
can be calculated by using (1) without decryption. It is because P (Aj = 1|Ct = 1) and P (Aj = 0|Ct = 1) are stored as
plaintext form in PU and the scalar-multiplicative homomorphism of Paillier encryption can be used to compute EP K c (Xj ).
EP K c (P (Aj = Xj |Ct = 1)). Furthermore, KÌ‚t,1 and KÌ‚t,0 are
needed to be calculated. From (2), we can see that multiplication
of the plaintext is needed. Fortunately, SM protocol should be
used in this phase and its privacy has been proved in [11]. Nothing will be leaked to both sides during the execution. Because
all the calculations in Phase B are over ciphertext, PU cannot get any information from this procedure, privacy-preserving
computing can be achieved in Phase B.
C. Privacy of Phase C
In order to prove the privacy of Phase C in PPCD, the privacy
of PMAX, PMAXn , and TOP-K should be proved first. We will
use simulation model defined in secure two-party protocols for
semihonest adversaries [22], [23] to prove these three protocols.
This model is widely used to prove the privacy of multiparty
protocols. We will illustrate this model as follows.
We say a protocol is privacy preserving if each party in the
protocol can be computed based on its own inputs and outputs
only. We require that a partyâ€™s view in the protocol execution can
be simulated only given its own input and output. It is indicated
that each party learns nothing from the protocol by executing
itself. Let ViewÎ 
B be the real view of party B when interacting
with party A with private input x. Party Aâ€™s privacy can be
guaranteed if there exists a simulator SimB such that for any x,
SimB (y, f1 (x, y)) can generate a view indistinguishable from
the Bâ€™s view in the execution of the real protocol, that is
c

{SimB (y, f1 (x, y))}x,y âˆˆ{0,1}âˆ— â‰¡{ViewÎ 
B (x, y)}x,y âˆˆ{0,1}âˆ— .
The Bâ€™s privacy means that party B cannot get extra information
except those derived from x and b = f (x, y). Its privacy can be
achieved if there exists a simulator SimA such that for any y
with f2 (x, y) = b, SimA can generate a view indistinguishable
from the view of party B in the real execution, that is
c

{SimA (x, f2 (x, y))}x,y âˆˆ{0,1}âˆ— â‰¡{ViewÎ 
A (x, y)}x,y âˆˆ{0,1}âˆ— .
1) Privacy of PMAX: We first illustrate that our PMAX can
achieve PUâ€™s privacy. We construct a simulator SimA , which
simulates the protocol by selecting two randomly encrypted

664

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 2, MARCH 2016

tuples X1 , Y1  and X2 , Y2  as input, and letting y as PAâ€™s
input.
We now illustrate that the view generated by SimA is indistinguishable from the real view in protocol. SimA first randomly
selects s. By using X1 , Y1  and X2 , Y2 , if s = 1, SimA can
calculate C1	 , C2	 , C3	 by using (3)â€“(5), respectively. If s = 0,
SimA can calculate C1	 , C2	 , C3	 by using (6)â€“(8), respectively.
The view generated by SimA is {y, C1	 , C2	 , C3	 } and the view
in the real execution is {y, C1 , C2 , C3 }. Because of the privacy
of Paillier cryptosystem C1 and C1	 are indistinguishable. The
same is true for C2 and C2	 , C3 and C3	 . Thus, the sequence
of the ciphertexts generated by SimA are computationally
indistinguishable from the sequence in the real execution for
fixed output s. Once C1	 , C2	 , C3	 are received, PA can calculate
D2	 , D3	 according to the decryption result of C1	 . This simulation procedure is the same as that of the real protocol. SimA and
the real view ViewÎ 
A are indistinguishable.
Next, we analyze our PMAX, which can achieve PAâ€™s privacy.
Now, we construct a simulator SimU without the private input
of PA. We need the view generated by SimU to be indistinguishable from the view in the real execution. SimU simulates as follows. The input of SimU are the comparison results b âˆˆ {0, 1}
and PUâ€™s private encrypted tuple X1 , Y1  and X2 , Y2 . SimU
uses X1 , Y1  and X2 , Y2  to construct the C1 , C2 , C3 for the
first step. For the second step, SimU will generate the encryption called M according to the value of b. If b = 0, the SimU
generates M = EP K c (0). If b = 1, the SimU generates a random encryption as M . Finally, the view generated by SimU is
{X1 , Y1 , X2 , Y2 , C1 , C2 , C3 ; M, b}.
Because C1 , C2 , C3 are constructed by using the value
X1 , Y1  and X2 , Y2 , the distribution is identical to that of the
real execution. For fixed output b, the sequence of the ciphertexts are computationally indistinguishable from the sequence
in the real execution. Thus, PU cannot get PAâ€™s private input.
PMAX n just calls PMAX as subprotocol and all the messages
are encrypted by using Paillier encryption. Due to the privacy
of PMAX, no information are leaked to PU and PA.
2) Privacy of TOP-K: The protocol will run for k times and
the simulation procedure is similar. For simplicity, we only take
one round for example to illustrate.
We first illustrate our TOP-K, which can achieve PUâ€™s privacy.
We construct a simulator SimA , which simulates the protocol
by randomly selecting the encryption tuples T1	 , . . . , Tn	 as input. Using these random encryptions, PU can use PMAXn to
calculate TMAX and then calculate Vj	 by. Due to the privacy of
the Paillier encryption and PMAXn , all Vj	 are indistinguishable
from Vj in real execution. Thus, this simulation is the same as
that of the real protocol. SimA and the real view ViewÎ 
A are
indistinguishable.
Next, we analyze our TOP-K, which can achieve PAâ€™s privacy.
Now, we construct a simulator SimU without private input of
PA. We need the view generated by SimU to be indistinguishable
from the view of CP in the real execution. SimU simulates as follows. The inputs of SimU are the comparison result b âˆˆ {0, 1}
and PUâ€™s private input T1 , . . . , Tn . SimU uses T1 , . . . , Tn to construct V1 , . . . , Vn by using (9) for the first step. For the second
step, SimU will generate the sequence c1 , . . . , cn and d1 , . . . , dn

according to the result value b. If b = 0, the SimU generates one
encryptions with plaintext 0 from c1 , . . . , cn and n âˆ’ 1 other
encryptions of 1. Also, the SimU generates one encryption with
plaintext 0 from d1 , . . . , dn and n âˆ’ 1 others encryptions of 0.
If b = 1, the SimU generates n encryption of 1 and denotes
them as c1 , . . . , cn . Also, SimU generates n encryption of 0
and denotes them as d1 , . . . , dn . Finally, the view generated
by SimU is {T1 , . . . , Tn , V1 , . . . , Vn ; c1 , . . . , cn , d1 , . . . , dn , b}.
Since c1 , . . . , cn and d1 , . . . , dn are constructed by using the
value T1 , . . . , Tn , the distribution is identical to that in the real
execution. For fixed output b, the sequence of the ciphertexts are
computationally indistinguishable from the sequence in the real
execution. Thus, CP cannot get PAâ€™s private input. Moreover, CP
needs to use SM protocol to calculate Epk A (b	i ) and Epk A (yi	 )
by using (10) and (11) respectively. Due to the privacy of SM
protocol (see [11] for detail), both the PUâ€™s privacy and PAâ€™s
privacy can be achieved by running this protocol.
3) Privacy of Phase C: The privacy of Step 1 in Phase C can
be achieved by running PMAX. The privacy of TOP-K can be
achieved since all the calculations are manipulated over ciphertext, the privacy of PMAXn , and the privacy of SM protocol. By
running TOP-K, CP will send nd encryptions of disease name
(include top-k disease names, others are encryption of 0 to PA).
Due to the privacy of TOP-K, CP does not know the relationship
among the ciphertexts, which keeps the privacy of PA in Step 2.
Finally, only the name of disease will be sent to PA, which
guarantees the privacy of PU. Thus, the privacy requirements
can be satisfied in Phase C, which achieves privacy-preserving
computation.

D. Resist to Collusion Attack
In this section, we analyze that our PPCD can achieve the
privacy requirements, which resist collusion attack between CP
and PU. In Phase A, DP i uses pka i to encrypt the message and
sends [x(i) ]pk a i to CP. Due to the character of AHPA scheme,
even though CP and PU collude, x(i) cannot be decrypted from
the original ciphertext [x(i) ]pk a i or the reencrypted ciphertext
[x(i) ]pk p (see Section V-A2 for detailed analysis). In Phase B,
PAâ€™s symptoms are encrypted by using P Kc . Due to the privacy
of Paillier encryption scheme, even CP and PU collude, neither
CP nor P U can get PAâ€™s symptoms without knowing PAâ€™s
private key. In Phase C, due to the privacy of TOP-K, CP does
not know the relationship among the ciphertext (generate nd
new ciphertext from original nd ciphertext, include k disease
names, others are encryption of 0). Even though CP and PU
collude, PU cannot know the patientâ€™s top-k diseases without
PAâ€™s private key SKc . It can be guaranteed by the security of the
Pailliar encryption scheme [10] (adversary cannot get plaintext
from ciphertext without knowing the private key).

VI. PERFORMANCE ANALYSIS
In this section, we analyze the performance of the proposed PPCD in terms of computation cost and communication
overhead.

LIU et al.: PRIVACY-PRESERVING PATIENT-CENTRIC CLINICAL DECISION SUPPORT SYSTEM ON NAIÌˆVE BAYESIAN CLASSIFICATION

TABLE II
EFFECTIVENESS OF PPCD OVER THE REAL DATASET AID
Disease name
YES
NO
Overall

IUB

NRPO

59/59(100%)
45/61(73.77%)
104/120(86.67%)

50/50(100%)
60/70(85.71%)
110/120(91.67%)

A. Computation Cost
We evaluate computation cost of PPCD by using a custom
simulator built in Java. This experiment was run on a test machine with one 2.5-GHz two-core processor and 6-GB RAM.
In the experiment, we consider two datasets. One real dataset
is used from the UCI machine learning repository called acute
inflammations dataset (AID) [24]. We use this dataset to test
the performance of the naÄ±Ìˆve Bayesian classifier by using our
PPCD. We also use synthetic dataset to test all factors which
affect the performance of PPCD.
1) Real Dataset (AID): The AID was created by a medical
expert as a dataset to test the expert system, which was used to
perform the presumptive diagnosis of two diseases of the urinary system. This dataset contains 120 instances. Each instance
contains six attributes [temperature; occurrence of nausea; lumbar pain; urine pushing; micturition pains; burning of urethra,
itch, swelling of urethra outlet] and two decisions [inflammation of urinary bladder (IUB); nephritis of renal pelvis origin
(NRPO)]. All the attribute and decisions can be expressed as
binary bit 1 (YES) or 0 (No) except for temperature. The value
of temperature is varied from 35.5 to 41.5 â—¦ C in the dataset.
Before we use this dataset to classify, all the records should be
normalized to 56 attributes (including 51 attributes represent
for temperature) and two decisions. We first use PPCD to train
naÄ±Ìˆve Bayesian classifier and, then, use this classifier and AID
to test the success rate of the classifier. The result is shown in
Table II. From the table, we can see that all the instances, which
have IUB and NRPO can be successfully classified without false
negative diagnosis. However, there exists false positive diagnosis in AID. The false positive rate of IUB and NRPO diagnosis
are 26.23% and 14.29%, respectively. We also test the running
efficiency about PPCD. In Phase A, it takes 8.848 s for PU to
train the classifier (including 1.368 s for DP i to encrypt all the
symptoms and diseases offline). It takes 187.244 s for CP and
PA to compute a new PAâ€™s disease risk in Phase B (including
2.490 s for DP i to encrypt all the symptoms offline). In phase C,
it takes 8.724 s for CP and PA to retrieve top-1 (most related
diagnose result) by running TOP-K (include 2.490 s for DP i to
initial TOP-K offline).
2) Synthetic Dataset: In order to test all the factors that affect
our PPCD, we use the synthetic dataset to test. The randomly
generated synthetic dataset consists of 500 tuples with 70 attributes. The value of each elements is randomly picked from
0 to 1. There are four factors which affect the total running
time of PPCD: the number of historical medical data (NHMD),
the number of symptom attributes (NSA) contained in data, the
number of diseases (ND) needed to be classified, and the number

665

of diagnosis disease results (NDDR) needed to be retrieved. In
Fig. 4(a)â€“(c), we plot the running time (including total running
time and offline running time) of the PPCD vary with NHMD.
Only the running time of Phase A increases with the number
of data, where other phases are not affected. This is because
Phase A needs to aggregate more data as NHMD increases. It
requires more computational resources, while other phases will
not be affected. In Fig. 4, we plot the total running time of PPCD
which varies with NSA in dataset, from the figure we can see
that the running time of Phase A and Phase B increases with
the number of attributes. With the number of attributes increase,
CP needs more multiplications in order to aggregate the ciphertextin Phase A and calls more SM protocol to calculate
s
P (Fj = Xj |Ct = 1) Â· P (Ct = 1)) in Phase B.
EP K c ( nj =1
In Fig. 4, we plot the offline running time of PPCD, which
varies with NSA in dataset. The running time of all these phases
increases with NSA because more tuples are needed to be encrypted. In Fig. 4, we plot the total running time of PPCD varies
with NDDR. From the figure, we can see that Phase A and Phase
B will not vary with k, which means it will not introduce any
computations to Phase A and Phase B. More loops are required,
which introduces more computation cost to Phase C. In Fig. 4,
we plot the offline running time of PPCD varies with NDDR.
The running time of all these phases are not affected because
no extra tuples is needed to be encrypted during the initialization. In Fig. 4, we plot the total running time of the PPCD vary
with ND. It can be seen that more multiplications are required
in Phase A and more SM protocol are called in Phase B with
increasing of ND. More comparisons are also needed in order
to retrieve top-k disease names in Phase C. In Fig. 4, we plot
the offline running time of PPCD varies with ND. The running
time of all these phases are increased because more tuples are
needed to be encrypted during the initialization.
B. Communication Overhead
In the following, we discuss the communication cost in our
PPCD. The privacy parameter of Paillier encryption system used
is 2048 bits. In order to train naÄ±Ìˆve Bayesian classifier, all historical medical data should be encrypted and sent to CP which
costs O(l Â· (ns + nd )) to transmit. Then, CP needs to aggregate
all the historical medical data into one vector. This aggregated
vector costs O(ns + nd ) to transmit to PU. So the total communication cost of Phase A is O(l Â· (ns + nd )). In our AHPA
scheme, one ciphtertext tuple needs 2048 bits to store, and it
costs (l + 1) Â· (ns + nd ) Â· 2048-bits for CP to store all the data
in Phase A. Extra (l + 1) Â· (ns + nd ) Â· 2047 bits is needed for
storage in CP due to adoption of a privacy-preserving technique
(ciphertext expansion). The nonprivacy-preserving techniqueâ€™s
communication overhead of Phase A is O((l + 1)(ns + nd )).
In order to calculate PAâ€™s diseases, its encrypted symptom vector should be sent to PU to process, which costs O(ns ) to
transmit from PA to PU. After computation, the encrypted diagnosed probability and encrypted disease names should be sent
to CP to store which costs O(nd ). Therefore, the total communication cost of Phase B is O(ns + nd ) and it also costs
CP (ns + 2nd ) Â· 2048 bits to store PAâ€™s ciphertext (include nd

666

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 2, MARCH 2016

Fig. 4. Computation cost over synthetic dataset. (a) NSA = 40, ND = 10, NDDR = 1. (b) NSA = 40, ND = 10, NDDR = 1. (c) NSA = 40, ND = 10,
NDDR = 1. (d) NHMD = 200, ND = 10, NDDR = 1. (e) NHMD = 200, ND = 10, NDDR = 1. (f) NHMD = 200, ND = 10, NSA = 40. (g) NHMD = 40,
ND = 10, NSA = 40. (h) NHMD = 200, NSA = 0, NDDR = 1. (i) NHMD = 200, NSA = 10, NDDR = 1.

encrypted symptoms, nd encrypted disease risks, and nd encrypted disease names). The total communication cost of
nonprivacy-preserving technique of Phase B is O(ns + nd ) and
it also costs CP extra (ns + 2nd ) Â· 2047 bits to store due to the
usage of encryption technique. In Phase C, it first costs O(nd )
(1 round, between CP and PA by call PMAX) to achieve Step 1,
then needs O((nd )2 ) to calculate PMAXn (log2 nd rounds). After that, it takes O(k Â· (nd )2 ) (k(log2 nd + 1) rounds) to achieve
TOP-K in Step 2. Therefore, the total communication overhead is
O(k Â· (nd )2 ) (k Â· log2 nd + k + 1 rounds) in Phase C for PPCD.
It also costs 2nd Â· 2048 bits for CP to store the newly generated ciphertext (include nd encrypted top-k disease risks, and
nd encrypted top-k disease names). If a nonprivacy-preserving
technique is used, it does not need Phase C for selection, which
means the nonprivacy-preserving technique does not need extra
O(k Â· (nd )2 ) (k Â· log2 nd + k + 1 rounds) communication overhead and extra 2nd Â· 2048 bits for storage in CP.

VII. RELATED WORK
The computer-assisted CDSS was proposed by Ledley and
Lusted [25] who found that physicians have an imperfect knowledge of how they solve diagnostic problems. This paper dealt
with Bayesian and decision-analytic diagnostic systems and experimental prototypes appeared within a few years [3]. Warner
et al. [26] developed the first operational Bayesian CDSS for the
diagnosis of congenital heart diseases based on history, physical exam, and cardiac catheterization findings. Schurink et al.
[5] discussed computer-based decision-support systems to assist
intensive care unit physicians in the management of infectious
diseases. In this paper, they described several computer models (such as bayesian networks) that may be used in clinical
practice in the near future. As the privacy of the patientâ€™s information becomes more and more important, naÄ±Ìˆve Bayesian
classification were considered as a challenge to privacy preservation due to their natural tendency to use sensitive information

LIU et al.: PRIVACY-PRESERVING PATIENT-CENTRIC CLINICAL DECISION SUPPORT SYSTEM ON NAIÌˆVE BAYESIAN CLASSIFICATION

about individuals. Privacy-preserving naÄ±Ìˆve Bayesian classifier
was first proposed in [28], where data are horizontal partitioned
(different patientâ€™s tuples with same attribute are partitioned)
and stored distributively in different sites. KantarcÄ±olu et al.
[28] achieved naÄ±Ìˆve Bayesian classifier by using the secure sum
protocol [29], which can support both nominal attributes and
numeric attributes. Later, Yi and Zhang [30] improved the [28]
by both efficiency and privacy and this scheme could prevent
eavesdropping attack. This two-party protocol can also be easily extended to multiparty protocol. Different from horizontal
partition, another kind of data partition called vertically partition (one patientâ€™s different attributes are partitioned) were
introduced to privacy-preserving naÄ±Ìˆve Bayesian classifier by
using secure scalar product protocol [31], [32]. Vaidya et al.
[33] gave us a comprehensive study on both vertically as well as
horizontally partitioned data. The data in the existing privacypreserving naÄ±Ìˆve Bayesian classifier scheme were distributively
stored in different parties as a part of the whole data space.
One party should manage and store these data as plaintext.
With the development of cloud computing technique, outsourcing the encrypted data to cloud server to store was more common [34], [35]. However, cloud server was always a third-party
servers. Storing the patient health data in the third-party servers
entailed serious threats to data privacy. Therefore, it was imperative for user to store and manage the outsourced data in
a privacy-preserving way. Li et al. [36] gave a novel patientcentric framework and a suite of mechanisms for data access
control to personal health record stored in cloud servers. It provided a patient-centric model of scalable and secure health information exchange. Elmehdwi et al. [8] proposed a scheme which
allows user to make k-nearest neighbor (k-NN) query on oursourced encrypted database. This scheme also gave lots of secure
primitives and they used these primitives to construct k-NN classifier in [11]. Ayday et al. [37] used logistic regression model
to compute disease risk privately by using genomic, clinical,
and environmental data. Recently, Rahulamathavan et al. [38]
proposed a privacy-preserving clinical decision support system
using a Gaussian kernel-based support vector machine (SVM).
During the diagnosis process, patientsâ€™ data always remained in
the encrypted form which can protect patientsâ€™s privacy. More
comprehensive study about privacy-preserving SVM classification can be found in [39]â€“[41].
VIII. CONCLUSION
In this paper, we have proposed a PPCD using naÄ±Ìˆve Bayesian
classifier. By taking the advantage of emerging cloud computing technique, PC can use big medical dataset stored in CP to
train naÄ±Ìˆve Bayesian classifier, and then apply the classifier for
disease diagnosis without compromising the privacy of DP. In
addition, the patient can securely retrieve the top-k diagnosis
results according to their own preference in our system. Since
all the data are processed in the encrypted form, our system
can achieve patient-centric diagnose result retrieval in privacypreserving way. For the future work, we will exploit PPCD
with other advanced data mining techniques, such as SVM
classification.

667

REFERENCES
[1] (2013). Transforming health care through big data strategies
for leveraging big data in the health care industry. [Online]. Available: http://ihealthtran.com/wordpress/2013/03/iht%C2%B2releases-big-data-research-report-download-today/
[2] E. S. Berner, Clinical Decision Support Systems. New York, NY, USA:
Springer, 2007.
[3] M. A. Musen, B. Middleton, and R. A. Greenes, â€œClinical decision-support
systems,â€ in Biomedical Informatics. New York, NY, USA: Springer,
2014, pp. 643â€“674.
[4] H. Monkaresi, R. A. Calvo, and H. Yan, â€œA machine learning approach
to improve contactless heart rate monitoring using a webcam,â€ IEEE
J. Biomed. Health Informat., vol. 18, no. 4, pp. 1153â€“1160, Jul. 2014.
[5] C. Schurink, P. Lucas, I. Hoepelman, and M. Bonten, â€œComputer-assisted
decision support for the diagnosis and treatment of infectious diseases in
intensive care units,â€ Lancet Infectious Dis., vol. 5, no. 5, pp. 305â€“312,
2005.
[6] I. Kononenko, â€œMachine learning for medical diagnosis: History, state of
the art and perspective,â€ Artif. Intell. Med., vol. 23, no. 1, pp. 89â€“109,
2001.
[7] N. LavracÌŒ, I. Kononenko, E. Keravnou, M. Kukar, and B. Zupan, â€œIntelligent data analysis for medical diagnosis: Using machine learning and
temporal abstraction,â€ Artif. Intell. Commun., vol. 11, no. 3, pp. 191â€“218,
1998.
[8] Y. Elmehdwi, B. K. Samanthula, and W. Jiang, â€œSecure k-nearest neighbor
query over encrypted data in outsourced environments,â€ in Proc. IEEE
30th Int. Conf. Data Eng., pp. 664â€“675, 2014.
[9] K. M. Leung, â€œNaive Bayesian classifier,â€ Tech. Notes Polytechnic
Univ. Dept. Comput. Sci./Finance Risk Eng., (2007). [Online]. Available:
http://cis.poly.edu/ mleung/FRE7851/f07/naiveBayesianClassifier.pdf
[10] P. Paillier, â€œPublic-key cryptosystems based on composite degree
residuosity classes,â€ in Proc. Adv. Cryptol. Int. Conf. Theory
Appl. Cryptograp. Techn., Prague, Czech Republic, May 2â€“6, 1999,
pp. 223â€“238.
[11] Y. Elmehdwi, B. K. Samanthula, and W. Jiang, â€œk-nearest neighbor classification over semantically secure encrypted relational data,â€
IEEE Trans. Knowledge Data Eng., (2015). [Online]. Available:
http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6930802.
[12] A. McCallum and K. Nigam, â€œA comparison of event models for naive
Bayes text classification,â€ in Proc. Artif. Intell. Workshop Learn. Text
Categorization, 1998, vol. 752, pp. 41â€“48.
[13] J. Chen, H. Huang, S. Tian, and Y. Qu, â€œFeature selection for text classification with naÄ±Ìˆve Bayes,â€ Expert Syst. Appl., vol. 36, no. 3, pp. 5432â€“5435,
2009.
[14] I. Rish, â€œAn empirical study of the naive Bayes classifier,â€ in Proc. Int.
Joint Conf. Artif. Intell. Workshop Empirical Methods Artif. Intell., vol. 3,
no. 22, 2001, pp. 41â€“46.
[15] R. Bellazzi and B. Zupan, â€œPredictive data mining in clinical medicine:
current issues and guidelines,â€ Int. J. Med. Informat., vol. 77, no. 2,
pp. 81â€“97, 2008.
[16] J. L. Hellerstein, T. Jayram, and I. Rish, Recognizing End-User Transactions in Performance Management, IBM TJ Watson Research Center,
Yorktown Heights, NY, USA, 2000.
[17] T. ElGamal, â€œA public key cryptosystem and a signature scheme based
on discrete logarithms,â€ in Advances in Cryptology. New York, NY, USA:
Springer, 1985, pp. 10â€“18.
[18] B. K. Samanthula, Y. Elmehdwi, G. Howser, and S. Madria, â€œA secure
data sharing and query processing framework via federation of cloud
computing,â€ Inf. Syst., vol. 48, pp. 196â€“212, 2015.
[19] T. T. A. Dinh and A. Datta, â€œStream on the sky: Outsourcing access control
enforcement for stream data to the cloud, arXiv preprint arXiv:1210.0660,
(2012). [Online] Available: http://arxiv.org/abs/1210.0660
[20] D. Boneh, E.-J. Goh, and K. Nissim, â€œEvaluating 2-DNF formulas on
ciphertexts,â€ in Theory of Cryptography. New York, NY, USA: Springer,
2005, pp. 325â€“341.
[21] A. Shiryaev, â€œBayes formula,â€ in Encyclopedia of Mathematics.
New York, NY, USA: Springer, 2011.
[22] Y. Lindell and B. Pinkas, â€œA proof of security of YAOS protocol for
two-party computation,â€ J. Cryptol., vol. 22, no. 2, pp. 161â€“188, 2009.
[23] O. Goldreich, Foundations of Cryptography: Volume 2, Basic Applications. Cambridge, U.K.: Cambridge Univ. Press, 2009, vol. 2.
[24] Acute inflammations data set, UCI machine learning repository. (2009). [Online]. Available: https://archive.ics.uci.edu/ml/datasets/
Acute+Inflammations/

668

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 2, MARCH 2016

[25] R. S. Ledley and L. B. Lusted, â€œReasoning foundations of medical diagnosis,â€ Science, vol. 130, no. 3366, pp. 9â€“21, 1959.
[26] H. R. Warner, A. F. Toronto, L. G. Veasey, and R. Stephenson, â€œA
mathematical approach to medical diagnosis: Application to congenital heart disease,â€ J. Amer. Med. Assoc., vol. 177, no. 3, pp. 177â€“183,
1961.
[27] C. Schurink, P. Lucas, I. Hoepelman, and M. Bonten, â€œComputer-assisted
decision support for the diagnosis and treatment of infectious diseases in
intensive care units,â€ Lancet Infectious Dis., vol. 5, no. 5, pp. 305â€“312,
2005.
[28] M. KantarcÄ±oglu, J. Vaidya, and C. Clifton, â€œPrivacy preserving naive
bayes classifier for horizontally partitioned data,â€ in Proc. IEEE Int. Conf.
Workshop Privacy Preserving Data Min., 2003, pp. 3â€“9.
[29] C. Clifton, M. Kantarcioglu, J. Vaidya, X. Lin, and M. Y. Zhu, â€œTools for
privacy preserving distributed data mining,â€ ACM SIGKDD Explorations
Newslett., vol. 4, no. 2, pp. 28â€“34, 2002.
[30] X. Yi and Y. Zhang, â€œPrivacy-preserving naive Bayes classification on
distributed data via semi-trusted mixers,â€ Inf. Syst., vol. 34, no. 3,
pp. 371â€“380, 2009.
[31] A. Amirbekyan and V. Estivill-Castro, â€œA new efficient privacy-preserving
scalar product protocol,â€ in Proc. 6th Australas. Conf. Data Min. Analytics,
2007, pp. 209â€“214.
[32] R. Lu, H. Zhu, X. Liu, J. K. Liu, and J. Shao, â€œToward efficient and
privacy-preserving computing in big data era,â€ IEEE Netw., vol. 28, no. 4,
pp. 46â€“50, Jul./Aug. 2014.
[33] J. Vaidya, M. Kantarcioglu, and C. Clifton, â€œPrivacy-preserving naÄ±Ìˆve
Bayes classification,â€ Very Large Data Bases J., vol. 17, no. 4, pp. 879â€“
898, 2008.
[34] A. Abbas and S. U. Khan, â€œA review on the state-of-the-art privacypreserving approaches in the e-health clouds,â€ IEEE J. Biomed. Health
Informat., vol. 18, no. 4, pp. 1431â€“1441, Jan. 2014.
[35] Y. Tong, J. Sun, S. S. M. Chow, and P. Li, â€œCloud-assisted mobile-access
of health data with privacy and auditability,â€ IEEE J. Biomed. Health
Inform., vol. 18, no. 2, pp. 419â€“429, Mar. 2014.
[36] M. Li, S. Yu, Y. Zheng, K. Ren, and W. Lou, â€œScalable and secure sharing
of personal health records in cloud computing using attribute-based encryption,â€ IEEE Trans. Parallel Distrib. Syst., vol. 24, no. 1, pp. 131â€“143,
Jan. 2013.
[37] J.-P. Hubaux, J. Fellay, E. Ayday, M. Laren, J. L. Raisaro, P. J.
Mclaren, â€œPrivacy-preserving computation of disease risk by using
genomic, clinical, and environmental data,â€ in Proc. USENIX Security Workshop Health Inf. Technol., (2013). [Online]. Available:
http://dx.doi.org/10.1155/2014/827371.
[38] Y. Rahulamathavan, S. Veluru, R. Phan, J. Chambers, and M. Rajarajan, â€œPrivacy-preserving clinical decision support system using Gaussian
kernel based classification,â€ IEEE J. Biomed. Health Informat., vol. 18,
no. 1, pp. 56â€“66, Jan. 2014.
[39] K. Lin and M. Chen, â€œOn the design and analysis of the privacy-preserving
SVM classifier,â€ IEEE Trans. Knowl. Data Eng., vol. 23, no. 11, pp. 1704â€“
1717, Nov. 2011.
[40] H. Yu, X. Jiang, and J. Vaidya, â€œPrivacy-preserving SVM using nonlinear kernels on horizontally partitioned data,â€ in Proc. ACM Symp. Appl.
Comput. 2006, pp. 603â€“610.
[41] H. Li, L. Xiong, L. Ohno-Machado, and X. Jiang, â€œPrivacy preserving
RBF kernel support vector machine,â€ BioMed. Res. Int., vol. 2014, 2014.

Ximeng Liu (Sâ€™13) received the B.Sc. degree in electronic engineering from Xidian University, Xiâ€™an,
China, in 2010, where he is currently working toward
the Ph.D. degree at the School of Telecommunications Engineering.
He is a Visiting Ph.D. student at the INFINITUS
lab, School of Electrical and Electronics Engineering, Nanyang Technological University, Nanyang,
Singapore. His research interests include applied
cryptography and big data security.

Rongxing Lu (Sâ€™09â€“Mâ€™11) received the Ph.D. degree in computer science from Shanghai Jiao Tong
University, Shanghai, China, in 2006, and the Ph.D.
degree in electrical and computer engineering from
the University of Waterloo, Waterloo, ON, Canada,
in 2012.
Since May 2013, he has been with the School
of Electrical and Electronic Engineering, Nanyang
Technological University, Singapore, as an Assistant
Professor. His research interests include computer,
network and communication security, applied cryptography, security and privacy analysis for vehicular network, eHealthcare system, and smart grid communications.
Dr. Lu received the Canada Governor General Gold Medal. He also received
the IEEE Communications Society Asia Pacific Outstanding Young Researcher
Award in 2013.

Jianfeng Ma received the B.Sc. degree in mathematics from Shaanxi Normal University, Xiâ€™an,
China, in 1985, and the M.Sc. and Ph.D. degrees
in computer software and communications engineering from Xidian University, Xiâ€™an, in 1988 and 1995,
respectively.
He is currently a Professor and Ph.D. Supervisor
at the School of Computer Science and Technology,
Xidian University. His current research interests include information and network security, wireless and
mobile computing systems, and computer networks.
He has published more than 200 refereed articles in these areas and coauthored more than ten books. He is a Senior Member of the Chinese Institute of
Electronics.

Le Chen received the B.Sc. degree from the Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China, in 2007.
He is working toward the Ph.D. degree with the same
university.
He is currently a Visiting Scholar with the INFINITUS Lab, School of Electrical and Electronics Engineering, Nanyang Technological University,
Singapore. His research interests include secure data
aggregation, wireless network security, and applied
cryptography.

Baodong Qin received the B.Sc. degree in information security and the M.Sc degree in system analysis and integration from Shandong University, Jiâ€™na,
China, in 2004 and 2007, respectively. He is currently working toward the Ph.D. degree at the School
of Electronic Information and Electrical Engineering,
Shanghai Jiao Tong University, Shanghai, China.
He is a Research Assistant at the School of Information System, Singapore Management University, Singapore. His research interests include applied
cryptography and provable security.

