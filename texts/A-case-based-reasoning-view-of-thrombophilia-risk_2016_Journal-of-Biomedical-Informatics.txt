Journal of Biomedical Informatics 62 (2016) 265–275

Contents lists available at ScienceDirect

Journal of Biomedical Informatics
journal homepage: www.elsevier.com/locate/yjbin

A case-based reasoning view of thrombophilia risk
João Vilhena a, Henrique Vicente a,e, M. Rosário Martins b, José M. Grañeda c, Filomena Caldeira c,
Rodrigo Gusmão c, João Neves d, José Neves e,⇑
a

Departamento de Química, Escola de Ciências e Tecnologia, Universidade de Évora, Évora, Portugal
Departamento de Química, Escola de Ciências e Tecnologia, Laboratório HERCULES, Universidade de Évora, Évora, Portugal
c
Serviço de Patologia Clínica do Hospital do Espírito Santo de Évora EPE, Évora, Portugal
d
Drs. Nicolas & Asp, Dubai, United Arab Emirates
e
Centro Algoritmi, Universidade do Minho, Braga, Portugal
b

a r t i c l e

i n f o

Article history:
Received 10 March 2016
Revised 7 July 2016
Accepted 8 July 2016
Available online 9 July 2016
Keywords:
Thrombophilia
Venous thromboembolism
Logic programming
Knowledge representation and reasoning
Case-based reasoning
Similarity analysis

a b s t r a c t
Thrombophilia stands for a genetic or an acquired tendency to hypercoagulable states that increase the
risk of venous and arterial thromboses. Indeed, venous thromboembolism is often a chronic illness,
mainly in deep venous thrombosis and pulmonary embolism, requiring lifelong prevention strategies.
Therefore, it is crucial to identify the cause of the disease, the most appropriate treatment, the length
of treatment or prevent a thrombotic recurrence. Thus, this work will focus on the development of a diagnosis decision support system in terms of a formal agenda built on a logic programming approach to
knowledge representation and reasoning, complemented with a case-based approach to computing.
The proposed model has been quite accurate in the assessment of thrombophilia predisposition risk,
since the overall accuracy is higher than 90% and sensitivity ranging in the interval [86.5%, 88.1%]. The
main strength of the proposed solution is the ability to deal explicitly with incomplete, unknown, or even
self-contradictory information.
Ó 2016 Elsevier Inc. All rights reserved.

1. Introduction
Thrombophilia described genetic or acquired tendency to
hypercoagulable states that increase the risk of venous thrombosis
and, in some cases arterial thrombosis [1]. Venous ThromboEmbolism (VTE) is the most common vascular disease after acute
myocardial infarction and stroke. It is represented by two main
clinical events: Deep Venous Thrombosis (DVT) and Pulmonary
Embolism (PE), which often constitute a unique clinical picture in
which PE follows DVT [2]. Primary hypercoagulable states are generally inherited abnormalities of coagulation such as antithrombin
III deficiency, protein C and protein S deficiency. High risk thrombophilia includes natural coagulation inhibitors (antithrombin
deficiency, protein C deficiency, protein S deficiency and homozygosity for factor V Leiden or the prothrombin G20210A gene mutation, compound heterozygosity for factor V Leiden and the
prothrombin gene mutation) [3,4]. Secondary hypercoagulable
states are frequently acquired disorders in patients with underlying systemic diseases or clinical conditions, known to be associated
⇑ Corresponding author.
E-mail addresses: jmvilhena@gmail.com (J. Vilhena), hvicente@uevora.pt
(H. Vicente), mrm@uevora.pt (M.R. Martins), graneda1@sapo.pt (J.M. Grañeda),
filomenacaldeira1@gmail.com
(F.
Caldeira),
gusmao.rodrigo@gmail.com
(R. Gusmão), joaocpneves@gmail.com (J. Neves), jneves@di.uminho.pt (J. Neves).
http://dx.doi.org/10.1016/j.jbi.2016.07.013
1532-0464/Ó 2016 Elsevier Inc. All rights reserved.

with an increased risk of thrombosis (e.g., malignancy, pregnancy,
use of oral contraceptives, myeloproliferative disorders, hyperlipidemia, diabetes mellitus and abnormalities of blood vessels). The
most common acquired thrombophilia is antiphospholipid antibody syndrome [5]. Furthermore, the long distance travel is often
associated with an up to 4-fold increased risk of VTE compared
to non-travelers [6]. Air pollution was also associated to the hypercoagulable states in patients with DVT [7].
The incidence of VTE is estimated at 56–160/100.000 people/year
[8], and strongly age-dependent, rising nearly 1% per year in old age
[9]. Studies show that about 70% of patients presenting a first episode
of VTE are over 60 years old, and the rate of recurrence is higher when
the first episode of VTE occurs before 60 years old [10]. Patients with
VTE have laboratorial abnormalities and clinical conditions that are
associated with an increased risk of thrombosis (prethrombotic
states) or have recurrent thrombosis without recognizable predisposing factors (thrombosis-prone). The stated above highlights
how it is important to assess the patient’s clinical probability for
VTE. In this context, the Wells score has been commonly used,
namely in patients with suspected DVT or PE [11]. Based on Wells
score the physician can order the D-dimer test as a marker of endogenous fibrinolysis [11]. Follow-up of patients for prolonged periods
after an initial DVT or PE has revealed a startling fact, i.e., VTE often
is a chronic illness requiring lifelong prevention strategies. Thus, it

266

J. Vilhena et al. / Journal of Biomedical Informatics 62 (2016) 265–275

is crucial to identify the cause, the most appropriate treatment, how
long the treatment should be or how to prevent a thrombotic recurrence [12]. In the case of patients with a high risk of clinical complications preventive actions should be taken. The screening for
thrombophilia is mandatory in three high-risk groups, namely
women who are prescribed oral oestrogen preparations, pregnancy
and the puerperium and patients undergoing major orthopaedic surgery [13]. In addition, a significant number of arterial and venous
thrombotic episodes, especially among young individuals, occur
without a plausible explanation [2]. So, more studies are necessary
to reach a correct identification of factors associated with these diseases in order to assess the individual risk of thrombosis, and promote more targeted prophylactic and therapeutic alternatives.
In this study the complex pathophysiologic features of these
hypercoagulable states (i.e., genetic, environmental and acquired risk
factors) are discussed, and the problem was tackled with Artificial
Intelligence (AI) based methodologies and techniques for problem
solving. Thus, this work will focus on the development of an AI
grounded Decision Support System aiming the early diagnosis of
thrombophilia and signalize patients with hypercoagulable states.
The computational framework was built on top of a Logic Programming Case Base approach to knowledge representation and reasoning, which caters for the handling of incomplete, unknown, or even
self-contradictory information. Clustering methods centered on an
analysis of attribute’s similarities were used to distinguish and aggregate historical data according to the context under which it was
added to the Case Base, therefore enhancing the prediction process.
2. Background
2.1. Case based reasoning
A Case Based Reasoning (CBR) methodology for problem solving
stands for an act of finding and justifying a solution to a given

problem based on the consideration of similar past ones, by reprocessing and/or adapting their data or knowledge [21,22]. In CBR –
the cases – are stored in a Case Base, and those cases that are similar (or close) to a new one are used in the problem solving process.
There are several examples on the literature concerning the use of
CBR as a problem-solving methodology to be used in problems in
Medicine. Different researchers have reviewed more than thirty
CBR systems/projects [23,24] revealing that CBRs have been widely
employed in the medical domain, including disease diagnosis, classification, treatment and management. Indeed, a CBR approach
used in mental health problems, in order to predict the effect of
treatments of patients with anxiety disorders showed 65% of correct predictions in the absence of similarity restrictions, while for
scenario with similarity restrictions (i.e., under the condition that
the prediction was based only on cases with a similarity of at least
0.62), the accuracy increased to 80% [25]. Another study presents a
fuzzy ontology-based semantic CBR system for a decision support
system to answer complex medical queries related to semantic
understanding of medical concepts and handling of vague terms
in diabetes diagnosis. The proposed system exhibits an overall
accuracy of 97.7% higher than the accuracies obtained with other
artificial intelligence based tools like the k-nearest neighbour, with
k = 3 (68.3%), decision trees (90.0%), support vector machines
(76.7%), Bayesian classifier (76.7%) and artificial neural networks
(71.7%) [26]. A study of [27] combines CBR and multi-agent systems. The multi-agent architecture aims to take into account the
whole cycle of clinical decision-making, i.e., adaptable to different
medical aspects like the diagnosis, prognosis, treatment and therapeutic monitoring of gastric cancer. In the multi-agent architecture, the ontological agent type uses the knowledge domain in
order to ensure proficiency in the extraction of similar clinical
cases and provide treatment suggestions to patients and physicians. CBR, in turn, is used to memorize and to restore experience
data aiming to solve similar problems [27].

Fig. 1. An extended view of the CBR cycle.

J. Vilhena et al. / Journal of Biomedical Informatics 62 (2016) 265–275

The typical CBR cycle presents the mechanism that should be
followed to have a consistent model. The first stage consists in
the initial description of the problem. The new case is defined
and it is used to retrieve one or more cases from the repository.
At this point it is important to identify the characteristics of the
new problem and retrieve cases with a higher degree of similarity
to it. Thereafter, a solution to the problem emerges, on the Reuse
phase, based on the blend of the new case with the retrieved ones.
The suggested solution is reused (i.e., adapted to the new case), and
a solution is provided [21,22]. However, when adapting the solution it is crucial to have feedback from the user, since automatic
adaptation in existing systems is almost impossible. This is the
Revise stage, in which the suggested solution is tested by the user,
allowing for its correction, adaptation and/or modification, originating the test repaired case that sets the solution to the new problem. The test repaired case must be correctly tested to ensure that
the solution is indeed correct. Thus, one is faced with an iterative
process since the solution must be tested and adapted, while the
result of considering that solution is inconclusive. During the
Retain (or Learning) stage the case is learned and the knowledge
base is updated with the new case [21,22].
Despite promising results, the current CBR systems are neither
complete nor adaptable enough for all domains. In some cases,
the user cannot choose the similarity(ies) method(s) and is
required to follow the system defined one(s), even if they do not
meet their needs. Moreover, in real problems, the access to all necessary information is not always possible, since existent CBR systems have limitations related to the capability of dealing,
explicitly, with unknown, incomplete, and even selfcontradictory information. To make a change, a different CBR cycle
was induced (Fig. 1). It takes into consideration the case’s Qualityof-Information (QoI) and Degree of Confidence (DoC) metrics, matters
that will be explained in the next section. It also contemplates a
cases optimization process present in the Case Base, whenever they
do not comply with the terms under which a given problem as to
be addressed (e.g., the expected DoC on the diagnostic was not
attained. This process, that uses either Particle Swarm optimization
[28] or Genetic procedures [17]), just to name a few, generates a set
of new cases that are then used in the diagnostic, which are conform the invariant:
n
\
ðAi ; Di Þ–;

ð1Þ

i¼1

which denotes that the intersection of the attribute’s values ranges
in the cases that make the Case Base repository, and that were
selected as a first approximation to solve the problem (Ai), and
the ones being generated (Di), cannot be empty. n stands for the
cases that were selected from the Case Base repository. In this CBR
cycle are used Artificial Neural Networks (ANNs) for case’s classification in the following way:
 The extremes of the attribute’s values ranges, as well as their
DoCs and QoIs are fed to the ANN; and
 The outputs are given in a form that ensures that the case may
be used to solve the problem (no (0), yes (1)), and a measure of
the system confidence on such a result (Fig. 2).
2.2. Knowledge representation and reasoning
Logic Programming (LP) has been used for knowledge representation and reasoning, representing a point of convergence in the
disciplines of Logic, Mechanical Theorem Proving and Computer
Science. It may be given in terms of elements of Model Theory
[14,15] or Proof Theory [16,17]. In the present work the Proof Theoretical approach is followed as an extension to LP. Indeed, an
Extended Logic Program is a finite set of clauses in the form:

267

Fig. 2. A case’s classification procedure based on ANNs.

{
:p
not p; not exception p
p
p1 ;    ; pn ; not q1 ;    ; not qm
?ðp1 ;    ; pn ; not q1 ;    ; not qm Þ ðn; m P 0Þ
exceptionp1
...
exceptionpj ð0 6 j 6 kÞ; being k an integer number
} :: scoring v alue

where ‘‘?” is a domain atom denoting falsity, pi, qj and p are classical
ground literals, i.e., either positive atoms or atoms preceded by the
classical negation sign : [16]. Under this formalism, every program
is associated with a set of abducibles [14,15], given here in the form
of exceptions to the extensions of the predicates that make the
whole program. The term scoringvalue stands for the relative weight
of the extension of a specific predicate with respect to the extensions of the peers ones.
Therefore, the Quality-of-Information (QoI) of a logic program
will be given by a truth-value ranging between 0 and 1 [18,19], i.e.:
 QoIi = 1 when the extensions of the predicates that make the
program are known (positive) or false (negative), and QoIi = 0 if
such extensions are unknown; and
 For situations where the extensions of the predicates that make
the program also include abducible sets, its terms (or clauses)
present a QoIi given by:

QoIi ¼ 1=Card

ð2Þ

268

J. Vilhena et al. / Journal of Biomedical Informatics 62 (2016) 265–275

Fig. 5. Setting the QoIs of each attribute’s clause.

argument values or attributes of the terms that make the extension
of a given predicate, having into consideration their domains, are in
pﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2
a given interval [20]. The DoC is figured using DoC ¼ 1  Dl ,
where Dl stands for the argument interval length, which was set
to the interval [0, 1] (Fig. 7).
Thus, the universe of discourse is engendered according to the
information presented in the extensions of such predicates, according to productions of the type:
Fig. 3. QoI’s values for the abducible set for predicatei, when such a set is disjoint.

predicatei 

if the abducible set for predicatei is disjoint (where Card stands for
set cardinality). A pictorial view of this process is given in Fig. 3,
as a pie chart.
If the abducible set is not disjoint, the cardinality K of the
clause’s set is given by
established in the form:

C Card
1

QoIi16i6Card ¼ 1=C Card
; . . . ; 1=C Card
1
Card

þ  þ

C Card
Card ,

under which the QoIs

ð3Þ

where C Card
Card is a card-combination subset, with Card elements. A pictorial view of this process is given in Fig. 4, as a pie chart.
However, a term’s QoI also depends on their attribute’s QoI. In
order to evaluate this metric let us look to Fig. 5, where the segment with limits 0 and 1 stands for every attribute domain, i.e.,
all the attributes range in the interval [0, 1]. [A, B] denotes the
scope where the unknown attributes values for a given predicate
may occur, i.e., one may have:

QoIattributei ¼ 1  kA  Bk

ð4Þ

where ||A–B|| stands for the modulus of the arithmetic difference
between A and B. Therefore, one may have (Fig. 6):
Under this setting, a new metric has to be considered, which
will be denoted as DoC, that stands for one’s confidence that the

[

clausej ððQoIx1 ; DoC x1 Þ; . . . ; ðQoIxl ; DoC xl ÞÞ :: QoIj :: DoC j

16j6m

ð5Þ

S
where , m and l stand, respectively, for set union, the cardinality of
the extension of predicatei and number of attributes of each clause
[20]. The subscripts of QoIs and DoCs, x1, . . . , xl, stand for the attributes values ranges.
As an example, let us consider the logic program given by:

{
:f 1 ððQoIx1 ; DoC x1 Þ; ðQoIx2 ; DoC x2 Þ; ðQoIx3 ; DoC x3 ÞÞ
not f 1 ððQoIx1 ; DoC x1 Þ; ðQoIx2 ; DoC x2 Þ; ðQoIx3 ; DoC x3 ÞÞ
f 1 ððQoI? ; DoC ? Þ; ðQoI2 ; DoC 2 Þ; ðQoI½1;1:75 ; DoC ½1;1:75 ÞÞ :: QoI :: DoC
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
attribute’s

½3; 6½0; 3½0:5; 2
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}

v alues

attribute’s domains

exceptionf 1;1 ððQoI½5;6 ; DoC ½5;6 Þ; ðQoI? ; DoC ? Þ; ðQoI0:8 ; DoC 0:8 ÞÞ :: QoI1 :: DoC 1

exceptionf 1;k ððQoI? ; DoC ? Þ; ðQoI1:5 ; DoC 1:5 Þ; ðQoI½1;2 ; DoC ½1;2 ÞÞ :: QoIk :: DoC k
} :: 1 (once the universe of discourse is set in terms of the extension of only one
predicate)

Fig. 4. QoI’s values for the abducible set for predicatei, when such a set is not disjoint.

J. Vilhena et al. / Journal of Biomedical Informatics 62 (2016) 265–275

269

P
Fig. 6. QoI’s values for the abducible set for predicatei, when such a set is not disjoint. ni¼1 ðQoIi  pi Þ=n denotes the QoI’s average of the attributes of each clause (or term) that
sets the extension of the predicate under analysis. n and pi stand for, respectively, for the attribute’s cardinality and the relative weight of attribute pi with respect to its peers
P
( ni¼1 pi ¼ 1).

425 patients, i.e., 40.6% of the cohort, it was observed hypercoagulable states. The patients include in this subset aged between 22
and 88 years old (average of 43 ± 14 years old) and the gender distribution was 34.4% for male and 65.6% female.
3.3. Extract, transform and load process

Fig. 7. DoC’s evaluation.

where \ denotes a value of the type unknown and f1,1 . . . f1,k stand
for the abducible or exception set for predicate f1.
3. Materials and methods
3.1. Source of data
Aiming to develop a predictive model to assess thrombophilia
predisposition risk, a database was set. The data was taken from
the health records of patients followed up in the Laboratory of Clinical Pathology of the Hospital do Espírito Santo de Évora (HESE),
Portugal. The study protocol was approved by the Ethics Committee of HESE. Demographic data, clinical history, complementary
diagnostic tests and the final diagnosis were obtained by accessing
the HESE Information System.
3.2. Participants
This study included 1046 patients, aged between 22 and
90 years old, with an average of 46 ± 16 years old. The gender distribution was 31.4% and 68.6% for male and female, respectively. In

First of all, it must be said that the Extract, Transform and Load
(ETL) process is independent of the CBR one. With respect to the
problem presented here, it was gathered data from several sources
and carry out an ETL process to organize the information according
to the star schema presented in Fig. 8.
A star schema, which consists of a collection of tables that are
logically related to each other [29]. Thus, to obtain a star schema
it was essential to set a sequence of events. In the former one it
was necessary to understand the problem in study and gather
the parameters that have influence on the final outcome. The following stage was related with the dimensions that would be
needed to define these parameters on the facts table. Finally, information from several sources was collected, transformed according
the fact and dimension table and loaded to fact table.
The star schema conceived for this study (Fig. 8) takes into
account the variables that characterize the patients hypercoagulable states (Facts Table) where Dim Tables show how data were
classified. For example, patients under 40 years old, aged between
40 and 75, and over 75 years old, the assigned values were 0, 1 and
2, respectively.
3.4. A logic programming approach to data processing
It is now possible to build up a knowledge database given in
terms of the extensions of the relations depicted in Fig. 9, which
stand for a situation where one has to manage information aiming
to assess thrombophilia predisposition risk. Under this scenario
some incomplete and/or unknown data is also available. For
instance, in case 1, the Mutations/Polymorphisms is unknown,
which is depicted by the symbol \, while the Age/Heredity Predisposing ranges in the interval [0, 0.05].

270

J. Vilhena et al. / Journal of Biomedical Informatics 62 (2016) 265–275

Fig. 8. An overview of the relational data model.

The values present in Age/Heredity Predisposition column
depend on age group and genetic antecedents. Regarding general
population, the values range between [0, 0.05], [0.05, 0.5], and
0.5, respectively for the <40, between 40 and 75 and >75 age
groups. Concerning population with genetic antecedents the values
are [0.05, 0.5], [0.5, 5] and 5 for the age groups referred previously
[30]. The Blood Group Predisposition column is populated with the
intervals [0.08, 0.14] and [0.18, 0.30] for 0 blood group and for
non-0 blood groups, respectively [31]. The values presented in Natural Anticoagulants (Major), Thrombotic Risk Factors, Mutations/Polymorphisms and Earlier Secondary Factors columns are the sum of the
items belonging to the respective issue (Fig. 8), ranging in the
intervals [0, 3], [0, 9], [0, 8] and [0, 8], respectively.
Applying the algorithm presented in [20] to the fields that make
the knowledge base for thrombophilia predisposition risk assessment (Fig. 9), excluding of such a process the Description ones,
and looking to the DoCs values obtained, it is possible to set the

arguments of the predicate thrombophilia_risk (thrombrisk)
referred to below, that also denotes the objective function with
respect to the problem under analyze:

thrombrisk : Body Mass Index ; Age =Heredity Predisposition ; Blood Group Predisposition ;
Natural Anticoagulants Major ; T hrombotic Risk Factors ; Mutations =Polymorphisms ;
Eaelier Secondary Factors ! f0; 1g
where 0 (zero) and 1 (one) denote, respectively, the truth values
false and true.
The application of the algorithm presented in [20] comprises
several steps. In the former one the clauses or terms of the extension of the predicate are established. In the subsequent stage all
the arguments, of each clause, are transformed into continuous
intervals. In third step the boundaries of the attributes intervals
are set to the interval [0, 1] according to a normalization procedure
given by ðY  Y min Þ=ðY max  Y min Þ, where the Ys stand for themselves. Finally the DoC is evaluated as described in Section 2.2.

Fig. 9. A fragment of the knowledge base to assess thrombophilia predisposition risk.

271

J. Vilhena et al. / Journal of Biomedical Informatics 62 (2016) 265–275

Exemplifying with a term (case) that presents feature vector
(Body Mass Index = 1, Age/Heredity Predisposing = 0.5, Blood Group Predisposing =
[0.18, 0.3], Natural Anticoagulants Major = 2, Thrombotic Risk Factors = [2, 4],
Mutations//Polymorphisms = \, Earlier Secondary Factors = [2, 4]), one may
have:

Begin DoCs evaluation,
The predicate’s extension that sets the Universe-of-Discourse for the term under
observation is fixed
{
:thrombrisk ððQoIBMI ; DoC BMI Þ; . . . ; ðQoIM=P ; DoC M=P Þ; ðQoIES ; DoC ES ÞÞ
not thrombrisk ððQoIBMI ; DoC BMI Þ; . . . ; ðQoIM=P ; DoC M=P Þ; ðQoIES ; DoC ES ÞÞ
thrombrisk ðð11 ; DoC 1 Þ; . . . ; ð1? ; DoC ? Þ; ð1½2;4 ; DoC ½2;4 ÞÞ :: 1 :: DoC
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
attribute’s

½0; 2    ½0; 8½0; 8
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}

v alues

attribute’s domains

} :: 1
The attribute’s values ranges are rewritten
{
:thrombrisk ððQoIBMI ; DoC BMI Þ; . . . ; ðQoIM=P ; DoC M=P Þ; ðQoIES ; DoC ES ÞÞ
not thrombrisk ððQoIBMI ; DoC BMI Þ; . . . ; ðQoIM=P ; DoC M=P Þ; ðQoIES ; DoC ES ÞÞ
thrombrisk ðð1½1;1 ; DoC ½1;1 Þ; . . . ; ð1½0;8 ; DoC ½0;8 Þ; ð1½2;4 ; DoC ½2;4 ÞÞ :: 1 :: DoC
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
attribute’s

v alues ranges

½0; 2    ½0; 8½0; 8
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}

n
\
ðBi ; Ei Þ–;

ð6Þ

i¼1

which denotes that the intersection of the attributes range in the
cases that make the Case Base repository (Bi), and the equals of
the new case (Ei), cannot be empty. Then, the computational process may be continued, and one may have:
thrombrisknew ðð1; 1Þ; ð1; 0:99Þ; ð1; 0:96Þ; ð1; 1Þ; ð1; 0:99Þ; ð1; 1Þ; ð1; 1ÞÞ :: 1 :: 0:99
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ
ﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}

attribute’s domains

} :: 1
The attribute’s boundaries are set to the interval [0,1]
{
:thrombrisk ððQoIBMI ; DoC BMI Þ; . . . ; ðQoIM=P ; DoC M=P Þ; ðQoIES ; DoC ES ÞÞ
not thrombrisk ððQoIBMI ; DoC BMI Þ; . . . ; ðQoIM=P ; DoC M=P Þ; ðQoIES ; DoC ES ÞÞ
thrombrisk ðð1½0:5;0:5 ; DoC ½0:5;0:5 Þ; . . . ; ð1½0;1 ; DoC ½0;1 Þ; ð1½0:25;0:5 ; DoC ½0:25;0:5 ÞÞ
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
attribute’s

v alues ranges once normalized

:: 1 :: DoC
½0; 1    ½0; 1½0; 1
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
attribute’s domains once normalized

} :: 1
The DoC’s values are evaluated
{
:thrombrisk ððQoIBMI ; DoC BMI Þ; . . . ; ðQoIM=P ; DoC M=P Þ; ðQoIES ; DoC ES ÞÞ
not thrombrisk ððQoIBMI ; DoC BMI Þ; . . . ; ðQoIM=P ; DoC M=P Þ; ðQoIES ; DoC ES ÞÞ
ðð1; 1Þ; . . . ; ð1; 0Þ; ð1; 0:97ÞÞ
:: 1 :: 0:83
thrombrisk
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
attribute’s quality-of -information
and respectiv e confidence v alues
½0:5; 0:5 . . . ½0; 1½0:25; 0:5
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
attribute’s

analyzed with string similarity algorithms, namely the Dice coefficient [32].
When confronted with a new case, the system is able to retrieve
all cases that meet such a structure and optimize such a population, i.e., it considers the attributes DoC’s value of each case or of
their optimized counterparts when analyzing similarities among
them. Thus, under the occurrence of a new case, the goal is to find
similar cases in the CaseBase. Having this in mind, the algorithm
given in [20] is applied to a new case that presents the feature vector BMI = 2, Age/Heredity Predisposing = [0, 0.05], Blood Group Predisposing =
[0.08, 0.14], Natural Anticoagulants Major = 1, Thrombotic Risk Factors = [0,1],
Mutations/ /Polymorphisms = 1, Earlier Secondary Factors = 2, having in consideration that the cases retrieved from the Case Base must satisfy
the invariant:

v alues ranges once normalized

½0; 1 . . . ½0; 1½0; 1
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
attribute’s domains once normalized

} :: 1

new case

Then, the new case can be depicted on the Cartesian plane in
terms of its QoI and DoC, and by using k-means clustering methods
[33], it is feasible to identify the clusters that intermingle with the
new one (symbolized as a square in Fig. 10). The new case is compared with every retrieved case from the cluster using a similarity
function sim, given in terms of the average of the modulus of the
arithmetic difference between the arguments of each case of the
selected cluster and those of the new case. Thus, one may have:
thrombrisk1 ðð1; 1Þ; ð1; 0Þ; ð1; 0:96Þ; ð1; 1Þ; ð1; 1Þ; ð1; 1Þ; ð1; 0:96ÞÞ :: 1 :: 0:84
thrombrisk2 ðð1; 1Þ; ð1; 0:99Þ; ð1; 0:83Þ; ð1; 1Þ; ð1; 1Þ; ð1;0:97Þ; ð1; 1ÞÞ :: 1 :: 0:97
..
.
thrombriskj ðð1; 1Þ; ð1; 1Þ; ð1; 0:96Þ;ð1;1Þ;ð1;1Þ;ð1;0Þ; ð1; 1ÞÞ :: 1 :: 0:85
normalized cases from retriev ed cluster

Assuming that every attribute has equal weight, the dissimilarDoC

DoC

thrombrisknew!1 , may be computed as follows:

3.5. A case based approach to computing
A soft computing approach to model the universe of discourse
based on a CBR methodology for problem solving is now set. Contrasting with other problem solving methodologies (e.g., Decision
Trees or ANNs), in a CBR based methodology for problem solving
relatively little work is done offline. Undeniably, in almost all the
situations the work is performed at query time. The main difference between this new approach and the typical CBR one relies
on the fact that not only all the cases have their arguments set in
the interval [0, 1], but it also caters for the handling of incomplete,
unknown, or even self-contradictory data or knowledge. Thus, the
classic CBR cycle was changed (Fig. 1), being the Case Base given in
terms of triples that follow the pattern:

Case ¼ f< Rawdata ; Normalizeddata ; Descriptiondata >g
where Rawdata and Normalizedcase stand for themselves, and Descriptiondata is made on a set of strings or even in free text, which are

DoC

ity, in terms of DoC, between thrombrisknew and thrombrisk1 , i.e.,

Fig. 10. A case’s set divided into clusters.

272

J. Vilhena et al. / Journal of Biomedical Informatics 62 (2016) 265–275
DoC

k1  1k þ k0:99  0k þ    þ k1  1k þ k1  0:96k
7
¼ 0:15

thrombrisknew!1 ¼

DoC

Thus, the similarity for thrombrisknew!1 is 1  0.15 = 0.85. Regarding
QoI

QoI the procedure is similar, returning thrombrisknew!1 ¼ 1. Thus,
one may have:
QoI;DoC

thrombrisknew!1 ¼

1 þ 0:85
¼ 0:925
2

These procedures should be applied to the remaining cases of the
retrieved cluster in order to obtain the most similar ones, which
may stand for possible solutions to the problem. This approach
allows physicians to define the most appropriate similarity threshold to address the problem (i.e., it gives the user the possibility to
narrow the number of selected cases with the increase of the similarity threshold). Description allows physicians to assess patients’
information such as previous therapy and their actual clinical status. Furthermore, the proposed system display to physician clinical
data of the target patient and their relatives in order to signalizing
thrombotic events and making appropriate recommendations. It
must be also stated that parameter settings, detail experimental
data descriptions or implementations of the different modules, as
well as issues like correctness, appropriateness and repeatability
of the experimental results were already treated in others publications, namely in [34,35].
3.6. Model validation and performance assessment
To ensure statistical significance of the attained results, 25 runs
were applied in all tests. In each simulation, the available data is
randomly divided into two mutually exclusive partitions, i.e., the
training set, with about two-thirds of the available data and used
to construct the models, and the test set, with the remaining cases
being used after training, in order to validate the model.
Table 1
A generic coincidence matrix.
Target

True (1)
False (0)

Predictive
True (1)

False (0)

True positive
False positive

False negative
True negative

The performance assessment of model is carried out based on
the coincidence matrix, i.e., a matrix of size L  L, where L denotes
the number of possible outputs classes (two in the present case).
This matrix is created by matching the predicted and target values
(Table 1). Based on coincidence matrix it is possible to compute
sensitivity, specificity, Positive Predictive Value (PPV) and Negative
Predictive Value (NPV) of the classifier:

sensitiv ity ¼ TP=ðTP þ FNÞ

ð7Þ

specificity ¼ TN=ðTN þ FPÞ

ð8Þ

PPV ¼ TP=ðTP þ FPÞ

ð9Þ

NPV ¼ TN=ðTN þ FNÞ

ð10Þ

where TP, FN, TN and FP stand, respectively, for true positive, false
negative, true negative and false positive.
The sensitivity and specificity are measures of the performance
of a binary classifier. Sensitivity evaluates the proportion of true
positives that are correctly identified as such, while specificity
translates the proportion of true negatives that are correctly identified. Moreover, it is necessary to know the probability of the classifier that give the correct response. Thus, it is also calculated both
PPV and NPV, while PPV stands for the proportion of cases with positive results which are correctly classified, NPV denotes the proportion of cases with negative results which are successfully labeled
[36].
In addition, the Receiver Operating Characteristic (ROC) curves
were considered. An ROC curve displays the trade-off between sensitivity and specificity and may be used to visualize the performance of a binary classifier, i.e., a model with two possible
output classes in present case. The Area Under the Curve (AUC)
quantifies the overall ability of the test to discriminate between
the output classes. The AUC can be interpreted as the probability
that a randomly chosen positive case is rated or ranked as more
likely to be positive than a randomly chosen negative case [37].
The maximum AUC, i.e., 1 (one) means that the test is perfect in
the differentiation between the two possible output classes. This
happens when the distribution of test results for the output classes
do not overlap. The minimum AUC should be considered a chance
level, i.e., AUC = 0.5, since AUC = 0 means that the test classifies
incorrectly all cases.

Table 2
Prevalence of inherited risk factors regarding patients with observed hypercoagulable states (n = 425).
Inherited risk factors for VTE
Natural anticoagulants (Major)

Anti-thrombin III deficiency
Protein C deficiency
Protein S deficiency

Mutations//Polymorphisms

Factor V Leiden (G1691A)
Prothrombin 20210A

Homozygous
Heterozygous

MTHFR 677C/T

Homozygous
Heterozygous

PAI-I 5G/4G

Homozygous
Heterozygous

Gender

Count

Sensitivity (%)

F
M
F
M
F
M

3
4
13
8
22
11

1.6

F
M
F
M
F
M
F
M
F
M
F
M
F
M

11
8
1
0
12
9
42
17
125
62
55
32
158
66

5.0
7.8
4.5
5.1

57.9

73.1

J. Vilhena et al. / Journal of Biomedical Informatics 62 (2016) 265–275

4. Results
4.1. Sample characterization
The prevalence of inherited risk factors in patients with hypercoagulable states (425 patients, i.e., 40.6% of the cohort) is presented in Table 2. Gene mutations/ /polymorphisms and natural
coagulation proteins were observed in 423 patients (99.5%) and
51 patients (12.0%), respectively. A perusal of Table 2 shows that
within natural coagulation (major), the protein S deficit was the
predominant (7.8%). The most frequent mutations/polymorphisms
were the heterozygous MTHFR 677C/T (44.0%) and PAI-I 5G/4G
(52.7%). Furthermore, in 21.4% of populations it was observed the
MTHFR 677C/T and PAI-I 5G/4G mutations simultaneously. Conversely, only seven patients presented three heterozygous mutations, namely MTHFR 677C/T, PAI-I 5G/4G and Prothrombin 20210.
4.2. Model and biomarkers performance assessment
Table 3 present the coincidence matrix (the values denote the
average of the 25 experiments). A perusal to Table 3 shows that
the model accuracy was 90.7% for the training set (634 correctly
classified in 699) and 90.2% for test set (313 correctly classified
in 347). Thus, the predictions made by the CBR model are satisfactory, attaining accuracies higher than 90%.
The sensitivity and specificity for training and test sets were
88.1%, 86.5%, 92.5%, and 93.0%, respectively. PPV and NPV were
89.0%, 90.1%, 91.8% and 90.2%, for training and test sets, respectively. The ROC curves for the training and test sets are shown in
Fig. 11. The areas under ROC curves (close 0.9 for both cases)
denoting that the model exhibits a good performance in the assessment to thrombophilia predisposition risk.
5. Discussion
The present study reveals a predominance of patients with gene
mutations or polymorphisms when compared with those that presented deficit of natural coagulation proteins (Table 2). NevertheTable 3
The coincidence matrix for CBR model.
Target

less, inherited antithrombin, protein C and protein S deficiencies
are rare but presents strong risk factors for venous thrombosis
[2]. The inherited deficiency of one of these inhibitors leads to a
critical reduction of the natural anticoagulant system and
enhances thrombin generation, increasing susceptibility to VTE
[38]. This study also shows that the most frequent mutations were
the MTHFR 677C/T and PAI-I 5G/4G heterozygous, while the less
common gene mutations were associated with Prothrombin
20210 and factor V Leiden (Table 2). Conversely, the study presented in [2] reported that the most common genetic risk factors
for VTE are the G1691A mutation in the factor V gene (factor V Leiden) and the G20210A mutation in the prothrombin gene. Despite
the benefit achieved with life-style modification, blood pressure
control and the use of statins and anticoagulants, the residual risk
of recurrent acute events in patients remains high [2,13]. A study
involving 355 patients reported that the recurrent VTE incidence
were 8.6%, 17.5% and 30.3% after 6 months, 2 years, and 8 years,
respectively [39]. Moreover, recurrent DVT and PE were associated
with an increased risk of post-thrombotic syndrome and chronic
thromboembolic pulmonary hypertension [40].
A glance to Table 2 shows that the sensitivity of deficiency in
natural anticoagulants (Major) was only 1.6%, 5.0% and 7.8% for
anti-thrombin III, protein C and protein S, respectively. Regarding
the mutations/polymorphisms of Factor V Leiden (G1691A),
Prothrombin 20210A, MTHFR 677C/T and PAI-I 5G/4G, the sensitivity was 4.5%, 5.1%, 57.9% and 73.1% respectively. Conversely, the
proposed model showed a high sensitivity and specificity, enabling
the early diagnosis of thrombophilia and signalizes patients with
hypercoagulable states, classifying properly the presence (sensitivity higher than 86.5%) and the absence (specificity higher than
92.5%) of these hypercoagulable states.
The pathogenesis of thrombophilia should be considered in a
multifaceted perspective, blending genetic and environmental
thrombophilia risk factors and epidemiological data. Indeed, the
present model, beyond to consider the genetic deficiency of natural
anti-coagulants and molecular mutations/polymorphisms, enables
the integration of age/heredity predisposing and blood group predisposing with other factors such as thrombotic risk and earlier
secondary factors (Fig. 8), being therefore assertive in the prediction of hypercoagulable states.
6. Conclusions

Predictive
Training set

True (1)
False (0)

273

Test set

True (1)

False (0)

True (1)

False (0)

252
31

34
382

128
14

20
185

This work presents an intelligent decision support system to
assess thrombophilia predisposition risk. It is centered on a formal
framework based on LP for Knowledge Representation and Reasoning, complemented with a CBR approach to problem solving that
caters for the handling of incomplete, unknown, or even selfcontradictory information. With respect to this last issue (see Section 2.2), an Extended Logic Program was defined as a finite set of
clauses in the form:
{
:p
notp; not exceptionp
p
p1 ;    ; pn ; not q1 ;    ; not qm
?ðp1 ;    ; pn ; not q1 ;    ; not qm Þðn; m P 0Þ
exceptionp1
...
exceptionpj ð0 6 j 6 kÞ; being k an integer number
} :: scoring v alue

Fig. 11. The ROC curves for training set (—) and for test set ( ).

Therefore, if we have two or more programs with atoms that are
positive in one situation and negative in another, we are faced with
information that is self-contradictory, i.e., if one has two or more

274

J. Vilhena et al. / Journal of Biomedical Informatics 62 (2016) 265–275

Fig. 12. The relative position of a given case to the uttermost one.

programs that report to a given individual clinical situation, the one
to be followed by the clinical experts is the one that has the lowest
metric value given by Eq. (11), which is also given in a graphical
form (Fig. 12).

06

 Pn

Pn
1 i¼1 QoIi þ 1  i¼1 DoC i 
61
2

ð11Þ

This approach focus on the processing of information acquired from
molecular and biochemical parameters and clinical data in order to
identify patients with thrombotic risk, to prevent recurrent events,
to monitor the treatment of patients with chronic illness and
improve their quality of life. The proposed model allows the comprehensive integration of natural coagulation inhibitors and gene
mutations or polymorphisms with thrombotic and secondary risk
factors. It is able to provide adequate responses since the overall
accuracy higher than 90% and the area under ROC curve is near
0.9. Additionally, under this scenery the users may define the
weights of the cases’ attributes on the fly, letting them to choose
the most appropriate strategy to address the problem (i.e., it gives
the user the possibility to narrow the search space for similar cases
at runtime).
Conflict of interest statement
All authors declare that there isn’t any actual or potential conflict of interest.
References
[1] E. Favaloro, D. Mcdonald, G. Lippi, Laboratory investigation of thrombophilia:
the good, the bad, and the ugly, Semin. Thromb. Hemost. 35 (2009) 695–710.
[2] E. Previtali, P. Bucciarelli, S.M. Passamonti, I. Martinelli, Risk factors for venous
and arterial thrombosis, Blood Transfus 9 (2011) 120–138.
[3] P.H. Reitsma, F.R. Rosendaal, Past and future of genetic research in thrombosis,
J. Thromb. Haemost. 5 (2007) 264–269.
[4] J.B. Segal, D.J. Brotman, A.J. Necochea, L.M. Wilson, M.T. Crim, E.B. Bass, et al.,
Prothrombin G20210A in adults with venous thromboembolism and in a
family members of those with a mutation, JAMA 301 (2009) 2472–2485.
[5] D. Garcia, E. Akl, R. Carr, C. Keaton, Antiphospholipid antibodies and the risk of
recurrence after a first episode of venous thromboembolism: a systematic
review, Blood 122 (2013) 817–824.
[6] S. Kuipers, A.J.M. Schreijer, S.C. Cannegieter, H.R. Büller, F.R. Rosendaal, S.
Middeldorp, Travel and venous thrombosis: a systematic review, J. Intern.
Med. 262 (2007) 615–634.
[7] A. Baccarelli, I. Martinelli, A. Zanobetti, P. Grillo, L.F. Hou, P.A. Bertazzi, P.M.
Mannucci, J. Schwartz, Exposure to particulate air pollution and risk of deep
vein thrombosis, Arch. Int. Med. 168 (2008) 920–927.
[8] A.T. East, T.W. Wakefield, What is the optimal duration of treatment for DVT?
An update on evidence-based medicine of treatment for DVT, Semin. Vasc.
Surg. 23 (2010) 182–191.

[9] F.R. Rosendaal, Venous thrombosis: the role of genes, environment, and
behavior, Hematol. Am. Soc. Hematol. Educ. Program 2005 (2005) 1–12.
[10] G. Pernod, C. Biron-Andreani, P.E. Morange, F. Boehlen, J. Constans, F.
Couturaud, et al., Recommendations on testing for thrombophilia in venous
thromboembolic disease: a French consensus guideline, J. des Maladies
Vasculaires 34 (2009) 156–203.
[11] S. Pulivarthi, M.K. Gurram, Effectiveness of d-dimer as a screening test for
venous thromboembolism: an update, N Am. J. Med. Sci. 6 (10) (2014) 491–
499.
[12] C. Sinescu, M. Hostiuc, D. Bartos, Idiopathic venous thromboembolism and
thrombophilia, J. Med. Life 4 (2011) 57–62.
[13] O. Wu, L. Robertson, S. Twaddle, G.D.O. Lowe, P. Clark, M. Greaves, et al.,
Screening for thrombophilia in high-risk situations: systematic review and
cost-effectiveness analysis. The thrombosis: risk and economic assessment of
thrombophilia screening (TREATS) study, Health Technol. Assess. 10 (11)
(2006), http://dx.doi.org/10.3310/hta10110.
[14] A. Kakas, R. Kowalski, F. Toni, The role of abduction in logic programming, in:
D. Gabbay, C. Hogger, I. Robinson (Eds.), Handbook of Logic in Artificial
Intelligence and Logic Programming, vol. 5, Oxford University Press, Oxford,
1998, pp. 235–324.
[15] L. Pereira, H. Anh, Evolution prospection, in: K. Nakamatsu (Ed.), New
Advances in Intelligent Decision Technologies – Results of the First KES
International Symposium IDT 2009, Studies in Computational Intelligence, vol.
199, Springer, Berlin, 2009, pp. 51–64.
[16] J. Neves, A logic interpreter to handle time and negation in logic databases, in:
R. Muller, J. Pottmyer (Eds.), Proceedings of the 1984 Annual Conference of the
ACM on the 5th Generation Challenge, Association for Computing Machinery,
New York, 1984, pp. 50–54.
[17] J. Neves, J. Machado, C. Analide, A. Abelha, L. Brito, The halt condition in genetic
programming, in: J. Neves, M.F. Santos, J. Machado (Eds.), Progress in Artificial
Intelligence. LNAI, vol. 4874, Springer, Berlin, 2007, pp. 160–169.
[18] J. Machado, A. Abelha, P. Novais, J. Neves, J. Neves, Quality of service in
healthcare units, in: C. Bertelle, A. Ayesh (Eds.), Proceedings of the ESM 2008,
Eurosis – ETI Publication, Ghent, 2008, pp. 291–298.
[19] P. Lucas, Quality checking of medical guidelines through logical abduction, in:
F. Coenen, A. Preece, A. Mackintosh (Eds.), Proceedings of AI-2003 (Research
and Developments in Intelligent Systems XX), Springer, London, 2003, pp.
309–321.
[20] F. Fernandes, H. Vicente, A. Abelha, J. Machado, P. Novais, J. Neves, Artificial
neural networks in diabetes control, in: Proceedings of the 2015 Science and
Information Conference (SAI 2015), IEEE Edition., 2015, pp. 362–370.
[21] A. Aamodt, E. Plaza, Case-based reasoning: foundational issues,
methodological variations, and system approaches, AI Commun. 7 (1994)
39–59.
[22] M.M. Richter, R.O. Weber, Case-Based Reasoning: A Textbook, Springer, Berlin,
2013.
[23] S. Begum, M.U. Ahmed, P. Funk, N. Xiong, M. Folke, Case-based reasoning
systems in the health sciences: a survey of recent trends and developments,
IEEE Trans. Syst., Man, Cybern., Part C (Appl. Rev.) 41 (2011) 421–434.
[24] X. Blanco, S. Rodríguez, J.M. Corchado, C. Zato, Case-based reasoning applied to
medical diagnosis and treatment, in: Distributed Computing and Artificial
Intelligence, Springer, Berlin, 2013, pp. 137–146.
[25] R. Janssen, P. Spronck, A. Arntz, Case-based reasoning for predicting the
success of therapy, Expert Syst. 32 (2015) 165–177.
[26] S. El-Sappagh, M. Elmogy, A.M. Riad, A fuzzy-ontology oriented case-based
reasoning framework for semantic diabetes diagnosis, Artif. Intell. Med. 65
(2015) 179–208.
[27] Y. Shen, J. Colloc, A. Jacquet-Andrieu, K. Lei, Emerging medical informatics with
case-based reasoning for aiding clinical decision in multi-agent system, J.
Biomed. Inform. 56 (2015) 307–317.
[28] R. Mendes, J. Kennedy, J. Neves, Watch thy neighbor or how the swarm can
learn from its environment, in: Proceedings of the 2003 IEEE Swarm
Intelligence Symposium (SIS’03), IEEE Edition., 2003, pp. 88–94.
[29] P. O’Neil, B. O’Neil, X. Chen, Star Schema Benchmark, Revision 3, June 5, 2009
<http://www.cs.umb.edu/~poneil/StarSchemaB.pdf>2016 (accessed 13.02.16).
[30] A.R. Sacher, Thrombophilia: a genetic predisposition to thrombosis, Trans. Am.
Clin. Climatol. Assoc. 110 (1999) 51–61.
[31] L. Spiezia, E. Campello, M. Bon, T. Tison, M. Milan, P. Simioni, et al., ABO blood
groups and the risk of venous thrombosis in patients with inherited
thrombophilia, Blood Transfus 11 (2013) 250–253.
[32] L.R. Dice, Measures of the amount of ecologic association between species,
Ecology 26 (1945) 297–302.
[33] M. Figueiredo, L. Esteves, J. Neves, H. Vicente, A data mining approach to study
the impact of the methodology followed in chemistry lab classes on the weight
attributed by the students to the lab work on learning and motivation, Chem.
Educ. Res. Pract. 17 (2016) 156–171.
[34] A. Coimbra, H. Vicente, A. Abelha, M.F. Santos, J. Machado, J. Neves, J. Neves,
Prediction of length of hospital stay in preterm infants – a case-based
reasoning view, in: I. Czarnowski, A.M. Caballero, R.J. Howlett, L.C. Jain (Eds.),
Smart Innovation, Systems and Technologies, vol. 56, Springer International
Publishing, Cham, 2016, pp. 115–128.
[35] R. Faria, H. Vicente, A. Abelha, M.F. Santos, J. Machado, J. Neves, A case-based
approach to nosocomial infection detection, in: L. Rutkowski, M. Korytkowski,
R. Scherer, R. Tadeusiewicz, L.A. Zadeh, J.M. Zurada (Eds.), Artificial
Intelligence and Soft Computing, LNAI, vol. 9693, Springer International
Publishing, Cham, 2016, pp. 159–168.

J. Vilhena et al. / Journal of Biomedical Informatics 62 (2016) 265–275
[36] C. Florkowski, Sensitivity, specificity, receiver-operating characteristic (ROC)
curves and likelihood ratios: communicating the performance of diagnostic
tests, Clin. Biochem. Rev. 29 (Suppl 1) (2008) S83–S87.
[37] K. Hajian-Tilaki, Receiver operating characteristic (ROC) curve analysis for
medical diagnostic test evaluation, Caspian J. Intern. Med. 4 (2013) 627–635.
[38] U. Seligsohn, A. Lubetsky, Genetic susceptibility to venous thrombosis, N. Engl.
J. Med. 344 (2001) 1222–1231.

275

[39] P. Prandoni, A.W. Lensing, A. Cogo, S. Cuppini, S. Villalta, M. Carta, et al., The
long-term clinical course of acute deep venous thrombosis, Ann. Intern. Med.
125 (1996) 1–7.
[40] T. Baglin, What happens after venous thromboembolism?, J Thromb. Haemost.
7 (2009) 287–290.

