IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 2, MARCH 2014

643

Visualization of Needle Access Pathway
and a Five-DoF Evaluation
Wing-Yin Chan and Pheng-Ann Heng, Senior Member, IEEE

Abstract—It is a common practice nowadays to plan needle access pathways to the volumetric organs before performing surgeries. An enormous amount of needle access planning systems has
been proposed in recent years. Recent works mainly focus on the
system usability or target accessibility. Visualization of the planned
access pathways has drawn little attention and its effect on insertion quality is left unattended. We aim to address this problem by
introducing an all-round evaluation framework that links up with
human motions and computer graphics. Our evaluation framework provides an objective and quantitative analysis of the illustrativeness of the needle access pathway visualization techniques to
an extent of five degrees of freedom. Our experimental results show
that the visualization method adopted greatly influences insertion
accuracy. Based on this finding, we propose a new visualization
technique that intuitively conveys placement and orientation information. We also show that our method better conveys pathway
orientation and thus enables a higher quality of insertion.
Index Terms—Biopsy simulator, evaluation, medical visualization, needle placement, surgical planning.

I. INTRODUCTION
ANY medical treatments involve inserting fine instruments like needles or catheters into the human body.
The success of these treatments solely depends on the accurate
placement of the equipment, accessing the target, and not damaging vulnerable body parts. These tasks are very complex and,
thus, require highly skilled and trained clinicians. Taking advantage of the developments in the computer-assisted medical
systems (e.g., surgical planners, training systems, and evaluation systems), clinicians are able to carry out virtual trials before
actual operations. In modern days, preoperative planning of an
insertion pathway is generally accepted to be an effective way
to ensure patient safety.

M

Manuscript received December 10, 2012; revised April 10, 2013 and June 28,
2013; accepted July 22, 2013. Date of publication July 30, 2013; date of current
version March 3, 2014. This project was supported in part by the Research
Grants Council of the Hong Kong Special Administration Region under General Research Fund Project CUHK 412510 and in part by the National Natural
Science Foundation of China under Project 61233012.
W.-Y. Chan is with the Department of Computer Science and Engineering, Chinese University of Hong Kong, Shatin, Hong Kong (e-mail:
wychan@cse.cuhk.edu.hk).
P.-A. Heng is with the Department of Computer Science and Engineering,
Chinese University of Hong Kong, Shatin, Hong Kong, and also with the Center
for Human-Computer Interaction, Shenzhen Institute of Advanced Integration
Technology, Chinese Academy of Science, Shenzhen 518055, China (e-mail:
pheng@cse.cuhk.edu.hk).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2013.2275741

Most of the medical systems share a common action—users
insert an equipment under the guidance of a predefined pathway.
A predefined pathway can be a preconfirmed optimal path decided in a surgical planner or a recommended trajectory given in
a training system. Under these circumstances, the quality of insertions can be guaranteed only when the clinicians are capable
of following exactly what has been planned or recommended.
Therefore, the visualized needle access pathways should convey
as much needle placement information as possible to encourage
better insertions.
Evaluating the quality of needle placement has long been the
central concern of various communities. In the context of clinical practice, the quality of needle placement can be examined by
using guiding equipments (e.g., ultrasound guidance or X-ray
guidance). The precision of the examination is limited by the
imaging mechanisms—ultrasound images are blurry and can
only visualize a cross section inside the human body, whereas
the X-ray guidance projects a 3-D working environment into a 2D radiographic image whose depth information along the X-ray
propagation direction is lost. In the context of computer-assisted
medical systems, evaluations are done based on recorded user
actions. Evaluation metrics such as the distance from the needle
tip to the target, the alignment of the needle with the ultrasound imaging plane, or the specificity of ultrasound ablation
volume are proposed in various works. One property of all the
aforementioned evaluations is that the evaluation is carried out
after a needle is inserted. The community barely conducts an
investigation if the adoption of illustrative visualization is able
to enhance the accuracy before insertion.
As the adoption of augmented reality technologies in operation rooms and the acceptance of using computer-based surgical simulators in the mainstream curriculum are growing, we
believe that an illustrative visualization of the needle access
pathways can provide auxiliary information about the insertion
accuracy to both junior students and senior clinicians. In this
paper, we propose a novel visualization approach to enhance
the needle placement and alignment. We make use of the intrinsic perception of the human vision system to construct a new
access pathway illustration. Not only the placement and orientation of the illustration can be perceived easily, but also any
tiny displacement error or misalignment can be spotted and corrected systemically by the users. We also develop an evaluation
framework to evaluate the illustrativeness of any visualization
technique for the needle access pathways. To our knowledge,
this kind of evaluation framework has never been reported so far.
The results show that the visualization method adopted greatly
influences the user performance.
The remainder of this paper is organized as follows. In
Section II, we review related work. In Section III, we explain

2168-2194 © 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

644

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 2, MARCH 2014

important factors in visualizing access pathways and how we
should evaluate visualization techniques in the context of needle placement procedures. In Section IV, we analyze existing
visualization techniques and then, in Section V, introduce the
design of our novel illustration. In Section VI, we describe the
experiments we carried out to evaluate various techniques. We
present the results and analysis in Section VII and the conclusion
in Section VIII.
II. RELATED WORK
A. Computer-Assisted Medical Systems
There are various types of computer-assisted medical systems to fit different purposes. Preoperative planning systems
are designed to provide off-line decision making and optimal
path computation. Some integrated planning systems are made
for specific surgeries, like neurosurgery [1]–[4] or ultrasoundguided biopsy [5]. Besides, the adoption of the augmented reality system in operation rooms has gained much attention. Sato
et al. [6] conducted a pioneer study that combines 3-D position sensors with a calibrated ultrasound probe to acquire ultrasound images before surgical sections. Then, the acquired
ultrasound images are superimposed on the patient during the
operation. The geometrical location of the tumor can be accurately located by the surgeons through a display. More advanced
systems focusing on better visualizations or clinical evaluations
are proposed later [7], [8]. Furthermore, there are many needle
placement simulators aiming at simulating the actual procedures
during the operation. They focus broadly on the tissue deformation under needle insertion [9], [10], haptic rendering [11], [12],
or training effectiveness [13]. Most of these systems provide limited assistance for inserting a needle according to a predefined
pathway or safety areas. Chan et al. [14] recently proposed a
recommendation scheme that suggests multiple pathways based
on clinical practices and physical limitations. Their work includes a model to consider the blockage of bone structures, the
avoidance of vital structures, and the sono-visualization of needle under the ultrasound guidance. A more complicated model
considering highly irregular tissues is proposed by Khlebnikov
et al. [15].
B. Pathway Visualization
Most of the early medical systems do not provide pathway visualization [1], [3], [10]–[12] or provide only a simple straight
line to represent the planned optimal path [2], [4], [7], [8].
Straight lines are not illustrative enough to convey needle alignment information and are potentially ambiguous (Detailed analysis is in Section IV). Recently, Röttger et al. [16] presented multimodal visualizations for preoperative neurosurgical planning.
They add rings along a pathway to facilitate the understanding of
the spatial arrangement. Later, Khlebnikov et al. [15] specially
designed a visualization technique to visualize possible pathways. Their algorithm is inspired by a natural phenomenon—
“crepuscular rays.” The visualization is basically a volume rendering of fog volume which is computed by considering a tumor as a volumetric light source and vulnerable structures as

obstacles. The output of their algorithm is usually “ray” like and
thus can be used as an illustration of direction. Chan et al. [14]
used tensor line strips to represent multiple insertion pathways.
The insertion orientation is conveyed by shape deformation of
strips and the feasibility is color coded. In general, illustrative
visualization of line data can also be done by employing tubes,
stream lines, or halos [17]. To our knowledge, there is still no
framework to evaluate the effectiveness of different visualization methods with regard to needle placement procedures.
C. Line Illustration as Information Carrier
Conveying important information to the viewers has long
been the central focus in the field of visualization. Diverse applications are made by line drawings. Visualization of 2-D/3-D
flows can be presented by stream lines [18], [19]. Shapes and
illuminations can be presented by hatching patterns [20]–[22].
Geographic topology in maps can be presented by isohypses
[23]. Examples are too many to mention. Most of these methods
are encoding information by drawing multiple lines with special
techniques—density, convergence, divergence, stroke thickness,
gestalt configuration, etc. Note that all these skills are comparative. The density of isohypses of a cliff looks high only when
a hill exists. A stroke looks thick only when thin strokes exist.
This means that most of the visualization techniques have to
illustrate multiple conditions concurrently for them to be comprehensible. The interpretation of a scene in the human vision
system depends heavily on comparison. In our application, only
a single optimal path would be visualized. It is extremely difficult to illustrate the placement and orientation information to
viewers without the help of other reference objects. Thus, this
is a very challenging problem to be defeated.
III. EVALUATION FRAMEWORK
In this section, we shall introduce a framework to evaluate
visualization techniques for the needle access pathway. This
evaluation aims at estimating the illustrativeness of any visualization technique that assists needle insertion with a given
optimal path. We presume that a good insertion should follow
exactly the planned trajectory. Therefore, the visualized needle
access pathway should help users inserting the needle along the
planned trajectory as precise as possible. As “precise alignment”
is an abstract concept, we transform it into a negative definition:
A visualization technique of needle access pathway should be
illustrative enough for the users to spot any errors and correct
them. To this end, we have to investigate possible types of errors
that would happen during the operation.
Imagine that a user is practicing needle access procedures
using a virtual reality system (see Fig. 1). The user controls a
sensor-attached needle. There is also a phantom block to mimic
a patient. A virtual patient and some virtual equipments are presented on a screen. A virtual insertion pathway is presented,
indicating a feasible entry point and orientation. Through the
screen, the user tries to move and rotate the needle so that the
virtual needle overlaps with the suggested pathway. With regard to the alignment, the goal is to eliminate any displacement
errors and orientation disparities. The user can only judge the

CHAN AND HENG: VISUALIZATION OF NEEDLE ACCESS PATHWAY AND A FIVE-DOF EVALUATION

645

Fig. 1. Training scenario using a VR medical system. Various kinds of errors that users encountered can be categorized into four types. These four types of errors
involve five degrees of freedom of a freely moving needle. (a) Training scenario. (b) IPD. (c) OPD. (d) IPT. (e) OPT.

alignment through the rendered 2-D images, while the position
and orientation in the virtual world are 3-D. Errors and misjudgments can happen. Once the user thinks that the needle has
been well aligned, the user may puncture the phantom block to
access the virtual tumor.
A. Displacement Error
A freely moving needle has six degrees of freedom, three represents the position. When a virtual needle and a needle access
pathway are projected onto the screen, their relative displacement can be spotted [see Fig. 1(b)]. Users can move the needle
to minimize the displacement until both of them overlap. However, even when the needle overlaps with the illustrated pathway,
there can still be displacement along the camera direction [see
Fig. 1(c)]. This kind of error can be eliminated by moving the
needle along the camera direction, until the depth ordering interchanges. The user moves the needle back and forth to assure
a correct placement. These two types of displacement errors are
tackled in different ways, and therefore, we classify them into
two categories. Those of which can be spotted directly on the
screen are called in-plane displacement (IPD); those spanning
along the camera direction are called out-of-plane displacement
(OPD).
B. Orientation Disparity
Orientation uses the other three degrees of freedom. Selfspinning of a needle is seldom considered in most applications (it
is reported to be important in Chinese acupuncture). We exclude
this degree of freedom as it is not related to the needle alignment.
Similar to displacement errors, part of the orientation disparity
can be spotted directly by looking at the directions of the virtual
needle and the illustrated pathway [see Fig. 1(d)]. To minimize
the orientation disparity, the needle is rotated until the virtual
needle is parallel to the illustrated pathway. Yet, paralleling the
virtual needle and the illustrated pathway does not eliminate all
the orientation disparities. Part of the orientation disparity spans
on a plane that is perpendicular to the screen [see Fig. 1(e)].
Tilting of the needle toward the far end or the front end (w.r.t.
the virtual screen) would change the depth ordering of the needle
and the illustrated pathway. The alignment is ideal (if possible)
when the depth ordering changes upon further tilting of the

needle. These two components of orientation disparity are called
in-plane tilting (IPT) and out-of-plane tilting (OPT).
We have just transformed all possible errors from five degrees of freedom into four operational categories. Computation
of these measurements can be found in Appendix A. At first
glance, it seems easy to eliminate errors by moving and rotating the needle, but in reality, it is very difficult to achieve high
precision with improper visualization techniques. In the next
section, we would analyze the illustrativeness of some common
visualization techniques for the needle access pathway.
IV. ANALYSIS OF COMMON TECHNIQUES
Before we introduce a new technique, we first analyze the
pros and cons of previous works. We examine the illustrativeness of existing techniques based on the evaluation framework
proposed in the last section. We examine four methods, namely,
straight line, strip, ghost object, and crepuscular ray. Examples
of optimal paths visualized by these techniques are shown in
Fig. 2. The analysis below is closely related to the rendering of
computer graphics. We keep the descriptions as general as possible. If any specification is needed, we refer to the OpenGL.
Table I illustrates all the situations during the elimination of
errors with various visualization techniques. In each box, a rendering of an aligned needle is placed in the middle. On two
sides, misaligned needles are shown. The continuity of rendering is described by the terms continuous or discrete. Continuous
means that there are continuous rendering results in between the
shown statuses. Discrete means that only countable rendering
results can be produced. Some of the illustrations may produce ambiguous indications and fall into a “probably aligned”
situation.
A. Straight Line
Straight line is the most common technique of pathway visualization. It is easy to implement with common graphic libraries.
Lines are basic forms of indicators; fundamental information
like insertion direction and entry point can be conveyed. Although lines are logically 1-D, they are usually rendered with a
width of 1–5 pixels and a depth of a thin sheet.
1) IPD: Any displacement shown on the screen between the
virtual needle tip and the illustrated path can be spotted
easily. The precision is very high since a line is very fine

646

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 2, MARCH 2014

(a)

(b)

(c)

(d)

(e)

Fig. 2. Examples of using various techniques to visualize an optimal path. All the visualized paths are placed in the same position and same orientation. (a) Line.
(b) Strip. (c) Ghost Object. (d) Crepuscular Ray. (e) Our method.
TABLE I
ILLUSTRATION OF THE ILLUSTRATIVENESS OF VARIOUS NEEDLE ACCESS PATHWAY VISUALIZATION METHODS
Type

In-plane displacement

Out-of-plane displacement

continuous

Line

missed

aligned

discrete
missed

missed

(a)

Strip

aligned

missed

aligned

missed

aligned

missed

(m)

missed

aligned

(q)

aligned

missed

aligned

(r)

probably aligned

missed

aligned

m i s s ed

probably aligned

missed

aligned

(s)

aligned

missed

(l)

continuous
missed

missed

probably aligned

missed

(p)

continuous

continuous
missed

missed

discrete
missed

(o)

missed

aligned

(h)

continuous
missed

missed

discrete
missed

(k)

missed

aligned

(d)

continuous

missed

continuous

missed

missed

(g)

(n)

continuous

Our
method

missed

continuous

missed

discrete
missed

continuous

missed

(j)

continuous
missed

aligned

aligned

(c)

discrete

missed

(i)

Crepuscular
ray

missed

(f)

continuous
missed

aligned

Out-of-plane tilting

continuous

missed

discrete

missed

(e)

Ghost
object

aligned

(b)

continuous
missed

In-plane tilting

missed

missed

aligned

(t)

missed

CHAN AND HENG: VISUALIZATION OF NEEDLE ACCESS PATHWAY AND A FIVE-DOF EVALUATION

compared to the whole virtual environment. IPD can be
effectively eliminated by overlapping the virtual needle
tip with the illustrated path.
2) OPD: Most of the real time graphic libraries nowadays are
depth-buffer based. Only the front most element (in relation to the camera) is drawn, resulting in a binary depth
ordering: either the virtual needle is covering the illustrated path or vice versa. The only way a user can confirm
the alignment is to move the needle back and forth along
the camera direction. An alternate overlapping between
the virtual needle and the illustrated path indicates a small
OPD. We refer to this action as depth testing. Nevertheless,
the final rendered scene does not depend on the value of
the OPD and there does not exist any rendering state that
truly represents zero OPD [see Table I(b)]. Using depth
testing to eliminate OPD is time consuming.
3) IPT: Similar to IPD, in-plane orientation disparity can be
spotted easily. Even the virtual needle and the illustrated
line are of different depth. It is easy to align them by
paralleling them. The precision of this technique is high.
4) OPT: A line on the screen does not bear any depth information. Tilting of a line, inward or outward, does not
change the rendering result. Only when a fixed-length line
is rendered, the rendered length changes due to projection
and this gives a hint of the orientation. It is very difficult
for a user to guess the amount of OPT through a projected
line. Using a straight line to convey OPT information is
ineffective and creates unavoidable errors.
B. Strip
Strip is an enriched line. Tilting information is encoded by
varying the strip width at the two ends. The basic idea behind
is that, from a human’s perspective, a strip appears to be wider
when closer. Depth-dependent-haloed strip, presented in [17],
is a way to visualize the depth difference between a strip and
its’ background.
1) IPD: Strips are widened to a certain width such that tilting
information can be encoded. This weakened the specificity
to locate the entry point and the placement of the optimal
path, compared to a line. The widening does not help in
eliminating IPD.
2) OPD: Depth ordering of strip rendering is again binary,
which means it inherits the properties from a line. The
tilting information indicates the orientation of the optimal
path, which encourages a better initial guess for depth
testing and slightly helps eliminating OPD.
3) IPT: A tilted strip is usually wider at one end and thinner
at the other end. This makes the elimination of IPT very
difficult due to the poor specificity at the wide end. It takes
extra effort to rotate the needle until both the ends of the
virtual needle are placed in the middle of the strip.
4) OPT: The major advantage of using strips is to convey
the OPT information of the pathways. Users can comprehend basic orientation from the illustrated pathway and
are exempt from guessing the orientation in a large dynamic range of rotational space. It is theoretically easier

647

to eliminate OPT with a strip than a line. However, the
final orientation is still confirmed using depth testing.
C. Ghost Object
Ghost object is a semitransparent object that duplicates what
a user is controlling. A ghost object may reflect a previous performance or demonstrate a prefect example. This technique is
extensively applied in teaching applications, for example competing with a previous trial in a car racing simulation or imitating
a gesture in a sign language teaching software. In needle access
simulators, a ghost object can be implemented by rendering a
slightly larger semitransparent needle mesh. When the virtual
needle is perfectly aligned, it would be flawlessly enclosed by
the ghost needle.
1) IPD: Since the ghost needle can be designed to just fit the
virtual needle, any IPD can be easily spotted. Moreover,
the needle tip is usually fine. Thus, the specificity of the
entry point is as good as a line.
2) OPD: The ghost needle is larger than the original virtual
needle mesh. We can therefore assume that the virtual
needle is covered by the ghost mesh when it is in optimal
position. A user can move the virtual needle until the
depth ordering just interchanges. At that position, the OPD
would be very small. Note that the amount of displacement
error beyond the optimal position is yet unresolvable from
the rendered image.
3) IPT: The virtual needle fits into the ghost needle in an ideal
orientation. Therefore, it is easy to spot any orientation
disparities and correct them.
4) OPT: The outline of the ghost mesh provides OPT information. Users can comprehend basic orientation from
the rendering of the mesh. This also helps users guess the
orientation, yet the final placement has to be confirmed
using depth testing. Rotating the virtual needle until it is
just covered by the ghost mesh is practical but takes time.
D. Crepuscular Ray
Crepuscular ray is a natural phenomenon that light beams
emit from the sky. It is first proposed to be used for visualizing
possible entry positions by Khlebnikov et al. [15]. The visualization is basically a volume rendering of a volume of fog. In the
original work, the beams are of indefinite size. Here, we discuss
a special case where there is only one beam and the beam is
near conical to increase the specificity of the entry point.
1) IPD: The visualized beam of fog contains various numbers
of visible voxels. Even the finest end has to be two to three
times wider than the radius of the shaft of the needle mesh,
otherwise, the basic operation of volume rendering would
be corrupted. The width of the illustrated pathway is lower
bounded and gets difficult to be very specific. Placing the
needle tip in the middle of the beam is feasible, but needs
some practice.
2) OPD: In contrast to opaque illustrations, the rendered image depends on the value of OPD due to the “volumetric”
property of a beam. As long as a virtual needle travels
toward the far end along the direction of the camera, the

648

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 2, MARCH 2014

virtual needle fades out and the color of the beam fades
in. Users can make use of this continuous change to analyze the amount of OPD. Although users may need some
practice in learning this skill, this visualization technique
enables a rendering state that represents zero OPD.
3) IPT: The beam is conical and has a wide end; thus, the
virtual needle would appear to be within the beam in a
wide range of rotational angles. It is difficult for a user to
spot the amount of disparity and assure orientation.
4) OPT: A beam does not bear OPT information, it requires
a user to test the orientation. However, taking advantage
of its “volumetric” nature, the amount of OPT can be
observed though the rendered image. This also requires
users’ adaption.
To conclude this section, we generalize some effective means
that can enhance illustrativeness. To effectively eliminate IPD,
the illustration should be as fine as possible. Any displacement
errors are perceived by the partial overlapping of the virtual
needle and the illustrated path. This idea can also be applied to
eliminate IPT error. There is one more constraint, i.e., the outer
end of the illustration cannot be too wide or ambiguous. To
eliminate OPD, the rendering of the final image should be based
on the amount of displacement errors. An effective technique is
to render a volume of fog in order to provide a continuous depth
perception, rather than a binary depth ordering which is done by
tradition depth-buffer-based rendering. The same idea can also
be applied to eliminate OPT error. Moreover, it is essential to
provide basic information about the orientation of the optimal
pathway, e.g., the pathway is pointing inward/outward to the
screen.
V. OUR METHOD
After reviewing the existing methods, we learnt that different
types of errors are handled by using different mechanisms and
none of the methods are all-round. Thus, the remaining task is
to design a new illustration that groups the advantages and minimizes any possible shortcomings. In this section, we present
our method to illustrate the needle access pathway that provides sufficient illustrativeness to defeat various types of errors.
Our method is a hybrid mixture of two elements, each of them
provides one mechanism to eliminate errors—depth ordering
cue and configural cue. Depth ordering cue provides continuous
depth information depending on the amount of out-of-plane errors; configural cue provides both basic orientation information
and sufficient prompts for refining the needle orientation. Fig. 3
gives an overview of our design.
A. Overview
Our illustration is composed of two parts, the lower part
is a fine volumetric beam and the upper part is an array of
circular rings. The ratio of the length of the beam and the rings
should depend on the mesh model of the needle. The volumetric
beam should cover most of the needle shaft and the array of
circular rings should cover most part of the handle of the virtual
needle. This setting fits the functional properties of each part.
The width of the volumetric beam should be two times the radius

Fig. 3. Illustration of our visualization technique. Composing of two parts—a
volumetric beam for depth comparison and an array of rings as configural cue.

of the needle shaft at the tip and five times at the wide end. The
second part is an array of circular rings. The number of rings
is recommended to be 5–7. There are two reference lines on
each side passing through the cocenter of the rings. This special
design will serve for both perceptual and visual assistants. We
shall discuss them in detail in later sections.
B. Array of Rings as a Configural Cue
Based on the analysis in Section IV, we understand that volumetric beam is a remarkable visual effect for depth comparison.
Unfortunately, it does not convey any orientation information as
it is just a “foggy mask” on the screen. Presenting a 3-D sensation on a 2-D screen is an interesting topic. One of the ways is
to provide cues to guide the human vision system. This method
is simple, but for this to work, specially designed “tricks” are
needed. We employ a Gestalt-like configural cue plus a use of
the reference frame effect to “lead” the human vision system.
The reference frame effect is proven to be capable of interfering
with our visual processing system [24].
We shall demonstrate the building methodology of our cue
step by step. Fig. 4(a) shows a series of circles overlapping with
each other. These circles can be seen as, and only as, lying in
the same depth plane. Nothing can be retrieved when no cue
is present. When halos are drawn around the circles, as shown
in Fig. 4(b), a sensation of depth arises. We can tell that every circle is covering its neighbor on the left. This sensation
is completed by our visual processing system to explain the
occlusion shown by the halos. However, the depth perception
is not definitive. It is reasonable for a viewer to interpret such
a configuration as these circles are stacked up tightly together
within a very small range of depth. It is known that haloed
edges can provide information about the depth-ordering, but not
necessarily the geometrical depth difference between the occludent and the occluded background. Yet, it is proven possible to

CHAN AND HENG: VISUALIZATION OF NEEDLE ACCESS PATHWAY AND A FIVE-DOF EVALUATION

(a)

649

(b)

A

B

(c)
Fig. 4.

Fig. 5. Demonstration of the illustrativeness of our method in various situation: perfectly aligned (Left); IPT (Middle); OPT (Right). When the virtual
needle is not well aligned, errors are reflected by the cues.

(d)

Gestalt-like configural cue to convey depth perception.

strengthen the depth sensation by combining multiple consistent
cues [25]. We do this by adding two reference lines. The addition of reference frames/lines would interfere with the visual
processing system to construct a 3-D layout of the presented
content [24]. Fig. 4(c) shows a configuration of circles exactly
like in Fig. 4(b) with an addition of two oblique lines. Each of
these two lines touch the center of one of the circles. Although
these two lines are disconnected, but the human vision system
is so powerful that broken lines can be interpreted as a single
continuous line, provided that there are occlusions filling the
broken areas. Another perception comes along with this illusion
is that one would think that the line is actually passing through
the centers of all these circles. This forces our visual processing
system to construct a 3-D scene that seems the illustration is an
outline of a tube that spans certain depth. If more depth cues
incorporate with this configuration, the depth perception can be
even stronger. As demonstrated in Fig. 4(d), some of the circles
are relatively smaller, giving a sense of perspective. Now, one
can feel that side A is much closer to the viewer than side B.
Although all the drawings are presented in a 2-D manner, the
human visual processing system will just output what seems to
be logical/rational/possible, even if a creation of 3-D space is
needed. We adopt this configural cue to be part of the pathway
illustration, letting the users construct the pathway orientation
using their own imagination.
C. Illustrativeness for Needle Access Pathway
The ultimate goal of our design is to illustrate the needle access pathways. We focus mainly on its illustrativeness. Again,
we evaluate our design based on the evaluation framework introduced in Section III. We also demonstrate its effectiveness in
reflecting misalignments using figures.
1) IPD: Although placing a virtual needle in the middle of a
volumetric beam is not difficult, the specificity is low. The
shortcoming is overcome by placing rings in the upper
part. Since the rings are centered along the pathway and
the radius is just a bit larger than the handle, any IPD is
reflected by leakages on the left or right side. The reference

line on the top also helps the placement of the virtual
needle [see Table I(q)].
2) OPD: The lower part of our illustration provides a continuous rendering result depending on the amount of OPD.
When placed in an ideal position, the needle tip blends in
with the volumetric beam. If a clear needle tip is shown,
the needle is placed in front of the beam. If the needle tip
is covered by the beam, it is at the back side. The upper
ring also helps placing the needle. A perfect example is
demonstrated in Fig. 5(left).
3) IPT: The wider end of the beam does not enhance the
indication of orientation, the rings complement this shortcoming. The rings fully embrace the virtual needle only
when the needle is perfectly aligned. Orientation disparity is reflected by partial leakage of the virtual needle.
Fig. 5(middle) shows a virtual needle intercrossing an illustrated pathway. Four out of six rings are cutoff. The
number of rings being cutoff also suggests the degree of
disparity. This can be corrected by rotating the needle and
revealing the covered rings, which is a clear objective that
can be achieved in a systematic way.
4) OPT: The upper rings act as a hint for the elimination of
OPT. Users tilt the needle back and forth to let the rings
embrace the virtual needle. The number of rings being covered by the virtual needle in the front part provides a discrete signal for the alignment status. Fig. 5(right) demonstrates that a virtual needle is tilted toward the screen. The
covered rings in the upper part suggest that the handle is
too close to the camera. The faded needle shaft suggests
that the needle is at the back of the volumetric beam.
Our design conveys information through a 2-D image which
can be directly displayed on a single screen. Compared to the
traditional methods, like presenting multiple cross sections or
equipping stereoscopic devices, our method is more intuitive.
Space reconstruction is required if orthogonal cross sections
are presented and yet it does not provide any mechanism to
encourage the alignment. Stereoscopic goggles are now more
common. However, in some operations, clinicians have to wear
surgical loupes and switching to goggles is not practical.

650

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 2, MARCH 2014

VI. EXPERIMENT
We report tests in this section. We designed an testing platform
to simulate a user performing needle access procedures with a
VR system. An optimal insertion pathway was provided. The
pathway was visualized by one of the five illustrations described
in this paper. We then analyzed users’ performance based on the
proposed evaluation framework.
A. Design
Our testing platform is a simple VR system equipped with
a phantom Omni as an input device. Users manipulate a statue
to control the movement of the virtual needle. A screen shows
a bounded environment where the users can freely move the
virtual needle. There is also an optimal pathway visualized by
various types of illustrations. The type of illustration used is
chosen by the computer. At the beginning of each session, there
is a 5 s countdown. After that, users can move the virtual needle
and try their best to align the virtual needle with the optimal
pathway. When the placement is satisfied, users can click on a
button to end that trial. Position and orientation information of
the virtual needle are recorded throughout the experiment with
a sampling rate of 30 samples/s.
B. Procedures
Every subject was first given 15 min to play with our testing
platform. During this period, they were instructed about the basic flow and the controls of the platform. Participants were told
that the goal was to align the virtual needle with the optimal
pathways. After that, the subjects were informed that we would
be recording 30 trials of this test. The sequence of the types of
illustration was a randomized Latin square sequence to eliminate the possible learning effect. There was no time limit for
each trial. At the beginning of each trial, the participants were
instructed to place the needle in a resting position for fairness.
C. Participants
We have invited 15 participants. All of them have neither experience with needle placement operations nor with the related
simulators. All of them are right-handed and have normal or
corrected-to-normal eyesight.
VII. RESULTS AND ANALYSIS
Performance by adopting various methods is evaluated using
the proposed framework. The implemented computation steps
of the four metrics are presented in Appendix A. The results
are visualized by bar charts in Fig. 6. The four figures represent IPD, OPD, IPT, and OPT from top to bottom, respectively.
Error bars show one standard deviation. Tests of statistical significance between our method and other methods are performed
using two-tailed t-test. Significance is shown in the charts where
“not significant” is abbreviated using “N.S.” and significant is
represented by the “p-value.” Ghost object is abbreviated using “Ghost O.” and crepuscular ray is abbreviated using “Cre.
Ray.” Performance of users is post tested with respect to the

Fig. 6.

Participants performance grouped by illustration.

CHAN AND HENG: VISUALIZATION OF NEEDLE ACCESS PATHWAY AND A FIVE-DOF EVALUATION

testing sequence. No first-order relationship is found, i.e., the
performance of later appearing trials is no better than former appearing trials. This shows that participants had reached a stable
level after the 15 min rehearsal.
In terms of IPD, Line enables the lowest possible error. It is
significantly better than our method (p < 0.01) and other three
methods. This result matches our analysis in Section IV. A line
is very fine and therefore the precision is very high compared to
other methods that render more complicated illustrations on the
screen. Our method performs similarly to Ghost object but is
significantly better than Crepuscular ray (p < 0.05) and Strip
(p < 0.05).
In terms of OPD, Line is still ranked first but is no more
significantly better than our method. The averaged difference in
error is 0.067 cm (commonly used 18 Gauge needle is of 0.1 cm
in diameter). The ranking of the rest of the methods are the same
as in the case of IPD. Our method and Ghost object tie but are
significantly better than Crepuscular ray (p < 0.05) and Strip
(p < 0.05).
In terms of IPT, our method is ranked first and is significantly
better than other methods (p < 0.001). This may suggest that
the addition of the configural cue can help the participants better
spot the in-plane orientation disparity. When the virtual needle
is not aligned well with the optimal path, the leakage in the
rings can be spotted and errors can be corrected by the users.
The remaining methods are ranked in the order : Line, Ghost
object, Crepuscular ray, and Strip. Strip is ranked the last, this
suggests that its wide end hinders alignment to certain extent.
This conforms to our previous analysis.
In terms of OPT, Ghost object ranked first but not significantly better as our method which ranked second. Line
(p < 0.05) and Crepuscular ray (p < 0.001) work significantly
worse than our method. As we have mentioned in the analysis
part, neither a line nor a volume beam bears orientation information. Users get confused when they have no idea whether the
illustrated path is pointing inward or outward, it is reasonable
that the users performed worse. Strip works better than Line:
this may suggest that participants somehow acquired the tilting
information from the varying width of a strip.
In Fig. 7, we show the average elapsed time of each trial
using various methods. Participants spent the least amount of
time to finish each trial when our illustration was employed. It
took about 38% longer when Line was employed. This may be a
possible explanation of why the performance of participants was
good when Line was employed in the two displacement metrics.
Line is a common indicator in our daily life. People know that
even a line might not be very intuitive, they can keep moving
the needle and accumulate more information before they make
any decision. This is a classical example of speed-accuracy
tradeoff. Obviously, we cannot simply say that faster is better.
A more proper way should be to find out which illustration
gives a better representation of the position and orientation of
the optimal path such that a participant requires less time to
understand the rendered scene. In this regard, we investigate the
motions performed by the participants during the experiment.
We have recorded the motions of the participants throughout
the experiment. We could reconstruct their performance in terms

Fig. 7.

651

Average elapsed time of trials grouped by illustrations.

of the time domain. Since we are aware of the fact that it is not
difficult for a 2-D screen to visualize in-plane information, we
put our eye on the two out-of-plane metrics to observe the overall
performance of the participants.
We evaluate the OPD and OPT of every sampling moment
during the experiment. We take an average of every trial of every participant. For those trials that ended earlier, we pad the
remaining performance data using the data from the last sampling moment. The first 13.6 s of the evaluated result is plotted.
Fig. 8 shows a plot of OPD versus time (top) and a plot of
OPT versus time (bottom). At the beginning of each session, the
needle was placed in a rest position such that the displacement
and tilting disparity were very large. Their magnitudes soon
dropped to a reasonable range. After that, the performance differed greatly depending on the adopted type of illustrations. For
those methods that require the participants to carry out depth
testing (moving back and forth to change the depth ordering) to
validate the correctness of the placement, the curves rebounded
significantly. The sole dependence on depth testing is reflected
by the slow converging speed of those curves. When our method
was adopted [red lines in Fig. 8(a) and (b)], the converging
speed was relatively faster. The participants spent more time in
microcontrolling the needle, rather than moving vigorously and
trying to reconstruct the placement information by observing
the changes in depth ordering. The rebound in OPT was even
more obvious when Line and Crepuscular ray were adopted.
Those large magnitude rebounds are mainly due to the lack of
orientation information. Participants were forced to rotate the
needle at a high dynamic range of rotational space to reconstruct
the implicit orientation encoded in the illustration. In contrast
to this, when our method was adopted, the OPT quickly converged to a stable level. This suggests that the configural cue
successfully conveys the orientation information to the users.
Therefore, the participants were spending most of the time to
fine-tune the orientation, not to understand the rendered image.
To conclude, Line enables the lowest IPD, OPD, but gives a
very high OPT. Our method gives the lowest IPT and generally
produces a low error level in every other metric. Our method is
more all-round and does not have a significant flaw compared to
other existing methods. Time domain analysis of participants’

652

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 2, MARCH 2014

lustration. Our design evades the limitation of 2-D displays and
successfully conveys both placement and orientation information to the viewer. An experiment has been carried out and user
data have been collected. Although our method does not rank
best in all metrics, unlike the others, our method bears no critical weak point in any of the four metrics. Time domain analysis
of participants’ motions clearly shows that our illustration can
help viewers reconstruct the orientation of the optimal pathway effectively. We look forward to extending our evaluation
framework to other similar medical applications.
APPENDIX
DEFINITION OF MEASUREMENTS

(a)

This section defines the measurements described in Section III. The definition is closely related to the selected computer
graphic library. Here, we adopt a common open standard API,
the OpenGL.
For a point defined in the object space, its object coordinate
will be first converted to the eye coordinate and then to the clip
coordinate by multiplying with the model-view matrix and the
projection matrix1 :
⎛
⎞
⎛
⎞
xclip
xob j
⎜ yclip ⎟
⎜ yob j ⎟
⎝
⎠ = Mpro jection · Mm o delview ⎝
⎠ . (1)
zclip
zob j
wclip
wob j
Then, the screen coordinate is computed by perspective division
(assumes a standard viewport).
⎞ ⎛
⎞
⎛
xclip /wclip
xscreen
⎝ yscreen ⎠ = ⎝ yclip /wclip ⎠ .
(2)
zscreen
zclip /wclip
The distance between two objects on the screen solely depends
on the x and y components. Therefore, the in-plane distance
(IPD) between the optimal path and the virtual needle is defined
as the shortest distance between the tip of the virtual needle and
the optimal path
IPD = DISTX Y (To + ((Tn − To ) · N̂o )N̂o , Tn )

(3)

where Tn and To are the tip position of the virtual needle and the
optimal path, respectively, N̂o is the unit vector of the direction
of the optimal path and DISTX Y computes the distance of two
points by using the x and y components only. Similarly, the
out-of-plane distance (OPD) is defined as
OPD = DISTZ (To + ((Tn − To ) · N̂o )N̂o , Tn )
(b)
Fig. 8. Participants performance throughout the experiment. In both cases,
our method enables a faster convergence toward a stable level.

(4)

where DISTZ computes the distance of two points by using the
z component only.
The orientation disparity between the optimal path and the
virtual needle can be computed by calculating the dot product
between two unit vector

motions suggests that our method gives an intuitive presentation
to the placement and orientation of an optimal path.

cos θ = N̂o · N̂n

VIII. CONCLUSION

1 The model-view matrix defines object position relative to the camera position and the projection matrix determines how an object is projected onto the
screen. For details, please refer to the OpenGL programming guide (Red Book)
Chapter 3.

In this paper, we proposed not only an evaluation framework
that suits needle access procedures, but also a new type of il-

(5)

CHAN AND HENG: VISUALIZATION OF NEEDLE ACCESS PATHWAY AND A FIVE-DOF EVALUATION

where N̂n is the unit vector of the direction of the virtual needle.
This angle θ composed of both the in-plane component and the
out-of-plane component. We separate these two components by
comparing the similarity between the axis of rotation with the
camera direction. The similarity is defined as the dot product
of the axis of rotation and the camera direction. The axis of
rotation is defined as the normalized cross product between the
direction of the optimal path and the virtual needle. Thus, IPT
is defined as the in-plane component of the angle θ
	


 N̂ × N̂



o
n
(6)
· N̂cam era  θ
IPT = θ IP = 
 N̂o × N̂n 

where N̂cam era is the camera direction. The length of the cross
product becomes zero when the virtual needle and the optimal
path are perfectly aligned or perfectly reversed. Both cases can
be detected by checking the value of the angle θ to avoid division by zero. Lastly, the OPT is the remaining part of the total
orientation disparity
OPT = θ OP = θ − θ IP .

(7)

REFERENCES
[1] J. Beyer, M. Hadwiger, S. Wolfsberger, and K. Buhler, “High-quality
multimodal volume rendering for preoperative planning of neurosurgical interventions,” IEEE Trans. Visual. Comput. Graph., vol. 13, no. 6,
pp. 1696–1703, Nov./Dec. 2007.
[2] E. J. L. Brunenberg, A. Vilanova, V. Visser-Vandewalle, Y. Temel,
L. Ackermans, B. Platel, and B. M. T. H. Romeny, “Automatic trajectory planning for deep brain stimulation: A feasibility study,” in Proc.
Med. Image Comput. Comput. Assist. Interv., 2007, pp. 584–592.
[3] N. Navkar, N. Tsekos, J. Stafford, J. Weinberg, and Z. Deng, “Visualization and planning of neurosurgical interventions with straight access,” in
Information Processing in Computer-Assisted Interventions. vol. 6135,
N. Navab and P. Jannin, Eds. Berlin, Germany: Springer-Verlag, 2010,
pp. 1–11.
[4] P. Herghelegiu, V. Manta, R. Perin, S. Bruckner, and M. E. Gröller, “Biopsy
planner—Visual analysis for needle pathway planning in deep seated brain
tumor biopsy,” Comput. Graph. Forum, vol. 31, no. 3, pp. 1085–1094, Jun.
2012, (presented at EuroVis 2012).
[5] A. Badawi and M. Elmahdy, “Path planning simulation for 3d-ultrasound
guided needle biopsy system,” in Proc. IEEE Int. Midwest Symp. Circuits
Syst., 2003, pp. 345–347.
[6] Y. Sato, M. Nakamoto, Y. Tamaki, T. Sasama, I. Sakita, Y. Nakajima,
M. Monden, and S. Tamura, “Image guidance of breast cancer surgery
using 3d ultrasound images and augmented reality visualization,” IEEE
Trans. Med. Imag., vol. 17, no. 5, pp. 681–693, Oct. 1998.
[7] M. Rosenthal, A. State, J. Lee, G. Hirota, J. Ackerman, K. Keller,
E. D. Pisano, M. Jiroutek, K. Muller, and H. Fuchs, “Augmented reality guidance for needle biopsies: An initial randomized, controlled trial in
phantoms,” Med. Image Anal., vol. 6, no. 3, pp. 313–320, 2002.
[8] F. Wacker, S. Vogt, A. Khamene, J. Jesberger, S. Nour, D. Elgort,
F. Sauer, J. Duerk, and J. Lewin, “An augmented reality system for MR
image-guided needle biopsy: Initial results in a swine model,” Radiology,
vol. 238, no. 2, pp. 497–504, 2006.
[9] N. Chentanez, R. Alterovitz, D. Ritchie, L. Cho, K. Hauser, K. Goldberg,
J. Shewchuk, and J. O’Brien, “Interactive simulation of surgical needle
insertion and steering,” in Proc. ACM SIGGRAPH 2009, Aug. 2009, pp.
88:1–88:10.
[10] O. Goksel, S. E. Salcudean, and R. Rohling, “Image synthesis of deformed
tissue with application to ultrasound for prostate brachytherapy,” in Proc.
Can. Med. Biol. Eng. Conf., 2006.

653

[11] D. Ni, W. Chan, J. Qin, Y. Qu, Y. Chui, S. Ho, and P. Heng, “An ultrasoundguided organ biopsy simulation with 6dof haptic feedback,” in Proc. Med.
Image Comput. Comput. Assist. Interv., 2008, pp. 551–559.
[12] F. Vidal, P. Villard, R. Holbrey, N. John, F. Bello, A. Bulpitt, and D. Gould,
“Developing an immersive ultrasound guided needle puncture simulator,”
in Proc. Med. Meets Virtual Reality 17, 2009, vol. 142, pp. 398–400.
[13] W. Chan, D. Ni, W. Pang, J. Qin, Y. Chui, C. Yu, and P. Heng, “Learning
ultrasound-guided needle insertion skills through an edutainment game,”
Trans. Edutainment, vol. IV, pp. 200–214, 2010.
[14] W. Chan, J. Qin, Y. Chui, and P. Heng, “A serious game for learning
ultrasound-guided needle placement skills,” IEEE Trans. Inf. Technol.
Biomed., vol. 16, no. 6, pp. 1032–1042, Nov. 2012.
[15] R. Khlebnikov, B. Kainz, J. Muehl, and D. Schmalstieg, “Crepuscular
rays for tumor accessibility planning,” IEEE Trans. Vis. Comput. Graph.,
vol. 17, no. 12, pp. 2163–2172, Dec. 2011.
[16] D. Röttger, S. Engelhardt, and S. Müller, “Multimodal visualizations for
pre-operative neurosurgical planning,” in Proc. Emerg. Technol. Med.
Diagnosis Ther., INFORMATIK 2011, Oct. 2011.
[17] M. Everts, H. Bekker, J. B. Roerdink, and T. Isenberg, “Depth-dependent
halos: Illustrative rendering of dense line data,” IEEE Trans. Vis. Comput.
Graphics, vol. 15, no. 6, pp. 1299–1306, Nov./Dec. 2009.
[18] D. Stalling, M. Zöckler, and H.-C. Hege, “Fast display of illuminated field
lines,” IEEE Trans. Vis. Comput. Graph., vol. 3, no. 2, pp. 118–128, Apr.
1997.
[19] H.-W. Shen and D. L. Kao, “A new line integral convolution algorithm for
visualizing time-varying flow fields,” IEEE Trans. Vis. Comput. Graph.,
vol. 4, no. 2, pp. 98–108, Apr. 1998.
[20] V. Interrante, H. Fuchs, and S. M. Pizer, “Conveying the 3D shape of
smoothly curving transparent surfaces via texture,” IEEE Trans. Vis. Comput. Graph., vol. 3, no. 2, pp. 98–117, Apr. 1997.
[21] G. Elber, “Line art illustrations of parametric and implicit forms,” IEEE
Trans. Vis. Comput. Graph., vol. 4, no. 1, pp. 71–81, Jan. 1998.
[22] A. Hertzmann and D. Zorin, “Illustrating smooth surfaces,” in Proc. 27th
Annu. Conf. Comput. Graph. Interact. Technol., ser. SIGGRAPH 2000,
pp. 517–526.
[23] P. Harvey, The History of Topographical Maps; Symbols, Pictures and
Surveys. London, U.K.: Thames and Hudson, 1980.
[24] S. E. Palmer, E. Simone, and P. Kube, “Reference frame effects on shape
perception in two versus three dimensions,” Perception, vol. 17, no. 2,
pp. 147–163, 1988.
[25] J. Burge, M. A. Peterson, and S. E. Palmer, “Ordinal configural cues combine with metric disparity in depth perception,” J. Vis., vol. 5, no. 6,
pp. 534–542, 2005.

Wing-Yin Chan received the B.Eng. degree in computer engineering from the
Chinese University of Hong Kong, Shatin, Hong Kong, where he is currently
working toward the Ph.D. degree in the Department of Computer Science and
Engineering.
His research interests include virtual reality simulation and nonphotorealistic
rendering.

Pheng-Ann Heng (M’92–SM’06) received the Ph.D. degree in computer science from Indiana University, Indianapolis, IN, USA.
He is currently a Professor in the Department of Computer Science and
Engineering, Chinese University of Hong Kong, Shatin, Hong Kong, where he
is also the Director of the Virtual Reality, Visualization, and Imaging Research
Centre. He is also the Director of the Center for Human–Computer Interaction,
Shenzhen Institute of Advanced Integration Technology, Chinese Academy of
Sciences, Shenzhen, China. His research interests include virtual reality applications in medicine, visualization, medical imaging, human–computer interfaces,
rendering and modeling, interactive graphics, and animation.

