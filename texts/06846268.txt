IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

1153

On the Use of Coupled Shape Priors for Segmentation
of Magnetic Resonance Images of the Knee
Jincheng Pang, Student Member, IEEE, Jeffrey B. Driban, Timothy E. McAlindon,
José G. Tamez-Peña, Member, IEEE, Jurgen Fripp, Member, IEEE, and Eric L. Miller, Fellow, IEEE

Abstract—Active contour techniques have been widely employed
for medical image segmentation. Significant effort has been focused
on the use of training data to build prior statistical models applicable specifically to problems where the objects of interest are embedded in cluttered background. Usually, the training data consist
of whole shapes of certain organs or structures obtained manually
by clinical experts. The resulting prior models enforce segmentation accuracy uniformly over the entire structure or structures to
be identified. In this paper, we consider a new coupled prior shape
model which is demonstrated to provide high accuracy, specifically
in the region of the interest where precision is most needed for the
application of the segmentation of the femur and tibia in magnetic
resonance (MR) images. Experimental results for the segmentation of MR images of human knees demonstrate that the combination of the new coupled prior shape and a directional edge force
provides the improved segmentation performance. Moreover, the
new approach allows for equivalent accurate identification of bone
marrow lesions, a promising biomarker related to osteoarthritis,
to the current state of the art but requires significantly less manual
interaction.
Index Terms—Active contours, bone marrow lesion (BML),
coupled prior shape, image segmentation, level set methods.

I. INTRODUCTION

O

STEOARTHRITIS (OA) is a common debilitating disease afflicting over 71 million people globally. Due to its

Manuscript received August 16, 2013; revised May 15, 2014; accepted June
4, 2014. Date of publication June 30, 2014; date of current version May 7,
2015. This work was supported by Grant 1R01AR054938 from NIH/NIAMS.
The Osteoarthritis Initiative (OAI) is a public-private partnership comprised of
five Contracts (N01-AR-2-2258; N01-AR-2-2259; N01-AR-2-2260; N01-AR2-2261; N01-AR-2-2262) funded by the National Institutes of Health, a branch
of the Department of Health and Human Services, and conducted by the OAI
Study Investigators. Private funding partners include Pfizer, Inc.; Novartis Pharmaceuticals Corporation; Merck Research Laboratories; and GlaxoSmithKline.
Private sector funding for the OAI is managed by the Foundation for the National
Institutes of Health.
J. Pang and E. L. Miller are with the Department of Electrical Engineering,
Tufts University, Medford, MA 02155 USA (e-mail: pangjc@ece.tufts.edu;
elmiller@ece.tufts.edu).
J. B. Driban and T. E. McAlindon are with the Division of Rheumatology,
Tufts Medical Center, Boston, MA 02111 USA (e-mail: jdriban@gmail.com;
tmcalindon@tuftsmedicalcenter.org).
J. G. Tamez-Peña is with the Tec de Monterrey, Monterrey 64849, Mexico,
and also with Qmetrics Technologies LLC, Rochester, NY 14618 USA (e-mail:
jose.tamezpena@itesm.mx).
J. Fripp is with the CSIRO Computational Informatics, The Australian
e-Health Research Center, Brisbane, Qld. 4029, Australia (e-mail: jurgen.
fripp@csiro.au).
This paper has supplementary downloadable material available at http://
ieeexplore.ieee.org, provided by the authors. This material is a multimedia mp4
format video clip which shows curve evolution processes regard to different
initial curves. This material is 8.74 MB in size.
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2329493

Fig. 1.

MRI knee image with femur, tibia, cartilage, BML denoted.

large social and economical burden, significant resources have
been directed to understanding the pathophysiology of OA. Cartilage degeneration is an important index of OA progression;
thus, a large number of image processing-based quantitative
measurement methods for cartilage measurement [1]–[6] have
been developed to aid clinical researchers. In addition to cartilage, bone marrow lesions (BMLs) also represent a common
OA-related MRI finding associated with structural degeneration
and pain [7]–[11]. From an image-processing perspective, characterization of cartilage and BMLs tends to follow a two-step
approach: locate the bones, then locate the cartilage or BMLs.
This strategy is necessitated by the challenges associated with
identifying cartilage or BMLs directly. As shown in Fig. 1, knee
cartilage is quite thin relative to the femur and tibia, may be
affected with poor contrast in the image, and cartilage defects
may well indeed comprise multiple cartilage components depending on the state of OA in the knee and the image slice being
segmented. In the case of BMLs, it is difficult to extract and
quantify these structures directly due to the uncertain shapes,
numbers, and locations of BMLs [12]. Thus, most researchers
[10], [13]–[15] also prefer to segment bone first to either define
a region of interest (ROI) in which BMLs may be located or to
serve as reference for healthy bone.
Although characterizations of cartilage and BMLs follow the
same two-step approach, the MR sequences for imaging cartilage and BMLs are very different [16]. The MR sequences for
cartilage evaluation suppress the inhomogeneity (mainly BMLs)

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

1154

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

[1]–[6], while in the MR sequences for BMLs segmentation, the
heterogeneity in the bone regions is more prominent[7]–[11].
State-of-the-art bone segmentation methods [1]–[6] have been
designed and validated for the former type of data. Unfortunately, as we demonstrate in Section III-A, the application of
these methods to the data of interest here results in degraded performance specifically for those cases where there is significant
structure within the bones such as BMLs.
Motivated by these results, in this paper, we present an active contour algorithm based on the level set framework [17],
[18]. It is designed to segment femur and tibia on data collected using a BML protocol. Active contours have been widely
used in medical image segmentation problems [19], [20] and
can be divided into two classes: region-based and edge-based.
In the case of the region-based approach, a number of statistically driven curve evolution techniques have been developed.
For example, the well-known Chan–Vese model [21] implicitly assumes that the intensity distribution of object and background are Gaussian with the same variance, and as a consequence seeks a segmentation which minimizes, in part, a mean
square error type of objective function. For cases where such a
parametric model is not appropriate, a variety of nonparametric techniques have been developed most often based on the
estimation of pixel-intensity probability distribution functions
(PDFs) constructed using the kernel density estimation (KDE)
method [22]. These approaches employ training data to construct prior distributions for the object and background pixels.
From these estimated PDFs, objects are identified using curve
evolution algorithms designed to maximize the match between
the PDFs constructed for an estimated object and background
relative to these priors. Here, we point to a range of metrics that
have been developed to measure quality of the match including
the Kullback–Leibler distance [23], the Bhattacharyya distance
[24], etc. However, the size, location, and the intensity histogram
of the inhomogeneous area and the BMLs within the bone area
(see Fig. 1 and other figures in Section III) are uncertain in our
knee bone segmentation problem making the intensity distributions of bones very difficult to model. Thus, as we demonstrate in
Section III-A, region-based active contours have a difficult time
performing well for our problem.
In contrast to region-based active contour, edge-based active
contour [25] tends to suffer from limited capture range and
sensitivity to initialization. Thus, many active contour methods based on the use of image gradient information have been
developed to address this challenge. Xu and Prince [26] developed the gradient vector flow (GVF) method which not only
increases the capture range for edge-based contours but also is
bidirectional which means initial curves are not necessary to
be either inside or outside true boundaries as required in [25],
etc. Later, Li and Acton [27] proposed Vector Field Convolution
(VFC). The VFC field is generated simply by convolving the
image edge map with a suitably designed vector field kernel.
Although certain anatomical structures of the knee bone exists
in our problem, noise, clutter, BMLs, and degeneration in the
boundaries yield rather poor performance for purely edge-based
active contour methods.

Due to noise, artifacts, and other inconsistencies encountered
when dealing with real data, active contour techniques typically
require some form of regularization to achieve suitable results in
practice. While generic curvature based methods were initially
considered [17], in recent years, there has been considerable
effort directed toward the use of prior instances of segmented
shapes for purposes of regularization [28]–[35]. Generally, there
are two ways to encode prior shape information into a level
set-based active contour segmentation scheme. The first one is
to represent the level set function φ as a linear combination
of basis functions obtained via principal component analysis
(PCA) applied to the signed distance functions in the training set
[33], [35]. Modifications to the methods in [33] and [35] include
the use of binary prior shapes in [31] and [36], kernel PCA of
binary prior shapes in [36], and the addition of constraints on
the evolution of the PCA coefficients in [31]. The second way to
incorporate prior shape is to use a penalty term to ensue that the
evolving curve does not move “far” from the reference shapes.
In [28] and [29], the authors consider the use of a single such
reference shape. Extensions to libraries of prior observed shapes
include the work in [30], [32], and [37] based on KDE techniques
to estimate the similarities between a shape and a set of training
shapes as well as [30], [32] where the metrics to evaluate the
similarities between two shapes are also mentioned and briefly
discussed. The introduction of KDE into the prior shape model
as in [30] and [32] employed the shape information for each
image in the training set and thus improved the capability to
capture large shape variances when segmenting test data.
All the prior shape methods mentioned previously are for
single object problems. For the case of segmenting multiple
components, not only the shape of each object or component
but also the relative positions among objects could be used as
prior information for segmentation. Tsai et al. [38] directly extended their PCA prior shape model of single object [33], [35]
for multiple objects. In addition to the shape information, Han
et al. [39] proposed an algorithm to maintain the number of
initial disconnected components during the evolution of multiple curves while Sundaramoorthi and Yezzi [40] designed a
coupling repulsive force to realize the same functionality. In
addition, Zimmer and Oliver-Marin [41] used a penalty term
to prevent two curves from overlapping each other. Moreover,
[42] and [43] designed specific coupling forces to take into account more information about the relative position or topology
of the object structure. In addition, Ma et al. proposed a shape
influence term [44] to incorporate relative distance information
and used the region competition scheme [45] for the segmentation of female pelvic organs [46]–[48]. Moreover, the coupled
nonparametric shape (CNS) [49] model used the KDE [22] to
incorporate the prior shape information and extended the single
prior shape model in [32] to multiple components situation for
the segmentation of basal and ganglia structures.
In the case of BMLs within the knee, clinicians are especially concerned with accuracy in the vicinity of the joint. The
key contribution of the study in this paper is the adaptation of
shape prior methods to account for this type of region-specific
accuracy requirement in the context of a multipart segmentation

PANG et al.: ON THE USE OF COUPLED SHAPE PRIORS FOR SEGMENTATION OF MAGNETIC RESONANCE IMAGES OF THE KNEE

1155

Fig. 2. (a) Reference image for alignment and our primary concern is the area near the joint which is between the two horizontal lines. (b) Aligned shape stack
with respect to the newly defined knee centers u φ . (c) Aligned femur with respect to the femur center u φ 1 and tibia center u φ 2 individually (CNS model in [49]).
(d) Unaligned shape stack. (e) and (f) Standard deviation of aligned shape stacks with respect to (b) and (c), respectively.

problem in [7] to the curve evolution process. More specifically,
of primary concern in this paper is the segmentation in the vicinity of the joint where we seek a method that can identify the
individual bones reliably even when provided with imagery containing BMLs corrupting the bones themselves. In our coupled
shape model, this prior places strong constraints on the segmentation in the region near the joint [i.e., areas within the two
horizontal lines as show in Fig. 2(a)] where the separate components (femur and tibia segments) must be kept from either
merging or moving too far from one another even in the presence of significant clutter from BMLs, cartilage etc. Moreover,
the model provides less of a constraint in those areas further
from the joint in our case where either accuracy is not required
(e.g., inhomogeneous area in Fig. 1). Here, we want to point that
the idea of [49] is similar to ours but still like other prior shape
methods, the authors in [49] also evaluate the match uniformly
over the whole image domain which is not what we seek for
the knee segmentation problem and, as we show empirically in
Section III-A, does not perform quite as well as the approach
we suggest for the problem of interest here.
In addition to the coupled prior shape model, active contours
can be driven by image-based forces (region-based or edgebased). As mentioned previously, it is very challenging to build
region-based forces due to the uncertain size, location, and intensity histogram of BMLs within the bone region. Moreover,
the femur and tibia are separated by the cartilage which is very
thin as shown in Fig. 1. Thus, edge force fields generated by
the femur/cartilage interface and tibia/cartilage interface using,
e.g., GVF and VFC methods can overwhelm with each other as
illustrated in Fig. 4. To overcome this difficulty, we adapt the

directional edge information idea [50], [51], adjust and apply it
to our knee segmentation problem. By combining the coupled
prior shape model and the directional force field, we demonstrate that our active contour model is robust to initializations
and can segment the femur and tibia accurately even in highly
cluttered situations. Another major contribution of this paper is
the development and validation of our active contour model for
knee bone segmentation and sequently BML segmentation and
quantification which yields comparable results but requires far
less human interaction with the data than competing methods.
Before moving on, we note that the study in this paper is
concerned primarily with the processing of two dimensional
(2-D) images with relatively large slice thickness and interslice
gap. The fact that state of the art in cartilage segmentation does
consider the full 3-D problems such as [3] and [4] is due, at least
in part, to the availability of MRI datasets characterized by small
slice thickness and usually no interslice gaps. As illustrated
in Section III-A, the 3-D methods have similar results as our
2-D method when bone regions are homogeneous and with few
BMLs but their performance does degrade when large BMLs
and other inhomogeneities are present. This fact indicates the
advantages of our method in cases of great relevance to BML
analysis. Based on our validated 2-D method in this paper, we
feel that extension to 3-D is best left to the future.
The remainder of this paper is organized as follows. In Section
II, we present the level set framework of knee segmentation
and our coupled prior shape model as well as the directional
edge-based force. Then, experimental results are presented and
discussed in Section III. Finally, we draw our conclusion and
discuss our future work in Section IV.

1156

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

II. SEGMENTATION BASED ON COUPLED PRIOR SHAPE
AND DIRECTIONAL EDGE FORCE
In this section, we first set up the framework of curve evolution
for our knee segmentation problem in Section II-A. In Sections
II-B and II-C our coupled prior shape model and the directional
vector field convolution (DVFC) are illustrated, respectively.
The implementation details are presented in Section II-D.
A. Framework of Curve Evolution
The essential idea of level set methods for segmentation is

to represent a curve C(t)
as the zero slice of an auxiliary level
set function φ(x, t), where t is an artificial time parameter,

i.e., C(t)
= {x|φ(x, t) = 0)}. Active contour techniques using
level set functions “evolve” φ as a function of time such that, as

t → ∞, C(t)
approaches the contour of interest in the image.
Since we are going to handle two curves simultaneously, we use
two level set functions to model the shapes of both femur and
 1 and C
2
tibia.1 Thus, we seek to identify two closed curves C
which we define as the zero level sets of functions φ1 and φ2 ,
respectively
 k = {x ∈ Ωk |φk (x) = 0},
C

k = 1, 2

where Ω1 and Ω2 represent the femur and tibia, respectively. By
using the chain rule, an evolution equation of φk is
∂φk
= −∇φk · F(x)
(1)
∂t
where F(x) = xt is known as the speed function. If F(x) is in

the normal direction of C(t),
then (1) becomes
∂φk
= |∇φk |F (x)
(2)
∂t
where F (x) = |F(x)| is the magnitude of F(x).
The essential work of various active contour methods [21],
[24], [26], [27], [30], [32], [37] is to design the speed function
F (x) or F(x). From the variational perspective, some of these
forces are conservative vector fields which means they equal the
gradient of a scalar functional. Those conservative vector fields
 k (t) [52]
are always oriented toward the normal direction of C
and result in evolution processes of the form in (2). Usually,
energy functionals based on image fitting [21], [24], [53], [54]
and prior shape modeling [28]–[30], [32] are constructed, and
the corresponding forces are derived. From a force balance perspective [26], [27], [52], F(x) could also be designed directly
without constructing the associate energy functional [26], [27],
[43], [55].
In this paper, we present two novel force fields denoted by Fkcs
 k (k = 1, 2). Since Fk is
and Fkdvfc which act upon the curve C
cs
derived from a coupled shape prior based energy functional and
1 While one could use a single level set function constrained to have two
connected components to represent both the femur and the tibia, in this paper,
we choose to use two level sets, one for each bone. We are motivated to make this
choice primarily by the nature of the edge-based forces we develop in Section
II-C. Specifically, one set of forces is defined for the tibia and a second for the
femur. Thus, it proves convenient to employ separate level set functions for each
rather than a single such function which would need to be processed at each
stage of the algorithm to keep track of the individual components.

 k , we only focus
its direction is toward the normal direction of C
on its magnitude Fcsk . In addition, Fkdvfc is constructed directly
by incorporating directional information to the existing vector
field convolution method [27]. By combining those two forces,
we have the following evolution equation:
∂φk
= λ|∇φk |Fcsk (x) − ∇φk · Fkdvfc (x),
∂t

k = 1, 2

(3)

where λ is a positive coefficient to balance these two force
fields, Fcsk is derived from a shape prior while Fkdvfc from the
edge information. In the following two sections, we illustrate
how to build Fcsk and Fkdvfc , respectively.
B. Coupled Prior Shape Force
Similar to [30], [32], and [37], we employ the KDE method
[22] to capture our prior shape information. Instead of modeling p(φ1 ) and p(φ2 ) separately, we model the joint probability
density function p(φ1 , φ2 ) as follows:


N
1 
Di (φ1 , φ2 )
p(φ1 , φ2 ) ∝
exp −
(4)
N i=1
2σφ2
resulting in the corresponding coupled shape energy
Ecs = − log p(φ1 , φ2 )
where Di (φ1 , φ2 ) is a shape dissimilarity metric between φ1 , φ2 ,
and the corresponding shapes in the ith training sample, and
N is the number of training samples. In addition, σφ is the
kernel width. One contribution in this paper is our design of a
novel Di (φ1 , φ2 ) discussed below. We set σφ2 the mean squared
nearest-neighbor distance following [30].
By using the calculus of variation, we have


N
Di
∂Di
i=1 Di exp −
2
2σφ ∂φk
∂Ecs


=
(5)
∂φk
N
Di
2
2σφ i=1 exp − 2
2σφ
where k = 1, 2 and thus the force derived from the prior shape
driving curve evolution can be defined by
Fcsk = −

∂Ecs
,
∂φk

k = 1, 2.

(6)

Next, we introduce a new coupled prior shape model to describe the knee shape for both femur and tibia as well as their
relative positions simultaneously by defining a new Di (φ1 , φ2 ).
For the ith training image i = 1, 2, . . . , N , we obtain the shape
of the femur and tibia and denote their corresponding level set
functions as ψ1i and ψ2i , respectively. For all i, we preprocess
the data to ensure that ψ1i and ψ2i are aligned via only translation (i.e., no rotation or scaling) with respect to the “center” of
the two objects structure as illustrated in Fig. 2(a) and defined
rigorously below. The aligned shapes of knees are displayed in
Fig. 2(b).
For arbitrary level set functions φ1 and φ2 (for femur and tibia,
respectively, in our knee problem), the dissimilarity between the

PANG et al.: ON THE USE OF COUPLED SHAPE PRIORS FOR SEGMENTATION OF MAGNETIC RESONANCE IMAGES OF THE KNEE

pair of φ1 and φ2 and the pair ψ1i and ψ2i is defined by

i
i
Di (φ1 , φ2 , ψ1 , ψ2 ) =
[H2, (φ1 (x + uφ ))

1157

way (see Fig. 2), meaning that the center of gravity for both
the femur and tibia is not consistently defined. However, the
newly defined uφ in (9) takes into account this factor by linkΩ
ing itself to the geometry of the gap between the bones where
2
+H2, (φ2 (x + uφ )) − H2, (ψ1i ) − H2, (ψ2i ) dx. (7) we do have significant information and where accuracy is most
required. Moreover, our method is also different from [49] in
The approximate Heaviside function H2, (·) is defined in [21] two aspects. First, for each component, the aligned center is still
as
defined as the center of gravity of that component which means

	 z 

the prior shape constraint is still imposed uniformly around the
1
2
H2, (z) =
1 + arctan
.
(8)
shape rather than in a specific region. In addition, the authors
2
π

in [49] use the summation of KDE of the shape of each comFor simplicity, we use H(·) to represent H2, (·) through the ponent to build the energy functional and establish the coupling
paper. In addition, the knee center uφ is defined as follows relationships among components.
[see Fig. 2(a)]. First, the centroids of the femur and tibia are
As an example, we show in Fig. 2 the results of aligning 30
computed. We define uφ as a point that lies on the line crossing femur and tibia support functions from the dataset used to valithe femur and tibia centroids with the same distance to both date our approach in Section III. The reference image within the
bones. Formally, uφ is given by
training set for alignment is displayed in Fig. 2(a). In Fig. 2(c),
uφ = suφ 1 + (1 − s)uφ 2
(9) the centroids of the individual bones are used to align the tibia
and femurs as in [49]. In Fig. 2(b), we display the result of
where
jointly aligning both bones with respect to uφ defined in (9). As

xH(φi )dx
can
be seen both from the overlay of the individual images in
uφ i = 
, i = 1, 2
the training sets [see Fig. 2(b) and (c)] as well as from the maps
H(φi )dx
of the variance in each pixel of the aligned training sets [see
and s ∈ (0, 1) such that
Fig. 2(e) and (f)], the coupled shape approach provides greater
stability and thus a stronger geometric constraint precisely in
d(uφ , Ω1 ) = d(uφ , Ω2 ).
the region of most interest for this problem, i.e., in the vicinity
Here, d(uφ , Ωk ), k = 1, 2 denotes the distance from uφ to the
of the joint. As mentioned, due to the inconsistency of shape far
region Ωk .
from the joint in the training set, the alignment with respect to
the centroids of femur and tibia individually causes large vari

∂Di
= 2δ(φ1 (x)) H(φ1 (x)) + H(φ2 (x)) − H(ψ1i (x − uφ )) ance near the joint region as shown in Fig. 2(f) indicating week
∂φ1
constraint there [34].

By using calculus of variation, we obtain the gradient flow of


(x − uφ 1 )T
(7) as (10) where the delta function δ(·) in (10) is defined as the
− H(ψ2i (x − uφ )) + s 
H(φ1 (x ))
H(φ1 )dx
derivative of H2, . Details concerning the derivation of (10) are


i

i

provided
in the Appendix.
+ H(φ2 (x )) − H(ψ1 (x − uφ )) − H(ψ2 (x − uφ ))

C. DVFC Force
× δ(φ1 (x ))∇φ1 (x )dx
The force Fcsk stems from prior shape information discussed

above and is the gradient of an associated energy functional.

∂D
= 2δ(φ2 (x)) H(φ1 (x)) + H(φ2 (x)) − H(ψ1i (x − uφ )) However, forces can be also designed directly without construct∂φ2
ing the corresponding energy functionals from a force balance

perspective. One drawback of the VFC and GVF method is that
− H(ψ2i (x − uφ ))
weak edges might be overwhelmed by the strong edges espe

(x − uφ 2 )T
cially for our knee segmentation problem in the cartilage region



+ (1 − s)
H(φ1 (x )) + H(φ2 (x ))
H(φ2 )dx
[27], [55]. Inspired by the works in [43], [50], and [51], we

constructed a directional VFC force field which incorporates
i

i

− H(ψ1 (x − uφ )) − H(ψ2 (x − uφ ))
direction information into the VFC method.

A VFC field F(x) = F(x, y) is usually obtained by con


(10) volving a feature map f (x, y) with a kernel ker(x, y) =
× δ(φ2 (x ))∇φ2 (x )dx
[kerx (x, y), kery (x, y)]
Equation (7) is inspired by the intrinsic alignment shape model
F(x, y) = [f (x, y) ∗ kerx (x, y), f (x, y) ∗ kery (x, y)]
proposed by [30]. The major difference between our coupled
prior shape model and [30] is the definition of uφ . In [30], uφ is
where f (x, y) is usually taken as the edge map which usually is
defined as the center of gravity of a single shape. In our situation,
a single plane image of edge magnitudes. The kernel ker(x, y)
since the clinical researchers are mostly interested in the femur
is
and the tibia near the joint, people usually do not segment the
ker(x, y) = m(x, y)n (x, y)
parts of the femur and the tibia far from the joint in a consistent

1158

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

where m(x, y) is the magnitude of the ker(x, y) at location
(x, y). We adapt the power from definition of m(x, y) as defined
in [27]
m(x, y) = (r +  )−γ

(11)



n (x, y) = [−x/r, −y/r]
(12)

except n (0, 0) = [0, 0] and r = x2 + y 2 ,  is a small number
to prevent division by zero, and γ is a positive number to control the decrease. The continuous ker(x, y) is discretized over
a region {(x, y)|x, y = −R, . . . , −1, 0, 1 . . . R} for implementation and R denotes the kernel radius. More information about
the edge map f (x, y) and the kernel ker(x, y) can be found
in [27].
From the MRI knee imagery in, e.g., Fig. 1, we see that the
healthy femur and tibia are the dark regions separated by the
cartilage and surrounded by tissue. Because both cartilage and
tissue are brighter than the femur and tibia, there exists some
directional information about femur and tibia edges that can be
incorporated into the VFC model. Here, we draw on the ideas
in [51] using the synthetic image (see Fig. 3) to help illustrate
the concepts.
Assume the reference point O in Fig. 3 has the coordinate
(x0 , y0 ), then the directional edge map is

∇I(x, y) · n, 0 ≤ θ < π/2
fd (x, y) =
(13)
0,
else.

where n = (x − x0 , y − y0 )/ (x − x0 )2 + (y − y0 )2 , and θ
is the angle between n and ∇I which is the gradient of the
image. From Fig. 3, we can see that the outer edge is omitted
in the directional edge map. For example, A2 , A5 are typical
points in the outer edges and we can see that θ2 , θ5 > π/2. In
addition, the inner edge in the center part such as A3 is also
omitted which will prove quite useful for the knee problem.
In our knee problem, we let (xk , yk ) be a point within
the femur (k = 1) and the tibia (k = 2) and denote the angle between the vector (x − xk , y − yk ) and the image gradient, ∇I, as θk (x, y). We now note that only the edges with
0 ≤ θk (x, y) < π/2 are the valid edges for the femur Ω1 and
the tibia Ω2 , and thus, we have the directional edge map for this
structure as follows:

∇I(x, y) · nk , 0 ≤ θk < π/2
fdk (x, y) =
(14)
0,
else.

where nk = (x − xk , y − yk )/ (x − xk )2 + (y − yk )2 , and
θk is the angle between ∇I and nk .
Thus, the directional VFC force can be defined by
Fkdvfc = [fdk (x, y) ∗ kerx (x, y), fdk (x, y) ∗ kery (x, y)]
k = 1, 2.

(15)

To illustrate the utility of this new force, consider the knee
data shown in Fig. 4(a) with the smaller ROI provided along
with a number of VFC-based force fields. From Fig. 4(b), we
observe that the traditional VFC force field “leaks” into the
interbone region which will degrade the resulting segmentation.

Fig. 3. (a) Original image. O represents a reference point. Red dash arrow represents direction unit. Blue solid arrow denotes image gradient. Five
typical points are represented by A 1 − A 5 . (b) Conventional image edges.
(c) Directional image edges.

For example, the tibia edges in the middle and the femur edges in
left up are overwhelmed in Fig. 4(b). Alternatively, Fig. 4(c) and
(d) shows that the edges of femur and tibia are well preserved
by incorporating direction information, respectively.
D. Implementation
By combining the shape prior force Fcsk and the directional
VFC-based force Fkdvfc and according to (3), we get the curve
evolution equation for our knee segmentation problem as
∂φk
= λFcsk − Fkdvfc · ∇φk ,
∂t

k = 1, 2

(16)

where the λ is a positive coefficient to balance these two forces,
Fcsk and Fkdvfc are defined in (6) and (15), respectively. In addition, φ1 and φ2 are regularized as signed distance functions
[17], [18] and for each iteration, φ1 and φ2 are updated; then, the
centroid uφ is updated according to (9). For the heaviside function H(·) and the delta function defined in (8) and its derivative
δ(·), we use  = 1.5.
For the directional VFC force, we set the location reference
points (x1 , y1 ) and (x2 , y2 ) as the centroids for the initial curves
for the femur and tibia, respectively. The kernel radius R is
set to 15 in all of our experiments which is at the same scale
of the shape variance bandwidth as displayed in Fig. 2(e). In
addition, we set γ = 1.5 and  = 0.002. We also scale Fcsk to
have maximum value equal to one at each iteration leaving
λ to determine the relative impact of the two forces. In all
experiments presented in this paper, λ = 0.5 so that the force
due to the prior is generally a bit smaller than that of the edges.
With this weighting, in the early stages of the evolution, we see
two effects. First, Fkdvfc allows the curves to quickly converge to
those portions of the bones characterized by well-defined edges.
At the same time, for those areas where the edges are less well
defined or where there is clutter, the prior shape term keeps the
curve from straying too far from ground truth. At the later stages
of the algorithm after the clear edges are identified, in some of
the more ambiguous regions, Fkdvfc will then move the curve to

PANG et al.: ON THE USE OF COUPLED SHAPE PRIORS FOR SEGMENTATION OF MAGNETIC RESONANCE IMAGES OF THE KNEE

1159

Fig. 4. (a) MRI knee image with ROI (red box), the femur–cartilage and tibia–cartilage interfaces within ROI are denoted by the blue and green lines, respectively.
(b) Original VFC field. (c) Directional VFC field based on fd1 (x, y). (d) Directional VFC based on fd2 (x, y). In (b) neither of the interfaces are preserved. In (c)
and (d), the femur–cartilage and tibia-cartilage are well preserved, respectively.

Fig. 5. (a) Scheme for knee bone and BML segmentation. (b) Original MR
image. (c) Knee bone and BML segmentation results. Red and yellow lines
denote the knee bone and BML segmentation, respectively.

better find the true edges than would have been the case where
only the shape prior used.
The convergence criterion for the curve evolution process is
that if the region size change of φ1 ≥ 0 and φ2 ≥ 0 is less than
2 pixels between two adjacent iterations and we assume that the
force balance is achieved.
III. EXPERIMENT AND DISCUSSION
To evaluate the validity of our new knee bone segmentation method, we conducted two experiments based on the Osteoarthritis Initiative (OAI) databases, which are available for
public access at http://oai.epi-ucsf.org. All images were obtained using the Siemens Trio 3T MR systems and a USA instruments quadrature transmit-receive knee coil at one of four
OAI clinical sites. The MR sequences were acquired using sagittal intermediate weighted, turbo spin echo, fat-suppressed MR
sequences (field of view = 160 mm, slice thickness = 3 mm,
skip = 0 mm, flip angle = 180◦ , echo time = 30 ms, recovery
time = 3200 ms, 313 × 448 matrix [interpolated to 512 × 512,
phase encode superior/inferior. x resolution = 0.357 mm, and y
resolution = 0.511 mm). The first experiment aims to illustrate
the type of scenario where our prior model provides improved
performance relative to a number of state of the art, comparable
segmentation techniques such as [3], [4], and [30].
In the second experiment, we explore the performance of
the bone segmentation approach developed in this paper in the
context of BML identification. As shown in Fig. 5, in [10], we

developed and validated a BML segmentation scheme that was
based on a two-step process involving first the segmentation of
the bones and then the identification of BMLs using a modified
Chan–Vese [21] curve evolution technique which accounted for
the bones structures. Unlike the approach in this paper, the bone
segmentation strategy in [10] uses a combination of edge and
local region information [55] to overcome the challenges associated with the bone inhomogeneities. Since both edge and local
region information-based forces are sensitive to initial curves,
for the method in [55], the user needs to initialize two polygons
close to the femur and tibia boundaries for each MR slice, a
process requiring significant manual interaction with the data.
In Section III-B, we compare BML localization performance
when using the method in [10] to that obtained when bone segmentation is accomplished via the approach in this paper with
the second step being identical to that of [10]. We demonstrate
that despite a factor of 30 drop in the time required for human
interaction with the data, ultimate accuracy in identification of
BMLs is impacted relatively little.
A. Segmentation Results on MRI Slice with Typical BMLs
We begin by comparing the method of interest in this paper
to a number of comparable techniques for the segmentation of
the femur and tibia from the datasets described at the beginning of Section III. Of specific interest are robustness to two
issues: intensity inhomogeneities (mainly BMLs, see Fig. 1)
within the bone regions and curve initialization. Because many
BMLs are located close to the edges of bones, robustness to
intensity inhomogeneities is needed to ensure that BML regions
are not excluded from the bone areas. Moreover, robustness to
curve initialization means that our method requires less effort
to initialize which is essential to reduce user interaction thereby
facilitating the analysis of large datasets.
We build two coupled prior shape models for the lateral and
medial knee, respectively. For each model, 30 training slices are
used. The initial curves are two blue circles inside the femur
and the tibia, respectively, as displayed in Fig. 6. In Figs. 6 and
7, we provide a collection of segmentation results comparing
the method proposed in this paper to a number of alternative
techniques. To be clear, in all cases, the results are obtained using
images that are not in the associated training sets. In both Figs. 6
and 7, the ground truth knee bone segmentations are as displayed
as red lines. The ground truth knee bone segmentation was

1160

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

Fig. 6. Example segmentation results for a number of images from dataset discussed in Section III-A. The red line denotes the ground truth for the femur and
tibia, the blue line represents initial curves, and the yellow line represents the segmentation results. Rows: individual cases. Columns 1 to 6: results using Methods
I (DVFC + Cremer), II (CV + CS), III (DVFC + CNS), IV [3], V [4], and our method (DVFC + CS), respectively. Methods IV and V are 3-D atlas-based method,
and no initial curve is used.

obtained by well-trained researchers at Tufts Medical Center
using MATLAB graphic user interface tools as described in
[10]. In addition, an expert looked over all of the segmentation
results and adjusted them as necessary.
Method I (DVFC + Cremer) uses two separate prior shapes
(Cremer’s model) for femur and tibia plus the directional VFC
force. Method II (CV + CS) uses our coupled prior shape plus
the Chan–Vese’s image term. Method III (DVFC + CNS) uses
the directional VFC force and the CNS model [49]. Our proposed method (DVFC + CS) is the combination of the directional VFC force and our coupled prior shape model. In addition to these four curve evolution-based methods, we also
present results from two 3-D atlas-based methods [3], [4] which
are considered as state-of-the-art 3-D knee bone segmentation
techniques for cartilage imaging-based MR sequences. These
3-D methods [3], [4] are applied to the entire MR slice stack for
each knee but here only results for slices are displayed for direct
comparison with the 2-D methods. Fig. 6 provides representative

results for the methods described previously. From Fig. 6, we
can see that Method I (DVFC + Cremer) provided strong results
in some cases (the second and the third rows), but we observe in
the results in the first, the fourth, and the fifth rows that the tibia
contours are trapped in local minima. Method II (CV + CS) preserves the relative position between the segmented femur and
tibia as well as the bone shapes but the inhomogeneous pixels
distributions in both bones due to the BMLs prevent the curve
evolve to the desired position especially in the third and the fifth
rows. Method III (DVFC + CNS) does have some improvements over Method I (DVFC + Cremer) in the first, fourth, and
the fifth rows, but it seems that the intercomponents constraint
of the CNS model [49] is not strong enough to draw curves into
the right position. In general, Method IV (Atlas 1) [3] and V
(Atlas 2) [4] do a good job in most cases except in cases that
very large BML exists such as in the fourth and fifth rows where
some degradation can be seen. In particular, the BML volumes
for the knees in the fourth and fifth rows of Fig. 6 are 1.53 cm3

PANG et al.: ON THE USE OF COUPLED SHAPE PRIORS FOR SEGMENTATION OF MAGNETIC RESONANCE IMAGES OF THE KNEE

Fig. 7.

1161

Corresponding zoomed—in images for the areas near the joint in Fig. 6.

and 14.1 cm3 for the femur and 8.4 cm3 and 0.8 cm3 for the tibia
while the BMLs volumes for the knees in the first to the third
rows are 3.2 cm3 , 1.2 cm3 , and 2.7 cm3 for the femur, 1.9 cm3 ,
1.3 cm3 , and 2.2 cm3 for the tibia. Our method (DVFC + CPS)
outperforms the other methods in those knee images, because
the directional edge-based force could push the contours into the
right position, and the coupled prior shape force preserves both
the femur and tibia shape and as well as the relative positioning
information.
Fig. 7 displays the magnified areas near the joints of the images in Fig. 6. Here, we see that an added complication associated with the processing of the BMLs dataset is that the articular
cartilage may have a lower signal intensity than normal (e.g.,
closer to the signal intensity of bone) due to anatomical features
and/or the composition of articular cartilage. Some examples
can be found in parts of the tibial cartilage in the first and the
third rows of Fig. 7. Essentially two things could cause cartilage
to look darker—the structural composition of cartilage could
be different (e.g., a different amount of water in the tissue) or
certain areas of the knee or certain knee shapes may be predisposed to having abnormal signal intensity in the cartilage.
In such kind of challenging cases, our method does degrade
a bit, but still is no worse than other methods as shown in
Fig. 7.
For more quantitative analysis, we compare the accuracy of
our approach to Methods I (DVFC + Cremer), III (DVFC +
CNS), IV (Atlas 1) [3], and V (Atlas 2) [4] as the poor performance of Method II (CV + CS) in Figs. 6 and 7 was generally the
case for a wider range of knees thereby precluding this approach

from further consideration. As the basis for the quantitative
analysis, we consider the average symmetric surface distance
(AvgD) as defined in [56] but here adapted to the 2-D problem.
In a bit more detail, we start by extracting the boundary pixels in
our segmentation results as well as in the ground truth. For each
pixel on the boundary of the segmentation, the nearest pixel in
the reference is determined, and the Euclidean distance between
them is calculated and saved. Then, for each boundary pixel in
the ground truth, the closest pixel in the segmentation boundary
is found, and the Euclidean distance between them is computed
and stored. Finally, the average distance of all the stored values
is the AvgD. In addition, to better quantify the segmentation
error near the knee joint region, we also calculated the AvgD for
boundaries in region between the two horizonal lines as shown
in Fig. 2(a) as well as Fig. 8. The distance between these lines is
120 pixels, and the distances from the centroids of knee bones
for each image to the upper and bottom lines are 70 and 50 pixels,
respectively.
We pick 20 MRI slices with BMLs. These 20 MRI slices
are from ten patients with age 61 ± 8. Most of these patients
have BLOKS [57] BML score 2 or 3 (0 means healthy and
3 means the worst). In addition, about two MR slices were
chosen manually by identifying the slices of the largest BMLs
per patient. Then, we use randomly generated circles as initial
curves and apply our method (DVFC + CS) and Methods I
(DVFC + Cremer) and III (DVFC + CNS) to these 20 MRI
slices. The centroids of these circles are uniformly distributed
within the red squares (20 × 20 pixels) in the first column of
Fig. 8, the radii of these circles are uniformly distributed between

1162

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

Fig. 8. Example segmentation results for a number of images from dataset discussed in Section III-A. Rows: individual cases. Column 1: Randomly generated
initialing curves (circles). The centers of these circles uniformly distribute within the red squares and their radii uniformly distribute within 15 to 30. Columns 2,
3, and 6: the results based on Methods I (DVFC + Cremer), III (DVFC + CNS), and our method (DVFC + CS). Columns 4 and 5: Red line denotes the ground
truth, yellow line denotes the segmentation results based on Method IV and V. Different colors (yellow, blue, cyan, green, and magenta) represent the results based
on the corresponding initial curves in column 1, and the red line denotes the ground truth. The area near the joint where the AvgD is evaluated is denoted by red
horizontal lines.

15 and 30 pixels. Some of the segmentation results are displayed
in Fig. 8. For each initialization, we compute the AvgD values
near the joint between knee bone segmentation and the ground
truth, and then, we calculate the mean and standard deviation of
the AvgD values regard to different initializations for each slice.
Since Methods IV (Atlas 1) [3] and V (Atlas 2) [4] do not use
initial curves, the AvgD near the joint is computed only once.
Detailed information including the mean and standard deviation
for AvgD values near the joint of various methods is displayed
in Fig. 9. The curve evolution methods (Method I, Method III,
our method) work well for the femur but Methods I (DVFC +
Cremer) and III (DVFC + CNS) are very sensitive to the initial
curves in slices 1, 2, 4, 6, 12, 14, 19, and 20 (8 out of 20) for
the tibia. In Table I, both the mean and the standard deviation of
the AvgD statistic for our method are substantially smaller than

those of Methods I (DVFC + Cremer) and Method III (DVFC
+ CNS) which means that our method not only better captures
the true boundary of the tibia but also is more robust to different
initializations.
The 3-D atlas methods (Methods IV and V) work well except
Method IV [3] for slices 3, 16, 17, and 18 (4 out of 20) and
Method V [4] for slices 17 and 18 (2 out of 20) mainly due
to very large BMLs in the femur. Here, we assume slices with
AvgD values for the femur larger than 1 mm are failures. For the
tibia, Methods IV [3] and V [4] perform well except slices 18 to
20 (3 out of 20) for Method IV and slices 8 and 18 to 20 (4 out
of 20) for Method V again mainly caused by large BMLs. We
assume slices with AvgD values for the tibia larger than 2 mm
are failures, since the mean AvgD value for tibia is much larger
than that of femur.

PANG et al.: ON THE USE OF COUPLED SHAPE PRIORS FOR SEGMENTATION OF MAGNETIC RESONANCE IMAGES OF THE KNEE

1163

Fig. 9. Error bar figures of the AvgD values regarding different initializations. Left and right figures represent the AvgD values for the femur and the tibia,
respectively. The MR slices are tagged from 1 to 20 in ascending order to their knee BMLs volumes in the femur for the left figure and in the tibia for the right
figure.

TABLE I
AVGD VALUES NEAR THE JOINT OF DIFFERENT METHODS TO THE GROUND TRUTH (UNIT: MM)
Structure
Femur
Tibia

Our Method

Method I

Method III

Method IV

Method V

0.459 ± 0.187
0.845 ± 0.392

0.543 ± 0.201
1.944 ± 1.675

0.545 ± 0.167
2.000 ± 0.629

0.795± 0
1.216± 0

0.651 ± 0
1.301 ± 0

TABLE II
AVGD VALUES NEAR THE JOINT (EXCLUDING FAILURE SLICES) OF DIFFERENT METHODS TO THE GROUND TRUTH (UNIT: MM)
Structure
Femur
Tibia

Our Method

Method I

Method III

Method IV

Method V

0.459 ± 0.187
0.845 ± 0.392

0.543 ± 0.201
0.953 ± 0.432

0.545 ± 0.167
1.032 ± 0.575

0.560 ± 0
0.976 ± 0

0.474 ± 0
0.986 ± 0

The AvgD values (excluding failure slices) near the joint of
various methods are displayed in Table II. We can see that after excluding the failure slices, the AvgD values near the joint
for our method and the 3-D atlas methods are almost the same
for the femur while for the tibia, the 3-D atlas methods are
slightly larger (about 0.14 mm). Therefore, our method performs slightly better than state-of-the-art 3-D Methods IV [3]
and V [4] for cases where there are no or few BMLs. However,
we do significantly better when inhomogeneity areas such as
BMLs within the knee bones are apparent. This is exactly the
case for which our method is designed.

B. Application on the BML Segmentation
In this section, we show that our method could provide comparable accuracy to the BML-related clinical research while
requires only about 1/30th manual operation than our previous
method [10]. The method in [10] is considered state of the art
for BML segmentation because it could segment BMLs without
the reader needing to manually segment each BML. In addition,
to the best of our knowledge, the method in [10] is the first
semiautomated method to evaluate BMLs volume size quantitatively rather than some semiquantitative rating scores such as

[57]. Since the method in [10] is well validated and already used
for clinical research focusing on BMLs volume changes [58],
[59], we use the BML volumes and the knee bone segmentations
obtained by two raters using method in [10] as the ground truth
for evaluation in this experiment. The method we are going to
validate in this experiment and that of [10] have the same framework displayed in Fig. 5. Given the knee bones are identified,
the Chan–Vese method [21] is used to obtain the BMLs within
the segmented bone region. The difference is how Step 1—knee
bone segmentation as shown in Fig. 5(a) is performed.
For each knee, both the baseline and 24-month follow-up
were tested, and two raters segmented those 15 knees using the
approach in [10] in which clinical researchers have to initialize
two polygons near the knee bones for every MRI slice which
costs about 30 s for each slice. For our new approach, we only
initialize two slices for each knee dataset, one for the lateral part
and one for the medial part of each knee dataset; for these two
slices, we only need to draw two circles as displayed in Figs. 6–8
which costs about 3–5 s. Due to the robustness to initial curves
as shown in Section III-A, the segmentation result of a MRI
slice could be used as initial curves for the next slice. Instead
of directly using the segmentation result of the current slice
as the initial curves for the next slice, we applied the erosion

1164

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

morphological operation [60] to keep the initial curves inside
the femur and the tibia. Thus, in general, the manual interaction
time for each dataset could be reduced from 6 min (for 12 slices
as discussed below) to about 10 s.
Following [10], there were about 37 slices, and we omitted
the central slices from the analysis (i.e., the middle nine slices)
to focus on BMLs adjacent to the chondral surface and to improve reliability for each knee. For analyses with pain, it is likely
to underestimate the association between BMLs and pain due
to the exclusion of the central lesion. For analyses with structure, omitting these slices would unlikely influence our results.
It is reported that central BMLs were not associated with cartilage loss unless they extended into the subchondral region of
the index compartment [61], which we measured. We acknowledge that it would be ideal if we could include this region down
the road but this is particularly challenging based on the noise
on these slices as well as the challenges in identifying the border
of the bone.
We applied our algorithms to 15 knee datasets. The goal
of that study was to validate the accuracy and consistency of
our semiautomated processing approach across multiple users.
Quantitatively, there we used intraclass correlation (ICC) analysis [62] to measure this consistency. Within the context of that
analysis, 15 participants was deemed sufficient to detect a significant ICC if the coefficient was greater than 0.65 (with an
alpha level < 0.05 and power > 0.90). Hence, we choose to use
these same 15 datasets for our analysis here. As the primary
objective of this study is to demonstrate the utility of the modeling ideas in Section II especially in Section II-B, we consider a
slice-by-slice approach to the processing of these MRI images.
In addition, we also omitted the beginning and ending slices
for each knee which have no or little bone structure. Over the
entirety of the dataset, there were 363 MRI slices processed in
total with 12.1 ± 1.92 MRI slices per dataset.
Slices in a single knee data set were divided into six groups
from a lateral to medial order. As a group, these images have
similar bone geometries near the joint region. Hence, six prior
shape models were generated, respectively. Given a new knee,
each slice was assigned to one of these six groups based on the
order within the knee and processed using the corresponding
prior shape model. For each of these six groups, we used 30
training images to construct the coupled prior shape, and none
of the training slices was part of the test slices. These training
slices were generated by Rater 1.
The parameters stated in Section II-D work well for 347
out of 363 slices. For the other 16 slices, good segmentation
results could be obtained by tuning the kernel radius R from
10 to 20. As in Section III-A, we also used the AvgD and the
partial AvgD values near the joint area to evaluate our femur
and tibia segmentation results as displayed in Tables III and
IV, respectively. Comparing Tables III and IV, we can see that
significant variability arises from regions that are far from the
joint area. This is to be expected because the boundaries of the
knee bones near the joint are real anatomical structures, and they
could be consistently segmented for the training set while on the
contrast, the boundaries for the knee bones far from the joint
are “virtual” boundaries to define ROI, and they could hardly be

TABLE III
AVGD VALUES BETWEEN OUR METHOD AND MANUAL RESULTS (UNIT: MM)
Structure
Femur
Tibia

our method and Rater 1

our method and Rater 2

Rater 1 and Rater 2

0.950 ± 0.452
1.241 ± 0.363

1.128 ± 0.346
1.423 ± 0.379

0.742 ± 0.166
0.923 ± 0.155

TABLE IV
AVGD VALUES BETWEEN OUR METHOD AND MANUAL RESULTS NEAR
THE JOINT (UNIT: MM)
Structure
Femur
Tibia

our method and Rater 1

our method and Rater 2

Rater 1 and Rater 2

0.532 ± 0.293
0.795 ± 0.191

0.524 ± 0.264
0.852 ± 0.200

0.310 ± 0.095
0.489 ± 0.093

defined in a consistent way (see Fig. 2). Thus, the region near
the joint could be more accurately segmented due to both more
edge information and stronger geometric prior shape constraint.
From Table IV, we can see that the AvgD values near the joint
area for two raters are 0.310 and 0.489 mm for the femur and
tibia, respectively. The AvgD values for our method between the
two raters for the femur part are 0.532 and 0.524 mm which are
slightly bigger (less than 1 pixel) than that of the two raters. The
AvgD values for our method between the two raters for the tibia
part are 0.795 and 0.852 mm which are also less than or about 1
pixel larger than that of the two raters. In summary, the approach
considered here provides accuracy in terms of segmenting the
femur and tibia that is within about a pixel of that obtained by
two human raters but requires about 1/30th (10 s versus 6 min)
the time in terms of human interaction with the image data for
each knee as in [10].
To determine if our method generated similar BML volumes
as the manual bone segmentation, we performed the BMLs segmentation within the segmented knee bones obtained by our
method (n = 15 knees). Given the segmented bone structures,
the BMLs segmentation method is based on the Chan–Vese’s
method [21] with details provided in [10]. We tested the intermethod reliability based on ICC coefficients [2,1 model]
[62] which is commonly used in the OA research [7], [10],
[63]. For each knee dataset, we obtained four BMLs volumes
(Vi , i = 1, 2, 3, 4), which corresponded to BMLs in lateral femur (V1 ), lateral tibia (V2 ), medial femur (V3 ), and medial tibia
(V4 ) for both the baseline and 24-month follow-up. Then, we
calculated the ICCs of Vi , for baseline, follow-up, as well as
the Vi change from baseline to follow-up among two raters and
our method. Usually, the criterion for validating a BML segmentation method is that the ICC of the volume Vi for baseline
and follow-up between two raters is larger than 0.8, and the
volume changes correlation are larger than 0.7 [64]. The results
are presented in Table V2 . From Table V, we can see that our
automated method achieved this criterion except that the ICC
of the follow-up V4 between Rater 2 is slightly less than 0.8.
2 There were no significant differences in BML volumes among the three
approaches.

PANG et al.: ON THE USE OF COUPLED SHAPE PRIORS FOR SEGMENTATION OF MAGNETIC RESONANCE IMAGES OF THE KNEE

TABLE V
INTERTESTER RELIABILITY FOR BML VOLUME CHANGE GIVEN THE KNEE
BONE SEGMENTED BY OUR METHOD
Rater 1 and our method

Rater 2 and our method

Rater 1 and 2

V1

Baseline
Follow-up
Change

0.99
0.92
0.99

0.92
0.90
0.93

0.93
0.89
0.93

V2

Baseline
Follow-up
Change

0.99
0.99
0.91

0.91
0.96
0.95

0.95
0.99
0.98

V3

Baseline
Follow-up
Change

0.99
0.99
0.98

0.97
0.95
0.93

0.97
0.95
0.90

V4

Baseline
Follow-up
Change

0.96
0.88
0.95

0.85
0.79
0.87

0.86
0.87
0.86

Thus, our approach is consistent with manual segmentation for
the application on BML segmentation.
As some have suggested, BML volume could be an outcome measure in clinical trials [63], [65], [66]. Methods like
ours which could measure BMLs efficiently and reproducibly
would help to obtain BML volume in a big dataset and thus
facilitate the investigation of the outcome measure for OA
patient.
IV. CONCLUSION AND FUTURE WORK
In this paper, we presented a new coupled prior shape model
which implicitly incorporates prior shape and also the relative
position information for multiple objects. In addition, our new
shape model also implicitly puts on more constraint in areas
with less shape difference compared to the conventional shape
models which constrain informally on the whole shape. Moreover, an edge-based force incorporating directional information
was also introduced in this paper. Segmentation results on the
real MRI knee images demonstrate the feasibility of our new
coupled prior shape modal and also the directional edge-based
force. Based on the combination of our coupled prior shape
model and the directional edge-based force, we could reduce
the processing time for BML segmentation without sacrifice of
accuracy.
The current methods exclude the patella to focus on the
tibiofemoral joint. It would be ideal to eventually include the
patella, and this is a future goal for our projects but at this time,
we focused on the tibia and femur. This is also advantageous for
us since our group often focuses on measures of tibiofemoral OA
progression using measures of tibiofemoral joint space width or
joint space narrowing and periarticular bone measures in the
tibia. The patella indeed has BMLs but can represent unique
segmentation challenges because of the size, shape, and occasionally the lack of adequate fat suppression. An accurate
analysis of patella BML might also require an axial scan. After confirming that the method is functional in the two main
bones, our goal will be to explore segmenting the patella as
well as extend our method from the current 2-D form to its 3-D
version.

1165

APPENDIX
PROOF OF EQUATION (10)
∂ Di
i
Due to similar formulation of ∂∂ D
φ 1 and ∂ φ 2 as in (10), we
i
only deduce ∂∂ D
φ 1 here.
From (9), we have

xH(φ1 + 1 φ̃1 )dx
uφ 1 + 1 φ̃ 1 = 
.
H(φ1 + 1 φ̃1 )dx

Here, φ̃1 is a small perturbation of φ1 , and 1 is a scalar.
By using Taylor expansion, we have
H(φ1 + φ̃1 ) ≈ H(φ1 ) + 1 φ˜1 δ(φ1 ).

(17)

Thus,



x[H(φ1 ) + 1 φ̃1 δ(φ1 )]dx · H(φ1 )dx
uφ 1 + 1 φ̃ 1 ≈ 

H(φ1 )dx · H(φ1 ) + 1 φ̃1 δ(φ1 )dx
⎞

⎛

1 xφ̃1 δ(φ1 )dx ⎝
1
⎠

= uφ 1 + 

φ̃ δ (φ 1 )dx
H(φ1 )dx
1 + 1  H 1(φ 1 )dx





1 xφ̃1 δ(φ1 )dx
1 φ̃1 δ(φ1 )dx
≈ uφ 1 + 
1− 
H(φ1 )dx
H(φ1 )dx

1 (x − uφ 1 )φ̃1 δ(φ1 )dx

+ O(21 )
= uφ 1 +
H(φ1 )dx

1 (x − uφ 1 )φ̃1 δ(φ1 )dx

≈ uφ 1 +
.
H(φ1 )dx

Thus, we have
uφ+ 1 φ̃ 1 = suφ 1 + 1 φ̃ 1 + (1 − s)uφ 2



1 (x − uφ 1 )φ̃1 δ(φ1 )dx

= s uφ 1 +
+ (1 − s)uφ 2
H(φ1 )dx

1 (x − uφ 1 )φ̃1 δ(φ1 )dx

.
(18)
= uφ + s
H(φ1 )dx
Let define the coupling prior shape energy as

Di (φ1 , φ2 ) =
[H(φ1 (x + uφ )) + H(φ2 (x + uφ ))
Ω

2
−H(ψ1i ) − H(ψ2i ) dx
then, we want to obtain

d
D(φ1 + φ̃1 , φ2 )|=0 .
d
For simplicity, we use Di (φ1 + φ̃1 ) to denote Di (φ1 +
φ̃1 , φ2 ). Then

d
Di (φ1 + φ̃1 )|=0
d

= 2[H(φ1 + φ̃1 )(x + uφ+ φ̃ 1 ) + H(φ2 (x + uφ+ φ̃ 1 ))

1166

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015


−

H(ψ1i )

+d

−

H(ψ2i )]

· d

H(φ2 (x + uφ+ φ̃ 1 ))
d

H(φ1 + φ̃1 )(x + uφ+ φ̃ 1 )
d

[5]


|=0 .

(19)

Substituting (17), (18), into (19), we obtain

d
D(φ1 + φ̃1 )|=0
d

= 2 [H(φ1 (x + uφ )) + H(φ2 (x + uφ ))

[6]

[7]

[8]


−H(ψ1i (x)) − H(ψ2i (x))
[9]

× [sδ(φ1 (x + uφ ))∇(φ1 (x + uφ ))
 
(x − uφ 1 )T φ̃1 (x )δ(φ1 (x ))dx

+ φ̃1 (x
×
H(φ1 (x ))dx

[10]

+ uφ )δ(φ1 (x + uφ ))] dx

= 2 [H(φ1 (x)) + H(φ2 (x))

−H(ψ1i (x − uφ )) − H(ψ2i (x − uφ ))

[11]

× [sδ(φ1 (x))∇(φ1 (x))
 
(x − uφ 1 )T φ̃1 (x )δ(φ1 (x ))dx

×
H(φ1 (x ))dx

+ φ̃1 (x)δ(φ1 (x)) dx

= 2 [H(φ1 (x)) + H(φ2 (x))

[12]
[13]

[14]

− H(ψ1i (x − uφ )) − H(ψ2i (x − uφ ))]
× φ̃1 (x)δ(φ1 (x))dx

+ 2 [H(φ1 (x )) + H(φ2 (x ))

[15]

[16]

− H(ψ1i (x − uφ )) − H(ψ2i (x − uφ ))]

T
[17]


 (x − uφ 1 ) φ̃1 (x)δ(φ1 (x))dx
.
× sδ(φ1 (x ))∇(φ1 (x ))dx
H(φ1 (x))dx
[18]
Therefore,

∂ Di
∂ φ1

in (10) holds. Similarly, we can also obtain

∂ Di
∂ φ2

.

REFERENCES
[1] J. Fripp, S. Crozier, S. K. Warfield, and S. Ourselin, “Automatic segmentation of the bone and extraction of the bone-cartilage interface
from magnetic resonace images of the knee,” Phys. Med. Biol., vol. 52,
pp. 1617–1631, 2007.
[2] J. Folkesson, E. B. Dam, P. C. Pettersen, and C. Christiansen, “Segmentation articular cartilage automatically using a voxel classification
approach,” IEEE Trans. Med. Imag., vol. 26, no. 1, pp. 106–115,
Jan. 2007.
[3] J. Fripp, S. Crozier, S. K. Warfield, and S. Ourselin, “Automatic segmentation of the bone and quantitative analysis of the articular cartilages
from magnetic resonance images of the knee,” IEEE Trans. Med. Imag.,
vol. 29, no. 1, pp. 55–64, Jan. 2010.
[4] J. G. Tamez-Pena, J. Farber, P. C. Gonzales, E. Schreyer, E. Shneider, and
S. Totterman, “Unsupervised segmentation and quantification of anatom-

[19]
[20]

[21]
[22]
[23]
[24]

ical knee features: Data from the osteoarthritis inititiative,” IEEE Trans.
Biomed. Eng., vol. 59, no. 4, pp. 1177–1186 , Apr. 2012.
K. Li, S. Millington, X. Wu, D. Z. Chen, and M. Sonka, “Simultaneous
segmentation of multiple closed surfaces using optimal graph searching,”
in Proc. Int. Conf. Inform. Process. Med. Imag., 2005, pp. 406–417.
Y. Yin, X. Zhang, R. Williams, X. Wu, D. D. Anderson, and M. Sonka,
“Logismos—Layered optimal graph image segmentation of multiple objects and surfaces: Cartilage segmentation in the knee joint,” IEEE Trans.
Med. Imag., vol. 29, no. 12, pp. 2023–2037, Dec. 2010.
J. Driban, G. Lo, J. Y. Lee, R. Ward, E. Miller, J. Pang, L. Prince, and
T. McAlindon, “Quantitative bone marrow lesion size in osteoarthritic
knees correlates with cartilage damage and predicts lognitudinal cartilage
loss,” BMC Musculoskeletal Disorders, vol. 12, p. 217, 2011.
G. H. Lo, D. J. Hunter, Y. Zhang, C. E. McLennan, M. P. LaValley,
D. P. Kiel, R. R. McLean, H. K. Genant, A. Guermazi, and D. T.
Felson, “Bone marrow lesions in the knee are associated with increased local bone density,” Arthritis Rheumatism, vol. 52, no. 9,
pp. 2814–2821, 2005.
G. H. Lo, T. E. McAlindon, J. Niu, Y. Zhang, C. Beals,
C. Dabrowski, M. P. H. L. Graverand, and D. J. Hunter, “Bone marrow lesions and joint effusion are strongly and independently associated with weight-bearing pain in kneeosteoarthritis: Data from
the osteoarthritisinitiative,” Osteoarthritis Cartilage, vol. 17, no. 12,
pp. 1562–1569, 2009.
J. Pang, J. B. Driban, G. Destenaves, E. Miller, G. H. Lo, R. J. Ward,
L. L. Price, J. A. Lynch, C. B. Eaton, and T. E. McAlindon, “Quantification
of bone marrow lesion volume and volume change using semi-automated
segmentation: Data from the osteoarthritis initiative,” BMC Musculoskeletal Disorders, vol. 14, p. 3, 2013.
L. M. Wildi, J.-P. Raynauld, J. Martel-Pelletier, F. Abram, M. Dorais, and
J. Pelletier, “Relationship between bone marrow lesions, cartilage loss and
pain in knee osteoarthritis: results from a randomised controlled clinical
trial using MRI,” Ann. Rheum. Dis., vol. 69, pp. 2118–2124, 2009.
F. W. Roemer and A. Guermazi, “Osteoarthritis year 2012 in review:
Imaging,” Osteoarthritis Cartilage, vol. 20, pp. 1440–1446, 2012.
R. Frobell, H. Roos, E. Roos, M.-P. H. L. Graverand, R. Buck, J. TamezPena, S. Totterman, T. Boegard, and L. Lohmander, “The acutely ACL
injured knee assessed by MRI: Are large volume traumatic bone marrow
lesions a sign of severe compression injury?” Osteoarthritis Cartilage,
vol. 16, no. 7, pp. 829–836, 2008.
X. Li, B. C. Ma, R. I. Bolbos, R. Stahl, J. Lozano, J. Zuo, K. Lin,
T. M. Link, M. Safran, and S. Majumdar, “Quantitative assessment of
bone marrow edema-like lesion and overlying cartilage in knees with
osteoarthritis and anterior cruciate ligament tear using MR imaging
and spectroscopic imaging at 3 tesla,” J. Magn. Reson. Imag., vol. 28,
pp. 453–461, 2008.
M. E. Mayerhoefer, M. Breitenseher, S. Hofmann, N. Aigner, R. Meizer,
H. Siedentop, and J. Kramer, “Computer-assisted quantitative analysis of
bone marrow edema of the knee: Initial experience with a new method,”
Amer. J. Roentgenol., vol. 182, pp. 1399–1403, 2004.
C. G. Peterfy, G. Gold, F. Eckstein, F. Cicuttini, B. Dardzinski, and
R. Stevens, “MRI protocols for whole-organ assessment of the knee in
osteoarthritis,” Osteoarthritis Cartilage, vol. 14, pp. A95–A111, 2006.
S. J. Osher and R. P. Fedkiw, Level Set Methods and Dynamic Implicit
Surfaces. New York, NY, USA: Springer-Verlag, 2002.
J. A. Sethian, Level Set Methods and Fast Marching Methods: Evolving
Interfaces in Computational Geometry, Fluid Mechanics, Computer Vision, and Materials Science. Cambridge, U.K.: Cambridge Univ. Press,
1999.
A. Yezzi, A. Tsai, and A. Willsky, “A statistical approach to snakes for
bimodal and trimodal imagery,” in Proc. IEEE Int. Conf. Comput. Vision,
1999, vol. 2, pp. 884–900.
Z. Ma, J. M. Tavares, R. N. Jorge, and T. Mascarenhas, “A review of
algorithms for medical image segmentation and their applications to the
female pelvic cavity,” Comput. Methods Biomechanics Biomed. Eng.,
vol. 13, no. 2, pp. 235–246, 2010.
T. F. Chan, and L. A. Vese, “Active contours without edges,” IEEE Trans.
Image Process., vol. 10, no. 2, pp. 266–277, Feb. 2001.
E. Parzen, “On estimation of a probability density function and modes,”
Ann. Math. Statist., vol. 33, no. 3, pp. 1065–1076, 1962.
D. Freedman and T. Zhao, “Active contours for tracking distribution,”
IEEE Trans. Image Process., vol. 13, no. 4, pp. 518–526, Apr. 2004.
O. Michailovich, Y. Rathi, and A. Tannenbaum, “Image segmentation
using active contours driven by the Bhattacharyya gradient flow,” IEEE
Trans. Image Process., vol. 16, no. 11, pp. 2787–2801, Nov. 2007.

PANG et al.: ON THE USE OF COUPLED SHAPE PRIORS FOR SEGMENTATION OF MAGNETIC RESONANCE IMAGES OF THE KNEE

[25] M. Kass, A. Witkin, and D. Terzopoulos, “Snakes: Active contour models,”
Int. J. Comput. Vision, vol. 1, pp. 321–331, 1988.
[26] C. Xu and J. L. Prince, “Snakes, shapes and gradient vector flow,” IEEE
Trans. Image Process., vol. 7, no. 3, pp. 359–369, Mar. 1998.
[27] B. Li and S. Acton, “Active contour external force using vector field
convolution for image segmentation,” IEEE Trans. Image Process.,
vol. 16, no. 8, pp. 2096–2106, Aug. 2007.
[28] T. Chan and W. Zhu, “Level set based shape prior segmentation,” in Proc.
IEEE Conf. Comput. Vision Pattern Recog., 2005, pp. 1164–1170.
[29] Y. Chen, H. Tagare, S. Thiruvenkadam, F. Huang, D. Wilson, K. Gopinath,
and R. Briggs, “Using prior shapes in geometric active contours in a
variational framework,” Int. J. Comput. Vision, vol. 50, no. 3, pp. 315–
328, 2002.
[30] D. Cremers, S. J. Osher, and S. Soatto, “Kernel density estimation and intrinsic aligment for shape priors in level set segmentation,” Int. J. Comput.
Vision, vol. 69, no. 3, pp. 335–351, 2006.
[31] D. Cremers, F. R. Schmidt, and F. Barthel, “Shape priors in variational
image segmentation: Convexity, lipschitz continuity and globally optimal
solutions,” in Proc. IEEE Conf. Comput. Vision Pattern Recog., 2008,
pp. 1–6.
[32] J. Kim, M. Cetin, and A. S. Willsky, “Nonparametric shape priors
for active contour-based image segmentation,” Signal Process., vol. 87,
pp. 3021–3044, 2007.
[33] M. Leveton, E. Grimson, and O. Faugeras, “Statistical shape influence
in geodesic active contour,” in Proc. IEEE Conf. Comput. Vision Pattern
Recog., 2000, vol. 1, pp. 316–323.
[34] M. Rousson and N. Paragios, “Prior knowledge, level set representations
and visual grouping,” Int. J. Comput. Vision, vol. 76, pp. 231–243, 2008.
[35] A. Tsai, A. Yezzi, W. Wells, C. Tempany, D. Tucker, A. Fan,
W. E. Grimson, and A. Willsky, “A shape-based approach to the segmentation of medical imagery using level sets,” IEEE Trans. Med. Imag.,
vol. 22, no. 2, pp. 137–154, Feb. 2003.
[36] S. Dambreville, Y. Rathi, and A. Tannenbaum, “A framework for image segmentation using shape models and kernel space shape priors,”
IEEE Trans. Pattern Anal. Mach. Intell., vol. 30, no. 8, pp. 1385–1399,
Aug. 2008.
[37] S. Chen and R. J. Radke, “Level set segmentation with both shape
and intensity priors,” in Proc. IEEE Int. Conf. Comput. Vision, 2009,
pp. 763–770.
[38] A. Tsai, W. M. Wells, C. Tempany, E. Grimson, and A. S. Willsky, “Mutual
information in coupled multi-shape model for medical image segmentation,” Med. Image Anal., vol. 8, no. 4, pp. 429–445, 2004.
[39] X. Han, C. Xu, and J. Prince, “A topology preserving level set method for
geometric deformable models,” IEEE Trans. Pattern Anal. Mach. Intell.,
vol. 25, pp. 755–768, 2003.
[40] G. Sundaramoorthi and A. Yezzi, “More-than-topology-preserving flows
for active contours and polygons,” in Proc. IEEE Int. Conf. Comput.
Vision, 2005, vol. 2, pp. 1276–1283.
[41] K. Zimmer and J. Oliver-Marin, “Compled parametric active contours,”
IEEE Trans. Pattern Anal. Mach. Intell., vol. 27, no. 11, pp. 1838–1842,
Apr. 2005.
[42] N. Paragios and R. Deriche, “Coupled geodesic active regions for image
segmentation: A level set approach,” in Proc. Eur. Conf. Comput. Vision,
2000, pp. 224–240.
[43] A. Vazquez-Reina, E. Miller, and H. Pfister, “Multiphase geometric couplings for the segmentation of neural processes,” in Proc. IEEE Conf.
Comput. Vision Pattern Recog., 2009, pp. 2020–2027.
[44] Z. Ma, R. N. Jorge, and J. M. Tavares, “A shape guided C-V model to
segment the levator ani muscle in axial magnetic resonance images,” Med.
Eng. Phys., vol. 32, pp. 766–774, 2010.
[45] T. Brox and J. Weickert, “Level set segmentation with multiple regions,”
IEEE Trans. Image Process., vol. 15, no. 10, pp. 3213–3218, Oct. 2006.
[46] Z. Ma, R. N. M. Jorge, T. Mascarenhas, and J. M. Tavares, “Segmentation
of female pelvic cavity in axial t2-weighted MR images towards the 3D
reconstruction,” Int. J. Numer. Methods Biomed. Eng., vol. 28, nos. (6/7),
pp. 714–726, 2012.
[47] Z. Ma, R. N. M. Jorge, T. Mascarenhas, and J. Tavares, “Segmentation of
female pelvic organs in axial magnetic resonance images using coupled
geometric deformable models,” Comput. Biol. Med., vol. 43, pp. 248–258,
2013.
[48] Z. Ma, R. Jorge, T. Mascarenhas, and J. M. Tavares, “A level set based
algorithm to reconstruct the urinary bladder from multiple views,” Med.
Eng. Phys., vol. 35, pp. 1819–1824, 2013.
[49] M. G. Uzunbas, O. Soldea, D. Unay, M. Cetin, G. Unal, A. Ercil, and
A. Ekin, “Coupled nonparametric shape and moment-based intershape

[50]
[51]

[52]
[53]

[54]
[55]

[56]

[57]

[58]

[59]

[60]
[61]

[62]
[63]

[64]
[65]

[66]

1167

pose priors for multiple basal and ganglia structure segmentation,” IEEE
Trans. Med. Imag., vol. 29, no. 12, pp. 1959–1978, Dec. 2010.
J. Cheng, and S. Foo, “Dynamic directional gradient vector flow for
snakes,” IEEE Trans. Image Process., vol. 15, no. 6, pp. 1563–1571,
Jun. 2006.
J. Tang, S. Millington, S. T. Acton, J. Crandall, and S. Hurwitz, “Surface extraction and thickness measurement of the articular cartilage from
MR images using directional gradient vector flow snakes,” IEEE Trans.
Biomed. Eng., vol. 53, no. 5, pp. 896–907, May 2006.
C. Xu, A. Yezzi, and J. L. Prince, “On the relationship between parametric and geometric active contour,” in Proc. Asilomar Conf. Signal Syst.
Comput., 2000, pp. 483–489.
D. Freedman, R. J. Radke, T. Zhang, Y. Jeong, D. M. Lovelock, and
G. T. Y. Chen, “Model-based segmentation of medical imagery by matching distributions,” IEEE Trans. Med. Imag., vol. 24, no. 3, pp. 281–292,
Mar. 2005.
K. Ni, X. Bresson, T. Chan, and S. Esedoglu, “Local histogram based
segmentation using the wasserstain distance,” Int. J. Comput. Vision,
vol. 84, pp. 97–111, 2009.
J. Pang, E. Miller, J. Driban, A. Tassinari, and T. McAlindon, “A curve
evolution method for identifying weak edges with applications to the
segmentation of magnetic resonance images of the knee,” in Proc. IEEE
Int. Symp. Biomed. Imag., 2011, pp. 1410–1415.
T. Heimann, B. Morrison, M. Styner, M. Niethammer, and S. Warfield,
“Segmentation of knee images: A grand challenge,” in Proc. Med. Image
Comput. Comput.-Assisted Intervention Conf. Workshop Med. Image Anal.
Clinic, 2010, pp. 207–214.
D. J. Hunter, G. H. Lo, D. Gale, A. J. Grainger, A. Guermazi, and
P. G. Conaghan, “The reliability of a new scoring system for knee osteoarthritis MRI and the validity of bone marrow lesion assessment:
Bloks (boston leeds osteoarthritis knee score),” Ann. Rheum. Dis, vol. 67,
pp. 206–211, 2008.
J. B. Driban, L. L. Price, G. H. Lo, J. Pang, D. J. Hunter, E. Miller,
R. J. Ward, C. B. Eaton, J. Lynch, and T. E. McAlindon, “Evaluation of bone marrow lesion volume as a knee osteoarthritis biomarkerlongitudinal relationships with pain and structural changes: Data from the
osteoarthritis initiative,” Arthritis Res. Therapy, vol. 15, no. 5, p. R112,
2013.
J. Driban, G. H. Lo, L. L. Price, J. Pang, E. Miller, R. J. Ward, D. J. Hunter,
C. B. Eaton, J. A. Lynch, and T. E. McAlindon, “Bone marrow lesion
volume reduction is not associated with improvement of other periarticular
bone measures: Data from the osteoarthritis initiative,” Arthritis Res. Ther.,
vol. 15, no. 5, p. R153, 2013.
R. C. Gonzalez, R. E. Woods, and S. L. Eddins, Digital Image Processing
Using Matlab. Knoxville, Tennessee: Gatesmark Publishing, 2009.
G. Hernandez-Molina, A. Guermazi, J. Niu, D. Gale, J. Goggins, S. Amin,
and D. T. Felson, “Central bone marrow lesions in symptomatic knee
osteoarthritis and their relationship to anterior cruciate ligament tears and
cartilage loss,” Arthritis Rheumatism, vol. 58, pp. 130–136, 2008.
P. E. Shrout and J. L. Fleiss, “Intraclass correlations: Uses in assessing
rater reliability,” Ann. Math. Statist., vol. 86, no. 2, pp. 420–428, 1979.
D. T. Felson, M. J. Parkes, E. J. Marjanovic, M. Callaghan, A. Gait,
T. Cootes, M. Lunt, J. Oldham, and C. E. Hutchinson, “Bone marrow
lesions in knee osteoarthritis change in 6-12 weeks,” Osteoarthritis Cartilage, vol. 20, no. 12, pp. 1514–1518, 2012.
D. V. Cicchetti, “Guidelines, criteria, and rules of thumb for evaluating
normed and standardized assessment instruments in psychology,” Psychol.
Assess., vol. 6, no. 4, pp. 284–290, 1994.
L. Carbone, M. C. Nevitt, K. Wildy, K. D. Barrow, F. Harris, D. Felson,
C. Peterfy, M. Visser, T. B. Harris, B. W. Wang, and S. B. Kritchevsky,
“The relationship of antiresorptive drug use to structural findings and
symptoms of knee osteoarthritis,” Arthritis Rheum., vol. 50, no. 11, pp.
3516–3525, 2004.
L. L. Laslett, D. A. Dore, S. J. Quinn, P. Boon, E. Ryan, T. M. Winzenberg,
and G. Jones, “Zoledronic acid reduces knee pain and bone marrow lesions
over 1 year: A randomised controlled trial,” Ann. Rheum. Dis., vol. 71,
no. 8, pp. 1322–1328, 2012.

Authors’ photographs and biographies not available at the time of publication.

