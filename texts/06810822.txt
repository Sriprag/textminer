IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

1533

Service-Oriented Medical System for Supporting
Decisions With Missing and Imbalanced Data
Maciej Zieba
˛

Abstract—In this paper, we propose a service-oriented support
decision system (SOSDS) for diagnostic problems that is insensitive
to the problems of the imbalanced data and missing values of the
attributes, which are widely observed in the medical domain. The
system is composed of distributed Web services, which implement
machine-learning solutions dedicated to constructing the decision
models directly from the datasets impaired by the high percentage
of missing values of the attributes and imbalanced class distribution. The issue of the imbalanced data is solved by the application of
a cost-sensitive support vector machine and the problem of missing
values of attributes is handled by proposing the novel ensemblebased approach that splits the incomplete data space into complete
subspaces that are further used to construct base learners. We evaluate the quality of the SOSDS components using three ontological
datasets.
Index Terms—Classification algorithms, computer aided diagnosis, hybrid intelligent systems, imbalanced data, missing data,
support vector machines.

I. INTRODUCTION
HE growing amount of data available in the present
medical systems gives the opportunity to construct decision models that can be used to support medical experts in
various domains. Two issues are extremely important to be
considered in the process of constructing diagnostic models:
the problem of training interpretable models (classifiers) directly from raw data spoiled by missing values and class imbalance phenomenon, and the need of incorporating them in
the modern medical systems with a minimal interference to the
structure.
The first of the mentioned aspects is combined with the situation in which the raw data delivered to the system are not
perfect. In practice, it means that applying typical approaches
to learn decision models from it leads to constructing a weak
predictor. The poor quality of the data can be caused by imprecise, incomplete, or noisy values of some attributes, imbalanced
class distribution, or sequential nature of a delivering process.
Consequently, some mechanisms for dealing with the stated
problems should be involved in the training procedure to construct reasonable decision models. Additionally, in the field of
medical diagnosis, it is particularly important to construct the
predictors, such as, decision rules, decision trees, or scoring

T

Manuscript received November 19, 2013; revised March 5, 2014; accepted
April 28, 2014. Date of publication May 6, 2014; date of current version September 2, 2014. This work was supported by the European Union as part of the
European Social Fund.
The author is with the Department of Computer Science and Management
Institute of Informatics, Wroclaw University of Technology, 50-370 Wroclaw,
Poland (e-mail: maciej.zieba@pwr.wroc.pl).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2322281

tables that can be easily interpreted and modified by domain
experts.
The second of the stated points refers to the situation in which
a newly constructed decision model should be implemented and
delivered to the existing medical system in such a form that the
cost of modernizing the entire application would be as low as
possible. Therefore, the entire solution should be independent on
the programming language, flexible, encapsulated, and available
in the distributed environment via unified interfaces.
To solve both of the stated issues, we propose a serviceoriented support decision system (SOSDS) that is insensitive to
the problem of missing values and class imbalance phenomenon.
The entire system is designed according to the service oriented
architecture (SOA) paradigm, in which all functionalities related
to the problem of constructing and using a decision model are
represented by Web services. Using such an approach makes the
machine-learning solutions easily accessible for all applications
represented by Web service clients which have the ability to
communicate with services by simple object access protocol
(SOAP).
The problem of making decisions using bad quality data is
solved in SOSDS by formulating it as a problem of binary
classification and applying ensemble support vector machines
(SVMs) with a novel training method. The proposed method of
constructing the committee of balanced SVMs solves two major
problems with data: missing values of attributes and imbalanced
data. Each of the classifiers in the ensemble is constructed using
a different and complete training subset with the reduced vector
of features. The set of base learners is constructed in such a
way that each of the examples with missing values is used to
construct at least one classifier. Each of them is represented by
an SVM that is trained using different misclassification costs to
deal with the problem of imbalanced data. The problem of model
intelligibility is solved by applying a relabeling technique which
switches the class labels in the training set into output values
predicted by the committee of SVMs, and by applying one of
typical rules inducers on modified data. In such an approach,
the ensemble classifier is treated as an “oracle” that corrects the
training data to make it more balanced for rule-based learner.
This paper is organized as follows. In Section II, we present
related works to the three different aspects of this paper: distributed support medical decision systems and machine learning methods which solve the problems of missing values
and imbalanced data. In Section III, we present the architecture of the proposed SOSDS. Section IV describes machinelearning methods which constitute the components of SOSDS.
Section V presents the experimental studies made on three ontological datasets. This paper is summarized in Section VI.

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

1534

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

II. RELATED WORKS
A. Distributed Support Medical Decision Systems
The benefits of using SOA paradigm to design modern medical support decision systems aim at simpler software design
and implementation, improved software reusability, improved
adaptability to changing business requirements, and cost savings [1], [2].
Therefore, various systems’ architectures for clinical decision
support systems working in distributed environment were presented in the literature [3]–[6]. One of the proposed approaches
is Standards-Based Active Guideline Environment (SAGE) described in [4], which presents the methodology and the infrastructure that are required to communicate decision support solutions with commercial clinical information systems. SAGE
integrates the systems with service-based interfaces, uses Health
Level Seven’s Version 3 Reference Information Model as an information model standard, links knowledge to appropriate clinical contexts by an event-driven system, and makes use of Protege
as a knowledge-based modeling environment. SOA for NHIN
Decision Support (SANDS) [3] is another architecture that leverages the existing work toward developing a National Health Information Network (NHIN). The central idea of SANDS, contrary to other approaches, is to construct the layers of abstraction
in front of both the clinical decision support services and the
clinical information system, which represents the Web service
client.
B. Dealing With Missing Values
Various techniques are applied to solve the missing values
problem [7]: deletion of missing values, imputation, or estimation of missing values, using model-based procedures, and
adjusting machine learning approaches.
In first two groups of the methods, the problem of missing
values is handled externally, either by eliminating examples (or
attributes) containing missing values, or by completing missing
cases with the most probable value, or by the application of some
other imputation techniques [8]. In contrast, solutions from the
third group model the probability density function of the input
data (complete and incomplete cases), which is further used to
classify new instances based on the Bayes decision theory. In
the last group, the classifier is designed for handling incomplete
input data by modifying typical training procedures. In this
group, we can distinguish techniques that are used to construct
ensemble classifiers directly from incomplete data [9].
C. Dealing With Imbalanced Data Problem
The problem of imbalanced data was extensively studied in
the literature and three groups of methods can be distinguished
in this field [10]: external approaches, internal approaches, costsensitive methods.
The first group of methods operates directly on the preprocessing stage by modifying the training data. Two techniques
can be distinguished in this category: oversampling and undersampling approaches. The most popular and commonly used
technique in this category is Synthetic Minority Over-sampling

Fig. 1.

Proposal of an architecture for an SOSDS.

Technique (SMOTE) [11], which generates artificial examples
situated on the path connecting two neighbors from minority
class. The second group of methods deals with the problem of
uneven data directly on the training stage. In this group, it is
possible to distinguish ensemble models like SMOTEBoost [12]
and UnderBagging [13] that solve the issue of imbalanced data
by applying under- and oversampling methods to construct diverse and balanced base classifiers. The last group of methods
assigns a weight to each element of the training set to make minority examples more significant. These kinds of methods are
successively used in constructing cost-sensitive neural networks
[14] and SVMs [15].
III. SOSDS DESCRIPTION
In this paper, we present the distributed system composed
of Web services that represents the functionalities supporting
decision making in the field of medicine. Each Web service
provides a machine-learning method that solves one of the unprocessed data issues. The components of the proposed system
can be invoked directly by medical application that has incorporated mechanisms for communication with the SOAP protocol,
as well as can be used as a part of another supporting decisions
system like SANDS. Two fundamental processes particular for
medical diagnosis are presented to demonstrate how the system
works.
A. Architecture of the System
The architecture of the proposed system is presented in Fig. 1.
Each functionality is represented by a Web service described in
Web Service Definition Language and published via Enterprise
Service Bus. The communication in the system is achieved by
unified SOAP messages. Split data service splits the incomplete
data to subsets containing only complete cases by attributes and
instances reduction. Build classifier service constructs the base
learner from the given data Classify service assigns class labels using the ensemble of constructed base learners. Generate
rules service constructs decision rules from data using the set
of base learners Communicate with database (DB) represent the

ZIEBA:
˛
SERVICE-ORIENTED MEDICAL SYSTEM FOR SUPPORTING DECISIONS WITH MISSING AND IMBALANCED DATA

Fig. 2.

1535

Process of constructing a decision model.

mediation service that has implemented operations of managing
the DB. Communicate with knowledge base (KB) represent the
mediation service that has implemented operations for managing the KB of the constructed models.
All the functionalities that constitute the presented components are briefly described in Section IV. The components are
used in two key processes for supporting diagnostics: in the
process of constructing a decision model (training the classifier) using historical data about the patients and in the process
of decision making using the constructed classifier.
B. Constructing a Decision Model
The process of constructing a decision model is essential in
the system to make further diagnosis with unlabeled data. As
final products of the process, we expect to obtain two items:
the set of base classifiers trained on diversified data, which will
be further used to support making decision as a committee of
experts and the set of decision rules that will help the medical
expert to understand the mechanisms that represent the decision
process made by the ensemble of the constructed models.
The process of building the decision model is presented in
Fig. 2. It can be initialized by the default Web service client
(e.g., external medical application) by sending the request to
construct the classifier. In the first operation, the incomplete
data are divided into complete subsets, which are transferred
to the functions responsible for constructing the base models.
As a result of performing the operation, the complex classifier
composed of independently trained base learners is created.
Finally, the rules are induced from the entire training set by using
the constructed complex classifier as an oracle for relabeling the
data. The generated rules are returned to the Web service client
as a final result of the process.
The entire process is automatically executed by composite
service in which it is possible to distinguish component compos-

ite services CS1 , CS2,1 , . . . , CS2,K , CS3 responsible for performing each of the described operations. Each of the services is
composed of the atomic services included in the SOSDS architecture. First, the SOAP message with data query is sent to the
get data operation which is the component of the DB mediation
service. The data required to construct a decision model are gathered from DB and is sent to the split data Web service. The data
are divided according to the method described in Section IV-A
and redistributed to composite services CS2,1 , . . . , CS2,K in
such a way that each of them receives a different subset of
instances.
Each of the services CS2,1 , . . . , CS2,K has the same structure
but receives a different input data and is distinguished mainly
due to the possible parallel execution. In the first step, the base
learner is trained with the method described in Section IV-B. The
constructed model is further delivered in the serialized form to
the operation of writing the classifier, which is the component
of mediation service that stores it in the KB. All of the models
constructed by CS2,1 , . . . , CS2,K are delivered to the composite
service CS3 .
The composite service CS3 takes on the input the constructed
base learners as well as the initial training data delivered by CS1 .
In the first step, rules are induced using the committee of the
constructed classifiers as an oracle by invoking Web service labeled as generate rules. The procedure of constructing decision
rules is described in detail in Section IV-D. The rules are stored
in the KB by invoking the operation write rules and finally delivered to the Web service client on the output of the external
composite service.
C. Decision Making
The process of constructing a decision model is executed
rarely contrary to the process of decision making, which is run
each time when the need of diagnosis support is observed. The

1536

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

final product of the process is the diagnosis of the patient (class
label in terms of classification) whose symptoms were given on
the input. The process is performed automatically by executing
the atomic service classify, which takes the data describing the
patient and returns the decision made by the proper committee
of base learners selected to solve the decision problem. The
method of classification representing the functionality of the
Web service is described in Section IV-C.
D. Advantages of SOSDS
SOSDS can be seen as a set of distributed Web services that
are combined with service bus and are involved in the automatic
execution of two key processes for diagnostic problems: the
process of constructing a decision model based on the historical data and the process of making diagnosis of new patients.
It is possible to represent the entire process of constructing a
decision model as a one, indivisible atomic service but such
approach has few limitations. First, the procedure of constructing base classifiers would not be made in parallel. Second, the
process of constructing the base learner may be performed by
various machine-learning methods. The total cost of integrating
a new method for training the classifier by publishing a new
service is significantly lower than rebuilding the entire solution
encapsulated in one service. Because of the SOAP-based unified
communication protocol used by SOSDS, it is easy to provide
any new training method to the system, simply by defining the
proper Web interface. Third, each component of an SOSDS is
an autonomic Web service that can be invoked alongside any
of the considered processes. Fourth, the process of constructing decision models can be initialized by various Web service
clients and the different datasets can be used during training.
Therefore, the classification process can make use of diversified
base learners constructed in various circumstances.

subsets SN (F1 ), , . . . , SN (FK ). The subset SN (Fk ) is determined by limiting SN to the attributes from Fk and eliminating
all examples with missing values.
In this paper, we propose a heuristic procedure for creating
the sequence of sets of attributes’ indexes, which makes use
of two assumptions: the percentage of examples with missing
vales of attributes is very high and there are subsets of attributes
with highly correlated patterns of occurrence. Moreover, the
patterns of missing values for training and testing data should be
similar. Additionally, if many attributes contain missing values
that constitute the large number of missing patterns there is a
risk of constructing too many base learners. As a consequence,
the ensemble model constructed on such data can be overfitted.
Algorithm 1: The Procedure of Constructing Sets of Attributes’ Indexes.
Input : M: matrix representing missing values
occurrence.
Output: F1 , . . . , FK : sequence of attributes’ indexes.
1 A ←− {1, . . . , D};
2 k ←− 1;
3 Create coexistence matrix C by using equation (1);
4 while A = ∅ do
5
Fk ←− ∅;
6
Find j ∗ by solving (2);
7
cm ax ←− cj ∗ ,j ∗ ;
8
for i = 1 → D do
9
if ci,j ∗ ≥ (1 − α)cm ax then
10
Fk ←− Fk ∪ {i};
11
end
12
end
13
A ←− A \ Fk ;
14
k ←− k + 1;
15 end

IV. METHODS
In the following section, we describe the machine-learning
solutions that implement the components of an SOSDS and
deal with the problem of missing values and class imbalance
phenomenon. For the consistency with the previous section, we
associate the issue of medical diagnosis with the problem of
binary classification and we consider the decision model as the
classifier.
A. Splitting Dataset
The main goal of splitting the data is to save as much information as possible by creating the subsets with reduced number of the attributes and containing only the complete cases.
Assume that the training set is denoted by SN = {(xn , yn )},
(j )
where n = 1, . . . , N , xn is the value of jth attribute of nth
example (j = 1, . . . , D) and yn is a class label corresponding
to xn . M is the N × D matrix representing the missing values occurrence, where element mn ,j is equal to 1 if the value
(j )
xn is missing and 0 otherwise. Having M, we are interested
in finding the sequence of sets F1 , . . . , FK , where Fk contains
indexes of selected attributes, which are sufficient to construct

The procedure of generating sets F1 , . . . , FK is presented in
Algorithm 1. In the first step, we construct the D × D coexistence matrix C, where each element ci,j is calculated with the
formula
ci,j =

N


(1 − mn ,j )(1 − mn ,i ).

(1)

n =1

In other words, ci,j represents total number of examples, for
which the values of ith and jth attributes are known. Next, the
j ∗ th attribute is selected, for which the highest value of complete
examples was observed in the set A1
j ∗ = arg max cj,j .
j ∈A

(2)

Further, for each attribute i ∈ {1, . . . , D}, the coexistence
value ci,j ∗ is calculated. If the value of ci,j ∗ is not lower than
the value of cj ∗ ,j ∗ (denoted by cm ax ) corrected by (1 − α),
1 The set A is initially composed of all possible indexes of attributes and is
iteratively updated by eliminating selected features. To simplify the notation,
we further operate on indexes of the attributes, e.g., attribute i refers to x(i ) .

ZIEBA:
˛
SERVICE-ORIENTED MEDICAL SYSTEM FOR SUPPORTING DECISIONS WITH MISSING AND IMBALANCED DATA

α ∈ [0, 1], the attribute indexed by i is selected to be the member
of F1 . After examining all attributes, the set A is reduced by
eliminating all members of the set F1 . The entire procedure is
repeated until A becomes empty.
The idea behind the presented approach is to select in the first
place the attributes for which the percentage of missing values
is the lowest. In the first iteration, we search for an attribute j ∗
with the highest number of complete examples equal to cm ax .
Furthermore, we investigate which of the remaining attributes
have at least (1 − α)cm ax commonly complete examples with
attribute j ∗2 . All selected examples (including j ∗ ) are considered in set F1 . In the next iteration, we choose an attribute
with the highest number of complete examples, but without
considering the members of F1 . The process is continued until
each of the attributes will be selected at least in one of the sets
F1 , . . . , FK . Each result subset SN (Fk ) is created by leaving
only the attributes from FK and removing missing cases.
A similar approach was applied to store sufficient statistics for
decision rules induction [16]. However, the authors of [16] used
a graph represented by the coincidence matrix to accumulate
co-occurrence of the attributes.
B. Constructing Base Classifiers
Each of the generated subsets is delivered to one of the composite services CS2,1 , . . . , CS2,K , which are responsible for
creating the set of base learners. To deal with the issue of imbalanced data, we propose to use on this stage the cost-sensitive
SVM. Therefore, the functionality of the service CS2,k is to
construct the component classifier hk
hk (x) = sgn(wkT φ(x) + bk )

(3)

1537

TABLE I.
CONFUSION MATRIX FOR A TWO-CLASS DECISION PROBLEM

Is member of
positive class
Is member of
negative class

Classified to
positive class

Classified to
negative class

TP
(True positive)
FP
(False positive)

FN
(False negative)
TN
(True negative)

parameters for positive (minority) and negative (majority) examples in the training criterion: Ck ,+ = C 2NNkk, + and Ck ,− =
C 2NNkk, − 5 . With such estimations of Ck ,+ and Ck ,− , the misclassification cost for the positive class is higher than the penalization term for negative examples.
Additionally, each of the classifier has an assigned quality
criterion represented by the geometric mean of specificity and
sensitivity (GMean) calculated on the dataset SN (Fk ) and given
by the equation

GMean = TPrate · TNrate
(6)
TN
where TNrate = TN+FP
is named specificity rate and TPrate =
TP
TP+FN is called sensitivity rate. Values of TP (ang. true positive), FN (ang. false negative), FP (ang. false positive), and TN
(ang. true negative) are components of the confusion matrix
given in Table I. The Gmean criterion is widely used to evaluate
the quality of the classifier on the given imbalanced data, as an
alternative for the accuracy value. For each of the constructed
base classifiers, we remember the set of attributes’ indexes Fk .

3

where sgn(·) is a signum function , wk and bk are the parameters
of the model, and φ(x) denotes a fixed feature-space transformation. The procedure of constructing the base classifier hk
is performed in the supervised mode using the data stored in
SN (Fk ). The problem of training an SVM for the imbalanced
data can be formulated as an optimization task, in which the
following criterion is minimized

1
ξk ,n +
Q(wk , ξ k ) = wkT wk + Ck ,+
2


+ Ck ,−

n + ∈Nk , +

ξk ,n −

(4)

n − ∈Nk , −

under the following conditions:
yn (wkT φ(xn ) + b) ≥ 1 − ξk ,n

(5)

for n ∈ {1, . . . , Nk }4 .
In the contrast to the classical problem formulation of constructing balanced SVMs, we incorporate the different penalty
2 The role of parameter α is to weaken the degree of coexistence between
attributes indexed by j ∗ and i.
3 We consider binary classification tasks in which the set of possible class
labels is defined as follows: Y = {−1, 1}.
4 N is total number of examples in S (F ), ξ is the N -element vector
N
k
k
k
k
of the slack variables that weaken the optimization criterion by introducing the
soft margin, and ξk , n denotes the nth element of the vector ξk .

C. Classification
The process of classification is performed by the set of the
base learners to achieve the class label (medical diagnosis) for
unknown cases. The committee of classifiers makes the final
decision in a majority voting procedure according to the rule
presented below

H(x) = arg max
Gk I(hk (x) = y)
(7)
y ∈Y

k ∈K

where Y represents the set of possible class labels, hk is a base
classifier in the committee, I(·) is the indicator, which returns
1 if the statement is true, and 0 otherwise, K is the set of base
learners stored in the KB, and Gk is the quality of k-classifier
representing the strength of the model in the ensemble. The
set of decision models K used in the committee is defined as
follows: K = {k ∈ {1, . . . , K} : Fk ∩ Fx = Fk }, where the set
Fx is composed of indexes of attributes for which the values of
vector x are known. Consequently, we select only those base
learners, for which the limited input vector is complete.

5N
Nk , − = {n ∈ {1, . . . , N k } :
k , + = {n ∈ {1, . . . , N k } : y n = +1},
y n = −1}, and C is the parameter responsible for controlling the model’s
ability of generalization.

1538

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

D. Generating Decision Rules
The final product assumed to be observed on the output of
the process of constructing decision model is the set of decision
rules. Therefore, in this paper, we propose to use an oracle-based
approach described in [15] composed of the two main steps.
First, we modify the initial training set SN by relabeling each
element xn with the new class label returned by the classifier H.
Second, we make use of a typical rule inducer (e.g., RIPPER)
to generate the decision rules on the modified training data. The
idea of this approach is to take advantage of the constructed
committee of SVMs as a prophecy for predicting the true class
labels.
V. EXPERIMENTAL STUDIES
In this section, we present the empirical results for examining
the quality of the proposed methods using three ontological
datasets.
A. Datasets Description
The thoracic surgery dataset refers to the problem of postoperative liveability prediction after lung cancer surgery in terms
of binary classification. Based on the set of predictors, we are
interested in answering the question whether the patient is going
to live one year after thoracic surgery. The data were collected
retrospectively at Wroclaw Thoracic Surgery Center for over
1203 consecutive patients who underwent major lung resections for primary lung cancer in the years 2007–2011. Each of
the patients is described by the vector composed of 34 features
representing his condition before, during, and after the surgery.
The number of attributes containing missing values was equal
to 14. In the data, we can distinguish six attributes with 1 − 2%
of missing values. For the other eight attributes, the ratios of unknown cases were extremely high and equal: 28%, 44%, 53%,
54%, 57%, 58% and 61% (twice). The detailed description of
the most of the attributes and their impact on the output value
was presented in [15]. The problem was formulated as a binary
classification task, in which the positive class represented deaths
in one year after surgery (220 examples), and negative class, if
the patient survived after surgery (983 cases). In such problem
formulation, we identified the imbalanced data phenomenon biased toward the negative class.
The oncology dataset is a real-world medical dataset provided
by the Institute of Oncology, Ljubljana and refers to the problem
of predicting whether the patient will have a recurrence of breast
cancer within ten years after surgery or not. The entire dataset
is composed of 949 patients (365 recurrences, 584 nonrecurrences) described with 15 attributes (the detailed description of
the data is presented in [17]). The initial dataset does not suffer
from the missing values phenomenon; therefore, the patterns of
unknown values of the attributes were generated artificially. As
a consequence, the percentages of missing values were equal:
9% (two attributes) 11% (six attributes), 19% (two attributes),
20% (one attribute), and 27% (three attributes).
The breast cancer dataset is one of the most widely used
benchmark datasets published and described in detail in UCI
Machine Learning Repository [18] that also refers to the issue

of breast cancer recurrence. The entire data are composed of 286
instances (85 recurrences, 201 nonrecurrences), each described
with nine attributes. Random patterns of missing values were
generated from initial data that lead to 9% of unknown values
for three attributes and 3% missing cases for one attribute.
B. Experimental Results
The goal of the experimental studies was to evaluate the quality of two classification methods described in this paper: the
committee of SVMs (interchangeably named ensemble SVM,
ESVM), and decision rules constructed by applying an oraclebased approach together with the RIPPER algorithm (ESVMJ).
We compared the results for the proposed solutions with the
predictive performance of the reference classifiers commonly
used in the field of supporting decisions in medicine: classification and regression tree (CART), multilayer perceptron (MLP),
decision rules constructed with RIPPER rules inducer (JRip),
C 4.5 decision tree (C4.5), AdaBoost (AB), Bagging (Bag),
Random Forest (RF), logistic regression (LR), SVMs, and costsensitive version of an SVM (CSVM). The problem of missing
data for reference methods was solved by applying imputation
technique, in which the mean value of an attribute (or most
frequently observed value, in the case of nominal attributes) is
inserted for unknown cases.
We applied ten folds cross validation with ten repetitions as
the testing methodology. As the main criterion of evaluation,
we used GMean value. Additionally, we present the results for
TP+TN
.
TNrate , TPrate , and the accuracy equal TP+TN+FP+FN
The results of the experiment for thoracic surgery data are
given in Table II. The highest GMean value was gained by
the committee of SVM (ESVM) proposed in this paper. The
percentage of correctly detected positives6 for our method was
over 10% higher than for C-SVM and MLP, which were the most
balanced models of the reference classifiers. Applying other
classification methods considered in the study resulted in about
80% of correctly classified negative examples but not more than
7% accurately predicted positives. The generated decision rules
using an oracle-based approach (ESVMJ) performed almost the
same as ESVM.
The results of the experiment for oncology data are given
in Table III. The proposed method (ESVM) performed visibly
better than the reference solutions considering GMean criterion.
The accuracy of detected positives (TPrate ) by classifier ESVM
was over 50% and only MLP gained comparable result among
the state-of-the art methods. The results of the interpretable
ESVMJ were again almost the same as for noninterpretable
ESVM.
The results of the experiment for breast cancer data are given
in Table IV. The GMean value for ESVM classifier was the
same as for AB which was the strongest predictor in the group
of reference methods for the considered dataset. However, the
percentage of correctly detected positives by ESVM was over
6% higher than for AB. The set of decision rules gained by an
6 Positive class is a minority class and represents death of the patient after
surgery in one year.

ZIEBA:
˛
SERVICE-ORIENTED MEDICAL SYSTEM FOR SUPPORTING DECISIONS WITH MISSING AND IMBALANCED DATA

1539

TABLE II
DETAILED RESULTS FOR GMean ON Thoracic Surgery DATA (BEST RESULTS IN BOLD, STANDARD DEVIATION IN BRACKETS)
Method

TP r a t e

TN r a t e

Accuracy

GMean

CART
MLP
JRip
C4.5
AB
Bag
RF
LR
SVM
C-SVM
ESVM
ESVMJ

0.001(±0.003)
0.234(±0.027)
0.060(±0.013)
0.038(±0.011)
0.019(±0.009)
0.069(±0.019)
0.084(±0.013)
0.029(±0.019)
0.075(±0.014)
0.232(±0.034)
0.359(±0.018)
0.342(±0.032)

0.998(±0.005)
0.868(±0.007)
0.977(±0.005)
0.978(±0.007)
0.994(±0.002)
0.968(±0.002)
0.959(±0.007)
0.987(±0.009)
0.988(±0.001)
0.875(±0.020)
0.737(±0.005)
0.751(±0.012)

0.816(±0.003)
0.752(±0.006)
0.809(±0.005)
0.806(±0.005)
0.816(±0.002)
0.804(±0.006)
0.799(±0.005)
0.812(±0.006)
0.821(±0.003)
0.757(±0.015)
0.668(±0.006)
0.676(±0.006)

0.016(±0.034)
0.450(±0.026)
0.241(±0.028)
0.191(±0.028)
0.131(±0.038)
0.255(±0.031)
0.282(±.021)
0.156(±0.065)
0.270(±0.027)
0.450(±0.032)
0.514(±0.014)
0.506(±0.021)

TABLE III
DETAILED RESULTS FOR GMean ON Oncology DATA (BEST RESULTS IN BOLD, STANDARD DEVIATION IN BRACKETS)
Method

TP r a t e

TN r a t e

Accuracy

GMean

CART
MLP
JRip
C4.5
AB
Bag
RF
LR
SVM
C-SVM
ESVM
ESVMJ

0.418(±0.005)
0.525(±0.022)
0.461(±0.011)
0.424(±0.015)
0.411(±0.008)
0.445(±0.013)
0.433(±0.013)
0.433(±0.008)
0.412(±0.008)
0.468(±0.010)
0.515(±0.012)
0.504(±0.013)

0.902(±0.003)
0.733(±0.018)
0.857(±0.015)
0.888(±0.004)
0.910(±0.006)
0.879(±0.008)
0.841(±0.013)
0.892(±0.004)
0.898(±0.003)
0.765(±0.009)
0.824(±0.010)
0.832(±0.009)

0.716(±0.002)
0.653(±0.012)
0.705(±0.006)
0.709(±0.006)
0.718(±0.004)
0.712(±0.006)
0.685(±0.012)
0.716(±0.003)
0.711(±0.003)
0.651(±0.008)
0.705(±0.007)
0.706(±0.006)

0.614(±0.002)
0.620(±0.013)
0.628(±0.005)
0.613(±0.010)
0.611(±0.006)
0.626(±0.009)
0.604(±0.012)
0.622(±0.005)
0.608(±0.006)
0.599(±0.008)
0.651(±0.008)
0.648(±0.008)

TABLE IV
DETAILED RESULTS FOR GMean ON Breast Cancer DATA (BEST RESULTS IN BOLD, STANDARD DEVIATION IN BRACKETS)
Method

TP r a t e

TN r a t e

Accuracy

GMean

CART
MLP
JRip
C4.5
AB
Bag
RF
LR
SVM
C-SVM
ESVM
ESVMJ

0.211(±0.075)
0.433(±0.034)
0.305(±0.023)
0.262(±0.022)
0.432(±0.051)
0.229(±0.033)
0.354(±0.027)
0.295(±0.021)
0.336(±0.036)
0.419(±0.026)
0.495(±0.035)
0.551(±0.030)

0.909(±0.024)
0.767(±0.030)
0.895(±0.021)
0.949(±0.011)
0.830(±0.026)
0.905(±0.009)
0.840(±0.015)
0.924(±0.015)
0.857(±0.014)
0.709(±0.023)
0.720(±0.020)
0.709(±0.020)

0.702(±0.013)
0.667(±0.028)
0.720(±0.011)
0.745(±0.011)
0.712(±0.016)
0.705(±0.009)
0.695(±0.008)
0.737(±0.012)
0.702(±0.016)
0.623(±0.015)
0.653(±0.018)
0.662(±0.013)

0.429(±0.083)
0.576(±0.030)
0.522(±0.015)
0.499(±0.021)
0.597(±0.031)
0.455(±0.032)
0.545(±0.019)
0.522(±0.017)
0.536(±0.031)
0.545(±0.015)
0.597(±0.024)
0.624(±0.016)

oracle-based approach (ESVMJ) gained even better result with
over 55% of detected positives and GMean equal to 0.624.
The following conclusions arise while analyzing the experimental results. First, the proposed committee of SVMs (ESVMJ)
performs visibly better than the reference methods when the percentage of missing values is high and the data are imbalanced.
Second, the proposed classifier outperforms the reference methods significantly while detecting minority (positive) examples.
Third, the application of an oracle-based approach for generating rules (ESVMJ) perfectly imitates (or even outperforms in

the case of breast cancer dataset) the behavior of the ensemble
of SVMs and can be used alternatively in the system as a model
for supporting medical decisions.
VI. CONCLUSION
In this paper, we propose the support decision system composed of data processing Web services that can be used to solve
various medical diagnostic problems. The system enables constructing decision models directly from the unprocessed data

1540

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

with a high percentage of missing values of the attributes and imbalanced class distribution. These issues are solved by proposing
the hybrid method of constructing the committee of the costsensitive SVM that is insensitive to the disproportions between
classes and missing cases occurrence. Additionally, we present
the algorithm for discovering high-quality decision rules from
the proposed ensemble classifier. Finally, we examine the quality of the proposed solutions on three ontological datasets. The
results of the experiment show that both of the proposed models
(ESVM and ESVMJ) are better predictors (according to GMean)
than the other methods considered in this study. In the future
works, the entire procedure of constructing the ensemble classifier is going to be adjusted to deal with the problem of noisy
labels. Moreover, the SOSDS will be prepared for commercial
use and installed on the server.
ACKNOWLEDGMENT
The author would like to thank M. Lubicz for providing the
thoracic surgery data and E. Strumbelj for providing the oncology data.
REFERENCES
[1] P. M. Nadkarni and R. A. Miller, “Service-oriented architecture in medical
software: Promises and perils,” J. Amer. Med. Informat. Assoc., vol. 14,
no. 2, pp. 244–246, 2007.
[2] P. Światek,
˛
P. Stelmach, A. Prusiewicz, and K. Juszczyszyn, “Service composition in knowledge-based SOA systems,” New Generation Comput.,
vol. 30, no. 2–3, pp. 165–188, 2012.
[3] A. Wright and D. F. Sittig, “SANDS: A service-oriented architecture for
clinical decision support in a national health information network,” J.
Biomed. Informat., vol. 41, no. 6, pp. 962–981, 2008.
[4] S. W. Tu, J. R. Campbell, J. Glasgow, M. A. Nyman, R. McClure, J. McClay, C. Parker, K. M. Hrabak, D. Berg, T. Weida, J. G. Mansfield, M.
A. Musen, and R. M. Abarbanel, “The SAGE guideline model: Achievements and overview,” J. Amer. Med. Informat. Assoc., vol. 14, no. 5, pp.
589–598, 2007.

[5] K. Brzostowski, J. Drapła, A. Grzech, and P. Światek,
˛
“Adaptive decision
support system for automatic physical effort plan generation: Data-driven
approach,” Cybern. Syst., vol. 44, no. 2-3, pp. 204–221, 2013.
[6] A. Grzech, P. Światek,
˛
and P. Rygielski, “Dynamic resources allocation
for delivery of personalized services,” in Software Services for e-World.
New York, NY, USA: Springer, 2010, pp. 17–28.
[7] P. J. Garcia-Laencina, J. L. Sancho-Gomez, and A. R. Figueiras-Vidal,
”Pattern classification with missing data: A review, ” Neural Comput.
Appl., vol. 19, no. 2, pp. 263–282, Sep. 2009.
[8] L. Garg, J. Dauwels, A. Earnest, and K. P. Leong, “Tensor based
methods for handling missing data in quality-of-life questionnaires,”
IEEE J. Biomed. Health Informat., vol. PP, no. 99, p. 1, doi: 10.1109/
JBHI.2013.2288803.
[9] L. Nanni, A. Lumini, and S. Brahnam, “A classifier ensemble approach
for the missing feature problem,” Artif. Intell. Med., vol. 55, no. 1, pp.
37–50, 2012.
[10] H. He, and E. A. Garcia, “Learning from imbalanced data,” IEEE Trans.
Knowl. Data Eng., vol. 21, no. 9, pp. 1263–1284, Sep. 2009.
[11] N. V. Chawla, K. W. Bowyer, and L. O. Hall, “SMOTE: Synthetic minority
over-sampling technique,” J. Artif. Intell. Res., vol. 16, pp. 321–357, 2002.
[12] N. V. Chawla, A. Lazarevic, L. O. Hall, and K. Bowyer, “SMOTEBoost:
Improving prediction of the minority class in boosting,” in Proc. Principles
Knowl. Discovery Databases, 2003, pp. 107–119.
[13] D. Tao, X. Tang, X. Li, and X. Wu, “Asymmetric bagging and random
subspace for support vector machines-based relevance feedback in image
retrieval,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 28, no. 7, pp.
1088–1099, Jul. 2006.
[14] M. Kukar, and I. Kononenko, “Cost-sensitive learning with neural networks,” in Proc. 13th Eur. Conf. Artif. Intell., 1998, pp. 445–449.
[15] M. Zieba,
˛
J. M. Tomczak, J. Światek,
˛
and M. Lubicz, “Boosted SVM
for extracting rules from imbalanced data in application to prediction of
the post-operative life expectancy in the lung cancer patients,” Appl. Soft
Comput., vol. 14, Part A, pp. 99–108, 2014.
[16] J. M. Tomczak and A. Gonczarek, “Decision rules extraction from data
stream in the presence of changing context for diabetes treatment,” Knowl.
Inf. Syst., vol. 34, no. 3, pp. 521–546, 2013.
[17] E. Štrumbelj, Z. Bosnić, I. Kononenko, B. Zakotnik, and C. G. Kuhar,
“Explanation and reliability of prediction models: The case of breast
cancer recurrence,” Knowl. Inf. Syst., vol. 24, no. 2, pp. 305–324, 2010.
[18] K. Bache, and M. Lichman. (2013). UCI machine learning repository
[Online]. Available: http://archive.ics.uci.edu/ml

Maciej Zieba,
˛ photograph and biography not available at the time of publication.

