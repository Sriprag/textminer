196

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

Supervised Variational Model With Statistical
Inference and Its Application in Medical
Image Segmentation
Changyang Li∗ , Member, IEEE, Xiuying Wang, Stefan Eberl, Member, IEEE, Michael Fulham, Yong Yin,
and David Dagan Feng, Fellow, IEEE

Abstract—Automated and general medical image segmentation
can be challenging because the foreground and the background
may have complicated and overlapping density distributions in
medical imaging. Conventional region-based level set algorithms
often assume piecewise constant or piecewise smooth for segments,
which are implausible for general medical image segmentation.
Furthermore, low contrast and noise make identification of the
boundaries between foreground and background difficult for edgebased level set algorithms. Thus, to address these problems, we
suggest a supervised variational level set segmentation model to
harness the statistical region energy functional with a weighted
probability approximation. Our approach models the region density distributions by using the mixture-of-mixtures Gaussian model
to better approximate real intensity distributions and distinguish
statistical intensity differences between foreground and background. The region-based statistical model in our algorithm can
intuitively provide better performance on noisy images. We constructed a weighted probability map on graphs to incorporate spatial indications from user input with a contextual constraint based
on the minimization of contextual graphs energy functional. We
measured the performance of our approach on ten noisy synthetic
images and 58 medical datasets with heterogeneous intensities and
ill-defined boundaries and compared our technique to the Chan–
Vese region-based level set model, the geodesic active contour model
with distance regularization, and the random walker model. Our
method consistently achieved the highest Dice similarity coefficient
when compared to the other methods.

Manuscript received May 26, 2014; accepted July 19, 2014. Date of publication July 31, 2014; date of current version December 18, 2014. Asterisk
indicates corresponding author.
∗ C. Li is with the Biomedical and Multimedia Information Technology Research Group, School of Information Technologies, The University of Sydney,
Sydney, N.S.W. 2006, Australia (e-mail: changyang.li@sydney.edu.au).
X. Wang is with the Biomedical and Multimedia Information Technology Research Group, School of Information Technologies, The University of Sydney,
Sydney, N.S.W. 2006, Australia (e-mail: xiu.wang@sydney.edu.au).
S. Eberl is with the BMIT Research Group, The University of Sydney, Sydney,
N.S.W. 2006, Australia and also with the Department of PET and Nuclear
Medicine, Royal Prince Alfred Hospital, Camperdown, N.S.W. 2050, Australia
(e-mail: stefan.eberl@sydney.edu.au).
M. Fulham is with the Sydney Medical School, The University of Sydney,
Sydney, N.S.W. 2006, Australia and also with the Department of Positron
Emission Tomography and Nuclear Medicine, Royal Prince Alfred Hospital, Camperdown, N.S.W. 2050, Australia (e-mail: michael.fulham@sydney.
edu.au).
Y. Yin is with the Department of Radiation Oncology, Shandong Tumor
Hospital, Jinan 250117, China (e-mail: yinyongsd@yahoo.com.cn).
D. Feng is with the BMIT Research Group, School of Information Technologies, The University of Sydney, Sydney, N.S.W. 2006, Australia, and also with
the Med-X Research Institute, Shanghai Jia Tong University, Shanghai 200030,
China (e-mail: dagan.feng@sydney.edu.au).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2014.2344660

Index Terms—Image segmentation, level set, mixture-ofmixtures Gaussian model, PDE.

I. INTRODUCTION
MAGE segmentation extracts object or regions of interest
(ROIs), and it has an essential role in medical image analysis and interpretation, and it is used for diagnosis, treatment
planning, and in monitoring treatment response. Medical image segmentation can be done manually or in an automated
or semiautomated fashion. Manual segmentation is time consuming, operator-dependent, and poorly reproducible. Fully automated and application-driven image segmentation algorithms
have been developed for specific body organs, e.g., the liver with
computed tomography (CT) and the prostate with magnetic resonance (MR) imaging. Supervised segmentation refers to segmentation algorithms that require user input, e.g., the initial contour or labeled pixel/voxel as seeds, to guide the computer-aided
segmentation. Compared to application-driven algorithms, supervised segmentation approaches have wider applications and
are more accurate provided there is sufficient user input. Based
on different user input, supervised algorithms can be categorized
into boundary- and region-based algorithms.
Boundary-based algorithms specify an initial contour to be
close to the desired boundary and evolve the contour toward
the strongest gradients via the minimization of boundary-based
energy functional [1]; the geodesic level set algorithm [2] and
geometric level set algorithm [3] are two typical examples. In
these algorithms, image noise, weak boundaries, low contrast
among regions, and spurious gradients pose challenges for accurate edge detection in medical images. In such cases, the
resulting contour from the boundary-based algorithms may leak
away from the true boundaries [4] or be diverted by a spurious
gradient in heterogeneous regions [5].
Region-based supervised algorithms avoid the need for detection of image gradients and utilize region statistical estimation
or graph theory to improve the robustness and performance
of segmentation; they include region-based level set algorithms
[5]–[9] and graph-based algorithms [10], [11]. The region-based
level set energy functional is often derived from different classification models [6], [12], which include the K-means [13], fuzzy
C-means [14], and Gaussian mixture models [15]. By embedding K-means model, the Mumford and Shah functional [16]
is simplified by the piecewise constant (PC) level set algorithm
[5] and the multiphase level set algorithm [7], [17] to overcome

I

0018-9294 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

LI∗ et al.: SUPERVISED VARIATIONAL MODEL WITH STATISTICAL INFERENCE AND ITS APPLICATION IN MEDICAL IMAGE SEGMENTATION

image noise and blurred regions boundaries. Since the PC level
set algorithms can only solve two homogenous segments in images, multiphase level set energy functional is suggested for the
classification of multiple segments, which is determined by the
phase values. The multiphase level set energy functional [18],
[19] use fuzzy C-means and Markov random field (MRF) priors
[20] to deal with intensity inhomogeneities found in nature images and MR images. However, it is difficult for the multiphase
level set algorithms to predict accurate phase values for classifying the image with complex intensity distributions [21], [22]. In
order to avoid approximation of phase values, our previous work
[8] proposed to embed the finite Gaussian model and Gaussian
mixture model into the level set framework to approximate homogenous intensity distribution of foreground and the complex
intensity distributions of the background simultaneously. Due
to complicated structures of anatomy and pathology displayed
in medical images, the homogenous foreground assumption is
likely not to be valid, resulting in the current region-based level
set models not being able to accurately segment foreground.
A number of investigators have integrated statistical prior variation models, e.g., shape [23] and other features [24] of the
target(s), with a level set framework to improve segmentation
accuracy. However, there are substantial variations in the shape,
size, and intensity distributions of different tissues and organs
across patients; so, it is difficult to collect sufficient training
datasets to include all the normal and abnormal variations, in
particular, with tumors. Hence, there is limited improvement in
segmentation accuracy using the statistical prior models for the
foreground with heterogeneous intensity.
Graph-based segmentation is an active research area and
many hybrid graph-based algorithms have been applied in medical image segmentation [25], [26]. This approach requires a
small number of labeled pixels (called seeds) for the foreground
and the background and, given sufficient user interaction, these
algorithms can achieve accurate segmentation. The modern
graph-based segmentation algorithms primarily are variations
of the graph-cut (GC) [10], random walker (RW) [11], and the
geodesics shortest path [27] methods. The GC algorithm performs a max-flow/min-cut analysis to find the minimum-weight
cut between the foreground and background seeds. The GC algorithm may lead to oversegmentation [28] for low contrast or
noisy images since the GC algorithm returns the smallest cut
separating the seeds (called shrinking bias), and these cuts minimally separate the seeds from the rest of the image. In the RW,
the diffusion distances are calculated for each pixel to avoid
segmentation leakage and shrinking bias. The RW considers an
image (volume) as a purely discrete object that can be described
as a graph with a fixed number of vertices (nodes) and edges.
Each edge is assigned a weight corresponding to the likelihood
that a RW will cross the edge [11]. The probability that each
node/pixel sends a RW to the seeds can be calculated analytically by solving a sparse, positive-definite system of linear
equations with the graph Laplacian matrix via the minimization of the Dirichlet integral [11]. Grady [11] showed that the
RW can achieve better image segmentation performance than
the GC algorithm. However, the robustness and accuracy of
RW is still limited to locations of seeds since variations in the

197

Fig. 1. Transaxial MR image of a GBM. Intensity distribution analyses corresponding to the foreground (tumor delineated by a red outline) and the
background (partial background region delineated by a green outline). The
shaded region demonstrates the overlapping range of intensities of tumor and
background.

boundary conditions (locations of seeds) result in different harmonic functions [29]. Further limitation of graph-based algorithms include an inability to produce controllable boundary
smoothness [30], and they perform poorly when applied to noisy
images.
Medical images are not uniform; the foreground and background may have artifacts from noise, complicated intensity distributions, and abnormal tissue with heterogeneous signal intensities. In statistics, a multimodal/bimodal distribution consists
of two or more different modes and has multiple distinct peaks
in the probability density function. As an example, in Fig. 1,
we show a transaxial T1-weighted, gadolinium-enhanced MR
image of a malignant brain tumor, a Glioblastoma multiforme
(GBM). The tumor shows heterogeneity, and the intensity distribution shows multiple distinct peaks in Fig. 1(a). The overlapping intensity ranges in the distribution of the tumor (target) and
the background [shown as the shaded region of Fig. 1(b)] violate the assumption of disjoint intensity distributions of different
segments [7]. It is difficult to differentiate the pixels with the
same intensity value or marginal differences in the foreground
and the background based only on statistical classification, such
as with the Gaussian mixture model or fuzzy C-means. In addition, structures surrounding a region of pathology may have the
same intensity range or low contrast, resulting in weak and ambiguous boundaries, which pose challenges to boundary-based
segmentation algorithms.
We hypothesize that in a segmentation model, which takes
into account the statistical inference and global spatial properties, would improve the segmentation of ROI(s) with heterogeneity and blurred boundaries in medical images. We suggest a
new variational mixture-of-mixtures statistical functional to approximate the true intensity distribution of the foreground and
background. The user inputs regarding spatial properties and
intensity changes are provided to our energy framework for the
construction of the graph-based probability map. This probability map highlights the graph-based property of the ROIs and
better differentiates the foreground and the background when
similar intensities are shared. Under the level set framework,
the statistical functional and the graph-based probability map

198

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

are harnessed seamlessly with the smoothness and regularization functional to produce a smoothed, accurate boundary, and
it allows the evolving contour to adhere to geometric features
for segmentation.
II. RELATED WORK: RW ALGORITHM
Let Ω be the image domain, and u : Ω →  be a gray level
image. The RW defines the notion that a graph G consists of a
pair G = (V, E) with node υ ∈ V and edge e ∈ E ⊆ V × V .
Since the image is defined as a graph, a node υx would be
simplified as a node/pixel x. In a weighted graph, an edge exy
connecting from the pixel x to the pixel y is assigned a weight
w(exy ) or simplified as wxy . To represent the differences of
the image structures, edge weights should reflect changes in
image intensities; and hereby, the each edge weight wxy is the
likelihood that a RW would cross the edge. The graph weight
wxy is defined as


(1)
wxy = exp −β (u(x) − u(y))2
where β is the weight parameter, u(x) is the image intensity
value at pixel x, and (u(x) − u(y))2 is normalized to [0, 1].
Calculating the pixel’s membership is equivalent to the solution of the combinatorial Dirichlet problem [11]. The discrete
version of the weighted Dirichlet integral is formulated as
1
(2)
D [X] = X T LX
2
where X is a vector containing the indices of all the image
pixels, and L is the combinatorial Laplacian matrix, and its
element is given as
⎧
d ,
if x = y
⎪
⎨ x
Lxy = −wxy , if x and y are adjacent pixels
(3)
⎪
⎩
0,
otherwise

where dx = y wxy is the degree of a pixel x, which counts
the number of edges exy connecting the pixel x and pixel y.
For the initialization of RW, the user prescribes a set of seed
pixels VM (labelled seeds) for the foreground and background;
and VU includes all unlabelled pixels, where VM ∪ VU = V
and VM ∩ VU = ∅. The remaining unlabelled pixels VU are the
degrees of freedom. Accordingly, the discrete Dirichlet integral
(3) can be rewritten as



XM
1 	 T T 
 LM B
XM XU
D [XU ] =
2
XU
B T LU
=


1 T
XM LM XM + 2XUT B T XM + XUT LU XU
2
(4)

where LM describes the dependence between the seeds VM ,
LU describes the dependence between the unlabelled pixels,
and B and B T describe the coupling between the labelled and
unlabelled pixels.
Differentiating D [XU ] with respect to XU , we can obtain
LU XU = −B T XM .

(5)

As the result, every pixel x is assigned a value of probability pk (x) for reaching the seed with label k from the pixel x,
 k
where pk (x) = Xik and K
k p (x) = 1, K is the total number
of labels. With the RW, the seed propagation and the location
features would be incorporated to generate a probabilities map of
each pixel belonging to the foreground and background, though
the segmentation accuracy would depend on the number and
location of the labeled seeds.
III. METHODOLOGY
A. Supervised Variational Model With Statistical Inference
We consider an image u : Ω →  in a continuous domain Ω
to be partitioned into two segments: the foreground ΩF and the
background ΩB , where ΩF ∪ ΩB = Ω and ΩF ∩ ΩB = ∅. To
formulate the energy functional of intensity and region features
with the guidance of labeled seeds, we first define the supervised
variational formulation with unique descriptors for foreground
and background to determine the label of every pixel:

CSG
(x) =
S F (x)OF (u(x))dx
F
ΩF


S B (x)OB (u(x))dx

+

(6)

ΩB

where the statistical inference descriptors OF (u(x)) and
OB (u(x)) are used to calculate the probability density values
of a pixel based on the statistical intensity analysis, and S F (x)
and S B (x) are supervised terms that contribute the weights of
user intention to probability density values of each pixel.
In medical images, the intensity histograms of ROIs may
exhibit single or multiple distinct peaks and follow multimodal distribution. The mixture-of-mixtures Gaussian model
[31], where each component constitutes a parametric mixture
and is able to appropriately approximate the intensity multimodal distribution. In this paper, we assume that the value of
each pixel x ∈ Ω is drawn independently from intensity distributions. Accordingly, we modeled our statistical inference descriptors by using mixture-of-mixtures Gaussian model to represent
the multimodal intensity distribution of the foreground and the
background:

M
K
K
M odes



τ
τ
cτ pτ (x) =
cτ
cm Gm (u(x))
p(u(x)|Θ) =
τ =1

τ =1

m =1

(7)
where Θ is the full set of Gaussian parameters and Gτm (u(x)) =
τ
) denotes a Gaussian probability density; K
Gτm (u(x)|μτm , σm
is the number of segments and MM o des is number of Gaussian components; cτ and cτm are the mixing coefficients of the
segments and the modes, respectively.
In the following sections, we present the energy formulation for segmenting a single target from a given image. Accordingly, we can simplify K = 2 in the mixture-of-mixtures
model to approximate the two segments for foreground (a single target) and background. We assume the probability of the
mixing coefficients to be equal for the two segments, and
hereby, cτ = 0.5. To convert the discrete presentation into

LI∗ et al.: SUPERVISED VARIATIONAL MODEL WITH STATISTICAL INFERENCE AND ITS APPLICATION IN MEDICAL IMAGE SEGMENTATION

continuous level set formulation, we introduce the level set
function φ : Ω →  with signed values to represent the two
partitions. Provided that the implicit contour φ separates the
foreground ΩF = {x|φ(x) ≥ 0} and the background ΩB =
{x|φ(x) < 0}, we can reformulate the statistical model (7) by
using a variational formulation as follows:

(p(u(x) |ΘF )H(φ)
F (φ, Θ) =
Ω

+p(u(x) |ΘB )(1 − H(φ)))dx
 
MF
=
cFα GFα (u(x)|μFα , σαF )H(φ)dx
Ω α =1

+

 
MB

B
B
B
cB
ρ Gρ (u(x)|μρ , σρ )(1 − H(φ))dx

Ω ρ=1

(8)

where 

ψ exp −
constant;

T (z) =



(x,y )∈C





Z(z − x)u(x)dx;


Ω

199

Z(x) =

t (u (x) , u (y)) , ψ is a normalizing

t (u (x) , u (y)) is a sum of clique po-

(x,y )∈C

tentials t (u (x) , u(y)) over all possible cliques C; and
0, x = y
t (u (x) , u (y)) =
1, x = y.
Based on our weighted cost function (9), (4), and matrix
decomposition, SU (x) can be calculated as follows:


−B T XM
(10)
SU (x) = L−1
U
G
where
 represents the potentials of unseeded pixels; L =
 G SU (x)
LM B
; and the element of matrix LG is given as
B T LG
U
⎧ G G  G
⎨ dx , dx = y wxy , if x = y
G
LG
=
−wxy
,
if x and y are adjacent pixels
xy
⎩
0,
otherwise.

where H is the Heaviside function and defined as H (φ) =

1, φ ≥ 0
; ΘF and ΘB are the full set of Gaussian parame0, φ < 0
ters for the foreground and the background, respectively, where
Θ = {ΘF , ΘB }; MF and MB are the number of Gaussian components for the segments; cFα and cB
ρ are the mixing coefficients
 F F
of the modes for the segments, in which M
α =1 cα = 1 and
M B B
F
F
F
B
B
B
ρ=1 cρ = 1; and Gα (u(x)|μα , σα ) and Gρ (u(x)|μρ , σρ )
denote a Gaussian density for a pixel x for the segments, in
B
which μFα , σαF and μB
ρ , σρ are a set of Gaussian mean and
standard deviation for the Gaussian components in the mixture
model.
Using the Heaviside function, we can separately achieve the
maximum likelihood (ML) of the Gaussian mixture model for
the two segments ΩF and ΩB . In the following section, we
will define the supervised terms by using combinatorial graph
calculus.

After embedding the probability map into the supervised variational formulation with the unique descriptors (8), the energy
functional (6) can be represented as follows:


CSG
eF (φ, ΘF )H(x)
(φ, Θ) =
F

B. Combinatorial Energy Approximation
and Regularization Formulations

The statistical and conventional RW models have difficulty
in producing controllable boundary smoothness. To retain the
contour represented by the zero level set smoothing and maintain
the signed distance property, we introduce two regularization
terms into the proposed coupled statistical and graph (CSG)
variational model. The energy functional L(φ) was first defined
in the Mumford–Shah functional to compute the arc length of the
zero level contour of φ to smooth the contour by penalizing its
arc length [5]. In our model, we integrate the distance regularized
term R(φ) [33] to regulate the iterations of evolving surface
without a reinitialization problem and to keep the stability of
the evolution.
The combinatorial energy functional of our coupled statistical
and weighted-graph model is represented as follows:

As the mixture-of-mixtures model does not fully take into
account the contextual spatial constraint information and user
intention among the segments, it may fail to differentiate the labels of the pixels when the probability densities of these pixels
are equal or marginally different. To distinguish these pixels with
marginal different probability densities, the probability map is
proposed via a solution of
graph-based enthe combinatorial
k
S
(x)
=
1,
where
S k (x) equals
ergy functional based on K
k
k
p (x) in (5). However, noise will degrade the performance of
the conventional RW [19]. As discussed by Li et al. [20], MRF
theory takes the contextual constraint into account to characterize mutual influences among image pixels (entities). Hence,
we modeled context-dependent entities by embedding Gibbs
distribution from Hammersley–Clifford theorem [32] into the
weighted graph function (1) to enhance the contextual property
in the conventional RW and reformulated (1) as


G
(9)
= exp −β(T (x)u(x) − T (y)u(y))2
wxy

Ω


+eB (φ, ΘB )(1 − H(x)) dx
where

eF (φ, ΘF ) = −S F (x)

MF


(11)



cFα GFα x|μFα , σαF ,

α =1

eB (φ, ΘB ) = −S B (x)

MB


 B B
B
cB
ρ Gρ x|μρ , σρ ,

ρ=1
K


S k (x) = 1, and

k ∈ {F, B} .

k

E CSG (φ, Θ) = F CSG (φ, Θ) + λL(φ) + μR(φ)

(12)

where λ > 0 is the coefficients of the smoothing regularization
function L(φ), which is defined as

δ(φ) |∇φ| dx
(13)
L(φ) =
Ω

200

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

and μ > 0 is the constant weight for the distance regularization
function R(φ), which is defined by



p(|∇φ|)dx =

R(φ) =
Ω

Ω

1
(|∇φ| − 1)2 dx
(2π)2

(14)

where δ(φ) = H(φ) is the Dirac delta function.

IV. ENERGY MINIMIZATION AND ALGORITHM SUMMARY

M

⎧ step :
⎪
⎪
γαF (x)u(x)H(φ)dx
⎪
⎪
⎪
Ω
F
new
⎪
(μα )
=  F
⎪
⎪
⎪
γα (x)H(φ)dx
⎪
⎪
Ω
⎪
⎪
⎪
⎨
γαF (x)(u(x) − (μFα )new )2 H(φ)dx
Ω
F 2 new

((σα ) )
=
⎪
⎪
F
⎪
⎪
Ω γα (x)H(φ)dx
⎪

⎪
⎪
⎪
⎪
⎪
γαF (x)H(φ)dx
⎪
⎪
⎪
Ω
F
new
⎪(cα )

=
⎩
Ω H(φ)dx

AND check the convergence for Ω p(x|ΘF )H(φ)dx.

A. Minimization of CSG Energy Functional
Through the minimization of the variational functional
E CSG (φ, Θ), the segmentation solution of an object of interest
can be obtained. To minimize the variational CSG functional
E CSG (φ, Θ) (12), we utilize an alternating standard gradient
descent optimization approach where the objective functional
is minimized with respect to each of its parameters φ and Θ.
Since Θ is a full set of Gaussian parameters, EM [34] is applied
to estimate these parameters for each segment separated by the
Heaviside function H (φ).
1) Energy Minimization Regarding Level Set Function: We
derive the associated Euler–Lagrange equation for the level set
function φ, by keeping the set of Gaussian parameters Θ fixed
and minimizing E CSG (φ, Θ) with respect to φ. Using a standard variational calculus method [35], we compute the gradient
descent direction by using a setting time step ε ∈ [0, 2] to find
the steady-state solution of the gradient flow equation:

∂φ
= δ(φ)F + λδ (φ) div
∂t



∇φ
|∇φ|


+ μdiv (dp (|∇φ|)∇φ)

(15)
where F = eB (φ, ΘB ) − eF (φ, ΘF ), dp is a function defined
Δ



by dp = p (|∇φ|)
|∇φ| , and div(·) is a divergence operator.
2) Energy Minimization Regarding the Gaussian Parameters
Θ: Here, we keep φ fixed and minimize the energy data term
F CSG (φ, Θ) with respect to the descriptor parameters Θ. With
regard to Θ, the minimization of F CSG (φ, Θ) is equivalent to the
ML of a continuous log likelihood function. Under the previous
assumption of a mixture Gaussian model for the segments, EM
can be used to solve the optimization of Gaussian parameters
while ML is being achieved for the Gaussian mixture distribution of two defined regions separated by H (φ) and 1 − H (φ)
as follows:

H (φ) > 0

When
Ω

E step :

γαF



N u (x) H (φ) |μFα , σαF
(x) = M F


F
F
j =1 N u (x) H (φ) |μj , σj

(16)


1 − H (φ) > 0:

When
Ω

B
N (u(x)(1 − H(φ))|μB
ρ , σρ )
E step : γρB (x) = M B


B
B
j =1 N u (x) (1 − H (φ)) |μj , σj
M

⎧ step :
⎪
⎪
γρB (x)u (x) (1 − H (φ)) dx
⎪
⎪
 B new
⎪
⎪
μρ
= Ω
⎪
⎪
⎪
⎪
γρB (x) (1 − H (φ)) dx
⎪
⎪
⎪
Ω
⎪
⎪

⎪

⎨
 new 2
γρB (x) u (x) − μB
(1 − H (φ)) dx
  new
ρ
⎪
Ω
B 2
⎪

σ
=
⎪
ρ
B
⎪
⎪
Ω γρ (x) (1 − H (φ)) dx
⎪
⎪

⎪
⎪
⎪
⎪
⎪
γρB (x) (1 − H (φ)) dx
⎪  new
⎪
⎪
Ω
B
⎪

=
⎩ cρ
Ω (1 − H (φ)) dx

AND check the convergence for Ω p(x|ΘB ) (1 − H (φ)) dx
(17)

where Ω H (φ) dx > 0 denotes the region(s)
of
the
foreground

inside the contour implicitly defined by φ; Ω 1 − H (φ) dx > 0
is to define the region(s) of the background outside the contour implicitly defined by φ; γαF (x) and γρB (x) are the quantities as the corresponding posterior probabilities; and the
new
, covariances ((σαF )2 )new and
means (μFα )new and (μB
ρ )
B 2 new
new
((σρ ) ) , and the mixing coefficients (cFα )new and (cB
ρ )
are the intermediate values during EM optimization.
The Heaviside function and the Dirac delta function are approximated by Hε (φ) and δε (φ) from:
⎧
1,
x>ε
⎪
⎪
⎪

⎨1


1
πx
x
Hε (x) =
1 + + sin
, |x| ≤ ε
⎪
2
ε
π
ε
⎪
⎪
⎩
0,
x < −ε
⎧



⎨ 1 1 + cos πx , |x| ≤ ε
2ε
ε
(18)
δε (x) =
⎩
0,
|x| > ε

where ε > 0 is a nonzero scalar parameter for the approximation equation, δε (φ) provides a nonzero support for the interval

LI∗ et al.: SUPERVISED VARIATIONAL MODEL WITH STATISTICAL INFERENCE AND ITS APPLICATION IN MEDICAL IMAGE SEGMENTATION

201

els’ membership to the foreground [see Fig. 2(b)] or background
[see Fig. 2(e)]. The pixels with higher gray levels have a higher
probability of belonging to each segment. After embedding the
prior estimation with the statistical estimation [see Fig. 2(f) and
(g)], we can highlight the regions to be segmented, even with
marked heterogeneity and a blurred boundary [see Fig. 2(h)].
Using the minimization of our CSG functional, we can obtain the
optimized segmentation results outlined in yellow in Fig. 2(j).
V. EXPERIMENTAL RESULTS
In this section, we present the segmentation performance of
our method when compared to the Chan–Vese level set (CV)
[5], the geodesic active contour with distance regularization
(GACD) [33], and the RW [11] by using synthetic images and
medical images from different modalities. The experiments on
synthetic images at varying levels of noise were conducted to
demonstrate the robustness of CSG over noise. Segmentation of
various ROIs from different routine clinical medical images including MR and CT images was done using the four algorithms.
For medical images, the manually segmented tissue volumes
were used as the “ground truth” to validate the accuracy of the
segmentation. In assessment of the segmentation performance,
we used the DSC for precise evaluation of the segmentation
results for clinical and synthetic images:
DSC(Is ,Im ) = 100% ×
Fig. 2. Overview of the CSG variational segmentation model shows the steps
in segmenting liver from a CT image.

[−ε, ε], and, in consequence, the Euler–Lagrange equation only
acts on the level contours φ between [−ε, ε].
Accordingly, we represent a finite differences implicit scheme
for discretization of the equation in φ as follows:
⎛
⎞

∇φ i
Fi + λδε (φi ) div |∇φ
|
i
⎠.
(19)
φi+1 = φi + Δt ⎝
+μdiv (dp (|∇φi |)∇φi )
In (19), the motion of φ would be restricted to the level
contours that are in close proximity to {φ(x) = 0} in every
iteration. It allows the Gaussian parameters optimization to be
solved in the separate regions represented as foreground and
background.
B. Algorithm Summary
Fig. 2 illustrates the schematic flowchart of our model for
segmenting a liver with multiple liver tumors on a high-contrast
CT image.
The minimization of the Dirichlet energy functional conditioned on the seeds [see Fig. 2(a)] provides the prior estimation
of each pixel’s membership for the foreground [see Fig. 2(c)]
and background [see Fig. 2(d)]. However, the prior estimation
cannot estimate the boundary with limited user input. Based on
the approximation of intensity distributions, the statistical term
calculates the probability densities of pixels to estimate the pix-

2 |Is ∩ Im |
|Is | + |Im |

(20)

where Is is the segmentation result and Im is the ground-truth
reference. A figure of 100% for segmentation accuracy is perfect
segmentation and is 0 when the segmentation and reference do
not overlap at all.
A. Experimental Data
For the synthetic image group, we built ten clean synthetic
images with matrix sizes of 300 × 300 pixels. Each clean image
contained up to four objects of different shapes, intensities, and
spatial locations. The intensity distribution of target object was
multimodal [an example shown in Fig. 5(a)]. From this group,
all the ten synthetic images were first corrupted by Gaussian
noise with zero mean and sigma = 20, then by speckle noise
with zero mean and variance 0.1, and then by random salt and
pepper noise (SPN) with a density of 0.01.
Comparison experiments were performed on different medical images that varied in uniformity, size, shape, and contrast.
We used brain tumors and the prostate gland from MR images and the liver from high-contrast CT images. We compared the segmentation accuracy of the algorithms on four
MR studies of patients with GBMs from Shandong Cancer
Hospital. For each study, two MR volumes including T1weighted images with Gd and T2-weighted images were used;
these were acquired on a 3.0T PHILIPS MR scanner. The
voxel size was 0.45 × 0.45 × 5.00 mm for T1-weighted and
0.36 × 0.36 × 7.00 mm for the T2-weighted images. The manual segmentation was performed by three experienced radiologists using transaxial slices. All results were validated and if
necessary corrected by a single expert in the final procedure.

202

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

TABLE I
DESCRIPTION FOR LIVER TUMOR NUMBERS OF TESTING DATASETS
Tumor Tum ors > = Tum ors = 8 Tum ors = 3
Num.
20
or 7
or 2
Cases
Index

Case 6, 13,
19

Case 1, 4,
10

Case 8, 15,
17

Tum ors = 1

Tum ors = 0

Case 2, 3, 9, 12, Case 5, 7, 11,
16, 18
14, 20

In the second series of experiments, we used 30 experimental
MR prostate studies from the National Cancer Imaging Archive
(abbreviation: NCIA) [36]. All these transverse T2 -weighted
MR studies were acquired on a 3.0T Siemens TrioTim using a
pelvic-phased array coil. For the NCIA datasets, the MR image
matrix size of 320 × 320 gave pixel sizes 0.60 to 0.62 mm, and
there were different interslice distances from 3.6 to 4.0 mm. For
each prostate MR study, manual segmentation was delineated
by multiple radiologists as the segmentation ground truth.
The third dataset comprised 20 enhanced CT studies from
the 3D-IRCADb (3-D Image Reconstruction for Comparison
of Algorithm Database) [37], which is utilized to evaluate the
performance of segmenting livers with/without multiple tumors.
In 20 studies, six had more than six tumors involving multiple
lobes, nine studies had three tumors or less, and five studies had
no tumor (see Table I).
For the 3D-IRCADb datasets, the CT image matrix size of
512 × 512 gave pixel sizes varying from 0.56 to 0.961 mm, and
there were different interslice distances from 1.0 to 2.4 mm. In
these high-contrast CT studies, the manual segmentation of the
various structures of interest was performed by multiple experienced radiologists using the transaxial slices [37]. With the
3D-IRCADb dataset available online, it is possible to compare
intra- and interrater variation versus the algorithm’s robustness
and accuracy.
B. Implementation
We used the CV model with the same Heaviside and Dirac
functions used in our model. GACD is an improved robust
gradient-based level set model without reinitialization [33]. For
the CV and GACD models, the initial contours are the same and
assigned inside the ROIs. The RW was based on the published
implementation by Grady [11]. To achieve numerical stability, the time step Δt in (19) for the finite difference scheme
is required to satisfy the Courant–Friedrichs–Lewy condition
μΔt < 14 that was proved by Li et al. [33]. In our experiments,
we set the time step Δt = 1 to speed up the optimization for
GACD model and our CSG model and accordingly, μ = 0.2 was
used. Smaller values of parameter ε settings would slow down
the convergence of the energy minimization but the values of ε
have a marginal effect on segmentation accuracy [8]. In practice,
ε in (18) is set as 1 [5], [8], [33] for CV, GACD, and CSG models. The parameter β = 25 in (9) was determined empirically
for our CSG model in all the experiments. Unless otherwise
specified, as reported by Grady [11], we also set β = 90 (1) for
the RW.

Fig. 3. Effect of λ for different smoothing levels on the average DSC performance on the synthetic group.

Fig. 4. DSC rates of CSG by using different M F and M B values on the 20
medical images of different image modalities.

To evaluate the segmentation performance over the smoothing
parameter λ settings (12), we conducted the accuacy analysis
over the synthetic group and for 21 different λ values (λ ∈
[0, 10 ] with the interval of 0.5). As plotted in Fig. 3, the average
of DSC varied from 98.4% to 98.9%, which indicates that the
performance is only marginally affected by λ. However, if λ is
too large, the segmentation boundary may become too smooth
and eventually fails to capture the polytropic shape of the object.
This tendency is because the effect of the function L (φ) is
to penalize the arc length of the zero level contour of φ to
keep the smoothness of the contour. Based on this experimental
investigation, we chose λ = 2 in our experimental validation,
which corresponded to the maximum DSC for this evaluation.
In the CSG model, the Gaussian mixture model was used to
approximate the intensity distribution of foreground and background. We evaluated the segmentation performance over the
parameters MF and MB of the statistical energy functional
in (11). We conducted an accuacy analysis across 20 different
medical images from our experimental datasets and five different class values (MF ∈ [2, 6] and MB ∈ [2, 6] with an interval
of 1). As plotted in Fig. 4, the averages of DSC rates varied
from 93.7% to 74.1%, which indicated that the segmentation
accuracy would be affected with the changes of MF and MB .
To achieve better segmentation accuracy, we fixed the values of
MF and MB as 3.

LI∗ et al.: SUPERVISED VARIATIONAL MODEL WITH STATISTICAL INFERENCE AND ITS APPLICATION IN MEDICAL IMAGE SEGMENTATION

203

Fig. 6. DSC (mean ± standard) comparison of CV, GACD, RW, and CSG
on the ten noisy synthetic images. Back vertical bars illustrate the standard
deviation over five different initializations.

Fig. 5. Visual segmentation comparison of the synthetic image. (a) Corrupted
synthetic image, (b) ground truth of synthetic image, (c) CV (DSC = 79.5%),
(d) GACD (DSC = 43.2%), (e) RW (DSC = 31.7%), and (f) CSG (DSC =
98.2%). The seeds and contours for foreground and background were highlighted in blue and green. The segmentation results and the ground truth were
delineated in yellow and red color.

the comparison algorithms remains the same sequence as the
average DSC. Fig. 6 showed that our method had the highest
DSC ratio, lowest standard deviation, and a higher degree of
robustness with respect to noise.
D. Comparison and Evaluation of Brain Images

All foursegmentation models used for the comparison require
initialization. Different initializations may lead to variation in
the segmentation results. To evaluate the robustness of these
segmentation models, for each test dataset, five different initializations were provided to calculate the DSC mean and standard
deviation in the following experimental comparison groups. All
comparison models and experimental evaluation were implemented with MATLAB 2011a on Window 7 operating system
and performed on a DELL desktop with Intel(R) Core(TM)
CPU, 3.10-GHz, 4-GB RAM.
C. Comparison and Evaluation Over Synthetic Images
The image shown in Fig. 5(a) is the corrupted version of the
original image in Fig. 5(b) with four different types of artifacts.
In Fig. 5(a), due to the effect of noise, the boundaries between
foreground and background in the noisy synthetic image are
blurred and have low contrast.
In this group, three foreground seeds and two background
seeds were manually chosen five times to initialize RW and
CSG algorithms [an example shown in Fig. 5(e) and (f)]. The
initial contour for CV and GACD would be determined as the
region that contains all the foreground seeds [an example is
shown in Fig. 5(c) and (d)]. The segmentation results of CV,
GACD, RW, and CSG are shown in Fig. 5(c)–(f). As illustrated
in Fig. 5(c)–(f), the effect of noise on the segmentation result
of CSG algorithm is much less when compared to the other
algorithms.
The RW had the lowest average DSC of 45.6%. The GACD
model produced the average segmentation DSC of 71.5%, it
was 78.5% for CV, and 98.6% for CSG. The comparison of
the four segmentation models for the noisy synthetic image is
shown in Fig. 6. The individual DSC rate of each image for all

We compared the four algorithms for four patients’ brain MR
studies. These MR images had obvious heterogeneous intensity, and there was also marked heterogeneity with regions of
increased and reduced signal intensity consistent with regions
of active tumor and necrosis. For each MR brain test volume,
50 foreground seeds and 100 background seeds were randomly
chosen five times to initialize the RW and CSG algorithms, and
two examples are shown in Fig. 7(c) and (d). The initial region
was automatically determined by the region to contain the maximum number of the foreground seeds [two examples in Fig. 7(a)
and (b)].
The comparison is shown in Table II. CV produced the lowest
average DSC of 50.2%; GACD was 56.0%, the RW was 81.4%,
and CSG was 90.1%. Besides, CSG achieved the lowest standard
deviation across all the testing datasets in this group.
Two typical examples are visualized as below. As shown in
Fig. 7, the brain tumors in the two examples had markedly different intensities; in addition, the tumor region had poorly defined
boundaries where the intensity values were close to those of the
neighboring pixels. As shown in Fig. 7(a), the CV model was
unable to produce accurate segmentation. In Fig. 7(b), GACD
was unable to reach the true boundaries of the brain tumors.
In Fig. 7(c), the segmentation boundary produced by the RW
failed to capture the geometric features of the ROIs. In comparison, the boundaries delineated by our CSG [see Fig. 7(d)] were
the closest to the manual segmentation of all the models evaluated even when the foreground had markedly heterogeneous
regions.
E. Comparison and Evaluation Over Prostate MR Images
Similar to MR brain images, these MR images were corrupted
by bias field. The prostate gland has a peripheral zone and central

204

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

TABLE II
DSC ACCURATE RATES (MEAN ± STANDARD) OF FOUR SEGMENTATION
MODELS ON MR BRAIN TUMOR IMAGES
DSC Mean ± SD

All Datasets

CV

GACD

RW

CSG

50.2% ±
15.6%

56.0% ±
12.2%

81.4% ±
8.5%

90.1% ±
3.3%

Fig. 8. DSC (mean ± standard) comparison of CV, GACD, RW, and CSG on
the 30 prostrate MR datasets. Back vertical bars illustrate the standard deviation
over five different initializations.

On the average of DSC accuracy rate, the CV produced the
lowest average DSC of 35.6%; GACD was 71.9%; RW was
79.3%, and our CSG achieved 92.7%. The comparison of the
four segmentation models over each MR testing dataset is illustrated inFig. 8. Our CSG algorithms had the highest DSC ratios
over the each testing dataset and demonstrated a higher degree
of robustness in term of the lowest standard deviations in Fig. 8.
To compare our CSG model with the other three models, the
two examples of MR prostate images were chosen to visualize
the performance of the four algorithms shown in Fig. 9. The
CV algorithm delineated the region with relatively higher intensity range, which often belongs to peripheral zone as shown in
Fig. 9(a). The segmentation contours from GACD [see Fig. 9(b)]
leaked out of the manual contour or were blocked by the inconspicuous gradients. By visualizing the results in Fig. 9(c), RW
delineated the jagged segmentation boundaries of prostate region and would leak out of the true contours if the central gland
and the neighboring regions have similar intensities. Compared
to the other three models, the results from our model were consistent with the manual contours of the prostate regions [see
Fig. 9(d)], even when the prostate regions had heterogeneous
intensities and were surrounded by blurred boundaries.
Fig. 7. Comparison of brain tumor segmentation: (a) CV, (b) GACD, (c) RW,
and (d) CSG. The initial seeds and contours represent foreground (blue) and
background (green). The segmentation results by the methods tested and manual
segmentation were delineated in yellow and red color.

zone, where intensities differ. We placed 50 foreground seeds
and 100 background seeds randomly five times to determine the
initializations of all the algorithms for each prostate MR test
volume.

F. Comparison and Evaluation for CT Liver Images
We found that in abnormal liver segmentation, there are heterogeneities and blurred boundaries. Since there are often more
than 150 slices of each CT volume containing the liver region,
350 foreground seeds and 400 background seeds between liver
and the other tissues were randomly chosen five times to determine the initializations for the comparison algorithms over CT
testing volume.

LI∗ et al.: SUPERVISED VARIATIONAL MODEL WITH STATISTICAL INFERENCE AND ITS APPLICATION IN MEDICAL IMAGE SEGMENTATION

205

Fig. 9. Visual MR prostate segmentation comparison by using (a) CV, (b) GACD, (c) RW, and (d) CSG. The initial seeds and contours were for foreground
(blue) and background (green). The segmentation results by the methods tested and manual segmentation were delineated in yellow and red color.
TABLE III
DSC (MEAN ± SD) OF FOUR MODELS ON CT LIVER SEGMENTATION
DSC Mean ± SD

20 CT Datasets

CV

GACD

RW

CSG

65.8% ± 4.7%

81.3% ± 3.6%

68.6% ± 4.1%

94.5% ± 0.6%

Table III and Fig. 10 show the DSC comparison for the liver
segmentation. CSG had the highest mean DSC at 94.5%, GACD
was 81.3%, and RW was 68.6%. The CV produced the lowest
mean DSC of 65.8 and the highest DSC standard deviation
of 4.7%; in contrast, our CSG produced the lowest standard
deviation at 0.6% over the 30 testing datasets. Hence, our model
was robust and consistent across all the test datasets and was
less sensitive to the initialization and different test datasets than
the other models.
Two different images were chosen to visualize the liver segmentation performance of thefour models from CT volumes.
As shown in Fig. 11, the first row of image had markedly heterogeneous intensities in the foreground and background. The
foreground region had poorly defined boundaries where the intensity values were similar to those of the neighboring pixels in
the second row of image of Fig. 11. CV produced lower mean
intensity value than true mean intensity value of liver region in
CT volume. As a consequence, the contour produced by CV
model expanded out of the liver region shown in Fig. 11(a). For
the GACD model, the contours were blocked by the spurious
gradients in the foreground heterogeneous region shown in the
first row of Fig. 11(b) or edge energy pushed the contour leaking out of weak boundaries of liver regions shown in the second

Fig. 10. DSC comparison of CV, GACD, RW, and CSG on 20 clinical 3DIRCADb datasets. Back vertical bars illustrate the standard deviation over six
different initializations.

row of Fig. 11(b). For the RW, insufficient seeds resulted in
unacceptable liver segmentation results shown in Fig. 11(c).
Compared to the other three models, Fig. 11(d) demonstrated
that the results from our CSG model were consistent with the
manual contours of liver regions.
VI. DISCUSSION
The two major challenges for medical image segmentation
are heterogeneous intensities in the images and blurred boundaries between structures. The heterogeneous intensities result
in spurious gradients inside the ROI and multimodal intensity
distributions in foreground and background regions. Due to the
low contrast in the neighboring structures, blurred boundaries
lead to difficulty in assigning the pixels with similar intensity values to true segments. Our statistical energy functional
can better approximate the multimodal intensity distribution for
the issue of heterogeneous intensities. By integrating the prior

206

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

Fig. 11. Visual CT liver segmentation comparison by using (a) CV, (b) GACD, (c) RW, and (d) CSG. The initial seeds and contours for foreground and background
were outlined in blue and green. The segmentation results by the methods tested and manual segmentation were delineated in yellow and red color.

probability map with a statistical functional, our energy functional is able to distinguish the pixels with marginal different intensity values. Experimental evaluation and comparison across
58 different clinical datasets and ten synthetic images showed
that our CSG approach performed better than the three conventional methods.
Our comparisons of the four models showed that the CV
produced the lowest DSC because the intensity PCs used in
the CV model were not able to sufficiently describe the regions
with heterogeneous intensities. Compared to CV, the multiphase
level set functions [7] produced better segmentation, but it is
impractical to initialize multiple initial regions corresponding
to every segment in a medical image. Compared with the CV
model, GACD produced segmentation results with improved
accuracy because an analysis of the boundary condition was
taken into account. However, the spurious gradients of the brain
tumor, prostate, and liver regions prevented the edge energy of
GACD from reaching the true boundary or trapped it in a local
minimum.
Compared to GACD, on average, the RW generated more
accurate segmentation for MR brain tumors, but lower accuracy for the liver CTs. It is interesting to note that the DSC
dropped around 13% when segmenting the livers. This is because the liver region is much larger than either a prostate or
a brain tumor, with similar amount of seeds; the percentage of
labeled pixels to the unlabeled pixels for the liver would be
much lower than that of the prostate. This lower percentage of
labeled pixels has an impact on the minimization of Dirichlet
energy functional conditioned on boundary conditions and consequently led to reduced segmentation accuracy for the livers.
Besides, the RW produced the lowest DSC when segmenting
noisy synthetic images since the noise significantly reduced the

calculation precision of the conventional weighted function (5)
and therefore dramatically suppressed the performance of RW
for the noisy images.
Compared to the region-based supervised algorithms including CV and the RW, our CSG model more completely approximated the intensity distributions of segments and optimizes
the statistical term with the prior probability map and therefore
produced better segmentation results. As shown in the evaluation over the five different initializations, our CSG algorithm
consistently produced more accurate segmentations of the
datasets with marked heterogeneity and blurred boundaries.
Compared to the other three models, the CSG did not completely rely on the limited information from the user inputs. We
utilized the user intention to produce a prior probability map
to emphasize the spatial location of the ROI for the statistical term. To produce a more accurate segmentation boundary,
the mixture-of-mixtures model was formulated in our statistical
term to approximate more complete intensity distributions of the
foreground and background. Moreover, as depicted in Figs. 7, 9,
and 11, our model can better control the boundary smoothness
to adhere to the geometric change of the ROI in the medical
images, compared to the graph-based algorithms, such as RW.
VII. CONCLUSION
Our new supervised variational model unifies and optimizes
the statistical intensity functional with the prior probability map
to achieve more accurate and smoother medical image segmentation. The statistical functional can solve the approximation of
multimodal intensity distributions for the foreground and background, and the prior probability map distinguishes the regions
with marginal differences among mixture-of-mixtures model.

LI∗ et al.: SUPERVISED VARIATIONAL MODEL WITH STATISTICAL INFERENCE AND ITS APPLICATION IN MEDICAL IMAGE SEGMENTATION

Experimental validations showed that our segmentation model
provided a more general solution to segment medical image
of different modalities and produced more robust and accurate
results when segmenting images with complex multimodal intensity distributions, noisy artifacts, and weak and ambiguous
boundaries. The experimental comparisons demonstrated that
our model outperformed the other three state-of-the-art models
in terms of segmentation accuracy and robustness over different
medical images and synthetic images.
REFERENCES
[1] S. Osher and J. Sethian, “Fronts propagating with curvature-dependent
speed: Algorithms based on Hamilton-Jacobi formulations,” J. Comput.
Phys., vol. 79, pp. 12–49, Nov. 1988.
[2] V. Caselles, R. Kimmel, et al., “Geodesic active contours,” Int. J. Comput.
Vis., vol. 22, pp. 61–79, 1997.
[3] R. Malladi, J. A. Sethian, and G. Sapiro “Shape modeling with front
propagation: A level set approach,” IEEE Trans. Pattern Anal. Mach.
Intell., vol. 17, no. 2, pp. 158–175, Feb. 1995.
[4] R. H. Davies, C. J. Twining, T. F. Cootes, and C. J. Taylor, “Building 3-D
statistical shape models by direct optimization,” IEEE Trans. Med. Imag.,
vol. 29, no. 4, pp. 961–981, Apr. 2010.
[5] T. F. Chan and L. A. Vese, “Active contours without edges,” IEEE Trans.
Image Process., vol. 10, no. 2, pp. 266–277, Feb. 2001.
[6] M. Rousson and R. Deriche, “A variational framework for active and
adaptative segmentation of vector valued images,” in Proc. Workshop
Motion Video Comput., 2002, pp. 56–61.
[7] L. Vese and T. Chan, “A multiphase level set framework for image segmentation using the Mumford and Shah model,” Int. J. Comput. Vis.,
vol. 50, pp. 271–293, Dec. 2002.
[8] C. Li, X. Wang, S. Eberl, M. Fulham, and D. Feng, “A new energy
framework with distribution descriptors for image segmentation,” IEEE
Trans. Image Process., vol. 22, no. 9, pp. 3578–3590, Sep. 2013.
[9] C. Li, X. Wang, S. Eberl, M. Fulham, Y. Yong, C. Jinhu, and D. Feng, “A
likelihood and local constraint level set model for liver tumor segmentation
from CT volumes,” IEEE Trans. Biomed. Eng., vol. 60, no. 10, pp. 2967–
2977, Oct. 2013.
[10] Y. Boykov and V. Kolmogorov, “An experimental comparison of mincut/max- flow algorithms for energy minimization in vision,” IEEE Trans.
Pattern Anal. Mach. Intell., vol. 26, no. 9, pp. 1124–1137, Sep. 2004.
[11] L. Grady, “Random walks for image segmentation,” IEEE Trans. Pattern
Anal. Mach. Intell., vol. 28, no. 11, pp. 1768–1783, Nov. 2006.
[12] D. Cremers, M. Rousson, and R. Deriche, “A review of statistical approaches to level set segmentation: Integrating color, texture, motion and
shape,” Int. J. Comput. Vis., vol. 72, pp. 195–215, 2007.
[13] T. Kanungo, D. M. Mount, N. S. Netanyahu, C. D. Piatko, R. Silverman,
and A. Y. Wu, “An efficient k-means clustering algorithm: Analysis and
implementation,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 24, no. 7,
pp. 881–892, Jul. 2002.
[14] M. N. Ahmed, S. M. Yamany, N. Mohamed, A. A. Farag, and T. Moriarty, “A modified fuzzy c-means algorithm for bias field estimation and
segmentation of MRI data,” IEEE Trans. Med. Imag., vol. 21, no. 3, pp.
193–199, Mar. 2002.
[15] A. K. Jain, R. P. W. Duin, and M. Jianchang, “Statistical pattern recognition: A review,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 22, no. 1,
pp. 4–37, Jan. 2000.
[16] D. Mumford and J. Shah, “Optimal approximations by piecewise smooth
functions and associated variational problems,” Commun. Pure Appl.
Math., vol. 42, pp. 577–685, 1989.
[17] A. Tsai, A. Yezzi, and A. S. Willsky “Curve evolution implementation of
the Mumford-Shah functional for image segmentation, denoising, interpolation, and magnification,” IEEE Trans. Image Process., vol. 10, no. 8,
pp. 1169–1186, Aug. 2001.

207

[18] C. Li, R. Huang, Z. Ding, J. Gatenby, D. N. Metaxas, and J. C. Gore,
“A level set method for image segmentation in the presence of intensity
inhomogeneities with application to MRI,” IEEE Trans. Image Process.,
vol. 20, no. 7, pp. 2007–2016, Jul. 2011.
[19] C. Li, X. Wang, S. Eberl, M. Fulham, and D. Feng, “Robust model for
segmenting images with/without intensity inhomogeneities,” IEEE Trans.
Image Process., vol. 22, no. 8, pp. 3296–3309, Aug. 2013.
[20] S. Z. Li, “Modeling image analysis problems using Markov random fields,”
in Handbook of Statistics. New York, NY, USA: Elsevier, 2000.
[21] B. Sandberg, K. Sung Ha, and T. F. Chan, “Unsupervised multiphase
segmentation: A phase balancing model,” IEEE Trans. Image Process.,
vol. 19, no. 1, pp. 119–130, Jan. 2010.
[22] K. Sunhee and K. Myungjoo, “Multiple-region segmentation without supervision by adaptive global maximum clustering,” IEEE Trans. Image
Process., vol. 21, no. 4, pp. 1600–1612, Apr. 2012.
[23] M. E. Leventon, W. E. L. Grimson, and O. Faugeras “Statistical shape
influence in geodesic active contours,” in Proc. IEEE Conf. Comput. Vis.
Pattern Recognit., 2000, pp. 316–323.
[24] N. Paragios and R. Deriche, “Geodesic active regions and level set methods for supervised texture segmentation,” Int. J. Comput. Vis., vol. 46,
pp. 223–247, 2002.
[25] K. C. Ciesielski, P. A. V. Miranda, A. X. Falcão, and J. K. Udupa, “Joint
graph cut and relative fuzzy connectedness image segmentation algorithm,” Med. Image Anal., vol. 17, pp. 1046–1057, Dec. 2013.
[26] X. Chen and U. Bagci, “3D automatic anatomy segmentation based on
iterative graph-cut-ASM,” Med. Phys., vol. 38, pp. 4610–4622, 2011.
[27] C. Alvino, G. Unal, G. Slabaugh, B. Peny, and T. Fang, “Efficient segmentation based on Eikonal and diffusion equations,” Int. J. Comput. Math.,
vol. 84, pp. 1309–1324, 2007.
[28] C. Couprie, L. Grady, L. Najman, and H. Talbot, “Power watershed: A
unifying graph-based optimization framework,” IEEE Trans. Pattern Anal.
Mach. Intell., vol. 33, no. 7, pp. 1384–1399, Jul. 2011.
[29] Y. Wenxian, C. Jianfei, Z. Jianmin, and L. Jiebo, “User-friendly interactive
image segmentation through unified combinatorial user inputs,” IEEE
Trans. Image Process., vol. 19, no. 9, pp. 2470–2479, Sep. 2010.
[30] V. Vezhnevets and V. Konouchine, ““GrowCut”—Interactive multi-label
N-D image segmentation by cellular automata,” in Proc. Int. Conf. Comput. Graphics Vision, 2005, pp. 150–156.
[31] R. P. Browne, P. D. McNicholas, and M. D. Sparling, “Model-based learning using a mixture of mixtures of Gaussian and uniform distributions,”
IEEE Trans. Pattern Anal. Mach. Intell., vol. 34, no. 4, pp. 814–817, Apr.
2012.
[32] J. Besag, “Spatial interaction and the statistical analysis of lattice systems,”
J. Roy. Statist. Soc. Ser. B Statist. Methodol., vol. 36, pp. 192–236, 1974.
[33] C. Li, C. Xu, and M. D. Fox, “Distance regularized level set evolution and
its application to image segmentation,” IEEE Trans. Image Process., vol.
19, no. 12, pp. 3243–3254, Dec. 2010.
[34] T. K. Moon, “The expectation-maximization algorithm,” IEEE Signal
Process. Mag., vol. 13, no. 6, pp. 47–60, Nov. 1996.
[35] G. Aubert and P. Kornprobst, Mathematical Problems in Image Processing: Partial Differential Equations and the Calculus of Variations,
vol. 147, 2nd ed. New York, NY, USA: Springer-Verlag, 2006.
[36] T. C. I. Archive. (2012). NCI-ISBI 2013 Challenge—Automated Segmentation of Prostate Structures. [Online: Available: https://wiki.
cancerimagingarchive.net/display/Public/Prostate-3T
[37] L. Soler, A. Hostettler, V. Agnus, A. Charnoz, J.-B. Fasquel, J. Moreau,
A.-B. Osswald, M. Bouhadjar, and J. Marescaux, (2010). 3D image reconstruction for comparison of algorithm database: A patient-specific
anatomical and medical image database. [Online]. Available: http://wwwsop.inria.fr/geometrica/events/wam/abstract-ircad.pdf.

Authors’ photographs and biographies not available at the time of publication.

