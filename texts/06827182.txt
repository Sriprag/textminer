668

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 2, MARCH 2015

An Effective Ultrasound Video Communication
System Using Despeckle Filtering and HEVC
Andreas S. Panayides, Member, IEEE, Marios S. Pattichis, Senior Member, IEEE,
Christos P. Loizou, Senior Member, IEEE, Marios Pantziaris, Anthony G. Constantinides, Fellow, IEEE,
and Constantinos S. Pattichis, Senior Member, IEEE

Abstract—The recent emergence of the high-efficiency video coding (HEVC) standard promises to deliver significant bitrate savings over current and prior video compression standards, while
also supporting higher resolutions that can meet the clinical acquisition spatiotemporal settings. The effective application of HEVC
to medical ultrasound necessitates a careful evaluation of strict
clinical criteria that guarantee that clinical quality will not be sacrificed in the compression process. Furthermore, the potential use
of despeckle filtering prior to compression provides for the possibility of significant additional bitrate savings that have not been
previously considered. This paper provides a thorough comparison
of the use of MPEG-2, H.263, MPEG-4, H.264/AVC, and HEVC
for compressing atherosclerotic plaque ultrasound videos. For the
comparisons, we use both subjective and objective criteria based
on plaque structure and motion. For comparable clinical video
quality, experimental evaluation on ten videos demonstrates that
HEVC reduces bitrate requirements by as much as 33.2% compared to H.264/AVC and up to 71% compared to MPEG-2. The
use of despeckle filtering prior to compression is also investigated
as a method that can reduce bitrate requirements through the
removal of higher frequency components without sacrificing clinical quality. Based on the use of three despeckle filtering methods
with both H.264/AVC and HEVC, we find that prior filtering can
yield additional significant bitrate savings. The best performing
despeckle filter (DsFlsmv) achieves bitrate savings of 43.6% and
39.2% compared to standard nonfiltered HEVC and H.264/AVC
encoding, respectively.
Index Terms—Bitrate gains, clinical evaluation, despeckle filtering, encoding, high efficiency video coding (HEVC), H.264/AVC,
mHealth, video quality assessment (VQA).

I. INTRODUCTION

T

HE new high-efficiency video coding (HEVC) standard
is expected to revolutionize mobile health (mHealth)

Manuscript received March 7, 2014; revised May 21, 2014; accepted May 2,
2014. Date of publication June 6, 2014; date of current version March 2, 2015.
This work was supported by the Marie Curie Actions—Intra European Fellowships (IEF), FP7-PEOPLE-2011-IEF call, 301476, under the “Diagnostically
Robust Ultrasound Video Transmission over Emerging Wireless Networks”DRIVEN project.
A. S. Panayides and A. G. Constantinides are with the Department of Electrical and Electronic Engineering, Imperial College London, London, SW7 2AZ,
U.K. (e-mail: a.panagidis@imperial.ac.uk; a.constantinides@imperial.ac.uk).
M. S. Pattichis is with the Department of Electrical and Computer Engineering, University of New Mexico, Albuquerque, NM 87131 USA (e-mail:
pattichis@ece.unm.edu).
C. P. Loizou is with the Department of Computer Science, Intercollege, 3507
Limassol, Cyprus (e-mail: loizou.c@lim.intercollege.ac.cy).
M. Pantziaris is with the Department of Neurology, Cyprus Institute of Neurology and Genetics, 1683 Nicosia, Cyprus (e-mail: pantzari@cing.ac.cy).
C. S. Pattichis is with the Department of Computer Science, University of
Cyprus, 1678 Nicosia, Cyprus (e-mail: pattichi@ucy.ac.cy).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2329572

medical video communication systems [1]. Specifically designed for beyond high-definition (HD) video coding [2], HEVC
supports real-time transmission of medical video at the acquired
in-hospital resolution and frame rates. The latter is expected to
play a key role in the adoption of HEVC-based mHealth video
systems and services in standard clinical practice by eliminating
spatiotemporal conversions that could limit clinical capacity.
Ultrasound video exhibits significant levels of speckle that
are inherent in the ultrasound imaging process itself. Significant
levels of speckle noise can compromise medical video image
quality and require the moderate use of despeckle filtering that
does not compromise diagnostic quality through overfiltering.
Thus, the use of despeckle filtering prior to video compression
provides an opportunity to improve quality while also lowering
bandwidth requirements by reducing noisy components from
higher frequency components.
The need to guarantee the diagnostic capacity of the communicated clinical content motivates the development of diagnostically driven mHealth systems. The use of diagnostic region(s) of
interest (d-ROI) allows us to allocate bitrate budgets based on diagnostic capacity. As demonstrated in [3]–[5], the use of d-ROI
can provide significant bitrate gains. Furthermore, d-ROI can
be protected more strongly during transmission in error-prone
wireless networks as discussed in [3], [6], and [7]. Diagnostically resilient encoding and decoding described in [4] and [8]
provides support for effective mHealth video communications
in noisy channels.
Unfortunately, the quality of the compressed videos requires
medical expert verification and cannot be done automatically.
The development of new clinical video quality assessment
(c-VQA) algorithms is a necessary prerequisite for the wider
adoption of modern mHealth video communication systems in
standard clinical practice [1]. At the same time, the timely integration of new compression and wireless technologies enhances
the capacity of mHealth systems to accommodate diagnostically robust architectures and expedites utilization in standard
clinical care.
This is also highlighted in a preliminary study reported by
our group in [9], where the HEVC was shown to outperform the
d-ROI approach described in [4] that used H.264/AVC. We also
published another preliminary study on the use of HEVC for
reproducible clinical diagnosis in mHealth systems in a recent
conference paper in [10]. Similarly, preliminary results on the
use of despeckle filtering were published in conference papers
in [11] and [12]. A wide range of despeckle filtering methods
have been summarized in [13] and [14].

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

PANAYIDES et al.: AN EFFECTIVE ULTRASOUND VIDEO COMMUNICATION SYSTEM USING DESPECKLE FILTERING AND HEVC

669

Fig. 1. Ultrasound video encoding and evaluation system diagram. Ultrasound video denoising precedes video encoding. The user can select the appropriate
despeckle filtering algorithm and the most efficient video compression standard. VQA includes clinical evaluation by the relevant medical expert as well as
objective measurements. Despeckle filtering methods and video coding standards comparison provides the bitrate gains achieved by the best performing methods.

The paper has two objectives as reflected in the system diagram of Fig. 1. The first objective is to examine the effectiveness
of the use of despeckle filtering prior to encoding. The second
objective is to investigate the efficiency of the HEVC standard
for ultrasound video communications, while performing a comprehensive comparison to other video coding standards. Experimental evaluation is based on 1) full reference video quality
assessment (VQA) algorithms [e.g., peak signal-to-noise ratio
(PSNR) and structure similarity (SSIM)], 2) bitrate requirements
and resulting bitrate gains of the assessed methods following
comparison using the Bjontegaard metric (BD-rate), and 3) clinical evaluation of ultrasound videos compressed using different
methods by a neurovascular specialist.
The contributions of this paper are summarized under three
areas.
1) Despeckle filtering for ultrasound video communication
mHealth systems: Here, we investigate the use of despeckle filtering as a preprocessing step to ultrasound
video coding and transmission. The aim is to document
significant coding efficiency attributed to the use of despeckle filtering algorithms without compromising clinical capacity of the communicated ultrasound video.
2) Video coding standards comparison for ultrasound video
communications: The emerging HEVC standard is compared against its predecessor, the H.264/AVC standard, and also MPEG-4, MPEG-2, and H.263. Results are documented using both VQA metrics and a
clinical-VQA protocol for ultrasound-based assessment of
atherosclerosis.
3) Clinical evaluation using a clinically established protocol: Clinical evaluation is based on a clinically established protocol that reflects the assessment of in-hospital
atherosclerotic plaque ultrasound examinations. Clinical
criteria evaluate a) artery stenosis by assessing atherosclerotic plaque structure, b) atherosclerotic plaque type
by assessing atherosclerotic plaque morphology, and c)
atherosclerotic plaque motion patterns by assessing clinical motion of within plaque, boundary, and artery motions.
Clinical motion criterion is used for the first time in medical video communication mHealth systems evaluation.
The rest of this paper is organized as follows. Section II
provides a brief overview of video coding standards evolution,

while Section III summarizes the methodology, including the examined ultrasound video despeckle filtering algorithms. Section
IV discusses the experimental results analysis. Finally, Section
V highlights the potential impact of the depicted results and
provides some concluding remarks.
II. VIDEO CODING: FROM H.261 TO HEVC
We provide a brief overview of the capabilities and motivation
behind the video coding standards that are considered in the
current paper. We then provide a summary of the important
new features that were recently introduced in the new HEVC
standard.
The standard use of earlier video coding standards suffers from limited options of spatial resolutions. For example, H.261 [15] supports the common intermediate format
(CIF = 352 × 288) that was later extended to 16CIF (1408 ×
1152) in H.262/MPEG-2 [16]. H.262/MPEG-2 is still widely
used for satellite TV broadcasting and DVD storage. H.263 introduced in 1995 provided for improved quality at lower bit
rates and also allowed lower, sub-QCIF (128 × 96) video resolution encoding [17]. Significant coding tools improvements
over H.262/MPEG-2 include multiple reference pictures, scalability support, and the introduction of error resilience tools that
are essential for wireless medical video communications.
Compared to prior standards, H.264/AVC design tackles heterogeneous networks transportation. More specifically,
H.264/AVC defines a video coding layer (VCL) and a network abstraction layer (NAL) [18]. The VCL enrichment with
new coding tools (such as slice-based bi-predictive coding and
context-adaptive binary arithmetic coding (CABAC) for entropy
coding) and refinement of intra/intercoding, documents 50%
bitrate demands reductions for perceptually equivalent quality
compared to its predecessors [19]. CABAC has become standard
for HEVC.
H.264/AVC provides error resilience techniques for communications in noisy wireless channels used in m-Health
systems. Error resilient methods include the use of multiple reference pictures, flexible macroblock ordering (FMO)
(widely used in diagnostic-ROI systems), redundant slices, arbitrary slice ordering (ASO), data partitioning, and switchingpredictive/switching-intra pictures.

670

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 2, MARCH 2015

HEVC was launched in 2013 by the Joint Collaborative Team
on Video Coding [20]. In terms of motion estimation, HEVC
includes advanced motion vector prediction and merge mode for
motion vector signaling and substantially enhanced intraprediction extending directional modes to 33 (from 8 in H.264/AVC).
HEVC defines three parallel encoding schemes, namely tiles,
wavefront parallel processing (WPP), and dependent slices.
Tiles allow independent parallel decoding of rectangular regions. Despite the fact that tiles appear similar to the H.264/AVC
FMO concept, their primary objective is to expedite parallel decoding rather than provide for error resilience. WPP facilitates
parallel processing of CTUs rows composing a slice. Dependent
slices concept provides for a wavefront entry point or tile to be
assigned to different NAL units, thus potentially speeding up the
coding process. Parallel processing will significantly contribute
to beyond HD real-time video streaming, one of the primary
objectives of the HEVC standardization efforts. HEVC supports ultra-HD 8k × 4k (7680 × 4320) and up to 8192 × 4320
video resolutions compared to 4k × 2K (4096 × 2048 and
4096 × 2304 for 16:9 aspect ratio) in H.264/AVC. By supporting much higher resolutions, HEVC allows encoding of clinical
video at the original in-hospital resolution.
III. METHODOLOGY
The basic system diagram is presented in Fig. 1. Despeckle
filtering is applied prior to video compression to improve quality
while reducing bandwidth requirements. The filtered image is
then encoded using a variety of different standards and then
decoded in order to allow for comparisons with the original
video. Validation of the system includes objective VQA, clinical
evaluation based on mean opinion scores (MOS), and methods
comparison to determine bitrate gains. We provide details on
each component below.
A. Despeckle Filtering
We briefly introduce the despeckle filters used in this study
and discuss how they impact video compression by reducing
higher frequency content. For implementation details, we refer to [13]. The three despeckle filters used in this study were
selected among ten different despeckle filtering techniques investigated in [12]–[14]. More specifically, the considered filters
achieved the best performance in terms of visual (clinical) quality as assessed by medical experts [12]–[14], edge and texture
preservation, and image quality evaluation performance [14].
1) Linear Despeckle Filtering (DsFlsmv): The DsFlsmv filter which utilizes first order statistics of the image, such as the
variance and the mean of a pixel neighborhood is based on a
multiplicative noise model [13], [14]. The despeckled image is
estimated using
fi,j = ḡ + ki,j (gi,j − ḡ)

(1)

where fi,j denotes the despeckled image, gi,j denotes the input
image, ḡ is the local mean over a local window, and ki,j is a
weighting factor. The weighting factor ki,j ∈ [0, 1] is estimated

based on local image statistics as follows [13], [14]:
  


ki,j = 1 − ḡ 2 σ 2 / σ 2 1 + σn2 .

(2)

The values σ 2 and σn2 represent the variance in the moving
window and the variance of noise in the whole image frame,
respectively. The noise variance σn2 can be estimated for each
video frame based on the average noise variance over a number of windows with dimensions considerable larger than the
filtering window. The local averages are applied using a moving
window of size 5 × 5 and the filter is applied twice over the
input image. In (1), weighting factor ki,j varies between zero
and one. At near zero values, the output will be dominated by
the mean value which is highly compressible since it can be
effectively represented by the dc component. On the other hand,
since the weighting factor remains at or below 1, deviation from
the mean value will never be as high as in the original image.
2) Hybrid Median Filtering (DsFhmedian): DsFhmedian
[21] computes the average of the outputs generated by median filtering with three different window shapes (cross shape,
x-shape, and square windows of 5 × 5 pixels). As for DsFlsmv,
the filtered image is a smoothed average that suppresses higher
frequency content from the original input image.
3) Speckle Reducing Anisotropic Diffusion Filtering
(DsFsrad): Speckle reducing anisotropic diffusion attempts to
smooth image content within uniform regions while avoiding
smoothing across edges [22]. The smoothed equation is based
on
fi,j = gi,j +

1
div (srad (|∇g |) ∇gi,j )
ns

(3)

where the diffusion coefficient for the speckle anisotropic diffusion, srad (|∇g |), is used to discourage smoothing across edges.
Refer to [14] for implementation details. Clearly, DsFsrad attempts to improve over DsFlsmv by preserving edge structures.
Yet, as for DsFlsmv, DsFsrad will smooth regions and remove
higher frequency content.
B. Video Coding Standards Comparison
The highest efficiency modes are selected for each encoding standard as given in [23]. Indicatively, for HEVC, all new
coding tools are enabled—except weighted prediction—as per
the single defined profile in the standard termed Main Profile
(HEVC MP). For H.264/AVC the High Profile was selected
(H.264/AVC HP), also with weighted prediction disabled. For
MPEG-4 the Advanced Simple Profile (MPEG-4 ASP) was
used, while the Conversational High Compression was selected
for H.263 (H.263 CHC), and finally, the Main Profile was used
for MPEG-2/H.262 (MPEG-2 MP). For a fair comparison, we
vary the quantization parameters to achieve a similar range of
rate-distortion performance for all standards. Furthermore, the
quantization parameter step size is selected so that a single step
results in PSNR increase of approximately 3 dB. More specifically, for MPEG-2, MPEG-4, and H.263, ultrasound videos are
encoded using QPs ranging from 2 to 31 using QP = 2, 3, 4, 5,
6, 8, 10, 13, 16, 20, 25, 31, while for H.264/AVC and HEVC
QPs range between 20 and 42, with a QP step size of 2. For

PANAYIDES et al.: AN EFFECTIVE ULTRASOUND VIDEO COMMUNICATION SYSTEM USING DESPECKLE FILTERING AND HEVC

671

all cases, 200 frames per video sequence were encoded and an
intraencoded frame (I-frame) was inserted every 48 frames.
C. Video Quality Assessment
We consider the PSNR and the SSIM [24] for assessing video
quality. Here, we note that the average PSNR and SSIM are
computed over each video frame [25] and then averaged over
the entire video. Both the PSNR and the SSIM are full reference methods that require access to the original, uncompressed
videos. For evaluating image quality, SSIM correlates significantly better to perceived, visual quality than the standard use
of PSNR [26]. However, it does not assess the motion of the
reconstructed videos as required in our application. The subject
of VQA is still an open area of research. For our application, we
use extensive clinical VQA methods to properly address these
issues.
D. Rate-Distortion Comparisons
To estimate bitrate savings, we compute the percentage savings for equivalent (objective) video quality. This is accomplished using the BD-rate algorithm [27]. The BD-rate algorithm is used to compute the objective differences between two
rate-distortion curves and provides the percentage bitrate difference. The rate-distortion curves for the compared methods
are constructed as functions of 12 rate points based on the luma
PSNR (Y-PSNR). The final percentage difference is averaged
over the examined dataset.
E. Clinical Video Quality Assessment
c-VQA aims to address the diagnostic quality of the reconstructed videos. There are three d-ROI that are considered here.
1) Atherosclerotic plaque region: This is the primary d-ROI
(see caption in Fig. 2) and it is used to determine the
plaque’s type by assessing the plaque’s morphology and
texture characteristics.
2) Near and far wall regions: Visualizing the artery walls
and associated motions are needed for the assessment of
the degree of stenosis. Moreover, the motion differences
between the arteries and atherosclerotic plaque(s) can be
associated with plaque instability.
3) ECG region for visualizing ECG waveform: The ECG
region is needed for measuring how stenosis and motion
patterns of different plaque components change during the
cardiac cycle.
Based on the aforedescribed clinically sensitive regions, the
following c-VQA criteria are used for establishing the reproducibility of the diagnosis.
1) The degree of the artery stenosis: The percentage of the
artery that is blocked by the plaque’s presence, obscuring
blood flow. Significant stenosis can be associated with
stroke events.
2) The plaque’s morphology [28]: The appearance of the
plaque can be used to determine the plaque’s type and infer
the possible composition of the plaque. The composition

Fig. 2. Original and despeckled ultrasound images examples. Near and far
wall atherosclerotic plaque segmentation (outlined by the white lines) using the segmentation algorithm described in [30]. (a) Original, (b) DsFlsmv,
(c) DsFhmedian, and (d) DsFsrad. Note that the subtle differences between
the despeckled and original image are difficult to detect which indicates that
the moderate amount of despeckling used here removes higher frequencies that
are not easily detected by the HVS (as desired). They become visible when the
clinicians zoom into the regions of interest.

672

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 2, MARCH 2015

of the plaque provides critical information on the risk
factors associated with stroke events.
3) The plaque’s and artery walls motion characteristics:
Plaque motion stability can be classified as concordant
or discordant and be used as a potential risk factor as described in [29]. Here, we note that discordant motion is
associated with instability. On the other hand, stiff plaques
exhibit concordant motion and tend to be safer. Significant
differences between plaque and arterial wall motions can
also be used as an indicator of instability.
Individual scores are collected for each of the aforedescribed
clinical criteria. The rating scale allows scores between one (1)
at the lowest end, and five (5) on the opposite, highest end. A
rating of 5 is assigned to the processed video that is diagnostically equivalent to the original, uncompressed video. A rating
of 4 signals the loss of minor clinical details that is still diagnostically acceptable and provides sufficient information for
a confident diagnosis. The clinical information present in the
processed video is compromised and cannot be trusted for diagnosis purposes when the rating falls below the diagnostically
acceptable margin of 4. As a result, a rating of 3, while it still
contains clinical information does not qualify for atherosclerosis
disease assessment. The lowest clinical rating of 1 corresponds
to clinically useless ultrasound video.
IV. RESULTS AND DISCUSSION
We first present the results of the efficiency of despeckle filtering as a preprocessing step to video coding for ultrasound video
communications, followed by video coding standards comparison. In addition to the objective measurements, clinical evaluation is used to verify the clinical capacity of the processed
ultrasound videos.

Fig. 3. Despeckle filtering algorithms efficiency. Rate-distortion curves of
HEVC encoded videos (mean values of the ten 560 × 416@50 frames/s ultrasound videos for all investigated rate points). All algorithms outperform
the conventional encoding procedure involving no speckle filtering. The best
performing algorithm is the DsFlsmv. The DsFhmedian filter marginally outperforms the DsFsrad.

TABLE I
BITRATE SAVINGS WHEN USING DESPECKLE FILTERING PRIOR TO H.264/AVC
AND HEVC ENCODING
Bitrate Savings Relative to
Despeckle Filtering Method
DsFlsmv
DsFhmedian
DsFsrad

H.264/AVC Original

HEVC Original

39.2%
32.5%
23.4%

43.6%
34.1%
23.5%

A. Clinical Ultrasound Video Dataset
The dataset is composed of ten atherosclerotic plaque ultrasound videos, with a spatial resolution of 560 × 416 at
50 frames/s. Instead of using the QCIF (176 × 144) and CIF
(352 × 288) resolutions reported in [4], the collected videos at
560 × 416 do not include any resolution conversions. VQA is
based at this higher resolution exported by the ultrasound equipment. Furthermore, this new set of videos has been specifically
collected at 50 versus 15 frames/s of [4] to evaluate motion
estimation (not covered in [4]). As in [4], to support the reproducibility of the results, we follow an established clinical
protocol given in [30].
B. Video Compression Results After Despeckle Filtering
The use of despeckle filtering prior to video encoding can lead
to significant improvements in rate-distortion performance as
demonstrated in Fig. 3. As we describe next, these improvements
vary significantly depending on the despeckle filtering method.
We present video despeckling examples in Fig. 2. Atherosclerotic plaque(s) formed on the near and far wall are outlined
using the segmentation algorithm described in [31]. The segmented images allow visualization of the plaque boundaries and
plaque morphology. The despeckled images exhibit very subtle
differences that are hard to detect using the human visual system

(HVS). Note that this is the desired behavior. Ideally, despeckle
filtering removes higher frequencies that allow for better compression without visualizing significant artifacts that can compromise the diagnosis. After zooming into the images, it becomes clear that the despeckled images are smoother, missing
some of the finer details that are present in the original image. The differences between the different despeckling methods
are more difficult to visualize than their differences from the
original image.
The differences among the examined methods are easily visualized in the rate-distortion curves of Fig. 3. As depicted in
the graph, we have significant improvements for all methods.
Indicatively, as documented in Table I, DsFlsmv reduces bitrate requirements by as much as 43.6% and 39.2%, compared to
standard HEVC and H.264/AVC encodings, respectively. The
DsFhmedian filter lowers bitrate requirements by 34.1% for
HEVC and 32.5% for H.264/AVC, while the DsFsrad filter
achieves bitrate reductions of approximately 23% for both standards. As evident, the trend is the same for both standards. Based
on objective evaluation, the DsFlsmv is the best performing filter, as it achieves the best PSNR scores while requiring lower
bitrates than alternative methods. The hybrid median marginally
outperforms the DsFsrad filter. It is important to note here that

PANAYIDES et al.: AN EFFECTIVE ULTRASOUND VIDEO COMMUNICATION SYSTEM USING DESPECKLE FILTERING AND HEVC

673

Fig. 4. Boxplots of HEVC (red) versus H.264/AVC (blue) that demonstrate video quality (SSIM and PSNR) as a function of bitrate (rate distortion), for ten
ultrasound videos. HEVC requires significantly less bitrate while it achieves higher SSIM and PSNR scores than rival H.264/AVC standard. (a) HEVC SSIM
scores versus Bitrate boxplots, (b) H264 SSIM scores versus Bitrate boxplots, (c) HEVC PSNR scores versus Bitrate boxplots, and (d) H264 PSNR scores versus
Bitrate boxplots. The bitrate values used here are mean values of the ten ultrasound videos of the examined dataset of the 12 quantization parameters (QP range
20–42) discussed in Section III.

the objective results regarding the efficiency of the speckle filtering algorithms are also verified by the clinical evaluation
as discussed below in Section IV-D. To highlight the necessity of efficient video compression methods, we note that for
ultrasound video communication purposes, an original uncompressed video would require 93.18 Mbps (560 width resolution
× 416 horizontal resolution × 50 frames/s × 8 bits per pixel =
93.18 Mbps). Using the DsFlsmv and HEVC encoding for a QP
of 28, which achieves diagnostically lossless ultrasound video
quality, the transmission rate is reduced to 340 kbps. In other
words, a compression ratio of 274 is achieved. Beside the obvious storage space savings, efficient compression that preserves
the ultrasound video’s clinical capacity allows transmission over
existing 3.5G wireless infrastructure (for the particular video
resolution), otherwise not feasible for 4G cellular networks (for
the uncompressed video).
C. Video Coding Standards for Ultrasound
Video Communications
Fig. 4 shows boxplots of video quality measured in PSNR and
SSIM as a function of bitrate for the HEVC MP and H.264/AVC
HP video coding standards. From the plots, it is clear that HEVC
MP requires less bitrate while achieving higher video quality
than H.264/AVC HP. More directly, Fig. 5 presents a comparison of the median rate-distortion performance of HEVC MP
against H.264/AVC HP, H.263 CHC, MPEG-4 ASP, and MPEG2/H.262 MP. From Fig. 5, for the same bitrate, it is clear that
HEVC achieves higher levels of video fidelity.
As documented in Table II, HEVC achieves average bitrate
gains of 33.2% compared to H.264/AVC. Bitrate savings of
54.6% and 58.3% are observed for earlier H.263 CHC and
MPEG-4 ASP standards, respectively, while bitrate gains extend up to 71% when compared to MPEG-2/H.262 MP. Bitrate
reductions from using H.264/AVC or other later standards compared to earlier ones are also summarized in Table II.
D. Clinical Evaluation
1) Despeckle Filtering: Two medical experts (a cardiovascular surgeon and a neurovascular specialist) were asked to
grade the ultrasound videos based on the clinical criteria that
were discussed in Section III-E. To emphasize the effects of
despeckling, the original videos were presented side-by-side

Fig. 5. Video coding standards comparison. Rate-distortion curves (mean
values of the ten 560 × 416@50 frames/s ultrasound videos for all investigated
rate points). HEVC lowers bitrate requirements while it provides for higher
PSNR values compared to all prior video coding standards.

with the despeckled videos. All evaluations were performed
using laptop equipment with a spatial resolution 1920 × 1080
and maximum screen brightness, in a mildly dark environment.
Sufficient time was allocated for the medical expert’s eyes to
adjust to the current lighting conditions. The viewing distance
was approximately 1 m. Overall, the viewing conditions were
comparable to a routine clinical exam.
Table III summarizes the average scores for the three clinical
criteria for the ten ultrasound videos of the dataset, prior to compression. As evident in the table, the DsFlsmv and DsFhmedian
filters, yield comparable clinical ratings as the original video.
Furthermore, the medical experts emphasized that the overall
clinical capacity was neither compromised nor improved from
the use of the DsFlsmv and DsFhmedian filters. On the other
hand, in some cases, the DsFsrad filter did seem to negatively
affect the visualization of the morphology of the plaque as presented in Table III.
The clinical capacity of the despeckled and original ultrasound videos following compression was also clinically validated. The results are presented in Table IV for a subset of the

674

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 2, MARCH 2015

TABLE II
VIDEO BITRATE SAVINGS OF DIFFERENT STANDARDS COMPARED AGAINST PREVIOUS CODING STANDARDS
Bitrate Savings Relative to
Encoding

H.264/MPEG-4 AVC HP

H.263 CHC

MPEG-4 ASP

MPEG-2/H.262 MP

33.2%
-

54.6%
32.3%
-

58.3%
37.7%
7.5%
-

71%
56.8%
32.4%
27.4%

HEVC MP
H.264/MPEG-4 AVC HP
H.263 CHC
MPEG-4 ASP

TABLE III
CLINICAL CRITERIA EVALUATION FOR DESPECKLED VIDEOS (UNCOMPRESSED)
Filter
Original Video
Dflsmv
DsFhmedian
DsFsrad

Stenosis

Morphology

Motion

5.0
4.9
5.0
5.0

5.0
4.7
4.7
4.2

5.0
4.8
4.9
4.7

The average values for stenosis, morphology, and motion are graded from 1 (lowest) to 5 (highest).

TABLE IV
DESPECKLE FILTERING ULTRASOUND VIDEOS CLINICAL CAPACITY FOLLOWING HEVC ENCODING
Stenosis

Quantization Parameter
Original Video
DsFlsmv
DsFhmedian
DsFsrad

36
4.8
4.4
4.6
4.6

32
4.8
4.6
4.6
4.8

Morphology

28
4.8
4.6
4.6
4.4

36
4.8
3.8
3.8
4.2

32
4.8
4.2
4.2
4.6

Motion

28
4.8
4.6
4.8
4.4

36
4.8
4.6
4.4
4.8

32
5.0
4.6
4.8
4.8

28
4.8
4.6
4.8
4.8

MOS are presented for four videos for three QPs: 36, 32, and 28.

TABLE V
CLINICAL VALIDATION OF A SINGLE VIDEO FOR ALL INVESTIGATED VIDEO CODING STANDARDS
Stenosis

Quantization Parametera
HEVC MP
H.264/AVC HP
MPEG-4 ASP
H.263 CHC
MPEG-2/H.262 MP

42 (31)
5
5
3
3
3

32 (10)
5
5
5
4
4

Morphology

28 (6)
5
5
5
5
4

42 (31)
4
3
2
3
2

32 (10)
5
4
5
5
4

Motion

28 (6)
5
5
5
5
4

42 (31)
3
4
2
3
2

32 (10)
5
5
4
5
3

28 (6)
5
5
5
4
3

a

The quantization parameter outside the parenthesis corrsponds to HEVC and H.264/AVC standards while the QP inside the
parenthesis is used for MPEG-4, H.263, and MPEG-2 standards.
A clinical score from 1 to 5 is assigned for the three clinical criteria described in Section III. Here, for three QPs: 42, 32, and
28. This table also appeared in our conference paper in [10].

examined QPs averaged over four videos. Clinical scores verify
that despeckled ultrasound videos yield comparable diagnostic
capacity to the original, nondespeckled videos. Despite documented outliers (mostly for the DsFsrad filter), clinical capacity
of the compressed videos is enhanced as bitrate budget increases
(quantization levels decreases). Overall, ultrasound video denoising can be effectively used to minimize bitrate and storage
requirements, providing a powerful tool in wireless medical
video communications. Artery stenosis and the atherosclerotic
plaque’s motion assessment received consistently high ratings.
Both criteria relate to the ultrasound video’s frame rate and sup-

port the requirement of communicating medical videos at the
acquired frame rate. Morphology assessment requires encoding
using QPs lower than 32 for providing diagnostically acceptable clinical scores (≥4). Still, diagnostically acceptable HEVC
compression threshold needs to be investigated for a higher
number of cases.
2) Video Coding Standards Comparison: Table V records
the clinical ratings of a neurovascular specialist for each of the
assessed clinical criteria for all investigated video coding standards. Evaluation is performed for a subset of the total encoded
instances of a single video. However, the trend is the same for

PANAYIDES et al.: AN EFFECTIVE ULTRASOUND VIDEO COMMUNICATION SYSTEM USING DESPECKLE FILTERING AND HEVC

the ultrasound video dataset used in this study. As the clinical
scores indicate, the new HEVC standard is the only standard
that achieves maximum scores for all evaluated criteria for a QP
of 32. On the other hand, H.264/AVC and MPEG-4 require finer
quality encoding to achieve the highest clinical capacity possible at a QP of 28. Earlier standards such as H.263 and MPEG-2
do not provide quality comparable to the uncompressed video
at these QPs.
In general, for the ultrasound video dataset used in this
study, HEVC encoded videos are typically assigned higher clinical scores than the H.264/AVC encoded videos for the same
QPs, which in turn outperform MPEG-4 videos. H.263 and
MPEG-2 videos attain similar clinical ratings. As documented
in [23], HEVC achieves even greater bitrate gains compared
to H.264/AVC when the comparison is based on perceptual
quality.
V. CONCLUDING REMARKS
Both objective evaluations and MOS based on clinical criteria
provide evidence that the emerging HEVC standard yields significant improvements in compression efficiency compared to
prior video coding standards. For wired communications channels, we recommend that HEVC be adopted for medical video
communication systems. For wireless communications channels, there needs to be an exhaustive evaluation of HEVC’s
error-resilient performance in noisy channels. Despeckle filtering prior to video encoding can lead to significant bitrate savings
without compromising diagnostic quality.
Ongoing work involves investigating different medical video
modalities and emergency trauma videos for (beyond) HD
encoding using HEVC and transmission over LTE, LTEAdvanced, and WirelessMAN-Advanced wireless networks
based on both simulations and real-life scenarios [31]. Future
work should also focus on the development of automated methods that can be used to predict the MOS on each one of the
clinical criteria.
REFERENCES
[1] A. S. Panayides, M. S. Pattichis, and C. S. Pattichis, “Mobile-health systems use diagnostically driven medical video technologies [life sciences],”
IEEE Signal Process. Mag., vol. 30, no. 6, pp. 163–172, Nov. 2013.
[2] G. J. Sullivan, J.-R. Ohm, W.-J. Han, and T. Wiegand, “Overview of the
high efficiency video coding (HEVC) standard,” IEEE Trans. Circuits
Syst. Video Tech., vol. 22, no. 12, pp. 1649–1668, Dec. 2012.
[3] M. G. Martini and C. T. E. R. Hewage, “Flexible macroblock ordering for context-aware ultrasound video transmission over mobile
WiMAX,” Int. J. Telemed. Appl., vol. 2010, art. ID 127519, 14 pp., 2010.
doi:10.1155/2010/127519.
[4] A. Panayides, M. S. Pattichis, C. S. Pattichis, C. P. Loizou, M. Pantziaris,
and A. Pitsillides, “Atherosclerotic plaque ultrasound video encoding,
wireless transmission, and quality assessment using H.264,” IEEE Trans.
Inf. Technol. Biomed., vol. 15, no. 3, pp. 387–397, May 2011.
[5] A. Panayides, Z. Antoniou, Y. Mylonas, M. S. Pattichis, A. Pitsillides, and
C. S. Pattichis, “High-resolution, low-delay, and error-resilient medical
ultrasound video communication using H.264/AVC over mobile WiMAX
networks,” IEEE J. Biomed. Health Informat., vol. 17, no. 3, pp. 619–628,
May 2013.
[6] E. Cavero, A. Alesanco, and J. Garcia, “Enhanced protocol for real time
transmission of echocardiograms over wireless channels,” IEEE Trans.
Biomed. Eng., vol. 59, no. 11, pp. 3212–3220, Nov. 2012.
[7] E. Cavero, A. Alesanco, and J. Garcia, “Real-time echocardiogram
transmission protocol based on regions and visualization modes,” IEEE
J. Biomed. Health Informat., to be published. doi: 10.1109/
JBHI.2013.2294905.

675

[8] C. Debono, B. Micallef, N. Philip, A. Alinejad, R. Istepanian, and
N. Amso, “Cross layer design for optimised region of interest of ultrasound
video data over mobile WiMAX,” IEEE Trans. Inf. Technol. Biomed.,
vol. 16, no. 6, pp. 1007–1014, Nov. 2012.
[9] A. Panayides, Z. Antoniou, M.S. Pattichis, C. S. Pattichis, and A. G.
Constantinides, “High efficiency video coding for ultrasound video communication in m-health systems,” in Proc. Annu. Int. Conf. IEEE Eng.
Med. Biol. Soc., Aug. 28–Sep. 1, 2012, pp. 2170–2173.
[10] A. Panayides, M. S. Pattichis, and C. S. Pattichis, “HEVC encoding for
reproducible medical ultrasound video diagnosis,” in Proc Asilomar Conf.
Signals, Syst. Comput., Pacific Grove, CA, USA, Nov. 3–6, 2013, pp.
1117–1121.
[11] A. Panayides, C. P. Loizou, M. S. Pattichis, E. Kyriacou, C. N. Shizas,
A. Nicolaides, and C. S. Pattichis, “Ultrasound video despeckle filtering
for high efficiency video coding in M-health systems,” in Proc Constantinides Int. Workshop Signal Process., London, U.K., Jan. 2013,
pp. 1–4.
[12] C. P. Loizou, T. Kasparis, P. Christodoulides, C. Theofanous, M. Pantziaris,
E. Kyriakou, and C. S. Pattichis, “Despeckle filtering in ultrasound video
of the common carotid artery,” in Proc. IEEE 12th Int. Conf. Bioinf.
Bioeng., Larnaca, Cyprus, Nov. 11–13, pp. 721–726.
[13] C. P. Loizou and C. S. Pattichis, “Despeckle filtering algorithms and
software for ultrasound imaging,” in Synthesis Lectures on Algorithms
and Software for Engineering. San Rafael, CA, USA: Morgan & Claypool
Publishers, 2008.
[14] C. P. Loizou, C. S. Pattichis, C. I. Christodoulou, R.S.H. Istepanian,
M. Pantziaris, and A. Nicolaides “Comparative evaluation of despeckle
filtering in ultrasound imaging of the carotid artery,” IEEE Trans. Ultrason. Ferroelectr. Freq. Control, vol. 52, no. 10, pp. 1653–1669,
Oct. 2005.
[15] Video Codec for Audiovisual Services ar px64 kbit/s, ITU-T Recommendation H.261, Nov. 1990.
[16] Information Technology —Generic Coding of Moving Pictures and Associated Audio Information: Video, ITU-T Recommendation H.262,
Jul. 1995.
[17] Video Coding for Low Bitrate Communication, ITU-T Recommendation
H.263, Nov. 1995.
[18] Advanced Video Coding for Generic Audiovisual Services, ITU-T
and ISO/IEC 14496-10 Recommendation H.264 (MPEG4-AVC), May
2003.
[19] T. Wiegand, G. J. Sullivan, G. Bjontegaard, and A. Luthra, “Overview of
the H.264/AVC video coding standard,” IEEE Trans. Circuits Syst. Video
Technol., vol. 13, no. 7, pp. 560–576, Jul. 2003.
[20] H.265: High Efficiency Video Coding, ITU-T Recommendation H.265,
Jun. 2013.
[21] A. Nieminen, P. Heinonen, and Y. Neuvo, “A new class of detail-preserving
filters for image processing,” IEEE Trans. Pattern Anal. Mach. Intell.,
vol. PAMI-9, no. 1, pp. 74–90, Jan. 1987.
[22] Y. Yongjian and S. T. Acton, “Speckle reducing anisotropic diffusion,” IEEE Trans. Image Process., vol. 11, no. 11, pp. 1260–1270,
Nov. 2002.
[23] J.-R. Ohm, G. J. Sullivan, H. Schwarz, T. K. Tan, and T. Wiegand, “Comparison of the coding efficiency of video coding standards—Including
high efficiency video coding (HEVC),” IEEE Trans. Circuits Syst. Video
Tech., vol. 22, no. 12, pp. 1669–1684, Dec. 2012.
[24] Z. Wang, L. Lu, and A. C. Bovik, “Video quality assessment based on
structural distortion measurement,” Signal Process.: Image Commun.,
vol. 19, no. 2, pp. 121–132, Feb. 2004.
[25] Metrix_mux objective video quality assessment software. (2014). [Online]. Available: http://foulard.ece.cornell.edu/gaubatz/metrix_mux/
[26] K. Seshadrinathan, R. Soundararajan, A. C. Bovik, and L. K. Cormack,
“Study of subjective and objective quality assessment of video,” IEEE
Trans. Image Process., vol. 19, no. 6, pp. 1427–1441, Jun. 2010.
[27] G. Bjøntegaard, “Improvements of the BD-PSNR model,” ITU-T SG16
Q.6 Document, VCEG-AI11, Berlin, Germany, Jul. 2008.
[28] E. Kyriacou, M. S. Pattichis, C. S. Pattichis, A. Mavrommatis,
C. I. Christodoulou, S. Kakkos, and A. Nicolaides, “Classification of
atherosclerotic carotid plaques using morphological analysis on ultrasound images,” Appl. Intell., vol. 30, no. 1, pp. 3–23, Feb. 2009.
[29] H. Nasrabadi, M. S. Pattichis, P. Fisher, A. N. Nicolaides, M. Griffin,
G. C. Makris, E. Kyriacou, and C. S. Pattichis, “Measurement of motion
of carotid bifurcation plaques,” in Proc. IEEE 12th Int. Conf. Bioinformat.
Bioeng., Nov. 11–13, 2012, pp. 506–511.
[30] C. P. Loizou, C. S. Pattichis, M. Pantziaris, and A. Nicolaides, “An integrated system for the segmentation of atherosclerotic carotid plaque,”
IEEE Trans. Inf. Technol. Biomed., vol. 11, no. 5, pp. 661–667, Nov.
2007.

676

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 2, MARCH 2015

[31] A. Panayides, I. Eleftheriou, and M. Pantziaris, “Open-source
telemedicine platform for wireless medical video communication,”
Int. J. Telemed. Appl., vol. 2013, art. ID 457491, 12 pp., 2013.
doi:10.1155/2013/457491.

Andreas S. Panayides (M’13) received the B.Sc.
degree from the Department of Informatics and
Telecommunications, National and Kapodistrian
University of Athens, Athens, Greece, in 2004, the
M.Sc. degree in computing and Internet systems
from Kings College, London, U.K., in 2005, and the
Ph.D. degree from the University of Cyprus, Nicosia,
Cyprus, in 2011.
He is currently a Marie Sklodowska Curie Research Fellow in the Communication and Signal Processing Group, Department of Electrical and Electronic Engineering, Imperial College, London. His research interests include
medical video processing and communications, and mHealth and eHealth applications. He has published 7 journal publications, 18 conference papers, and
3 chapters in books in these areas.
Dr. Panayides served as TPC member and session chair in many IEEE conferences. His research funding comes from the project Diagnostically Robust
Ultrasound Video Transmission over Emerging Wireless Networks, 301476,
FP7-PEOPLE-2011-IEF scheme.

Marios S. Pattichis (M’99–SM’06) received the
B.Sc. (high honors and special honors) degree in computer sciences and the B.A. (high honors) degree in
mathematics, and minor in electrical engineering in
1991, the M.S. degree in electrical engineering in
1993, and the Ph.D. degree in computer engineering in 1998 from the University of Texas at Austin,
Austin, TX, USA.
He is currently a Full Professor in the Department
of Electrical and Computer Engineering (ECE), at
the University of New Mexico (UNM), Albuquerque,
NM, USA. He is also serving area chair of the Computer Engineering program
at UNM. His current research interests include mathematical models for digital image, video processing and communications, dynamically reconfigurable
computer architectures, and applications in biomedical and space imaging.
Prof. Pattichis is an Associate Editor of the IEEE Transactions on Image
Processing. He was the General Chair of the 2008 IEEE Southwest Symposium
on Image Analysis and Interpretation. At UNM, he received the 2004 ECE
Distinguished Teaching Award and the 2006 School of Engineering Harrison
Faculty Recognition Award.

Christos P. Loizou (SM’11) received the B.Sc. degree in electrical engineering and the Dipl.-Ing.
(M.Sc.) degree in computer science and telecommunications from the University of Kaisserslautern,
Kaisserslautern, Germany, in 1986 and 1990, respectively, and the Ph.D. degree in ultrasound image
analysis of the carotid artery from the Department
of Computer Science, Kingston University, London,
U.K., in 2005.
From 1996 to 2000, he was a Lecturer in the
Department of Computer Science, Higher Technical
Institute, Nicosia, Cyprus. Since 2000, he has been a Campus Program coordinator in the Department of Computer Science, Intercollege, Limassol, Cyprus.
He was a Supervisor of a number of Ph.D. and B.Sc. students in computer image
analysis and telemedicine. He is also an Associate Researcher at the Institute of
Neurology and Genetics, Nicosia, Cyprus and at the Cyprus University of Technology, Limassol, Cyprus. He is the author or coauthor of the book Despeckle
Filtering Algorithms and Software for Ultrasound Imaging, one more book, 14
chapters in books, 24 referred journals, and 52 conference papers in image and
video analysis. His research interests include medical imaging and processing,
motion and video analysis, signal and image processing, pattern recognition,
biosignal analysis, in ultrasound, magnetic resonance, and optical coherence
tomography imaging and computer applications in medicine.
Dr. Loizou is a Senior Member of the Institution of Electrical Engineers, and
served as a chair and co-chair, in many IEEE conferences.

Marios Pantziaris received the M.D. degree in
neurology from the Aristotelion University, Thessaloniki, Greece, in 1995.
Currently, he is working with Cyprus Institute of
Neurology and Genetics, Nicosia, Cyprus, as a Senior Neurologist in the Neurological Department and
is the Head of the Neurovascular Department. He has
been trained in Carotid DuplexDoppler ultrasonography at St. Mary’s Hospital, London, in 1995. In 1999,
he was a visiting doctor in acute stroke treatment at
Massachusetts General Hospital, Harvard University,
Boston. He has considerable experience in carotidstranscranial ultrasound, has
participated in many research projects, and has several publications to his name.
He is also the Head of the Multiple Sclerosis (MS) Clinic, where he is running
research projects towards the aetiology and therapy of MS.

Anthony G. Constantinides (S’68–M’74–SM’78–
F’98) is the Professor of Communications and Signal
Processing at Imperial College, London, U.K. and
former Head of Communications and Signal Processing Division of the Department of Electrical and
Electronic Engineering at the same place. He has been
actively involved with research in various aspects of
digital signal processing, digital image processing,
digital filter design, and communications for more
than 45 years.His recent work has been directed toward the demanding problems arising infinancial signal processingand he now leads the Financial Signal Processing Lab in the EEE
Department of Imperial College. He has published several books and over 400
learned articles in the areas of digital signal processing, image processing, and
communications, and their many applications.
Prof. Constantinides has been on, and is currently serving as, a member of
many technical program committees of the IEEE, the IEE and other international
conferences. He is the recipient of a number of awards and honours around the
world, including Officier, Palmes Academiques, by the French government. He
holds honorary doctorates from European and Far Eastern Universities. In addition he holds Visiting Professorships, Distinguished Lectureships, Fellowships
and other honours around the world. He has served as a Member of the Board of
Governors of the IEEE Signal Processing Society, a member of several Technical Committees of the IEEE and the IEE, and is on the Editorial Boards of many
professional journals. He has been on the Editorial Board of the Proceedings of
the Royal Society, Part B. He is a Fellow of the Royal Academy of Engineering
and of the Institution of Electrical Engineers (U.K.).

Constantinos S. Pattichis (S’88–M’88–SM’99) is
Professor with the Department of Computer Science
and Director of the eHealth Lab of the University of
Cyprus. He has a 20 year experience in eHealth systems, medical imaging, biosignal analysis, intelligent
systems, and more recently in life sciences informatics. He has been involved in numerous projects in
these areas funded by EU and other bodies, with a
total funding managed close to 7 million Euro. He
has published 74 journal publications, 182 conference papers, and 27 chapters in books in these areas.
He is Co-Editor of the books M-Health: Emerging Mobile Health Systems,
and Ultrasound and Carotid Bifurcation Atherosclerosis, published in 2006 and
2012 by Springer.
Prof. Pattichis was Guest Co-Editor of the Special Issues of the IEEE Transactions on Information Technology in Biomedicine on Emerging Technologies in
Biomedicine, Computational Intelligence in Medical Systems, Citizen Centered
e-Health Systems in a Global Health-care Environment, and Atherosclerotic
Cardiovascular Health Informatics. He was general chair of the IEEE 12thInternational Conference on BioInformatics and BioEngineering (BIBE2012), and
Information Technology Applications in Biomedicine (ITAB2009).

