IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

293

Multimodality Neurological Data Visualization With
Multi-VOI-Based DTI Fiber Dynamic Integration
Qi Zhang, Murray Alexander, and Lawrence Ryner

Abstract—Brain lesions are usually located adjacent to critical spinal structures, so it is a challenging task for neurosurgeons to precisely plan a surgical procedure without damaging
healthy tissues and nerves. The advancement of medical imaging technologies produces a large amount of neurological data,
which are capable of showing a wide variety of brain properties. Advanced algorithms of medical data computing and visualization are critically helpful in efficiently utilizing the acquired
data for disease diagnosis and brain function and structure exploration, which is helpful for treatment planning. In this paper, we
describe new algorithms and a software framework for multiple
volume of interest specified diffusion tensor imaging (DTI) fiber
dynamic visualization. The displayed results have been integrated
with a volume rendering pipeline for multimodality neurological
data exploration. A depth texture indexing algorithm is used to
detect DTI fiber tracts in graphics process units (GPUs), which
makes fibers to be displayed and interactively manipulated with
brain data acquired from functional magnetic resonance imaging, T1 - and T2 -weighted anatomic imaging, and angiographic
imaging. The developed software platform is built on an objectoriented structure, which is transparent and extensible. It provides
a comprehensive human–computer interface for data exploration and information extraction. The GPU-accelerated highperformance computing kernels have been implemented to enable
our software to dynamically visualize neurological data. The developed techniques will be useful in computer-aided neurological disease diagnosis, brain structure exploration, and general cognitive
neuroscience.
Index Terms—Diffusion tensor imaging (DTI), fiber tract rendering, functional magnetic resonance imaging (fMRI), graphics
process unit (GPU), high-performance computing, image fusion,
real time, visualization, volume of interest (VOI).

I. INTRODUCTION
A. Motivations
HE advancement of neuroimaging techniques can produce a large amount of multimodality neurological data,
which are generated through diffusion tensor imaging (DTI),
functional magnetic resonance imaging (fMRI), angiographic

T

Manuscript received February 27, 2014; revised June 19, 2014 and October
7, 2014; accepted November 1, 2014. Date of publication November 4, 2014;
date of current version December 31, 2015.
Q. Zhang is with the Department of Medical Imaging, University of Western
Ontario, London, ON N6A 3K7, Canada, and also with the Centre for Imaging Technology Commercialization, London, ON N6G 4X8, Canada (e-mail:
qzhang58@uwo.ca).
M. Alexander is with the Department of Physics, University of Winnipeg,
Winnipeg, MB R3B 2E9, Canada (e-mail: mu.alexander@uwinnipeg.ca).
L. Ryner is with the Department of Medical Physics, CancerCare Manitoba, Winnipeg, MB R3E 0V9, Canada (e-mail: Lawrence.Ryner@cancercare.
mb.ca).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2367026

imaging, as well as T1 - and T2 -weighted anatomic magnetic
resonance (MR) imaging. The acquired data are capable of displaying a wide variety of structural and functional properties of
the brain [1].
DTI is a rapidly evolving noninvasive technique that measures
water diffusion in tissues, which can be presented as tractography for showing its tracts in three-dimensional (3-D) space and
has been commonly used to observe white matter structures
on a microscopic scale [2]. DTI fibers provide an unique clue
to the fine architecture of brain nerves and offer a straightforward insight into the functional and anatomical connectivity
between different parts of brain on an individual basis [3]. DTI
fiber tracking and visualization allow accurately characterizing
intrinsic tissue integrity in clinical practice [4]. At the same
time, blood-oxygen-level-dependent (BOLD) fMRI describes
neural activities in hypothalamus or spinal cord via measuring
the changes in blood flow related to energy usage by brain cells,
which is the ratio of oxygenated to deoxygenated blood [5].
This imaging modality can be used to extract a large-scale perspective information of distributed neurological activities across
the brain in a noninvasive way and, thus, facilitate the understanding of how brain regions are functionally activated and
related [6]. The combination of DTI and fMRI provides a new
way to understand the human brain from both neuronal fiber
connectivity and functional activity between different brain regions [7]. Furthermore, combining DTI with MR angiography
and anatomy images will allow neurosurgeons to better avoid
important blood vessels and to efficiently estimate the locations and sizes of neuronal bundles that course through human
brain [8].
Medical image visualization has been widely used by neurosurgeons to investigate tractography data, during which DTI
fibers are displayed with anatomical context such that users
are able to derive insights into the observed data. However,
due to the limitation of deducting and rendering the fiber
tracks and demonstrating their spatial relationships with the
anatomical structures and lesions, it is still a challenging
task to effectively use the important information contained
in the acquired data [9]. To provide neurosurgeons with an
optimal understanding of complex brain structures and functions, an efficient neurological data exploration software is
critically important, which can be employed to interactively
view brain images, define fiber tracts, and show their relationships with surgical lesions [10]. In addition, efficient visualization of DTI fiber pathways and their connections with
brain functional regions is of significant interest for neurosurgical planning, which can aid in avoiding damage to healthy
tissues [11].

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

294

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

B. Related Works
There are many publications and software packages for DTI
visualization and neurological data rendering [12]. For example, Prčkovska et al. proposed an interactive framework to show
high-angular resolution diffusion imaging and DTIs, which took
advantages of modern graphics process units’ (GPUs) capabilities for glyph rendering and fiber tracking [13]. To decrease the
uncertainties in fiber tracking and improve the understanding
of parameter sensitivity, a visualization tool was developed by
Brecheisen’s group to allow users to explore the affect of small
variations in parameter values to the output of fiber display
[14]. However, their methods cannot render fibers in a volumerendered environment, therefore, cannot deliver anatomical information with displayed DTI fibers simultaneously.
Neurological image visualization was also used with new
equipments that were designed for neurosurgery applications,
such as Bertelsen et al. [15] developed a mobile display that
could track its position, and volume rendering was used to show
the images in a 3-D space. To reduce the complexity of DTI
fiber visualization, Brecheisen’s group presented a framework
that only show DTI fiber tracking uncertainties caused by the
noise and modeling errors [16]. Golby et al. [17] developed a
software package that plugged in 3-D slicer [18] to interactively
visualize diffusion tensor tractography for improving neurosurgical planning. The 3-D slicer was also used by Elhawary et al. to
interactively show DTI fibers for inspecting critical white matter tracts that were close to lesions [19]. In addition, Peng et al.
developed a comprehensive 3-D visualization-assisted analysis
[20] software platform for large-scale multidimensional image
visualization and management. This platform can be used for
new medical applications such as microscopic image display and
quantitative analysis. Recently, Fritzsche et al. [21] introduced
a toolkit component of the Medical imaging and interaction
framework [22] for processing and displaying diffusion MRI
datasets in multiple planar views.
There are some interesting publications in the field of data
visualization for neurosurgical planning in the 2010 IEEE Visualization Contest [23]. For example, Rieder et al. presented
an interactive techniques for rendering multimodal images that
were used in neurosurgical therapy planning [24]. In this paper,
the distance-based enhancements of functional data and lesions
were implemented for the purpose of allowing surgeon to perceive functional and anatomical structures simultaneously and
relate them to direct intervention. To assist surgeon to explore
brain image and conduct visual intervention, Born and his group
[25] developed several interaction methods and integrated them
into their visualization framework VolV [26], including adaptive scene graph, focus and context, distance measurements, as
well as access planning. In addition, Diepenbrock et al. [27]
presented a system for brain tumor resection planning, in which
fiber tracking and uncertainty extraction were used for volume
analysis. For the purpose of conveying the relation between
the lesion and various structures at risk, a set of 2-D and 3-D
views were developed and linked. This system allowed surgeons to interactively define the access path by clicking the 3-D
views and to perform distance measurements in both 2-D and

3-D. Furthermore, to evaluate the possible access paths and perform risk assessment, Vaillancourt and his group members extended the FiberNavigator for neurosurgical planning [28]. They
added several visualization features to the software platform
for quantifying and highlighting the relationships between tumors, brain functional areas, white matter fiber tracts, and blood
vessels.
Even though there are many algorithms and software packages for DTI fiber and multimodal neurological data visualization and exploration, and there are also some interesting applications in the field of neurological diagnosis and neurosurgical
planning, there is still not enough emphasis on multiple volume
of interest (VOI)-based DTI fiber tracking and high-quality volume rendering with fiber dynamic integration, which is crucial
for neurological data investigation. Most existing neurological
data visualization software was based on 2-D slices, which offered poor spatial context and imposed a significant burden on
users cognitive resources to interpret the displayed images. In
most published research, 3-D visualization was usually limited
to surface rendering, or volume rendering with inferior image
quality, or 3-D visualization without efficient DTI fiber, functional and anatomical image fusion, such as only combining
polygonal DTI data with 3-D texture mapping-based volume
rendering, which could not provide users with sufficient highquality inner anatomical and functional information for accurate
data explanation. The main contributions of our research is the
development of new algorithms and computer graphics pipelines
to address the described issues, which will be briefly introduced
in Section I-C.
C. Our Approach
In our software framework, we first used robust DTI fiber extraction algorithms to generate the whole brain fiber tracks and,
then, visualized them with multimodality neurological images,
which were similar with the methods described in some of the
published research. However, there are some new algorithms
and data exploration techniques developed in our research. We
first set multiple flexible cube-based VOIs and then developed
new algorithms for DTI fiber visualization. In our system, the
DTI fibers were visualized in real time and were dynamically
specified by multiple VOIs for interactively analyzing fiber connectivity. Two VOIs were used in our system for function testing. At the same time, the multifunction neurological images
were volume rendered on graphics hardware and fused with
the dynamically displayed fiber tracks in multiple synchronized
rendering windows. In our platform, 3-D data visualization and
fusion were accomplished with GPU-based raycasting and a
novel voxel classification algorithm, which offered neurosurgeons with interactivity and flexibility to see the targets from
viewpoints not physically possible and free them from mentally
reconstructing 3-D images from 2-D slices. Finally, a depth
texture indexing algorithm was used with frame buffer object
(FBO) to integrate DTI fibers with volume-rendered images,
and the fiber tracts near critical structures of interest could be
interactively manipulated and viewed to help users to determine
the spatial relationships between fibers and brain lesions.

ZHANG et al.: MULTIMODALITY NEUROLOGICAL DATA VISUALIZATION WITH MULTI-VOI-BASED DTI FIBER DYNAMIC INTEGRATION

II. DATA ACQUISITION AND PROCESSING
A. Anatomical and Function Data
Siemens TrioTim 3T MR scanner was used in data acquisition. T1 - and T2 -weighted anatomical data were first acquired
with intraplane image resolution 256 × 256 and pixel size 1.0 ×
1.0 mm2 . Totally 176 slice images were collected with thickness
1 mm. The following acquired data included two time-series
BOLD fMRI images for stimulus of foot and finger motion,
each of which 120 slices were collected with thickness 4 mm.
The final acquired data were angiography MR images. Totally
128 slices were acquired with slice thickness 0.7 mm. The software package statistical parametric mapping [29] was used to
process, register, and analyze the acquired images.
B. DTI Fiber Extraction and Image Processing
The acquired MR imaging sequence, i.e., echo planar imaging, was used in diffusion MR image computation. In our
study, totally 52 volumes were collected with 12 gradient directions computed at every voxel. The original image format was
Siemens Trio DICOM, which was converted to NIfTI through
using the software package DCM2NII [30]. Next, the DCM2NII
was employed to extract gradient directions and b-values and
the results were saved as two text files, which were then used by
software libraries FSL [31] and MedINRIA [32]. A Bayesian
framework [33] was used to compute and analyze the tractography fiber distribution, whose procedure was described in the
following algorithms.
1) Affine registration algorithm of FSL was first used to register the sequence of 52 echo planar volumes to a reference
volume to correct the stretches and shears in the diffusionweighted images caused by head motion and Eddy currents
in the gradient coils.
2) The corrected diffusion MR image was then registered to
the T1 -weighted anatomical MR brain image through a
mutual information-based registration algorithm with 256
histogram bins used.
3) MedINRIA was used to extract DTI fibers from the registered diffusion-weighted images and gradient direction
file, during which fractional anisotropy (FA) was employed
to characterize the structural anisotropy in the brain, and
the FA pixels were colorized in relation with the principal
directions of the white matter diffusion.
III. METHODS

correct depth texture computing and opacity blending. In our
algorithm, we successfully addressed these issues, i.e., multiple
volumetric data are loaded and visualized simultaneously on
graphics hardware, and geometry polygon-based DTI fibers are
integrated into the rendering pipeline and displayed with correct
opacity blending through depth texture indexing, computation,
and comparison. The working procedure of our algorithm is
that at every sampling point during volume rendering process,
acquire voxel values from multiple volumes, compare the sampling location with geometry-based polygon fibers, and fuse
the acquired scalar values together using depth texture-based
alpha blending. The final multimodality image and DTI fibers
are visualized in one 3-D and three 2-D display windows. The
detailed implementation will be described in Section III-C.
We briefly describe the GPU-based volume rendering algorithm used in our software platform. The graphics vertex and
fragment processors of OpenGL shading language (GLSL) were
used for volume rendering. First, load the volumetric raw data
and color table to the graphics memory as 3-D and 2-D textures.
Transform their texture coordinate from object space to local
texture space. These transformed texture coordinates are first
loaded to the vertex shader, interpolated, and then output to the
fragment shader. In the fragment shader, the interpolated 3-D
texture coordinates were first scaled by factors derived from the
dimension of the volumetric raw data, and were then used as the
entry point for the casting ray. The algorithm then obtained the
camera position from the model view matrix. The casting ray
entry point and the camera position are used to compute the ray
direction.
Next, a light emission-absorption optical model is used to
statistically simulate light passing through, and being reflected
by clouds of similar small particles [34], which is described in
(1), whose solution is given in (2), showing the intensity of each
pixel
dI(ζ)
˜
= c(ζ)τ (ζ) − I(ζ)τ (ζ) = c̃(ζ) − I(ζ)
dζ
 D

 ζ

I(D) = I0 T (D) +
c̃(ζ)exp − τ (t)dt dζ.
0

(1)
(2)

0

The first term I0 demonstrates light coming from the background, and D is the extent of the ray over which light is emitted.
The last term illustrates the behavior of the volume emitting and
absorbing incoming light. The Riemann sum is employed to
discretize the continuous function (2), resulting front-to-back
alpha blending

A. Extended Volume Rendering
Direct volume rendering was employed to display the acquired multimodality neurological data, i.e., anatomical MR
images, angiography MR images, and functional MR images. To
improve data navigation, in our visualization framework, multiplane reformatting was integrated with GPU-based raycasting
algorithm. In our system, the data processing and visualization
algorithms were totally compatible with the VTK programming
pipeline, which cannot visualize and fuse multiple volumetric
images correctly and also cannot integrate polygon data with

295

I(D)f

b

=

n

i=0

αi Ci

i−1

j =0

Tj =

n

i=0

αi Ci

i−1


(1 − αj )

(3)

j =0

where the item αi Ci is the total light emitted from a point
i. Tj (0 ≤ Tj ≤ 1) is the transparency of the point, and αj
is its opacity, which is defined as αj = 1 − Tj . Finally, alpha
blending was sued to blend the derived destination color with
the background color, and set the result as the output fragment
color.

296

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

B. VOI-Based DTI Fiber Visualization
1) Data File Format: To provide a simple method to communicate data between different software packages, in our system,
the extracted DTI fibers are saved in ASCII or binary Legacy
VTK format, including header, title, data type, i.e., either ASCII
or BINARY, geometry/topology, i.e., POLYDATA, and dataset
attributes. The concentrate explanation of the data format is
described in the Appendix.
2) DTI Dynamic Visualization Algorithm: When the DTI
fibers of the whole brain have been extracted from the acquired
diffusion tensor images and stored in a data file with format
illustrated in Section III-B1) “Data file format,” our software
platform can dynamically generate multiple VOIs to specify
the extracted fiber tracts and render part of these fibers that pass
through the VOIs in real time. Our algorithms were implemented
in new classes that were compatible with existing VTK classes
and programming pipelines. In this section, we describe our
multi-VOI specified DTI fiber visualization algorithm.
(1) From the input data stored in vector format, our software acquires the dataset’s information and polygon data,
which are used to initialize and allocate the memory of
the algorithm’s output data. The format of the input data
file Θ0 has been described in the Section III-B1) “Data
file format,” including points, lines, and color scalars.
(2) After initialization and memory allocation, set the acquired exact data extent, points, point scalar values (being
used for color encoding of every point on this line, and
the line segment color between two neighboring points
is linearly interpolated), and lines to the output data.
(3) The total number of VOI Φk in our system is assumed to
be N (N = 2 in our experiment), whose left low corner
and right high corner of the cuboid are (xM ink , yM ink ,
zM ink ) and (xM axk , yM axk , zM axk ) (k = 0, 1, . . .,
N −1), respectively, and the dimension and location of
these VOIs Φk can be dynamically updated.
(4) Assume there are m0 polypoint lines in the input data
Θ0 , for every line li0 (i = 0, 1, ..., m0 −1), there are np0i
points pji with coordinate (pxji , pyij , pzij ), while j = 0, 1,
. . ., np0i -1 and i = 0, 1, . . ., m0 −1. For every polypoint
line li0 (i = 0, 1, . . ., m0 −1) in the data file Θ0 , first
check whether there is at least one point that is located
inside the VOI Φ0 through serially testing xM in0 ≤ px0j
≤ xM ax0 && yM in0 ≤ pyj0 ≤ yM ax0 && zM in0 ≤
pzj0 ≤ zM ax0 (j = 0, 1, . . ., np0i −1).
(5) If one of these tests is true, stop the subsequent testing
along this line and the whole line li0 is put into the first
step output with all the information such as points and
scalar values. Now, we can generate a new data file Θ1
and assume there are m1 lines in it (m0 ≥ m1 ), which is
a subset of the original input dataset Θ0 .
(6) The data file Θ1 and polypoint line li1 (i = 0, 1, . . .,
m1 −1) are used as a new input file, repeat the previous
operation, getting a new data file Θ2 . This is a loop
computation and the algorithm will stop when the system
has checked all of the VOIs Φk (k = 0, 1, . . ., N −1).
The final output data file is ΘN −1 .

Fig. 1. Diagram describes the computation of DTI fibers passing through
multiple VOI. Note, here l00 , l01 , and l02 represent the same polydata line, and l10
and l11 represent the same line.

In our software system, all the VOIs Φk (k = 0, 1, . . ., N −1)
can be dynamically updated in real time and the number N
can also be updated during the DTI rendering process, so we
can dynamically display DTI fibers passing through a multiple
region of interest. Fig. 1 illustrates an example of the DTI fiber
visualization algorithm. There are two VOIs Φ0 and Φ1 , and
the original dataset Θ0 includes three lines li0 (i = 0, 1, 2)
with point number 9, 6, and 5, respectively. After the first step
testing, there are two lines l00 and l10 left, whose names are
also updated to l01 and l11 , respectively. In the dataset Θ1 , after
the second step testing, there is only one line l00 left in the
output dataset Θ2 , whose name is updated to l02 . The final output
line l02 is rendered with color encoded at every point p0j (j =
0, 1, . . ., 9) in real time. Using the described algorithm, our
system can dynamically display fibers passing through multiple
interactively updated VOIs, so the users can show a subset of
the whole DTI fibers to inspect specified fiber path of interest
during neurological data exploration process.
C. Multimodality Neurological Data Rendering
In this section, we describe the volume rendering pipeline of
multimodality neurological data fusion and geometry polygonbased DTI fiber integration. In the rendering procedure, the FBO
is used for render-to-texture operation in real time. It is a window
system independent off-screen rendering technique, working
as an extension of OpenGL for flexible off-screen rendering.
Through capturing images that would normally be drawn to the
screen, it is used to visualize multiple medical volumes and
geometry textures in the same rendering procedure.
Sampling Point Indexing: In our software framework, two
vertex and fragment shader pairs Π1 and Π2 are created. Π1
is used to render the polygon-based DTI fibers, while Π2 is
employed to display the fused multiple volumes with the DTI
fibers included. Three FBOs are created, each of which has a
unique color and depth texture pair attached.
(1) The front face color and depth of the volume object.
(2) The back face color and depth of the volume object.

ZHANG et al.: MULTIMODALITY NEUROLOGICAL DATA VISUALIZATION WITH MULTI-VOI-BASED DTI FIBER DYNAMIC INTEGRATION

297

Fig. 2. Working pipeline of multimodality neurological data acquisition and volumetric reconstruction, visualization, voxel classification, and fusion with DTI
fibers. In addition, three cross-volume planes are also integrated into the neurological navigation in real time. The DTI fiber passing through two VOIs, i.e., VOI1
and VOI2 . In our algorithm, after 3-D image registration, the three visualized neurological volumes have the same size.

(3) The color texture of the DTI fibers, and the depth texture
of the front face of these geometry polygon-based fibers.
Multiple 3-D dataset along with the corresponding color
lookup tables are loaded to the GPU fragment shader as 3-D
and 2-D texture, respectively, and the three newly generated
2-D texture pairs are also loaded to this fragment shader. In
the graphics memory depth buffer, a point’s associated depth
is nonlinearly related to its texture coordinate, therefore, it is
difficult to precisely compute its depth value. A “depth texture
indexing” algorithm is used to address this issue. First, acquire
the texture color coordinate and depth value of the front and
back faces of the volumetric object, getting the corresponding
color and depth textures, i.e., ςcf , ςcb , and ςdf , ςdb . Then, an
adjustable sampling number n is set to calculate sampling steps
of the color- and depth-texture: spc = |ςcb − ςcf |/n and spd
= |ςdb − ςdf |/n, where spd is referenced as the “depth texture
indexing” step length.
Due to clipping, for a casting ray r(t) in volume rendering
process, its actual entry and exit point may be not the same
as the volume boundaries, so the intersections of the ray r(t)
and clipping planes cpi (i = 0, 1, . . . , 5) were calculated, and
the two points with the shortest distances were used as the


, ςcb
, respectively. Then,
ray’s new starting and ending points ςcf


compute the number of skipped samplings nsp = |ςcf − ςcf
|×


ns /spc + 0.5 , while nsp is used to find the new start points pcs
and pds : pcs = ςcf + nsp × spc , and pds = ςdf + nsp × spd .
1) Multivolume Visualization With DTI Fiber Integration:
The following items describe our GPU-accelerated multimodality volume rendering and fusion algorithm with integration of
DTI fibers and three cross-volume navigation planes, i.e., sagittal, axial, and coronal planes. As illustrated in Fig. 2, all the
registered 3-D medical images are of the same size, and 3-D
texture used to store the anatomical brain data works as main
texture with name Ψ0 , while the textures storing angiography
and fMRI of foot motion are named as Ψ1 and Ψ2 , respectively,
and Γi (i = 0, 1, 2) is employed to represent their corresponding color and opacity lookup table. We assume there are M
multimodality neurological volumes.
(1) Compute color texture coordinates of the front and back
face of the texture volume Ψ0 on the GPU fragment
shader, i.e., ςcf and ςcb . Send a casting ray r(t) from every
pixel p on the display plane and calculate the segment
length l of r(t) within the volume Ψ0 . If l = 0, stop
processing the ray r(t), otherwise, go to step (2).


, ςcb
with
(2) Calculate the ray r(t) entry and exit points ςcf
clipping planes cpi (i = 0, 1, . . . , 5), which are used
to compute the skipping steps nsp , as well as the new
starting point pcs and the depth comparison point pds .

298

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

Fig. 3. Diagram describing the software platform’s architecture and functions, including data navigation and synchronization, volumetric image generation and
adjustment, cross-volume plane and 3-D volume management and navigation guidance, as well as DTI fiber visualization, manipulation and VOI-based rendering.

(3) Acquire the texture colors and depths of the DTI fibers
h
h
and ζdf
(h = 0, 1, . . ., H, and H is the numfront face ζcf
ber of total fibers visualized). When three cross-volume
planes are visualized, the texture color and depth of the
intersection of the casting ray r(t) with plane are also
cr
cr
and ζdf
. In our system, the texture
calculated, i.e., ζcf
pair with the smallest depth is selected in the computing
pipeline, i.e., ζcf and ζdf .
(4) At sampling point pk , lookup table Γi is used to map
the scalar values ski to color Cik and opacity αik (i =
0, 1, . . . , M ; k = 0, 1, . . . , N ), N is the total sampling
steps along r(t). Compute color C k and opacity αk at
the point pk
k

C =

M
−1


	
Cik

i=0
k

α =

M


αik .

1−

M
−1




αjk

(4)

j =0,j = i

(5)

i=0

(5) Assume the accumulated color and opacity at the samk −1
k −1
pling step k − 1 are Cac
and αac
, respectively, calculate the accumulated color and opacity at the sampling
k
k
and αac
step k, i.e., Cac


k
k −1
k −1
+ αac
Cac
= C k 1 − αac
(6)


k
k
k −1
k −1
αac = α 1 − αac + αac .
(7)
(6) Update the texture coordinate pcs and depth pds using
the step size spc and spd , respectively.
(7) Compare the updated depth with the depth of the DTI
fibers front face ζdf acquired from step (3). If the depth is
equal to or greater than ζdf , or the accumulated opacity
is larger than the preset threshold αm ax , or the accumulated sampling length is greater than l, stop the sampling
process along r(t). Otherwise, continue the sampling
process.
(8) After r(t) is stopped, assume totally sampling K steps
K −1
+
Compute the output color Cf = Cac
(K ≤ N ).
K −1
K −1
1.0 − αac × (1.0 − ϑ) × ζcf . Here, Cac is the accumulated opacity-associated color, ζcf is the fetched
color texture of the geometry objects, and ϑ (ϑ ∈ [0, 1])
is the transparency adjustment factor.

IV. PLATFORM ARCHITECTURE
The software platform was designed and developed with an
object-oriented approach using C++, OpenGL, and GLSL, as
well as VTK and ITK. It supplies functions for interactive
graphical user interface (GUI) and medical data I/O management, which were implemented with open-source libraries such
as Qt, CTK [35], and MITK [36], connecting user–computer’s
interactions with the system’s core functions of multimodality
neurological data exploration and multi-VOI specified DTI fiber
real-time tracking and visualization.
The main reason we choose Qt, CTK, MITK is that they
support multiple operation systems and can be seamlessly integrated with C++, OpenGL, GLSL, and VTK/ITK. They are
better than other GUI development tools, such as Microsoft
Foundation Class Library, which can only be used in windows
system, or scripting language Python or Tcl/Tk, which cannot be seamlessly merged with C++ and lack of efficiency and
flexibility.
As illustrated in Fig. 3, the software architecture was designed
with a functional layer structure. The first layer is the system’s
main I/O, loading various medical data into the software system; the second layer is the main management function, including volumetric medical data management, as well as 2-D/3-D
medical image and DTI fiber inspection; and the third layer is
the concrete implementation, for “volume manager,” the main
functions include multimodality medical image rendering and
fusion, 2-D/3-D image synchronization, transfer function-based
volume adjustment, and optical shading-based rendering result
enhancement, as well as cross-volume plane synchronization
and color mapping. For “Image Inspector,” the main functions
include the management of cross-volume navigation planes and
volumetric data, 2-D/3-D image fusion, VOI-specified DTI fiber
visualization, as well as real-time updated system feedback information for providing users with interactive guidance information during neurological data navigation process.
All these functions for neurological data exploration are built
on top of our real-time DTI fiber visualization and multiple
VOI-based fiber tract navigation algorithm as described in the
Section III-B2) “DTI Dynamic Visualization Algorithm III-B2,”
and the algorithm of GPU-accelerated multivolume rendering
with DTI fiber integration that is illustrated in the Section IIIC1) “Multivolume Visualization with DTI Fiber Integration.”
Two snapshots of the described software platform are shown

ZHANG et al.: MULTIMODALITY NEUROLOGICAL DATA VISUALIZATION WITH MULTI-VOI-BASED DTI FIBER DYNAMIC INTEGRATION

299

Fig. 5. Diagram describing DTI fiber visualization. (a) DTI fibers of the whole
brain; (b) DTI fibers passing through one VOI or (c), (e) two VOIs; (d) VOIspecified DTI fibers fused with blood vessels, as well as (f) VOI-specified DTI
fibers fused with blood vessels and fMRIs.

ration, and dynamic visualization. The graphics hardware used
in the experimentation included Nvidia GeForce 7900 GTO,
GTX 280, GTX 480, and GTX 680 and GTX 690, and their
graphics memories were 512 MB, 1, 1.5 GB, and 4, and 4G,
respectively. Nvidia GeForce R310 driver with version 310.90
was installed to support graphics acceleration.
Fig. 4. Two snapshots of the described software platform, whose main function includes multimodality neurological data visualization and fusion in both
one 3-D rendering window and three 2-D display windows with DTI fibers
passing through multiple VOIs. In the top figure, the 3-D brain volume is rendered semitransparently, so the users can see the inside data structures and DTI
fibers from outside of the brain volume, and the size of the 2-D and 3-D display
windows are the same. In the bottom figure, the 3-D render window has larger
size than the three same-size 2-D rendering windows. In addition, the 3-D brain
volume is cut, so the inside anatomic structures and DTI fibers can be seen
interactively.

in Fig. 4, in which the displayed data information is fused in
one rendering environment for neurological disease diagnosis,
treatment planning, and real-time neurological data exploration.
V. RESULTS AND ANALYSIS
As described in the Section II “Data Acquisition and Processing,” the multimodality neurological images were acquired
from a Siemens TrioTim 3T MR scanner, including anatomical
image, i.e., T1 and T2 -weighed MR brain images, segmented
white and gray matters, angiographic MR image, as well as
functional MR images, i.e., time-series BOLD fMRI images for
stimulus of foot and finger motion. In addition, DTI fibers were
first extracted from acquired MR diffusion images and, then,
were registered to the anatomical brain image.
The software platform running environment was Microsoft
Windows 7 Professional 64 bit, and the implementation hardware included an Intel Core i7-3770K processor (Ivy Bridge
3.5 GHz, 5.0 GT/s Intel QPI), and 32-GB DDR3 PC3-10600
memory (4 × 8 GB). Four generation Nvidia graphics cards
were used to evaluate the performance of the GPU-accelerated
multimodality neurological data volume rendering and fusion,
as well as multi-VOI specified DTI fiber integration, explo-

A. Visual Results
We have implemented the described algorithms for multiple
VOI specified DTI fiber visualization and multimodality neurological data volume rendering. As shown in Fig. 5(a), our
algorithm can display DTI fibers of the whole brain without
restriction. Due to the large number of tracts displayed, the unspecified fiber visualization cannot clearly show the fiber path
of interest, so can only provide limited structural and diagnostic
information. On the contrary, when selectively rendering fibers
passing through one VOI, as demonstrated in Fig. 5(b), the platform can more clearly display target specified DTI fibers than
those showed in Fig. 5(a). When two VOIs are used to specify
the DTI fiber visualization, the system can display dual or three
fiber bundles passing through these two VOIs from the low brain
to the upper region, which is demonstrated in Fig. 5(c)–(f). The
dimensions and locations of the VOIs can be updated in real
time, so the VOI-specified DTI fibers can be dynamically visualized, showing fiber tracts passing through multiple VOIs
during data exploration process. To provide users with comprehensive diagnostic information, multimodality neurological
data, including anatomical blood vessels and functional MR images, are integrated and visualized with the VOI-specified DTI
fibers, whose result is illustrated in Fig. 5(d) and (f).
As shown in Fig. 6(a), the whole brain image can be volume rendered semitransparently and fused with the neurological data displayed in Fig. 5(f). The rendered whole brain image
can provide context anatomical structure, in which DTI fibers,
blood vessels, functional MR images, and their spatial structures can be clearly displayed. As described in Fig. 6(b)–(d),
up to three cross-volume planes are visualized with DTI fibers,
functional MR images, and blood vessels. The navigation planes
can be interactively selected and manipulated, for example, only

300

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

TABLE I
VOLUME RENDERING PERFORMANCE COMPARISON BY USING FOUR
GENERATIONS OF GRAPHICS HARDWARE
Rendering Speed (fps) of Various Images

Fig. 6. Diagram showing DTI fibers and multifunction neurological images
for exploring multiple brain images. (a)–(f) DTI fibers are fused with blood
vessels, functional MR images, and gray matter/white matters. (a) and (b)–(f)
Semitransparent anatomical whole brain image is added. (b)–(f) Data navigation
planes are used to navigate the volume. (c)–(f) Brain volume is clipped with
data navigation planes and is rendered with various data information.

transversal and coronal planes are displayed in Fig. 6(b). While
the same volume navigation planes are visualized as Fig. 6(b),
the whole brain image is included and volume rendered semitransparently in Fig. 6(c), so the inner brain structures and the
spatial relationships of the multifunction neurological images
and DTI fibers can be viewed. In Fig. 6(d), three cross-volume
planes are visualized with the multimodality neurological images as shown in Fig. 6(b) and (c). The images displayed on
the cross-volume planes in Fig. 6(b)–(d) are human brain gray
matter and all the visualized images are registered and fused in
a unified coordinate system.
In the described visualization platform, the white matter can
also be displayed independently or fused on the image planes,
as shown in Fig. 6(b) and (f). The image navigation planes can
be used to clip brain volume, showing solid and semitransparent
regions of the 3-D brain image simultaneously in a volume visualization environment. The dynamically updated DTI fibers,
blood vessels, and functional MR images of hand stimulus are
visualized in real time with respect to the cross-volume planes in
the semitransparent region of the volume rendered brain, showing the connections and spatial relationships between different
structure of interest.
B. Rendering Performance
The performance evaluation of medical data rendering includes multimodality volumetric neurological image visualization and DTI fiber dynamic display. Our algorithms are GPU
accelerated, so their performance should be graphics hardware
related, which means that when updating to a newer generation
GPU, the performance of our system will be improved correspondingly. To test the extent of the performance improvement
and estimate the improvement potential of our system when updating to newer generation GPUs, four generation Nvidia GPUs
were used to quantitatively analyze the performance of neurological data display and fusion, as well as multi-VOI specified
DTI fiber integration and dynamic rendering. The dimension of
the main rendering window is 1000 × 1000, the camera posi-

Graphics
hardware

Brain
volume

White
matter

Blood
vessel

fMRI
image

DTI
fibers

7900 GTO
GTX 280
GTX 480
GTX 680

4.6
50.2
60.0
60.0

1.5
24.1
30.3
45.8

0.8
15.8
21.7
30.1

0.6
12.0
16.1
23.1

0.5
10.5
14.7
21.6

The dataset used in the experiment includes single anatomic
brain volume and multiple neurological data (anatomic brain,
fMRI of hand stimulus, blood vessel, and DTI fiber tracts). The
measurement of rendering speed is fps. Note, in the rendering
volumes, white matter means brain + white matter, fMRI image
means brain + white matter + fMRI image, and DTI fibers means
brain + white matter + fMRI image + DTI fibers.

Fig. 7. Average rendering speed of the five dataset as described in the Table I
and the standard deviation (SD) of mean is shown in the mean bar, during which
four graphics cards are used in the visualization process.

tion is (556, 358, 192) with focal point (0.0, 238.5,−6.0). The
dimensions of the rendering windows and visualized image are
similar to those used in the clinical practice.
As shown in Table I, for single whole brain volume, we can
achieve real-time performance when using graphics hardware
above GeForce 400 series. However, for multimodal rendering,
only GTX 680 can deliver rendering speed above 20 frames
per second (fps). Fig. 7 demonstrates that when compared with
the rendering speed of using GeForce 7900 GTO, mean performance increase can achieve ∼22 times faster when using the
newest generation graphics hardware, i.e., Nvidia GTX 680, and
the standard error of the mean of the high-performance rendering is ∼7.3, which is similar with that of GTX 280 and 480.
When compare the last two generation graphics hardware, the
average speed increase is ∼26.5%, which can be attributed to the
higher memory clock frequency and optimized graphics structure. When displaying the moderate neurological image that
can be totally loaded into the graphics memory, large graphics memory, such as 4-GB memory, does not give detectable
performance increase. We also find that the number of GPU

ZHANG et al.: MULTIMODALITY NEUROLOGICAL DATA VISUALIZATION WITH MULTI-VOI-BASED DTI FIBER DYNAMIC INTEGRATION

shaders and shader clock frequency are important to improve
the rendering speed.
The DTI fiber integration has little impact on the overall
rendering performance with speed decrease from ∼6.5% to
∼12.5%, which could be attributed to the usage of the fast
depth texture indexing algorithm, i.e., the fibers’ location can
be detected in real time during volume rendering process and the
ray casting computation will be dynamically terminated at the
detected fibers’ locations. When rendering large medical data
that cannot be loaded to the graphics memory directly, rendering speed degradation maybe detected. To address this issue,
dynamic multiresolution and texture blocking algorithms can
be employed to improve the overall visualization performance.
C. User Study
The developed software is not a comprehensive platform. The
main target of this paper is to develop new and efficient algorithms for multimodality neurological image visualization with
multiple VOI-based DTI fiber dynamic integration. To verify
the efficiency and usefulness of the developed algorithms and
technologies, we invited ten users with workable knowledge of
neurology, medical image, and brain anatomical structure to use
our software system to visualize DTI fibers and capture target
of interest in a multimodality neurological image rendering environment. We compared users’ performance of tracking DTI
fibers passing through multiple regions of interest within brain
and detecting their spatial relationships with fMRIs of hand and
foot stimulus, as well as blood vessels and white matters. This
experiment was designed to evaluate the function of our software
platform in improving the users’ performance of interacting and
analyzing 3-D brain structures and DTI fibers, and guiding them
to capture targets of interest and detect the connections of brain
functions and anatomic regions through data navigation.
In this study, two separate tracts in spinal cord were studied,
i.e., the lateral corticospinal tract and the anterior corticospinal
tract. The investigated spinal tracts can show the impulses from
brain to spinal cord, which contain most motor axons. Rendering and exploring the studied DTI fiber tracts can lead to an
understanding of one side of the body is controlled by the opposite side. We first asked users to use our software platform
to visualize DTI fibers with only one VOI to show the relationships between fMRI and blood vessels, and detect the spatial
locations of fibers that connect the inferior frontal gyrus and
occipitotemporal cortex. As a comparison, in the next step of
the experiment, the users employed our multi-VOI guided DTI
fiber tracking and rendering methods to repeat the tasks, during which the entire brain image was used as an anatomical
context reference and cross-volume navigation planes were also
integrated to detect the brain structures of interest.
As shown in Table II, there are seven neurological image guidance and visualization methodologies used in this experiment,
which are labeled as (i)–(vii). The users’ rankings are listed in
Table III, which are based on the users’ subjective judgement
of visual efficiency and guidance improvement. Fig. 8 shows
the mean value and standard deviation (σ) of the users’ ranking
marks, where σ is used to show the data variations from the
mean value.

301

TABLE II
INDEX OF THE NEUROLOGICAL IMAGE GUIDANCE METHODOLOGIES USED TO
HELP USERS TO NAVIGATE THE MULTIFUNCTION NEUROLOGICAL DATASET
AND FIND THE CONNECTIONS AND RELATIONSHIPS BETWEEN FUNCTIONAL
AND ANATOMICAL REGIONS
Index

Neurological Image Guidance Methodologies

(i)
(ii)
(iii)
(iv)
(v)
(vi)
(vii)

DTI fiber visualization
fMRI
Dynamically updated single VOI
Dynamically updated multiple VOI
Angiographic images, i.e., blood vessels
Three cross-volume navigation planes
Volume rendered entire brain image, solid/semitransparent

In each of these tests, (i) and (ii), i.e., the visualization of DTI
fibers and fMRIs were used as basic guidance means, and (iii),
i.e., dynamically updated single VOI or (iv), i.e., dynamically
updated multiple VOIs was first added to the display platform.
When comparing (iv) with (iii), we can see that the users’ mean
ranking was improved by ∼76% with σ decreased from 0.52
and 0.28, which means that the improvement was steady and
relatively uniform. In addition, when (v) was added to (iii) and
(iv), due to the integration of anatomic guidance information,
the users’ mean marks were further increased ∼38% and ∼16%,
respectively, with σ decreased ∼12% and the standard error of
mean decreased from 0.16 to 0.14 (iii) and from 0.09 to 0.08 (iv).
When three cross-volume planes were included, the visualization system could give users more data navigation choice, and
the users could locate fibers, fMRIs, and blood vessels with precision. The average marks were therefore improved by ∼12%
for both (iii) and (iv). Finally, when the entire brain volume was
displayed semitransparently as a comprehensive guidance for
data exploration (vii), the users’ ranking was improved ∼11%
and ∼13%, respectively. From Fig. 8, we can also detect that
when using multiple VOI as a guidance method, i.e., (iv), the
σ is smaller than that of using single VOI, i.e., (iii), whose
mean value are 0.25 and 0.45, respectively, which means that
the users’ rankings were more uniform when using (iv) as a
main guidance method than those of using (iii).
Preliminary user evaluation results indicate that our developed neurological data visualization and multi-VOI-based DTI
fiber display system can facilitate the interactive exploration of
brain fibers within their anatomical context and can help users
to discover features that are correlated with disease in neurological datasets. By combining anatomical and functional image
information acquired from the reference brain data with the overlaying dynamic multi-VOI-specified DTI fibers, the described
software framework can give the first hints to the anatomical
context of the fiber tracts and show their spatial relationships
with brain structures of interest.
To define a measure that meets the criteria of physicians
involves validating various clustering quality parameters. This
is done by letting physicians create a ranking of a number of
clustering results. This ranking is then used as a ground truth
for the ranking created by the clustering quality measures. The
procedure allows us to analyze and define a new measure that has
the highest correlation with the ranking of the physicians. This
is then used to analyze the different algorithms by finding the

302

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

TABLE III
USER STUDY AND RANKING OF USING DIFFERENT NEUROLOGICAL IMAGE GUIDANCE METHODS AND THEIR COMBINATIONS FOR EXPLORING BRAIN FUNCTIONS,
STRUCTURES, AND THEIR SPATIAL RELATIONSHIPS
Navigation Method
Combination
a: (i), (ii), (iii)
b: (i), (ii), (iv)
c: (i), (ii), (iii), (v)
d: (i), (ii), (iv), (v)
e: (i), (ii), (iii), (v), (vi)
f: (i), (ii), (iv), (v), (vi)
g: (i), (ii), (iii), (v), (vi), (vii)
h: (i), (ii), (iv), (v), (vi), (vii)

User Ranking
User 1

User 2

User 3

User 4

User 5

User 6

User 7

User 8

User 9

User 10

2.0
3.2
2.5
3.6
2.8
3.8
2.9
4.2

2.3
3.7
2.9
4.2
3.0
4.6
3.1
4.9

1.3
3.1
2.1
3.9
2.3
4.2
2.5
4.5

1.1
2.9
1.8
3.8
2.0
4.1
2.4
4.8

2.5
3.6
3.2
3.9
3.3
4.3
3.6
4.9

1.9
3.3
2.3
3.6
2.9
4.0
3.3
4.7

2.2
3.3
2.9
3.7
3.2
4.2
3.4
4.9

1.0
2.8
2.0
3.3
2.7
3.9
3.2
4.5

1.9
3.0
2.7
3.5
3.0
4.2
3.5
4.7

2.1
3.2
2.8
3.8
3.1
4.3
3.6
4.8

The ranking scores are based on how much guidance information provided and how easy to use such guidance information. The highest score
is 5, while the lowest one is 0. The ranking numbers are based on the users’ subjective judgement and only giving an approximate index of
the performance and efficiency evaluation.

Fig. 8. User ranking of the efficiency of the system’s visualization methods
and imaging modalities, during which the mean value and standard deviation
are used to measure the users’ ranking. Note, the index in the x -axis a–h are the
same as the index in the Table III.

optimal clustering results and comparing their quality measure
value.
As described in the Section II-B, FSL was used in the diffusion MR image correction and registration to the T1 -weighted
anatomical MR brain image, and MedINRIA was used for fiber
extraction. The registration accuracy and the goodness of our extracted DTI fibers in this experiment are supported through our
experiment results, user feedback, and the published research
results of these two software packages.
VI. CONCLUSION
In this study, we introduced a software framework for neurological data and DTI fiber visualization and exploration, combining the anatomical and functional brain image information
with the overlaying DTI fibers. When compared with existing
software packages and published researches, the advantage of
our software platform is that a new DTI fiber rendering algorithm was implemented on GPUs, in which neuronal white
matter fiber tracts were dynamically visualized and updated with
the specification of multiple VOIs. The dynamically displayed
DTI fibers were integrated with GPU-accelerated multimodality neurological image volume rendering and fusion, and up to

three volumetric medical data navigation planes were employed
to provide users with guidance information and to reveal crucial
neurological tissue structures and their connections.
The main limitation of this software platform is that it should
be tested on medical data from patients ready for surgery, which
is one of the most important purposes of this project. This is
one of the important tasks of our future work. Currently, the
platform’s performance was tested with different generation
graphics hardware and the platform’s function was evaluated
by neurologists and medical imaging researchers through using neurological data acquired from volunteers. Furthermore,
the software libraries such as FSL and MedINRIA were used
for fiber extraction and image processing. It will be useful to
integrate such functions and libraries into our software in the
future development of this platform. The presented results will
provide clinicians with an insight into the medical datasets, improve their understanding of brain structures and functions, and
enhance their ability of precisely locating lesions and knowing
their spatial relationships with healthy tissues.
APPENDIX
The following is the description of the DTI fiber data format
used in our software platform.
# vtk DataFile Version 3.0
vtk output
ASCII | BINARY
DATASET POLYDATA
POINTS n dataType
p0x p0y p0z
p1x p1y p1z
...
p(n-1)x p(n-1)y p(n-1)z
LINES m size
numPoints0, i0, j0, k0, ...
...
numPoints(m-1), i(m-1), j(m-1), k(m1), ...
POINT_DATA n

ZHANG et al.: MULTIMODALITY NEUROLOGICAL DATA VISUALIZATION WITH MULTI-VOI-BASED DTI FIBER DYNAMIC INTEGRATION

COLOR_SCALARS dataName nValues
c00 c01 ... c0(nValues-1)
...
c(n-1)0 c(n-1)1 ... c(n-1)(nValues-1)
In the above text file, the “dataType” is float and “nValues” is
3, which indicates that the scalar value is mapped to a color with
three channels. If the file format is ASCII, every color channel
is defined as float in the range of (0, 1), while the file format is
BINARY, the stream of data consists of the number of “nValues”
unsigned chars per scalar value. There is the same number of
point and color in the described fiber dataset, i.e, for every point
there is a corresponding color, and linear interpolation is used
to set the line segment color between the neighboring points.
ACKNOWLEDGMENT
The authors would like to Dr. U. Sboto-Frankenstein for her
clinical validation of the DTI fiber and fMRI analysis results,
and they would also like to thank researchers at the National Research Council Institute for Biodiagnostics, Winnipeg, Canada,
for evaluating the developed algorithms and software platform.
REFERENCES
[1] K. Doi, “Computer-aided diagnosis in medical imaging: Historical review,
current status and future potential,” Comput. Med. Imag. Graph., vol. 31,
nos. 4/5, pp. 198–211, 2007.
[2] P. J. Basser, S. Pajevic, C. Pierpaoli, J. Duda, and A. Aldroubi,
“Fiber tractography using DT-MRI data,” Magn. Reson. Med., vol. 44,
pp. 625–632, 2000.
[3] L. J. O’Donnell and C.-F. Westin, “An introduction to diffusion tensor image analysis,” Neurosurg. Clin. North Amer., vol. 22, no. 2,
pp. 185–196, 2011.
[4] M. M. Thurnher and M. Law, “Diffusion-weighted imaging, diffusiontensor imaging, and fiber tractography of the spinal cord,” Magn. Reson.
Imag. Clin. North Amer., vol. 17, no. 2, pp. 225–244, 2009.
[5] D. Dodell-Feder, J. Koster-Hale, M. Bedny, and R. Saxe, “fMRI
item analysis in a theory of mind task,” NeuroImage, vol. 55, no. 2,
pp. 705–712, 2011.
[6] T. A. Brown, M. F. Joanisse, J. S. Gati, S. M. Hughes, P. L. Nixon, R. S.
Menon, and S. G. Lomber, “Characterization of the blood-oxygen leveldependent (BOLD) response in cat auditory cortex using high-field fMRI,”
NeuroImage, vol. 64, pp. 458–465, 2013.
[7] T. Ethofer, M. Gschwind, and P. Vuilleumier, “Processing social aspects
of human gaze: A combined fMRI-DTI study,” NeuroImage, vol. 55,
no. 1, pp. 411–419, 2011.
[8] P. Svetachov, M. H. Everts, and T. Isenberg, “DTI in context: Illustrating brain fiber tracts in situ,” Comput. Graph. Forum, vol. 29, no. 3,
pp. 1023–1032, 2010.
[9] O. Clatz, S. Litrico, H. Delingette, P. Paquis, and N. Ayache, “Dynamic
model of communicating hydrocephalus for surgery simulation,” IEEE
Trans. Biomed. Eng., vol. 54, no. 4, pp. 755–758, Apr. 2007.
[10] E. Angelini, O. Clatz, E. Mandonnet, E. Konukoglu, L. Capelle, and H.
Duffau, “Glioma dynamics and computational models: A review of segmentation, registration, and in silico growth algorithms and their clinical
applications,” Current Med. Imag. Rev., vol. 3, no. 4, pp. 262–176, 2007.
[11] M. Shenton, H. M. Hamoda, J. S. Schneiderman, S. Bouix, O. Pasternak,
Y. Rathi, M. A. Vu, M. Purohit, K. Helmer, I. Koerte, A. P. Lin, C.-F.
Westin, R. Kikinis, M. Kubicki, R. A. Stern, and R. Zafonte, “A review
of magnetic resonance imaging and diffusion tensor imaging findings in
mild traumatic brain injury,” Brain Imag. Behav., vol. 6, pp. 1–9, 2012.
[12] K. M. Hasanemail, I. S. Walimuni, H. Abid, and K. R. Hahn, “A review
of diffusion tensor magnetic resonance imaging computational methods
and software tools,” Comput. Biol. Med., vol. 41, no. 12, pp. 1062–1072,
2011.
[13] V. Prckovska, T. Peeters, M. van Almsick, B. ter Haar Romeny, and A.
Vilanova i Bartroli, “Fused DTI/HARDI visualization,” IEEE Trans. Vis.
Comput. Graph., vol. 17, no. 10, pp. 1407–1419, Oct. 2011.

303

[14] R. Brecheisen, A. Vilanova, B. Platel, and B. ter Haar Romeny, “Parameter
sensitivity visualization for DTI fiber tracking,” IEEE Trans. Vis. Comput.
Graph., vol. 15, no. 6, pp. 1441–1448, Nov/Dec. 2009.
[15] A. Bertelsen, P. Irarrazaval, and R. F. Cadiz, “Volume visualization using
a spatially aware mobile display device,” Comput. Med. Imag. Graph.,
vol. 36, no. 1, pp. 66–71, 2012.
[16] R. Brecheisen, B. Platel, B. ter Haar Romeny, and A. Vilanova, “Illustrative uncertainty visualization of DTI fiber pathways,” Vis. Comput.,
vol. 29, pp. 297–309, 2013.
[17] A. Golby, G. Kindlmann, I. Norton, A. Yarmarkovich, S. Pieper, and
R. Kikinis, “Interactive diffusion tensor tractography visualization for
neurosurgical planning,” Neurosurgery, vol. 68, no. 2, pp. 496–505, 02
2011.
[18] S. Pieper, M. Halle, and R. Kikinis, “3D slicer,” in Proc. IEEE Int. Symp.
Biomed. Imag., Nano Macro., Apr. 2004, vol. 1, pp. 632–635.
[19] H. Elhawary, H. Liu, P. Patel, I. Norton, L. Rigolo, X. Papademetris, N.
Hata, and A. Golby, “Intra-operative real-time querying of white matter
tracts during frameless stereotactic neuronavigation,” Neurosurgery, vol.
68, no. 2, pp. 506–516, Feb. 2011.
[20] H. Peng, A. Bria, Z. Zhou, G. Iannello, and F. Long, “Extensible visualization and analysis for multidimensional images using Vaa3D,” Nature
Protocols, vol. 9, pp. 193–208, 2014.
[21] K. H. Fritzsche, P. F. Neher, I. Reicht, T. van Bruggen, C. Goch, M.
Reisert, M. Nolden, S. Zelzer, H.-P. Meinzer, and B. Stieltjes, “Interactive
diffusion tensor tractography visualization for neurosurgical planning,”
Methods Inf. Med., vol. 51, no. 5, pp. 441–448, Sep. 2012.
[22] I. Wolf, M. Vetter, I. Wegner, T. Böttger, M. Nolden, M. Schöbinger,
M. Hastenteufel, T. Kunert, and H.-P. Meinzer, “The medical imaging interaction toolkit,” Med. Image Anal., vol. 9, no. 6, pp. 594–604,
Dec. 2005.
[23] The 2010 IEEE visualization contest. (2010, Mar.). [Online]. Available:
http://sciviscontest.ieeevis.org/2010/
[24] C. Rieder, F. Ritter, M. Raspe, and H.-O. Peitgen, “Interactive visualization
of multimodal volume data for neurosurgical tumor treatment,” Comput.
Graph. Forum, vol. 27, no. 3, pp. 1055–1062, 2008.
[25] Silvia , W. Daniela, R. Peter, P. Matthias, F. Jan, and B. Dirk, “Neurosurgical Intervention planning with VolV,” in Proc. IEEE Vis. Contest Conf.,
2010 – Honorable Mention, 2010.
[26] M. Pfeifle, S. Born, J. Fischer, F. Duffner, J. Hoffmann, and D. Bartz,
“Volv-eine opensource-plattform für die medizinische visualisierung,”
presented at the Computer-und Roboterassistierte Chirurgie, Karlsruhe,
Germany, 2007.
[27] S. Diepenbrock, J.-S. Prani, F. Lindemann, H.-W. Bothe, and T. Ropinski,
“Pre-operative planning of brain tumor resections,” presented at the IEEE
Vis. Contest 2010, Winning Entry, Salt Lake City, UT, USA, 2010.
[28] O. Vaillancourt, A. Boré, G. Girard, and M. Descoteaux, “A fiber navigator
for neurosurgical planning (neuroplanningnavigator,” in Proc.IEEE Vis.
Conf., Salt Lake City, UT, USA, Nov. 2010, pp. 1–12.
[29] K. Friston, J. Ashburner, S. Kiebel, T. Nichols, and W. Penny, Eds,.
Statistical Parametric Mapping: The Analysis of Functional Brain Images.
San Diego, CA, USA: Academic, 2007.
[30] C. Rorden. (2009). “dcm2nii DICOM to NIfTI conversion,” The
Source for Neuroimaging: MRIcoron. [Online]. Available: http://www.
mccauslandcenter.sc.edu/mricro/mricron/dcm2nii.html
[31] S. M. Smith, M. Jenkinson, M. W. Woolrich, C. F. Beckmann, T. E. J.
Behrens, H. Johansen-berg, P. R. Bannister, M. D. Luca, I. Drobnjak, D.
E. Flitney, R. K. Niazy, J. Saunders, J. Vickers, Y. Zhang, N. D. Stefano,
J. M. Brady, and P. M. Matthews, “Advances in functional and structural
MR image analysis and implementation as FSL,” NeuroImage, vol. 23,
pp. 208–219, 2004.
[32] P. Fillard, J.-C. Souplet, and N. Toussaint, Medical Image Navigation and
Research Tool by INRIA (MedINRIA 1.9) Tutorial v2.0, INRIA Sophia
Antipolis—Research Project ASCLEPIOS, France, Oct. 2009.
[33] S. Jbabdi, M. Woolrich, J. Andersson, and T. Behrens, “A Bayesian framework for global tractography,” NeuroImage, vol. 37, no. 1, pp. 116–129,
2007.
[34] N. Max, “Optical models for direct volume rendering,” IEEE Trans. Vis.
Comput. Graph., vol. 1, no. 2, pp. 99–108, Jun. 1995.
[35] The Common Toolkit (CTK). (2011). [Online]. Available:
http://www.commontk.org.
[36] The Medical Imaging Interaction Toolkit (MITK), 0.14. (2009). Division
Med. Biol. Informat. German Cancer Res. Center, Heidelberg, Germany.
[Online]. Available: http://www.mitk.org.

Authors’ photographs and biographies not available at the time of publication.

