IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 3, MARCH 2015

865

Doppler Radar Fall Activity Detection
Using the Wavelet Transform
Bo Yu Su, Student Member, IEEE, K. C. Ho, Fellow, IEEE, Marilyn J. Rantz, Member, IEEE,
and Marjorie Skubic, Senior Member, IEEE

Abstract—We propose in this paper the use of Wavelet transform (WT) to detect human falls using a ceiling mounted Doppler
range control radar. The radar senses any motions from falls as
well as nonfalls due to the Doppler effect. The WT is very effective
in distinguishing the falls from other activities, making it a promising technique for radar fall detection in nonobtrusive inhome elder
care applications. The proposed radar fall detector consists of two
stages. The prescreen stage uses the coefficients of wavelet decomposition at a given scale to identify the time locations in which
fall activities may have occurred. The classification stage extracts
the time–frequency content from the wavelet coefficients at many
scales to form a feature vector for fall versus nonfall classification.
The selection of different wavelet functions is examined to achieve
better performance. Experimental results using the data from the
laboratory and real inhome environments validate the promising
and robust performance of the proposed detector.
Index Terms—Classifier, Doppler radar, fall detection, wavelet.

I. INTRODUCTION
UMAN falls are a main cause to morbidity among older
adults (aged 65 years and older) [1]. Preventing falls and
detecting when they occur are important for elder care. Timely
detection of falls enables immediate assistance by caregiver and
minimizes the negative consequences of falls [2].
Apart from the clinical techniques, less expensive personal
fall detection devices are becoming available in the commercial market. These devices can be broadly classified as wearable
[3]–[7] and nonwearable [8]–[17]. Nonwearable devices are often nonobtrusive and more acceptable to the users with better comfort. A commonly found nonobtrusive fall detection
device is the video camera [8]–[12], where image processing
techniques can isolate and detect falls. However, visual-based
systems cannot function under low-lighting or occlusion environments. Another is the microphone array that utilizes
the acoustic signal generated from the impact with the floor
for fall detection [13]–[15]. Acoustic devices have the shortcoming of requiring relatively quiet environments with little

H

Manuscript received August 5, 2014; revised October 24, 2014; accepted
October 27, 2014. Date of publication November 4, 2014; date of current version
February 16, 2015. This work was supported by the Agency for Healthcare
Research and Quality under Grant R01HS018477.
B. Y. Su and M. Skubic are with the ECE Department, University of
Missouri, Columbia, MO 65211 USA (e-mail: bsdg6@mail.missouri.edu;
SkubicM@missouri.edu).
K. C. Ho is with the ECE Department, University of Missouri, Columbia,
MO 65211 USA (e-mail: HoD@missouri.edu).
M. Rantz is with the Sinclair School of Nursing, University of Missouri,
Columbia, MO 65211 USA (e-mail: RantzM@missouri.edu).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2014.2367038

multipath reflections. Both the visual and audio systems can
work and complement with each other for inhome fall detection
to provide reliable results. Both cannot be used; however, in the
bathroom area where statistics have shown to be challenging
for fall detection [18]. Having video camera in the bathroom is
obviously not preferred. Also, the small dimension of a bathroom would create too many multipath reflections to render the
proper performance of an acoustic system, not to mention the
strong acoustic interferences from water flowing. In this paper,
we explore a relatively new approach based on motion sensing
by a Doppler range control radar (RCR) that would fill the need
for fall detection, especially in the bathroom.
A human fall generates motion that creates frequency change
between the sent and received signals of a Doppler radar. Analyzing the radar signal carefully can detect human falls [19],
[20]. A Doppler radar fall detection system separates itself from
the image-based and the acoustic-based system in that it can operate in low-lighting and highly noisy environments. In addition,
the radar detection system can address the privacy concerns,
which are particularly crucial in the bathrooms or bedrooms.
One challenge for radar fall detection is that the radar will
generate responses not only from human falls but also from other
human or nonhuman motions. Signal processing is an indispensable component to screen out the nonfall activities for improving
processing efficiency and increasing detection accuracy. Melfrequency cepstrum coefficients (MFCC) have been proposed
previously for radar fall detection [19]. MFCC is known to have
excellent features for speech recognition [21]. However, the rationale of using it in radar is not clear. Extensive evaluations
under practical inhome environments indicate the performance
of MFCC is not adequate and generates an exceeding number
of false alarms in radar fall detection.
This paper investigates another signal processing technique
called Wavelet transform (WT) [22] for radar fall activity detection. WT is a very effective method to analyze and extract
the characteristics of a signal that has nonstationary behaviors
[23]–[25] such as the radar fall signal. Indeed, WT has been
proposed recently by many researchers to process biomedical
signals such as electrocardiographic [26] data and heart sound
[23], [24] with numerous successes.
A fundamental question of using WT for radar fall detection
is the choice of the wavelet function. WT uses the dilated and
translated versions of a wavelet function to form bases for signal
decomposition. In this paper, we examine over 100 wavelet
functions and identify the ones that are suitable for fall detection.
The proposed radar fall detection is a two-stage processing:
prescreening and classification. The radar data comes in continuously and the first stage applies the WT coefficients at a

0018-9294 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

866

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 3, MARCH 2015

particular scale to locate an instance when potential fall activities may have occurred. The second stage forms feature vector
using the WT coefficients at many scales over the time region
identified and performs fall versus nonfall classification through
a trained classifier. A detection would trigger an alert to a
caregiver.
The contributions of this paper includes the introduction of
using the WT for radar fall detection, the developments of the
WT prescreener and classifier that perform significantly better than the previous methods, and the performance evaluations of the proposed radar fall activity detector with a wide
variety of fall types and the actual fall data from an elderly
person.
Closely related to our study, Gadde et al. [27] recently proposed the use of wavelet processing for fall detection as well,
where three features are extracted from the continuous WT of
a radar signal for fall versus sit/stand classification using the
Mahalanobis distance. The investigation here uses the discrete
WT at dyadic scales instead which would reduce the complexity
[28]. Gadde et al. [27] chooses the Morlet wavelet, and we conduct a study to determine the wavelet function that yields the
best performance for the fall detection problem. The features
of the proposed classifier are different from those in [27]. We
are able to advance the performance as illustrated in Section
VI, through extensive evaluations on data measurements from
laboratory and inhome environments containing realistic and
actual human falls of many kinds. In addition, we establish the
use of the wavelet coefficients at a certain scale for prescreening
to identify time segments for fall versus nonfall classification.
Gadde et al. [27] focuses on classification only and applies an
energy detector for prescreening, which yields larger amounts
of false alarms for the classifier to handle.
This paper is organized as follows. Section II gives a brief
background on Doppler radar. Section III provides the rationale
of using the WT for radar fall activity detection. Section IV
elaborates the details of the proposed fall activity detector using
the WT. Section V describes the data measurements for performance evaluations, and Section VI provides the results and
comparisons. Finally, we draw conclusions in Section VII.
II. DOPPLER RADAR
Doppler radar is a device that produces responses resulted
from the Doppler effect caused by the motion of an object
along the radar-object direction [29]. A Doppler radar sends
out gated sinusoids (modulated rectangular pulses) at radio frequencies and measures the echo reflected by a moving object.
The Doppler effect creates frequency difference between the
sent and received signals and the radar output contains harmonics at the frequency change.
The radar used in this study is a commercially available pulseDoppler RCR [30] which has a price comparable to a webcam.
The pulse repetition rate is 10 MHz and the duty cycle is 40%.
The carrier frequency fc is 5.8 GHz. The radar mixes the sent
and received signals and applies a low-pass filter to produce
the output. The radar output is then digitized at a sampling
frequency of 960 Hz.

Fig. 1. (a) Waveform of radar output from human fall, the fall is occurred at
14 s. (b) Spectrum of (a).

Fig. 1(a) gives a sample waveform of the radar output containing a human fall, and Fig. 1(b) is its spectrogram. The fall
happens at around 14 s. Due to the dynamics of the fall, a
higher frequency response appears at the beginning followed
by lower frequency content. A human fall typically reaches to
about v = 5 m/s before hitting the ground. Using the Doppler
frequency formula [31]
Δfm ax =

2v
fc
c

(1)

where c = 3 × 108 m/s is the light speed. We expect the fall
signal covers a frequency range from 0 up to the maximum
Doppler shift of about Δfm ax = 200 Hz. The prediction is consistent with the spectrogram shown in Fig. 1(b).
Although we use this particular radar for investigation, the
WT technique for radar fall detection is general and can be
applied to other Doppler radar with straightforward adjustments.
III. WAVELET TRANSFORM
The Fourier transform (FT) is typically used when analyzing
data in the frequency domain. One fundamental assumption of
the FT is that the data are stationary (or at least wide-sense
stationary) with time invariant statistical properties. It divides
the frequency range occupied by the data into bins of equal
size to examine the frequency content within. For biomedical
applications, most of the signals encountered are nonstationary,

SU et al.: DOPPLER RADAR FALL ACTIVITY DETECTION USING THE WAVELET TRANSFORM

Fig. 2.

867

Data processing blocks for fall activity detection.

and they contain high-frequency components of short bursts and
low frequency content of long durations. The FT is not sufficient
and not suitable to analyze these kinds of signals, and the WT has
been developed to better examine these kinds of nonstationary
signals [22].
A human fall typically starts with a quick movement of falling
down, followed by a slow motion of lying on the floor. A Doppler
radar captures the entire fall activity and produces similar dynamic characteristics of short duration of high frequencies and
long period of low frequencies in the output. This kind of signal
behavior makes the WT a good choice for data analysis and
feature extractions for Doppler radar.
The continuous WT of a signal x(t) is defined as [22]



t−τ
1
x(t)f ∗
dt
(2)
X(τ, a) = √
a
a
where f ∗ is the wavelet function. a is the scale factor, and
it is positive for practical applications. The wavelet is dilated
when
√ a > 1 and contracted when a < 1. τ is the translation and
1/ a is the energy normalization factor. Different choices of
the wavelet function will yield different WT.
The data are in sampled form in practice. By limiting the scale
a to be dyadic, the WT has a very efficient implementation by
using a pair of filters, one high-pass and the other low-pass, to
represent the wavelet function [22]. The resulting WT is often
termed as Discrete Stationary Wavelet Transform (SWT) [32]
in the literature. SWT is an online processing that transforms
the incoming data sequentially through successive applications
of the filters. The SWT is redundant in the sense that it will
generate the same number of samples in each dyadic scale as in
the original data.
It is imperative to determine which wavelet function can provide better performance in extracting the fall information and
suppressing the nonfall activities. We shall use the area under
the receiver operating characteristic (ROC) [33] curve to select
the wavelets. The details will be deferred to Section IV.
IV. ALGORITHM
Fig. 2 shows the block diagram of the proposed WT fall activity detector. The data first passes through SWT to generate
the wavelet coefficients at a number of dyadic scales. The coefficients at a particular scale, scale 4 in our case, will be used
to identify the possible time location at which fall activity may
have occurred. The SWT coefficients of other scales around the
identified time location will form a feature vector, which is used
by a classifier to perform fall versus nonfall classification. The
details of the prescreening stage to locate the fall occurrence and

Fig. 3.

Multilevel wavelet decomposition of Doppler radar signal.

the classification stage to detect the fall behavior are elaborated
in details below.
A. Prescreening Stage
Prescreening should maintain 100% true positives, while
seeking to minimize as many false positives as possible. To
make a balance between efficiency and complexity, we use only
a single scale for processing in this stage.
Through theoretical study and validation by experimental results, scale 4 is the best scale for prescreening. At the sampling
rate of 960 Hz, scale 4 corresponds to a frequency range of
about 120 to 240 Hz [22]. Using (1), we get the speed range of
3 to 6 m/s, which is what we expect at the early stage of a fall
before hitting the ground.
Fig. 3 is an example of the wavelet decomposition over a
data segment shown at the top, which contains a fall around
10 s and several nonfall activities between 17.5 and 30 s. The
SWT outputs at scales 2i , denoted by Di (n), i = 1, 2, . . . , 6 are
depicted below the data segment, where the wavelet function
is the reverse biorthogonal 3.3 (rbio3.3) [34]. Note that they
do not share a common range in the y-axis. Although the WT
coefficients over the fall are becoming larger as the scale increases from 2 to 64, the coefficients D2 (n) (scale 4) has the
largest fall to nonfall distinction. This observation is consistent
with the expectation from theory. We, therefore, use D2 (n) for
prescreening.
The fall confidence value for prescreening is the short-time
energy of D2 (n) over a moving window to average out variations. The window is Hamming; the window size is 0.5 s and
the amount of overlap is 50%. Hence, the location resolution of
a fall is 0.25 s. In essence, the prescreener detection value at
frame j is
C(j) =

N


(w(l)(D2 (l + j(N/2))))2 .

(3)

l=1

where w(l) represents the Hamming window and, N = 480
corresponds to the number of samples in 0.5 s.
A typical fall lasts about 2 s, and a detection is declared
if several consecutive C(j) values over a 2 s window exceed
the threshold. The frame that has the maximum prescreener

868

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 3, MARCH 2015

value among the neighboring frames will be assigned as the
potential fall location and it will be denoted by jp . We use
a 0.5 s frame instead of 2 s for computing the prescreener value
to provide a more accurate time location of a possible fall event
to the classifier. A 0.5 s window size also allows us to reuse the
prescreener values in the classifier.
Wavelet Selection: It is essential to determine which wavelet
function is more suitable for fall detection. We shall use the
detection performance curve which is the detection rate versus the number of false alarms, and calculate the area under
the curve as an index to evaluate the detection performance
from different wavelet functions. When computing the area, the
y-axis is the detection rate from 0 to 1 and the x-axis is from 0 to
the largest number of false alarms for reaching 100% detection
over the wavelet functions tested. The better wavelet function
for fall detection is the one that gives largest area.
In generating the detection performance curve, the detection rate and the number of false alarms are obtained using
the prescreening detection statistic C(j) after alarm merging
by stepping down the detection threshold. A typical fall is not
more than 2 s long, and we have one detection value for every
0.25 s. Contiguous detections up to a maximum of eight frames
are merged together with the largest among them as the merged
confidence. Noncontiguous detections are counted as separate
even if they are within eight frames.
The ROC is produced using the dataset collected in the lab
as will be described in Section V. We defer the details of the
results for optimum wavelet selection to Section VI.

typical fall of 2 s long, the extra 0.5 s provides a margin for
capturing the fall. This duration, under a frame size of 0.5 s and
50% overlap, translates to four frames before and four frames
after the frame jp .
The main purpose of the classification stage is to exploit the
changes in the time–frequency content during a fall to achieve
better detection performance. Rather than using Ei (j), we remove the energy factor in each scale through normalization with
the WT energy at that scale over the fall duration
Ẽi (j) = M

Ei (j)

m =−M

Ei (jp + m)

where j = jp − M, jp − M + 1, . . . , jp + M , and M = 4. The
features of frame j are
v(j) = [ Ẽ1 (j), Ẽ2 (j), . . . , Ẽ6 (j) ] .
The overall feature vector for classification is


v = vj p −M , vj p −M +1 , . . . , vj p +M .

The alarms from the prescreening stage detects any motion
at 3 to 6 m/s. This is a characteristic for a fall. Other activities
such as sitting down rapidly on a chair or standing up quickly,
however, would create similar motion at the velocity range and
result in strong detection. Most importantly, the dynamic behavior of a fall that gives rise to the variations in the frequency
content during a fall has not been explored. The classification
stage focuses on extracting the time–frequency features from
the WT to improve the fall detection performance.
The feature vector for classification is the concatenation of
the features from several frames centered at the fall location jp
identified by the prescreener. For a given frame j, we compute
the energy of the WT coefficients within after windowing:
Ei (j) =

N


(6)

(7)

The feature vector contains six normalized energies per frame
over nine frames, giving a length of 54.
C. Classifier
We use the nearest neighbor (NN) classifier with the feature
vector v. NN is the special case of the k-NN classifier having k
equal to 1. Given a test sample vtest , we obtain the l1 norm [35]
between vtest and the nearest training sample of falls vtrain,fall
distfall = |vtest − vtrain,fall | .

B. Time–Frequency Features

(5)

(8)

The l1 norm with respect to the closest nonfall training sample
is obtained similarly
distnonfall = |vtest − vtrain,nonfall | .

(9)

The statistic for fall detection is
conf = distnonfall − distfall .

(10)

Varying the detection threshold will trace out a detection performance curve.
Although simple, NN provides reasonably good results due
to the effectiveness of the time–frequency features from the WT.
We have tested other classifiers such as SVM with linear and
Gaussian kernel functions and the results are not as good as NN.
V. DATA DESCRIPTION

(w(l) Di ( l + j(N/2) ) )2

(4)

l=1

where i = 1, 2, . . . , 6, w(l) is the Hamming window, Di (n) is
the WT coefficients at scale 2i , and N = 480 is the window size
in samples corresponding to 0.5 s. The values Ei (j) characterize
the time–frequency content represented by six dyadic scales in
frame j. The window advances 0.25 s. (240 samples) to yield
the time–frequency content for the next frame.
The identified fall location from the prescreener is at the early
stage of a fall before hitting the ground. We, therefore, collect
the time–frequency content over the time range from 1 s before
the fall location to 1.5 s after for classification. Considering a

The Doppler radar used in the experimental study is the GE
Security PrecisionLine RCR-50 [30] whose characteristics have
been described in Section II. The radar data acquisition unit is
DATAQ DI710 [36] at 960 Hz sampling. The data collections
from human subjects have been approved by the Institutional
Review Board at the University of Missouri.
The performance evaluation of the proposed fall detection
system contains three datasets. The first dataset D0 was collected
in 2011, under a laboratory that simulates a home environment.
The second dataset D1 was acquired in 2013, in the bathrooms
of several senior residence apartments at TigerPlace [37]. The
third dataset D2 was taken also in a senior residence apartment

SU et al.: DOPPLER RADAR FALL ACTIVITY DETECTION USING THE WAVELET TRANSFORM

TABLE I
DESCRIPTION OF D0
Fall

times

Loose balance-Forward
Loose balance-Backward
Loose balance-Left
Loose balance-Right
Loss consciousness-Forward
Loss consciousness-Backward
Loss consciousness-Left
Loss consciousness-Right
Loss consciousness-Straight down
Trip and fall-Forward
Trip and fall-Sideways
Slip and fall-Forward
Slip and fall-Sideways
Slip and fall-Backward
Reach-fall (chair)-Forward
Reach-fall (chair)-Left
Reach-fall (chair)-Right
Reach-fall (chair)-Sliding forward
Reach-fall (chair)-Sliding backward
Couch fall-Upper body first
Couch fall-Hip first

5
5
5
5
5
5
5
5
5
5
5
5
5
5
5
5
5
5
5
5
5

869

TABLE III
STUNT ACTOR INFORMATION OF D1
Acted Nonfall
Walk
Kick
Clapping strongly
Bend over

times
486
107
107
4

Subject

Gender

Age

Height
(cm)

Weight
(kg)

Stunt actor A

female

34

160

60.8

TABLE IV
DESCRIPTION OF FALLS IN D1
Fall

TABLE II
STUNT ACTOR INFORMATION OF D0

Subject

Gender

Age

Height
(cm)

Weight
(kg)

Stunt actor A
Stunt actor B
Stunt actor C

female
female
male

32
46
30

160
163
173

61
53
77

at TigerPlace in 2013, but in the living room (not the bathroom)
with actual falls from an elderly resident. The data were recorded
continuously in time as the detection system operates in clinical
practice and we did not manually isolate out the fall and nonfall
segments.
For D0, the dimension of the simulated living room was 9 m ×
8.2 m × 3 m (L × W × H). The radar was mounted at the ceiling center pointing downward. The dataset contains 21 kinds
of falls from a combination of various fall types and directions as tabulated in Table I. Each was performed five times
from professional stunt actors, whose statistics are summarized in Table II, to strongly resemble the falls of elders after
training by nursing staff [38]. The dataset has eight kinds of
acted nonfalls that are typical daily activities. The total number of falls is 105 and that of acted nonfalls is 704. The total
length of D0 is 145 min. The data were collected and processed
continually.
In addition to the intentional nonfalls described in Table I,
there are many unintentional nonfall activities during the data
collection such as warming up, actively moving right before
or after falls, sitting down on a chair, reclining on a sofa, and
standing up after performing each fall. These activities create
an additional 286 nonfalls. Furthermore, when preparing the
experiment, repositioning the sofa, opening the door, moving

Loose balance-Forward
Loose balance-Backward
Loose balance-Left
Loose balance-Right
Loss consciousness-Forward
Loss consciousness-Backward
Loss consciousness-Left
Loss consciousness-Right
Loss consciousness-Straight down
Trip and fall-Forward
Trip and fall-Sideways
Slip and fall-Forward
Slip and fall-Sideways
Slip and fall-Backward
Reach-fall (chair)-Forward
Reach-fall (chair)-Left
Reach-fall (chair)-Right
Reach-fall (chair)-Sliding forward
Reach-fall (chair)-Sliding backward

Jan

Feb

Mar

Apr

May

0
1
1
1
0
1
1
1
0
1
1
1
0
0
0
1
1
1
0

1
0
1
1
1
0
1
0
1
0
1
1
1
0
0
0
1
1
1

2
2
0
2
2
2
0
2
0
0
0
2
2
2
2
0
0
2
2

2
0
0
0
0
0
0
0
2
0
0
0
2
2
0
0
0
0
2

6
6
6
6
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0

the fall protection pad, and pulling the chair will also generate
many nonfall activities.
In dataset D1, the stunt actor A, the same as the
one in D0 with information given in Table III, performed falls and nonfalls at three different bathrooms
at TigerPlace apartment over a period of five months.
Two bathrooms have dimensions 2.6 m × 2.4 m ×
2.7 m and one has 2.3 m × 2.3 m × 2.7 m. The radar was
mounted in the middle of the bathrooms, above in the attic. The
dataset D1 has 211 min in total from the collections over five
different months. The kinds of falls in D1 (see Table IV) are the
same as in D0 except the last two. Fourteen types of nonfall activities are specifically performed to emulate real-life scenarios
as follows. The counts for them in the five months are listed in
Table V.
1) Bend at the knees and stoop to a squatting position on
the floor, from a standing position.
2) Bend down and kneel on the floor, from a standing
position.
3) Bend down and kneel on the floor, wait for 2 s, then lie
down on the floor, from a standing position.
4) Bend down to plug an appliance into an electrical outlet
close to the floor, from a standing position.
5) Squat to tie a shoe, from a standing position.
6) Sit on the floor with the legs tucked under the body, from
a standing position.
7) Sit on the floor with the legs extended from the body,
from a standing position.

870

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 3, MARCH 2015

TABLE V
DESCRIPTION OF NONFALLS IN D1
Nonfall Type
1
2
3
4
5
6
7
8
9
10
11
12
13
14

Jan

Feb

Mar

Apr

May

0
1
1
1
0
0
0
1
2
0
1
1
1
3

0
0
1
1
1
0
0
2
1
1
0
1
1
3

0
0
0
2
2
2
0
2
4
2
2
0
2
6

0
0
0
2
2
0
0
2
0
2
0
0
0
2

2
2
2
0
0
0
0
4
2
2
2
2
0
6

Fig. 4.

Relative detection performance from different wavelet functions.

TABLE VI
RESIDENT’S (IN TIGERPLACE) INFORMATION OF D2

Subject

Gender

Age

Height
(cm)

Weight
(kg)

1

female

75

160

63.5

8) Perform three sit-ups and some stretches of upper
and lower extremities, from a lying position on the
floor.
9) Slowly rise to a half kneeling position, then rise to a
standing position, from a lying position on the floor.
10) Appear to trip but will regain balance and continue walking, from a walking position.
11) Walk forward for 3 s and then stop suddenly, from a
standing position.
12) Walk forward for 3 s and then stop suddenly and turn
around, from a standing position.
13) Walk to a stationary chair and sit on it, from a standing
position.
14) Bend over to pick up a book on the floor, from a sitting
position in a chair.
As in D0, D1 also contains those unintentional nonfall activities, which are not listed in Table V.
The dataset D2 is real life data acquired during the daily living of an elderly resident whose statistics are summarized in
Table VI. The radar was placed above the middle of the living
room (4.4 m × 6.4 m × 2.7 m) at the attic in a TigerPlace
apartment. The dataset is ten days long containing 13 real falls
from the resident. At least one fall occurred in each day and the
normal daily activities contribute to nonfalls. The subject has a
cat that has a weight of 3.8 Kg. The staff of the TigerPlace came
inside the apartment every day to help the subject and other
people visited during a day. The data portions with staff or visitors present are removed, for the purpose to assess performance
of the radar fall detection system under natural behavior of the
resident alone. Indeed, automated fall detection is not urgent
when others are present.

Fig. 5. Wavelet function rbio3.3 represented by a pair of filters in decomposition. (a) Decomposition low-pass filter coefficients. (b) Decomposition highpass filter coefficients.

VI. EXPERIMENTAL RESULTS
A. Wavelet Selection
We shall use the detection performance from the prescreener
on D0 to evaluate the performance of different wavelet functions
for fall detection.
We test 111 commonly used wavelet functions for evaluations
[28], [34]:
1) Daubechies (db) 1 ∼ 45;
2) biorthogonal (bior) and reverse biorthogonal (rbio) series
(1.1, 1.3, 1.5, 2.2, 2.4, 2.6, 2.8, 3.1, 3.3, 3.5, 3.7, 3.9, 4.4,
5.5, 6.8);
3) coiflets (coif) 1 ∼ 5;
4) discrete approximation of Meyer wavelet (dmey);
5) symlets (sym) 1 ∼ 30.
The areas under the detection curves from the wavelet functions are sorted in descending order and the results after normalizing them with the largest area are shown in Fig. 4 using cross
symbols. The best five wavelets are “rbio3.3,” “db3,” “sym3,”
“rbio1.3,” and “bior2.2.” Fig. 5 shows the low-pass and the highpass filter representation of “rbio3.3.” The worst one is “rbio3.1”
with a normalized area of 0.85.
To support the use of the second level of wavelet decomposition (a = 4) for prescreening, Fig. 6 shows the ROC curves
from different scales of the wavelet rbio3.3. It confirms that

SU et al.: DOPPLER RADAR FALL ACTIVITY DETECTION USING THE WAVELET TRANSFORM

Fig. 6. Prescreening ROCs of D0 using the wavelet coefficients from rbio3.3
at different scales.

Fig. 7.

Prescreener detection performance for D0.

Fig. 8.

Prescreener detection performance for D1.

871

the wavelet coefficients at scale 4 provide better detection than
those from other scales.
A better wavelet function for prescreening would yield
smaller number of nonfalls for classification. It would reduce
the effort of a classifier and provide better detection accuracy
after classification as well.
We next examine the classification performance of different
wavelet functions, at the detection locations identified by the
prescreener using its best wavelet function “rbio3.3.” The areas
under the detection curves relative to the largest are shown
in Fig. 4 using circle symbols. The top five wavelets for the
classification stage are “rbio3.3,” “coif4,” “db10,” “bior2.6,” and
“db11.” It is interesting that “rbio3.3” gives the best performance
for both prescreening and classification.
For the results presented in the rest of this section, we use the
“rbio3.3” in both the prescreening and classification stages.
B. Performance Evaluation
1) Prescreening: For reference purpose, we generate the
performance of the energy detector from the input signal as
follows:
Xenergy (j) =

M
1 
(w(n))((x(n + j(M/2)))2 )
M n =1

(11)

where Xenergy (j) represents the signal energy in frame j, and
x(n) is the radar data samples. The index n denotes the sample
number within the segment, and M corresponds to the number
of samples with the 2 s window size. w(n) is the Hamming
window function. We shall use Xenergy (i) to create the energy
detector ROC curve.
In addition to the energy detector, we also generated the results from the detector developed in [19], which is based on
the short-time Fourier transform (STFT). Figs. 7 and 8 compare the fall detection performance from the three prescreeners
for datasets D0 and D1. As expected, both the proposed WT

prescreener and the STFT prescreener perform better than the
energy detector; the difference is particularly obvious in D1.
The proposed WT prescreener is much more effective than the
STFT prescreener. At 95% detection rate, the reduction in the
number of false alarms is almost by a factor of 3.
2) Classification: We shall use the proposed prescreener to
locate the possible fall activities and then apply a classifier
to improve the performance. We shall compare the proposed
wavelet features with the MFCC features developed in [19]. For
a fair comparison, both features are used to train the same kind
of classifier, which is the NN, for classification. We also implemented the classification method from [27] that is based on
three time-scale (TS) features and the Mahalanobis distance.
The cross validation uses leave one out in the training and
testing [39].
Fig. 9 shows the ROC classification performance, in terms
of sensitivity versus 1-specificity, for D0. The results from the

872

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 3, MARCH 2015

Fig. 11.
Fig. 9.

Fig. 10.

ROC curves of the proposed classifier for D1 in five different months.

ROC curves of the proposed and MFCC classifiers for D0.

ROC curves for D1 using leave one out cross validation.

MFCC classifier are worse than the prescreener at the sensitivity
below 90% and comparable above. The performance of the
TS classifier is also below the prescreener. The proposed WT
classifier is able to provide significant performance gain over
the prescreener.
To obtain a better understanding, we analyzed the false alarms
of the proposed classifier to reach 100% sensitivity. Among
these 95 false alarms, 59 are caused by significant human activities such as moving around for preparing and finishing the data
collection; 11 from intentional kick actions for time synchronization; 7 from the stunt actors standing up after performing
falls; 6 from the warm up actions of the stunt actors; 5 from the
stunt actor motion activities right before or after falls; 4 from
clapping strongly; 2 from stunt actors bending over; and 1 from
a stunt actor lying down on the sofa.

The performance for D1 is shown in Fig. 10. In this dataset,
the MFCC classifier has better accuracy than the prescreeener
for the sensitivity below 90%. The TS classifier follows the
prescreener performance but having a nearly constant decrease
in sensitivity at a given specificity. The proposed WT classifier
remains the best and outperforms the prescreener considerably.
The WT classifier has 58 false alarms to reach 100% detection. Thirty-three false alarms come from significant preparation motions before or after the data collections: 19 from stunt
actors standing up after performing falls; 1 from the designed
type 3 nonfall activity; 1 from the designed type 4 nonfall activity; 1 from the designed type 13 nonfall activity; and 3 from
the designed type 14 nonfall activity.
Fig. 10 is the aggregated results of the data collected over five
months from January to May, 2013. Fig. 11 gives the separated
performance of the proposed detector for individual months
separately. It is interesting to note that detection performance in
March and May are particularly worse compared to the others. In
the two months, there were extra human activities in preparing
the experiments, and the stunt actor was standing up faster than
normal after performing the falls. Among the false alarms to
reach 100% sensitivity in Fig. 10, 26 out of 33 from activities
preparing the experiments, and 14 out of 19 from standing up
after falls are from these two months.
In practice, a classifier must be trained beforehand using available data before putting into practical use. The robust performance of the proposed classifier is illustrated in Fig. 12, where
we use the lab dataset D0 for training and apply it to the dataset
D1 for testing. The proposed classifier has consistent and comparable performance with the cross validation results in Fig. 10,
and this is not the case for the MFCC and TS classifiers.
The falls in D0 and D1 are from stunt actors. The apparent
large number of false alarms from the proposed classifier to
reach 100% detection is caused by nonnatural activities of the
stunt actor. Using D2, we are able to assess the performance of
the proposed detector for actual falls from an elderly resident
in a typical home environment. The proposed prescreener first
processes the dataset D2, and the proposed WT or the MFCC

SU et al.: DOPPLER RADAR FALL ACTIVITY DETECTION USING THE WAVELET TRANSFORM

873

TABLE VII
AREA UNDER THE ROC (AUC), SENSITIVITY, SPECIFICITY, AND ACCURACY
AT THE OPERATING THRESHOLD

WT Prescreener

WT Prescreener and
WT Classifier

WT Prescreener and
MFCC Classifier

WT Prescreener and
TS Classifier

Fig. 12.

Fig. 13.

AUC
Sensitivity
Specificity
Accuracy
AUC
Sensitivity
Specificity
Accuracy
AUC
Sensitivity
Specificity
Accuracy
AUC
Sensitivity
Specificity
Accuracy

D0

D1

D2

0.91
92.3%
88.9%
89.5%
0.96
97.1%
92.2%
93.0%
0.91
93.3%
89.7%
90.3%
0.76
85.7%
71.4%
73.8%

0.82
86.5%
80.8%
81.9%
0.92
95.1%
90.7%
91.6%
0.85
87.8%
89.1%
88.8%
0.77
85.4%
72.4%
75.1%

0.71
76.9%
76.9%
77.6%
0.82
92.3%
81.4%
83.5%
0.75
92.3%
62.9%
68.6%
0.48
69.2%
50.0%
73.1%

ROC curves for D1 using D0 as the training data.

ROC curves for D2 using D1 as the training data.

classifier operates on the declared locations from a prescreener
to produce the detection performance. Training uses dataset D1,
where the data from March and May are excluded due to their
abnormal behavior.
Fig. 13 illustrates the results. The MFCC classifier produces
worst results than the prescreener, which is consistent with
the previous observations from Fig. 12. The proposed detector
yields promising results. The number of false alarms is much
less to reach 100% detection, only 16 over 10 days. The proposed WT fall detector is quite resilient to false positives created
by natural daily nonfall activities. Among the 16 false alarms, 11
are from nonhuman activities possibility due to the cat or electromagnetic interference; 1 from random noise with nobody in
the living room; 2 from the subject adjusting the height of a
chair; 1 from the subject standing up quickly; and 1 from the
subject bending over to pick up an object.

The performance shown in Fig. 13 is for fall detection using
radar in the living room of an elderly resident. We expect it
represents the lower bound performance for fall detection in the
bathroom, since there are more differences between the training
and testing data and the living room has more nonfall activities
that can cause false positives than the bathroom.
In addition to the ROC curves, Table VII tabulates the performance metrics of the detectors obtained from the three datasets
at the operating thresholds [33]. The values shown for D1 are
the cross validation results as in Fig. 10. The proposed WT fall
detector (WT-based prescreener and classifier) achieves the best
and consistent performance. The experimental studies corroborate that the time–frequency features extracted from WT are
very effective for fall detection and the proposed fall activity
detector has more robust behavior than the previously proposed
detector using MFCC features.
The TS classifier [27] also uses wavelet processing and its
performance is below expectation. We believe there are two
main reasons. First, the three features of the TS classifier are
derived from backward falls and sit/stand nonfalls. Datasets D0
and D1 have large varieties of falls and nonfalls performed by
professional stunt actors as tabulated in Tables I, IV, and V, and
they have different characteristics than just backward falls and
sit/stand nonfalls. Second, the radar in [27] was placed 40 in
above the floor looking horizontally and our radar was mounted
in the ceiling pointing down. A Doppler radar responds to the
relative motion along the radar-object direction. The received
signals from a ceiling mounted radar and a ground standing
radar behave differently. We believe that the TS classifier from
[27] would work better when the radar is mounted on a wall
looking horizontally.
VII. CONCLUSION
We have developed a reliable detector using Doppler radar
measurements for the detection of human falls. The detector is
based on WT that explores the time–frequency characteristics
of a fall caused by its unique dynamics. The detector has two

874

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 3, MARCH 2015

stages; the prescreening stage that uses the WT coefficients at
a given scale to identify the possible occurrence of a fall, and
the classification stage that uses the WT coefficients at several
scales over many successive frames to form a feature vector
for fall versus nonfall classification. The better wavelet functions to reach higher detection accuracy are “rbio3.3,” “db3,”
“sym3,” “rbio1.3,” and “bior2.2” for prescreening and “rbio3.3,”
“coif4,” “db10,” “bior2.6,” “db11” for classification. Evaluations based on the data collected in the lab, in the bathrooms,
and in the senior residence apartment validate the promising and robust performance of the proposed WT fall activity
detector.
ACKNOWLEDGMENT
The authors would like to thank L. Liu for providing the
processing codes of STFT prescreening and MFCC feature extraction from radar signals used in [19].
REFERENCES
[1] S. B. Vyrostek, J. L. Annest, and G. W. Ryan, “Surveillance for fatal
and nonfatal injuries—United States, 2001,” MMWR Surveill Summaries,
vol. 53, pp. 1–57, 2004.
[2] F. Bagala, C. Becker, A. Cappello, L. Chiari, K. Aminian, J. M. Hausdorff,
W. Zijlstra, and J. Klenk, “Evaluation of accelerometer-based fall detection algorithms on real-world falls,” PLoS ONE, vol. 7, pp. 1–9,
May 2012.
[3] T. Tamrat, M. Griffin, S. Rupcic, S. Kachnowski, T. Taylor, and J. Barfield,
“Operationalizing a wireless wearable fall detection sensor for older
adults,” in Proc. 6th Int. Conf. PervasiveHealth, San Diego, CA, USA,
May 2012, pp. 297–302.
[4] P. Kumar and P. C. Pandey, “A wearable inertial sensing device for fall
detection and motion tracking,” in Proc. IEEE India Annu. Conf., Mumbai,
India, Dec. 2013, pp. 1–6.
[5] M. Terroso, R. Freitas, J. Gabriel, A. T. Marques, and R. Simoes, “Active assistance for senior healthcare: A wearable system for fall detection,” in Proc. 8th Iberian Conf. Inform. Syst., Technol., Lisboa, Portugal,
Jun. 2013, pp. 1–6.
[6] W. Bao, Y. Chen, and X. Zeng, “Wearable wireless system with embedded
real-time fall detection logic for elderly assisted living applications,” in
Proc. IEEE 11th Int. Conf. Solid-State Integr. Circuit Technol., Xi’an,
China, Oct. 2012, pp. 1–3.
[7] D. Chen, W. Feng, Y. Zhang, X. Li, and T. Wang, “A wearable wireless
fall detection system with accelerators,” in Proc. IEEE Int. Conf. Robot.
Biomemetics, Phuket, Thailand, Dec. 2011, pp. 2259–2263.
[8] V. Vaidehi, K. Ganapathy, K. Mohan, A. Aldrin, and K. Nirmal, “Video
based automatic fall detection in indoor environment,” in Proc. IEEE
Int. Conf. Recent Trends Inform. Technol., Chennai, India, Jun. 2011,
pp. 1016–1020.
[9] A. Edgcomb and F. Vahid, “Automated fall detection on privacy-enhanced
video,” in Proc. IEEE 34th Annu. Int. Conf. Eng. Med. Biol. Soc., San
Diego, CA, USA, Aug. 2012, pp. 252–255.
[10] V. Vaidehi, K. Ganapathy, K. Mohan, A. Aldrin, and K. Nirmal, “Video
based automatic fall detection in indoor environment,” in Proc. IEEE
Int. Conf. Recent Trends Inform. Technol., Chennai, Tamil Nadu, India,
Jun. 2011, pp. 1016–1020.
[11] Y. T. Ngo, H. V. Nguyen, and T. V. Pham, “Study on fall detection based
on intelligent video analysis,” in Proc. Int. Conf. Adv. Technol. Commun.,
Hanoi, Vietnam, Oct. 2012, pp. 114–117.
[12] W. Y. Shieh and J. C. Huang, “Speedup the Multi-camera videosurveillance system for elder falling detection,” in Proc. Int. Conf. Embedded Softw, Syst., Zhejiang, China, May 2009, pp. 350–355.
[13] Y. Li, Z. Zeng, M. Popescu, and K. C. Ho, “Acoustic fall detection using
a circular microphone array,” in Proc. IEEE 32th Annu. Int. Conf. Eng.
Med. Biol. Soc., Buenos Aires, Argentina, Sep. 2010, pp. 2242–2245.
[14] Y. Li, K. C. Ho, and M. Popescu, “A microphone array system for
automatic fall detection,” IEEE Trans. Biomed. Eng., vol. 59, no. 5,
pp. 1291–1301, May 2012.

[15] O. Gabai and H. Primo, “Acoustic motion capture,” U.S. Patent
20 110 009 194, Jan. 13, 2011.
[16] D. Anderson, R. H. Luke, J. M. Keller, M. Skubic, M. Rantz, and M. Aud,
“Linguistic summarization of video for fall detection using voxel person and fuzzy logic,” J. Comput. Vision Image Understanding, vol. 113,
pp. 80–89, Jul. 2008.
[17] E. E. Stone and M. Skubic, “Fall detection in homes of older adults
using the microsoft kinect,” IEEE J. Biomed. Health Informat., to be
published.
[18] M. J. Krauss, B. Evanoff, E. Hitcho, K. E. Ngugi, W. C. Dunagan,
I. Fischer, S. Birge, S. Johnson, E. Costantinou, and V. J. Fraser, “A
case-control study of patient, medication, and care-related risk factors for inpatient falls,” J. Gen. Internal Med., vol. 20, pp. 116–122,
Feb. 2005.
[19] L. Liu, M. Popescu, M. Rantz, and M. Skubic, “Fall detection
using Doppler radar and classifier fusion,” in Proc. IEEE 32th
Annu. Int. Eng. Med. Biol. Soc. Conf. BHI, Hong Kong, Jan. 2012,
pp. 180–183.
[20] L. Liu and M. Popescu, “An automatic in-room fall detection system
using Doppler radar signatures,” submitted for publication J. Ambient
Intell. Smart Environ., 2014.
[21] H. Y. Cho and Y. H. Oh, “On the use of channel-attentive MFCC for robust
recognition of partially corrupted speech,” IEEE Signal Process. Lett.,
vol. 11, no. 6, pp. 581–584, Jun. 2004.
[22] O. Rioul and M. Vetterli, “Wavelets and signal processing,” IEEE Signal
Process. Mag., vol. 8, no. 4, pp. 14–38, Oct. 1991.
[23] I. Hossain and Z. Moussavi, “An overview of heart-noise reduction of
lung sound using wavelet transform based filter,” in Proc. IEEE 25th
Annu. Int. Eng. Med. Biol. Soc. Conf., Cancun, Mexico, Sep. 2003,
pp. 458–461.
[24] J. J. Lee, S. M. Lee, I. Y. Kim, H. K. Min, and S. H. Hong, “Comparison
between short time Fourier and wavelet transform for feature extraction
of heart sound,” in Proc. Int. IEEE TENCON Conf., Cheju Island, Korea,
Dec. 1999, pp. 1547–1550.
[25] M. Yashita and N. Hamada, “Time-frequency masking method using
wavelet transform for BSS problem,” in Proc. Int. IEEE TENCON Conf.,
Hong Kong, China, Nov. 2006, pp. 1–4.
[26] L. Brechet, M. F. Lucas, C. Doncarli, and D. Farina, “Compression
of biomedical signals with mother wavelet optimization and best-basis
wavelet packet selection,” IEEE Trans. Biomed. Eng., vol. 54, no. 12,
pp. 2186–2192, Dec. 2007.
[27] A. Gadde, M. G. Amin, Y. D. Zhang, and F. Ahmad, “Fall detection and
classification based on time-scale radar signal characteristics,” Proc. SPIE,
vol. 9077, May 2014.
[28] S. Mallat, A Wavelet Tour of Signal Processing. New York, NY, USA:
Academic, 2008.
[29] F. Pfanner, T. Allmendinger, T. Flohr, and M. KachelrieB, “Monitoring
respiratory motion using continuous wave Doppler radar in a near field
multi antenna approach,” in Proc. Int. IEEE Med. Imag. Conf., Anaheim,
CA, USA, Oct. 2012, pp. 3575–3581.
[30] Available: http://utcfssecurityproducts.com/
[31] R. W. Ditchburn, Light. New York, NY, USA: Dover, 1991, pp. 331–333.
[32] G. P. Nason and B. W. Silverman, “The stationary wavelet transform and
some statistical applications,” Lect. Notes Statist., vol. 103, pp. 281–299,
1995.
[33] M. H. Zweig and G. Campbell, “Receiver-operating characteristic (ROC)
plots: A fundamental evaluation tool in clinical medicine,” Clin. Chem.,
vol. 39, pp. 561–577, 1993.
[34] I. Daubechies, Ten Lectures on Wavelets. Philadelphia, PA, USA: SIAM,
1992.
[35] J. W. Williams and Y. Li, “Comparative study of distance functions
for nearest neighbors,” in Advanced Techniques in Computing Sciences and Software Engineering. New York, NY, USA: Springer, 2010,
pp. 79–84.
[36] Available: http://www.dataq.com
[37] TigerPlace is an assisted living facility in Columbia, Missouri, USA [Online]. Available: http://eldertech.missouri.edu/
[38] M. J. Rantz, M. A. Aud, G. Alexander, B. J. Wakefield, M. Skubic,
R. H. Luke, D. Anderson, and J. M. Keller, “Falls, technology, and stunt actors: New approaches to fall detection and fall
risk assessment,” J. Nursing Care Quality, vol. 23, pp. 195–201,
Jul. 2008.
[39] R. Kohavi, “A study of cross-validation and bootstrap for accuracy estimation and model selection,” in Proc. Int. Joint Conf. Artif. Intell., Montreal,
QC, Canada, Aug. 1995, pp. 1137–1143.

SU et al.: DOPPLER RADAR FALL ACTIVITY DETECTION USING THE WAVELET TRANSFORM

Bo Yu Su (S’14) was born in Taipei, Taiwan. He received the B.S. degree in electrical engineering from
National Sun Yat-Sen University, Kaoshiung, Taiwan, in 2002, and the M.S. degree in electrooptical
engineering from Tatung University, Taipei, Taiwan,
in 2004. He is currently working toward the Ph.D. degree with the Department of Electrical and Computer
Engineering, University of Missouri, Columbia, MO,
USA.
His current research interests include the Doppler
radar and eldercare.

K. C. Ho (M’91–SM’00–F’09) was born in Hong
Kong. He received the B.Sc. degree with first class
honors in electronics and the Ph.D. degree in electronic engineering, both from the Chinese University
of Hong Kong, Shatin, Hong Kong, in 1988 and 1991,
respectively.
He was a Research Associate in the Royal Military College of Canada from 1991 to 1994. He joined
the Bell-Northern Research, Montreal, QC, Canada in
1995 as a Member of scientific staff. He was a Faculty
Member in the Department of Electrical Engineering
at the University of Saskatchewan, Saskatoon, Canada, from September 1996
to August 1997. Since September 1997, he has been with the University of
Missouri, Columbia, MO, USA, and he is currently a Professor in the Electrical and Computer Engineering Department. He was very active in the ITU
standard developments from 1995 to 2012. He is an Inventor of 20 patents in
the United States, Europe, Asia, and Canada on geolocation and signal processing for wireless communications. His research interests include sensor array
processing, detection and estimation, source localization, wireless communications, and the development of efficient signal processing algorithms for various
applications.
Dr. Ho received the Junior Faculty Research Award and the Senior Faculty
Research Award from the College of Engineering, University of Missouri. He
was the Chair of the Sensor Array and Multichannel Technical Committee in
the IEEE Signal Processing Society from 2013 to 2014. He was an Associate
Editor of the IEEE TRANSACTIONS ON SIGNAL PROCESSING and the IEEE SIGNAL PROCESSING LETTERS.

875

Marilyn J. Rantz (M’12) received the Ph.D. degree
in nursing from the University of Wisconsin, Milwaukee, WI, USA, in 1992.
She is with the University of Missouri (MU),
Columbia, MO, USA, where she is a Faculty Member
in the Sinclair School of Nursing and the Department
of Family and Community Medicine, MU School of
Medicine, where she is currently a Professor. She
is also the University Hospital Professor of nursing.
She has developed and sustained a research program
to improve the quality of care of elderly. Her innovative work in nursing home quality spans nearly 30 years, in practice and as a
Leading Researcher, establishes her as a Premier International Expert in quality
measurement in nursing homes. She and her multidisciplinary research team has
garnered nearly 60 million in funds to support their work measuring effectiveness of nurse care coordination, conduct cutting edge research in long-term care,
new delivery models of care, and for technology development to enhance aging
in place of community-dwelling elders. Her current research interests include
technology to enhance aging in place, long-term care quality measurement, and
quality improvement.
Prof. Rantz received both the MU Sinclair School of Nursing Faculty Award
for Excellence in Research and the National Gerontological Nursing Association Lifetime Achievement Award in 2005. In 2006, she received the MU
Alumni Association Faculty Alumni Award for her outstanding contributions to
her profession, the community, and the University of Missouri. She is a Fellow
of the American Academy of Nursing.

Marjorie Skubic (S’90–M’91–SM’13) received the
Ph.D. degree in computer science from Texas A&M
University, College Station, TX, USA, in 1997, where
she specialized in distributed telerobotics and robot
programming by demonstration.
In 2006, she established the Center for Eldercare
and Rehabilitation Technology at the University of
Missouri and serves as the Center Director for this
interdisciplinary team. The focus of the center’s work
includes monitoring systems for tracking the physical and cognitive health of elderly residents in their
homes, logging sensor data in an accessible database, extracting activity and
gait patterns, identifying changes in patterns, and generating alerts for health
changes. She is currently a Professor in the Electrical and Computer Engineering Department at the University of Missouri, Columbia, MO, USA, with a
joint appointment in computer science. In addition to her academic experience,
she has spent 14 years working in industry on real-time applications such as
data acquisition and automation. Her current research interests include sensory
perception, computational intelligence, spatial referencing interfaces, human–
robot interaction, and sensor networks for eldercare.

