IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

331

Ideal Time–Frequency Masking Algorithms Lead
to Different Speech Intelligibility and Quality
in Normal-Hearing and Cochlear
Implant Listeners
Raphael Koning∗ , Nilesh Madhu, and Jan Wouters

Abstract—Hearing impaired listeners using cochlear implants
(CIs) suffer from a decrease in speech intelligibility (SI) in adverse
listening conditions. Time–frequency masks are often applied to
perform noise suppression in an attempt to increase SI. Two important masks are the so-called ideal binary mask (IBM) with its
binary weights and the ideal Wiener filter (IWF) with its continuous weights. It is unclear which of the masks has the highest
potential for SI and speech quality enhancement in CI users. In
this study, both approaches for SI and quality enhancement were
compared. The investigations were conducted in normal-hearing
(NH) subjects listening to noise vocoder CI simulations and in CI
users. The potential for SI improvement was assessed in a sentence
recognition task with ideal mask estimates in multitalker babble
and with an interfering talker. The robustness of the approaches
was evaluated with simulated estimation errors. CI users assessed
the speech quality in a preference rating. The IWF outperformed
the IBM in NH listeners. In contrast, no significant difference was
obtained in CI users. Estimation errors degraded SI in CI users
for both approaches. In terms of quality, the IWF outperformed,
slightly, the IBM processed signals. The outcomes of this study
suggest that the mask pattern is not that crucial for CIs. Results of
speech enhancement algorithms obtained with NH subjects listening to vocoded or normally processed stimuli do not translate to
CI users. This outcome means that the effect of new strategies has
to be quantified with the user group considered.
Index Terms—Binary mask (BM), cochlear implants (CIs), noise
reduction, speech enhancement, Wiener filter (WF).

I. INTRODUCTION
NDERSTANDING speech in adverse listening conditions
with auditory prostheses like hearing aids or CIs is a very
challenging task. In particular in CI users, SI decreases rapidly in
noisy or reverberant environments. Therefore, a lot of research
is focused on the development of noise reduction strategies,

U

Manuscript received April 16, 2014; revised August 7, 2014; accepted August
14, 2014. Date of publication August 26, 2014; date of current version December
18, 2014. The work of R. Koning and N. Madhu was supported by the EU within
the Marie Curie ITN AUDIS, Grant Agreement No. PITN-GA-2008-214699.
This work was also partially supported by Cochlear, Ltd., in the frame of
IWT (Institute for the Promotion of Innovation by Science and Technology in
Flanders) Project 110722. Asterisk indicates corresponding author.
∗ R. Koning is with the Research Group Experimental Otorhinolaryngology,
Department of Neurosciences, University of Leuven, 3000 Leuven, Belgium
(e-mail: raphael.koning@med.kuleuven.be).
N. Madhu and J. Wouters are with the Research Group Experimental
Otorhinolaryngology, Deptartment of Neurosciences, University of Leuven,
3000 Leuven, Belgium (e-mail: nilesh.madhu@gmail.com; jan.wouters@med.
kuleuven.be).
Digital Object Identifier 10.1109/TBME.2014.2351854

which try to remove as much noise as possible from the mixture
of the target speech and the interfering sound, with the objective
of increasing SI and/or improving the speech quality of the
processed signal. A typical constraint of such strategies is that
distortions of the target signal should be avoided.
Usually, noise reduction algorithms operate upon a time–
frequency representation of the input (noisy) signal, applying a
gain to each time–frequency point to suppress the noise. The pattern of the gain function over all time–frequency points is often
called mask. Most of these time–frequency domain approaches
derive their gains as a function of the short-term signal-to-noise
ratio (SNR) in the respective time–frequency point. There is an
ongoing discussion about the choice of the perfect gain function
that improves SI and speech quality in NH listeners [1]–[4].
A very popular choice is the so-called binary mask (BM)
(see, e.g., [5], [6]). The mask is motivated by the auditory masking phenomenon and preserves with its binary values time–
frequency points, where the target is dominant (i.e., the shortterm SNR is above a threshold). The BM exploits the sparsity and disjointness of the target and interferer spectra. When
a priori knowledge of the signal and noise spectra is used in
the derivation of the mask, the mask is often called IBM. Under certain listening conditions, approaches based on BMs with
and without a priori knowledge for the mask computation can
increase SI in NH [1], [7]–[12], and hearing impaired listeners
[7], [9], [12].
In contrast to the hard-decision approach of the BM, state-ofthe-art noise reduction algorithms derive a mask with continuous
gains between 0 and 1 in proportion to the short-term SNR. Such
algorithms demonstrate improved speech quality as compared to
BM processed output [13]. A popular representative of this class
of algorithms is the Wiener filter (WF), which was shown to be
very promising in terms of quality improvement [13]. When
a priori knowledge was used to calculate the gain function of
the WF, the approach is referred to as IWF.
It was shown in [4] that the IWF restored perfect intelligibility with a Bark-scale frequency resolution even at very low
SNRs in both multitalker babble noise and interfering talker
scenarios. This was in stark contrast to the performance of the
IBM, which yielded intelligibility scores of around 60% at the
low SNRs. In [14] and [15], higher speech recognition scores
than 60% were obtained for low-input SNRs. In both studies,
the results were based on word correct scores and the mask
resolution was higher [14] or the influence of the interfering

0018-9294 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

332

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

background noise was discarded by modulating the mask pattern with a stationary noise masker [15]. Additionally, it was
shown that the WF was more robust to estimation errors than
the BM approach. In terms of quality, too, several studies have
confirmed that soft-decision approaches outperform BM approaches [2], [4], [16]. Therefore, it was hypothesized that the
IWF should be preferred over the IBM approach for application
in auditory prostheses. In this study, this hypothesis is tested for
CI applications.
Although multichannel speech enhancement algorithms for
CIs exist and have been proven to be beneficial for CI users
in monaural and bilateral applications [17]–[21], the further
investigation of single-channel noise reduction algorithms is
still very relevant. Single-channel noise reduction algorithms
designed and developed for application in CIs have shown to
lead to an increased SI in CI users [21], [22].
In this study, the potential of the IWF and the IBM approaches
in terms of SI and speech quality is investigated with regard to
its application in CIs. The tests are carried out on two groups of
participants: a group of NH subjects listening to noise vocoder
simulations as a model of CI processing of the processed signals,
and a group of CI users.
Because of the relative ease with which NH volunteers may
be recruited, tests on NH listeners, presented with noise vocoded
versions of the processed signals comparable to CI processing,
are often used in a first step to evaluate speech enhancement
strategies for application in CIs. Although dependent on the
specific research question, it was shown that the results obtained on this cohort often correlate with the performance of CI
users [23]. In our case, the inclusion of such tests with noise
vocoded sounds (also referred to as CI simulations) allows us to
investigate if the intelligibility scores obtained on NH listeners
translate to the scores of CI users as well.
The aims of this study are the following: we wish to investigate in terms of SI, which mask pattern is more beneficial for NH subjects listening to noise vocoder CI simulations
and for CI users. It is interesting in particular for CI users,
because noise reduction approaches based on time–frequency
masks can be added to the signal processing chain of existing clinical coding strategies without significant effect on other
stages. Furthermore, we study the influence of estimation errors on the SI for both groups of listeners, as it was shown in
[20] that CI users are less sensitive to speech distortions. The
design of the study allows us to investigate if the SI results obtained with NH listeners using CI simulations can be translated
to that of CI users. Additionally, we want to study the potential for speech quality improvement of both mask patterns in
CI users.
II. SIGNAL PROCESSING
In CIs of Cochlear, Ltd., up to N = 22 envelopes are extracted
in the frequency range up to 8 kHz. Therefore, such CIs usually
operate with a frequency resolution that is close to the Barkscale spectrum used in [4]. The signal model and processing
used in this study are very similar to that in [4]. For purposes of
completeness, we present these briefly below.

A. Signal Model
Denote the time-discrete signal recorded by the microphone
as y(t), where t is the sample index. The signal y(t) consists
of the target signal s(t) and the additive interference v(t). This
additive signal model for the recorded signal can be written as
y (t) = s (t) + v (t) .

(1)

Due to the fact that the IBM and IWF speech enhancement
approaches operate in the frequency domain, the short-time–
frequency representation of the signal in (1) can be written,
with the frame index n and the frequency index k, as
Y (n, k) = S (n, k) + V (n, k) .

(2)

Y (n, k) is the microphone signal in the time–frequency domain, S (n, k) and V (n, k) represent the target signal and the
interferer, respectively.
The estimate Ŝ(n, k) of the target signal is obtained by applying the time–frequency mask G (n, k) ∈ [0, 1] yielded by the
IBM and/or IWF approach, to Y (n, k). Thus, the output of the
speech enhancement step can be written as
Ŝ (n, k) = G (n, k) Y (n, k) .

(3)

Both the IBM and the IWF approaches derive their respective
masks as a function of the short-term SNR ξ (n, k), which is
defined as the ratio between the power spectral density (PSD)
of the target signal ΦS S (n, k) and the PSD of the interferer
ΦV V (n, k)
ξ (n, k) =

ΦS S (n, k)
.
ΦV V (n, k)

(4)

Usually, the PSD of the target signal and the interfering sound
are computed by using the Welch method, one implementation
which is a first-order recursive smoothing of the respective periodograms. Since we deal with ideal estimates of the parameters
of the IBM and the IWF approach, we can approximate the PSD
with
ΦS S (n, k) = |S (n, k) |2

(5)

ΦV V (n, k) = |V (n, k) | .

(6)

2

1) Ideal Binary Mask: The IBM GIBM consists of binary
weights. GIBM is equal to 1 when the SNR is above a threshold
value, and 0 when the SNR is lower than this threshold. In this
study, the threshold used was the global input SNR ξin . The BM
GIBM can be written as

1, if ξ (n, k) ≥ ξin
(7)
GIBM (n, k) =
0, else.
Note that for a given combination of s(t) and v(t), the mask
pattern is constant and independent of the SNR. This is termed
as the local threshold [4], [14].
The binary gain function GIBM is applied to the input signal
Y to obtain the enhanced output ŜIBM
ŜIBM (n, k) = GIBM (n, k) Y (n, k) .

(8)

KONING et al.: IDEAL TIME–FREQUENCY MASKING ALGORITHMS LEAD TO DIFFERENT SPEECH INTELLIGIBILITY AND QUALITY

2) Ideal Wiener Filter: The gain function GIW F of the WF
approach is a continuous value between 0 and 1. It is obtained
as the minimum mean-squared error estimate of the complex
spectral amplitude [24]
min E{|S (n, k) − Ŝ (n, k) |2 }

(9)

and can be written as
GIW F (n, k) =

ξ (n, k)
.
1 + ξ (n, k)

(10)

The corresponding estimate ŜIW F may then be written as
ŜIW F (n, k) = GIW F (n, k) Y (n, k) ,

(11)

3) Simulation of Estimation Errors: To investigate the influence of estimation errors in the mask patterns of WF and the
BM on SI, such errors in the mask pattern were simulated. Due
to the fact that over- and under-estimation errors influence SI
differently [25], we use the approach first described in [4] to
generate a balanced pattern of estimation errors. For the mask
derivation, the spectra of the target and the noise signal were
corrupted with an additional noise term which can be written as
S̃ (n, k) = S (n, k) + S (k)

(12)

Ṽ (n, k) = V (n, k) + V (k)

(13)

where S (k) and V (k) are complex randomly distributed variables with zero mean and power equal to the respective clean
signal in the frequency band k.
The corrupted spectra influence the short-term SNR estimation in (4) and, thereby, the mask computation. This results
in corrupted mask patterns GBM and GW F . When referring to
results and patterns obtained in the condition with perturbed
estimates, the masks are called BM and WF. The output signals
for the BM and the WF mask are
ŜBM (n, k) = GBM (n, k) Y (n, k)

(14)

ŜW F (n, k) = GW F (n, k) Y (n, k) .

(15)

The corrupted parameter estimates are only used for the mask
pattern estimates. The corrupted masks are applied to the original, unperturbed mixture in (14) and (15).
This manner of simulating estimation errors allows for both
under- and over-estimation of the instantaneous PSD estimate.
Additionally, such a perturbation of the underlying spectrum
has the advantage that it does not preserve the silence periods of the speech and/or interference. Thus, the musical-noise
phenomenon will be present in such speech/interference pauses
[26]. This lends realism to the simulation.
B. General Processing Steps
The processing steps to generate the stimuli that are presented
to the listener are shown in Fig. 1. The first six processing
steps are the same for both groups of listeners. The processing
steps that are different between NH listeners and CI users are
represented by the black trace for the noise band vocoder CI
simulation with NH listeners and by the dashed gray trace for
the electrical stimulation with CI users.

333

In the first step, the target signal s(t) and the interfering signal
v(t) (sampled at 16 kHz) are filtered with a preemphasis filter
that consists of the frequency response of the SP12 microphone
of the Freedom speech processor of Cochlear, Ltd. The result of
this preemphasis is a boost of the higher frequencies. Following
this, the noisy mixture at the desired SNR is created.
As in the Freedom speech processor of Cochlear, Ltd., the
signals are next transformed into the frequency domain using a
discrete Fourier transform with a window length of 128 samples
and a frame-shift of 32 samples. A square-root Hann window
was used as the analysis window. The envelope extraction is
done by grouping the magnitude-squared DFT coefficients into
N frequency bands. This process is applied to the target and the
interfering signal to calculate the power spectral density (PSD)
estimates used for the gain computation in (7) and (10).
In the noise reduction step, the computed gains are applied
to the N extracted envelopes to obtain the filtered envelopes.
Due to the fact that the Wiener gain in (10) can be very small
for low SNRs, the processed signal is rescaled to the same
presentation level as the clean target speech. This circumvents
audibility issues in the output signals [4], which would otherwise
influence the intelligibility.
C. Noise Band Vocoder as CI Simulation
The number of channels used for the noise band vocoder CI
simulation was set to N = 8, because asymptotic SI performance for most CI users is reached with the current clinical
speech processing strategies with eight effective channels [27].
The cutoff frequencies to obtain the band-pass filtered envelopes
are 187.5 , 437.5 , 687.5 , 1062.5 , 1562.5 , 2312.5 , 3437.5 ,
5187.5 , and 7937.5 Hz. These cutoff values for the band-pass
filters correspond to bandwidths of 250 , 250 , 375 , 500 , 750 ,
1125 , 1750 , and 2750 Hz for the eight channels. The signal
components under 187.5 Hz are not considered in the signal
processing.
In the noise band vocoding step, the enhanced envelopes are
used to modulate a broadband noise carrier subsequently filtered
by a fourth-order Butterworth filter bank with the same cutoff
frequencies as in the analysis stage. Finally, all noise vocoded
channels are added to obtain the final audio stimulus that can be
presented acoustically to the NH listener.
D. Cochlear Implants
The current clinical CI device of Cochlear, Ltd., can stimulate
22 channels. Therefore for most patients, N = 22 frequency
bands are processed in the envelope extraction stage. In this
study, all six patients used a frequency resolution of 22 channels.
The advanced combination encoder (ACE) strategy that is the
default speech processing strategy in CIs of Cochlear, Ltd.,
does not stimulate all available channels in each time frame.
The ACE strategy consists of a maxima selection stage in each
frame, where the M < N channels with envelopes of the highest
amplitude in the respective frame are selected and only these
channels are stimulated. In clinical practice, the number M of
selected maxima varies between 7 and 12. In this study, all
patients used M = 8.

334

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

Fig. 1. Processing chain for the experiments with a noise band vocoder in the top line for NH listeners (black trace) and the bottom line for CI listeners (dashed
gray trace).

TABLE I
DETAILS OF THE PARTICIPATING CI SUBJECTS: GENDER (MALE/FEMALE),
AGE (YEARS), EXPERIENCE WITH THE CI (YEARS), IMPLANT MODEL,
NUMBER OF CHANNELS, AND ETIOLOGY
Sub.

Gender

Age

Exp.

Implant

Chan.

Etiology

F
M
M
M
M
M

46
69
62
19
26
63

12
5
14
17
19
12

CI24R c(CS)
CI24R (CA)
CI24R (CS)
CI24M
CI24R (CS)
CI24R (CS)

22
22
22
22
22
22

unknown
DFNA9
progressive
congenital
meningitis
progressive

S1
S2
S3
S4
S5
S6

city) and the electrodogram (second row) are shown for the clean
speech signal input. The electrodogram of the sentence when it
was mixed with multitalker babble noise at an SNR of −20 dB
and processed with the IWF or the IBM approach is shown in the
third and fourth row, respectively. An electrodogram depicts the
excitation of the respective electrode as a function of the time.
The height of the lines represent the amplitude of the excitation
of the electrode. For CI, this can be interpreted as the analogue
of a spectrogram.
III. METHODS
A. Subjects

Fig. 2. Example of the processing with the IBM and the IWF of the Dutch
sentence “Morgen gaan we naar de stad” (Tomorrow, we are going to the city).
In the first two lines, the waveform and the electrodogram of the speech signal
is shown. Below, the resulting electrodogram at an SNR of −20 dB is shown
in the third row for the IWF and in the fourth row for the IBM processed signal.
Multitalker babble was used as the interference.

Next, a nonlinear compression maps the broad dynamic range
of the incoming sound to the reduced dynamic range of electrical
stimulation. In the channel mapping step, the selected envelopes
are modulated with an electrical pulse train. During this modulation, the threshold and comfort levels, the pulse shape and
the stimulation rate of the clinical map of the CI patient are
taken into account. Finally, the stimuli are presented with the
L34 research processor provided by Cochlear, Ltd., to the CI
patient. The L34 research processor allows direct stimulation of
the channels of the CI.
In Fig. 2, the waveform (first row) of the Dutch sentence
“Morgen gaan we naar de stad” (Tomorrow, we are going to the

The sentence recognition task with the noise vocoded CI
simulation was conducted with six NH listeners. All NH subjects
were between 16 and 22 years old (mean age 20.1 years) and
had hearing thresholds below 20 dB hearing level (HL), on both
ears, for the octave frequencies between 125 and 8000 Hz. They
were not paid for their travel expenses.
The second group of listeners consisted of six CI users. Details
of their age, experience with their CI device, the processor and
the number of processing channels can be found for each subject
in Table I. The group of CI users was paid for their participation.
All subjects were Dutch speaking adults. They signed an
informed consent form before the tests were conducted.
B. Test Material
The Leuven Intelligibility Sentence Test (LIST) sentences
[28], [29] were selected as the target speech material. These
are Dutch/Flemish sentences spoken by a male and a female speaker. The female LIST sentence material consists of
35 lists of ten Dutch/Flemish sentences. There are 38 lists of ten
Dutch/Flemish sentences available in the male LIST sentence

KONING et al.: IDEAL TIME–FREQUENCY MASKING ALGORITHMS LEAD TO DIFFERENT SPEECH INTELLIGIBILITY AND QUALITY

material of which the vocabulary of 20 lists is different from the
female lists. Only these non-overlapping lists were used during the experiments. Each sentence for the male and the female
speaker consists of four to eight words. Keywords are marked in
each sentence which results in 32 to 33 keywords per list. Each
list is balanced according to the phonetic distribution of conversational speech. The scoring was done on sentence level, where
a sentence was marked as correctly recognized if all keywords
of the respective sentence were repeated correctly.
The experiments were conducted in two different adverse listening conditions: speech in multitalker babble noise and speech
in speech. In the speech recognition task in multitalker babble
noise, the female LIST sentences were used as the target speech
material and the Auditec multitalker babble noise (from the CD
Auditory Tests (Revised), Auditec, St. Louis, MO, USA) was used
as the interfering sound. In the speech in speech scenario, the
male LIST sentences served as the target speech material, while
the female lists were the interfering speaker. The lists that did
not serve before as the target speech material in the sentence
recognition task in multitalker babble noise were used as the
interferer.
C. Procedure
The SI improvement was evaluated in two sentence recognition tasks: a sentence recognition task when the mask patterns
were derived with ideal parameter estimates, and a sentence
recognition task with simulated estimation errors in the mask
calculation. Both groups of listeners participated in these tasks.
A quality rating was performed to assess the potential for speech
quality improvement by the IWF and the IBM with CI users.
All listening tasks were conducted in a test-retest design of
the study with a break of at least one week between the two
sessions, each session lasting around 90 min.
In all listening tasks, the processed signals for all algorithms
were rescaled to the same presentation level of the clean target
speech. This was done to prevent audibility issues of the processed signals at low SNRs. The presentation level was set to
65 dB sound pressure level. The software platform Apex3 [30]
was used to present the stimuli to the subjects.
All tasks were performed in a double blind manner. At the
time of the testing, neither the subject nor the experimenter knew
which condition was tested. All subjects had the possibility to
take breaks during the testing to avoid an influence of listening
fatigue on the percent correct scores.
1) Speech Intelligibility: In this first sentence recognition
task, the signals were mixed at SNRs of 0 dB to −20 dB or
−25 dB in steps of 5 dB for the noise vocoded speech and the
CI users, respectively. The mask patterns for the IWF and IBM
were constructed with ideal parameter knowledge [(10) and
(7)]. After the processing steps described previously, the signals
were presented monaurally (left ear) using Sennheiser HDA200
headphones, in a sound-proof booth, for the NH participants.
With CI users, direct stimulation of the channels of the CI was
done with the L34 research processor.
At each SNR, one list of ten sentences of the LIST speech
material corpus was used to determine the sentence percent

335

TABLE II
OVERVIEW OVER THE CONDITIONS OF THE CONDUCTED LISTENING
TESTS OF THIS STUDY
Group

Test

Processing

Noise Type

SNR ξ 0 [dB]

CI sim.

SI

CI users

SI

IWF/IBM
WF/BM
IWF/IBM
WF/BM
IWF/IBM/no

Speech/Babble
Babble
Speech/Babble
Babble
Speech/Babble

−20, −15, . . . , 0
−5, 0
−25, −20, . . . , 0
−5, 0
0

PR

correct scores. In each session, the combination of processing
algorithm and SNR was randomized.
In each session, a training was conducted with one list of the
female LIST material of the clean speech as well as the IWFand IBM-processed speech.
2) Robustness to Estimation Errors: In this second task, both
groups of listeners were tested at SNRs of 0 and −5 dB for
the WF and the BM processed signals. The interfering signal
was multitalker babble noise. The SNRs chosen in this study
represent more realistic listening environments as compared to
the first task.
3) Preference Rating: We also investigated the speech quality of the IWF and the IBM approaches. For this, a preference
rating was done only with the CI users. Preference is often used
as a model of quality [4], [31], [32] . Therefore it is assumed
that a preference in a pairwise comparison correlates with a
quality advantage of the preferred signal. For the quality improvement, the same procedure as in [4] and [32] was used.
This consists of a two-stage pairwise preference rating test. The
pairwise comparison was administered across
1) clean speech and IWF processed output;
2) clean speech and IBM processed output;
3) IWF processed output and IBM processed output.
Clean speech, as implied here, corresponds to the clean target sentence without any interfering signal present and without
being subject to any noise reduction. Two noise conditions were
tested (speech-in-speech, speech-in-babble) at an SNR of 0 dB.
First, the signals of the respective pairwise comparison were
played one after the other and the subject had to make a decision on which one was preferred in terms of quality. After
this decision, they had to rate their preference on a five-point
scale ranging from “imperceptible” to “hugely better.” One list
of ten sentences was used per noise type. In the first session,
the subject listened to the first five sentences of a list, and in the
second session, the remaining five sentences. In total, 60 comparisons were done (10 sentences × 3 pairwise comparisons ×
2 noise conditions). The subjects were allowed to listen to the
processed stimuli as often as they wanted before making the decisions for the respective pairwise condition. Presentation order
was randomized.
The preference rating was not done with CI simulations, because the question is irrelevant in this case.
An overview with the target group, processing conditions and
mixing SNRs of listening tasks conducted in this study is given
in Table II.

336

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

Fig. 3. Results of six NH listeners for the noise vocoded stimuli processed with
the IWF (solid gray line marked with diamonds) and IBM (dashed black line
marked with triangles) in multitalker babble noise (top) and with an interfering
talker (bottom) along the tested input SNRs. The error bars depict one standard
deviation of the sentence correct scores.

IV. RESULTS
The results will be presented independently for each group
of listeners (NH listeners with CI simulations and CI users). All
percent correct scores of the sentence recognition tasks were
transformed to “rationalized” arcsine units [33] for the statistical analysis. Furthermore, the significance level of p = 0.05
was corrected with a Bonferroni correction for the multiple
comparisons in the repeated measures analysis of variance (RMANOVA).
All figures show the raw sentence correct scores of the sentence recognition tasks. In all figures, the error bars represent
one standard deviation of the raw scores.
A. Group of NH Listeners With CI Simulations
1) Speech Intelligibility: Group mean scores for the sentence recognition task with NH subjects listening to noise
vocoded speech simulations of a CI averaged over both sessions are shown in Fig. 3 for the multitalker babble noise condition (top) and for an interfering talker (bottom). The solid gray
line with diamonds represents the scores obtained for the IWF
processed signals, while the dashed black line with triangles
represents the scores obtained for the IBM processed signals.
For the multitalker babble noise condition, a three-way RMANOVA was conducted with the factors strategy, SNR, and
session. The statistical analysis revealed that the factor session
was not statistically significant. For the factor strategy, overall group mean scores for the IWF processed signals were
significantly higher by 29.5% [F (1, 5) = 110.4; p < 0.001]
than the IBM processed output. The group mean score
of the IWF processed signal was 93.5% which means almost perfect intelligibility at all tested SNRs. The factor
SNR was also significant [F (4, 20) = 23.6; (p < 0.001)]. The

Fig. 4. Mean percent scores for the sentence recognition task with corrupted
parameter estimates. The scores for the BM and the WF are shown in gray and
white, respectively. For comparison purposes, the results of the IBM (black) and
IWF (light gray) are also shown. The error bars represent the standard deviation
of the scores.

interaction between the factors strategy and SNR was also
significant [F (4, 20) = 4.865; (p < 0.05)]. Post hoc analysis
per SNR of the data revealed significant mean differences of
8.3% (p < 0.05) at 0 dB SNR, 27.5% (p < 0.001) at −5 dB
SNR, 30.8% (p < 0.001) at −10 dB SNR, 39.2% (p < 0.05)
at −15 dB SNR, and 41.7% (p < 0.001) at −20 dB SNR in
favor of the IWF in comparison with the IBM processed signal. The interaction effect of the strategy and the SNR was
also further analyzed. Post hoc analysis of the effect of SNR
for both strategies revealed that the effect of the SNR was not
statistically significant for the IWF condition but highly significant (p < 0.001) for the IBM approach, with a decreased SI
performance at lower SNRs.
Results for the interfering talker condition with the male target
speaker and the female interfering speaker are shown in the
bottom row in Fig. 3. For the interfering talker condition, a threeway RM-ANOVA was used to evaluate the data with regard to
the factors strategy, session, and SNR. In contrast to the results of
the statistical analysis in the multitalker babble noise condition,
no significant main or interaction effect was obtained.
2) Robustness to Estimation Errors: In Fig. 4, the results of
the second sentence recognition tasks with corrupted parameter estimates are shown. For comparison purposes, the results
obtained for the two different strategies in the first sentence
recognition task are also shown.
To analyze the data, a four-way RM-ANOVA with the factors estimation condition, strategy, session, and SNR was conducted. A significant effect was found for the estimation condition [F (1, 5) = 237.8; p < 0.001], where the scores were on
average 53.8% higher for the IWF and IBM in comparison to
the WF and BM processed output. Also, the factor strategy was
significant [F (1, 5) = 56.2; (p < 0.001)], which corresponds
to an advantage of (on average) 32.1% for the soft-decision approach over the binary approach. Additionally, the interaction
between the factors estimation condition and strategy was also
statistically significant [F (1, 5) = 15.5; (p < 0.05)]. A threeway interaction between the factors estimation condition, SNR,

KONING et al.: IDEAL TIME–FREQUENCY MASKING ALGORITHMS LEAD TO DIFFERENT SPEECH INTELLIGIBILITY AND QUALITY

Fig. 5. Results of six CI users for the SI task with the IWF (solid gray line
with diamonds) and IBM (dashed black line with triangles) processed stimuli in
multitalker babble noise (top) and with an interfering talker (bottom) along the
tested input SNRs. The error bars depict one standard deviation of the sentence
correct scores.

and strategy occurred [F (1, 5) = 57.4; (p < 0.05)]. Post hoc
analysis of the data with corrupted estimates revealed that the
WF approach scored on average significantly higher by 46.3%
than the BM approach. No significant effect of the factors session and SNR was obtained.
B. Group of CI Users
1) Speech Intelligibility: The results for the SI task with
ideal parameter estimates with CI users are shown in Fig. 5
for the multitalker babble noise (top) and the speech in speech
(bottom) condition, respectively. The results obtained with the
IWF mask pattern are represented by the solid gray line with
diamonds, and the results obtained with the IBM mask pattern
is represented by the dashed black line with triangles.
Statistical analysis with a three-way RM-ANOVA with the
factors strategy, SNR, and session revealed that there were
no significant main or interaction effects in multitalker babble noise. For the speech in speech scenario, a significant effect
of the main factors strategy [F (1, 5) = 12.3; (p < 0.05)] and
SNR [F (5, 25) = 13.7; (p < 0.001)] were obtained. Additionally, there was a significant interaction effect between the factors
strategy and SNR obtained [F (5, 55) = 3.6; (p < 0.05)].
Post hoc analysis of the data revealed that the SI scores
at a SNR of 0 dB differed significantly (p < 0.05) from
−20 and −25 dB SNR. The SI of the IWF differed significantly (p < 0.05) from the IBM processed signals only at
−25 dB SNR corresponding in a mean difference in intelligibility of 27%. At all other tested SNRs, both approaches did
not differ significantly from each other.
2) Robustness to Estimation Errors: The results of the
sentence recognition task with corrupted parameter estimates
are shown in Fig. 6. The error bars depict one standard

337

Fig. 6. Mean percent correct sentence scores for the sentence recognition task
with corrupted parameter estimates in CI users. The scores for the BM and the
WF are shown in gray and white, respectively. For comparison purposes, the
results of the IBM (black) and IWF (light gray) are also shown. The error bars
represent the standard deviation of the scores.

deviation. A four-way RM-ANOVA was conducted with
the estimation condition as the additional fourth factor. For
the CI users, a significant effect of the main factors estimation condition [F (1, 5) = 41.9; (p < 0.001)] and SNR
[F (1, 5) = 21.8; (p < 0.001)] were obtained. However, no interaction effect between the factors estimation condition and the
strategy was obtained. A decrease in SI for both mask patterns
was observed.
3) Preference Rating: The win count for the pairwise preference rating task are shown for all three pairwise comparisons
in Fig. 7 for speech in multitalker babble noise (dark gray bars)
and with an interfering talker (light gray bars). The win count
for a condition represents the number of times the respective
condition was preferred.
A statistical analysis was conducted for all three conditions
after a numerical score was assigned to each degree of preference. The absolute value of the score ranged from 1 (imperceptible) to 5 (hugely better). A positive value was assigned,
when condition A was preferred to condition B in the A versus
B comparison. Otherwise a negative value was assigned. Additionally, the mean score for each subject was determined and
used for the statistical analysis. For each pairwise comparison
and each interferer, a nonparametric Wilcoxon signed rank test
was conducted with the mean scores of all subjects.
The clean speech signal was significantly preferred over the
IWF processed signal with the interfering talker (p < 0.05).
There was no statistically significant difference in multitalker
babble noise between the clean speech signal and the IWF processed signal. In the case of the IBM processed signal, the clean
speech signal was preferred for both types of interfering sounds.
This preference was statistically significant (p < 0.05). In the
pairwise comparisons between the IWF and the IBM mask patterns, the IWF was statistically preferred over the IBM processed
signal in the speech-in-speech scenario (p < 0.05), while there
was no statistical preference in multitalker babble noise.

338

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

Fig. 7. Win-count histograms of the preference rating tests for the multitalker babble noise condition (dark gray) and the interfering talker condition (light gray).
The IWF and IBM processed signals were mixed at an SNR of 0 dB.

V. DISCUSSION
A. SI Task With Ideal Parameter Estimates
The SI performance for the IWF processed signals was very
high even at very low SNR in multitalker babble noise and with
an interfering talker as background sound in the group of NH
listeners with acoustical noise vocoded signals. The results suggest that the resolution of just eight frequency bands is sufficient
enough to restore almost perfect intelligibility at all SNRs. In
the statistical analysis, no significant effect of the factor SNR
was obtained.
Under ideal parameter estimates, the SI of the IBM processed
signals was perfect with the interfering talker but showed significantly lower performance, especially at low SNRs, in the
multitalker babble noise condition. The results for the cohort of
NH listeners presented with CI simulations are consistent with
the results in [4].
However, in the group of CI users, a different pattern was
observed. The SI scores in multitalker babble noise and with
an interfering talker were not at 100% for both mask patterns,
but both approaches resulted in scores that are close to the SI in
quiet for CI users. Due to the fact that there was no significant
effect of the factor strategy obtained in the statistical analysis
in multitalker babble noise and just at the lowest SNR in the
speech in speech scenario, both approaches seem to be able to
reach close-to-ceiling performance.
Therefore, the conclusion drawn in [4] that the IWF approach
should be preferred over the IBM approach cannot be confirmed
for CI applications. In contrast, the results suggest that both
approaches would be almost equally suitable in terms of SI
improvement potential under ideal parameter estimates.
Another outcome of this study is that the use of CI simulations with NH listeners can be questioned as a method to evaluate
speech enhancement algorithms developed for the application
in CIs. While CI simulations were very successful in the simulation of available spectral channels [27], [34], they were not
successful for the noise reduction algorithms evaluated in this

study. It was shown that there is a good correlation between the
scores of CI users and different types of CI simulations [23].
However, the best type of vocoder processing was depending
on the listening task. It remains unclear if a different type of CI
simulations would lead to higher correlations with the CI scores
in this study. However, the differences between the groups are
large suggesting that the trend of the scores would still be maintained with other types of CI simulations. Furthermore, it was
shown in [20] that CI users are much less sensitive to distortions
in the speech signal, because the ability to resolve temporal fine
structure is very limited due to the signal processing in CIs. In
addition, the hearing system of CI users is severely impaired
which can furthermore reduce the ability. That effect is also
present in people with sensorineural hearing loss [35]. NH listeners are still much more sensitive to distortions introduced
by the signal processing than CI users are, even when they are
listening to noise vocoded stimuli.
B. Robustness to Estimation Errors
The errors introduced in this study were independent from
the input signal. For the IBM processed signals, the total error
rate of one list of sentences had a mean of 23% with a standard
deviation of 1.7%. The total error is the sum of the type I error
when time–frequency points labelled with 0 are changed to 1
(false alarm) and the type II error when time–frequency points
originally labelled with 1 are changed to 0 (miss). For one list of
sentences, the type I error and type II error had a mean of 20%
and 3% with a standard deviation of 2.1% and 1%, respectively.
It was shown in [36] that type I errors decrease SI of BM signals
in NH listeners.
The SI for both approaches decreases for the group of NH
listeners with the noise vocoded sounds. The deterioration in
performance in multitalker babble noise is larger for the IBM
mask pattern, where performance is almost zero at both SNRs,
while the IWF still maintains around 50% SI at an SNR of
−5 dB. The WF scores are not statistical different from the IBM

KONING et al.: IDEAL TIME–FREQUENCY MASKING ALGORITHMS LEAD TO DIFFERENT SPEECH INTELLIGIBILITY AND QUALITY

scores at −5 dB SNR. Therefore, the results suggest, consistent
with [4], that the WF approach seems to be more robust to
estimation errors.
In general, the WF preserves the envelope of the target signal
better than the BM approach. When the parameters are estimated in error, the BM approach would completely discard potentially useful time–frequency regions, whereas the WF would
only scale these regions in a disadvantageous way. Thus, unlike
the BM approach, no information of the target signal will be
discarded.
For CI users, the results suggest that the estimation errors
affected the SI performance for both mask patterns. Disregarding a certain amount of information in the binary approach or
weighting the time–frequency points in a disadvantageous way
in the soft-decision approach under the condition of estimation
errors seems to equally affect the SI in CI users. Again, the
results of the CI simulation and the CI users are not in total
agreement with each other. But the results of the NH listeners
with vocoded speech show the same pattern as observed with
a different speech material with NH listeners in [4]. Comparing the SI scores of the CI users with the corrupted IBM mask
pattern at both SNRs to the scores of NH subjects listening to
noise vocoder CI simulations shows that the SI performance of
CI users is less deteriorated than in NH listeners if the signal
is affected by a certain amount of distortions. This underlines
the results of the first sentence recognition task, where the SI
of CI users is also higher than in NH subjects listening to noise
vocoded stimuli at lower SNRs. At lower SNRs the processed
signal is more distorted than at higher SNRs.

C. Preference Rating
The clean signal was preferred over the IWF and IBM processed signal in the interfering talker condition. For the IBM
approach, the unprocessed signal was also preferred in multitalker babble noise. In comparison to NH listeners in [4], the
preference is not that prominent and even absent for the IWF processed signal in multitalker babble noise. This may be explained
as follows: while a frequency resolution of 22 frequency bands
allows some leakage of the interferer into the output signal,
since mainly the envelopes of the enhanced signal are transmitted with a CI, the leakage does not affect the perceived speech
quality that much. Furthermore, since the envelope of the multitalker babble noise is more stationary than of the interfering
talker, the quality is more affected in the speech in speech case
by the interferer envelope than in multi-talker babble noise.
While the IBM and IWF mask patterns do not differ in terms
of potential for SI improvement, they differ in terms of potential for speech quality improvement in the speech-in-speech
scenario. In multitalker babble noise, there was no statistically
significant preference for either mask patterns. The results in
babble noise are consistent with the results obtained in [37],
where no difference between a soft mask and a BM was reported. The IWF approach seems to be more successful than
the IBM approach to discard the influence of the interfering
background sound when it is of highly nonstationary nature.

339

These results suggest that both single-channel algorithms perform almost equally well in terms of quality with a slight preference for the IWF in multitalker babble noise. In comparison to
[4], the preference in all pairwise conditions was much smaller,
which confirms the poorer ability of CI users to resolve speech
distortions introduced by the signal processing [20].
VI. CONCLUSION
This study investigated the potential of the IWF and the BM
approaches for SI and speech quality improvement in CIs. The
results of NH listeners presented with noise-vocoded CI simulations are consistent with that obtained in [4], and favor the
soft-decision approach over the BM. However, the outcomes of
this study suggest that for CI users with the ACE channel selection strategy, the choice between a hard- and a soft-decision
approach is not important in terms of SI.
For CI users, the SI remained close to that obtained in quiet,
even at low SNRs for both the approaches, in both types of
interference scenarios. The distortions that are introduced with
the binary gain function of the IBM do not seem to affect SI in
CI users, while NH listeners are still sensitive to the introduced
speech distortions when listening to noise vocoded speech, even
with a low spectral resolution of eight frequency bands. The
spectral resolution of the noise reduction algorithms was with
its 22 channels close to the 25 frequency bands of the Barkspectrum scale used in [4]. Therefore, the frequency resolution
is sufficient for the IBM to restore SI also at low SNRs in CI
users.
The simulated estimation errors in the derivation of the mask
patterns influenced the SI scores obtained with CI users for both
mask patterns in contrast to the data obtained with the CI simulations and NH listeners in [4]. In NH subjects, the estimation
errors led to a huge decrease in SI of the BM processed signals
and to no decrease in SI of the WF processed signals regardless
if the stimuli were also subjected to a noise vocoder or not. The
reduced sensitivity to introduced speech distortions of CI users
seems to be the most prominent reason why CI users can benefit
from real-time implementations of noise reduction algorithms
[19], [22], [38], while NH listeners are more sensitive to the
introduced speech and noise distortions. The results of the IBM
approach with estimation errors are much higher for CI users
at both tested SNRs than for the NH subjects listening to noise
vocoder CI simulations. The results suggest that noise reduction algorithms for the application in CIs can be tuned more
aggressively in terms of reducing the noise component of the
noisy mixture and tolerating introduced speech distortions by
the processing. When enough residual speech information is left
in the signal, the SI will be affected to a smaller extent.
This study also points out that the frequency resolution of
the noise reduction algorithm is a less important parameter in
the application of CI than it seems to be in NH listeners [36].
In NH listeners, eight channels seem to be sufficient enough
for the IWF approach to restore perfect intelligibility with noise
vocoded speech. It was shown that even with a low temporal and
spectral resolution, the IBM can achieve perfect intelligibility
[15], [36], but not with eight channels at very low-input SNRs.

340

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

In quiet environments, NH listeners need at least four channels
to understand speech [39]. In noisy conditions, they benefit from
an increased number of channels but asymptotic SI performance
is obtained with eight channels [27], [34].
Qualitywise, the soft-decision IWF approach was preferred
by the CI users over the IBM approach. The preference was
small and it was not as prominent as for NH listeners, who
clearly prefer soft-decision approaches over binary approaches
[4], [40], [41].
In this study, both mask patterns were evaluated with mask
parameter estimates that are not obtained from the noisy mixture
of the target speech and the interfering background sounds.
Without a priori knowledge of the target and noise components,
it would not be possible to rescale the signal to the original
speech level. Furthermore, the simulated errors were introduced
independent from the signal. Especially in the speech-in-speech
condition, noise power estimators based on statistic principles
have severe difficulties to differentiate between the target signal
and the background sound to obtain a good noise power estimate.
Therefore, the interpretation of the results has to be done with
caution. However, in this study, the maximum potential of both
mask pattern approaches was assessed. The obtained results
are a reference for SI evaluations of time–frequency masking
algorithms applied to noisy signals without a priori knowledge.
In conclusion, this study suggests that the development of
speech enhancement algorithms in general should be optimized
for the respective target group of listeners. The conclusions
drawn from studies with NH listeners cannot be generalized in
terms of SI or speech quality to the group of severely hearing
impaired people.
ACKNOWLEDGMENT
The author would like to thank all subjects who voluntarily
participated in these experiments. Furthermore, they would also
like to thank C. De Schepper for significant help in accumulating
the data.
REFERENCES
[1] D. S. Brungart, P. S. Chang, B. D. Simpson, and D. Wang, “Isolating
the energetic component of speech-on-speech masking with ideal timefrequency,” J. Acoust. Soc. Amer., vol. 120, pp. 4007–4018, 2006.
[2] I. Brons, R. Houben, and W. A. Dreschler, “Perceptual effects of noise
reduction by time-frequency masking of noisy speech,” J. Acoust. Soc.
Amer., vol. 132, no. 4, pp. 2690–2699, 2012.
[3] D. Wang, “Time-frequency masking for speech separation and its potential
for hearing aid design,” Trends Amplification, vol. 12, no. 4, pp. 323–353,
2008.
[4] N. Madhu, A. Spriet, S. Jansen, R. Koning, and J. Wouters, “The potential
for speech intelligibility improvement using the ideal binary mask and
the ideal wiener filter in single channel noise reduction systems: Application to auditory prostheses,” IEEE Trans. Audio, Speech, Lang. Process.,
vol. 21, no. 1, pp. 63–72, Jan. 2013.
[5] D. Wang, “On ideal binary mask as the computational goal of auditory
scene analysis,” in Speech Seperation by Humans and Machines. Norwell,
MA, USA: Kluwer, 2005, pp. 181–197.
[6] D. Wang and G. J. Brown, Computational Auditory Scene Analysis: Principles, Algorithms, and Applications, 1st ed. New York, NY, USA: Wiley,
2006.
[7] M. C. Anzalone, L. Calandruccio, K. A. Doherty, and L. H. Carney, “Determination of the potential benefit of time-frequency gain manipulation,”
Ear Hearing, vol. 27, no. 5, pp. 480–492, 2006.

[8] S. Cao, L. Li, and X. Wu, “Improvement of intelligibility of ideal binarymasked noisy speech by adding background noise,” J. Acoust. Soc. Amer.,
vol. 129, no. 4, pp. 2227–2236, 2011.
[9] E. W. Healy, S. E. Yoho, Y. Wang, and D. Wang, “An algorithm to improve
speech recognition in noise for hearing-impaired listeners,” J. Acoust. Soc.
Amer., vol. 134, no. 4, pp. 3029–3038, 2013.
[10] G. Kim, Y. Hu, and P. Loizou, “An algorithm that improves speech intelligibility in noise for normal-hearing listeners,” J. Acoust. Soc. Amer.,
vol. 126, no. 3, pp. 1486–1494, 2009.
[11] N. L. Li and P. C. Loizou, “Factors influencing intelligibility of ideal
binary-masked speech: Implications for noise reduction,” J. Acoust. Soc.
Amer., vol. 125, no. 3, pp. 1673–1682, 2008.
[12] D. Wang, U. Kjems, M. S. Pedersen, J. B. Boldt, and T. Lunner, “Speech
intelligibility in background noise with ideal binary time-frequency masking,” J. Acoust. Soc. Amer., vol. 125, no. 4, pp. 2236–2347, 2009.
[13] Y. Hu and P. C. Loizou, “A comparative intelligibility study of singlemicrophone noise reduction algorithms,” J. Acoust. Soc. Amer., vol. 122,
pp. 1777–1786, 2007.
[14] U. Kjems, J. B. Boldt, M. S. Pedersen, T. Lunner, and D. Wang, “Role
of mask pattern in intelligibility of ideal binary-masked noisy speech,”
J. Acoust. Soc. Amer., vol. 126, pp. 1415–1426, 2009.
[15] D. Wang, U. Kjems, M. S. Pedersen, J. B. Boldt, and T. Lunner, “Speech
perception of noise with binary gains,” J. Acoust. Soc. Amer., vol. 124,
no. 4, pp. 2303–2307, 2008.
[16] Y. Hu and P. C. Loizou, “Subjective comparison and evaluation of speech
enhancement algorithms,” Speech Commun., vol. 49, pp. 588–601, 2007.
[17] R. J. van Hoesel and G. M. Clark, “Evaluation of a portable twomicrophone adaptive beamforming speech processor with cochlear implant patients,” J. Acoust. Soc. Amer., vol. 97, no. 4, pp. 2498–2503,
1995.
[18] J. Wouters and J. Vanden Berghe, “Speech recognition in noise for cochlear
implantees with a two microphone monaural adaptive noise reduction
system,” Ear Hearing, vol. 22, pp. 420–430, 2001.
[19] A. Spriet, L. Van Deun, K. Eftaxiadis, J. Laneau, M. Moonen, B. van Dijk,
A. van Wieringen, and J. Wouters, “Speech understanding in background
noise with the two-microphone adaptive beamformer beam in the nucleus freedom cochlear implant system,” Ear Hearing, vol. 28, pp. 62–72,
2007.
[20] O. Ur Rehman Qazi, B. van Dijk, M. Moonen, and J. Wouters, “Understanding the effect of noise on electrical stimulation sequences in cochlear
implants and its impact on speech intelligibility,” Hearing Res., vol. 299,
pp. 79–87, 2013.
[21] K. Kokkinakis, B. Behnam, Y. Hu, and D. R. Friedland, “Single and
multiple microphone noise reduction strategies in cochlear implants,”
Trends Amplification, vol. 16, no. 2, pp. 102–116, 2012.
[22] S. J. Mauger, P. W. Dawson, and A. A. Hersbach, “Perceptually optimized gain function for cochlear implant signal-to-noise ratio based noise
reduction,” J. Acoust. Soc. Amer., vol. 131, no. 1, pp. 327–336, 2012.
[23] T. Strydom and J. J. Hanekom, “The performance of different synthesis
signals in acoustic models of cochlear implants,” J. Acoust. Soc. Amer.,
vol. 192, no. 2, pp. 920–933, 2011.
[24] P. Vary and R. Martin, “Single and Dual Channel Noise Reduction,” in
Digital Speech Transmission—Enhancement, Coding and Error Concealment, 1st ed. New York, NY, USA: Wiley, 2006, pp. 389–466.
[25] P. C. Loizou and G. Kim, “Reasons why current speech-enhancement
algorithms do not improve speech intelligibility and suggested solutions,”
IEEE Trans. Audio, Speech, Lang. Process., vol. 19, no. 1, pp. 47–56,
Jan. 2011.
[26] O. Cappé, “Elimination of the musical noise phenomenon with the
Ephraim and Malah noise suppressor,” IEEE Trans. Audio, Speech, Lang.
Process., vol. 2, no. 2, pp. 345–349, Apr. 1994.
[27] L. M. Friesen, R. V. Shannon, D. Baskent, and X. Wang, “Speech recognition in noise as a function of the number of spectral channels: Comparison
of acoustic hearing and cochlear implants,” J. Acoust. Soc. Amer., vol. 110,
pp. 1150–1163, 2001.
[28] A. van Wieringen and J. Wouters, “LIST and LINT: Sentences and numbers for quantifying speech understanding in severely impaired listeners
for flanders and the Netherlands,” Int. J. Audiol., vol. 47, pp. 348–355,
2008.
[29] S. Jansen, R. Koning, J. Wouters, and A. Van Wieringen, “Development
and validation of the leuven intelligibility sentence test with male speaker
(list-m),” Int. J. Audiol., vol. 53, no. 1, pp. 55–59, 2014.
[30] T. Francart, A. van Wieringen, and J. Wouters, “Apex3: A multi-purpose
test platform for auditory psychophysical experiments,” J. Neurosci. Methods, vol. 172, pp. 283–293, 2008.

KONING et al.: IDEAL TIME–FREQUENCY MASKING ALGORITHMS LEAD TO DIFFERENT SPEECH INTELLIGIBILITY AND QUALITY

[31] K. H. Arehart, J. M. Kates, M. C. Anderson, and L. O. Harvey Jr., “Effects
of noise and distortion on speech quality judgments in normal-hearing
and hearing-impaired listeners,” J. Acoust. Soc. Amer., vol. 122, no. 2, pp.
1150–1164, 2007.
[32] H. Luts, K. Eneman, J. Wouters, M. Schulte, M. Vormann, M. Buechler,
N. Dillier, R. Houben, W. A. Dreschler, M. Froehlich, H. Puder, G. Grimm,
V. Hohmann, A. Leijon, A. Lombard, D. Mauler, and A. Spriet, “Multicenter evaluation of signal enhancement algorithms for hearing aids,”
J. Acoust. Soc. Amer., vol. 127, pp. 1491–1505, 2010.
[33] G. A. Studebaker, “A ‘rationalized’ arcsine transform,” J. Speech Hearing
Res., vol. 28, pp. 455–462, 1985.
[34] M. F. Dorman, P. C. Loizou, J. Fitzke, and Z. Tu, “The recognition of sentences in noise by normal-hearing listeners using simulations of cochlearimplant signal processors with 6-20 channels,” J. Acoust. Soc. Amer.,
vol. 104, pp. 3583–3585, 1998.
[35] K. S. Henry and M. G. Heinz, “Diminished temporal coding with sensorineural hearing loss emerges in background noise,” Nature Neurosci.,
vol. 15, no. 10, pp. 1362–1364, 2012.
[36] N. L. Li and P. C. Loizou, “Effect of spectral resolution on the intelligibility
of ideal binary masked speech,” J. Acoust. Soc. Amer., vol. 123, no. 4,
pp. EL59–EL64, 2008.
[37] O. Ur Rehman Qazi, B. van Dijk, M. Moonen, and J. Wouters, “Speech
understanding performance of cochlear implant subjects using timefrequency masking-based noise reduction,” IEEE Trans. Biomed. Eng.,
vol. 59, no. 5, pp. 1364–1373, May 2012.
[38] P. W. Dawson, S. J. Mauger, and A. A. Hersbach, “Clinical evaluation
of signal-to-noise ratio-based noise reduction in nucleus cochlear implant
recipients,” Ear Hearing, vol. 32, no. 3, pp. 382–390, 2011.
[39] R. V. Shannon, F. G. Zeng, V. Kamath, J. Wygonski, and M. Ekelid,
“Speech recognition with primarily temporal cues,” Science, vol. 270,
pp. 303–304, 1995.
[40] J. Jensen and R. Hendricks, “Spectral magnitude minimum mean-square
error binary masks for DFT based speech enhancements,” in Proc. IEEE
Int. Conf. Acoust., Speech, Signal Process., 2011, pp. 4736–4739.
[41] N. Madhu, C. Breithaupt, and R. Martin, “Temporal smoothing of spectral
masks in the cepstral domain for speech separation,” in Proc. IEEE Int.
Conf. Acoust., Speech, Signal Process., 2008, pp. 1–4.

Raphael Koning was born in Hattingen, Germany,
in 1985. He received the Dipl.Ing. degree in electrical engineering from the Ruhr-Universität, Bochum,
Germany, in 2009.
In 2009, he received the Marie Curie Scholarship for Doctoral studies under the EU-ITN AUDIS, and he joined the Research Group Experimental
Otorhinolaryngology, Department of Neurosciences,
University of Leuven, Leuven, Belgium. His general
research interests include digital speech signal processing and speech enhancement. In particular, he is
interested in the development and application of speech enhancement algorithms
in hearing aids and cochlear implants.

341

Nilesh Madhu received the Dr. Ing. degree from the
Ruhr-Universität, Bochum, Germany.
His thesis was on the localization and separation
of acoustic signals using microphone arrays. He is
passionate about signal processing, and he is especially interested in the field of signal detection and
enhancement. He contributed to the research in this
paper during his term as a Postdoctoral Fellow at the
Division of Experimental Otorhinolaryngology, Department of Neurosciences, Katholieke Universiteit,
Leuven, Belgium. He has also spent time at the Auditory Perception Group, Department of Experimental Psychology, University
of Cambridge, U.K., where he researched the effect of masker comodulation
by beamforming algorithms and at the Speech Technology Group of Microsoft
Research, Redmond, USA, where he developed algorithms for multichannel
acoustic echo control.

Jan Wouters was born in 1960. He received the
Master’s and Ph.D. degrees in physics from the University of Leuven, Katholieke Universiteit (KU) Leuven, Leuven, Belgium, in 1982 and 1989, respectively, with intermission for officer military service.
From 1989 to 1992, he was a Postdoctoral Research Fellow with the Belgian National Fund for
Scientific Research, Institute of Nuclear Physics,
Catholic University of Louvain, Louvain-la-Neuve
and at NASA Goddard Space Flight Center, USA.
Since 1993, he has been a Professor at the Neurosciences Department, KU Leuven, and has been a Full Professor since 2005.
His research interests include audiology and the auditory system, signal processing for cochlear implants, and hearing aids.
Dr. Wouters is the Editorial Board of the International Journal of Audiology,
the Journal of Communication Disorders, and the Journal B-ENT. He is the
President of the European Federation of Audiological Societies and the Belgian
Audiological Society. He is a Member of the International Collegium for ORL
(CORLAS), and a Board Member of the International Collegium for Rehabilitative Audiology.

