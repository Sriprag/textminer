1318

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 4, APRIL 2014

Sensory Subtraction in Robot-Assisted Surgery:
Fingertip Skin Deformation Feedback
to Ensure Safety and Improve Transparency
in Bimanual Haptic Interaction
Leonardo Meli, Student Member, IEEE, Claudio Pacchierotti∗ , Student Member, IEEE,
and Domenico Prattichizzo, Member, IEEE

Abstract—This study presents a novel approach to force feedback in robot-assisted surgery. It consists of substituting haptic
stimuli, composed of a kinesthetic component and a skin deformation, with cutaneous stimuli only. The force generated can then
be thought as a subtraction between the complete haptic interaction, cutaneous, and kinesthetic, and the kinesthetic part of it.
For this reason, we refer to this approach as sensory subtraction.
Sensory subtraction aims at outperforming other nonkinesthetic
feedback techniques in teleoperation (e.g., sensory substitution)
while guaranteeing the stability and safety of the system. We tested
the proposed approach in a challenging 7-DoF bimanual teleoperation task, similar to the Pegboard experiment of the da Vinci Skills
Simulator. Sensory subtraction showed improved performance in
terms of completion time, force exerted, and total displacement
of the rings with respect to two popular sensory substitution techniques. Moreover, it guaranteed a stable interaction in the presence
of a communication delay in the haptic loop.
Index Terms—Biomedical engineering, haptic interfaces,
surgery, telemedicine, telerobotics.

I. INTRODUCTION
ELEOPERATED robot-assisted surgical systems can
greatly improve the accuracy and safety of medical procedures. They can filter out high-frequency signals, such as
surgical tremors [1], or scale down clinician’s movements to enhance their accuracy [2]. Moreover, they may also increase the
comfort of clinicians in the operating theatre, since the control

T

Manuscript received October 30, 2013; revised December 30, 2013; accepted
January 14, 2014. Date of publication January 28, 2014; date of current version
March 17, 2014. This work was supported from the European Union Seventh Framework Programme FP7/2007-2013 under Grant 270460 of the project
“ACTIVE—Active Constraints Technologies for Ill-defined or Volatile Environments” and under Grant 601165 of the project “WEARHAP—WEARable
HAPtics for humans and robots.” Asterisk indicates corresponding author.
L. Meli and D. Prattichizzo are with the Department of Information Engineering and Mathematics, University of Siena, 53100 Siena, Italy, and also with
the Department of Advanced Robotics, Istituto Italiano di Tecnologia, 16163
Genova, Italy (e-mail: meli@dii.unisi.it; prattichizzo@dii.unisi.it).
∗ C. Pacchierotti is with the Department of Information Engineering and Mathematics, University of Siena, 53100 Siena, Italy, and also with the Department
of Advanced Robotics, Istituto Italiano di Tecnologia, 16163 Genova, Italy
(e-mail: pacchierotti@dii.unisi.it).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2014.2303052

interface can be always positioned in a way convenient for the
operator to control. Teleoperated robotic systems are composed
of a slave robot, which interacts with the given environment,
and a master system, operated by a human. The slave robot is
in charge of resembling the movement of the clinician who, in
turn, needs to observe the environment the robot is interacting
with. If the clinician receives sufficient information about the
slave system and the remote environment, he will feel as if he is
actually present at the remote site: this condition is referred to as
telepresence [3], [4]. Achieving it is mainly a matter of technology. A human operator, in fact, upon reflection, knows where he
really is, despite the use of any kind of machine, but, if the slave
system transmits sufficient information, displayed in a rather
natural way, the illusion of telepresence can be compelling [4].
The primary tool to attain this objective is providing a transparent implementation of the teleoperation system, which can
be defined as the correspondence between the master and slave
positions (kinematic correspondence) and forces [5]. A convincing illusion of telepresence can be achieved through different
types of information, which flow from the remote scenario to
the human operator. They are usually a combination of visual,
auditory, and haptic stimuli. Visual and auditory feedback are
already employed in commercial robotic surgery systems (e.g.,
the da Vinci Si Surgical System1 ), while it is not common to
find commercially available devices implementing haptic force
feedback. Two of the few examples are the DLR MiroSurge [6]
and the Sensei2 robotic catheter system.
However, haptic force is widely considered to be a valuable
navigation tool during teleoperated surgical procedures [7], [8].
It allows to detect local mechanical properties of the tissue
being penetrated and distinguish between expected and abnormal resistance due, for example, to the unexpected presence
of vessels [2]. Force feedback has been shown to enhance operators’ performance in teleoperation in terms of completion
time of a given task [9], [10], accuracy [7], [11], [12], peak,
and mean applied force [11], [13]. In surgery, improved performance when providing force feedback was demonstrated for
telerobotic catheter insertion [14], suturing simulation [12], cardiothoracic procedures [15], cell injection systems [16], and fine
microneedle positioning [8]. Other studies have linked the lack
1 Intuitive
2 Hansen

Surgical, Sunnyvale, CA, USA.
Medical, Mountain View, CA, USA.

0018-9294 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

MELI et al.: SENSORY SUBTRACTION IN ROBOT-ASSISTED SURGERY

of significant haptic feedback to increased intraoperative injury
in minimally invasive surgery operations [17] and endoscopic
surgical operations [18]. Moreover, haptic feedback can be also
employed to augment the surgical environment, providing additional valuable information to the operator, such as navigation
cues or tool contact accelerations. Nakao et al. [19], for example, presented a haptic navigation method which allows surgeons
to avoid collision with forbidden regions by employing haptic
feedback through a two-dimensional (2-D) master manipulator,
and McMahan et al. [20] developed a sensing and actuating device for the da Vinci S Surgical System to provide auditory and
vibrotactile feedback of tool contact accelerations.
In addition to transparency, another important goal in teleoperation with force feedback is stability [5]. The kinesthetic part
of the haptic interaction can, in fact, lead to undesired oscillations of the system, which may be unsafe for both the clinician
and the patient being operated on. Stability of haptic systems can
be significantly affected by communication latency in the teleoperation loop, hard contacts, stiff control settings, and many
other destabilizing factors which dramatically reduce the effectiveness of haptic force feedback in teleoperation [7], [21]. In
this respect, passivity [22] has been exploited as the main tool
for providing a sufficient condition for stable teleoperation in
several controller design approaches, such as time domain passivity control [23], energy bounding algorithm [24], and passive
set position modulation [25]. However, control techniques guarantee the stability of the system at the price of a temporary loss
of transparency, which could lead to degraded performance [26].
Moreover, in cases of serious failures of the actuators, the teleoperation loop can experience problems that cannot be managed
by control and can lead to an abrupt change in the behavior of
the remote robot [7]. For this reason, feedback approaches that
disregard kinesthetic feedback are lately gaining great interest, especially in fields where safety is paramount, e.g., robotic
surgery.
A popular nonkinesthetic approach to provide information
about forces exerted at the slave side is sensory substitution. It
consists of substituting kinesthetic force with alternative forms
of feedback, such as vibrotactile [29], auditory, and/or visual
feedback [30]. In this case, since no kinesthetic force is fed back
to the operator, the haptic loop becomes intrinsically stable and
no bilateral controller is thus needed [7].
However, these stimuli are often very different from the ones
being substituted (e.g., a beep sound instead of force feedback)
and they may show worse performance than that achieved employing unaltered force feedback [7]. Similarly to sensory substitution, Prattichizzo et al. [7] presented a feedback approach
that substituted haptic force feedback with cutaneous feedback
only. Results showed higher transparency levels than that obtained compared to other conventional sensory substitution techniques. The authors named this technique sensory subtraction,
since the force provided (i.e., cutaneous stimuli only) can be
thought as a subtraction between the complete haptic interaction,
consisting of cutaneous and kinesthetic components [31], [32],
and the kinesthetic part of it. However, the study presented by
Prattichizzo et al. only considered a 1-DoF teleoperation task,
carried out in a virtual environment.

1319

Fig. 1. The da Vinci Skills Simulator contains a variety of exercises designed
to give clinicians the opportunity to improve their proficiency with the surgeon
console controls (right). In this study, we evaluated the sensory subtraction
approach in a 7 degrees-of-freedom (DOF) bimanual experiment, very similar
to the Pegboard module provided by the da Vinci Skills Simulator (left).

In this paper, we exploited the idea of sensory subtraction in a
challenging medical scenario: a bimanual 7-DoF teleoperation
task, very similar to the Pegboard module of the da Vinci Skills
Simulator3 (see Fig. 1). The master system was composed of
two 7-DoF haptic interfaces, used together with four wearable
cutaneous devices. The task consisted of inserting four rings in
two different pegs. Performances were compared while providing 1) complete haptic force feedback through a couple of haptic
interfaces, 2) cutaneous force feedback through four cutaneous
devices, i.e., the sensory subtraction approach, 3) visual and
4) audio feedback in substitution of force feedback, which are
two popular sensory substitution techniques.
The paper is organized as follows: Section II introduces the
idea of sensory subtraction, together with the cutaneous devices
employed in this study. Sections III and IV evaluate the sensory
subtraction approach in two paradigmatic 7-DoF bimanual experiments. Both are discussed in Section V. Finally, Section VI
addresses concluding remarks and perspectives of the study.
II. SENSORY SUBTRACTION: A NOVEL APPROACH TO FORCE
REFLECTION IN TELEOPERATION
General-purpose commercial haptic interfaces can be classified as either ground-based devices (force reflecting joysticks
and linkage-based devices) or body-based devices (gloves, suits,
exoskeletal devices). The former are solidly connected to the
“world,” while the latter are attached to the body of the user.
Most of the well-known grounded haptic devices, such as the
Omega4 or the Phantom,5 provide kinesthetic force feedback to
the users [32]. However, these devices also provide cutaneous
stimuli to the fingertips, if we assume that the interaction with the
remote environment is mediated by a stylus, a ball, or any other
tool fixed on the haptic interface [7], [28]. For this very reason,
we can consider the haptic force feedback provided by grounded
3 Intuitive Surgical, Sunnyvale, CA, USA, and Mimic Technologies, Seattle,
WA, USA.
4 Force Dimension, Nyon, Switzerland.
5 Sensable group, Geomagic, 3-D Systems, Rock Hill, SC, USA.

1320

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 4, APRIL 2014

at the platform’s center, in contact with the finger, so that it
measures the component of the cutaneous force perpendicular
to the volar skin surface of the fingertip.
In this study, we will employ a customized version of the
cutaneous device employed by Pacchierotti et al. [28]. The force
sensor has been removed, and the two platforms have been
reshaped to make it easier to use together with the 7-DoF haptic
interfaces.
III. 7-DOF BIMANUAL PEGBOARD EXPERIMENT
In order to evaluate the feasibility of sensory subtraction in a
challenging teleoperation scenario, a 7-DoF bimanual Pegboard
experiment was carried out.
A. Experimental Setup

Fig. 2. Two fingertip skin deformation devices employed in sensory subtraction. (a) Prattichizzo et al. in [27]. (b) Pacchierotti et al. in [28]. (c) Pacchierotti
et al. in [28].

haptic devices as perceived by the operator through two different channels: cutaneous and kinesthetic [7], [28], [31], [32].
Cutaneous stimuli are sensed by pressure receptors in the skin
and they are useful to recognize the local properties of objects
such as shape, edges, embossings, and recessed features. This
is possible, principally, thanks to a direct measure of intensity
and direction of contact forces, and to the encoding of the force
spatial distribution over the fingertip [31], [33]. On the other
hand, kinesthesia provides the user with information about the
relative position of neighboring parts of the body, mainly by
means of sensory organs in muscles [34] and joints [32].
The sensory subtraction approach, first introduced in [7], consists of substituting this haptic force with cutaneous stimuli only,
provided by custom fingertip skin deformation devices. The first
device developed for this purpose is the 3-DoF wearable cutaneous interface presented by Prattichizzo et al. [27] and shown
in Fig. 2(a). It consists of two platforms: One is placed on the
back of the finger and supports three small electrical motors; the
other one is in contact with the volar skin surface of the fingertip. The two parts are connected by three wires. The motors, by
controlling the length of the wires, move the platform toward
the user’s fingertip, generating a force that simulates the contact
with an arbitrary surface. Three force sensors are placed near
to the platform vertices, in contact with the finger, so that they
measure the three components of the cutaneous force applied to
the fingertip. An improved version of the same device has been
employed by Pacchierotti et al. [28], and it is shown in Fig. 2(b)
and (c). It is similar to the one mentioned previously, but shows
higher accuracy. It consists again of two platforms connected
by three wires. Three small electrical motors, equipped with
position encoders, control the length of the wires, moving the
mobile platform toward the fingertip. One force sensor is placed

Fig. 3 shows the experimental setup. The master system was
composed of two Omega 7 haptic interfaces and four cutaneous
devices. The Omega 7 is a grounded haptic interface with 7 DoF,
four active (translation and gripper) and three passive (wrist).
The cutaneous devices are the ones presented in Section II and
were worn as shown in Fig. 3(b), i.e., on the thumb and index
finger of both hands. The slave system was composed of two virtual surgical pliers, directly controlled by the master interfaces.
The pliers accurately resembled fingers’ motion on the Omega
devices. Users were able to move and rotate the pliers in the 3-D
space and control their gripping force. The virtual environment
consisted of four rings, two green and two red, and two pegs,
one green and one red [see Fig. 3(c)]. The rings weighed 30 g
and had a minor radius of 3 cm, a major radius of 5 cm, and a
height of 1 cm. The pegs were fixed to the ground and had a base
diameter of 4 cm and a height of 10 cm. A spring k0 = 40 N/m
was used to model the contact force between the proxies and
the objects, according to the god-object model [35]. The virtual environment was built using CHAI 3-D, an open-source
set of C++ libraries for computer haptics and interactive realtime simulation. The haptic interfaces were controlled using the
Haptik Library [36].
The task consisted of lifting, one by one, the rings from the
ground with one pair of pliers, handing them to the other pair
and inserting them into the peg of the corresponding color. An
insertion was considered valid only when the ring was inserted
in the correct peg. As already mentioned, the task resembles the
Pegboard experiment proposed in the da Vinci Skills Simulator.
The task started when the user grasped a ring for the very first
time and ended when all the rings were inserted into the pegs.6
B. Force Feedback Conditions
Each participant made sixteen trials of the aforementioned
Pegboard task, with four randomized repetitions of each force
feedback modality considered:
1) complete haptic force feedback provided by the Omega 7
haptic interfaces (modality H);
2) cutaneous force feedback provided by the cutaneous devices (modality C), i.e., the sensory subtraction approach;
6 Video

of the experiment can be downloaded at http://goo.gl/Wc6WYB

MELI et al.: SENSORY SUBTRACTION IN ROBOT-ASSISTED SURGERY

1321

Fig. 3. Experimental setup. Users had to wear four cutaneous devices, one on the thumb and one on the index finger of both hands, and teleoperate two pairs of
surgical pliers using a couple of Omega 7 haptic interfaces. The task consisted of lifting the rings from the ground with one pair of pliers, handing them to the
other pair, and inserting them into the peg of the corresponding color. Ten subjects participated in the experiment. (a) General overview of setup. (b) Detail of one
hand wearing the cutaneous devices. (c) Virtual environment with surgical pliers.

3) visual feedback in substitution of force feedback, provided
by changing color brightness of the ring being grasped
(modality V);
4) auditory feedback in substitution of force feedback, provided by changing the repetition frequency of a stereo
beep tone (modality A).
In all the considered modalities, the Omega 7 devices were
in charge of controlling the movements of the surgical pliers by
tracking position and orientation of the operator’s hands. The
virtual environment then computed the interaction forces, and
the controller provided force feedback to the user through either
the haptic devices, cutaneous devices, or a substitution (visual
or audio) modality (see Fig. 4).
Haptic force feedback (modality H) was provided through
the Omega 7 haptic interfaces, which are able to render grip and
translation forces in the 3-D space. As mentioned previously,
the force provided by this type of grounded devices is composed
of two components, cutaneous and kinesthetic.
Cutaneous force feedback (modality C) was provided by
four prototypes of the custom cutaneous device presented in
Section II. Since they did not embed any force sensor, no direct
measurement of the applied cutaneous stimuli was available.
This force was thus estimated according to the fingertip model
employed in [27], which considers a linear relationship between
resultant wrench at the fingertip and device’s platform displacement. In other terms, we assumed device’s platform configuration ξ = [px py pz α β γ]T ∈ 6 to be proportional to the
T
6
wrench wp = [fpT mT
p ] ∈  applied to the mobile platform
ξ = K −1 wp

(1)

where K ∈ 6×6 is the fingertip stiffness matrix. An isotropic
elastic behavior was then considered, so that the stiffness value
was the same for all the elements of the diagonal matrix: K =
kI, k = 0.5 N/mm [37].
Sensory substitution by visual feedback (modality V) was
employed to provide the operator with information about how
much grasping force was applied to a ring: the more force was
applied, the brighter the ring appeared. As shown in Fig. 3(c),
the rings were presented in two colors, red and green. Colors
were rendered using the RGB color model, and their perceived
brightness was evaluated as indicated in [38], i.e.,

pb (r, g, b) = 0.241r2 + 0.691g 2 + 0.068b2

Fig. 4. Teleoperation system overview. The Omega 7 haptic interfaces are in
charge of controlling the position and orientation of the surgical pliers in the
virtual environment. The latter then computes the interaction force to be fed
back to the user, while the controller provides it to the human operator through
either the haptic devices, cutaneous devices, or a substitution (visual or audio)
modality.

where r, g, and b ∈ [0, 255] indicate the red, green, and blue
components of the color, respectively. Brightness of the ring
being manipulated was then computed as a function of the grip
force fh , expressed in Newtons,
pb (r, g, b) = 8fh  + 85

1322

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 4, APRIL 2014

with
g=b=0

for red rings, and

r=b=0

for green rings.

Sensory substitution by auditory feedback (modality A) was
also employed to provide the operator with information about
how much grasping force was applied to the rings. A series of
stereo beep sounds were used: the more force was applied, the
higher the frequency7 of the series of beeps sounds. The pair of
pliers controlled by the operator’s right hand produced a sound
on the right earphone, while the other pair produced a sound on
the left one, making it very easy for the operator to understand
which tool was applying force. The series of beep sounds can
be seen as a pulse wave, with a fixed pulse duration τa = 0.05 s
(the duration of a single beep), and a period, expressed in seconds, of
⎧
fh 
⎨
1.2 −
if fh  ≤ 5
Ta =
5
⎩
0.2
if fh  > 5
where fh indicates again the grip force applied to the object,
expressed in Newtons. The operator, therefore, hears the beeps
getting closer to each other while the force exerted increases. It
is worth highlighting that in modalities C, V, and A, the Omega
7 was only used to track the position of the fingers and did not
provide any force feedback.
C. Subjects
Ten participants took part in the experiment. Five of them
had previous experience with haptic interfaces, but only two
have tried cutaneous devices before. None of the participants
reported any deficiencies in their perception abilities. Subjects
were asked to complete the task as soon as possible. Participants
were informed about the procedure before the beginning of the
experiment, and a 10-min familiarization period was provided
to make them acquainted with the experimental setup.
D. Results
In order to evaluate the performance of the considered feedback modalities, we recorded 1) the time needed to complete
the task, 2) the forces generated by the contact between the pliers and the rings,8 and 3) the total displacement of the rings.
Data resulting from different repetitions of the same feedback
modality, performed by the same subject, were averaged before
comparison with other modalities’ data.
Fig. 5(a) shows the average time elapsed between the instant
the user grasps the object for the very first time and the instant
she/he completes the Pegboard task. Fig. 5(b) reports the average
grip forces generated between the two pairs of pliers and the
rings along the direction of actuation of the Omega’s gripper,
i.e., the one perpendicular to the object surface. Only data with
7 Note that we refer to the frequency of repetitions of the beeps, e.g., beeps
per seconds.
8 Measuring the average of intensities of the contact forces is a widely used
approach to evaluate energy expenditure during the grasp [39].

Fig. 5. 7-DoF bimanual Pegboard experiment. Completion time, contact
forces, and rings’ displacement (mean is plotted) for the haptic (H), cutaneous
(C), visual (V), and auditive (A) modalities. Lower values of this metrics indicate higher performances in completing the given Pegboard task. P-values of
post-hoc group comparisons are reported when a statistical difference is present
(confidence interval of 95%). (a) Completion time. (b) Contact forces. (c) Rings’
displacement.

nonzero forces were considered. Fig. 5(b) shows the sum of the
rings’ displacements, averaged over the subjects. Finally, Fig. 6
reports the grip forces exerted on the rings by the pliers for a
representative run.
In order to evaluate the performance of sensory subtraction,
both with respect to the ideal case H and to the other popular sensory substitution techniques V and A, we tested the three
metrics for differences among the four feedback conditions considered. All the data passed the Shapiro–Wilk normality test.9
Only data regarding objects displacement passed the Levene’s
homogeneity test. For this reason, means were tested using a
one-way ANOVA and Tukey HSD post-hoc test for data about
9 Data in this and in the following statistical tests were transformed, if necessary [40].

MELI et al.: SENSORY SUBTRACTION IN ROBOT-ASSISTED SURGERY

1323

TABLE I
ANOVA RESULTS FOR THE PEGBOARD EXPERIMENT (CONFIDENCE INTERVAL
OF 95%)

rings’ displacement, and a Welch ANOVA and Games–Howell
post-hoc test for data regarding completion time and grip forces.
The tests revealed no significant difference between the visual
and auditory modalities (V and A) for all the considered metrics, while it revealed a significant difference between the other
modalities. Details on the statistical analysis are reported in
Table I and Fig. 5.
IV. 7-DOF BIMANUAL PEGBOARD EXPERIMENT WITH
COMMUNICATION DELAY
A second experiment was then carried out. It considered the
same task, performed by the same ten subjects, with the same experimental setup and feedback modalities. However, this time
we introduced a communication delay of 20 ms between the
master and slave systems. Time delays, if no countermeasures
are taken, are known to bring teleoperation systems with force
reflection close to an unstable behavior, i.e., undesired oscillations [41]. In order to evaluate the performance of the considered
feedback modalities, we again recorded 1) the time needed to
complete the task, 2) the forces generated by the contact between the pliers and the rings, and 3) the total displacement of
the rings. Data resulting from different repetitions of the same
feedback modality, performed by the same subject, were again
averaged before comparison with other modalities’ data.
A. Results

Fig. 6. Pegboard experiment. Force exerted by the pliers on the rings, for
a representative run, versus time. (a) Modality H. (b) Modality C (sensory
subtraction). (c) Modality V. (d) Modality A.

As for the first experiment, Fig. 7(a) shows the average task’s
completion time, Fig. 7(b) shows the average grip forces generated between the pliers and the rings, and Fig. 7(c) shows
the sum of the rings’ displacements, averaged over the subjects.
Fig. 8 reports the grip forces exerted on the rings by the pliers for
a representative run. In order to evaluate the performance of sensory subtraction, both with respect to the ideal case H and to the
other popular sensory substitution techniques V and A, we again
tested the three metrics for differences among the four feedback
conditions considered. All the data passed the Shapiro–Wilk
normality test. All the data, except the ones regarding completion time, passed the Levene’s homogeneity test. For this reason,
means were tested using a one-way ANOVA and Tukey HSD
post-hoc test for data about rings’ displacement and grip forces,
and a Welch ANOVA and Games–Howell post-hoc test for data
regarding completion time. The tests revealed no significant difference between the visual and auditory modalities (V and A)
for all the considered metrics, no significant difference between
cutaneous and haptic modalities (C and H) for what regards the
gripping force, and no significant difference between visual and

1324

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 4, APRIL 2014

TABLE II
ANOVA RESULTS FOR THE PEGBOARD EXPERIMENT (CONFIDENCE INTERVAL
OF 95%, DELAY OF 20 MS IN THE HAPTIC LOOP)

Fig. 7. 7-DoF bimanual Pegboard experiment with communication delay.
Completion time, contact forces, and rings’ displacement (mean is plotted) for
the haptic (H), cutaneous (C), visual (V), and auditive (A) modalities. Lower
values of this metrics indicate higher performances in completing the given
Pegboard task. P-values of post-hoc group comparisons are reported when a
statistical difference is present (confidence interval of 95%). A communication delay of 20 ms was simulated between the master and the slave systems.
(a) Completion time. (b) Contact forces. (c) Rings’ displacement.

haptic modality (V and H) for what regards completion time. It
then revealed a significant difference between the modalities in
all the other cases. Details on the statistical analysis are reported
in Table II and Fig. 7.
We then performed an additional analysis to compare performance between this experiment and the one without communication delay (see Section III-D). We tested the means of
each feedback modality across the two experiments, for the
three metrics considered, e.g., haptic feedback with delay versus haptic feedback without delay, cutaneous feedback with
delay versus cutaneous feedback without delay, etc. In order to

determine whether the performance observed here can be considered equivalent to that registered in the first experiment, we
used the two one-sided t-test (TOST). The null hypothesis of
the TOST states that the mean values of two groups are different by a certain amount θ (or larger). Then, in order to test for
equivalence, the 90% confidence intervals for the difference between the two groups are evaluated. The null hypothesis that the
groups differ by at least θ is rejected if the limits of the interval
fall outside the ±θ bounds. Conversely, comparability is demonstrated when the bounds of the 90% confidence interval of the
mean difference fall entirely within the ±θ bounds [42], [43].
The design of equivalence tests can be quite tricky since the
acceptance criterion θ has to be defined on the basis of prior
knowledge of the measurement. For a sample dataset of n independent measurements with standard
√ deviation s, for instance,
θ must be for sure greater than s/ n, otherwise the test may
fail simply because of imprecision, rather than because of a true
difference. However, it must also be less than any specifications
or standards that the testing is challenging, or the test becomes
too easy and will thus not adequately discriminate. In this study,
we evaluated θ as suggested in [43], where the authors provide a
useful step-by-step process for performing equivalence testing
with commonly available computational software packages.
We ran 12 TOST equality tests to compare, across the two
experiments, three metrics in four feedback modalities. The tests
revealed statistical equivalence for cutaneous (C) and auditory
(A) feedback in all the metrics and for visual feedback (V) for
what regards completion time only. However, visual feedback in
the other two metrics (displacement and forces) was very close
to equality. In fact, running a new TOST with θw = 1.5 θ made
modality V equivalent across the two experiments for all the
metrics, as we expected. Haptic force feedback (H) did not pass
the TOST equality tests in any metric. We thus ran a paired t-test
to check haptic feedback data (H) for differences across the two
experiments. Results revealed a significant difference between
the data in all the considered metrics (p < 0.001 for completion
time, grip force, and rings’ displacement).
V. DISCUSSION
We tested four feedback modalities in two different experimental scenarios, the second of which introduces a 20-ms communication delay in the teleoperation loop.
Results of the first experiment (no delay) are reported in
Section III-D and Fig. 5. Subjects, while receiving haptic force
feedback (H), showed better performance than while receiving any other form of stimuli (C, V, or A). Moreover, sensory

MELI et al.: SENSORY SUBTRACTION IN ROBOT-ASSISTED SURGERY

1325

subtraction (C) yielded to significant better results than employing auditory or visual feedback in substitution of haptic feedback
(A and V). The two latter modalities showed no significant differences between each other. These considerations are valid
for all the metrics considered: completion time, grip force, and
rings’ displacement.
In order to validate the stability properties of sensory subtraction, we carried out an additional experiment, in which we
introduced a communication delay of 20 ms between the master and slave systems. Results are reported in Section IV-A and
Fig. 7. Sensory subtraction (C) and the substitution modalities (A and V) showed a behavior similar to the one registered
previously (when no delay was present), while haptic force feedback showed highly degraded performance.10 The occurrence
of such a degraded behavior is well known in the literature and
was reported here to highlight the intrinsic stability of sensory
subtraction.
From these results, we can conclude that sensory subtraction
may be a valid replacement for sensory substitution techniques
in teleoperation. Moreover, it may also be a valid replacement
to complete haptic feedback in those scenarios where safety is
paramount, e.g., robotic surgery. Sensory subtraction, in fact,
guarantees the intrinsic stability of the system. On the other
hand, stability of teleoperation systems with haptic feedback can
be significantly affected by various destabilizing factors (e.g.,
time delays in the teleoperation loop), which may compromise
the safety of both the patient and the clinician.
The results hereby registered are in agreement with previous
results in the literature. Prattichizzo et al. performed four experiments of teleoperated needle insertion in 1-DoF and found sensory subtraction to perform better than sensory substitution with
visual feedback [7]. Pacchierotti et al. developed two custom devices to provide cutaneous stimuli in teleoperation [10], [44].
Both of them were attached to the end-effector of grounded
haptic interfaces, such as the one employed here, and showed
performances comparable to the ones presented in this study.
However, all the aforementioned papers agree that haptic force
feedback, when no oscillations arise, perform significantly better than any substitutive modality.
VI. CONCLUSION AND FUTURE WORKS

Fig. 8. Pegboard experiment with communication delay. Force exerted by
the pliers on the rings, for a representative run, versus time. (a) Modality H
(unstable behavior arises). (b) Modality C (sensory subtraction). (c) Modality
V. (d) Modality A.

In this study, we presented a novel approach to force feedback
in robot-assisted surgery, which we called sensory subtraction.
It was first introduced by Prattichizzo et al. [7] and consists of
substituting haptic stimuli, composed of a kinesthetic component and a skin deformation, with cutaneous stimuli only.
The force generated can be thus thought as a subtraction between the complete haptic interaction and the kinesthetic part
of it. For this reason, we refer to this approach as sensory subtraction and not sensory substitution.
We evaluated the sensory subtraction approach in a challenging 7-DoF bimanual teleoperation task, similar to the Pegboard tasks proposed in the da Vinci Skills Simulator. We compared sensory subtraction with complete haptic feedback, i.e.,
10 Video of this second experiment, focusing on the unstable behavior of the
haptic modality, can be downloaded at http://goo.gl/4T51Tw.

1326

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 4, APRIL 2014

force feedback provided by a grounded interface, and two popular sensory substitution techniques, i.e., visual and auditory
feedback in substitution of force feedback. Sensory subtraction outperformed the two sensory substitution techniques but,
as expected, performed worse than providing complete haptic
feedback. However, sensory subtraction guaranteed the intrinsic
stability of the teleoperation system and kept the system stable
even in the presence of a communication delay in the teleoperation loop. Haptic force feedback, on the other hand, showed
highly degraded performance in the presence of such a delay.
Although sensory subtraction seems very promising, haptic
force feedback, when no oscillations arise, still showed better
performance in all the metrics considered. Moreover, surgeons
may not be totally positive about the idea of wearing four fingertip devices while operating. And finally, the force sensed through
this kind of cutaneous devices is upper bounded by the sensing
capabilities of human cutaneous receptors. Work is in progress
to design new cutaneous displays with better dynamic performance and better wearability. Furthermore, new experiments,
aiming at evaluating system performance while interacting with
a real environment, will be performed in the next future. Finally,
work is in progress to validate the approach with more subjects.
REFERENCES
[1] A. M. Okamura, “Methods for haptic feedback in teleoperated robotassisted surgery,” Ind. Robot, Int. J., vol. 31, no. 6, pp. 499–508, 2004.
[2] D. De Lorenzo, E. De Momi, I. Dyagilev, R. Manganelli, A. Formaglio,
D. Prattichizzo, M. Shoham, and G. Ferrigno, “Force feedback in a piezoelectric linear actuator for neurosurgery,” Int. J. Med. Robot. Comput.Assist. Surg., vol. 7, no. 3, pp. 268–275, 2011.
[3] T. B. Sheridan, “Telerobotics,” Automatica, vol. 25, no. 4, pp. 487–507,
1989.
[4] T. Sheridan, Telerobotics, Automation, and Human Supervisory Control.
New York, NY, USA: MIT Press, 1992.
[5] K. Hashtrudi-Zaad and S. E. Salcudean, “Transparency in time-delayed
systems and the effect of local force feedback for transparent teleoperation,” IEEE Trans. Robot. Autom., vol. 18, no. 1, pp. 108–114, Feb. 2002.
[6] U. Hagn, R. Konietschke, A. Tobergte, M. Nickl, S. Jörg, B. Kübler,
G. Passig, M. Gröger, F. Fröhlich, U. Seibold, L. Le-Tien, A. AlbuSchäffer, A. Nothhelfer, F. Hacker, M. Grebenstein, and G. Hirzinger,
“DLR MiroSurge: A versatile system for research in endoscopic
telesurgery,” Int. J. Comput.-Assist. Radiol. Surg., vol. 5, no. 2, pp. 183–
193, 2010.
[7] D. Prattichizzo, C. Pacchierotti, and G. Rosati, “Cutaneous force feedback
as a sensory subtraction technique in haptics,” IEEE Trans. Haptics, vol. 5,
no. 4, pp. 289–300, Oct.–Dec. 2012.
[8] S. E. Salcudean, S. Ku, and G. Bell, “Performance measurement in scaled
teleoperation for microsurgery,” in Proc. 1st Joint Conf. Comput. Vis.,
Virtual Reality Robot. Med. Med. Robot. Comput.-Assist. Surg., 1997,
pp. 789–798.
[9] M. J. Massimino and T. B. Sheridan, “Teleoperator performance with
varying force and visual feedback,” Human Factors: J. Human Fact. Ergonom. Soc., vol. 36, no. 1, pp. 145–157, 1994.
[10] C. Pacchierotti, F. Chinello, M. Malvezzi, L. Meli, and D. Prattichizzo,
“Two finger grasping simulation with cutaneous and kinesthetic force
feedback,” Haptics: Perception, Devices, Mobility, Commun., pp. 373–
382, 2012.
[11] D. Prattichizzo, C. Pacchierotti, S. Cenci, K. Minamizawa, and G. Rosati,
“Using a fingertip tactile device to substitute kinesthetic feedback in
haptic interaction,” Haptics: Generating Perceiving Tangible Sensations,
vol. 6191, pp. 125–130, 2010.
[12] L. Moody, C. Baber, and T. N. Arvanitis, “Objective surgical performance
evaluation based on haptic feedback,” Stud. Health Technol. Informat.,
vol. 85, pp. 304–310, 2002.
[13] C. R. Wagner, N. Stylopoulos, and R. D. Howe, “The role of force feedback in surgery: Analysis of blunt dissection,” in Proc. 10th Symp. Haptic
Interfaces Virtual Environ. Teleoperator Syst., 2002, pp. 68–74.

[14] A. Kazi, “Operator performance in surgical telemanipulation,” Presence:
Teleoperator Virtual Environ., vol. 10, no. 5, pp. 495–510, 2001.
[15] C. W. Kennedy, T. Hu, J. P. Desai, A. S. Wechsler, and J. Y. Kresh, “A
novel approach to robotic cardiac surgery using haptics and vision,” Cardiovasc. Eng., vol. 2, no. 1, pp. 15–22, 2002.
[16] A. Pillarisetti, M. Pekarev, A. D. Brooks, and J. P. Desai, “Evaluating the
effect of force feedback in cell injection,” IEEE Trans. Autom. Sci. Eng.,
vol. 4, no. 3, pp. 322–331, Jul. 2007.
[17] A. M. Okamura, “Haptic feedback in robot-assisted minimally invasive
surgery,” Curr. Opin. Urol., vol. 19, no. 1, pp. 102–107, 2009.
[18] M. Hashizume, M. Shimada, M. Tomikawa, Y. Ikeda, I. Takahashi, R. Abe,
F. Koga, N. Gotoh, K. Konishi, S. Maehara, K. Sugimachi et al., “Early
experiences of endoscopic procedures in general surgery assisted by
a computer-enhanced surgical system,” Surg. Endosc., vol. 16, no. 8,
pp. 1187–1191, 2002.
[19] M. Nakao, K. Imanishi, T. Kuroda, and H. Oyama, “Practical haptic navigation with clickable 3-D region input interface for supporting masterslave type robotic surgery,” Stud. Health Technol. Informat., vol. 98,
pp. 265–271, 2004.
[20] W. McMahan, J. Gewirtz, D. Standish, P. Martin, J. A. Kunkel, M. Lilavois,
A. Wedmid, D. I. Lee, and K. J. Kuchenbecker, “Tool contact acceleration
feedback for telerobotic surgery,” IEEE Trans. Haptics, vol. 4, no. 3,
pp. 210–220, May/Jun. 2011.
[21] M. Franken, S. Stramigioli, S. Misra, C. Secchi, and A. Macchelli, “Bilateral telemanipulation with time delays: A two-layer approach combining
passivity and transparency,” IEEE Trans. Robot., vol. 27, no. 4, pp. 741–
756, Aug. 2011.
[22] A. J. van der Schaft, L2-Gain and Passivity Techniques in Nonlinear Control. New York, NY, USA: Springer-Verlag, 2000.
[23] J. Ryu, D. Kwon, and B. Hannaford, “Stable teleoperation with timedomain passivity control,” IEEE Trans. Robot. Autom., vol. 20, no. 2,
pp. 365–373, Apr. 2004.
[24] J. P. Kim and J. Ryu, “Robustly stable haptic interaction control using an
energy-bounding algorithm,” Int. J. Robot. Res., vol. 29, no. 6, pp. 666–
679, 2010.
[25] D. Lee and K. Huang, “Passive-set-position-modulation framework for
interactive robotic systems,” IEEE Trans. Robot., vol. 26, no. 2, pp. 354–
369, Apr. 2010.
[26] C. Pacchierotti, A. Tirmizi, G. Bianchini, and D. Prattichizzo, “Improving
transparency in passive teleoperation by combining cutaneous and kinesthetic force feedback,” in Proc. IEEE/RSJ Int. Symp. Intell. Robots Syst.,
2013, pp. 4958–4963.
[27] D. Prattichizzo, F. Chinello, C. Pacchierotti, and M. Malvezzi, “Towards
wearability in fingertip haptics: A 3-DOF wearable device for cutaneous
force feedback,” IEEE Trans. Haptics, vol. 6, no. 4, pp. 506–516, Oct.–
Dec. 2013.
[28] C. Pacchierotti, A. Tirmizi, and D. Prattichizzo, “Improving transparency
in teleoperation by means of cutaneous tactile force feedback,” ACM
Trans. Appl. Perception, 2014, in press.
[29] R. E. Schoonmaker and C. G. L. Cao, “Vibrotactile force feedback system
for minimally invasive surgical procedures,” in Proc. IEEE Int. Conf. Syst.,
Man, Cybern., 2006, vol. 3, pp. 2464–2469.
[30] M. Kitagawa, D. Dokko, A. M. Okamura, and D. D. Yuh, “Effect of
sensory substitution on suture-manipulation forces for robotic surgical systems,” J. Thor. Cardiovasc. Surg., vol. 129, no. 1, pp. 151–158,
2005.
[31] I. Birznieks, P. Jenmalm, A. W. Goodwin, and R. S. Johansson, “Encoding
of direction of fingertip forces by human tactile afferents,” J. Neurosci.,
vol. 21, no. 20, pp. 8222–8237, 2001.
[32] V. Hayward, O. R. Astley, M. Cruz-Hernandez, D. Grant, and G. RoblesDe-La-Torre, “Haptic interfaces and devices,” Sens. Rev., vol. 24, no. 1,
pp. 16–29, 2004.
[33] K. O. Johnson, “The roles and functions of cutaneous mechanoreceptors,”
Curr. Opin. Neurobiol., vol. 11, no. 4, pp. 455–461, 2001.
[34] B. B. Edin and N. Johansson, “Skin strain patterns provide kinaesthetic
information to the human central nervous system,” J. Physiol., vol. 487,
no. 1, pp. 243–251, 1995.
[35] C. B. Zilles and J. K. Salisbury, “A constraint-based god-object method
for haptic display,” in Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., 1995,
vol. 3, pp. 146–151.
[36] M. de Pascale and D. Prattichizzo, “The Haptik Library: A component
based architecture for uniform access to haptic devices,” IEEE Robot.
Autom. Mag., vol. 14, no. 4, pp. 64–75, Dec. 2007.
[37] K. H. Park, B. H. Kim, and S. Hirai, “Development of a soft-fingertip and
its modeling based on force distribution,” in Proc. IEEE Int. Conf. Robot.
Autom., 2003, vol. 3, pp. 3169–3174.

MELI et al.: SENSORY SUBTRACTION IN ROBOT-ASSISTED SURGERY

[38] D. R. Finley. (2006). HSP Color Model—Alternative to HSV
(HSB) and HSL. [Online]. Available: http://web.archive.org/web/
20130629041836/http://alienryderflex.com/hsp.html
[39] D. Prattichizzo and J. Trinkle, “Chapter 28 on grasping,” in Handbook
on Robotics, B. Siciliano and O. Kathib, Eds. New York, NY, USA:
Springer-Verlag, 2008, pp. 671–700.
[40] S. Wallenstein, C. L. Zucker, and J. L. Fleiss, “Some statistical methods
useful in circulation research.,” Circulat. Res., vol. 47, no. 1, pp. 1–9,
1980.
[41] D. A. Lawrence, “Stability and transparency in bilateral teleoperation,”
IEEE Trans. Robot. Autom., vol. 9, no. 5, pp. 624–637, Oct. 1993.
[42] C. Chen, N. Rathore, W. Ji, and A. Germansderfer, “Statistical equivalence
testing for assessing bench-scale cleanability,” BioPharm Int., vol. 23,
no. 2, 2010.
[43] G. B. Limentani, M. C. Ringo, F. Ye, M. L. Bergquist, and E. O. McSorley,
“Beyond the t-test: Statistical equivalence testing,” Anal. Chem., vol. 77,
no. 11, pp. 221–226, 2005.
[44] C. Pacchierotti, F. Chinello, and D. Prattichizzo, “Cutaneous device for
teleoperated needle insertion,” in Proc. IEEE Int. Conf. Biomed. Robot.
Biomechatron. Surg. Robot. Symp., 2012, pp. 32–37.

Leonardo Meli (S’14) received the M.S. degree (cum
laude) in computer engineering from the University
of Siena, Siena, Italy, in 2012. He was an exchange
student at the Karlstad University, Karlstad, Sweden
in 2010. He is currently working toward the Ph.D.
degree at the Department of Information Engineering and Mathematics, University of Siena and at the
Department of Advanced Robotics, Italian Institute
of Technology, Genoa, Italy.
His research interests include robotics and haptics focusing on cutaneous force feedback techniques,
teleoperation systems for medical applications and grasping.

1327

Claudio Pacchierotti (S’12) received the M.S. degree (cum laude) in computer engineering in 2011
from the University of Siena, Siena, Italy. He was an
exchange student at the Karlstad University, Sweden,
in 2010. He is currently working toward the Ph.D.
degree at the Department of Information Engineering and Mathematics, University of Siena and at the
Department of Advanced Robotics, Italian Institute
of Technology, Genova, Italy.
His research interests include robotics and haptics,
focusing on cutaneous force feedback techniques in
teleoperation, wearable devices, and haptics for robot-assisted surgery.

Domenico Prattichizzo (S’93–M’95) received the
M.S. degree in electronics engineering and the Ph.D.
degree in robotics and automation from the University of Pisa, Pisa, Italy, in 1991 and 1995, respectively.
Since 2002, he has been an Associate Professor
of Robotics at the University of Siena, Siena, Italy.
Since 2009, he has been a Scientific Consultant at
Istituto Italiano di Tecnologia, Genova, Italy. In 1994,
he was a Visiting Scientist at the MIT AI Lab. He is
the coauthor of the Grasping chapter of Handbook of
Robotics (Springer, 2008), awarded with two PROSE
Awards presented by the American Association of Publishers. His research interests include haptics, grasping, visual servoing, mobile robotics, and geometric
control. He is the author of more than 200 papers in these fields.
Since 2007, he has been an Associate Editor and Chief of the IEEE TRANSACTIONS ON HAPTICS. From 2003 to 2007, he was an Associate Editor of the IEEE
TRANSACTIONS ON ROBOTICS and IEEE TRANSACTIONS ON CONTROL SYSTEMS
TECHNOLOGIES. He was the Vice-chair for Special Issues of the IEEE Technical
Committee on Haptics from 2006 to 2010. He was the Chair of the Italian Chapter of the IEEE RAS from 2006 to 2010, awarded with the IEEE 2009 Chapter
of the Year Award. He was the coeditor of two books by STAR, Springer Tracks
in Advanced Robotics, (Springer, 2003, 2005). He is the Coordinator of the
European project “WEARHAP—WEARable HAPtics for humans and robots.”

