2768

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 11, NOVEMBER 2014

Three-Dimensional Spatiotemporal Features for Fast
Content-Based Retrieval of Focal Liver Lesions
Sharmili Roy∗ , Yanling Chi, Jimin Liu, Sudhakar K. Venkatesh, and Michael S. Brown

Abstract—Content-based image retrieval systems for 3-D medical datasets still largely rely on 2-D image-based features extracted
from a few representative slices of the image stack. Most 2-D features that are currently used in the literature not only model a
3-D tumor incompletely but are also highly expensive in terms of
computation time, especially for high-resolution datasets.
Radiologist-specified semantic labels are sometimes used along
with image-based 2-D features to improve the retrieval performance. Since radiological labels show large interuser variability,
are often unstructured, and require user interaction, their use as lesion characterizing features is highly subjective, tedious, and slow.
In this paper, we propose a 3-D image-based spatiotemporal feature
extraction framework for fast content-based retrieval of focal liver
lesions. All the features are computer generated and are extracted
from four-phase abdominal CT images. Retrieval performance and
query processing times for the proposed framework is evaluated
on a database of 44 hepatic lesions comprising of five pathological
types. Bull’s eye percentage score above 85% is achieved for three
out of the five lesion pathologies and for 98% of query lesions, at
least one same type of lesion is ranked among the top two retrieved
results. Experiments show that the proposed system’s query processing is more than 20 times faster than other already published
systems that use 2-D features. With fast computation time and high
retrieval accuracy, the proposed system has the potential to be used
as an assistant to radiologists for routine hepatic tumor diagnosis.
Index Terms—Clinical decision support system, contentbased image retrieval, 3-D spatiotemporal focal liver lesion
representation.

I. INTRODUCTION
OCAL lesion in the liver refers to a region of different
echogenicity, attenuation or signal intensity compared to
surrounding liver parenchyma on ultrasound, computed tomography (CT) and magnetic resonance imaging, respectively, and
can be of different pathologies. Multiphase contrast-enhanced
CT is the primary imaging technique employed for the detection

F

Manuscript received December 23, 2013; revised May 22, 2014; accepted
May 27, 2014. Date of publication June 5, 2014; date of current version October
16, 2014. This work was supported by the Singapore Academic Research Fund
Tier 1 FRC Grant under Project R-252-000-497-112 and in part by the Agency
for Science, Technology, and Research under Grant JCO-1231BFG044. Asterisk
indicates corresponding author.
*S. Roy is with the Department of Computer Science, National University of
Singapore, Singapore 117417 (e-mail: sharmili@comp.nus.edu.sg).
Y. Chi and J. Liu are with the Singapore Bioimaging Consortium,
Agency for Science, Technology and Research, Singapore 138671 (e-mail:
chi_yanling@sbic.a-star.edu.sg; liujm@sbic.a-star.edu.sg).
S. K. Venkatesh is with the Department of Radiology, Mayo Clinic
College of Medicine, Rochester, MN 55905 USA (e-mail: venkatesh.
sudhakar@mayo.edu).
M. S. Brown is with the Department of Computer Science, National University
of Singapore, Singapore 117417 (e-mail: brown@comp.nus.edu.sg).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2014.2329057

and characterization of focal liver lesions (FLLs) [1]–[5]. The
ability to detect and accurately characterize FLLs by qualitative visual inspection comes with years of training and experience and hence is frequently dependent on who is performing
the diagnosis. Content-based image retrieval (CBIR) systems
are finding increasing use as diagnostic decision support systems. CBIR systems assist radiological diagnosis by searching
and retrieving from databases of medical exams and reports confirmed cases that have image features similar to the case under
investigation [6]–[8].
It has been clinically observed that FLLs exhibit different
visual characteristics at various time points after intravenous
contrast injection. This evolution of visual features over time
carries important diagnostic information and greatly influences
FLL classification. Multiphase contrast-enhanced CT procedure
captures this transition by performing consecutive CT scans before and after injection of contrast. A noncontrast enhanced
(NC) phase scan is usually performed before contrast injection. The patient then receives intravenous contrast injection
and three or more scans are obtained in the arterial (ART) phase
(typically 25–40 s after start of injection), portal venous (PV)
phase (60–75 s) and delayed (DL) phase (3–5 min). Diffusion
of the contrast media over the different phases enhances the
vessels and the lesion tissues, thereby assisting in lesion type
determination.
Classification of liver lesions using image-based features is an
active research area. Some studies have reported texture-based
classification of lesions in nonenhanced CT and ultrasonography images using techniques like neural networks [9] and fuzzy
support vector machines [10]. Mougiakakou et al.[11] provide
a comprehensive performance comparison of various texturebased classifier architectures and conclude that a voting-based
combination of three primary classifiers gives best classification
results. Yu et al. in [12] developed a CBIR system to differentiate three types of hepatic lesions using global features derived
from nontensor product wavelet filter and local features based on
image density and texture. However, clinical experience shows
that nonenhanced CT captures limited diagnostic information.
The enhancement patterns observed during various phases of
contrast-enhanced images are fundamental for identifying specific focal lesions.
Some published studies have reported characterization of
FLLs using multiphase features. In [13], Yu et al. use spatially partitioned bag of visual words (BoW) and intensity,
texture, and shape-based features derived from a few representative triple-phase image slices to differentiate three lesion
types. The features are averaged over all phases which leads to
loss of temporal enhancement information. The mean average

0018-9294 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

ROY et al.: THREE-DIMENSIONAL SPATIOTEMPORAL FEATURES FOR FAST CONTENT-BASED RETRIEVAL OF FOCAL LIVER LESIONS

precision of the retrieval system is reported to be 88%. In another
study by the same group, the BoW-based method is improved to
obtain a precision of above 90% using a different set of lesions
[14]. A CBIR framework is proposed in [15] to characterize six
types of hepatic tumors using multiphase density and texture
features. The texture features are averaged over a bounding box
around the tumor and tracked over multiple phases. A “Bull’s
Eye Percentage” (BEP) score of 78% is achieved. We provide
a more detailed comparison of our method with [13]–[15] in
Section IV-A.
In [16], Costa et al. use semantic features annotated by radiologists and image features derived from three orthogonal
2-D planes of a single phase CT image to train a random forest classifier that distinguishes benign from malignant tumors
in a retrieval framework. The framework is used to characterize subcentimeter liver lesions. Subcentimeter lesions are often
found indistinguishable in clinical practice and hence are left
unclassified though closely monitored. Further, Costa et al. in
[16] neglect tumor temporal characteristics while designing their
features. Napel et al. in [17] use high level radiological semantic
features and single phase texture and boundary features to characterize three lesion types. Semantic features are unstructured
subjective descriptions made by radiologists and are known to
exhibit large interuser variation [18], [19]. Hence, utilization of
semantic features in image retrieval may be closely tied to the
clinical setup for which the system is designed.
The CBIR systems discussed thus far represent FLLs using
2-D features derived from a few representative slices of the
entire exam stack. Physiologically, however, FLLs are 3-D volumes. Hence, 2-D features derived from a few slices are clearly
an incomplete tumor representation. Further, 2-D features may
not be representative of the whole lesion, especially in cases of
large and heterogenous lesions. Medical image retrieval systems
based on 3-D features have not been reported extensively in the
literature. This is mainly due to the high computation time for
3-D features, especially when retrieving high resolution
datasets. In [15], Chi et al. represent 3-D liver lesions by averaging 2-D texture features extracted from all the slices where
the lesion is visible. Slice-by-slice 2-D features only capture
structures from the surface. Thus, spatial structural information
interlaced within the volume is lost. Linear binary pattern (LBP)
extracted from three orthogonal 2-D planes have been used to
approximate 3-D features for fast retrieval of brain lesions in
[20]. Again, by modeling the lesions using only three image
slices significant part of the lesion volume is neglected. In [21],
Burner et al. use 3-D LBP-based texture bags to retrieve lung
lesions. Feature computation time, however, is not reported.
In this paper, we propose a fast content-based retrieval framework for FLLs based on 3-D spatiotemporal features derived
from four-phase CT scans. All the features are computer generated and no radiological labels are used. The proposed retrieval
framework identifies FLLs automatically and aligns the lesions
in the four phases using an automated registration pipeline. Regional image-based features are computed from spatially partitioned lesion volumes and tracked over the four phases using
feature temporal derivatives. Feature similarity is then used to

2769

retrieve similar lesions from a database of confirmed cases. To
the best of our knowledge, this is the first study to use 3-D spatiotemporal features extracted from multiphase CT images in a
CBIR framework for FLLs. The rest of the paper is organized
as follows: In Section II, we describe the evaluation database
and the methods used for lesion identification, multiphase image alignment, and 3-D feature extraction Section III. illustrates
the results and Section IV provides a comparative discussion of
the proposed framework with existing FLL CBIR systems. We
conclude this paper in Section V.
II. MATERIALS AND METHOD
A. Materials
Institutional review board approval was obtained for retrospective analysis of four-phase contrast-enhanced CT images
of 30 deidentified patients. CT scans were acquired using a
64-detector SOMATOM sensation scanner (Siemens Medical
Solutions, Forchheim, Germany) via a standard four-phase
contrast-enhanced imaging protocol with a slice collimation of
0.6 mm, a matrix of 512 × 512 pixels, and an in-plane resolution of 0.59–0.78 mm. The raw data were reconstructed at
an isotropic resolution of 0.6 × 0.6 × 0.6 mm3 . The evaluation
database was constructed using 44 confirmed lesions identified
in the 30 patients. The 44 lesions consisted of five types, namely,
cyst, hemangioma (HEM), focal nodular hyperplasia (FNH),
metastatis (METS), and hepatocellular carcinoma (HCC). There
were 14 cases of cyst, ten cases of HEM, five cases of FNH,
11 cases of METS, and four cases of HCC in the 44 confirmed
lesions. One representative lesion was identified in each patient
for analysis. The pathology type of the lesions were confirmed
based on clinical features, CT scans, data from other imaging
modalities and biopsy, wherever needed.
B. Method
The proposed retrieval framework automatically detects candidate FLLs in the CT image [22]. The FLL of interest is then
identified in all the four phases using a B-spline-based registration [23]. The FLL is quantitatively represented using 3-D spatiotemporal features extracted from various regions within the
FLL volume of interest (VOI). An FLL database is constructed
using the resulting feature vectors and the corresponding clinical diagnosis. A L2-norm similarity measure between feature
vectors of the query lesion and lesions in the database is used for
retrieval. The retrieved results are ranked on the basis of similarity score and presented as evidential support to the radiologists.
Fig. 1 shows a flowchart of the proposed retrieval framework.
1) Focal Liver Lesion Identification: We use a hybrid
generative-discriminative method proposed in [22] to detect
FLLs in a 3-D image. The method first uses a generative model
to represent nonlesion components such as the healthy liver
parenchyma and the enhanced liver vasculature. The candidate
FLLs are then identified within the liver volume by eliminating
these nonlesion areas. False positives among the identified candidate FLLs are then suppressed using a discriminative approach

2770

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 11, NOVEMBER 2014

Fig. 3. Central calcification inside a HEM. To capture the spatial tissue characteristics, we divide the lesion into three partitions.
Fig. 1.

Flowchart of the proposed system.

Fig. 2. Visual appearance of various lesions over the four phases. Images in a
row are from the same lesion; cyst, HEM, FNH, METS, and HCC, respectively,
and images in a column belong to the same contrast phase.

that uses a lesion-likelihood measure comprising of three shapebased features, namely, spherical symmetry, compactness, and
size. All the detected FLLs are presented to an expert who then
selects one for further processing.
2) Four-Phase Lesion Alignment: FLLs usually do not appear visually distinguishable in all the phases. A FLL is typically
detected in the phase in which it shows the highest contrast with
respect to the liver parenchyma and is localized in the other
phases using a nonlinear B-spline registration [23].
3) Three-Dimensional Spatiotemporal Feature Design and
Extraction: Fig. 2 shows evolution of various lesions over different contrast phases. Liver cysts are benign fluid-filled lesions
that typically appear as round or oval smooth-edged regions
with uniformly low density. Cysts do not show much enhancement after intravenous contrast injection. HEMs exhibit discontinuous nodular peripheral enhancement in the ART phase
with centripetal enhancement over time. Central fibrosis and

calcification may sometimes be observed due to thrombosis in
the vascular channels that makes classification of HEMs challenging. FNH, without any contrast, is usually hypo- or isodense
to the liver parenchyma. FNH demonstrates bright ART contrast
enhancement except for the central scar; pronounced central arteries may be visible. In the PV phase, FNH becomes isodense to
liver. HEMs and FNHs show similar peripheral enhancement in
the ART phase. Also, presence of central abnormalities sometimes make PV washout of HEM and FNH visually similar.
METS, on the other hand, is a malignant tumor that usually
spreads from other cancer affected organs. METS enhance homogeneously, however, they tend to have less well-defined margins than cysts. METS have a band like peripheral enhancement
in ART phase and a washout in DL phase. HCC typically shows
ART phase hyper enhancement and washout in either PV or DL
phases.
Clinicians primarily use visual patterns generated by contrast
intrusion over time to identify FLLs. Spatial visual characteristics such as ring enhancement, nodule-within-a-nodule enhancement, pseudocapsule, central true and pseudo-scars, peripheral
washout are fundamental to identifying specific focal lesions
[24]. However, accurate FLL classification comes with years of
clinical experience. Our goal is to design spatiotemporal image
features that perform an objective modeling of the tumors and
computationally assist in this classification process. We divide
the tumor VOI into three volumetric partitions and extract features from these partitions over the four phases. An example of
volumetric partitioning is shown in Fig. 3. The innermost partition, Pt1 , captures central enhancement characteristics caused
by structures such as the central scar, fibrosis, calcification,
necrosis, if any. The intermediate partition, Pt2 , models the tumor tissue characteristics and the outermost partition, Pt3 is
designed to represent features and the enhancement pattern of
the tumor boundary.
We use a standard distance transformation technique based
on Euclidean distance to partition the tumor VOI [25]. Distance transformation converts a binary volume into a gray scale
volume. The binary volume in our case is the tumor VOI
where voxels inside the tumor form the foreground and the
rest comprise the background. The tumor is assumed to be segmented either manually or using existing tumor segmentation

ROY et al.: THREE-DIMENSIONAL SPATIOTEMPORAL FEATURES FOR FAST CONTENT-BASED RETRIEVAL OF FOCAL LIVER LESIONS

methods [26], [27]. Distance transformation of this binary volume results in a gray scale volume where each voxel of the
gray scale volume represents the distance of that voxel from the
closest background voxel in the binary volume. Voxels in the
gray scale volume are then grouped into three partitions based
on these distance values.
An additional benefit of tumor partitioning is the computational speedup. Image features from each partition can now be
computed in parallel. In effect, the tumor is now partitioned
into three subvolumes and the computation time is governed
by the largest of these subvolumes instead of the entire tumor.
In Section III, we discuss, in detail, the speedup and enhancement in retrieval performance achieved by tumor partitioning.
Large computation time is the primary deterrent to using 3-D
feature-based retrieval systems in clinical practice. In order to
accelerate processing time, instead of extracting features from
all voxels within the tumor partitions, we perform a uniform
subsampling of the voxels and use only the selected samples for
feature computation. In Section III-C, a detailed analysis of how
the processing time and retrieval performance vary with various
amounts of subsampling is provided.
Postpartitioning various features such as those based on
shape, user-supplied semantics, texture, and intensity can be
extracted from the partitions to model the tumor. Shape features are good at distinguishing benign from malignant tumors
since benign tumors are well encapsulated as opposed to the
malignant ones that often have irregular and visually indistinct
boundary. However, shape features have insufficient power to
differentiate among benign lesions, or among malignant lesions
[15]. Further, since FLLs are most distinctively visible only in
one of the phases, temporal change in FLL shape cannot be
extracted accurately. In this paper, our focus is on features that
exhibit spatial and temporal evolution; hence, we do not employ
shape features. User-supplied semantic labels are subjective and
often unstructured description of the tumor characteristics with
high interuser variability. Hence, we do not want to use semantic features. Image texture is widely used in the literature to
model tumor tissues. Methods that model texture are broadly
categorized into statistical and structural approaches. Statistical
approaches such as histogram of pixel gray levels and graylevel cooccurrence have been found to work best with images
whose microtexture can be modeled with a stochastic formulation. Structural approaches such as textons, wavelet transforms,
and Gabor filters, on the other hand, compute weighted mean of
pixel neighborhoods, and hence, eliminate finer textural details
[20], [28]. Published literature reports that gray-level density
and cooccurrence-based texture features are particularly important to encode local features of hepatic tumors [10], [12], [15],
and are most widely used for liver CT image retrieval. Hence,
we derive these features from the volumetric partitions and track
their temporal evolution over the four phases. We define four
3-D feature vectors to model a tumor as follows.
4) Density Feature: The density feature, F1 , represents the
ratio of average pixel intensity inside the partitions to the average pixel intensity of liver parenchyma. F1 measures lesion
enhancement with respect to the surrounding liver tissues and is

2771

defined as
F1 = {DNC , DART , DPV , DDL }

(1)

NC
NC
NC
NC
NC
NC
where DNC = {dNC
Pt 1 /dliver , dPt 2 /dliver , dPt 3 /dliver }. dPt i is
the average pixel intensity inside Pti in the NC phase and dNC
liver
is the average pixel intensity of the healthy liver tissue in the NC
phase. DART , DPV , and DDL are defined in a similar fashion.
The resulting density features obtained from all phases are arranged in a 12-D density feature vector. The density feature aims
to capture contrast enhancement and washout. For example, if a
lesion has |DART | > |DNC | and |DPV | < |DNC |, then the lesion is enhanced in the ART phase due to contrast propagation
and has a washout in the PV phase.
5) Temporal Density Feature: The temporal density feature,
F2 , measures temporal enhancement of the lesion in ART, PV,
and DL phases with respect to the NC phase. It is defined as

F2 = {T DART/NC , T DPV /NC , T DDL/NC }
(2)


ART/NC
ART/NC
ART/NC
where T DART/NC = tdPt 1
and
, tdPt 2
, tdPt 3
for i = 1, 2, 3
ART/NC

=

NC
dART
Pt i − dPt i
dNC
Pt i

(3)

PV /NC

=

NC
dPV
Pt i − dPt i
dNC
Pt i

(4)

DL/NC

=

NC
dDL
Pt i − dPt i
.
NC
dPt i

(5)

tdPt i

tdPt i

tdPt i

Similar definitions follow for T DPV /NC and T DDL/NC . Temporal density features from ART, PV, and DL phases are encoded
into a nine-dimensional feature vector that models the temporal
enhancement of the tumor.
6) Texture Feature: We use a 3-D gray-level cooccurrence
matrix (GLCM) to quantify the gray tone distribution in the
tumor subvolumes. GLCM is an estimation of the joint probability distribution of a pair of gray-level voxels. An element
G(θ ,d) (i, j) of the GLCM matrix is the probability of the occurrence of gray levels i and j at distance of d from each other
along the direction θ. The variables i and j can vary from one
to N, where N is the number of gray levels in the volume. In
3-D, θ can take 26 values resulting from linking a voxel to each
of its 26 nearest neighbors. Since directions that are 180◦ apart
result in the same cooccurrence matrix, we only consider 13
unique directions. Given an offset d, we compute GLCM over
all 13 directions and use the average to make the texture rotation invariant. Offset d is experimentally chosen as described in
Section III-A.
Six texture coefficients, namely, energy, entropy, inverse difference moment, inertia, cluster shade, and correlation as defined in [29], are derived from the rotation invariant GLCM.
The texture feature, F3 , is composed as follows:
F3 = {T ART , T PV , T DL }

(6)

2772

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 11, NOVEMBER 2014

TABLE I
TEXTURE COEFFICIENTS DERIVED FROM THE GLCM MATRIX
Texture
Coefficient

ttDL
kP ti

Expression and Qualitative Analysis

Entropy

Inverse
Difference
Moment
Inertia
Cluster
Shade

Correlation

Inverse difference moment measures the
local homogeneity in the image.
 N −1  N −1
2
t4 =
i= 0
j = 0 (i − j ) g (i, j )
Inertia gauges local variations in an image.
 N −1  N −1
t5 =
+ j − μ i − μ j ) 3 g (i, j )
i = 0  j = 0 (i
N −1
−1
where, μ i =
i N
i
=
0
j = 0 g (i, j ),
 N −1  N −1
and μ j =
j
i= 0
j = 0 g (i, j ).
Cluster shade quantifies perceptual
uniformity and proximity.
 N −1  N −1 ( i −μ i ) ( j −μ j ) g ( i , j )
t6 =
i= 0
j=0
σiσj
 N −1
 N −1
2
where, σ i =
i = 0 (i − μ i )
j = 0 g (i, j ),
 N −1
N −1
2
and σ j =
j = 0 (j − μ j )
i = 0 g (i, j ).
Correlation assesses the linearity of
relationship between various gray-level
pixel pairs.

The term g (i, j ) represents the joint probability density of the
gray-level pair (i, j ).

ART
ART
ART
where T ART = {TPt
, TPt
, TPt
} represents the texture
1
2
3
features derived from the three partitions in the ART phase.
ART
ART
ART
= {tART
TPt
1 P t i , . . . , t6 P t i } where tk P t i ’s, k = {1, . . . , 6}, are
i
computed as defined in Table I from the GLCM of Pti in the
ART phase. Similar definition applies for T PV and T DL . The
resulting texture coefficients from nine partitions in ART, PV,
and DL phases are arranged into a 54-D feature vector which
encodes the tumor texture.
7) Temporal Texture Feature: Temporal texture, F4 , is defined as the normalized difference in texture at the three enhancement phases. F4 is formulated as

F4 = {T T ART , T T PV , T T DL }

(7)

ART
ART
ART
where T T ART = {T TPt
, T TPt
, T TPt
} is the temporal
1
2
3
texture in the ART phase formulated as derivative of the six texART
=
ture coefficients in each partition in the ART phase; T TPt
i
ART
ART
{tt1 P t , . . . , tt6 P t }, i = {1, 2, 3}. Derivative of each texture
i
i
coefficient is defined as

ttART
kP t =
i

tART
kP t −

median

tPk P t

i
P∈{ART,PV ,DL}
P
max
tk −
min
tPk
P∈{ART,PV ,DL} P t i
P∈{ART,PV ,DL} P t i
i

(8)

for k = 1, . . . , 6. Texture derivative in PV and DL phases, T T PV
and T T DL , respectively, are formulated analogously with the
individual texture coefficient derivatives defined as
ttPV
kP t =
i

tPV
kP t −

median

tPk P t

i
P∈{ART,PV ,DL}
P
max
tk −
min
tPk
P∈{ART,PV ,DL} P t i
P∈{ART,PV ,DL} P t i
i

=

i

. (10)

Texture derivatives computed for the three enhanced phases
are organized into a 54-D temporal texture feature vector that
represents the textural evolution of the tumor. The four feature
vectors F1 , F2 , F3 , and F4 form the FLL model.
Since we use GLCM-based texture features in this paper, it
turns out that we can further improve tumor processing speed
by reducing the number of gray levels used while populating
the GLCM matrix. An element (i, j) of the GLCM matrix measures the probability of cooccurrence of gray-level pairs i and j.
Computing 3-D GLCM in 13 directions using the original CT
values is highly expensive, both computationally and in terms of
memory requirement. We quantize down the original CT values
to fewer distinct gray levels in order to reduce the size and computation time of the GLCM. Optimum number of gray levels
can be determined experimentally. Section III-C provides analysis of gain in computation time versus retrieval performance
for various gray-level counts.
8) Similarity Assessment and Evidence Rendering: Similarity between a query FLL and the model FLLs in the database
can be measured using an L2 distance between the respective
feature vectors. Distance between two lesions FLL1 and FLL2
in L2 is defined as

 N −1  N −1
2
t1 =
i= 0
j = 0 g (i, j )
Energy quantifies the repetition of gray-level
pairs in an image.
 N −1  N −1
t2 =
i= 0
j = 0 g (i, j )log 2 (g (i, j ))
Entropy represents the randomness
in the image.
 N −1  N −1
1
t3 =
i= 0
j = 0 1 + ( i −j ) 2 g (i, j )

Energy

median
tPk
P∈{ART,PV ,DL} P t i
max
tPk −
min
tPk
P∈{ART,PV ,DL} P t i
P∈{ART,PV ,DL} P t i
tDL
kP t −

(9)

DL 2 (FLL1 , FLL2 ) =

4


i
i
wi ||FFLL
− FFLL
|| 2 .
1
2 L

(11)

i=1
i
The term FFLL
represents the ith feature vector of FLL1 , where
1
i iterates over density, temporal density, texture and temporal
texture feature vectors, and wi is the respective weight. Weight
selection is elaborated in Section III-A.
Model FLLs in the database are sorted in increasing order
of their distance to the query FLL and the closest matching
FLLs are rendered to the radiologist. It is possible to predict the
pathological type of the query FLL using BEP. BEP is defined
for each query as the percentage of correct retrievals with respect
to the query FLL’s class within the top 2C results where C is the
size of the query FLL’s class [30]. The query FLL is predicted
to belong to the class that has the highest BEP score as follows:

Query ⊆ Ci
if BEP(Ci ) =

max (BEP(Ck ))

k =1,2,...,5

(12)

where Ck represents the kth class of FLL pathology in the
database. The term BEP(Ci ) represents the BEP score when
query FLL is assumed to belong to class Ci . The distance of the
query FLL to a class Ck can be computed using average distance
to model FLLs belonging to class Ck retrieved within the top
2|Ck | results as formulated below:
N Ck
1 
DL 2 (FLLQuery , FLLi )
Distance (Ck ) =
NCk i=1

(13)

where NCk is the number of FLLs belonging to class Ck retrieved
in the top 2|Ck | results.

ROY et al.: THREE-DIMENSIONAL SPATIOTEMPORAL FEATURES FOR FAST CONTENT-BASED RETRIEVAL OF FOCAL LIVER LESIONS

Fig. 4. System BEP score for various values of offsets. The offset, d, is the
distance between gray-level pairs used for computing GLCM entries.

Although a CBIR system can predict the pathological type of
an unknown lesion, the primary contribution of a CBIR system
in the clinical routine is its capability of providing evidential
support in favor and also against its prediction. It is important
for radiologists to not only look at examples of similar lesions
from the same pathology type but also refer to visually similar
lesions belonging to a different class of pathology for a possible
differential diagnosis.
III. EXPERIMENTS AND RESULTS
The proposed CBIR framework is evaluated on a database
of 44 FLLs identified in 30 patients and comprising of five
pathological types. One representative FLL is chosen from each
patient for analysis. Precision–recall curve and BEP score are
used to evaluate the retrieval performance of the proposed framework. Precision is defined as the ratio of retrieved lesions that
belong to the query class with respect to the total number of
lesions retrieved1 and recall is defined as the ratio of number of
retrieved lesions that belong to the query class with respect to
all model lesions in the database that belong to the query class.
Leave-one-out cross validation scheme is used to compute the
precision–recall curves and the BEP scores.
A. Parameter Optimization
In this section, we describe selection of offset (distance between gray-level pairs while computing GLCM) and feature
weights (used for interlesion comparison), respectively.
Offset: We compare the retrieval performance at various values of offsets, d, by computing texture and temporal texture features from GLCM at d = 1, 2, . . . , 10, and measuring the corresponding system BEP scores (see Fig. 4). Higher offsets produce
better results, albeit, using a smaller subset of the dataset. Large
offsets cannot be used to model small tumors. In our framework,
1 This definition of precision is used in the field of information retrieval and
is not equal to the one used in other areas of science and technology.

2773

Fig. 5. Variation in tumor volume (in cm3 ) for the five tumor classes in the
database.

we first partition a tumor into three subvolumes and then extract
the GLCM matrix from each individual subvolume. If the offset value is too large, then GLCM for the subvolumes of small
tumors remains very sparsely populated or empty. Hence, with
high offset, it is not possible to model small tumors. The results
reported with higher offsets include only the big tumors which
could be a reason for better system performance. In Fig. 5, we
plot tumor size distribution for the five classes of lesions in our
database. From the experiments, we observe that a maximum
offset of four is able to model all the tumors in our database,
and hence, for subsequent analysis, we set d = 4.
Feature Weights: Similarity between the two lesions is assessed using a weighted L2 difference between the respective
feature vectors [see (11)]. To compute the optimum weights,
we conduct a brute-force search where the objective is to maximize the system BEP score under an increment/decrement of the
weights in steps of 0.05 while keeping their sum equal to one.
It is found that a weight vector of [0.3 0.3 0.2 0.2] generates the best results. Fig. 6 compares precision–recall curves for
various weights including the optimal and equal weight vectors.
B. Tumor Partitioning
As mentioned in Section II-B, we divide the tumor into partitions and extract features from each partition to capture the spatiotemporal characteristics of the tumor. Fig. 7 shows the gain
in retrieval performance obtained by dividing the tumor into
three partitions against the case when tumors are represented by
features extracted from the whole VOI. Retrieval performance
postpartitioning is clearly superior to the nonpartitioned case.
C. Retrieval Performance and Processing Speed
Fig. 7 plots the retrieval performance of the proposed retrieval
framework in terms of precision and recall. The system’s precision remains above 0.85 till a recall of 0.6. The BEP score for the
five lesion pathologies is tabulated in Table II. The global mean

2774

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 11, NOVEMBER 2014

TABLE II
BEP FOR VARIOUS LESION CLASSES
Lesion Class
Cyst
HEM
FNH
METS
HCC

Fig. 6. Precision versus recall curves for different feature weight vectors.
Precision–recall curves for optimal and equal weight vectors are observed to be
close.

Fig. 7. Precision–recall curves when the lesions in the database are volumetrically partitioned into three subvolumes versus when they are not. The retrieval
performance obtained by nonpartitioned lesions is found to be inferior to that
obtained by partitioned lesion representation.

score of 82.6% demonstrates good discriminatory properties of
the 3-D spatiotemporal features. A more detailed examination
of the results shows excellent BEP scores, between 87% and
100%, for cyst, METS, and HCC. This can be contributed to the
markedly different temporal enhancement of these three lesion
types. The low number of HCCs in our database may have led to
a perfect BEP score for HCC. For a more thorough evaluation,
we would like to test the performance with a wider example set
of HCC. HEM and FNH, however, report lower BEP scores.
Pt3 , which captures the peripheral enhancement, tends to show
similar enhancement in ART phase for both HEM and FNH.
Further, Pt1 shows similar temporal washout in the DL phase
for both HEM and FNH due to the occasional presence of a
central scar in FNH. This may explain why lower scores are

BEP Score
0.87
0.62
0.70
0.94
1.00

obtained for HEM and FNH. FNH is difficult to detect and it is
well known clinically that they are called “stealth lesions” if the
ART phase enhancement is not well demonstrated.
Fig. 8 shows the top retrieval results for five query lesions, one
from each of the five lesion classes. For 98% of query lesions,
at least one lesion of the same pathological type as the query
lesion is rendered in the top two retrieval results.
Low query processing time is critical for the clinical feasibility of a retrieval system. Various characteristics of our feature extraction framework contribute toward accelerating query
processing time. Tumor partitioning is the first contributor. By
partitioning the tumor, we process all subvolumes concurrently
in a multicore computing framework. The processing time is
now governed by the largest subvolume instead of the entire
tumor volume.
Further, we perform subsampling of the subvolumes instead
of using all voxels during feature computation. Fig. 9 shows
how the system BEP score and the total feature computation
time for all lesions in the database vary with varying amounts
of subsampling. The computation time is measured using
MATLAB R2011b without any GPU acceleration in an Intel
Xeon 2.4-GHz four core processor with 6 GB RAM. We observe that BEP score varies from 0.80 to 0.82 with additional
sampling; however, gain in speedup is substantial when lower
number of voxels are sampled. In this paper, we use 25% subsampling to compute features.
Use of GLCM for texture computation gives us another parameter to gain additional speedup, namely, the number of distinct gray levels used for GLCM computation. Larger the number of distinct gray levels, bigger is the GLCM matrix, and
hence, slower is the computation. We quantize down the original CT gray levels to a lower number of distinct values and
study its effect on the computation time and the retrieval accuracy. Fig. 10 plots the system BEP score versus number of gray
levels used for feature computation. Total time taken to compute 3-D features for all lesions in the database is also plotted
against the number of gray levels. As expected, higher number
of gray levels increases the computation time; however, the gain
in performance saturates after certain gray levels. In this paper,
we use 60 gray levels for feature extraction.
Table III compares the processing times for some FLLs with
and without net computation acceleration obtained by tumor
partitioning, volumetric subsampling, and gray-level quantization. On an average, the computation with acceleration is more
than 28 times faster than without acceleration.

ROY et al.: THREE-DIMENSIONAL SPATIOTEMPORAL FEATURES FOR FAST CONTENT-BASED RETRIEVAL OF FOCAL LIVER LESIONS

2775

Fig. 9. BEP scores and the processing times for various amounts of volumetric
subsampling.

Fig. 10. BEP scores and the processing times for various counts of distinct
gray levels.

Fig. 8. Top retrieval results for five query lesions, one from each of the five
lesion classes.

IV. DISCUSSION
A. System Comparison
In this paper, we propose a retrieval framework for FLL characterization using 3-D image-based spatiotemporal features. To
the best of our knowledge, no FLL CBIR system based on
3-D multiphase features have been reported in the literature.
The closest related works have studied lesion retrieval based
on 2-D features derived from representative slices of single or

TABLE III
PROCESSING TIMES FOR SOME FLLS WHEN TUMOR PARTITIONING,
VOLUMETRIC SUBSAMPLING, AND GRAY-LEVEL QUANTIZATION
ARE USED TO ACCELERATE FEATURE COMPUTATION VERSUS
WHEN NO ACCELERATION IS USED
FLL Size
(in cm3 )
69.6
133.6
184.1
286.4
328.1

Processing time with
acceleration (in min.)

Processing time without
without acceleration (in min.)

0.08
0.19
0.26
0.33
0.46

2.41
5.34
7.66
8.95
12.84

For acceleration, we use 25% subsampling and 60 gray levels.

2776

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 11, NOVEMBER 2014

multiphase CT images [13]–[17]. In the following paragraphs,
we compare the proposed system with these prior studies in
detail.
Yu et al. in [13] propose retrieval of three types of FLLs,
namely, cyst, HEM, and HCC using BoW and 2-D image-based
features. The lesions are spatially partitioned and BoW histograms are computed for each partition. The visual vocabulary
for BoW histogram is constructed using image patches of the
training lesions without normalization. Additionally, 93 imagebased global features are constructed from the unpartitioned
tumor region of interest based on intensity, GLCM, Gabor filter,
and tumor shape. The lesion is represented by averaging spatial
BoW and global image-based features across multiple phases. A
mean average retrieval precision of 88% is reported. In an extension to this study, Yang et al. in [14] eliminate lesion partitioning
and use distance metric learning methods to compute similarity
between global BoW histograms and report an average precision of above 90% when evaluated on a database of cyst, HEM,
and hepatomas. Processing time, however, is not reported. In
[13], lesion spatial-partitioning is used, though only to construct the BoW histograms. For other image-based features, no
spatial information is preserved. Furthermore, averaging BoW
and image features over multiple phases leads to loss of temporal information. In [14], both spatial and temporal information
is neglected for BoW and image features. Pathologically different lesions may appear visually similar in some phases. By
combining features from various phases, a good correspondence
between lesions in sequential phases is not guaranteed. Similar
sequential evolution of two lesions is essential for them to be
categorized to the same pathological type. Further, from experiments we observe that computing GLCM texture features over
the whole tumor without acceleration is slow. Research shows
that computing texture using Gabor filter is even slower than
GLCM [20]. We propose a much simpler modeling of tumors
using density and only six GLCM-based texture coefficients that
preserve both spatial and temporal characteristics of the tumor
and are also faster to compute as against the elaborate modeling of tumors proposed in [13] and [14] using 93 features and
BoW learning. When evaluated using cyst, HEM, and HCC, our
system achieves a higher mean average precision of 92.4%.
In [15], Chi et al. design an FLL retrieval framework using
GLCM-based 2-D temporal features derived from multiphase
CT images. The features are, however, derived by averaging
density and texture over a tumor bounding box. The system is
tested on a database of 69 FLLs comprising of six pathological
types. A BEP score of 78% is obtained. It is reported that for
90% query lesions, the processing time is more than 10 min.
Two-dimensional GLCM captures the joint probability distribution of gray-level pairs in only four directions, namely, 0◦ , 45◦ ,
90◦ , and 135◦ . However, a 3-D GLCM represents gray-level
distribution in 13 directions along the 13 neighbors of a voxel.
Averaging 2-D features over multiple slices does not accurately
approximate the 3-D texture. Further, by averaging features over
the whole bounding box, authors dismiss the spatial enhancement characteristics of the tumor. In this paper, we use 3-D
regionally partitioned temporal features and obtain a superior

precision–recall curve and a higher system BEP score than in
[15] with more than 20 times faster processing speed.
A CBIR system is proposed in [16] to differentiate cyst
from METS using radiological semantic labels and computergenerated features based on density histogram and its moments
obtained from three orthogonal 2-D cuts of a single-phase scan
volume. A random forest classifier is used to learn a discriminant
distance between various FLL attributes. The classification performance is measured using a receiver operating characteristic
curve. The framework proposed in [16] uses only global densitybased features derived from the lesion area and the whole liver
in a single contrast phase. Moments are well-known quantitative measures of the global shape of a set of points. FLL shapes,
however, are rarely used to differentiate different lesions in the
clinical routine. This may explain why inferior results are obtained using moments as the discriminating features of the FLLs.
In [17], the authors propose retrieval of cyst, METS, and HEM
using only a single image in the PV phase on a database of 30
images. Computer-generated image-based features and higher
level radiological semantic labels are used to represent an FLL.
Visual similarity between each pair of lesions is adjudged by
two senior radiologists based on texture, boundary shape, and
boundary sharpness. The similarity measure between two FLLs
is defined as 3/2/1 for very similar, somewhat similar, and not
similar pairs, respectively. The system is evaluated in terms of
precision and recall on how well the system retrieves visually
similar lesions in comparison to radiology experts. A mean precision greater than 90% is achieved. The retrieval framework
proposed in [17] is optimized and characterized for retrieving
visually similar lesions as perceived by expert radiologists as
opposed to retrieving lesions belonging to the same lesion class.
Retrieval performance in terms of FLL characterization is not reported which makes a formal performance comparison with our
system difficult. Further, only one slice in the PV phase, selected
manually, is used for feature computation. Higher level radiological annotations that are inherently known to be subjective
and widely user dependent are used to bridge the performance
gap.
B. System Performance
For most cases, the proposed CBIR system ranks lesions belonging to the same pathological type as the query lesion higher
than lesions from other pathological groups. However, in certain cases, lesions from a different lesion class may be ranked
higher as shown in Fig. 11. This is due to variation in visual
appearance among lesions belonging to the same pathological
group. In clinical practice, other higher level semantic information and clinical history are used to distinguish such cases.
In this paper, we do not use any semantic information. However, we try to model commonly used semantic descriptions
such as relative density of tumor region with respect to the liver
parenchyma and tumor edge characteristics using image-based
features. Nonetheless, in future we would like to explore other
features that are more efficient in distinguishing visually similar
lesions from different pathological classes.

ROY et al.: THREE-DIMENSIONAL SPATIOTEMPORAL FEATURES FOR FAST CONTENT-BASED RETRIEVAL OF FOCAL LIVER LESIONS

2777

ACKNOWLEDGMENT
The authors would like to thank Dr. T. Hennedige, Department of Diagnostic Imaging, National University Hospital,
Singapore, for her help in data collection.

REFERENCES

Fig. 11. Some cases where the top retrieved lesion does not belong to the
query lesion class.

C. Clinical Feasibility
By reducing query computation time, the proposed framework establishes the clinical feasibility of 3-D feature-based
CBIR systems. However, at present we do not have a graphical
user interface for easy use of the system by radiologists. Design
of a good user interface poses its own set of technical challenges.
These need to be addressed before clinical deployment of the
system is possible.

V. CONCLUSION
In this paper, we propose an FLL CBIR framework using
3-D spatiotemporal features derived from four-phase contrastenhanced CT images. Acceleration techniques are employed to
speed up the 3-D feature extraction process, known to be the
primary bottleneck in integration of 3-D feature-based retrieval
systems into the clinical routine. The proposed system is evaluated in terms of precision–recall and system BEP score on
a database of 44 lesions comprising of five pathological categories. The proposed system performs better and faster than
existing 2-D feature-based FLL CBIR systems.
In future study, we would like to conduct a clinical validation
of the proposed system and evaluate the system’s performance
on a larger database that includes more FLL pathologies. We
acknowledge that the database used in this paper, though at
par with some of the existing studies [15], [17], is small. A
systematic search on the intrinsic dimensionality of the database
will be a future addition to this study. CBIR systems are known
to improve radiological diagnostic accuracy [15]; however, high
processing times have rendered their integration into the clinical
routine impractical. By keeping the query processing time low
and including more pathological cases, we hope to be able to
integrate the proposed system as a diagnostic assistant into the
routine radiological practices.

[1] H. Ji, J. D. McTavish, K. J. Mortele, W. Wiesner, and P. R. Ros, “Hepatic
imaging with multidetector CT,” Radiographics, vol. 21, no. 1, pp. S71–
S80, 2001.
[2] R. Lencioni, D. Cioni, and C. Bartolozzi, Focal Liver Lesions: Detection,
Characterization, Ablation. New York, NY, USA: Springer-Verlag, 2005.
[3] I. R. Kamel, M. A. Choti, K. M. Horton, H. J. V. Braga, B. A. Birnbaum,
E. K. Fishman, R. E. Thompson, and D. A. Bluemke, “Surgically staged
focal liver lesions: Accuracy and reproducibility of dual-phase helical CT for detection and characterization,” Radiology, vol. 227, no. 3,
pp. 752–757, 2003.
[4] I. R. Francis, R. H. Cohan, N. J. McNulty, J. F. Platt, M. Korobkin,
A. Gebremariam, and K. Ragupathi, “Multidetector CT of the liver and
hepatic neoplasms: Effect of multiphasic imaging on tumor conspicuity
and vascular enhancement,” Am. J. Roentgenol., vol. 180, no. 5, pp. 1217–
1224, 2003.
[5] H. J. Kim, A. Y. Kim, T. K. Kim, J. H. Byun, H. J. Won, K. W. Kim,
Y. M. Shin, P. N. Kim, H. K. Ha, and M. G. Lee, “Transient hepatic
attenuation differences in focal hepatic lesions: Dynamic CT features,”
Am. J. Roentgenol., vol. 184, no. 1, pp. 83–90, 2005.
[6] H. Muller, N. Michoux, D. Bandon, and A. Geissbuhler, “A review of
content-based image retrieval systems in medical applications—Clinical
benefits and future directions,” Int. J. Med. Informat., vol. 73, no. 1,
pp. 1–23, 2004.
[7] C. B. Akgul, D. L. Rubin, S. Napel, C. F. Beaulieu, H. Greenspan, and
B. Acar, “Content-based image retrieval in radiology: Current status and
future directions,” J. Digit. Imag., vol. 274, no. 2, pp. 208–222, 2011.
[8] L. R. Long, S. Antani, R. M. Deserno, and G. R. Thoma, “Content-based
image retrieval in medicine: Retrospective assessment, state of the art,
and future directions,” Int. J. Healthcare Inf. Syst. Informat., vol. 4, no. 1,
pp. 1–16, 2009.
[9] M. Gletsos, S. G. Mougiakakou, G. K. Matsopoulos, K. S. Nikita, A. S.
Nikita, and D. Kelekis, “A computer-aided diagnostic system to characterize CT focal liver lesions: Design and optimization of a neural network
classifier,” IEEE Trans. Inf. Technol. Biomed., vol. 7, no. 3, pp. 153–162,
Sep. 2003.
[10] G.-M. Xian, “An identification method of malignant and benign liver
tumors from ultrasonography based on GLCM texture features and fuzzy
SVM,” Expert Sys. Appl., vol. 37, no. 10, pp. 6737–6741, 2010.
[11] S. G. Mougiakakou, I. K. Valavanis, A. Nikita, and K. S. Nikita, “Differential diagnosis of CT focal liver lesions using texture features, feature
selection and ensemble driven classifiers,” Artif. Intell. Med., vol. 41,
no. 1, pp. 25–37, 2007.
[12] M. Yu, Z. Lu, Q. Feng, and W. Chen, “Liver CT image retrieval based on
non-tensor product wavelet,” in Proc. Int. Conf. Med. Image Anal. Clin.
Appl., 2010, pp. 67–70.
[13] M. Yu, Q. Feng, W. Yang, Y. Gao, and W. Chen, “Extraction of lesionpartitioned features and retrieval of contrast-enhanced liver images,” Comput. Math. Methods Med., vol. 2012, art. 972037, 12 pp., 2012. DOI:
10.1155/2012/972037.
[14] W. Yang, Z. Lu, M. Yu, M. Huang, Q. Feng, and W. Chen, “Content-based
retrieval of focal liver lesions using bag-of-visual-words representations
of single- and multiphase contrast-enhanced CT images,” J. Digit. Imag.,
vol. 25, pp. 708–719, 2012.
[15] Y. Chi, J. Zhou, S. K. Venkatesh, Q. Tian, and J. Liu, “Content-based image
retrieval of multiphase CT images or focal liver lesion characterization,”
Med. Phys., vol. 40, no. 10, art. 103502, 2013.
[16] M. Costa, A. Tsymbal, M. Hammon, A. Cavallaro, M. Suhling,
S. Seifert, and D. Comaniciu, “A discriminative distance learning-based
CBIR framework for characterization of indeterminate liver lesions,” Med.
Content-Based Retrieval Clin. Decis. Supp., vol. LNCS-7075, pp. 92–104,
2012.
[17] S. A. Napel, C. F. Beaulieu, C. Rodriguez, J. Cui, J. Xu, D. Korenblum,
H. Greenspan, Y. Ma, and D. L. Rubin, “Automated retrieval of CT images
of liver lesions on the basis of image similarity: Method and preliminary
results,” Radiology, vol. 256, no. 1, pp. 243–252, 2010.

2778

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 11, NOVEMBER 2014

[18] J. L. Sobel, M. L. Pearson, K. Gross, K. A. Desmond, E. R. Harrison,
L. V. Rubenstein, W. H. Rogers, and K. L. Kahn, “Information content
and clarity of radiologists’ reports for chest radiography,” Acad. Radiol.,
vol. 3, no. 9, pp. 709–717, 1996.
[19] M. J. Stoutjesdijk, J. J. Futterer, C. Boetes, L. E. Van Die, G. Jager, and
J. O. Barentsz, “Variability in the description of morphologic and contrast enhancement characteristics of breast lesions on magnetic resonance
imaging,” Invest. Radiol., vol. 40, no. 6, pp. 355–362, 2005.
[20] Y. Qian, X. Gao, M. Loomes, R. Comley, B. Barn, R. Hui, and Z. Tian,
“Content-based retrieval of 3D medical images,” in Proc. 3rd Int. Conf.
eHealth, Telemed., Soc. Med., 2011, pp. 7–12.
[21] A. Burner, R. Donner, M. Mayerhoefer, M. Holzer, F. Kainberger, and
G. Langs, “Texture Bags: Anamoly retrieval in medical images based
on local 3D-texture similarity,” in Medical Content-Based Retrieval for
Clinical Decision Support. Berlin, Germany: Springer-Verlag, 2012, pp.
116–127.
[22] Y. Chi, J. Zhou, S. K. Venkatesh, S. Huang, Q. Tian, and J. Liu, “Computeraided focal liver lesion detection,” Int. J. Compt. Assist. Radiol. Surg., vol.
8, no. 4, pp. 511–525, 2013.
[23] P. A. Yushkevich, J. Piven, H. C. Hazlett, R. G. Smith, S. Ho, J. C. Gee,
and G. Gerig, “User-guided 3D active contour segmentation of anatomical
structures: Significantly improved efficiency and reliability,” Neuroimage,
vol. 31, no. 3, pp. 1116–1128, 2006.

[24] K. M. Elsayes, V. R. Narra, Y. Yin, G. Mukundan, M. Lammle, and
J. J. Brown, “Focal hepatic lesions: Diagnostic value of enhancement
pattern approach with contrast-enhanced 3D gradient-echo MR imaging,”
Radiographics, vol. 25, no. 5, pp. 1299–1320, 2005.
[25] A. Rosenfeld and J. L. Pfaltz, “Sequential operations in digital picture
processing,” J. ACM, vol. 13, no. 4, pp. 471–494, 1996.
[26] S.-J. Park, K.-S. Seo, and J.-A. Park, “Automatic hepatic tumor segmentation using statistical optimal threshold,” Comput. Sci.—ICCS, vol. 3514,
pp. 934–940, 2005.
[27] L. Massoptier and S. Casciaro, “A new fully automatic and robust algorithm for fast segmentation of liver tissue and tumors from CT scans,”
Eur. Radiol., vol. 18, no. 8, pp. 1658–1665, 2008.
[28] T. Maenpaa and M. Pietikainen, “Texture analysis with local binary patterns,” in Handbook of Pattern Recognition and Computer Vision, 3rd ed.
Singapore: World Scientific, 2005, pp.197–216.
[29] R. M. Haralick, K. Shanmugam, and I. Dinstein, “Textural features for
image classification,” IEEE Trans. Syst., Man, Cybern., vol. SMC-3,
no. 6, pp. 610–621, Nov. 1973.
[30] B. S. Manjunath, Introduction to MPEG-7: Multimedia Content Description Interface. New York, NY, USA: Wiley, 2002.
Authors’ photographs and biographies not available at the time of publication.

