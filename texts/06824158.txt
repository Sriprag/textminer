IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 2, MARCH 2015

635

Recognizing Common CT Imaging Signs of Lung
Diseases Through a New Feature Selection Method
Based on Fisher Criterion and Genetic Optimization
Xiabi Liu, Ling Ma, Li Song, Yanfeng Zhao, Xinming Zhao, and Chunwu Zhou

Abstract—Common CT imaging signs of lung diseases (CISLs)
are defined as the imaging signs that frequently appear in lung CT
images from patients and play important roles in the diagnosis of
lung diseases. This paper proposes a new feature selection method
based on FIsher criterion and genetic optimization, called FIG for
short, to tackle the CISL recognition problem. In our FIG feature
selection method, the Fisher criterion is applied to evaluate feature subsets, based on which a genetic optimization algorithm is
developed to find out an optimal feature subset from the candidate features. We use the FIG method to select the features for the
CISL recognition from various types of features, including bagof-visual-words based on the histogram of oriented gradients, the
wavelet transform-based features, the local binary pattern, and
the CT value histogram. Then, the selected features cooperate with
each of five commonly used classifiers including support vector machine (SVM), Bagging (Bag), Naı̈ve Bayes (NB), k-nearest neighbor
(k-NN), and AdaBoost (Ada) to classify the regions of interests
(ROIs) in lung CT images into the CISL categories. In order to evaluate the proposed feature selection method and CISL recognition
approach, we conducted the fivefold cross-validation experiments
on a set of 511 ROIs captured from real lung CT images. For all the
considered classifiers, our FIG method brought the better recognition performance than not only the full set of original features
but also any single type of features. We further compared our FIG
method with the feature selection method based on classification
accuracy rate and genetic optimization (ARG). The advantages
on computation effectiveness and efficiency of FIG over ARG are
shown through experiments.
Index Terms—Common CT imaging signs of lung diseases
(CISLs), feature selection, lung CT images, lung lesion classification, medical image classification.

I. INTRODUCTION

C

OMPUTED tomography (CT) scan can provide valuable
information in the diagnosis of lung diseases. We have

Manuscript received October 20, 2013; revised March 12, 2014 and April 16,
2014; accepted May 23, 2014. Date of publication June 2, 2014; date of current
version March 2, 2015. This work was supported by the National Natural
Science Foundation of China under Grants 60973059 and 81171407 and the
Program for New Century Excellent Talents in the University of China under
Grant NCET-10-0044. (Corresponding author: Xinming Zhao.)
X. Liu and L. Ma are with the Beijing Lab of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing
100081, China (e-mail: liuxiabi@bit.edu.cn; maling0@bit.edu.cn).
L. Song was with the Beijing Institute of Technology, Beijing 100081, China.
She is now with Qihoo 360 Technology Co. Ltd., Beijing 100015, China (e-mail:
song1i@bit.edu.cn).
Y. Zhao, X. Zhao, and C. Zhou are with the Department of Imaging Diagnosis, Cancer Institute and Hospital, Chinese Academy of Medical Sciences, Beijing 100021, China (e-mail: zyf24@sina.com; xinmingzh@sina.com;
cjr.zhouchunwu@vip.163.com).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2327811

been witnessing the enormous increase in CT images of the human lungs, which should be read in time. This challenge plus
the difficulty of recognizing subtle lesions even for radiologists
promote the research interests in the computer-aided diagnosis
(CAD) and the content-based medical image retrieval (CBMIR)
based on thoracic CT scans. To support CAD and CBMIR applications, the computer should have the abilities of detecting,
classifying, and quantifying CT findings of lung lesions. The CT
findings denote what radiologists see in CT scans for diagnosing diseases, which are also often called “CT features” or “CT
manifestation.” This paper focuses on the problem of automatic
classification of CT findings of lung lesions in CT scans.
There are two main purposes of developing lung lesion classification methods in previous works. The first one is to distinguish
abnormal tissues from normal ones, usually for abnormality detection such as nodule detection. The second one is to identify
visual patterns of a specific lung disease. In this paper, we try to
achieve a slightly different purpose: classifying different types
of CT findings of lung lesions under the ignorance of underlying
diseases. To our knowledge, this problem has not received much
attention of researchers. A radiologist relies on the analysis to
CT findings of lesions for making decisions about the diagnosis.
But the correlation between CT findings and diseases is complicated. On one hand, a same category of CT findings could
be observed in the images corresponding to different diseases.
On the other hand, different categories of CT findings could
appear in the CT images from the patients with a same disease.
Therefore, it is useful for CAD and CBMIR applications to recognize the categories of CT findings in the regions of interests
(ROIs) in lung CT images under the ignorance of diseases. For
example, we can apply this technique to retrieve historical CT
scans containing the interested categories of CT findings from
large repositories, and the retrieved results are valuable for not
only diagnostics but also medical research and teaching.
There are some well-known categories of CT findings of lung
lesions that frequently appear in patients’ lung CT images and
play important roles in the diagnosis of lung diseases. We call
this kind of CT findings as the common CT imaging signs of
lung diseases (CISL). We summarized nine categories of CISLs,
which are illustrated in Fig. 1 and explained in the following. Notice that this taxonomy is neither complete nor widely accepted
at present, but these CT signs are really often encountered and
widely used in the diagnosis of lung diseases.
1) Grand Grass Opacity (GGO): GGO can be characterized
by areas of hazy increased attenuation of the lung with
preservation of bronchial and vascular margins [1]. It is

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

636

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 2, MARCH 2015

Fig. 1. Instances of nine categories of CISLs, which are indicated by the
smaller rectangles in lung CT images and magnified to display clearer in the
bigger rectangles overlapping on the images.

2)

3)

4)
5)

6)

7)

associated with the adenocacinoma of lung and bronchioloalveolar carcinoma [2], [3].
Lobulation: Lobulation is dependent on the ingrowth of
connective tissue septae containing fibroblasts derived
from perithymic mesenchyme [4], which indicates a malignant lesion [5].
Cavity and Vacuolous (CV): Both cavity and vacuolous are
hollow spaces within the tissue. We can regard vacuolous
as little cavity. Vacuolous is associated with the adenocarcinoma and bronchioloalveolar carcinoma, while cavity is
associated with the tumors larger than 3 cm [6], [7].
Spiculation: Spiculation is a stellate distortion caused by
the intrusion of cancer into surrounding tissue [8].
Pleural Indentation (PI): PI is caused by the contraction
of scar affected by the tumor, which is associated with
most peripheral adenocarcinomas containing a central or
subpleural anthracotic and fibrotic focus [9].
Obstructive Pneumonia (OP): OP can be characterized
by the following appearances: 1) alveolar septum has not
been completely destroyed by tumor, 2) alveolar wall is
thin, and 3) alveolus contains gas. This feature is associated with the alveolar carcinoma, lymphoma, pulmonary
infarction, and pulmonary edema [10].
Calcification: Calcification is the deposition of insoluble
salts of calcium and magnesium. Its morphology and distribution are important for discriminating between benign
lung diseases and malignant ones. The coarse, dense, and
popcorn-like calcification indicates benign lesions, while
the calcification located in the center of lesions, spotted,
and appearing irregularly suggests malign lesions [11].

8) Air Bronchogram (AB): AB is an important radiologic
sign of airspace consolidation, in which the normally invisible bronchial air column becomes visible. It usually
accompanies with cavity. This feature is associated with
the lung cancer, pulmonary pneumonia, and lymphoma
[12].
9) Bronchial Mucus Plugs (BMP): BMP can be represented
by focal opacities. Its density varies from liquefied density
to higher than 100 Hounsfield Units (HU). It is associated
with the allergic bronchopulmonary aspergillosis [13].
In a previous preliminary work [14], we began to investigate
the problem of recognizing the CISLs contained in the ROIs in
lung CT images, where four CISL categories including GGO,
cavity, speculation, and calcification were considered. In this
paper, we expand the number of CISL categories to nine and
propose a new feature selection method based on FIsher criterion
and genetic optimization for tackling the problem. The proposed
feature selection method is called FIG for short. It cooperates
with each of five commonly used classifiers, including SVM,
Bag, NB, k-NN, and Ada, to fulfill the CISL recognition task.
We conducted the experiments to demonstrate the effectiveness
of the proposed FIG feature selection method as well as CISL
recognition approach.
The remainder of this paper is organized as follows.
Section II reviews related works on lung CT image classification
and feature selection in medical imaging. Section III presents
our FIG method for feature selection. Section IV describes our
CISL recognition approach. The experiments are discussed in
Section V. We conclude in Section VI.
II. RELATED WORKS
We review the previous works on the image classification and
the feature selection in the medical image community. For the
former problem, we restrict our discussions on lung CT images.
For the latter problem, since there is not much related work
specific to lung CT images, we expand our view to include
other types of medical images.
A. Lung CT image Classification
As described in Section I, the works on lung CT image classification can be divided into three categories according to their
purposes: 1) the discrimination between normal and abnormal
lung tissues, 2) the identification among visual patterns of specific lung diseases, and 3) the classification of different types
of lung lesions. In the first category of works, many methods
are presented for nodule detection and GGO detection. They are
usually adopted in the final stage of detection systems to decide
whether a candidate is true or false. In the second category of
works, the explored lung diseases include diffuse parenchyma
lung disease (DPLD), chronic obstructive pulmonary disease,
and interstitial lung disease (ILD). Although the purposes of
three categories of works are different, the frameworks of classification systems are similar in principle, which are usually
composed of two components: feature extractor and classifier.
For the classifier, the researchers have tried two strategies:
single classifier and classifier fusion. The main single classifiers

LIU et al.: RECOGNIZING COMMON CT IMAGING SIGNS OF LUNG DISEASES THROUGH A NEW FEATURE SELECTION METHOD

have been explored, such as rule-based [15], linear discriminant
analysis (LDA) [16], artificial neural networks (ANN) [17]–
[20], Bayesian classifier [21]–[24], k-NN [25], [26], and SVM
[16]. Sluimer et al. [27] evaluated linear discriminant classifier,
quadratic discriminant classifier, SVM, and k-NN. The k-NN
classifier performed best according to their experimental results. Nuzhnaya et al. [28] compared k-NN, SVM, and ANN.
They showed that the k-NN achieved the best average performance, and the SVM performed fairly well on some of individual datasets. Depeursinge et al. [29] compared five common
classifiers, including NB, k-NN, decision tree, ANN, and SVM,
in their abilities to categorize six lung tissue patterns in highresolution CT images of patients affected with ILD. The results
revealed that the SVM constitutes the best tradeoff between
the error rate on the training set and the generalization. In the
classifier fusion strategy, we have witnessed the applications of
various combinations, such as the rule-based classifier and LDA
[30], the rule-based and ANN [31], k-NN and ANN [32], and
multiple SVMs [33].
For the feature extractor, there are three main types of features
for lung CT image classification. The first one is the geometric
features, such as geometric shape features [15], radius features,
and profile features [16], the boundary and circularity information [22], major and minor axes and their ratio [27], the eccentricity of a fitted ellipse [27]. The second type of features are
textural features, such as run-length features [20], [23], local
binary patterns (LBP) [21], cooccurrence features [23], [24],
[27], [32], multiple texton-based features [33], vector quantization generating texture descriptor [28], histogram of oriented
gradients (HOG) features [21], and wavelets [29]. The third type
of features is intensity-based ones. We have gradient magnitude
features [16], edge-gradient features [31], CT value histogram
(CVH) [21], and intensity distributions [27]. Among the three
types of features, the geometric features are mainly used on
the lesions having the fixed geometrical properties. The other
two types of features, especially textural features, are used more
often.
B. Feature Selection for Medical Image Classification
In order to achieve good classification results, we usually use
several types of features at the same time. Since the different
types of features may contain complementary information, it
could bring better classification performance through selecting
discriminative features from various feature spaces. This idea
has attracted a lot of attention in the related fields, including the
medical image classification [34]. According to Guyon and Elisseff [35], the feature selection techniques can be organized into
mainly three categories: filter, wrapper, and embedded methods. We follow their taxonomy to review the feature selection
methods for medical image classification.
Filter techniques rank the features by the intrinsic properties
of the data, independent of the choice of the classifier. The features are selected based on their ranking. Zuluaga et al. [36]
used three different strategies, including F-score, random forest (RF) and SVM-recursive feature elimination (SVM-RFE),
to rank the features and take the top ten features for vascular

637

anomaly detection. The classification results based on the features selected by using F-score and RF are pretty close, while
the ones from SVM-RFE present higher sensitivity (SE) and
specificity (SP). Nithya and Santhi [37] proposed a feature filter
that is called maximum difference feature selection. They used
the dissimilarity between the features in normal and abnormal
patterns as the criterion function and then selected the top five
features as the most discriminative ones. Silva et al. [38] proposed two filter-based feature selection algorithms for medical
image classification: the silhouette-based greedy search and the
silhouette-based Genetic Algorithm (GA) search, in which the
simplified silhouette statistic is calculated and used to evaluate
the features. Huang et al. [39] employed the information entropy
and the sequential backward selection algorithm to determine
the importance degrees of features for breast cancer diagnosis.
Wrapper techniques take the optimal subset of features as
the one that lead to the best performance of the classifier, but
the learning of the classifier is invisible to the feature selection.
The crucial factors in wrapper techniques are the search algorithm and the criterion for evaluating feature subsets. Firpi and
Vogelstein [40] used the misclassification error and the particle
swarm optimization search algorithm to select features for cognitive state detection in a brain–computer interface system. Dy
et al. [41] used the trace ratio of the expectation-maximization
clustering result in the feature space and the sequential forward
selection search algorithm to select feature subsets. The resultant algorithm was applied to the CBMIR of lung CT images.
Park et al. [42] applied the k-NN classifier to detect the pulmonary embolisms depicted on CT images. They preselected
an optimal feature set by using the GA and the evaluation criterion of the normalized area under a free-response receiver
operating characteristics (FROC) of the classifier. Zheng et al.
[43] used the SE and SP of the classifier as the evaluation criterion and the GA as the search algorithm to select the features
for colonic polyp detection. Hupse and Karssemeijer [44] used
the mean SE of the classification system in a predefined range
of FROC and the sequential floating forward selection search
algorithm to select features for detecting malignant masses in
mammograms. Wu et al. [45] used the GA search algorithm and
the criterion involving the classification rate and the number of
selected features to select feature subsets. The method is first
performed to select features from each feature space, respectively, and then performed again on the resultant features from
all the considered feature spaces to select the final feature subset
for ultrasonic liver tissue characterization. Zhu et al. [46] employed the GA search algorithm and the misclassification rate
of the classifier to select multiple groups of feature subsets with
different numbers of features and tested them for discriminating
benign solitary pulmonary nodules from malignant ones.
Embedded methods integrate the feature selection into the
process of classifier training. Ozcift [47] first made use of a
linear SVM to rank the features. Then, the feature vector was
determined for each of other classifiers by adding the features
one by one and in order until the accuracy of the classifier discontinues increasing. Finally, the rotation forest ensemble classifier was established for improving the diagnosis of Parkinson
disease. Maggio et al. [48] evaluated the performance of the

638

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 2, MARCH 2015

feature subset at increasing set size. For different cardinalities,
the subset which maximizes the min-redundant max-relevance
measure was selected and, the performances of the Fisher linear
discriminant classifier trained on this subset were computed. The
best cardinality and consequently the best subset were chosen
according to the minimum misclassification error.

this paper. We complete the evaluation task based on Fisher
criterion. Accordingly, the fitness of individuals is computed as
follows.


i,j
i,j
be the full feature vector of
Let X i,j = xi,j
1 , x2 , . . . , xd
the jth example of the ith class, ni be the number of examples
of the ith class, C be the number of classes. First, we calculate
the mean of feature vectors belonging to the ith class as

III. FEATURE SELECTION METHOD BASED ON FISHER
CRITERION AND GENETIC OPTIMIZATION
In essence, the feature selection problem is to find out the
best feature subset in the power set of features. Therefore, it involves two subproblems: 1) how to evaluate feature subset and
2) how to implement search. For the search algorithm, the GA
is a popular and good choice. But most of GA-based feature
selection algorithms measure the quality of feature subset by
its classification accuracy rate (CAR). In the following descriptions, a feature subset is called an individual, and the quality
of it is called its fitness, according to GA’s terminology. Using
the CAR as the individual fitness has two disadvantages. First,
it makes the feature selection method depend on the underlying
classifier. The optimal feature subset generated for one classifier may not be necessarily appropriate to another one. Second,
for getting the individual fitness, the classifier must be retrained
with the corresponding feature subset and then used to perform
classification on the dataset to obtain the CAR. This procedure
of fitness evaluation is obviously time consuming and leads to
the unsatisfactory efficiency of GA search. In order to solve the
two shortcomings above, our FIG method introduces the Fisher
discriminative criterion [49] to measure the individual fitness in
the GA-based optimum search. Although both the Fisher criterion and the GA algorithm have been explored in previous
works on feature selection, respectively, this strategy of ours for
combining them is the first one to our knowledge.
Furthermore, in most of GA-based feature selection methods,
the feature selection result is represented by a binary string.
Each bit in the string corresponds to a feature, where the value
1 indicates that the feature is selected and 0 indicates that the
feature is discarded. Different from these methods, we assign a
weight in [0, 1] to each feature and evolve the weights. It is more
reasonable and more accurate for measuring the importance
degree of a feature than the hard value of 0 or 1. After the
weight evolution is completed, the feature whose weight exceeds
a threshold is chosen as a member of the optimal feature subset.
The threshold is determined adaptively according to training
data, as explained in the last paragraph of Section III-A.

mi =

ni
1 
X i,j
ni j =1

(1)

and the mean of feature vectors of all the training examples as
C n i
i,j
i=1
j =1 X
.
(2)
m=
C
i=1 ni


Suppose the resultant mi = mi1 , mi2 , . . . , mid , and the resultant m = {m1 , m2 , . . . , md }. Second, we get the average
weighted distance between all the training examples and the
corresponding class mean as
SW =

ni 
C
d

2

1 
i
wk xi,j
−
m
,
k
k
n
i=1 i j =1

(3)

k =1

and the weighted distance between classes as
SB =

C 
d


	

2
wk mik − mk .

(4)

i=1 k =1

Finally, the Fisher criterion can be formulated as maximizing S B
and minimizing S W simultaneously. Thus, the fitness function
for evaluating w is designed as
f (w) =

SW
.
SB

(5)

The optimal w is taken as the one that minimizes (5). Then,
we select the features whose weights in the optimal w are larger
than a threshold. Here, we use k-NN classifier examination to
obtain a data-driven threshold. Actually, the nine thresholds
from 0.1 to 0.9 are used to select the features, respectively. Each
resultant subset of features is employed in a k-NN classifier to
perform the classification. The feature subset leading to the best
CAR is taken as the final selection result and the corresponding
threshold as the optimal one. This final feature selection result
is unchanged in the subsequent classification stage, no matter
what classifier is used.

A. Fitness Function Based on Fisher Criterion
A reasonable objective of feature selection for pattern classification is to maximize classification accuracy. The Fisher
criterion measures the distance among all the classes and the
divergence within the members of each class. Thus, it reflects
the classification accuracy under the absence of classifiers.
Let d be the number of considered feature elements, w
 =
(w1 , w2 , . . . , wd ) be the feature-weight vector, where wi di=1
reflects the importance of the ith feature. According to GA’s
terminology, a w is an individual required to be evaluated in

B. Genetic Optimization for Feature Selection
Under GA optimization framework, the main components
of our FIG algorithm include population initialization, fitness
evaluation, selection, crossover, mutation, and termination judgment. The corresponding flowchart of the algorithm is illustrated
in Fig. 2, where “Fisher Fitness Evaluation” means “the fitness
evaluation based on Fisher criterion.” The fitness evaluation
method has been presented in the last section. The details of
other components are given as follows.

LIU et al.: RECOGNIZING COMMON CT IMAGING SIGNS OF LUNG DISEASES THROUGH A NEW FEATURE SELECTION METHOD

639

features. Then, we perform the single-point crossover in each
part of the chromosome, respectively.
The probability of crossover affects the search ability and
the convergence speed of GA. In this study, we follow Yang
et al. [51] to adopt the adaptive probability of crossover. Let
it is denoted as Pc . Initially, a large Pc is used to strengthen
the search ability. As the evolution goes on, Pc is decreased to
improve the convergence speed gradually. Formally, let Pc 0 be
the initial crossover probability, g be the number of generation;
C i and C j be the chromosomes of parent individuals, then Pc
is adjusted by

pc 0
fm ax ≥ f
log 1 0 (g +1) ,
pc =
(7)
fm ax < f
pc 0 ,
where
fm ax = max(f (C i ), f (C j ))

(8)

and
f=

Fig. 2.

Flowchart of the proposed FIG algorithm.

1) Population Initialization: In the GA algorithms, all the
individuals in each generation construct the population. Each
individual is encoded as a binary string, which is thought to be
the individual’s chromosome. As described previously, an individual in the FIG algorithm is a feature-weight vector. Suppose
the weights are required to be accurate to p decimal places, then
the closed interval [0, 1] needs to be divided into 10p equal
parts. If
2q −1 < 10p < 2q

(6)

then the length of the binary string for each weight should
be q-bit and the chromosome will be encoded as C =
{c1 . . . cq , cq +1 . . . c2q , . . . , c(d−1)q +1 , . . . , cdq }.
     



w1

w2

wd

2) Selection Operator: The selection operator is used to select the parent individuals which will participate in producing offsprings for the next generation. Here, the commonly
used roulette wheel selection technique [50] is used. Actually, the probability
of selecting an individual is calculated as
M
p(C i ) = f (C i )
k =1 f (C k ), where C i is the chromosome
of the ith individual in the population, f (C i ) is the fitness value
corresponding to C i , and M is the number of individuals in the
population.
3) Crossover Operator: The crossover operator is used to
create new individuals by recombining the genes of the chromosomes of the selected two parents. Considering that there are
different types of features for selection and at least one feature
of each type should be selected, the multipoint crossover is performed. Actually, we divide the chromosome of an individual
into several parts, each of which is corresponding with a type of

M
1 
f (C i ).
M i=1

(9)

Notice that in (7), we use log10 (g + 1) instead of log2 (g + 1)
which is used in [51]. The reason is that this change makes the
crossover probability drop more slowly and thus leads to better
results in our experiments.
4) Mutation Operator: The mutation occurs right after the
crossover is completed. It is performed by inversing one bit in
each part of an individual’s chromosome to create a child. Similar to the processing in the crossover, each part of the chromosome is corresponding with a type of features, and the mutation
probability is also adjusted adaptively. The adaptive equation is
 pm 0
, f ≥f
(10)
pm = log 1 0 (g +1)
f <f
pm 0 ,
where Pm 0 is the initial mutation probability, f is the fitness of
the individual mutated; g and f¯ have the same meaning as those
in (7).
5) Termination Judgment: The algorithm will be terminated
when it converges or the predefined maximum number of generations is reached. The condition that we use to judge whether
the algorithm converge is: The difference between the maximum
fitness values of adjacent two generations does not exceed an
infinitesimal (denoted as ε) after m generations.
IV. CISL RECOGNIZER
Our approach of recognizing CISLs in ROIs in lung CT images consists of two components: feature extraction and ROI
classification. First, the features are extracted from each ROI and
some of them are selected by using the proposed FIG method to
form a feature vector for representing the ROI. Then, the ROI is
classified into the corresponding CISL category by using some
classifiers.
A. Feature Extraction
We consider four types of ROI features, including the bag-ofvisual-words based on the HOG (B-HOG), the wavelet features,

640

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 2, MARCH 2015

the LBP, and the CVH. We have 18-D B-HOG features, 26-D
wavelet features, 96-D LBP features, and 40-D CVH features.
Total 180 features are extracted. The details of each type of
features are given as follows.
1) B-HOG: The HOG feature is a texture descriptor describing the distribution of image gradients in different orientations.
Following the HOG feature extraction scheme of Dalal and
Triggs [52], we divide a ROI into smaller rectangular blocks
of 8 × 8 pixels and further divide each block into four cells of
4 × 4 pixels. An orientation histogram which contains nine bins
covering a gradient orientation range of 0–180° is computed
for each cell. Then, a block is represented by the linking of the
orientation histograms of cells in it. This means a 36-D HOG
feature vector is extracted for each block.
The commonly used image representation based on HOG
features is to join the feature vectors of all the blocks in the
image in sequence. This kind of HOG-based image representation strategy requires that all the images have the same size, or
else the dimensions of resultant feature vectors will be diverse
for different images. But the size of ROIs in lung CT images
varies with different patients and different pathological lesions.
So this widely used strategy is not applicable in this study. To
solve this problem, we adopt the bag-of-visual-words [53] on
HOG features as the ROI representation. However, different
from the original bag-of-visual-words method, we use a clustering algorithm based on Gaussian mixture modeling (GMM)
[54], instead of the k-means algorithm, to generate more accurate visual words. In this paper, total 18 visual words are
obtained.
The 36-D HOG feature vector of each block is mapped to the
visual word corresponding to the highest likelihood for it. Then,
the number of HOG feature vectors assigned to each visual word
is accumulated and normalized by the number of all the HOG
feature vectors to form a 18-D histogram representation of the
ROI.
2) Wavelet Features: Wavelets are important and commonly
used feature descriptors for texture analysis, due to their effectiveness in capturing localized spatial and frequency information
and multiresolution characteristics [55]. In this paper, the ROIs
are decomposed to four levels by using 2-D symlets wavelet because the symlets wavelet has better symmetry than Daubechies
wavelet and more suitable for image processing [56]. Then, the
horizontal, vertical, and diagonal detail coefficients are extracted
from the wavelet decomposition structure. Finally, we get the
wavelet features by calculating the mean and variance of these
wavelet coefficients.
3) LBP: The LBP feature is a compact texture descriptor in
which each comparison result between a center pixel and one
of its surrounding neighbors is encoded as a bit [57]. In this
way, we can get an integer for each pixel. Then, the frequency
of each integer is figured out on the ROI level to obtain the
corresponding feature vector.
The neighborhood in the LBP operator can be defined very
flexibly by using circular neighborhoods and the bilateral interpolation of pixel values. These kinds of neighborhoods can be
denoted by (P, R), which means we evenly sample P neighbors
on the circle of radius R around the center pixel. The correspond-

ing LBP features will be denoted as LBP(P, R) in the following
descriptions. We consider multiple P and R to get multiscale
LBP features.
4) CVH Features: CVH means the histogram of CT values. In
lung CT images, the CT values of pixels are expressed in HU.
We compute the histogram of CT values over each ROI. The
number of bins in the histogram is determined by experiments.
In fact, we obtain various CVHs with different numbers of bins.
Each CVH is tested for classification under k-NN classifier, and
the corresponding CAR is calculated. Then, the number of bins,
which brings the highest CAR, is adopted. This choice will keep
unchanged for all the experiments.
B. ROI Classification
Five classifiers, including SVM, Bag, NB, k-NN, and Ada,
are, respectively, tested for cooperating with the selected features to classify ROIs into CISL categories. These classifiers are
implemented by using the corresponding functions in WEKA
[58], a machine-learning library in java. The name of these functions are: 1) “SMO” (SVM), 2) “Bag,” 3) “NB,” 4) “IBk” (k-NN,
k = 1 and Euclidean distance are adopted), 5) “AdaBoostM1”
(Ada, using REPTree as weak learner).
Each function provides two execution modes: training and
testing. We call the function with the training mode on the
training data to obtain the corresponding classifier. Then, it is
evaluated on the test data by calling the function with the testing
mode.
V. EXPERIMENTS
A. Experimental Setup
1) Dataset: The instances of nine categories of CISLs were
collected from the Cancer Institute and Hospital at the Chinese
Academy of Medical Sciences. The lung CT images were acquired by CT scanners of GE LightSpeed VCT 64 and Toshiba
Aquilion 64 and saved in DICOM 3.0 format. The slice thickness is 5 mm, the image resolution is 512 × 512, and the in-plane
pixel spacing ranges from 0.418 to 1 mm (mean: 0.664 mm).
The rectangular ROIs wrapping CISLs in these lung CT images are manually labeled and annotated by qualified radiologists to produce a gold standard. The resultant numbers of ROIs
are 511. The sets of all these available instances are split into
five disjoint subsets nearly evenly, in order that fivefold crossvalidation experiments can be conducted. Furthermore, the data
in different subsets are guaranteed to come from different patients, so that the bias in measuring classification performance
is avoided. Table I lists the numbers of ROI examples in five
data subsets and the numbers of patients for each CISL category,
where S1–S5 denote the first to the fifth subsets, respectively,
and NoP means “the number of patients.”
2) Evaluation Criterion: The performance of CISL recognition is evaluated by the SE and SP, CAR, and confusion matrix
(CM).
1) The SE and SP are widely used in the medical image
classification community. They are essentially two measurements of performance of binary classifiers. In this

LIU et al.: RECOGNIZING COMMON CT IMAGING SIGNS OF LUNG DISEASES THROUGH A NEW FEATURE SELECTION METHOD

TABLE I
DISTRIBUTION OF ROIS USED IN FIVEFOLD CROSS-VALIDATION EXPERIMENTS

TABLE III
NUMBER OF BINS IN CVH FEATURE EXTRACTION AND THE RESULTANT CAR

CISL

S1

S2

S3

S4

S5

Total

NoP

Number of Bins

GGO
lobulation
calcification
CV
spiculation
PI
AB
BMP
OP
Total

9
9
10
30
6
16
5
17
4
106

9
8
10
30
6
16
5
16
4
104

9
8
9
29
6
16
5
16
4
102

9
8
9
29
6
16
4
16
3
100

9
8
9
29
5
16
4
16
3
99

45
41
47
147
29
80
23
81
18
511

25
21
20
75
18
26
22
29
16
252

20
30
40
50
60

TABLE II
PARAMETERS OF OUR FIG METHOD USED IN THE EXPERIMENTS
Parameters
Values

Population size

Pc 0

Pm 0

ε

m

60

0.8

0.8

0.001

50

paper, we use them to reflect the ability of our CISL
recognizer for discriminating one CISL category from
any other categories. If a positive example for a CISL
category can be recognized correctly by the algorithm, we
call it “true positive”; otherwise, we call it “false negative”. The meanings of “true negative” and “false positive”
are defined similarly. Let TP, TN, FP, FN be the number
of true positives, true negatives, false positives, and false
negatives for a CISL category, respectively. Then, the SE
and SP of the classifier for this category are measured as
TP/(TP+FN) and TN /(TN+FP), respectively.
2) Our CISL recognition problem is actually a multiclass
classification problem. So we use the CAR to give an
overall measurement of performance of our CISL recognizer. It is the ratio of the number of correctly classified
examples to the number of all examples.
3) The CM is used to summarize the tendency for our CISL
recognizer to classify a pattern into a correct class or any
of other wrong classes.
3) Parameter Setting: Two groups of parameters of our approach were set up through experiments. The first group of parameters is those in the proposed FIG feature selection method.
Table II lists the values of this group of parameters, which correspond to the experimental results reported in the following.
The reasons behind these values are explained as follows: 1)
The population size should be designed on the basis of the dimension of original feature vector. The small population size
will weaken the search ability of our FIG, while the large population size will slow down the speed of the algorithm. Since the
dimension of original feature vector in this research is 180, we
assign a moderate value, i.e., 60, to population size. 2) The initial
probabilities of crossover and mutation, i.e., Pc 0 and Pm 0 , are
set by following Yang et al. [51]. 3) ε and m for terminating the
algorithm are set by observing the change of maximum fitness
values of adjacent generations in the experiments. We found that

641

CAR %
44.1
47.1
49.1
45.1
45.1

TABLE IV
NUMBERS OF SELECTED FEATURES AND WEIGHT THRESHOLD
FOR SELECTING FEATURES IN EACH ROUND OF TESTS
Test Round

Num of Selected Features

Weight Threshold

92
132
145
146
141

0.5
0.3
0.2
0.2
0.2

1
2
3
4
5

TABLE V
AVERAGE CISL RECOGNITION PERFORMANCE OF OUR FIG
FEATURE SELECTION METHOD
Classification Results (%)
Classifiers

SE

SP

CAR

SVM
Bag
NB
k-NN
Ada

70.2
71.8
79.4
68.4
68.1

97.2
96.9
97.1
96.4
96.7

80.26
77.88
77.84
73.58
75.70

the maximum fitness values will keep stable after the converge
condition configured with these two values is satisfied.
The second group of parameters is those in LBP and CVH
feature extraction. The ranges of P and R for calculating LBP
feature are set to be {4, 5} and {1, 2}, respectively. They are
enough to adapt to the sizes of ROIs encountered in the experiments. As for the number of bins in CVH computation, we tested
five numbers from 20 to 60. For each tested number, the corresponding CVH features were extracted and cooperated with
k-NN to perform the CISL recognition. The resultant CARs are
listed in Table III, from which we can see that the best number
is 40 and it was used in all the following experiments.
B. Experimental Results
1) Results of Feature Selection and CISL Recognition: We
conducted feature selection and ROI classification experiments.
Table IV shows the numbers of features selected from original
180 features and the determined weight threshold for selecting
features in each round of fivefold cross-validation experiments.
Table V lists the average CISL recognition performance
over nine categories of CISLs by using selected features and
each of five classifiers. In each round of tests, each classifier with selected feature vector is trained and tested by

642

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 2, MARCH 2015

TABLE VI
SE AND SP FROM SVM AND SELECTED FEATURES FOR EACH
CATEGORY OF CISLS
Classification Results of SVM (%)
CISLs

SE

SP

GGO
lobulation
calcification
CV
spiculation
PI
AB
BMP
OP
Average

100
80
89.3
89.3
18.2
79.8
0
95.0
80.0
70.2

99.4
99.6
99.6
86.5
99.8
91.7
100
98.9
99.4
97.2

Fig. 3. Examples of wrong classified CISLs: (a) lobulation noised by blood
vessel; (b) calcification identified difficultly; (c) and (d) easy confused AB and
CV; (e) and (f) easy confused spiculation and PI.

using the corresponding routines in WEK library. According to
the CAR, the best CISL recognition performance came from
the SVM classifier. Thus, we further show the SE and SP
from the combination of selected features and SVM for each
category of CISLs in Table VI. Notice that in this situation,
the recognition performance is evaluated for each category of
CISLs, separately and respectively. For an input pattern, we
need to determine whether this pattern belongs to the specific
category of CISLs or not. Thus, this is a binary classification
problem, and the values of resultant SE and CAR are equal with
each other.
We carefully analyzed the reasons behind wrong classification
results from the recognizer established by combining selected
features and the SVM. The reasons are illustrated in Fig. 3 and
explained as follows, where the lesions are indicated by the
smaller rectangles in lung CT images and magnified to display
clearer in the bigger rectangles overlapping on the images. 1)
Some CISLs are noised by blood vessels surrounding them, as
shown in Fig. 3(a). 2) Some CISLs are so small and hazy that it
is difficult to recognize them even by radiologists, as shown in
Fig. 3(b). 3) The visual appearance of some CISLs are very similar with each other, which can be seen by comparing Fig. 3(c)

and (d) as well as Fig. 3(e) and (f). Especially for the CISL
“AB,” it is very visually similar with the CISL “CV.” Furthermore, the training examples of “AB” are far less than those of
“CV.” Consequently, most of ‘AB’ instances were classified into
“CV,” which leads to unsatisfied SE of 0 for “AB” category.
2) Comparisons With Independent Feature Space and Original Full Set of Original Features: In order to prove the necessity
of feature selection, we further conducted the CISL recognition
by using each type of original features and the full set of original features, respectively. The corresponding average results
on all the categories of CISLs are shown in Table VII, where
LBP(P, R) means the LBP feature vector configured with P
neighbors and radius R, as described in Section IV.
According to Table VII, 1) the best classifier is NB for the
full set of features; 2) the best single type of features is B-HOG;
and 3) the combination of different types of features can really
improve the classification performance, since the SE, SP, and
CAR from the full set of features are all better than those from
each single type of features for all the classifiers. But through
comparing the data in Table V and VII, we can see that all the
measurements of recognition performance from the full set of
features are behind those from the selected features by using our
FIG method. In Table VIII, we list the increase rates of SE, SP,
and CAR brought by our selected features for each of classifiers,
compared with the full set of features and B-HOG, respectively.
These data confirm the effectiveness of our FIG method. It
leads to better classification results and is independent of used
classifiers. However, the increase rates for NB classifier and the
full set of features are not very impressive. A possible reason
is that the NB classifier is established based on the assumption
that the features are statistically independent with each other;
thus, the influence of negative features may be weakened greatly
after the training of NB, similar as the effect of feature selection.
To demonstrate the advantage of our selected features over
the full set of features more clearly, we further calculate the
difference between CMs for the combination of each classifier
and our selected features and those for each classifier and the
full set of features. The results are shown in Fig. 4. The fact that
most of diagonal elements in differential CMs are positive and
most of the others are negative proves that the use of selected
features can increase the possibility of classifying the patterns
into its true class and lower the possibility of confusing between
different classes.
3) Comparisons With ARG Feature Selection Method: To further prove the performance of our FIG feature selection method,
we compare it with the commonly used GA feature selection
method based on CAR. We call it ARG for short. The ARG
method is similar to our FIG method in the framework, the main
difference between them is the design of fitness function. The
fitness in the FIG is computed based on the Fish criterion, while
it is computed based on CAR in the ARG. We recorded the CISL
recognition performance and computation time of FIG and ARG
algorithm, respectively. All the experiments were performed on
a computer with 2.33-GHz CPU and 4-GB Memory.
The comparisons of CAR for each considered classifier between FIG and ARG methods are shown in Fig. 5, where we
can see that the classification accuracy brought by the ARG

LIU et al.: RECOGNIZING COMMON CT IMAGING SIGNS OF LUNG DISEASES THROUGH A NEW FEATURE SELECTION METHOD

643

Fig. 4. Difference between the CMs for each classifier and our selected features and those for each classifier and the full set of original features: (a) for SVM;
(b) for Bag; (c) for NB; (d) for k-NN; (e) for Ada.

644

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 2, MARCH 2015

TABLE VII
CLASSIFICATION PERFORMANCE FROM EACH OF SINGLE FEATURE SPACES AND THE FULL SET OF FEATURES
SVM (%)

Bag (%)

NB (%)

k-NN (%)

Ada (%)

Feature Spaces

SE

SP

CAR

SE

SP

CAR

SE

SP

CAR

SE

SP

CAR

SE

SP

CAR

B-HOG
LBP(5,1)
LBP(5,2)
LBP(4,1)
LBP(4,2)
CVH
Wavelet
Full

47.9
32.7
33.1
27.7
30.4
39.1
34.1
65.3

95.3
93.0
92.7
91.8
92.4
93.4
93.2
96.6

67
52.3
51.1
47.4
49.3
54.2
52.6
76.32

48.4
34.7
37.4
38.9
39.5
38.3
40.2
66.1

94.9
93.2
93.2
93.6
93.2
93.4
93.7
96.5

65
51.3
52.4
54.4
51.7
51.7
55.0
74.74

62.4
45.5
49.4
43.0
48.4
43.7
40.6
78.4

95.2
93.6
93.6
93.3
93.4
92.2
93.8
97.0

63
50.5
50.5
49.1
49.9
36.8
44.2
77.26

54.5
36.8
44.4
38.8
40.1
40.0
49.2
66.9

94.5
93.1
93.7
92.9
93.2
93.1
94.2
96.0

59.5
48.9
53.2
46.8
48.5
49.1
56.6
69.66

54.4
33.1
33.2
33.6
33.5
34.5
36.4
67.4

95.1
92.7
92.5
92.4
92.3
92.9
92.8
96.4

63.4
45.6
46.8
45.2
44.2
47.2
48.3
73.82

pendent of the classifiers and is performed only once for all the
classifiers, the computation time of it does not vary with the
classifiers. Only 0.16 s is needed for the FIG to complete a computation of one generation. In contrast, the computation time of
ARG varies from 1.86 to 684.40 s according to the classifier
complexity. The big difference of the efficiency between the
ARG and the FIG exists in that the ARG must retrain the classifier with the feature subset and perform the data classification
in each iteration of fitness evaluation.

Fig. 5. Comparisons of CARs for each considered classifier between ARG
and FIG feature selection methods.

TABLE VIII
INCREASE RATES OF SE, SP, AND CAR BROUGHT BY OUR SELECTED
FEATURES, COMPARED WITH THE FULL SET OF FEATURES AND
THE BEST SINGLE TYPE OF FEATURES, RESPECTIVELY
Increase Rates (%)
Full Set of Features

B-HOG

Classifier

SE

SP

CAR

SE

SP

CAR

SVM
Bag
NB
k-NN
Ada

7.50
8.62
1.28
2.24
1.04

0.62
0.41
0.10
0.42
0.31

5.16
4.20
0.75
5.63
2.55

46.56
48.35
27.24
25.50
25.18

1.99
2.11
2.00
2.01
1.68

19.79
19.82
23.56
23.66
19.40

is slightly lower than that by the FIG for all the considered
classifiers.
We further conducted the paired t-test analysis [59] to determine whether there is a significant difference in effectiveness
between FIG and ARG. The resultant two-tailed p values for
SVM, Bag, NB, k-NN, and Ada are 0.823, 0.334, 0.319, 0.957,
and 0.858, respectively. Usually p < 0.05 is accepted as significant. So we conclude that although the FIG behaved a little better
than the ARG on the average, the difference in the effectiveness
between them is not significant.
However, the FIG is much better than the ARG on the computation efficiency. This can be demonstrated by comparing the
average running time of one generation in the FIG and that in
the ARG, as shown in Fig. 6. Since our FIG method is inde-

VI. CONCLUSION
This paper has proposed a new feature selection method based
on Fisher criterion and genetic optimization for recognizing
CISLs. The main contributions of this paper are summarized as
follows.
1) The problem of recognizing nine categories of CISLs in
lung CT images is put forward, which is important for
the CAD and the CBMIR based on thoracic CT scans.
To our knowledge, this problem has not received much
attention of researchers. The previous works on lung tissue
classification mainly concern about how to distinguish
abnormal tissues from normal ones or identify among
different visual patterns of a specific lung disease.
2) A feature selection method is presented based on FIsher
criterion and genetic optimization, which is called FIG
for short. The Fisher criterion is applied to evaluate
feature selection results, based on which a genetic optimization algorithm is developed to find out the optimal
feature subset from candidate features. As demonstrated
by the experimental results, our FIG method can bring
more effective recognition results at the satisfactory computation costs, compared with single type of features and
the full set of original features. Furthermore, it brought
slightly better recognition performance and much better
computation efficiency than the commonly used genetic
feature selection method based on classification accuracy
rate. Another advantage of the FIG is that it is independent of the classifiers; it is required to be performed only
once to select the features suitable for all the considered
classifiers.
3) The FIG method and each of five commonly used
classifiers are combined to establish CISL recognizers,

LIU et al.: RECOGNIZING COMMON CT IMAGING SIGNS OF LUNG DISEASES THROUGH A NEW FEATURE SELECTION METHOD

Fig. 6.

645

Comparison of running time between ARG and FIG feature selection methods.

respectively, among which the SVM classifier behaved
best. In fivefold cross-validation experiments on 511 ROIs
which are manually extracted from real lung CT images,
the cooperation of FIG and SVM achieved the average SE
of 70.2%, the average SP of 97.2%, and the classification
accuracy rate of 80.26%.
In the future, we want to add some image preprocessing steps
to further improve the performance of our CISL recognizer. We
can filter the blood vessels to get rid of the confusion between
vessels and CISLs. We can also enhance the regions wrapping
CISLs to make the visual appearance of CISLs clearer and thus
increase the possibility of correct classification.
REFERENCES
[1] G. Battista, C. Sassi, M. Zompatori, D. Palmarini, and R. Canini, “Groundglass opacity: Interpretation of high resolution CT findings,” La Radiologia Medica, vol. 106, pp. 425–442, 2003.
[2] Z. G. Yang, S. Song, and S. Talcashima, “High-resolution CT analysis of
small lung adenocarcinoma revealed on screening helical CT,” Amer. J.
Roentgenol., vol. 176, no. 6, pp. 1399–1407, 2001.
[3] T. Aoki, Y. Tomoda, H. Watanabe, H. Nakata, T. Kasai, H. Hashimoto, M.
Kodate, T. Osaki, and K. Yasumoto, “Peripheral lung adenocarcinoma:
Correlation of thin-section findings with histologic factors and survival,”
Radiology, vol. 220, pp. 803–809, 2001.
[4] J. J. T. Owen, D. E. McLoughlin, R. K. Suniara, and E. J. Jenkinson, “The
role of mesenchyme in thymus development,” Current Topics Microbiol.
Immunol., vol. 251, pp. 133–137, 2000.
[5] M. R. Melamed, B. J. Flehinger, M. B. Zaman, R. T. Heelan, W. A.
Perchick, and N. Martini, “Screening for lung cancer: Results of the memorial sloan-kttering study in New York”, Chest, vol. 86, no. 1, pp. 44–53,
1984.
[6] C. V. Zwirewich, S. Vedal, R. R. Miller, and N. L. Müller, “Solitary
pulmonary nodule: High-resolution CT and radiologic-pathologic correlation,” Radiology, vol. 179, no. 2, pp, 469–476, 1991.
[7] S. F. Huang, R. F. Chang, D. R. Chen, and W. K. Moon, “Characterization
of spiculation on ultrasound lesions,” IEEE Trans. Med. Imag., vol. 23,
no. 1, pp. 111–121, Jan. 2004.
[8] M. Noguchi and Y. Shimosato, “The development and progression of
adenocarcinoma of the lung,” Cancer Treatment Res., vol. 72, pp. 131–
142, 1995.
[9] T. V. Colby and C. Lombard. “Histiocytosis X in the lung,” Human Pathol.,
vol. 14, no. 10, pp. 847–856, 1983.
[10] V. J. Lowe, J. W. Fletcher, L. Gobar, M. Lawson, P. Kirchner, P. Valk,
J. Karis, K. Hubner, D. Delbeke, E. V. Heiberg, E. F. Patz, and R. E.
Coleman, “Prospective investigation of positron emission tomography in
lung nodules,” J. Clin. Oncol., vol. 16, no. 3, pp. 1075–1084, 1998.
[11] K. S. Lee, Y. Kim, and S. L. Primack, “Imaging of pulmonary lymphomas,”
Amer. J. Roentgenol., vol. 168, no. 2, pp. 339–345, 1997.
[12] J. W. Gurney, “Determining the likelihood of malignancy in solitary
pulmonary nodules with Bayesian analysis: Part 1. Theory,” Radiology,
vol. 186, no. 2, pp. 405–413, 1993.
[13] J. J. Erasmus, H. I. McAdama, and J. H. Connolly, “Solitary pulmonary
nodules: Part II. Evaluation of the indeterminate nodule,” Radiographics,
vol. 20, no. 1, pp. 59–66, 2000.

[14] L. Song, X. Liu, L. Ma, C. Zhou, X. Zhao, and Y. Zhao, “Using HOGLBP features and MMP learning to recognize imaging signs of lesions,”
in Proc. Comput.-Based Med. Syst., 2012, pp. 1–4.
[15] X. Ye, X. Lin, G. Beddoe, and J. Dehmeshki. “Efficient computer-aided
detection of ground-glass opacity nodules in thoracic CT images,” in Proc.
29th Annu. Int. Conf. IEEE Eng. Med. Biol. Soc., 2007, pp. 4449–4452.
[16] T. W. Way, B. Sahiner, H. P. Chan, L. Hadjiiski, P. N. Cascade, A.
Chughtai, N. Bogot, and E. Kazerooni, “Computer-aided diagnosis of pulmonary nodules on CT scans: Improvement of classification performance
with nodule surface features,” Med. Phys., vol. 36, no. 7, pp. 3086–3098,
2009.
[17] H. Chen, Y. Xu, Y. Ma, and B. Ma, “Neural network ensemble-based
computer-aided diagnosis for differentiation of lung nodules on CT images clinical evaluation,” Acad. Radiol., vol. 17, no. 5, pp. 595–602,
2010.
[18] H. U. Kauczor, K. Heitmann, C. P. Heussel, D. Marwede, T. Uthmann,
and M. Thelen, “Automatic detection and quantification of ground-glass
opacities on high-resolution CT using multiple neural networks: Comparison with a density mask,” Amer. J. Roentgenol., vol. 175, no. 5, pp.
1329–1334, Nov. 2000.
[19] K. G. Kim, J. M. Goo, J. H. Kim, H. J. Lee, B. G. Min, K. T. Bae, and J. G.
Im, “Computer-aided diagnosis of localized ground-glass opacity in the
lung at CT: initial experience,” Radiology, vol. 237, no. 2, pp. 657–661,
2005.
[20] S. C. Park, J. Tan, X. Wang, D. Lederman, J. K. Leader, S. H. Kim, and B.
Zheng, “Computer-aided detection of early interstitial lung diseases using
low-dose CT images,” Phys. Med. Biol., vol. 56, no. 4, pp. 1139–1153,
2011.
[21] L. Song, X. Liu, A. Yang, K. Pang, C. Zhou, X. Zhao, and Y. Zhao, “A
novel approach of computer-aided detection of focal ground-glass opacity
in 2D lung CT images,” Proc. SPIE, vol. 8670, pp. 86702W, 1–6, 2013.
[22] R. Shen, I. Cheng, and A. Basu, “A hybrid knowledge-guided detection
technique for screening of infectious pulmonary tuberculosis from chest
radiographs,” IEEE Trans. Biomed. Eng., vol. 57, no. 11, pp. 2646–56,
Nov. 2010.
[23] R. Uppaluri, T. Mitsa, M. Sonka, E. A. Hoffman, and G. McLennan,
“Quantification of pulmonary emphysema from lung computed tomography images,” Amer. J. Respir. Crit. Care Med., vol. 156, pp. 248–254, Jul.
1997.
[24] F. Chabat, G. Z. Yang, and D. M. Hansell, “Obstructive lung diseases: Texture classification for differentiation at CT,” Radiology, vol. 228, pp. 871–
877, Jul. 2003.
[25] P. Korfiatis, A. Karahaliou, C. Kalogeropoulou, A. Lazamtzo, and
L. Costaridou, “Texture based identification and characterization of
interstitial pneumonia patterns in lung multidetector CT,” IEEE
Trans. Inform. Technol. Biomed., vol. 14, no. 3, pp. 675–680, May
2010.
[26] L. Sørensen, P. Lo, H. Ashraf, J. Sporring, M. Nielsen, and M. de Bruijne,
“Learning COPD sensitive filters in pulmonary CT,” in Proc. Med. Image
Comput. Comput.-Assited Intervention Conf., 2009, vol. 5762, pp. 699–
706.
[27] I. Sluimer, P. F. van Waes, M. A. Viergever, and B. van Ginneken,
“Computer-aided diagnosis in high resolution CT of the lungs,” Med.
Phys., vol. 30, no. 12, pp. 3081–3090, Dec. 2003.
[28] T. Nuzhnaya, V. Megalooikonomou, H. Ling, M. Kohn, and R. Steine,
“Classification of texture patterns in CT lung imaging,” Proc. SPIE, vol.
7963, pp. 796336, 1–7, 2011.
[29] A. Depeursinge, J. Iavindrasana, and A. Hidki, “A classification framework for lung tissue categorization,” Proc. SPIE, vol. 6919, pp. 69190C,
1–12, 2008.

646

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 2, MARCH 2015

[30] M. N. Gurcan, B. Sahiner, N. Petrick, H. P. Chan, E. A. Kazerooni, P. N.
Cascade, and L. Hadjiiski, “Lung nodule detection on thoracic computed
tomography images: Preliminary evaluation of a computer-aided diagnosis
system,” Med. Phys., vol. 29, no. 11, pp. 2552–2558, 2002.
[31] J. Shiraishi, F. Li, and K. Doi, “Computer-aided diagnosis for improved
detection of lung nodules by use of PA and lateral chest radiographs,”
Radiology, vol. 237, no. 2, pp. 657–661, 2005.
[32] M. B. Huber, M. Nagarajan, G. Leinsinger, L. A. Ray, and A. Wismüller,
“Classification of interstitial lung disease patterns with topological texture
feature,” Proc. SPIE, vol. 7624, pp. 762410, 1–8, 2010.
[33] M. J. Gangeh, L. Sørensen, S. B. Shaker, M. S. Kamel, and M. D. Bruijne,
“Multiple classifier system in texton-based approach for the classification
of CT images of lung,” Med. Comput. Vis., vol. 6533, pp. 153–163, Feb.
2011.
[34] Y. Saeys, I. Inza, and P. Larrañaga, “A review of feature selection techniques in bioinformatics,” Bioinformatics, vol. 23, no. 19, pp. 2507–2517,
2007.
[35] I. Guyon and A. Elisseeff, “An introduction to variable and feature selection,” J. Mach. Learn. Res., vol. 3, pp. 1157–1182, 2003.
[36] M. A. Zuluaga, E. J. F. D. Leyton, M. H. Hoyos, and M. Orkisz, “Feature
selection for SVM-based vascular anomaly detection,” in Proc. Int. MICCAI Conf. Med. Comput. Vis., Recognit. Tech. Appl. Med. Imag., 2010,
pp. 141–152.
[37] R. Nithya and B. Santhi, “Mammogram classification using maximum
difference feature selection method,” J. Theor. Appl. Inform. Technol.,
vol. 33, pp. 197–204, 2011.
[38] S. F. da Silva, B. Brandoli, D. M. Eler, J. B. Neto, and A. J. Traina,
“Silhouette-based feature selection for classification of medical images,”
in Proc. Comput.-Based Med. Syst., 2010, pp. 315–320.
[39] M. L. Huang, Y. H. Hung, and W. Y. Chen, “Neural network classifier
with entropy based feature selection on breast cancer diagnosis,” J. Med.
Syst., vol. 34, no. 5, pp. 865–873, Oct. 2010.
[40] H. A. Firpi and R. J. Vogelstein, “Particle swarm optimization-based feature selection for cognitive state detection,” in Proc. Eng. Med. Biol. Soc.,
2011, pp. 6556–6559.
[41] J. G. Dy, C. E. Brodley, A. Kak, L. S. Broderick, and A. M. Aisen,
“Unsupervised feature selection applied to content-based retrieval of lung
images,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 25, no. 3, pp. 373–
378, Mar. 2003.
[42] S. C. Park, B. E. Chapman, and B. Zheng, “A multistage approach to improve performance of computer-aided detection of pulmonary embolism
depicted on CT images: preliminary investigation,” IEEE Trans. Biomed.
Eng., vol. 58, no. 6, pp. 1519–1527, Jun. 2011.
[43] Y. Zheng, X. Yang, M. Siddique, and G. Beddoe, “Simultaneous feature
selection and classification based on genetic algorithms: An application to
colonic polyp detection,” Proc. SPIE, vol. 6915, pp. 69150E, 1–9, 2008.
[44] R. Hupse and N. Karssemeijer, “The effect of feature selection methods on
computer-aided detection of masses in mammograms,” Phys. Med. Biol.,
vol. 55, no. 10, pp. 2893–2893, 2010.
[45] C. C. Wu, W. L. Lee, Y. C. Chen, C. H. Lai, and K. S. Hsieh, “Ultrasonic
liver tissue characterization by feature fusion,” Expert Syst. Appl., vol. 39,
pp. 9389–9397, Aug. 2012.
[46] Y. Zhu, Y. Tan, Y. Hua, M. Wang, G. Zhang, and J. Zhang, “Feature selection and performance evaluation of support vector machine (SVM)-based
classifier for differentiating benign and malignant pulmonary nodules by
computed tomography,” J. Dig. Imag., vol. 23, no. 1, pp. 51–65, 2010.
[47] A. Ozcift, “SVM feature selection based rotation forest ensemble classifiers to improve computer-aided diagnosis of parkinson disease,” J. Med.
Syst., vol. 36, no. 4, pp. 2141–2147, Aug. 2012.
[48] S. Maggio, A. Palladini, L. De Marchi, M. Alessandrini, N. Speciale,
and G. Masetti, “Predictive deconvolution and hybrid feature selection for
computer-aided detection of prostate cancer,” IEEE Trans. Med. Imaging,
vol. 29, no. 2, pp. 455–464, Feb. 2010.
[49] R. O. Duda, P. E. Hart, and D. G. Stork, Pattern Classification, 2nd ed.
New York, NY, USA: Wiley, 2007.
[50] D. E. Goldberg and K. Deb, “A comparative analysis of selection
schemes used in genetic algorithms,” Urbana, vol. 51, pp. 61801–2996,
1991.
[51] W. Yang, D. Li, and L. Zhu, “An improved genetic algorithm for optimal
feature subset selection from multi-character feature set,” Expert Syst.
Appl., vol. 38, pp. 2733–2740, May 2011.
[52] N. Dalal and B. Triggs, “Histograms of oriented gradients for human
detection,” in Proc. Comput. Vis. Pattern Recognit., 2005, pp. 886–893.
[53] J. Wang, Y. G. Jiang, A. G. hauptmann, and C. W. Ngo, “Evaluating
bag-of-visual-words representations in scene classification,” in Proc. Int.
Workshop Multimedia Inf. Retrieval, 2007, pp. 197–206.

[54] Y. Wan, X. Liu, K. Tong, X. Wei, Y. Wu, F. Guan, and K. Pang, “GMMcluster forest: A novel indexing approach for multi-features based similarity search in high-dimensional spaces,” in Proc. Int. Conf. Neural Inf.
Process., 2012, pp. 210–217.
[55] Y. Tao, L. Lu, M. Dewan, A. Y. Chen, J. Corso, J. Xuan, M. Salganicoff, and
A. Krishnan, “Multi-level ground glass nodule detection and segmentation
in CT lung images,” in Proc. Med. Image Comput. Comput.-Assisted Surg.,
2009, pp. 715–723.
[56] A. Wang, H. J. Sun, and Y. Y. Guan, “The application of wavelet transform
to multi-modality medical image fusion,” in Proc. IEEE Int. Conf. Netw.,
Sensing Control, 2006, pp. 270–274.
[57] T. Ojala, M. Pietikainen, and D. Harwood, “A comparative study of texture measures with classification based on feature distributions,” Pattern
Recogit., vol. 29, no. 1, pp. 51–59, 1996.
[58] H. Geoffrey, D. Andrew, and H. W. Ian, “WEKA: A machine learning
workbench,” in Proc. 2nd Australia New Zealand Conf. Intell. Inf. Syst.,
1994, pp. 357–361.
[59] D. B. Rubin. “Matching to remove bias in observational studies,” Biometrics, vol. 29, no. 1, pp. 159–183, 1973.

Xiabi Liu was born in Jingzhou city, Hubei province,
China, in 1972. He received the B.S. degree in computer application from the Huazhong University of
Science and Technology, Hubei, China, in 1998,
and the Ph.D. degree in computer science from the
Beijing Institute of Technology, Beijing, China, in
2005.
From 2005 to 2008, he was a Lecturer at the School
of Computer Science, Beijing Institute of Technology. Since 2008, he has been an Associate Professor
at the School of Computer Science, Beijing Institute
of Technology. He found and leads the Machine Learning and Multimedia Retrieval lab, Beijing Institute of Technology. He was the Principal Investigator of
several research grants from the National Natural Science Foundation of China
and the Ministry of Education in China. He is the author or coauthor of one
book and more than 30 papers. He holds four patents. His current research interests include multimedia retrieval, machine learning, pattern recognition, and
computer vision.

Ling Ma received the B.S. and M.S. degrees in computer science and technology from Jilin University,
Changchun, China, in 2008 and 2011. She is currently working toward the Ph.D. degree at the School
of Computer Science, Beijing Institute of Technology, Beijing, China.
Her research interests include computer-aided diagnosis and content-based image retrieval.

Li Song was born in Datong, Shanxi province, China,
in 1987. She received the B.S. degree in computer science and technology from Qufu Normal University,
Shandong, China, in 2010, and the M.S. degree in
computer science and technology from the Beijing
Institute of Technology, Beijing, China, in 2013.
She is currently working for Qihoo 360 Technology Co. Ltd. as a Safety Engineer. Her research
interests include pattern recognition, machine learning, and computer vision. During the study, she had
published several papers related to her research fields.

LIU et al.: RECOGNIZING COMMON CT IMAGING SIGNS OF LUNG DISEASES THROUGH A NEW FEATURE SELECTION METHOD

Yanfeng Zhao was born in Beijing, China, in 1978.
He received the B.S. degree in medicine from Capital
Medical University, Beijing, in 2001, and the M.S.
degree in imaging and nuclear medicine from the
Chinese Academy of Medical Sciences (CAMS) and
Peking Union Medical College in Beijing, in 2012.
From 2001 to 2014, he was a Resident Physician
and Attending Doctor at the Department of diagnostic
radiology in CAMS. His research interest includes
medical imaging diagnosis of oncology. He is the
author of more than ten articles.

Xinming Zhao was born in Xiangyang city, Hubei
province, China, in 1964. He received the B.S. degree
in medicine from Tongji Medical University, Wuhan,
China, in 1988.
Since 2005, he has been a Professor at the Department of diagnostic radiology, Cancer Hospital of Chinese Academy of Medical Sciences, Beijing, China.
He has published six books and more than 70 papers.
Prof. Zhao is a Member of abdominal group in the
Chinese Society of Radiology and Pancreatic Oncology Group in the China Society of Oncology. He is
on Editorial Boards of the Chinese Journal of Cancer and the Chinese Journal
of Oncology Prevention and Treatment. He received the Second Class Prize of
Science and Technology Progress Award in Higher School, nominated by the
Ministry of Education in China, in 2012, and the Third Class Prize of Beijing
Municipal Science and Technology Award in 2012.

647

Chunwu Zhou received the M.D. degree from the
School of Clinical Medicine, China Medical University, Shenyang, China, in 1978.
From 1995 to 2006, he served as the Clinical Vice
Director of the Cancer Hospital, Chinese Academy
of Medical Sciences, Beijing, China. He is currently
a Professor, Chief Physician, Doctoral Tutor, and the
Director at the Department of Diagnostic Imaging,
Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing,
China. After 30 years of work on cancer imaging
diagnosis, research, and teaching, he is a renowned Expert in the diagnostic imaging and differential diagnostic imaging of tumors and other diseases.
He was also involved in many important national and international research
projects. He was the Principal Investigator of the National “9th Five-year” and
“11th Five-year” Science & Technology Construction Program, and National
“863” High Tech research project. He also worked as a Coinvestigator of two
national “9th Five-year” projects and two national “10th Five-year” Projects.
He has published more than 80 papers in the international and Chinese journals.
He was also the Chief Editor of five books and the Deputy Editor of one book.
Dr. Zhou is a Member of the Standing Committee of Chinese Society of Radiology, Chinese Medical Association, the Leader of the Breast Research Group
of the 12th Committee of the Chinese Society of Radiology, Chinese Medical
Association; the Vice Chairman of the Radiologist Association, Chinese Medical Association, the Chairman of Beijing Branch of the Chinese Association of
Radiologists. He is the Deputy Editor of the Chinese Journal of Medical Imaging Technology and the Chinese Journal of Oncoradiology. He is also on several
other journals’ Editorial Boards including the Chinese Journal of Radiology
and the Journal of Clinical Radiology. He accepted the special government allowances of the State Council in China in 1997.

