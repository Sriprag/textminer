2480

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 10, OCTOBER 2015

Obstetric Ultrasound Simulator With Task-Based
Training and Assessment
Li Liu∗ , Jason Kutarnia, Petra Belady, and Peder C. Pedersen, Senior Member, IEEE

Abstract—The increasing use of point-of-care (POC) ultrasound
presents a challenge in providing efficient training to POC ultrasound users for whom formal training is not readily available. In
response to this need, we developed an affordable compact laptopbased obstetric ultrasound training simulator. It offers a realistic
scanning experience, task-based training, and performance assessment. The position and orientation of the sham transducer are
tracked with 5 DoF on an abdomen-sized scan surface with the
shape of a cylindrical segment. On the simulator, user interface
is rendered a virtual torso whose body surface models the abdomen of the pregnant scan subject. A virtual transducer scans
the virtual torso by following the sham transducer movements on
the scan surface. A given 3-D training image volume is generated
by combining several overlapping 3-D ultrasound sweeps acquired
from the pregnant scan subject using a Markov random field-based
approach. Obstetric ultrasound training is completed through a series of tasks, guided by the simulator and focused on three aspects:
basic medical ultrasound, orientation to obstetric space, and fetal
biometry. The scanning performance is automatically evaluated by
comparing user-identified anatomical landmarks with reference
landmarks preinserted by sonographers. The simulator renders 2D ultrasound images in real time with 30 frames/s or higher with
good image quality; the training procedure follows standard obstetric ultrasound protocol. Thus, for learners without access to
formal sonography programs, the simulator is intended to provide
structured training in basic obstetrics ultrasound.
Index Terms—Diagnostic ultrasound training, obstetric ultrasound, simulation.

I. INTRODUCTION
IVEN the relatively modest cost of ultrasound scanners
and the absence of ionizing radiation, ultrasound has become the preferred imaging modality for many diagnostic procedures. In fact, growth in ultrasound-based diagnostic procedures
far exceeds that of any other imaging modality [1]. It is noteworthy that the use of point-of-care (POC) ultrasound is expanding,
such as a 60% increase in POC use for cardiology between
2004 and 2009, during which the use of POC ultrasound by
nonradiologist physicians increased 28% [2].

G

Manuscript received December 15, 2014; revised March 19, 2015 and April
21, 2015; accepted May 4, 2015. Date of publication May 14, 2015; date of current version September 16, 2015. This work was supported by the Telemedicine
and Advanced Technology Research Center under Grant W81XWH-10-1-0529.
Asterisk indicates corresponding author.
∗ L. Liu is with the Department of Biomedical Engineering, Worcester Polytechnic Institute, Worcester, MA 01609 USA (e-mail: lliu@wpi.edu).
J. Kutarnia is with the Department of Electrical and Computer Engineering,
Worcester Polytechnic Institute, Worcester, MA.
P. Pedersen is with the Department of Electrical and Computer Engineering
and with the Department of Biomedical Engineering, Worcester Polytechnic
Institute, Worcester, MA.
P. Belady is with the UMass Memorial Medical Center.
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2015.2433679

In contrast to other major imaging modalities, mainly CT
and MRI, ultrasound images are generated and displayed in
real time, and the proper manipulation of the ultrasound transducer on the surface of the body by the sonographer is critical
to produce images of diagnostic quality. Thus, well-developed
psychomotor skills are an important aspect of scanning competency. In addition, the ultrasound users need to possess substantial anatomical and physiological knowledge in order to acquire
ultrasound images or videos suitable for diagnostic decision
making.
The skill levels necessary for ultrasound-based diagnostic
decision making are wide ranging, from simple assessment of
fetal position or detecting the presence of gallstones to procedures requiring more precise probe position, such as detection of
pneumothorax or pericardial effusion. Clearly, good ultrasound
diagnostic skills require a good understanding of the human
anatomy and the ultrasound manifestations of organs and tissue structures, along with knowledge of the ultrasound scanner
(“knobology”), in order to choose the appropriate transducer
type and frequency, gain setting and focal point(s). However,
the latter has become somewhat simplified through procedurespecific presets.
Radiology department sonographers receive formal ultrasound training in accredited programs. However, with the advent
of POC ultrasound, clinical specialists without certified formal
ultrasound training have begun utilizing ultrasound [3]. POC
ultrasound training today is available in a range of formats, e.g.,
short courses and online training. Training is thus ad hoc, often
costly, inconvenient, and lacking procedure- and/or disciplinespecific standards.
The role of simulation in medical training, in general, is well
established, as evidenced by several annual conferences and
numerous publications [4]. Simulation provides a controlled
and safe practice environment to promote learning [5]. A critical review of more than 100 simulation studies concluded that
“high-fidelity medical simulations are educationally effective
and simulation-based education complements medical education in patient care settings” [6]. A similar conclusion was
reached in a recent review article on simulation in obstetrics
and gynecology [7]. However, despite their promise, ultrasound
simulators are being utilized only to a modest extent for training.
Even medical schools that include ultrasound in their curricula
rely mainly on traditional teaching methods [8].
Several studies have demonstrated the learning effectiveness
of ultrasound simulator-based training in diagnostic ultrasound.
A direct cross-over study demonstrated that ultrasound simulators can provide the proper skills for real patient examination
reliably and reproducibly [10]. Three different training levels
(with actual ultrasound scanners) revealed diagnostic accuracy

0018-9294 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

LIU et al.: OBSTETRIC ULTRASOUND SIMULATOR WITH TASK-BASED TRAINING AND ASSESSMENT

of 94.5%, 60%, and 38.8% depending on the level of training
for abdominal ultrasound, clearly signaling the need for better
training and for validated performance standards [11]. An actual
side-by-side comparison of training on patients and training on
simulators gave nearly the same level of detection of pathologies, confirming that simulators can deliver effective task-based
training [12].
The effectiveness of simulator-based training in ultrasoundguided procedures has similarly been validated. In one study,
30 trainees received a course on the amniocentesis procedure,
with hands-on training sessions using a simulator [13], where
the study results demonstrated the simulator’s effectiveness. A
recent study concluded that simulation plus didactic training in
ultrasound-guided central venous catheter insertion was superior to didactic training alone for acquisition of skill in aseptic
technique; after combined training, novices outperformed experienced residents in aseptic technique and measurements of
knowledge [14].
An overview of diagnostic ultrasound simulation systems up
to 2004 was given in [9]. A more recent overview [15] included classification of simulator types, methods for image
generation, and evaluation approaches. The SonoTrainer was
developed primarily for obstetrics training and has been utilized
mainly in Germany [12], [16]. It is simple in design, uses a body
sized manikin and sham transducer with magnetic-based tracking sensors, and has a high level of user satisfaction [17]. The
UltraSim is a large ultrasound simulator that includes a realisticlooking mock ultrasound scanner and a full-torso manikin and
is available for ultrasound scanning training for a broad range
of medical specialties [18], [19].
Recent academic research efforts include the development of
a transrectal ultrasound simulator for prostate imaging, utilizing a Wii Remote attached to a dummy probe [20]. A 2012
paper described a configurable, open-source training platform
for ultrasound-guided needle insertions, named Perk Tutor [21].
A virtual training system for prostate brachytherapy training,
using haptic feedback along with simulated ultrasound and fluoroscopy images, was recently published [22].
Examples of current commercial (2014) ultrasound training
simulators include the SonoMan and the TraumaMan from Simulab; these simulators use a torso manikin, where placing a simulated probe on specific points (or windows) will present the
corresponding images or videos. Simbionix recently launched
the U/S Mentor for cardiac imaging, also using a manikin and
a sham transducer to demonstrate both cardiac anatomy and
synthesized echocardiographic dynamic images. SonoSim is a
lower cost laptop-based ultrasound simulator, which uses a sham
transducer with orientational sensing in combination with ultrasound image volumes acquired from patients at specific body locations. The ScanTrainer products, i.e., the transvaginal and the
transabdominal simulators, are the only commercial simulators
to provide haptic feedback and to use extended image volumes
(i.e., mosaicked individual 3-D volumes). The CAE/Vimedix
has a product line of ultrasound simulators, where an anatomical image is presented side by side with a synthesized ultrasound
image, while scanning a physical manikin with a sham transducer.

2481

This paper describes an affordable and compact simulationbased ultrasound training system, which emulates the actual
scanning experience in obstetric ultrasound. This is achieved
by a combination of laptop-based implementation and low-cost
scanning simulation hardware, and by using mosaicked image
volumes that include the fetus, amniotic fluid, the placenta, and
the uterus. This design allows the cost to be lowered to the point
of making personal ownership of the simulator feasible. A major component of the simulator system is the task-based training
curriculum, organized into three modules, where trainees can
complete basic obstetric ultrasound training guided by the simulator. Furthermore, the simulator is able to automatically evaluate trainees scanning performance in specified training tasks.
The paper is structured as follows. Section II describes
the choices for creating the image material used for training
and the unique features of the simulator design. Section III
presents the available options for the sham transducer tracking
system, the chosen tracking system design, along with specifications for the physical scan surface (PSS). This is followed in
Section IV by a brief explanation of the acquisition and creation
of the image volumes used for training material. In Section V,
the mapping of the PSS to the surface of a specific image volume
used as training material is described. The simulator software
structure and components are described in Section VI. Next,
Section VII introduces the training tasks, training procedure,
and evaluation approaches. The method by which the simulator
assesses how well the training tasks are performed is outlined in
Section VIII. In Section IX, we present preliminary evaluation
results, both for the simulator performance on image rendering
speed and image quality, and also on task completion times by
expert sonographers. Finally, Section X and XI contain discussion and conclusion, respectively.
II. SIMULATION DESIGN OVERVIEW
The ultrasound simulator was designed to be a compact,
adaptable, and inexpensive training tool that can provide a realistic scanning experience. This requires the simulator to be
primarily software based. Nonetheless, physical components
are needed to realize the psychomotor aspects of diagnostic ultrasound training: Manipulation of a physical sham transducer
on a body-like surface, while making diagnostic decisions or
biometric measurements on the observed ultrasound image.
The choice of ultrasound image generation technique is important, and computer-based ultrasound simulators use one of
the four approaches for image generation [15]. CT or MRI
images volumes can be “ultrasonified” by adding texture and
speckle, but such image material typically exhibits too welldefined boundaries and lacks shadowing artifacts [23], [24].
An alternative is a deformable-mesh model-based approach that
synthesizes ultrasound images by simulating ultrasound wave
transmission in target organs. This approach is promising, retains diffraction, and shadowing effects, but is currently too
computationally demanding except for simple tissue structures
[25]. The mathematical-model-based method is usually applied
to the nonstationary organs, like the heart and blood vessels
[26]. This approach is less accurate compared to other three

2482

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 10, OCTOBER 2015

entation of the sham transducer, thus referred to as a “resliced”
image. The complete image slice is not shown; instead what is
displayed is a “stenciled” segment of the image slice, with the
“stencil” determined by the selected transducer type and by the
depth setting. At any given moment, the 2-D image is determined by the position and orientation of the sham transducer
on the PSS. Finally, the right side of the screen contains a basic
ultrasound console (gain, TGC, depth, transducer selection).
III. SIMULATOR SCANNING TRACKING SYSTEM

Fig. 1.

Block diagram over ultrasound training simulator.

approaches and needs further verification. The last of the four
approaches is the interpolation-based method [27], [28], which
uses actual ultrasound image volumes that are commonly created from one or more sequences of 2-D images from human
subjects; thus, this method normally offers a higher level of realism in real time with acceptable computational requirements.
The displayed 2-D image is obtained by reslicing the digitalized
3-D ultrasound image volume based on the position and orientation of the sham transducer. When weighing these four options,
we chose the interpolation-based method for our obstetrics ultrasound simulator.
The simulator design is intended to permit scanning over the
body surface area associated with a given ultrasound scanning
protocol, such as the obstetrics examination. This necessitates
a physical scan surface (PSS), mapped to cover that particular
body surface area, as well as a set of ultrasound image volumes,
which for obstetrics ultrasound must contain the fetus as well as
the maternal anatomical structures, such as uterus, placenta, and
amniotic fluid. Such large ultrasound image volumes can only
be produced by stitching together several overlapping 3-D images, while overcoming the unavoidable misalignment artifact
especially when acquiring fetal images. This mosaicking process, while not the main subject of this paper, will be described
briefly in Section IV.
As shown in the upper left part of Fig. 1 and in Fig. 2(b), the
physical components consists of a PSS emulating a specific part
of the human anatomy, and the sham transducer with integrated
position and orientation tracking sensors providing 5 degrees
of freedom (DoF). To minimize cost and space, these tracking
sensors were selected so that an external physical reference is
not required. The PSS is implemented as a cylindrical segment,
with a footprint corresponding to the scanning area of a typical
adult abdomen, appropriate for obstetrics ultrasound.
The user interface of the laptop contains several windows, two
of which are key to implementing the design concept. This is
illustrated in Fig. 2(a), where one window shows a rendering of
the body surface (the virtual torso). The part of the body surface
that can be scanned is unique to the selected 3-D image volume,
and a rendering of an actual transducer follows the movements
of the sham transducer (the virtual transducer). Another window
contains the B-mode image, which is a slice through the selected
3-D image volume and is determined by the position and ori-

A key aspect of the training simulator is the ability to track
the position and orientation (“motion tracking”) of the sham
transducer relative to the PSS. Commonly, motion tracking is
a process of capturing the movement of objects in a specific
coordinate system. Motion tracking devices have been widely
used in many interactive applications, such as robot-assisted
surgery [29], [30], interactive entertainment systems [31], and
especially in simulation systems [32], [33], such as military
flight simulators [34]. Ultrasound simulation systems require a
tracking system with as few as 3 DoF or as many as 6 DoF to
measure the orientation and/or position of the sham transducer.
Generally speaking, there are three commonly used categories
of tracking systems [35], electro-magnetic, electro-optical, and
electro-mechanical. In many medical simulator systems [12],
[36], an electro-magnetic tracking system (EMTS) is chosen
and can be implemented with ac [37] or dc [38] pulsed magnetic
fields. It can track the orientation and position of an object in
6 DoF using a small sensor attached to the sham transducer
that detects the magnetic field from an electro-magnetic field
transmitter. The EMTS [39], [40] has small latency (down to
5 ms), high accuracy (ࣈ1 mm), medium cost, and no need
of line-of-sight to the objects, but it suffers from interferences
from metallic structures in the vicinity of the sensor. A distinct
disadvantage is the need of an external reference in the form of
a transmitter.
The second category of tracking systems covers electrooptical tracking systems (EOTS) [41]. In camera-based EOTS,
the object(s) to be followed are equipped with markers, and
EOTS can provide up to 3-DoF position information. Camera
tracking normally has a high refresh rates (> 60 Hz) and good
accuracy (<1 mm). However, limitations arise from the problems of line of sight, environmental configurations (brightness,
cameras locations, etc.), and the need for camera(s) to function as external references. In contrast, a cross-correlation-based
EOTS, such as that used in the optical computer mouse, does
not require an external reference, but offers only 2-DoF position
data. It also cannot measure the absolute position of objects in a
specific space and it performs poorly on some uneven or transparent surfaces. A unique electro-optical tracking method is
based on pattern recognition, in the form of so-called digital paper or interactive paper [42], which is a (paper) surface imprinted
with a coded pattern and used in conjunction with a digital pen
with an embedded camera. The most widely used coded pattern
is the Anoto pattern [43]. While providing only 2-DoF positional information, digital paper overcomes the limitations of the
previous two optical tracking techniques and provides absolute

LIU et al.: OBSTETRIC ULTRASOUND SIMULATOR WITH TASK-BASED TRAINING AND ASSESSMENT

Fig. 2.

2483

Ultrasound simulator physical appearance. (a) Simulator user interface. (b) PSS.

position information in the coordinates of the digital paper even,
while the paper is placed on a curved surface [44].
The third category of tracking systems, the electromechanical tracking, enables orientation tracking by the use
of one or more gyroscopes. An important 3-DoF orientational
tracking system is the inertial measurement system (IMU) consisting of a three-axis gyroscope, a three-axis accelerometer,
and a three-axis geomagnetic sensor. It supplies rotation angle
information (α, β, γ) along three orthogonal axes. By using
magnetic north and the gravitational field as reference vectors,
the IMU’s orientation is obtained in world coordinates with the
format of quaternion or Euler angles and is free of drift.
The tracking system for our training simulator design needs
to be integrated into a sham transducer having same shape and
size as an actual ultrasound transducer. In addition, the tracking
system needs to satisfy the following requirements.
1) Degrees of Freedom: At least 5 DoF needed to offer realistic scanning simulation.
2) Speed: Provide tracking data more than 25 times every
second to guarantee smooth visual experience.
3) Accuracy: Measure the position and rotation angle with
accuracy of better than 1 mm and 1°.
4) Robustness: Tracking accuracy cannot be affected by the
environmental configurations.
5) Cost and Portability: Low cost suitable for personal ownership.
6) External Reference: Not acceptable.
The only solution that meets all the requirements stated above
is a combination of an IMU and an optical tracking device based
on a digital paper technology. We selected the Anoto digital paper (Anoto AB, Lund, Sweden) [43] and the PNI SpacePoint
IMU sensor (PNI Sensor Corp., Santa Rosa, CA, USA), as the
specific tracking components. The Anoto pen is mounted in the
center of the sham transducer [a transducer shell for a convex
array transducer (Sound Technology, State College, PA, USA)].
The pen contains an infrared (IR) light source for illuminating a
small area of the Anoto pattern, an IR camera for capturing the
illuminated pattern area and an image processor to extract the
corresponding absolute position of that area. A pressure sensor

in the pen activates the light source, which for the ultrasound
simulator emulates the transducer contact with the skin surface
(Anoto pattern). The Anoto pattern is printed on a durable compliant skin-colored vinyl surface (Visual Magnetics, Mendon,
MA, USA), similar to a flexible magnetic sheet, to provide a
more realistic simulation experience. Our evaluation [44] of the
Anoto technology indicates that it can correctly measure the
absolute position at a rate of 75 Hz with a resolution of around
0.3 mm even when the pattern was placed on the curved surfaces
(cylinder) or tilted at a large angle relative to normal (< 55°).
The PNI sensor can sample the object’s orientation along all
three axes at a rate of 125 Hz with a resolution better than 0.1°.
The design of the ultrasound training simulator requires that
the PSS meets several requirements, such as dimensions and
shape that are approximately similar to the body surface to be
scanned. However, the geometry of the PSS must be limited to
the shapes that can be obtained by curving, but not stretching or
in other ways deforming, a planar surface to ensure no distortion of the Anoto pattern. In addition, every point on the scan
surface must have a well-defined position and surface normal
so that they can be formulated in the chosen coordinate system.
For an obstetrics ultrasound simulator, the PSS needs to have
dimensions similar to the human abdominal region. Specifically,
we have chosen the PSS to be a 120° segment of a cylindrical
surface with a cylinder radius of approximately 6 and with a
footprint of 10 × 12 , made from lightweight and inexpensive polyethylene sheet and covered with a 1-cm foam rubber
for an appropriate degree of surface compliance, to emulate the
compliance of a body surface.
Using the fixed dimensions and geometry for the PSS, the simulator can transform the probe position from the 2-D coordinates
(x, y) of the Anoto surface to the 3-D cylindrical coordinates (θ,
z) referenced to the PSS. This is shown in (1) and Fig. 3, where
X and Y are the dimensions of the Anoto surface, and where
z is the normalized length. The α, β, γ variables denote rotation angles from the PNI sensor. The 5-DoF tracking data (θ,
z, α, β, γ) from the sham transducer need to be transformed
from the PSS coordinates into 3-D image coordinates using an
mathematical model generated offline before they are used to

2484

Fig. 3.

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 10, OCTOBER 2015

Cross section of physical scanning surface.

guide the simulator to extract 2-D images from the 3-D image
volume. The model generation and coordinate transformation
are described in Sections V and VI, respectively,
⎧
2π x
⎪
⎪
⎨θ = 3 X
.
(1)
⎪
⎪
⎩z = y
Y
IV. METHODOLOGY FOR CREATING 3-D IMAGE VOLUMES
A novel Markov random field (MRF)-based method for the
mosaicking of 3-D ultrasound volumes was used for the creation
of the 3-D image volumes used in the training simulator. The
process is broken down into five distinct steps, which encompass
individual 3-D volume acquisition, rigid registration, calculation
of a mosaicking function, groupwise nonrigid registration, and
final blending. Each of these steps, common in medical image
processing, has been investigated in the context of ultrasound
mosaicking and has resulted in an improved algorithm [45].
The groupwise nonrigid registration problem is first formulated as maximum likelihood estimation, where the joint probability density function is comprised of the partially overlapping
ultrasound image volumes. This expression is simplified using
a block-matching methodology, and the resulting discrete registration energy is shown to be equivalent to a MRF. Graph-based
methods common in computer vision are then used for optimization, resulting in a set of transformations that bring the
overlapping volumes into alignment. This optimization is parallelized using a fusion approach, where the registration problem
is divided into eight-independent subproblems whose solutions
are fused together at the end of each iteration. This method provided a significant speedup over the single threaded approach
with no noticeable reduction in accuracy. Furthermore, the registration problem is simplified by introducing a mosaicking function, which partitions the composite volume into regions filled
with data from unique partially overlapping source volumes.
These mosaicking functions attempt to minimize intensity and
gradient differences between adjacent sources in the composite
volume. With this method, composite obstetrics image volumes
are constructed using clinical scans of pregnant subjects [46].
A solution to blending, which is the final step of the mosaicking process, has also been implemented. The learner will
have a better experience if the volume boundaries are visually
seamless, and this usually requires some blending prior to stitch-

ing. Also, regions of the volume where no image data were
collected during scanning should be given an ultrasound-like
appearance before being displayed in the simulator. This ensures that the learner’s visual experience is not degraded by
clearly missing image material. A discrete Poisson approach
has been adapted to accomplish these tasks.
For the purpose of acquiring actual clinical ultrasound data,
from which training datasets were produced, 11 pregnant subjects were scanned by experienced sonographers at the University of Massachusetts Medical School following an approved
IRB protocol. Specifically, the scan pattern is a sequence of
parallel free-hand 3-D scans, spaced close enough so that the
scan volumes, produced by this sequence of 3-D scans, overlap
at all ranges. A 6-DoF tracking system is used to acquire the
exact location and orientation of the transducer at the moment
of capture of each image frame. From the collected data, seamless 3-D fetal mosaicking volumes were generated, and then
subsequently formatted into training datasets for our simulator.
V. MAPPING OF PHYSICAL SURFACE TO 3-D IMAGE VOLUMES
While each 3-D image volume has a unique abdominal surface geometry, the dimensions of the PSS are fixed. Therefore,
the movements of the sham transducer on the PSS can neither
directly be translated into the movement of the virtual transducer on the virtual torso nor guide the reslicing of a 3-D image
volume for generating 2-D image. Thus, a method is required to
map each point on the abdominal surface of a given 3-D image
volume back to the full PSS so that the orientation and position
of the sham transducer in the PSS coordinates can be correctly
transformed into the unique 3-D image coordinates. Usually, the
geometry of the abdominal surface of a pregnant woman in the
second trimester can be approximated to a truncated ellipsoid
segment [47], that is, a surface obtained by cutting an ellipsoid
by a plane parallel to the major axis, and then, truncating by
planes normal to the major axis near both ends. Therefore, we
have defined a virtual scan surface (VSS), shaped as a cylindrical segment, and virtual abdominal surface (VAS), shaped
as a truncated ellipsoid segment, by means of which any location and orientation of the sham transducer on the PSS can be
transformed into a corresponding location and orientation of the
virtual transducer on the abdominal image surface (AIS) of a
given 3-D image volume and vice versa. The purpose of introducing these additional transformation steps is to improve the
accuracy of the transducer position transformation by making
the transformed cylindrical coordinates closer to the AIS coordinates. This cylinder-to-ellipsoid model, or more accurately,
the cylindrical segment to ellipsoid segment model, will assist
the simulator in transforming 5-DoF tracking data into the 3-D
image volume coordinates.
The generation of a composite 3-D image volume consists
of aligning and merging the overlapping 3-D individual images
volumes based on the fetal and the maternal anatomies. Consequently, the abdominal surface of a given composite image
volume is often irregular as seen in Fig. 4, and not all surface points represent the true abdominal surface of the pregnant
subject. This typically leads to lower accuracy when mapping a

LIU et al.: OBSTETRIC ULTRASOUND SIMULATOR WITH TASK-BASED TRAINING AND ASSESSMENT

2485

Fig. 4. Three-dimensional volume mesh, with the surface of the image volume
shown in a darker color.

Fig. 6.

Fig. 5.

Final abdominal image surface (AIS).

3-D image volume to the PSS. To obtain the abdominal surface
for model creation, the image volume mesh, created from the
given 3-D image volume using Fang’s approach [48], needs to
be preprocessed so that all mesh vertices, not likely to represent
the true abdominal surface (see light color region in Fig. 4), are
manually removed, and then, smoothed with the 3-D graphic
software Blender. The resulting surface is denoted as the abdominal image surface, or AIS, as shown in Fig. 5. It can be
considered to be the best representation of the abdominal surface
and is used for creating cylinder-to-ellipsoid model. In addition,
it will be used to create the virtual torso, which is explained in
Section VI-C.
The process of generating the parameters for the cylinder-toellipsoid model is carried out offline for each image volume as
detailed in Appendix I. The calculated parameters for the VSS
and the VAS are stored and loaded together with each image volume. During training, the simulator probe driver first performs
a linear transformation of the position and normal orientation of
the sham transducer to the corresponding position and orientation on the VSS, followed by a second linear transformation to
the VAS that represents the abdominal surface of the 3-D image
volume.
VI. TRAINING SIMULATOR SOFTWARE FRAMEWORK
One critical consideration in the simulator design is that the
system must guarantee smooth visual experience by being able
to render a minimum of 25 frames/s on a current standard laptop. Therefore, the software for the simulator is developed based
on the open-source library, medical imaging interaction toolkit
[49] (MITK), which is an extension of insight toolkit (ITK)
and visualization toolkit [50] (VTK), to balance development
flexibility and complexity, system performance, and cost efficiency [51]. VTK is a widely used 2-D/3-D image-rendering

Simulator software structure.

library supporting multiple data formats. This library is written in C++, which enables fast image rendering on medium
speed computers. Although VTK offers powerful visualization,
there are only a limited number of graphic user interface (GUI)
classes available for developers. In contrast, MITK not only
inherits all classes from ITK and VTK but also extends them
by providing easy-to-use GUI classes and additional features. It
creates a single rendering pipeline so that the image processing
algorithms in ITK can be seamlessly integrated into the VTK
rendering process.
For the GUI design, we use Qt [52], which is a widely used
cross-platform application framework. MITK has implemented
some Qt widgets that can bind the image processing and rendering libraries to the simulator quickly. The software contains
several components, or software blocks, as shown in Fig. 6,
which will be described in the following sections.
A. Data Manager
The purpose of this software block is to load and manage
training sets, while the simulator is running. A training set contains four types of data: a 3-D image, registered 3-D anatomical
landmark bounds (surfaces enclosing landmarks), a corresponding virtual torso, and mapping parameters. After a given training
set is loaded into the simulator, it is managed in a tree architecture, where we set the 3-D image volume as the parent of other
three types of data. The preregistered landmark bounds from
the training set are only needed for performance assessment
and are invisible to the user during training; however, a list of
landmarks, already identified by the learner for a given image
volume, can be seen in the data manager window on the GUI,
as shown in the lower left part of Fig. 2(a).
B. Probe Driver
This driver is an interface that translates the 5-DoF tracking
data from the sham transducer into the corresponding position
and orientation data in the selected 3-D image volume coordinates as shown in Fig. 7. The position and orientation on the
PSS are first transformed to their corresponding position and
orientation on the least-square-fit (LSF) cylinder segment, or
VSS, and then on the LSF ellipsoid, or VAS, based on the PSS

2486

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 10, OCTOBER 2015

can be used in the learner’s performance assessment. Although
the cylinder-to-ellipsoid model has been used to approximate
the abdominal surface of 3-D image, the virtual transducer still
fails to follow the VAS at some locations, but instead either
intersects or separates from the surface of the virtual torso. To
correct this problem, we have incorporated the software library
for interference detection (SOLID) into the simulator software;
SOLID detects the intersection depth or the distance of transducer to abdominal surface and then corrects the position data
from the cylinder-to-ellipsoid model.

Fig. 7.

D. Two-Dimensional Image Reslicer

Position and orientation transformation.

geometry and the mapping parameters as shown in (2). The
position transformation is detailed in Appendix II-A.
f1

f2

Pphysical ⇒ Pcylinder ⇒ Pellipsoid .

(2)

The orientation data from the IMU are referenced in world
coordinates, defined by the gravity vector and magnetic north
vector and formulated in quaternions, and need to be transformed to the corresponding orientation in the PSS coordinates
and then into dynamic local coordinates established at the scanning point, that is, the point of contact of the sham transducer
and the PSS as shown in (3). An autocalibration routine has been
developed to transform the IMU’s orientation data in world coordinates to the orientation data in the PSS coordinates by leveraging the custom capability of the Anoto pen, which allows the
spinning angle around the pen’s own axis to be measured. The
autocalibration utilizes the spinning angle and will be triggered
whenever the transducer is roughly normal (<5°) to the curved
PSS at the contact point. The orientation transformation and autocalibration are detailed in Appendix II-B and Appendix II-C,
respectively,
f3

f4

Qworld ⇒ QPSS ⇒ Qlo cal .

(3)

C. Virtual Torso and Probe Display
Using the PSS with fixed dimensions to emulate the abdomen
of a pregnant subject provides only a generic representation of
the actual abdominal surface of the subject who was scanned
to produce the given image volume. We have implemented a
virtual torso rendering by manually blending a generic female
body with the unique abdominal surface (the AIS) of a given
3-D image volume with Blender software, as shown in Fig. 7,
to provide a more realistic training experience.
While the learner is performing the ultrasound scanning by
moving the physical sham transducer on the PSS, a virtual transducer scans the virtual torso by following the (transformed)
movement of the sham transducer on the PSS with respect
to both position and orientation as illustrated in Figs. 2 and
7. Moreover, the valid scanning region of the virtual torso is
marked with a different shade of skin color. The movement path
of the virtual transducer over the valid scanning region can optionally be recorded and visualized, and the recorded path length

This software block utilizes the transformed orientation and
position from the sham transducer driver to define a slicing
plane, which guides the extraction of 2-D slices from the 3-D
image volume. First, the coordinates of every point on the slicing
plane are transformed back to its corresponding coordinates in
the 3-D image volume. If a given set of coordinates matches
an existing voxel in the image volume, the voxel intensity is
sampled directly. Otherwise, a trilinear interpolation is used
to calculate the voxel intensity of the corresponding point in
terms of the intensities of neighbor voxels. The visual effect of
using either the linear or convex array transducer is implemented
by spatial filtering the extracted 2-D images with a stencil of
rectangular or sector shape for a linear array and a convex array
transducer, respectively.
E. Assessment Unit
This software block implements the assessment of the performance of the individual tasks. One of its functions is to transform a given landmark in the 2-D ultrasound image that the
learner was asked to locate back to the corresponding position
in the 3-D images, as shown in (4). With the sham transducer
appropriately oriented and positioned, specific anatomical structures can be observed in the simulator’s rendering window (i.e.,
the window displaying the ultrasound image) where the learner
is to identify these structures on the screen. The position of
the learner-identified landmark in the coordinates of the laptop
screen is first transformed to the corresponding position in the
coordinates for the slicing plane and then to the position in the
coordinates of the 3-D image volume. It can be thought as a
reverse procedure of generating the 2-D ultrasound image by
reslicing the 3-D image volume
f5

f6

Pscreen ⇒ P2 -Dslice ⇒ P3 -Dim age .

(4)

Another function of this block is to examine if the learneridentified anatomical landmarks (points) is within the corresponding landmark bounds, as defined in (5). The definition of
landmark bounds is explained in Sect. VIII, part A. For the landmarks used in fetal biometry, the learner needs to click two or
more times on the screen for the measurement to be performed.
For simple length measurements, the simulator calculates the
value by using (6) in the 3-D image volume coordinates and

LIU et al.: OBSTETRIC ULTRASOUND SIMULATOR WITH TASK-BASED TRAINING AND ASSESSMENT

compares it to the stored value, obtained by a sonographer

true,
if x inside anatomical bounds
Outcome =
(5)
false, if x outside anatomical bounds
d = (p − q ) · s

(6)

where p and q denote the coordinates of two measurement
points of a given anatomical structure, e.g., the fetal femur in
the 3-D image coordinates, and s denotes the voxel space.
F. Ultrasound Console
A software-based console has been implemented, where the
learner is able to select the scan depth (12, 16, 20 cm), ultrasound
probe type (convex array or linear array), and overall gain. These
functions represent the most basic scan settings used in obstetric
ultrasound.
VII. TRAINING MODULES AND PROCEDURE
OF OBSTETRIC ULTRASOUND
The obstetric ultrasound training focuses on the late stage of
the second trimester of pregnancy and the early stage of the third
trimester (24–36 weeks), where the fetus has developed sufficiently so that important anatomical structures can be observed.
In prenatal scanning, the protocol requires the sonographer to
identify fetal and placental position, which are two important
indicators affecting clinical decision making, and then perform
biometric measurements on key anatomical structures, in particularly, biparietal diameter (BPD), abdominal circumference
(AC), and femur length (FL) based on which fetal weight [53]
can be estimated. To provide the basic ultrasound physics background and to learn and practice obstetrics ultrasound scanning
skills, the obstetrics simulator offers three training modules,
each of which contains several training tasks as listed in Fig. 8.
The first module introduces basic ultrasound concepts, such
as tissue density, acoustic impedance, resolution, and artifacts.
It also familiarizes the learner with key aspects of ultrasound
training, the proper use of the transducer, and techniques for
adjusting gain and depth settings. In Module 2, the learner will
practice how to correctly manipulate the transducer so that the
uterus, cervix, fetus, and placenta are observed in the ultrasound
image. This module aims to train the learner to correctly identify
the anatomical structures in the B-mode image and to evaluate
the fetal and placental position in the uterus. In Module 3, the
learner is required to perform biometric measurements, i.e., to
locate and measure important anatomical structures, and then
estimate fetal weight based on these measurements.
The training covered in Modules 2 and 3 is implemented as a
sequence of three steps as depicted in Fig. 9, which the learner
should complete sequentially. Step 1 is the tutorial mode, consisting of a set of separate, prerecorded videos, in which a sonographer demonstrates, using the simulator, how each individual
task in Modules 2 and 3 is completed. Step 2 is the practice
mode, where the learner will acquire and refine his/her scanning skills by identifying anatomical structures and completing
biometric measurements, with the simulator verifying whether
each task was correctly completed or not. The practice mode

Fig. 8.

Training tasks in Modules 1–3.

Fig. 9.

Three step training procedure.

2487

2488

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 10, OCTOBER 2015

uses a set of 3-D image volumes, each obtained from a different pregnant subject. Thus, the learner’s training is equivalent
to scanning several human subjects. In the practice mode, the
simulator provides additional guidance in identifying necessary
anatomical structures, while performing the biometric measurements, as well as informing the learner whether a task was
correctly performed or not.
After the learner has acquired sufficient skills in carrying out
the tasks in Modules 2 and 3, he/she can demonstrate their competence by completing Step 3, which is the test mode. Here, the
training simulator evaluates the learner’s training performance
using the same tasks in step 2, but based on a new 3-D image
volume. In the test mode, the learner only receives the result of
pass or fail from the simulator. The score of pass indicates that
the learner has successfully completed all tasks within stipulated
time slot. Otherwise, the learner receives the score of fail.

VIII. TRAINING PERFORMANCE ASSESSMENT
BY OBSTETRIC ULTRASOUND
A. Landmark Bounds Insertion
An essential component of the training simulator is its ability
to automatically assess whether the learner has correctly identified a specified landmark. This is achieved by using a preinserted surface that surrounds, or bounds, the landmark at a
close distance, where such a surface will be referred to as a “landmark bound.” Every training set contains a series of landmark
bounds, placed by experienced sonographers or determined by
segmentation algorithms. Utilizing these bounds, the simulator
can automatically evaluate the learner’s performance, as well
as provide scanning guidance during the practice. This section
provides two examples of the creation and insertion of landmark
bounds.
In Task 2 of Module 2, the learner is asked to identify the
fetal head from a given image volume as part of the process
of determining fetal position, and in Task 1 of Module 3, the
learner will measure the diameter of the fetal head, referred to
as the BPD. To establish the landmark bound for the fetal head,
an iterative randomized Hough transform [54] designed for 2-D
images is modified to create a 3-D ellipsoid model for the fetal
head of a given 3-D image volume.
In Task 3 of Module 2, the learner is required to locate the
placenta and determine its position. Usually, the placenta in
the uterus is crescent shaped or flat [55]. It is therefore very
challenging to use a single geometrical shape to model the whole
placenta. Therefore, we segmented the whole placenta using
GrowCut [56] on a sequence of 2-D image planes containing
the entire placenta. Then, we used Fang’s approach [48] to create
the placenta’s isosurface with triangular meshes.
Landmark bounds for all other anatomical structures to be
identified, such as thalami, stomach bubble, umbilical vein,
bladder, and cervix, are manually inserted under the guidance
of an experienced sonographer. Each of them is defined as a
bounded surface (a sphere with different radius in current design). The BPD, FL, and AC are also measured by experienced

sonographers and then stored with the above landmark bounds
in the same file.
B. Tasks Assessment
The simulator evaluates the learner’s understanding of medical ultrasound basics in Module 1 by a series of multiple choice
questions randomly selected by the simulator from a pool. For
the training tasks in Modules 2 and 3, the simulator evaluates the
learner’s scanning performance based on whether the learner is
able to:
1) Position the sham transducer so that the 2-D image contains specific anatomical structures required by a given
task and then freeze the 2-D image.
2) Identify specific landmarks by clicking on them with the
mouse on the 2-D image.
3) Carry out specified biometric measurements on the 2-D
image.
4) Answer multiple choice questions associated with a given
task and prompted by the simulator.
For a given biometric measurement task, the simulator focuses on: 1) if the learner has correctly located the 2-D image
needed for performing the measurement and 2) if the measurement is correct or not by comparing the measured value to
the corresponding biometric value obtained by an experienced
sonographer. The simulator gives feedback to the learner regarding the accuracy of the measurement result, as follows: correct (<5% error), less accurate (5%–10% error), and incorrect
(>10% error). This feedback function is only active for the tasks
requiring biometric measurements. As to the landmark identification tasks, the simulator checks if the learner has correctly
identified the specified landmark(s) and/or correctly answered
questions presented by the simulator. The main assessment criteria for the tasks in Modules 2 and 3 are as follows.
Task 1 of Module 2 (Task 2a): The simulator examines if the
selected 2-D image contains cervix and bladder. Otherwise, the
simulator will point out which anatomical structure is missing.
In addition, the learner will need to identify the aforementioned
landmarks by clicking them.
Task 2 of Module 2 (Task 2b): The learner must identify
the fetal head and then determine whether the fetal position is
cephalic, breech, or transverse.
Task 3 of Module 2 (Task 2c): The learner must identify the
placenta and then determine whether the placenta position is
anterior, posterior, previa, or fundal.
Task 4 of Module 2 (Task 2d): The simulator checks if the
learner has correctly measured the four quadrants depths of the
amniotic fluid at correct positions. The learner needs to judge if
the amniotic fluid is oligohydramnios, normal, or polyhydramnios after completing the measurements. If the learner measures
the quadrant depth at a wrong position, the simulator will point
out that error.
Task 1 of Module 3 (Task 3a): The simulator examines first
if the selected 2-D image contains the thalami of the fetal head
and then compares the measured BPD value with the reference
value.

LIU et al.: OBSTETRIC ULTRASOUND SIMULATOR WITH TASK-BASED TRAINING AND ASSESSMENT

Task 2 of Module 3 (Task 3b): The simulator examines first
if the selected 2-D image contains the umbilical vein and stomach bubble and then check if the anterior–posterior diameter
is roughly at right angle to the lateral diameter and, finally,
compares the measured AC with the reference value.
Task 3 of Module 3 (Task 3c): The simulator examines first if
the selected 2-D image contains both ends of a femur and then
compares the measured value with the reference value.
Task 4 of Module 3 (Task 3d): Once the learner has completed
Tasks 1–3 of Module 3, the simulator loads the measured BPD,
AC, and FL values automatically and then calculates the fetal
weight based on these values [57]. In this task, if the estimate
obtained from the learner’s measurements is within ±10% of
the reference value, the simulator considers the fetal weight to
have been correctly estimated. The learner needs to determine if
the fetal development is appropriate for gestational age, or there
is intrauterine growth restriction or macrosomia, based on the
completed biometric measurements.
IX. EVALUATION OF SIMULATOR PERFORMANCE
The simulator is evaluated based on the following qualities: 1)
an adequate image generation and rendering speed for the simulator, 2) a realistic 2-D ultrasound image quality and achievable
biometric measurement, and 3) a structured training with skillbased evaluation by trained sonographers.
First, we present the results of the rendering speed testing
of the simulator on two different laptops with different hardware configurations. Second, we compare 2-D ultrasound images generated from the simulator to actual ultrasound images
acquired from a pregnant subject at the same time that the 3-D
image volumes were acquired. Finally, we present a preliminary evaluation of the obstetric training by a small group of
experienced obstetricians.
A. Simulator Rendering Speed Testing
In the simulator design, the 2-D image generation and rendering speed directly influence the training experience and realism
of the simulator. We tested the simulator on two moderately
priced laptops with different hardware configurations.
1) Laptop A: Core i7-3520 at 2.90 GHz, 8 GB memory,
Windows 7, 64 bit.
2) Laptop B: Core i3-2350 at 2.3 GHz, 6 GB memory, Windows 7, 64 bit.
The rendering speeds on the two laptops are calculated in
frames per second (frames/s) based on the total time of rendering 500 frames, with the results presented in Table I. These
numbers also include the time required for virtual torso and
virtual transducer rendering. We configured the simulator to
render 2-D images at speeds of 33 and 50 frames/s. For the
lower rendering speed, the simulator performance was almost
the same on two platforms, but laptop A performed much better
than laptop B if the rendering speed was set to 50 frames/s,
mainly resulting from the difference in the CPUs and memory
sizes of the two laptops. The results in Table I show that the
simulator is able to generate and render 2-D images at a speed
above 30 frames/s. This satisfies our design goal of greater

2489

TABLE I
RENDERING SPEED OF 2-D ULTRASOUND IMAGES ON LAPTOP A AND B

Frame Rate
Total Rendering
Time (s)

A (33 frames/s)

B (33 frames/s)

A (50 frames/s)

B (50 frames/s)

30.17
16.59

29.48
16.95

39.37
12.70

30.60
16.34

TABLE II
CLINICAL VERSUS SIMULATED BIOMETRIC MEASUREMENTS (DIMENSIONS
IN CM)
Image Volume
1
2

Image Type

BPD

AC

FL

Clinical
Simulated
Clinical
Simulated

6.48
7.6
8.31
8.3

22.31
24.67
28.91
23.43

4.68
5.21
6.21
5.6

than 25 frames/s, which is a widely accepted requirement for
a smooth visual presentation and minimum interfering motion
blur or jitter. The image volumes used for performance evaluation have an average size of 800 × 550 × 900 voxels. The voxel
dimensions are 0.49 mm in the x-, y- and z-directions of the 3-D
image volume coordinates.
B. Comparison Between Simulator Generated and Actual
Biometric Measurements and 2-D Images
Given that biometric measurements are an important aspect
of obstetric ultrasound training, we have compared the values
of BPD, AC, and FL measured on the simulator-generated images against the values of BPD, AC, and FL measured on the
clinical ultrasound images obtained, while scanning the human
subjects. This comparison of simulated images with real ones is
a demanding test, because the 3-D image volume is constructed
from 2-D images acquired from multiple linear scans, while the
real images for measurements are obtained directly. Even for the
same pregnant subject, both the fetal biometric measurements
and 2-D images used for the measurements, vary from one scan
to the next, due to unavoidable fetal movements.
The clinical fetal measurements were obtained with a Philips
iU22 ultrasound scanner. The sonographer who carried out the
initial fetal measurements on the pregnant subjects was not the
sonographer who performed the measurements on the simulator.
The biometric measurements for two image volumes performed
on the simulator-generated images and on the clinical ultrasound
images are presented in Table II.
We can see the simulator-derived measurements are not fully
consistent with clinical results. However, the level of error is
deemed acceptable for ultrasound training, considering that the
clinical and simulated measurements were not taken at the exact same positions and orientations and that sonographers may
define the anatomical locations used in biometric measurements
slightly differently. That has been confirmed by the experienced
sonographer who performed the measurements on the simulated
images.

2490

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 10, OCTOBER 2015

TABLE III
SCANNING TIMES FOR SUCCESSFUL COMPLETION OF MODULES 2 AND 3 TASKS
ON IMAGE VOLUMES 1 AND 2 (TIMES IN S)
Expert 1
Task 2b
Task 2c
Task 2d
Task 3a
Task 3b
Task 3c

Fig. 10.

Comparison of clinical images and simulated images.

The realism of 2-D images is critical to the user experience, so
we compare simulator-generated 2-D images to the corresponding images directly from the Philips iU22 ultrasound scanner.
The images required for measuring BPD, AC, and FL were
chosen for this comparison. Fig. 10 presents the comparison
between clinical images and simulator-generated images from
same subject (volume 2). The first row contains fetal skull images for BPD measurement. The shapes of the skull outline in the
two images are not exactly the same, which may result from the
fact that the simulated image is generated from slightly different transducer positions and orientations, compared to the image
obtained directly from the ultrasound scanner. The second row
of images contains the fetal abdomen. We can see clearly the
stomach bubble (a round dark region at the lower of abdomen)
and umbilical vein (above the stomach bubble and appearing
like a “J”), which are two important references to judge if the
2-D image is suitable for the AC measurement. The third row
contains images required for the measurement of FL.
C. Preliminary Evaluation of the Simulator as a Training Tool
For the preliminary determination of the suitability of the
ultrasound simulator as a valid training tool, we undertook an
evaluation of the following learning criteria: 1) are the tasks in
Modules 2 and 3 achievable, 2) do the tasks constitute an integrated learning experience, and 3) do the simulator provide a
realistic scanning experience and good image quality. Criterion
1 was obtained by measuring the completion times for Modules 2 and 3 tasks, while Criteria 2 and 3 were assessed via a

10
7
102
221
20
24

8
24
32
248
23
18

Expert 2

Expert 3

20
10
63
46
17
36

6
11
50
13
18
18

9
11
20
75
26
12

6
21
22
13
16
15

questionnaire. The evaluation of all three criteria was carried
out by three experienced obstetrics sonographers from the University of Massachusetts Medical Center.
For Criterion 1, we evaluated the ability of the ultrasonographers to successfully complete six tasks in Modules 2 and 3,
where each expert scanned two image volumes, volumes 1 and
2. We recorded the time for successful completion of each task
as shown in Table III. The times on task for volumes 1 and 2 are
listed in the left and right columns under each task, respectively.
The results indicate that the tasks required different amounts
of time and effort; nonetheless, the times required for the task
completion were fairly consistent across the three experts, with
the exception of the time spent on task 3a (BPD measurement)
by expert 1 who took longer time, mainly because we defined a
tight bound around the thalami, thus making an error message
for the BPD measurement likely.
From the responses in the questionnaire, all three sonographers agreed that the tasks were easily performed and well organized in sequence. In addition, the sonographers considered
the simulated images to be adequately realistic for ultrasound
training and found the simulator to provide a fully adequate
level of processing speed.
The sonographers further noted that the simulator had the
potential for becoming a good supplemental training tool for
medical schools students and resident doctors and that the training tasks were appropriate for obstetrics training. One sonographer indicated that the absence of a beating fetal heart in the
ultrasound image of the simulator somewhat detracted from the
realism.
X. DISCUSSION
The goal of this study has been to develop an affordable
simulator that is able to provide a realistic scanning experience.
Making the simulator affordable requires that the simulator software is able to run on an ordinary laptop or PC. In addition, the
low-cost aspect dictates the design of the 5-DoF tracking system, a requirement met by using an Anoto pen and an IMU.
The component cost of the IMU, the Anoto pen, the PSS, and
transducer case totals less than US $300.
The PSS provides the learner with a realistic scanning experience, that is, the learner can continuously scan an extended
region, while allowing angling and/or rotation of the sham transducer. This feature is critical to proper training in psychomotor
skills. To provide further realism to the scanning experience, a

LIU et al.: OBSTETRIC ULTRASOUND SIMULATOR WITH TASK-BASED TRAINING AND ASSESSMENT

display window containing a virtual torso with a virtual transducer allows the learner to see the position and orientation of the
(virtual) transducer on the (virtual) abdomen. The customized
software design makes the simulator able to run on a regular
laptop with a frame rate better than 25 frames/s.
As mentioned, the obstetric simulator has the notable strength
of supporting continuous scanning over an extended simulated
body surface, requiring training volumes assembled from overlapping 3-D scans. This presents a challenge to the registration
algorithm that assembles the individual 3-D volumes into one
large image volume, due to both fetal and maternal movement
during scanning as well as the occasional heavy shadowing in
2-D images. To that end, we developed a new method that can
mosaic 3-D ultrasound volumes based on MRF.
The obstetrics simulator is designed to provide self-paced
simulator-assisted training on the basic or even the intermediate
obstetric ultrasound level by integrating training guidance and
scanning evaluation in the simulator software. We have formulated our training tasks and assessment criteria based on standard practice of obstetric ultrasound. Specifically, the structured
training tasks aim to train the learner in the proper obstetric ultrasound examination sequence, identification of critical anatomical structures, and biometric measurements. This is achieved
by inserting landmark bounds for all anatomical structures to be
identified, a task either implemented with algorithms or under
the guidance of an obstetrics sonographer.
A preliminary evaluation was performed by a group of three
experienced sonographers. They completed six specified tasks in
a reasonable time by following the instructions provided by the
simulator. Expert 1 took longer time on the BPD measurement
because we initially defined a tight bound for the thalami, with
the effect that the BPD could only be correctly measured over
a narrow range of transducer positions. To remedy this, we
widened the bounds to include the whole landmark.
Training in detection of fetal anomalies is indeed feasible with
the training simulator described here, but would require such
fetal anomalies to have been captured when acquiring image
volumes for training. This in turn would require a large number
of pregnant women to be scanned.
The training simulator design described in this paper, with
some modifications, is well suited for adaption to ultrasound
training in other medical specialties. For example, the training
simulator can be adapted to emergency medicine, especially for
abdominal injuries, where the same PSS can be utilized. Here,
the challenge lies in the production of training volumes. Since
time-consuming scanning of injured individuals would not be
feasible, mosaicked scans of various normal individuals would
be utilized, followed by organ boundary segmentation and injury
simulation by numerical techniques. The simulator can also be
adapted for training in ultrasound guided procedures, where a
second Anoto pen with force sensing can be used to model
the needle and where integrated force sensing will be used to
simulate the needle tip progression across tissue layers.
XI. CONCLUSION
In this paper, we have described a new low-cost portable obstetric ultrasound simulator with integrated self-paced training.

Fig. A1.

2491

Procedure for generating the VSS and the VAS.

This low-cost design makes the personal ownership of the simulator feasible, which in turn allows obstetric ultrasound training
to be pursued at an individual pace. The use of extended 3-D ultrasound image volumes and 5-DoF tracking hardware gives the
learner a realistic scanning experience. The integrated obstetric ultrasound training tasks and automated assessment allow
the learner to practice the scanning skills with multiple image
volumes under the simulator’s guidance. Based on the feedback
from the sonographers who participated in our evaluation, the
simulator has the potential to be a good supplementary training
tool for medical school students and resident doctors.
A near term development of the simulator involves the integration of a beating fetal heart into the 3-D image volumes, for
which the 4-D images material has been acquired. An additional
development involves the design of automated segmentation and
modeling algorithms to improve efficiency and accuracy of the
insertion of landmark bounds. An evaluation of the training efficacy of the simulator using medical school students with little
obstetric ultrasound experience is planned.
APPENDIX I
The generations of the VSS and the VAS involve several coordinate systems, such as world coordinates, the PSS coordinate,
3-D image volume coordinates, etc. Given that the VSS and VAS
are directly derived from the abdominal image surface (AIS) of
a 3-D image volume, all computations in Appendix I are based
on the Cartesian coordinate system for the original 3-D image
volume (image coordinates), which was established during the
3-D image volume generation.
A. Generation of VSS
Both the VSS and the VAS are specified based on the geometry of the smoothed AIS using the Newton–Gauss nonlinear
(NGNL) algorithm [58]. As a general rule, an AIS cannot directly generate the corresponding VAS from a given image volume due to the deviations from an ellipsoidal shape (even after
smoothing) and the limited number of vertices of AIS. Therefore, the process of generating the cylinder-to-ellipsoid model
has been optimized as shown in Fig. A1.
The first step is to determine the parameters of the VSS by
a LSF of the VSS to the AIS through NGNL algorithm (see
step 1 in Fig. A1). Specifically, we determine the radius, spanning angle, and cylinder axis of the VSS. Note that the VSS is
coaxially aligned to the PSS, but has different dimensions and
spanning angles. In general, the z-axis (cylinder axis) of the VSS

2492

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 10, OCTOBER 2015

is initially not parallel to the z-axis of the image coordinates.
Second, we compute a transformation matrix R by aligning the
VSS cylinder axis to z-axis of image coordinates and then transform the AIS (see step 2 in Fig. A1). The purpose of this step
is to simplify the computation in step 3 by restricting the parameters that can be modified of the VAS only to the lengths of
ellipsoid axes, instead of also including the rotation, translation,
and axes length parameters. The matrix of R−1 will be integrated
into probe driver to offset the AIS transformation in this step.
Third, we generate a LSF VAS from the transformed AIS using
an NGNL algorithm, where the VAS has same parameters as
VSS except for the radii, which are the ellipsoid axes lengths
in the image coordinates (see step 3 in Fig. A1). In addition,
its major axis is coaxially aligned with the cylinder (VSS) axis.
Restricting the number of VAS DoF also guarantees that we can
obtain VAS successfully despite the limitation of 3-D image
volumes. Finally, the PSS and the VSS are normalized for later
transformation.
B. Generation of VSS
An arbitrary point (xc , yc , zc ) on the cylinder surface that
computes the final VSS can be expressed parametrically as follows:
⎡ ⎤
⎡
⎤ ⎡ ⎤
xc
r cos θ
x0
⎢ ⎥
⎢
⎥ ⎢ ⎥
(A1)
⎣ yc ⎦ = Rx ∗Ry ∗ ⎣ r sin θ ⎦ + ⎣ y0 ⎦
zc

cosθy

⎢
Ry = ⎣ 0

−sinθy

0

1

0

sinθy

1

0

0

cosθy

(A3)

To find the cylinder that is the LSF to the AIS, we assume the
cylinder to be in a fixed position and instead transform the AIS
in the following calculations. The fixed cylinder is described as
⎡ ⎤ ⎡
⎤
xc
r cos θ
⎢ ⎥ ⎢
⎥
(A4)
⎣ yc ⎦ = ⎣ r sin θ ⎦ .
zc

⎡

⎤

vxi

⎤

⎡

⎢
⎢  ⎥
⎥ ⎢
⎢ v ⎥ = ⎢ vy i ⎥ + ⎢
⎣
⎣ yi ⎦
⎦ ⎣
vz i

⎤

0

⎥
⎥,1 ≤ i ≤ N
⎦

0

s

First, the AIS, which is described in terms of vertices, are
translated by a vector vt = (0, 0, –zcent ) as shown in (A5),

,vy i , vz i ) represent ith initial and
where (vxi , vy i , vz i ) and (vxi
translated vertex of the AIS, respectively. N is total number of
the AIS vertices. The variable zcent is obtained from the AIS

(A5)

−zcent
⎤

vz i
⎡

N
1 
vxi ⎥
⎢
⎡
⎤
⎢ N i=1
⎥
xcent
⎢
⎥
N
⎢
⎥

⎢
⎥
1
⎢
⎥
⎢ ycent ⎥ = ⎢
v
⎥ , 1 ≤ i ≤ N.
y
i
⎣
⎦
⎢N
⎥
i=1
⎢
⎥
⎢
⎥
N
zcent
⎣ 1 
⎦
vz i
N i=1

(A6)

Thus, we use a five-parameter set s = (θx , θy , xt , yt , r), given
in (A7), to manage the cylinder orientation and position. The
solution of (A7) defines a cylinder that is a LSF to the corresponding AIS. Similar to (A1), θ is a free variable (0 ≤ θ < 2π);
L is the length of the cylinder; Rx and Ry are rotation matrices;
r is the cylinder radius; (xt , yt , 0) is a point on the axis of the
cylinder
⎡

xc

⎤

⎡

r cos θ

⎤

⎡

xt

⎤

⎢ ⎥
⎢
⎥ ⎢ ⎥
⎣ yc ⎦ = Rx ∗ Ry ∗ ⎣ r sin θ ⎦ + ⎣ yt ⎦ .

(A7)

0

L

To solve it, the Newton–Gauss nonlinear method is used,
which requires an initial guess. The original AIS suggests that
the cylinder axis is roughly parallel to z-axis, so we set the
initial guess as θx = θy = 0, xt = −xcent , yt = −ycent , r = c,
where c is a constant number and associated with the 3-D image
volume. We define a vector d such that the ith scalar is the
distance of ith vertex on the abdominal surface to the cylinder
axis; hence, this vector can be written as
⎡

dxi

⎤

⎛⎡


vxi

⎤

⎡

−xt

⎤⎞

⎢
⎥
⎥ ⎢
⎜⎢
⎥⎟


⎣ dy i ⎦ = Ry ∗ Rx ∗ ⎝⎣ vy i ⎦ + ⎣ −yt ⎦⎠ ,

⎤
⎥
⎦.


vxi

zc

where θ is a free variable (0 ≤ θ < 2π); L is the length of the
cylinder; (x0 , y0 , z0 ) is a point on the axis of the cylinder; r
is the cylinder radius; Rx and Ry are rotation matrices derived
from θx and θy that represent rotation angles of the cylinder axis
around x- and y-axes, respectively, as given in (A1) and (A3).
The parameters of L, r, x0 , y0 , z0 , θx , and θy are fixed values
for a specific cylinder
⎡
⎤
cosθx −sinθx 0
⎢
⎥
cosθx 0 ⎦
Rx = ⎣ sinθx
(A2)
⎡

⎡

z0

L

0

centroid (xcent , ycent , zcent ) as shown in (A1)

vz i

dz i

1≤i≤N

0

(A8)
where dxi , dy i , dz i are the ith distance that is projected to x-,
y-, and z-axes. Rx and Ry are inverse matrices of Rx , Ry . The
distance of a vertex to the cylinder surface is

fi = dxi

dy i


dz i ∗ N t − r

where
⎡



dxi

⎢
⎢ d2xi + d2y i
⎢
d
Nt = ⎢
⎢  yi
⎢
⎣ d2xi + d2y i
0

⎤
⎥
⎥
⎥
⎥,
⎥
⎥
⎦

1 ≤ i ≤ N.

(A9)

LIU et al.: OBSTETRIC ULTRASOUND SIMULATOR WITH TASK-BASED TRAINING AND ASSESSMENT

2493

To minimize the f = [f1 , f2 , . . . , f i, . . . , fN ], (1 ≤ i ≤ N ),
we construct a Jacobian matrix as
⎡ ∂f
∂f1
∂f1
∂f1 ∂f1 ⎤
1
⎢ ∂s1
∂s2
∂s3
∂s4 ∂s5 ⎥
⎥
⎢
⎢···
·
·
·
·
·
·
··· ··· ⎥
(A10)
J =⎢
⎥
⎥
⎢
⎦
⎣ ∂fN ∂fN ∂fN
∂fN ∂fN
∂s1
∂s2
∂s3
∂s4 ∂s5
where
⎧
⎛⎡  ⎤ ⎡ ⎤⎞
xt
vxi
⎪
⎪
⎪
⎪
⎢
⎜
⎢
⎥
⎥⎟
∂f
⎪
i
⎪
⎢ v  ⎥ − ⎢ yt ⎥⎟
⎪
= N t(i) ∗ Ry ∗ dRx ∗ ⎜
yi ⎦
⎪
⎣
⎝
⎣
⎦⎠
⎪
∂s
⎪
⎪ 1
⎪

⎪
v
0
⎪
⎪
⎛⎡ z i ⎤ ⎡ ⎤⎞
⎪
⎪
x
v
⎪
t
xi
⎪
⎪
⎪
⎢
⎜
⎢
⎥
⎥⎟
⎪
∂f
i
⎪
⎢ v  ⎥ − ⎢ yt ⎥⎟
⎪
= N t(i) ∗ dRy ∗ Rx ∗ ⎜
⎪
yi ⎦
⎣
⎝
⎣
⎦⎠
⎪
∂s
⎪
2
⎪
⎪

⎪
⎪
vz i
0
⎪
⎨
⎡
⎤
−1
⎢
⎥
⎪
∂fi
⎪
⎥
⎪
0
= N t(i) ∗ Ry ∗ Rx ∗ ⎢
⎪
⎪
⎣
⎦
⎪
∂s3
⎪
⎪
⎪
⎪
0
⎪
⎪
⎡
⎤
⎪
⎪
0
⎪
⎪
⎪
⎪
⎢
⎥
⎪
⎪ ∂fi = N t ∗ R ∗ R ∗ ⎢ −1 ⎥
⎪
(i)
y
x
⎪
⎣
⎦
⎪
∂s4
⎪
⎪
⎪
⎪
0
⎪
⎪
⎪
⎪
∂f
i
⎪
⎩
= −1
∂s5
dRx , dRy are the derivatives of Rx , Ry
⎤
⎡
1
0
0
⎥
⎢
dRx = ⎣ 0 −sinθx −cosθx ⎦
0
⎡
⎢
dRy = ⎣

−sinθx

cosθx

−sinθy

0

cosθy

0

1

0

−cosθy

(A11)

⎤
⎥
⎦.

(A12)

0 −sinθy

Best-fit cylinder to abdominal surface.

Fig. A3.

Abdominal surface in standard position.

points on the pretransformed and posttransformed LSF cylinder
surface, respectively; (x0 , y0 , z0 ) is the point on the cylinder
axis and closest to the centroid of abdominal surface. As shown
in Fig. A3, the axis of cylinder passes through the origin and is
aligned to the z-axis
⎡

The five-parameter set s is continuously updated using (A13),
where p is the solution of (A14)
s = s+p

(A13)

p = − f /J .

(A14)

Once the tolerance level t, computed in (A15), is less than a
predefined value (0.01 in our case), the update process terminates, allowing a LSF cylinder to be defined as shown in Fig. A2
and described using (A7)
t = norm(p)/norm(s).

Fig. A2.

(A15)

To simplify generation of VAS and calculate the cylinder
angle and length, the LSF cylinder and AIS are transformed
as shown in (A16), where (xc , yc , zc ) and (xc , yc , zc ) represent

xc

⎤

⎛⎡

xc

⎡

⎤

x0

⎡

⎤⎞

r cos θ

⎤

⎥
⎜ ⎢ ⎥ ⎢ ⎥⎟ ⎢
⎢ ⎥
⎢ yc ⎥ = R2 ∗ R1 ∗ ⎜ ⎢ yc ⎥ − ⎢ y0 ⎥⎟ = ⎢ r sin θ ⎥ .
⎦
⎝ ⎣ ⎦ ⎣ ⎦⎠ ⎣
⎣ ⎦
zc

zc

s

z0

(A16)
The cylinder segment angle θv cm ax , as shown in Fig. A4, is
determined by two AIS vertices (p1 and p2 ), which can yield
maximal angle. The angle θv cm ax is calculated by (A17) using
p1 and p2 which are the projections of p1 and p2 on the xy plane
that passes the origin. The length of cylinder (lc ) is determined
by the maximal length between two AIS vertices along the zaxis. The final VSS is shown in Fig. A5
θv cm ax = cos

−1



p1 − p2
|p1 | |p2 |


.

(A17)

2494

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 10, OCTOBER 2015

If we define an N × 3 matrix f whose ith row vector is the
distance from the ith vertex (vxi , vy i , vz i ) of the AIS to a point
(xei , yei , zei ) on the ellipsoid surface that minimizes the distance
between them
⎤ ⎛⎡
⎤ ⎡
⎤⎞
⎡
fi1
vxi
xei
⎥
⎥ ⎢
⎥⎟
⎢
⎜⎢
f i = ⎣ fi2 ⎦ = ⎝⎣ vy i ⎦ − ⎣ yei ⎦⎠ .
(A19)
fi3

Fig. A4.

Cylinder cross-sectional angle.

Fig. A6.

Virtual cylinder segment defines the VSS as a LSF to a given AIS.

⎧
⎡
⎤
− cos θ sin φ
⎪
⎪
⎪
⎪
⎢
⎥
⎪
∂fi
⎪
⎥
⎪
0
=⎢
⎪
⎣
⎦
⎪
∂s1
⎪
⎪
⎪
⎪
⎪
0
⎪
⎪
⎡
⎤
⎪
⎪
0
⎪
⎪
⎨ ∂f
⎢
⎥
i
− sin θ sin φ ⎥
=⎢
⎣
⎦,
⎪
∂s2
⎪
⎪
⎪
⎪
0
⎪
⎪
⎡
⎤
⎪
⎪
0
⎪
⎪
⎪
⎪ ∂fi
⎢
⎥
⎪
⎪
⎪
0 ⎥
⎪ ∂s = ⎢
⎣
⎦
⎪
3
⎪
⎪
⎩
− cos φ

1≤i≤N.

The parameter set s is continuously updated using (A13) and
(A14) until the tolerance t in ((A15)) reaches the predefined
value (0.01 in our case). The initial guess of the ellipsoid radii
are set to half of the AIS lengths along x-, y- and z-axes. The LSF
ellipsoid (see Fig. A6) is actually coaxial with the LSF cylinder. In our preliminary studies, all available 3-D image volumes
have similar radii along the x- and y-axes, so we replace a and
b with their average value in the position transformation, as
described in Appendix II. This makes VSS and VAS share the
same segment angle θv cm ax and simplify the position transformation. The VAS length is equal to the VSS length. The final
VAS is shown in Fig. A7.

Best-fit ellipsoid.

C. Generation of VSS
Similar to the generation of the VSS, an ellipsoid that is a LSF
to the transformed AIS can be simply represented using (A18),
where a, b, and c are the radii of a specific ellipsoid along the
x-, y-, and z-axes, ϕ and θ are two free variables 0 ≤ ϕ < π,
0 ≤ θ < 2π as shown in Fig. A6. Thus, we can use a parameter
set s = (a, b, c) to control the ellipsoid geometry.
⎡ ⎤ ⎡
⎤
xe
a cos θ sin ϕ
⎢ ⎥ ⎢
⎥
(A18)
⎣ ye ⎦ = ⎣ b sin θ sin ϕ ⎦ .
ze

zei

To minimize the matrix f, we construct another Jacobian matrix in equation (A20). N is the total number of abdominal surface vertices
⎡
⎤
∂f1
∂f1
∂f1
⎢ ∂s1
∂s2
∂s3 ⎥
⎢
⎥
⎢···
···
··· ⎥
(A20)
J =⎢
⎥
⎢
⎥
⎣ ∂fN ∂fN ∂fN ⎦
∂s1
∂s2
∂s3
where

Fig. A5.

vz i

c cos ϕ

APPENDIX II
A. Position Transformation
1) Position Transformation From the PSS to the VSS: The
PSS is in the form of a cylindrical segment with fixed dimensions and spanning an angle of 120o , while the VSS is a best
fit to the given image volume, under the constraints of cylindrical segment geometry with dimensions and spanning angle
as variable parameters. Thus, VSS and PSS need to be scaled
so they can fully map to each other. The PSS and VSS length

LIU et al.: OBSTETRIC ULTRASOUND SIMULATOR WITH TASK-BASED TRAINING AND ASSESSMENT

Fig. A7.

Fig. B1.

2495

Fig. B2.

Deviation angles in the cross section of the VSS and the VAS.

Fig. B3.

Dynamic PSS-based local coordinate system.

Fig. B4.

Identity quaternion in PSS coordinates.

Virtual ellipsoid segment defines the VAS as a LSF to a given AIS.

Deviation angles in the cross section of the VSS and the PSS.

along the cylinder axis are normalized to the range [−0.5, 0.5].
The central angle θv cm ax of VSS obtained from Appendix I
is scaled to the PSS spanning angle of 120° so that a specific
deviation angle (θr c ) from the y-axis (middle line) of the PSS
will yield the corresponding deviation angle (θv c ) on the VSS
through (B1) as shown in Fig. B1. The normalized coordinate
(zr c ) along cylinder axis (z-axis) of the PSS becomes the corresponding normalized coordinate (zv c ) on the VSS as shown in
(B2)
θr c
θv c
=
2π/3
θv cm ax

(B1)

zr c = zv c .

(B2)

2) Position Transformation From the VSS to the VAS: For
a specific position on the VSS, its unscaled coordinate (zv c )
on z-axis is used to calculate angle ϕ in (A18). The θv e can
be obtained in (B3), and then plugged into ((A18) to calculate
the x- and y-coordinates. All position transformations are actually referenced to the 3-D image volume coordinates, so the
(x, y, z{ vc}) is the position that guides 2-D ultrasound image
extraction from the 3-D image volume
θv e = θv c .

(B3)

B. Orientation Transformation
The sham transducer orientation is measured in the IMU in the
form of quaternions [59] that reflect its orientation in world coordinates. As the IMU aligns to the magnetic north and the center
of the earth, it will output an identity quaternion of (1, 0, 0, 0).
However, to determine the sham transducer orientation relative
to the PSS, the IMU’s world coordinates need to be transformed

into a dynamic PSS-based local coordinate system defined by
the normal (y-axis) to the PSS at the point of contact of the
sham transducer, the long axis (z-axis) of the PSS and a vector
(x-axis) tangential to the PSS and orthogonal to the other two
axes as illustrated in Fig. B2. A specific transducer orientation
is calculated through two consecutive steps: 1) the transducer
is only rotated along the PSS z-axis from identity quaternion
orientation, as shown in Fig. B4, to a point on the PSS and then
2) rotated in the local coordinates at that point to make a smaller
adjustment.
Assume that the quaternion Qp is the orientation of the sham
transducer at a specific position on the PSS referenced to world
coordinates. Qp can then be decomposed into three parts according to the following three coordinate operations as
Qp = Qp1 ∗ Qp2 ∗ Qp3 .

(B4)

Qp1 is defined as the quaternion for the orientation of PSS in
world coordinates; the calculation of Qp1 is performed through
an autocalibration routine, described in the following section;
Qp2 is the quaternion that describes the sham transducer rotation only around z-axis of the PSS starting from the identity
quaternion in the PSS coordinates as shown in Fig. B4. This will
generate a dynamic PSS-based local coordinate system at that
specific position (see Fig. B3). Qp2 is derived from the deviation
angle (θr c in Fig. Fig. B1). Qp3 is the rotation referenced to this

2496

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 10, OCTOBER 2015

local coordinate system. By premultiplying the inverse of Qp1
and Qp2 , the orientation referenced to local coordinate Qp3 is
obtained as
−1
Qv = Q−1
p2 ∗ Qp1 ∗ Qp1 ∗ Qp2 ∗ Qp3 = Qp3 .

(B5)

In the position transformation, deviation angle (θr c ) on the
PSS is same as deviation angle (θv e ) on the VAS, so we can
directly use Qv , which preserves the orientation referring to the
dynamic PSS-based local coordinate system to obtain quaternion Q
Q = Qv e ∗ Qv .

(B6)

C. Auto calibration
When the transducer is roughly normal to the PSS in the local coordinates, the quaternion Qp3 is mainly determined by
the transducer spinning angle around its axis. Since the spinning angle can be obtained from the digital Anoto pen, Qp3 is
calculated through an Euler to quaternion transformation.
As Qp2 is derived from the deviation angle (θr c ) and Qp is
the output of the transducer, the orientation of the PPS Qp1 can
be obtained as
−1
−1
−1
Qp1 = Qp ∗ Q−1
p3 ∗ Qp2 = Qp1 ∗ Qp2 ∗ Qp3 ∗ Qp3 ∗ Qp2 .
(B7)

ACKNOWLEDGMENT
The authors would like to thank sonographers D. Cascione
and K. Fitzpatrick from the UMass Memorial Medical Center
for patient scanning, training video production, and extensive
clinical advice. They would also like to thank Anoto Corporation, in particular, to P. Ericson, for invaluable software help,
and, finally, J. Deetz at Visual Magnetics for assistance in producing Anoto pattern on vinyl sheets and to R. Edmiston at
the Sound Technology for providing the transducer shells are
greatly appreciated.
REFERENCES
[1] T. L. Szabo, Diagnostic Ultrasound Imaging, Inside Out, 2nd ed. San
Francisco, CA, USA: Academic, 2013, p. 25.
[2] D. C. Levin et al., “Noncardiac point-of-care ultrasound by nonradiologist physicians: How widespread is it?” J. Amer. Coll. Radiol., vol. 8,
pp. 772–775. 2011.
[3] C. L. Moore and J. A. Copel, “Point-of-care ultrasonography,” N. Engl. J.
Med., vol. 364, pp. 749–757, 2011.
[4] R. M. Satava, “Identification and reduction of surgical error using simulation,” Minimally Invasive Ther. Allied Technol., vol. 14, pp. 257–261,
2005.
[5] K. H. Henriksen and E. Dayton, “Issues in the design of training for quality
and safety,” Quality Safety Health Care, vol. 15, pp. i17–i24, 2006.
[6] S. B. Issenberg et al., “Features and uses of high-fidelity medical simulations that lead to effective learning: A BEME systematic review,” Med.
Teacher, vol. 27, pp. 10–28, 2005.
[7] R. Gardner and D. B. Raemer, “Simulation in obstetrics and gynecology,”
Obstetr. Gynecol. Clin. North Amer., vol. 35, pp. 97–127, 2008.
[8] R. A. Hoppmann et al., “An integrated ultrasound curriculum (iUSC) for
medical students: 4-year experience,” Crit. Ultrasound J., vol. 2, pp. 1–12,
Feb. 2011.
[9] H. Maul et al., “Ultrasound simulators: Experience with the SonoTrainer
and comparative review of other training systems,” Ultrasound Obstetr.
Gynecol., vol. 24, pp. 581–585, 2004.

[10] C. Terkamp et al., “Neue konzepte in der gastroenterologischen sonographieausbildung durch schulung am ultraschallsimulator (new concepts in ultrasound education in gastroenterology by simulator training),”
Zeitschrift für Gastroenterologie, vol. 42, pp. 1311–1314, 2004.
[11] K. Seitz, “Zur qualitat der oberbauchsonographie (quality of abdominal ultrasound),” Ultraschall in der Medizin-Eur. J. Ultrasound, vol. 27,
pp. 217–219, 2006.
[12] C. Terkamp et al., “Simulation of abdomen sonography. Evaluation
of a new ultrasound simulator,” Ultraschall in der Medizin, vol. 24,
pp. 239–244, 2003.
[13] R. Pittini et al., “Teaching invasive perinatal procedures: Assessment of a
high fidelity simulator-based curriculum,” Ultrasound Obstetr. Gynecol.,
vol. 19, pp. 478–483, 2002.
[14] R. K. Latif et al., “Teaching aseptic technique for central venous access
under ultrasound guidance: A randomized trial comparing didactic training
alone to didactic plus simulation-based training,” Anesthesia Analgesia,
vol. 114, no. 3, pp. 626–633, 2012.
[15] T. Blum et al., “A review of computer-based simulators for ultrasound
training,” Simul. Healthcare, vol. 8, pp. 98–108, 2013.
[16] P. Bayer et al., “New ultrasound simulation system: A method for training
and improved quality management in ultrasound examination (in German),” Z. Geburtshilfe Neonatal., vol. 205, pp. 213–217, 2001.
[17] R. Marquardt et al., “Ultraschalldiagnostik mit dem SonotrainerZwischenbilanz einer praxinahen Fortbildung,” Frauenarzt, vol. 45,
pp. 660–662, 2004
[18] D. Aiger and D. Cohen-Or, “Real-time ultrasound imaging simulation,”
Real-Time Imag., vol. 4, pp. 263–274, 1998.
[19] H. L. Nisenbaum et al., “Ultrasound simulator (UltraSim) as an evaluation
tool of residents scanning skills: A pilot study,” presented at the Amer.
Inst. Ultrasound Med. Conf., San Francisco, CA, USA, Apr. 2000.
[20] Y. Shen et al., “The Wii transrectal ultrasonography simulator,” presented
at the 24th Eng. Urol. Soc. Annu. Meet., Chicago, IL, USA, Apr. 2009, p.
31.
[21] T. Ungi et al., “Perk tutor: An open-source training platform for
ultrasound-guided needle insertions,” IEEE Trans. Biomed. Eng., vol. 59,
no. 12, pp. 3475–3481, Dec. 2012.
[22] O. Goksel et al., “Prostate brachytherapy training with simulated ultrasound and fluoroscopy images,” IEEE Trans. Biomed. Eng., vol. 60,
no. 4, pp. 1002–1012, Apr. 2013.
[23] R. Shams et al., “Real-time simulation of medical ultrasound from CT
images,” in Proc. Int. Conf. Med. Imag. Comput. Comput.-Assisted Intervention Conf., 2008, vol. 11 (Pt 2), pp. 734–741.
[24] Y. Zhu et al., “A virtual ultrasound imaging system for the simulation
of ultrasound-guided needle insertion procedures,” in Proc. Med. Image
Understand. Anal. Annu. Conf., 2006, pp. 61–65.
[25] B. Burger et al., “Real-time GPU-based ultrasound simulation using
deformable mesh models,” IEEE Trans. Med. Imag., vol. 32, no. 3,
pp. 609–618, Mar. 2013.
[26] G. Reis et al., “Towards a virtual echocardiographic tutoring system,”
in Visualization in Medicine and Life Sciences. New York, NY, USA:
Springer, 2008, pp. 99–119.
[27] R. Alterovitz et al., “Simulating needle insertion and radioactive seed
implantation for prostate brachytherapy,” Stud. Health Technol. Informat.,
vol. 94, pp. 19–25, 2003.
[28] N. Dong et al., “A virtual reality simulator for ultrasound-guided biopsy
training,” IEEE Comput. Graph. Appl., vol. 31, no. 2, pp. 36–48, Mar./Apr.
2011.
[29] N. G. Hockstein et al., “Robotic microlaryngeal surgery: A technical feasibility study using the daVinci surgical robot and an airway mannequin,”
Laryngoscope, vol. 115, no. 5, pp. 780–785, May 2005.
[30] J. H. Palep, “Robotic assisted minimally invasive surgery,” J. Minimal
Access Surg., vol. 5, no. 1, pp. 1–7, 2009.
[31] J. Chung et al., “Vision based motion tracking system for interactive
entertainment applications,” in Proc. IEEE TENCON Region Conf., 2005,
vol. 10, pp. 1–6.
[32] T. Sielhorst et al., “An augmented reality delivery simulator for medical
training,” in Proc. Int. Workshop Augmented Environ. Med. Imag., MICCAI
Satellite Workshop, pp. 11–20, 2004.
[33] K. Fushima et al., “Real-time orthognathic surgical simulation using a
mandibular motion tracking system,” Comput. Aided Surg., vol. 12, no. 2,
pp. 91–104, 2007.
[34] G. Welch and E. Foxlin, “Motion tracking survey,” IEEE Comput. Graph.
Appl., vol. 22, pp. 24–38, 2002.
[35] G. Baratoff and S. Blanksteen, “Tracking devices,”. Available at
http://hitl.washington.edu/projects/knowledge_base/virtual-worlds/EVE/
I.D.1.b.TrackingDevices.html (accessed May 2015)

LIU et al.: OBSTETRIC ULTRASOUND SIMULATOR WITH TASK-BASED TRAINING AND ASSESSMENT

[36] I. Heer et al., “Ultrasound training: The virtual patient,” Ultrasound Obstetr. Gynecol., vol. 24, no. 4, pp. 440–444, 2004.
[37] Y. Liu et al., “Study on tracking system with pulsed AC magnetic field for
virtual reality system,” in Proc. 3rd Int. Conf. Virtual Reality Appl. Ind.,
Int. Soc. Opt. Photon., 2003, pp. 172–177.
[38] O. Suess et al., “Evaluation of a DC pulsed magnetic tracking system in
neurosurgical navigation: technique, accuracies, and influencing factors,”
Biomedizinische Technik. Biomed. Eng., vol. 52, no. 3, pp. 223–233, 2007.
[39] E. Wilson et al., “A buyer’s guide to electromagnetic tracking systems
for clinical applications,” Med. Imag., Int. Soc. Opt. Photon., vol. 6918,
p. 69182B, 2003, pp. 1–12.
[40] T. Koivukangas et al., “Technical accuracy of optical and the electromagnetic tracking systems,” Springer Plus, vol. 2, no. 1, pp. 1–7, 2013.
[41] D. Markov-Vetter et al., “3D augmented reality simulator for neonatale
cranial sonography,” Comput. Assisted Radiol. Surg., vol. 4, pp. 19–20,
2009.
[42] J. D. Hollan, M. Muhlhauser, Pen-and-Paper User Interface. New York,
NY, USA: Springer, 2012
[43] R. L. Hofer and A. Kunz, “Digisketch: Taming anoto technology on
LCDs,” in Proc. 2nd ACM SIGCHI Symp. Eng. Interactive Comput. Syst.,
2010, pp. 103–108
[44] D. P. Skehan, “Virtual training system for diagnostic ultrasound,” M.S.
thesis, Dept. Electr. Comput. Eng., Worcester Polytech. Inst., Worcester,
MA, USA, 2011.
[45] J. Kutarnia and P. C. Pedersen, “3D seam selection techniques with application to improved ultrasound mosaicing,” presented at the SPIE Med.
Imag. Conf., Lake Buena Vista, FL, USA, 2013.
[46] J. Kutarnia, “A Markov random field based approach to 3d mosaicking and
registration applied to ultrasound simulation,” Ph.D. dissertation, Dept. of
Electr. and Comput. Eng., Worcester Polytech. Inst., Worcester, MA, USA,
2014
[47] J. D. Rupp et al., “Design, development, and testing of a new pregnant
abdomen for the hybrid III small female crash test dummy”, Final Report
UMTRI 2001-07-11. University of Michigan Transportation Research Institute, Ann Arbor, Tech. Rep. HS-043 320, 2001.
[48] Q. Fang and D. Boas, “Tetrahedral mesh generation from volumetric
binary and gray-scale images,” in Proc. IEEE Int. Symp. Biomed. Imag.,
2009, pp. 1142–1145.
[49] I. Wolf et al., “The medical imaging interaction toolkit,” Med. Image
Anal., vol. 9, no. 6, pp. 594–604, 2005.
[50] W. J. Schroeder et al., “Visualizing with VTK: A tutorial,” IEEE Comput.
Graph. Appl., vol. 20, no. 5, pp. 20–27, Sep./Oct. 2000.
[51] J. J. Caban et al., “Rapid development of medical imaging tools with
open-source libraries,” J. Digit. Imag., vol. 20, no. 1, pp. 83–93, 2007.
[52] J. Blanchette and M. Summerfield, C++GUI Programming With Qt 4.
Englewood Cliffs, NJ: Prentice-Hall 2006.
[53] R. A. Fillyand and F. P. Hadlock, “Sonographic determination of menstrual
age,” in Ultrasonography in Obstetrics and Gynecology, P. W. Callen, Ed.,
4th ed. Philadelphia, PA, USA: Saunders, 2000
[54] W. Lu et al., “Automated fetal head detection and measurement in ultrasound images by iterative randomized Hough transform,” Ultrasound
Med. Biol., vol. 31, no. 7, pp. 929–936, 2005.
[55] H. Azpurua et al., “Determination of placental weight using twodimensional sonography and volumetric mathematic modeling,” Amer.
J. Perinatol., vol. 27, pp. 151–155, 2010
[56] V. Vezhnevets and V. Konouchine, “GrowCut: Interactive multi-label ND
image segmentation by cellular automata,” in Proc. Graphicon Conf.,
2005, pp. 150–156.
[57] F. P. Hadlock et al., “Estimation of fetal weight with the use of head,
body, and femur measurements—A prospective study,” Amer. J. Obstetr.
Gynecol., vol. 151, no. 3, pp. 333–337, 1985.
[58] S. Gratton et al., “Approximate Gauss-Newton methods for nonlinear
least squares problems,” SIAM J. Optim., vol. 18, no. 1, pp. 106–132,
2007.
[59] F. Dunn and I. Parberry, 3D Math Primer for Graphics and Game Development. Boca Raton, FL, USA: CRC Press, 2011.

2497

Li Liu received the B.S. and M.S. degrees from the
School of Electronic and Information Engineering,
Beijing University of Aeronautics and Astronautics,
Beijing, China, in 2005 and 2008, respectively. He is
currently working toward the Ph.D. degree in biomedical engineering at Worcester Polytechnic Institute,
Worcester, MA, USA.
He was a DSP in application engineering with
Analog Devices, Shanghai, China. His current research interests include in developing a personal obstetric ultrasound simulator with integrated training
curriculum and automated training assessment to meet the needs of providing
appropriate training to point of care ultrasound users, his other research effort
has been H.264 video algorithm optimization and system optimization on embedded platforms.

Jason Kutarnia, photograph and biography not available at the time of publication.

Petra Belady received the B.S. degree in biological
sciences from Cornell University, Ithaca, NY, USA,
in 1987, and the M.D. degree from the University of
Texas Health Sciences Center, Houston, TX, USA, in
1991.
She completed an Obstetrics and Gynecology Residency from SUNY Stony Brook in 1995, followed
by a fellowship in Maternal Fetal Medicine in 1997.
She is currently an Assistant Professor of obstetrics and gynecology at the Division of MaternalFetal-Medicine, University of Massachusetts Medical School, Worcester, MA, USA, and is also the Obstetrics and Gynecology
Residency Program Director. She is board-certified in maternal-fetal medicine as
well as obstetrics and gynecology. As the Obstetrics and Gynecology Residency
Program Director, she is responsible for maintaining an accredited teaching curriculum for 20 Resident Physicians. She has been involved in creating an online
technology model for the postpartum hemorrhage simulation project. She is the
Chair of the departmental education committee. Her clinical expertize include
prenatal diagnosis and obstetric ultrasound, as well as in caring for high-risk
obstetric patients.

Peder C. Pedersen (S’74–M’76–SM’87) received
the B.S. degree in electrical engineering from Aalborg Engineering College, Aalborg, Denmark, in
1971, and the M.E. and Ph.D. degrees in bioengineering from the University of Utah, Salt Lake City,
UT, USA, in 1974 and 1976, respectively.
He was an Associate Professor with the Department of Electrical and Computer Engineering, Drexel
University, Philadelphia, PA, USA. In October 1987,
he joined the Faculty at Worcester Polytechnic Institute, Worcester, MA, USA, where he is currently a
Professor at the Electrical and Computer Engineering Department. His research
interests include elastography methods for quantitative imaging of the Young’s
modulus in soft tissues and the development of a low-cost portable personal
ultrasound training simulator with structured curriculum and integrated assessment methods to satisfy the training needs of the widely used point-of-care
scanners, another research effort has been the design of a smartphone-based
diabetic wound analysis system, specifically for foot ulcers.

