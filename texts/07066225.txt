1392

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

Understanding User Intents in Online Health Forums
Thomas Zhang, Jason H. D. Cho, and Chengxiang Zhai

Abstract—Online health forums provide a convenient way for
patients to obtain medical information and connect with physicians
and peers outside of clinical settings. However, large quantities of
unstructured and diversified content generated on these forums
make it difficult for users to digest and extract useful information. Understanding user intents would enable forums to find and
recommend relevant information to users by filtering out threads
that do not match particular intents. In this paper, we derive a
taxonomy of intents to capture user information needs in online
health forums and propose novel pattern-based features for use
with a multiclass support vector machine (SVM) classifier to classify original thread posts according to their underlying intents.
Since no dataset existed for this task, we employ three annotators
to manually label a dataset of 1192 HealthBoards posts spanning
four forum topics. Experimental results show that a SVM using
pattern-based features is highly capable of identifying user intents
in forum posts, reaching a maximum precision of 75%, and that
a SVM-based hierarchical classifier using both pattern and word
features outperforms its SVM counterpart that uses only word
features. Furthermore, comparable classification performance can
be achieved by training and testing on posts from different forum
topics.
Index Terms—Forum intents, online health forums, pattern
based features, support vector machines, user intent classification.

I. INTRODUCTION
HE spread of Health 2.0 [2] technologies in the last decade
has made the Internet a popular place for patients to learn
and discuss health-related issues. In particular, online medical
forums such as HealthBoards,1 MedHelp,2 and Wellescent3 have
become very popular because they provide cost-effective ways
for users to learn about health-related issues outside of clinical
care settings. On these forums, users can post their problems
and obtain advice from both peers and health care professionals, or simply browse relevant threads. Forums are particularly
valuable in the sense that they contain first-hand experiences,
which often have richer content than that offered by any single
expert. For example, Eysenbach [3] find that many physicians
are unaware of the numerous alternative and complementary
treatment medications found in forum discussions, and Hartzler and Pratt [4] show that patients offer expertize that differs
significantly from that offered by health professionals.

T

Manuscript received December 15, 2014; revised March 1, 2015; accepted
March 16, 2015. Date of publication March 24, 2015; date of current version July 23, 2015. This work was supported in part by the National Science
Foundation under Grant CNS-1027965. This is a minor revision of the work
[1] published in BCB ’14: Proceedings of the 5th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics, September 2014,
http://dx.doi.org/10.1145/2649387.2649445
The authors are with the Department of Computer Science, University of
Illinois at Urbana-Champaign, Urbana, IL 61801 USA (e-mail: zhang156@
illinois.edu; hcho33@illinois.edu; czhai@illinois.edu).
Digital Object Identifier 10.1109/JBHI.2015.2416252
1 http://www.healthboards.com/boards
2 http://www.medhelp.org/forums/list
3 http://wellescent.com/

As the popularity of health forums continues to grow, more
research is needed to better connect users with the vast quantities of information present on these forums. In present-day
health forums, users often start new threads to ask questions and then patiently wait for responses while the answers
that they are looking for may already be on some forum.
If we could somehow discern the intent of these threads,
we could have recommended to the author a set of similar threads that match both his intent and the content of his
post, perhaps saving him from having to indefinitely wait for a
response.
Knowing the intents of original thread posts would also assist
a number of existing works that aim to retrieve information from
health forum content. The intent of the original post in a thread
sets the topic of that thread and determines what type of information users could expect to find in the responses. Applications
can therefore use this knowledge to reduce the sizes of search
spaces by filtering out threads with intents that are less likely
to contain relevant information, resulting in more efficient run
time and more accurate results. To illustrate this claim, we can
hypothetically incorporate intents to several works that utilize
health forum data. For example, Vydiswaran et al. [5] searched
for all relevant posts that support claims from an online health
forum corpus. If they knew the intent of every post, they could
have simply conducted their search on posts with “treatment”
intent. Similarly, Cho et al. [6] extracted treatment sentiments
from over 130K online health forum posts to model treatment
effectiveness. With knowledge of intents, they could instead run
their algorithm only on posts with “treatment” and “adverse effects of treatment” intent. Finally, Jiang et al. [7] organized and
integrated patient drug outcomes by splitting the health forum
comments into “comment units,” and classifying each unit into
one of two groups. Much like in the case of Cho et al. [6], we
claim that the comment units can be extracted from messages in
threads with “treatment” or “adverse effects of treatment” intent
since these posts are mostly likely to contain information about
patient drug outcomes.
To our knowledge, no previous work has sought to identify
user intents from original health forum posts. In this paper, we
cast this problem as a classification problem to make the task
more tractable. However, since this is a new task, no existing
intent taxonomy or datasets exist for this problem, and so we
must first derive a taxonomy of user intents from existing medical literature and create a new labeled dataset for evaluation. For
classification, we use a supervised learning method and propose
a set of novel pattern-based features specific to health forum
content. Experimental results show that a support vector machine (SVM) classifier using pattern-based features can achieve
high precision upward of 75%, and that a hierarchical classifier
using both pattern and word features outperforms a classifier using only word features with statistical significance. In addition,

2168-2194 © 2015 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution
requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

ZHANG et al.: UNDERSTANDING USER INTENTS IN ONLINE HEALTH FORUMS

1393

we find that our classifiers give comparable performance when
trained and tested on posts from different forum topics.
The remainder of this paper is organized as follows. The next
section surveys relevant past work in both the health and general
domains. Section III motivates and derives the intent taxonomy.
Section IV formally presents the problem, while Sections V
and VI introduce the classification framework and feature set,
respectively. Section VII presents the data, describes the experiments, and summarizes the evaluation results. Finally, in Section
VIII, we apply our method to a MedHelp dataset to analyze the
distribution of intents for several forum topics.

domain-specific platforms such as health forums. In addition,
the proposed taxonomies in these studies are irrelevant to the
health domain and thus cannot be used to describe the intents of
health forum users.
In addition to questions, previous research on user intents
have also focused on web search engine queries. Dogan et al.
[20] investigated user behavior in the biomedical search engine
PubMed4 through an analysis of user sessions and queries. Their
studies revealed, among others, that the most frequent types of
search are by author name, gene or protein, and disease. Cartright et al. [21] explored information goals and patterns of
attention in web exploratory health search (EHS) through analysis of search sessions. They identified EHS sessions, extracted
different intentions persisting as foci of attention from those
sessions, and demonstrated how this knowledge can be used to
better understand EHS behavior and support health search on
the web. Similarly, other works such as [22], [23], and [24] have
also used interaction logs to study web search behavior, but
none have focused on identifying medical query intent. In general purpose search, Broder’s seminal work [25] found that user
query goals can be classified into a trichotomy of web search
types: information, navigational, and transactional. Subsequent
works such as [26]–[28], and [29] show that various automatic
learning-based approaches can be used to produce solid predictive performance in classifying queries. Much like questions,
queries differ from forum posts in several ways. First, queries
often consist of discrete keywords whereas forum posts are formulated in natural language, reflecting the discrepancy between
their intended audiences. Second, search queries typically reflect some specific underlying “need” [25] whereas the “need”
behind forum posts may not be as clear. These key differences
mean that we must take into account both the structural properties of forum posts as well as the needs of their authors while
trying to characterize their intents.
As we have mentioned earlier, we do not know of any previous
work related to user intents in the health forum space. Nevertheless, many works have utilized health forum data to accomplish
other tasks in recent years, notably by [6] to conduct Comparative Effectiveness Research (CER), [7] to organize and integrate
patient outcomes, [30] to classify posts into news, comments, or
spam, and [31] to track trends in people’s reactions to drugs over
time. These works demonstrate that health forums contain valuable information that can be exploited to advance knowledge in
the health domain.

II. RELATED WORK
A lot of research work has been done on medical question
answering (QA) systems. Many of these works have identified
question understanding, framed as a classification problem, as
a necessary and important first step in the implementation of
such systems. For example, Yu et al. [8] made use of supervised learning approaches to classify questions based on the
Evidence Taxonomy proposed by Ely et al. [9] and later on general topics [10], and found that including concepts and semantic types from the Unified Medical Language System (UMLS)
as additional features can enhance classification results. Later,
Kobayashi and Shyu [11] classified questions into taxonomies
by the Family Physicians Inquiries Network and the generic
taxonomy proposed by Ely et al. [12] and showed that augmenting UMLS concepts and semantic types with standard parsing
representations improves classification performance. Last but
not least, Slaughter et al. [13] investigated semantic patterns of
health consumers’ questions and physicians’ answers and found
that semantic relationships can indeed lead to clues for creating
semantic-based QA techniques. These studies all demonstrate
semantic-based question classification approaches in medical
QA systems, and we will show in this paper how similar approaches can be used to classify original thread posts in online
health forums.
Subjective understanding of user intents has also been extensively studied in the context of general community question
answering (CQA) services. Categorizing questions into different
semantic classes impose constraints on potential answers so that
they can be used in later stages of the QA process. Prominent
works in this area include the novel CQA question taxonomy
developed by Liu et al. [14] which expand upon Broder’s taxonomy of web search queries to include both informational and
social categories, the three-level question taxonomy proposed
by Zhang et al. [15] that make use of interrogative patterns, hidden user intentions, and specific answer expectations to model
user information need, the semisupervised cotraining system
introduced by Li et al. [16], [17] which exploits the association between questions and answers to predict whether a user
is seeking subjective or objective information, and the ensuing
work by Chen et al. [18], [19] which adds a new social category
to Li’s taxonomy and proposes a classification method using
only features extracted from questions. However, all of these
studies are insufficient for our purposes as their methods make
use of content found on general CQA, and thus do not leverage the unique semantic information that can be found on more

III. INTENT TAXONOMY
A. Motivation
Ely et al. [12] developed a taxonomy of doctor’s questions
about patient care consisting of 64 generic question types which
aims to capture information needs of doctors during patient visits. Boot and Meijman [32] investigated the feasibility of using
this taxonomy to classify health questions asked by the general public and found many differences between the information
needs of patients and professionals. For example, there exists no
suitable category in Ely’s taxonomy for questions about standard
4 http://www.ncbi.nlm.nih.gov/pubmed

1394

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

TABLE I
TOP TEN GENERIC QUESTIONS BY PRIMARY CARE DOCTORS FROM [12]
Rank

Question

1
2
3
4
5

What is the drug of choice for condition x?
What is the cause of symptom x?
What test is indicated in situation x?
What is the dose of drug x?
How should I manage condition x (not specifying
diagnostic or therapeutic)?
What is the cause of physical finding x?
How should I treat condition x (not limited to
drug treatment)?
What is the cause of test finding x?
Could this patient have condition x?
Can drug x cause (adverse) finding y?

6
7
8
9
10

TABLE II
BASELINE Word Classifier CV RESULTS
Fivefold CV
Intent
Manage
Cause
Adverse
Story
Overall

Fourfold Forum CV

P

R

F1

P

R

F1

58.25
61.92
39.47
39.54

62.85
59.75
29.41
40.74
53.44

60.46
60.82
33.71
40.13

54.34
61.20
35.29
37.31

61.15
53.65
24.24
41.08
50.59

57.55
57.18
28.74
39.10

TABLE III
HIERARCHICAL CLASSIFIER CV RESULTS
Fivefold CV

medical knowledge (e.g., What can I expect during treatment
x?) due to the fact that they are rarely asked by doctors, yet these
questions are frequently asked by patients. In addition, patients
often tend to ask more ambiguous questions than doctors would
due to their lack of expertise in health-related matters. Classification using Ely’s taxonomy would in turn become problematic
since the taxonomy contains categories with very similar meanings (e.g., “What is the cause of symptom x?” and “Could this
patient have condition y?”). Their findings prove that it is inappropriate to use a taxonomy designed for doctors to characterize
patient intents.
B. Derivation
1) Intuition: Boot and Meijman’s study raises the need for a
new taxonomy designed for patients. For our purposes, we want
a taxonomy that captures the intents of online health forum
users, specifically, the intents of users who start new threads.
To our knowledge, no previous work has been done in this
area, but Choudhury et al. [33] identified the intents of online
users who search for general purpose health information. If
we assume that these users have roughly the same intents as
online health forum users, we can derive an intent taxonomy
from the original taxonomy of doctor’s questions proposed by
Ely et al. to generate a one-to-one mapping to the user intents
discovered by Choudhury et al. [33]. Our ability to generate this
mapping validates the correctness of our classes in capturing
the majority of intents of online health forum users. Later, we
will complete the taxonomy by adding several additional intent
classes specific to health forums.
2) Clustering: Ely et al. [12] presented a list of the top ten
most commonly asked generic questions by doctors (shown in
Table I). On close inspection, we see that these questions can
be clustered into groups with related intents. The clustering is
as follows: (2), (6), (8), and (9) are reduced into the intent class
“What is the cause of symptom, physical finding, or test finding
x?”Ranks (1), (4), (5), and (7) are reduced to the intent class
“How should I manage or treat condition x?” [Ranks (1) and
(4) are essentially questions pertaining to treatment]. Rank (10)
is its own class, and rank (3) is discarded because it refers to
questions that only doctors, not patients, would ask.
3) Mapping: Choudhury et al. [33] examined the intents of
197 survey respondents who use search engines to seek health

Intent
Manage
Cause
Adverse
Story
Overall

Fourfold Forum CV

P

R

F1

P

R

F1

58.71
61.72
60.81
47.28

65.26
66.67
48.39
38.05
57.63*

61.81
64.10
53.89
42.16

56.05
62.66
54.43
45.42

64.55
62.34
46.24
38.38
55.87*

60.00
62.50
50.00
41.61

*indicates statistical significance at α = 0.05 against baseline results in Table II

information online. They found that the most common motivations of these users are, in decreasing order, identifying
treatment options, diagnosing health conditions, understanding
health conditions or procedures, and understanding medications.
We see here that our formulated taxonomy classes from Section
III-B2 match the most common user motivations. “What is the
cause of symptom, physical finding, or test finding x?” maps
to diagnosing health conditions, “How should I manage/treat
condition x?” maps to identifying treatment options, and “Can
drug/treatment x cause (adverse) finding y?” to understanding
medications and procedures. The existence of this mapping validates our approach of deriving an intent taxonomy from an
existing taxonomy of doctor’s questions.
4) Expansion: We make two observations with regards to
health forums. First, we notice that some forum posts contain
multiple medical inquiries corresponding to more than one intent. We therefore introduce a “Combination” class that corresponds to such posts. Second, we find that it is common for
users to ask for or share health-related experiences or news, post
personal stories aiming to garner emotional support from the forum community, or post off-topic messages. For such posts, we
propose a “Story Telling” class. As we shall see, these particular
types of posts tend to show up in certain forums more often than
others.
C. Summary
Our derivation in Section III-B yields five categories of intent,
summarized with examples from HealthBoards below.
Manage: How should I manage/treat condition X?
Description: Information regarding treatment options; management of long-term illnesses; illness prevention.
HealthBoards Example: Hello I have found out through many
self test that I have depression I know I should see a counselor
but I feel I should not I dont want to tell my parents because

ZHANG et al.: UNDERSTANDING USER INTENTS IN ONLINE HEALTH FORUMS

they think I am a happy person I just dont know what to do at
this point does anyone else know how to get through this?
Cause: What is the cause of symptoms/physical findings/test
findings X?
Description: Diagnosis of physical findings or test results,
including statistics (e.g., high blood pressure readings).
Health Boards Example: My husband has been waking up
with a slight stuffy nose that he says feels like pressure at times
and has a slight headache. He has some drainage that goes down
his throat and he says that he has some congestion. Does this
sound typical of allergies?
Adverse: Can drugs or treatments X cause (adverse) finding
Y?
Description: Negative side effects of drugs or treatments (e.g.,
heart surgery), including short/long-term health risks, effects of
dosage, and withdrawal effects.
Health Boards Example: I hear people talking about how
certain nasal sprays has steroids in them which could be bad
for you if you continue to take it regularly. I assume astelin,
flonase, nasonex, and other prescription nasal sprays are okay
to take regularly?
Combo: Combination.
Description: Two or more of the three intents above.
Health Boards Example: I have had a constant pain in my
chest and sometimes my neck. What is happening? and right
now I m having a pain in the center of my chest and shortness
of breath and my heads kind of spinning what should i do?
Story: Story telling, news, sharing or asking about experience,
soliciting support, or others.
Description: Asking/sharing experience or news; comments
to garner emotional support; off-topic content.
Health Boards Example: Everyone will lie to me. Everyone
wants stuff from me and gives little in return. The ONLY person
I can count on is me. Living again on klonopin. Thank God for
it. But I feel like a zombie. Like I am not really here. Scared to
be here though. All I want to do is turn the ac way up, get my
room dark as possible, crawl in bed with my dogs and sleep.
Thanks for listening.
IV. PROBLEM FORMULATION
Define O as an original thread post with intent ci from a
taxonomy of intents C = {c1 , ..., ck }, and let S = (s1 , ..., sn )
denote the sentence representation of O. We classify O as some
cj ∈ C using S as evidence. O is correctly classified if and only
if j = i.
One caveat to this formulation is that it does not identify all
intents from multiple intent posts, which is in practice quite
common. Posts with multiple intents (i.e., Combo posts) will be
considered to be correctly classified if one of its intents matches
the predicted intent. Multiple intent identification will be left as
future work.
V. METHODOLOGY
Our classification method is based on the classic supervised
learning framework. To do so, we design features to capture
intents in forum posts. Our task is to apply these features to our

1395

TABLE IV
Pattern Classifier CV PERFORMANCE, ISOLATED FROM THE
HIERARCHICAL CLASSIFIER
Fivefold CV
Intent
Manage
Cause
Adverse
3-Class

Fourfold Forum CV

P

R

F1

P

R

F1

75.51
73.53
80.85
75.05

36.72
43.86
40.86
40.34

49.41
54.95
54.29
52.47

72.59
72.72
71.70
72.55

34.96
42.75
40.86
38.99

48.38
53.17
48.41
50.72

dataset to construct a feature representation of each post, and
then separate these representations into discrete training and test
sets. Finally, we will train a classifier using the training set and
evaluate on the test set. For each post in the test set, the classifier
will compute a score for each intent. The intent with the highest
score will be assigned to that post.
In our experiments, we use the popular SVM classifier and
assume that our choice of features will generalize well to other
classifiers, leaving experimentation with different classifiers as
future work.
A. Support Vector Machines
SVMs first introduced in [34] are binary classifiers that construct hyperplanes to separate training instances belonging to
two classes. SVMs maximize the separation margin between
this hyperplane and the nearest training data points of any class.
The larger the margin, the lower the generalization error of the
classifier. In our experiments, we use the LIBSVM [35] implementation with a RBF kernel, and train the classifiers using a
one-versus-all multiclass approach.
B. Hierarchical Classifier
We use a hierarchical classification setup that consists of a
sequence of two cascading SVM classifiers using word and
pattern features (see Section V-C). The first classifies posts that
match at least one pattern feature (Pattern Classifier), while the
second classifies all posts that do not match any pattern features
using word features (Word Classifier).
C. Features
As mentioned in Section V-B, we use two types of features
in our hierarchical setup: words and patterns. This section describes each feature type in more detail.
1) Word Features: These features are based on the traditional
bag-of-words model [36]. In this model, text is represented as
a set of its words, disregarding grammar, and word order but
keeping multiplicity. For our purposes, we use standard unigram
word features weighted with TF-IDF [37].
2) Pattern Features: These features are recurring sentence
patterns5 found in forum posts, each indicating a specific intent. For example, the pattern “What could X be...” indicates
strong Cause intent, but “What can X do...” indicates Manage
5 See

http://thejason.co/intents/{patterns.txt, README.txt}.

1396

Fig. 1.

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

Distribution of classified intents for the MedHelp dataset, separated by topics.

intent. We carefully compile patterns that are most representative of Manage, Cause, and Adverse intents. We do not extract
patterns from posts with Story intent because the posts have
too much content variation. Each pattern has to be sufficiently
discriminative for its respective intent, but also generic enough
as to match content across many forum posts. As a result, we
replace certain words inside our patterns with their stemmed
roots, part-of-speech tags, and semantic group labels from the
UMLS Metathesaurus,6 extracted using MetaMap [38].
VI. EVALUATION
A. Dataset
There is no existing dataset available for our classification
task, so we create a new dataset consisting of 1192 original
forum posts from HealthBoards, evenly divided between four
topics: allergies, breast cancer, depression, and heart disease.
These topics give us a good mix of posts from both major and
minor health disorders. Two computer science students with
substantial agreement per Landis and Koch [39] (based on Cohen’s kappa [40] κ = 0.665) and substantial agreement with
two medical students (based on Fleiss’ kappa [41] κ = 0.67)
label the dataset using the five-class taxonomy as described in
Section III-C. A third computer science student labels Combo
posts with all intents from {Manage, Cause, Adverse}.
B. Experiments
Two experiments are conducted with their descriptions below. Note that for all experiments, Combo posts are excluded
for training, but every forum post in the dataset is used for testing. A Combo post is considered to be correctly classified if
its predicted class label matches at least one of its labels. Otherwise, we pick the first label in the order of Manage, Cause,
and Adverse and consider the post to be misclassified for that
particular class.
1) Fivefold Cross-Validation: In this experiment, we evaluate and compare fivefold cross-validation performance of the
hierarchical classifier in Section V-B with that of a baseline
Word Classifier.
2) Fourfold Forum Cross-Validation: Here, each fold in
cross-validation consists of only forum posts from one topic.
This experiment therefore evaluates the capacity of our classifier to predict the intents of posts from forums not seen in
6 http://www.nlm.nih.gov/research/umls

training, which is akin to how the classifier will be used in a
real-life scenario.
C. Results
We make several observations pertaining to the results:
Pattern classifier achieves high precision but low recall.
75.05% for fivefold CV, and 72.55% for fourfold forum CV
(see Table IV), which means the classifier can accurately predict intents of posts that match at least one pattern feature. To
increase recall, we need to expand our pattern feature set.
Hierarchical classifier improves over baseline. 57.63% from
53.44% in fivefold CV, and 55.87% from 50.59% in fourfold
forum CV. These results are both statistically significant per
McNemar’s test [42] at 0.05-level.
Fourfold forum CV compares with fivefold CV. 55.87% with
57.63% (see Table II and III). This shows our method generalizes
well to posts from forums not represented in the training set.
Both baseline and hierarchical classifiers struggle to identify
Story intent. 40.13% and 42.16% for fivefold CV, and 39.10%
and 41.61% for fourfold forum CV (F1 scores). This is expected
as we did not extract pattern features for posts with Story intent.
Pattern Classifier makes mistakes on posts that match features
across different intents by accident. For example, a post could
contain a sentence like ”the doctor says (disorder) could be
caused by...” but at the end ask “does anyone know if (treatment)
helps?”. It is clear that the post intent is Manage, but the classifier
might be confused by the matched feature in the first sentence
that appears in many Cause posts. We find that most of the
classification errors occur due to this phenomenon.
VII. MEDHELP DISTRIBUTION
We can use our classification method to analyze the distribution of intents for any collection of original health forum posts.
To demonstrate this, we crawl 61 225 posts from MedHelp from
the same topics as those in our HealthBoards dataset (i.e., allergy, breast cancer, depression, and heart disease).
Recall that since Story intents are hard to identify (see Section VI-C), we instead focus on identifying the other three intents (Manage, Cause, and Adverse). We decided to use a Pattern Classifier to classify the MedHelp dataset because it gives
impressive precision on posts it classifies, albeit with low recall. Furthermore, since patterns are less forum dependent than
words, we believe that a Pattern Classifier generalizes better to
forum posts across different topics.

ZHANG et al.: UNDERSTANDING USER INTENTS IN ONLINE HEALTH FORUMS

1397

Fig. 1 shows the distribution of classified intents for the MedHelp dataset as separated by topics. From these statistics, we
can make several observations:
Cause makes up a majority in three of the four topics. This
may be due to the propensity of forum users to use health forum
information to make preliminary diagnosis of their conditions
before consulting a medical professional.
Manage makes up a majority in the topic of depression. This
leads us to believe that depressed patients are mostly concerned
with finding ways to mitigate their symptoms.
Depression contains the greatest proportion of Adverse posts.
We believe that this is due to many medications listing depression as a side effect. This in turn causes users of these medications to ask about them on health forums.
Allergy forum contains a smaller ratio of Cause to Manage
posts. Since allergies are relatively minor ailments, patients are
more interested in asking about treatment options than obtaining
an accurate diagnosis.

is required to identify all of the intents in a multiintent forum
post.

VIII. CONCLUSION
This paper presents a machine-learning approach to identifying user intents from original thread posts from online health
forums. From an information retrieval perspective, knowledge
of intents is extremely important because it allows threads with
certain intents to be filtered out, thereby reducing the search
space. This technique can be applied to a variety of applications
such as thread search and recommendation, and also benefit
many existing works such as treatment trustworthiness, CER,
and drug outcome clustering.
Our main contributions in this study are threefold. First, we
derived an intent taxonomy to capture information needs of
online health forum users. We showed in our derivation that the
classes map directly to the common motivations of users who
search for health information online. Second, we demonstrated
that a classifier trained on novel pattern features is capable of
identifying intents of forum posts with high precision. Third, we
showed, with statistical significance, that a hierarchical classifier
that uses both pattern and word features outperforms a one that
uses only word features. Finally, we find that the performance
of our classifier is capable of classifying posts from forums
not seen during training with high accuracy. This proves that
our classifier can be trained and tested on posts from different
forum topics.
Several limitations exist within the scope of this study. First,
we did not conduct a study of health forum user intents due to
limited resources, which would have better justified the intents
we decided to include in our taxonomy. Second, we need to
work on expanding our pattern feature set in order to improve
classification performance. Third, our current pattern classifier
does not handle classification of posts with Story intent, so future
work is needed to identify such posts. Fourth, we would ideally
want a larger annotated dataset for more accurate evaluation and
a set of annotated forum posts from MedHelp to obtain further
validation that our classifiers do in fact generalize well to posts
from other data sources. Finally, we are currently unable to
extract all intents for posts with Combo intent and further work

ACKNOWLEDGMENT
The authors would like to thank A. Szmelter and N. Chitturu
for providing their excellent medical expertise in labeling health
forum posts, S. Nguyen and J. Friedman for labeling our dataset,
and H. Lin for helping us with revision. In addition, we thank the
anonymous reviewers for their insightful comments. Finally, we
would also like to thank Jump Trading and the Siebel Foundation
for their generous scholarships that supported this research.
REFERENCES
[1] T. Zhang, J. H. D. Cho, and C. Zhai. (2014). Understanding user intents in online health forums. in Proc. 5th ACM Conf. Bioinformatics, Comput. Biol. Health Informat. pp. 220–229. [Online]. Available:
http://doi.acm.org/10.1145/2649387.2649445
[2] T. H. Van De Belt, L. J. Engelen, S. A. Berben, and L. Schoonhoven,
“Definition of health 2.0 and medicine 2.0: A systematic review.” J. Med.
Internet Res., vol. 12, no. 2, p. e18, 2010.
[3] G. Eysenbach. (2003). The impact of the internet on cancer outcomes.
CA, Cancer J. Clinicians. 53(6). pp. 356–371, 2003. [Online]. Available:
http://dx.doi.org/10.3322/canjclin.53.6.356
[4] A. Hartzler and W. Pratt, “Managing the personal side of health: How
patient expertise differs from the expertise of clinicians,” J. Med. Internet
Res., vol. 13, no. 3, p. e62, 2011.
[5] V. V. Vydiswaran, C. Zhai, and D. Roth. (2011). Gauging the internet
doctor: Ranking medical claims based on community knowledge. in Proc.
Workshop Data Mining Med. Healthcare, pp. 42–51. [Online]. Available:
http://doi.acm.org/10.1145/2023582.2023589
[6] J. H. Cho, V. Q. Liao, Y. Jiang, and B. R. Schatz. (2013). Aggregating personal health messages for scalable comparative effectiveness research. in Proc. Int. Conf. Bioinformatics, Comput. Biol. Biomed. Informat.
pp. 907:907–907:916. [Online]. Available: http://doi.acm.org/10.1145/
2506583.2512363
[7] Y. Jiang, Q. V. Liao, Q. Cheng, R. B. Berlin, and B. R. Schatz, “Designing
and evaluating a clustering system for organizing and integrating patient
drug outcomes in personal health messages,” in Proc. AMIA Annu. Symp.,
2012, vol. 2012, pp. 417–426.
[8] H. Yu, C. Sable, and H. R. Zhu. (2005). Classifying medical questions based on an evidence taxonomy. in Proc. AAAI Workshop Question Answering Restricted Domains, pp. 27–35. [Online]. Available:
http://www.uwm.edu/ hongyu/publications.html
[9] J. Ely, J. A. Osheroff, M. H. Ebell, M. L. Chambliss, D. Vinson,
J. J. Stevermer, and E. A. Pifer. (2002). Obstacles to answering doctors’ questions about patient care with evidence: Qualitative
study,” BMJ, 324(7339), p. 710, pp. 710–716. [Online]. Available:
http://www.bmj.com/cgi/content/full/324/7339/710
[10] H. Yu and Y.-G. Cao, “Automatically extracting information needs
from ad hoc clinical questions,” in Proc. AMIA Annu. Symp., 2008,
pp. 96–100.
[11] T. Kobayashi and C.-R. Shyu, “Representing clinical questions by semantic type for better classification,” in Proc. AMIA Annu. Symp., 2006,
vol. 2006, p. 987.
[12] J. W. Ely, J. A. Osheroff, P. N. Gorman, M. H. Ebell, M. L. Chambliss,
E. A. Pifer, and P. Z. Stavri. (2000). A taxonomy of generic clinical
questions: Classification study. Brit. Med. J., 321(7258), pp. 429–432.
[Online]. Available: http://www.pubmedcentral.nih.gov/articlerender.
fcgi?tool=pubmed&pubmedid=10938054
[13] L. A. Slaughter, D. Soergel, and T. C. Rindflesch. (2006). Semantic representation of consumer questions and physician answers,” I. J.
Med. Informat. 75(7), pp. 513–529. [Online]. Available: http://dblp.unitrier.de/db/journals/ijmi/ijmi75.html#SlaughterSR06
[14] Y. Liu, S. Li, Y. Cao, C.-Y. Lin, D. Han, and Y. Yu. (2008). Understanding
and summarizing answers in community-based question answering services. in Proc. 22nd Int. Conf. Comput. Linguistics, pp. 497–504. [Online].
Available: http://dl.acm.org/citation.cfm?id=1599081.1599144
[15] Y. Zhang, X. Wang, X. Wang, S. Fan, and D. Zhang. (2009). Using
question classification to model user intentions of different levels. in

1398

[16]

[17]

[18]

[19]

[20]
[21]

[22]

[23]
[24]
[25]
[26]

[27]
[28]

[29]

[30]
[31]
[32]

[33]

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

Proc. IEEE Int. Conf. Syst., Man Cybern. pp. 1153–1158. [Online]. Available: http://dl.acm.org/citation.cfm?id=1732323.1732520
B. Li, Y. Liu, and E. Agichtein. (2008) Cocqa: Co-training over questions and answers with an application to predicting question subjectivity orientation. in Proc. Conf. Empirical Methods Natural Language
Process. pp. 937–946. [Online]. Available: http://dl.acm.org/citation.
cfm?id=1613715.1613836
B. Li, Y. Liu, A. Ram, E. V. Garcia, and E. Agichtein. (2008). Exploring
question subjectivity prediction in community QA. in Proc. 31st Annu. Int.
ACM SIGIR Conf. Res. Develop. Inform. Retrieval. pp. 735–736. [Online].
Available: http://doi.acm.org/10.1145/1390334.1390477
L. Chen, D. Zhang, and M. Levene. (2013). Question retrieval with
user intent. in Proc. 36th Int. ACM SIGIR Conf. Res. Develop. Inform.
Retrieval. pp. 973–976. [Online]. Available: http://doi.acm.org/10.1145/
2484028.2484129
L. Chen, D. Zhang, and L. Mark. (2012). Understanding user intent in
community question answering. in Proc. 21st Int. Conf. Companion World
Wide Web. pp. 823–828. [Online]. Available: http://doi.acm.org/10.1145/
2187980.2188206
R. I. Dogan, G. C. Murray, A. Névéol, and Z. Lu, “Understanding
R
pubmed
user search behavior through log analysis,” Database, vol. 2009,
pp. 1–19, 2009.
M.-A. Cartright, R. W. White, and E. Horvitz. (2011). Intentions and
attention in exploratory health search. in Proc. 34th Int. ACM SIGIR
Conf. Res. Develop. Inform. Retrieval. , pp. 65–74. [Online]. Available:
http://doi.acm.org/10.1145/2009916.2009929
S. K. Bhavnani, R. T. Jacob, J. Nardine, and F. A. Peck. (2003). Exploring
the distribution of online healthcare information. in Proc. Extended Abstracts Human Factors Comput. Syst.. pp. 816–817. [Online]. Available:
http://doi.acm.org/10.1145/765891.766009
A. Spink, Y. Yang, J. Jansen, P. Nykanen, D. P. Lorence, S. Ozmutlu,
and H. C. Ozmutlu, “A study of medical and health queries to web search
engines,” Health Inform. Libraries J., vol. 21, no. 1, pp. 44–51, Mar. 2004.
S. L. Ayers and J. J. Kronenfeld, “Chronic illness and healthseeking information on the Internet,” Health (London), vol. 11, no. 3,
pp. 327–347, Jul. 2007.
A. Broder. (2002). A taxonomy of web search,. SIGIR Forum. 36(2),
pp. 3–10. [Online]. Available: http://doi.acm.org/10.1145/792550.792552
B. J. Jansen, D. L. Booth, and A. Spink. (2008, May). Determining the informational, navigational, and transactional intent of web
queries. Inf. Process. Manage., 44(3), pp. 1251–1266. [Online]. Available: http://dx.doi.org/10.1016/j.ipm.2007.07.015
U. Lee, Z. Liu, and J. Cho. (2005). Automatic identification of user goals
in web search. in Proc. 14th Int. Conf. World Wide Web. pp. 391–400.
[Online]. Available: http://doi.acm.org/10.1145/1060745.1060804
R. Baeza-Yates, L. Calderón-Benavides, and C. González-Caro. (2006).
The intention behind web queries. in Proc. 13th Int. Conf. String Process.
Inform. Retrieval, 2006, pp. 98–109. [Online]. Available: http://dx.doi.org/
10.1007/11880561_9
I.-H. Kang and G. Kim. (2003). Query type classification for web
document retrieval. in Proc. 26th Annu. Int. ACM SIGIR Conf.
Res. Develop. Inform. Retrieval. pp. 64–71. [Online]. Available:
http://doi.acm.org/10.1145/860435.860449
Y. Jiang, C. X. Lin, and B. Schatz, “Multi-class classification for online
personal healthcare messages,” Web Sci. Med. Domain, p. 3, 2011.
B. Chee, R. Berlin, and B. Schatz, “Measuring population health using
personal health messages,” in Proc. AMIA Annu. Symp., 2009, vol. 2009,
pp. 92–96.
C. R. Boot and F. J. Meijman, “Classifying health questions asked by the
public using the ICPC-2 classification and a taxonomy of generic clinical
questions: An empirical exploration of the feasibility,” Health Commun.,
vol. 25, no. 2, pp. 175–181, 2010.
M. De Choudhury, M. R. Morris, and R. W. White, “Seeking and sharing
health information online: Comparing search engines and social media,”
in Proc. 32nd Annu. ACM Conf. Human Factors Comput. Syst., 2014,
pp. 1365–1376.

[34] B. E. Boser, I. M. Guyon, and V. N. Vapnik, “A training algorithm for
optimal margin classifiers,” in Proc. 5th Annu. Workshop Comput. Learn.
Theory, 1992, pp. 144–152.
[35] C.-C. Chang and C.-J. Lin. (2013. Apr.). LIBSVM—A Library for Support Vector Machines. [Online]. Available: http://www.csie.ntu.edu.tw/
cjlin/libsvm
[36] G. Salton and M. J. McGill, Introduction to Modern Information Retrieval.
New York, NY, USA: McGraw-Hill, 1983.
[37] G. Salton, A. Wong, and C.-S. Yang, “A vector space model for automatic
indexing,” Commun. ACM, vol. 18, no. 11, pp. 613–620, 1975.
[38] A. R. Aronson. (2001). . Proc. AMIA Symp., pp. 17–21. [Online]. Available: http://view.ncbi.nlm.nih.gov/pubmed/11825149
[39] J. R. Landis, G. G. Koch, “The measurement of observer agreement for
categorical data,” Biometrics, vol. 33, no. 1, pp. 159–174, 1977.
[40] J. Cohen, “A coefficient of agreement for nominal scales,” Edu. Psychol.
Meas., vol. 20, no. 1, pp. 37–46, 1960.
[41] J. Fleiss, “Measuring nominal scale agreement among many raters,” Psychol. Bullet., vol. 76, no. 5, pp. 378–382, 1971.
[42] Q. McNemar, “Note on the sampling error of the difference between
correlated proportions or percentages,” Psychometrika, vol. 12, no. 2,
pp. 153–157, 1947.

Thomas Zhang received the Bachelor’s and Master’s
degrees in computer science from the University of
Illinois in Urbana-Champaign, Urbana, IL, USA, in
2014.
He was a Member of the Text Information Management and Analysis Research Group, University
of Illinois in Urbana-Champaign. His research interests include the development of smart systems and
applications using text mining, natural language processing, and machine learning methods.

Jason H.D. Cho received the Bachelor’s and Master’s degrees, and is currently working toward the
Ph.D. degree in computer science at the University of
Illinois in Urbana-Champaign, Urbana, IL, USA.
His research interests include the applications of
natural language processing and text mining on health
domains. In particular, he is interested in obtaining
deeper understanding of what patients and clinicians
write, and what general medical population are interested in.

Chengxiang Zhai received the Ph.D. degree in computer science from Nanjing University, Nanjing,
China, in 1990, and the Ph.D. degree in language
and information technologies from Carnegie Mellon,
Pittsburgh, PA, USA, in 2002.
He is currently a Professor of computer science at
the University of Illinois at Urbana-Champaign, and
an ACM Distinguished Scientist. He worked at Clairvoyance Corp. as a Research Scientist and a Senior
Research Scientist from 1997 to 2000. His research
interests include information retrieval, text mining,
machine learning, biomedical informatics, and intelligent education systems.

