1436

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 5, MAY 2014

Visual and Auditory Brain–Computer Interfaces
Shangkai Gao∗ , Fellow, IEEE, Yijun Wang, Member, IEEE, Xiaorong Gao, Member, IEEE,
and Bo Hong, Member, IEEE

Abstract—Over the past several decades, electroencephalogram
(EEG)-based brain–computer interfaces (BCIs) have attracted attention from researchers in the field of neuroscience, neural engineering, and clinical rehabilitation. While the performance of BCI
systems has improved, they do not yet support widespread usage.
Recently, visual and auditory BCI systems have become popular
because of their high communication speeds, little user training,
and low user variation. However, building robust and practical
BCI systems from physiological and technical knowledge of neural modulation of visual and auditory brain responses remains a
challenging problem. In this paper, we review the current state
and future challenges of visual and auditory BCI systems. First,
we describe a new taxonomy based on the multiple access methods
used in telecommunication systems. Then, we discuss the challenges of translating current technology into real-life practices and
outline potential avenues to address them. Specifically, this review
aims to provide useful guidelines for exploring new paradigms and
methodologies to improve the current visual and auditory BCI
technology.
Index Terms—Brain–computer interface (BCI), visual BCI, auditory BCI, multiple access (MA).

I. INTRODUCTION
RAIN–COMPUTER interfaces (BCIs) establish a direct
communication channel between a brain and a computer
or external device. The primary aim of BCI research is to create a
nonmuscular communication channel so that people with severe
motor disabilities can use it for communication and control. BCI
has rapidly developed into a highly recognized field of biomedical engineering in the past few decades. Among different brain
imaging techniques that have been applied to BCIs, electroencephalography (EEG) is the most commonly used method and
the only type we studied in this paper.

B

Manuscript received September 22, 2013; revised December 17, 2013 and
January 8, 2014; accepted January 8, 2014. Date of publication January 14, 2014;
date of current version April 17, 2014. This work was supported by National
Basic Research Program (973) of China under Grant 2011CB933204, National
Natural Science Foundation of China under Grant 90820304, Grant 91120007,
and Grant 91220301, National High-tech R&D Program (863) of China under
Grant 2012AA011601, and Tsinghua University Initiative Scientific Research
Program under Grant 20111081111. Asterisk indicates corresponding author.
∗ S. Gao is with the Department of Biomedical Engineering, Tsinghua University, Beijing 100084, China (e-mail: gsk-dea@tsinghua.edu.cn).
Y. Wang is with Swartz Center for Computational Neuroscience, Institute for
Neural Computation, University of California San Diego, La Jolla, CA 92093
USA (e-mail: yijun@sccn.ucsd.edu).
X. Gao and B. Hong are with the Department of Biomedical Engineering,
Tsinghua University, Beijing 100084, China (e-mail: gxr-dea@tsinghua.edu.cn;
hongbo@tsinghua.edu.cn).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2014.2300164

While performance of EEG-based BCI systems is slowly increasing, the current levels of BCI performance do not yet support widespread usage. Accordingly, visual and auditory BCI
systems (hereinafter referred to as v-BCI and a-BCI, respectively) that exhibit high communication speed and classification
accuracy have become more popular in recent BCI research.
Specifically, the v-BCI and a-BCI systems covered in this review only include BCIs based on brain responses to exogenous
visual or auditory stimuli [e.g., steady-state visual evoked potentials (SSVEP) and auditory steady-state responses (ASSR)]
and endogenous potentials linked to the reaction to the visual or
auditory stimuli [e.g., visual and auditory P300 event-related
potentials (ERPs)]. Exogenous and endogenous brain responses
generally represent sensory-specific stimulus processing and
nonsensory-specific mental processing, respectively. Note that,
this review does not include BCIs based on other EEG signals
(e.g., BCIs based on motor imagery [1], and BCIs based on slow
cortical potentials (SCPs) [2]), although most of them use cues
and feedbacks in visual or auditory modalities.
A. Historical Review
The term “brain–computer interface” first appeared in 1970s.
Vidal used the term to express the concept of putting observable electrical brain signals to work as carriers of information in
man-computer communication or for the purpose of controlling
external apparatus [3], [4]. In the following decades, several
pioneers developed many of the classical v-BCI paradigms. In
1988, Farwell and Donchin reported a BCI paradigm based on
P300 evoked potentials [5]. This 6 × 6 matrix visual speller
system demonstrated the promising prospect of real BCI applications. In the early 1990s, a number of new BCI paradigms
were proposed. An efficient visual evoked potential (VEP) based
BCI system was presented by Sutter in 1992 [6]. The 8 × 8
speller determined the user’s intents by recognizing the direction of eye gaze using VEP recorded from the visual cortex.
This study reported the first clinical application of v-BCI which
obtained a communication speed above 10 words per minute
in an amyotrophic lateral sclerosis (ALS) patient. In addition
to these well-known studies, there were others in this period
that received less attention by the BCI community. For example, Principe’s group had proposed a novel system based on
the cognitive response to congruent or incongruent words in a
sentence in 1990 [7]. The studies in this period laid important
groundwork for the field.
In the first decade of the new century, v-BCI and a-BCI research achieved rapid development. The numbers of research
groups and scientific publications increased tremendously. Advanced signal processing and machine learning techniques have
been applied to system implementation [8], [9]. Many new BCI

0018-9294 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

GAO et al.: VISUAL AND AUDITORY BRAIN–COMPUTER INTERFACES

paradigms, such as SSVEP-based BCI [10], [11], motion onset VEP-based BCI [12], as well as auditory BCIs [13], [14],
emerged and gradually matured. Meanwhile, the early developed paradigms (e.g., BCIs based on P300 and VEPs) were significantly improved and resulted in initial clinical trials. These
systems were proved applicable to patients with ALS, stroke,
and spinal cord injury [14]–[17].
During the past several years, the clinical application of vBCIs and a-BCIs has received increased attention [18], [19].
Sellers et al. [18] tested the P300-based BCI with an ALS patient during long-term independent home use. Recently, the aBCI system has been further tested in patients with disorders of
consciousness [19]. With the rapid development of the v-BCI
and a-BCI technology, researchers in the broader scientific and
medical communities have become involved. The potential applications go far beyond the initial clinical settings. Recently,
new subtypes of BCI (e.g., hybrid BCI [20], passive BCI [21],
emotional BCI [22], and collaborative BCI [23]) have appeared
in various publications. The v-BCI and a-BCI technology contributes a lot to these new BCI paradigms. There is no general
consensus about whether the new types conform to the original BCI definition. However, the relaxed restrictions of the BCI
definition has broadened its applications and will hopefully lead
to further advances in the coming decades.
B. About This Review
The v-BCI and a-BCI systems have become more popular in
recent BCI research. However, building robust and practical systems from physiological knowledge of the modulation of neural
responses to visual and auditory stimulus still poses a great
challenge to researchers. In the BCI literature, the published review papers tend to focus on specific engineering aspects such
as signal processing [24], [25], classification [26]–[28], general
system design [29]–[33], or applications [34], [35]. A methodological review of v-BCI and a-BCI systems that describes their
current stage as well as future challenges is missing. This topic
is of significant importance for the following reasons:
1) The v-BCI and a-BCI can be categorized into gaze dependent and gaze independent systems. The gaze dependent
v-BCI systems take advantage of high signal-to-noise ratio
(SNR) in EEG recordings and high information transfer
rates (ITRs). The gaze independent v-BCI and a-BCI systems can provide relatively high system performance for
locked-in patients who cannot use gaze dependent BCIs.
Since high BCI performance relies on reliable, repeatable,
and distinguishable brain signals, the v-BCI and a-BCI
systems can provide robust system performance. Other
advantages might include fewer electrodes, less user training, and lower user variation [36], [37]. All of these reasons make v-BCI and a-BCI systems a good candidate for
real-life applications.
2) The current v-BCI and a-BCI systems lack a unified system framework, in part due to the fact that they have
been studied separately since their conception. A summary of the general paradigms and methodologies developed in the v-BCI and a-BCI systems will facilitate future

1437

Fig. 1. Brain signal modulation in visual and auditory BCI systems. The
scalp topographies illustrate an example of temporospatial patterns of ERPs to
auditory target digits [39]. N2 and the LPC reflect attentional control and mental
process, respectively.

development and improvement. Their common properties
such as the multiple target coding methods and the challenges in signal processing and classification have never
been systematically reviewed or summarized.
The present review will focus on the current state and future
challenges of the v-BCI and a-BCI systems. To put all varieties
of v-BCI and a-BCI systems in a unified framework, we borrow the concept of signal modulation and multiple access (MA)
methods [38] from the telecommunication systems. The remaining parts of this review are organized as follows. Section II introduces the general methods for brain signal modulation and
the commonly used brain signals in current v-BCI and a-BCI
systems. Section III describes the information stream followed
by a taxonomy summary of v-BCI and a-BCI paradigms under
a unified framework based on the MA methods. Section IV explores the challenges and strategies to cope with them. Finally,
a brief summary is given in Section V.
II. BRAIN SIGNALS IN V-BCI AND A-BCI
A. Brain Signal Modulation
Brain signals could be modulated by exogenous stimuli or endogenous mental activities. As shown in Fig. 1, the exogenous
stimuli in v-BCI and a-BCI systems are visual and auditory
stimuli, while endogenous components could be induced by
users’ covert attention or mental tasks. These brain responses
can happen at sensation, perception, or cognition levels. Sensation is the processing of senses by the sensory system to external
stimulus signals. Evoked potentials (EP) produced by visual and
auditory stimuli reflect typical sensation processes. Perception
deals with the organization, identification, and interpretation of
sensory information. A sensory perception at conscious level allows the individuals to sense the environment around them. The
process of cognition contains attention, learning, reasoning, decision making and so on. In a BCI system, the brain responses of
the above three stages can be modulated by voluntary attention
of the subject, thus the conveyed information can be encoded.
The features in the modulated brain signals can be extracted in
time, frequency, or space domains. The combination of features
from different domains can substantially improve classification
accuracy, and thereby enhancing the BCI performance.

1438

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 5, MAY 2014

B. Brain Signals for v-BCI and a-BCI
The brain signals commonly used in the v-BCI and a-BCI
systems are listed later.
1) Brain Signals Modulated by Exogenous Stimulus:
a) visual evoked potentials, VEP (transient VEP, SSVEP, motion VEP, code-modulated VEP) [6], [40]; and
b) auditory steady-state responses (ASSR) [41].
VEPs are brain’s response to visual stimuli, which can be
recorded with maximum amplitude over the occipital region on
the scalp [40]. The subtypes of VEPs in current v-BCIs include:
1) transient VEP (TVEP) under low-rate stimulus condition
(<2 Hz); 2) steady-state VEP (SSVEP) under high-rate stimulus condition (>6 Hz); 3) motion VEP, which reflects visual
motion processing; and 4) code-modulated VEP, which can be
elicited by a pseudo-random stimulus sequence [6]. ASSR is an
exogenous brain signal that has been used in current a-BCIs.
ASSR is an auditory EP (AEP) in response to rapid auditory
stimuli, which can be recorded from the scalp with maximum
amplitude at the vertex [41].
2) Endogenously Modulated Brain Signals:
a) response to oddball stimulus (auditory mismatch negativity (MMN) [42], N200 and P300 [43]);
b) response to mental tasks [late positive components (LPC)]
[44];
c) response inhibition (No-Go N2) [45];
d) semantic processing (N400) [46]; and
e) attention-modulated brain signals (SSVEP, ASSR) [47],
[48].
Endogenous ERP signals play important roles in v-BCIs and
a-BCIs. Major ERP components used in current v-BCIs and aBCIs include MMN, N200, P300, LPC, No-Go N2, and N400.
The auditory MMN, which is a frontocentral negative potential originating from the auditory cortex, peaks at 150–250 ms
from the onset of the deviant stimulus [42]. N200 and P300
ERP components, maximal over the central and parietal areas,
reflect stimulus evaluation, selective attention, and conscious
discrimination in oddball tasks [43]. LPC, which have a parietal maximum, reflect cognitive response selection process in
mental tasks [44]. No-Go N2, which is mainly distributed over
the frontal-central area, reflects inhibitory response control [45].
N400 is a brain response to words and other meaningful stimuli,
typically showing a centro-parietal scalp distribution [46]. In
addition to ERP signals, endogenous attention has been widely
used in v-BCIs and a-BCIs. Selective attention such as spatial
attention has been found to significantly modulate the amplitude
of SSVEP and ASSR [47], [48].
III. MULTIPLE TARGET CODING IN V-BCI AND A-BCI
A. Information Stream in v-BCI and a-BCI
The technologies in the telecommunication system can inspire new train of thoughts in BCI designs. Essentially, information stream in a BCI is quite similar to a telecommunication system. To express different intents, brain signals must be
modulated in a certain way so that the intent embedded EEG
signals can be then demodulated into the original messages.

Meanwhile, to avoid the mutual interference, the modulated
brain signals for different intents should be orthogonal or near
orthogonal to each other. For this purpose, the modulated brain
signals could be arranged by time/frequency/code/space divisions. This strategy is similar to the MA technology that allows
multiple users to simultaneously share the bandwidth with least
performance degradation in telecommunication systems [38].
There are four basic MA schemes: time-division multiple access
(TDMA), frequency-division multiple access (FDMA), codedivision multiple access (CDMA), and space-division multiple
access (SDMA). In TDMA, the users are allotted different time
slots during which they have the entire channel bandwidth. In
FDMA, the entire bandwidth is divided into a number of partial frequency bands and distributed among users. In CDMA,
the users are assigned separate codes to modulate their signals,
which differentiate them from each other. SDMA divides the
geographical space into smaller spaces and discriminates users
based on their spatial locations. Details of these methods can be
found in [38]. In fact, we can find analogies to all these methods in v-BCI and a-BCI systems [49]. The basic principles of
the multiple target access methods used in BCIs are described
in Table I. In most ERP-based BCIs, multiple targets appear
at different time slots following the principle of TDMA. The
SSVEP-based BCI is a typical FDMA system in which each
target occupies its own frequency band without overlap. The
BCI based on pseudorandom code modulated VEP works in
a similar way to the CDMA method. The SDMA method has
been applied to the designs of v-BCI, in which the EEG signals
are modulated by different target locations in the visual field.
In addition, the hybrid multiple access (HMA) method has recently been employed in the v-BCI studies to improve system
performance [50]–[54].
B. Taxonomy of v-BCI and a-BCI
Current BCI systems could be classified by operation
manner (such as dependent/independent BCIs and synchronous/asynchronous BCIs) or the brain signals employed
in the system (e.g., SSVEP and P300) [55]. Here, to highlight
the nature of BCI as a novel communication system, we propose a new taxonomy to sort the existing v-BCI and a-BCI
according to the multiple target access methods (see Table I).
In our previous study, the VEP-based BCI systems were categorized using this classification method [49]. This study further
extends the taxonomy to classify all v-BCI and a-BCI systems
in a comprehensive and systematic way. Similar to the classification of the telecommunication systems, the v-BCI and a-BCI
systems can be sorted into the following five groups: 1) TDMA,
2) FDMA, 3) CDMA, 4) SDMA, and 5) HMA. In this way,
v-BCI and a-BCI systems can be examined under a unified
framework based on multiple target access methods. There are
three primary advantages to this categorization. First, it simplifies the understanding of the design and implementation of
v-BCI and a-BCI systems, making it easier for BCI researchers
to incorporate existing technologies from traditional communication into these systems. For example, system design optimization and system performance evaluation methods in the

GAO et al.: VISUAL AND AUDITORY BRAIN–COMPUTER INTERFACES

TABLE I
VISUAL AND AUDITORY BCI PARADIGMS

1439

1440

telecommunication systems are easily transferable. Second, it
facilitates the comparison between v-BCI and a-BCI as well
as between systems using different EEG signals. For example,
the auditory and visual P300 BCI systems are grouped together
into the TDMA category. In this way, methods and techniques
applied separately in v-BCI and a-BCI systems can be better
understood and then integrated to improve system performance.
Third, it can help to transfer the existing methodologies and
techniques in communication systems to improve system performance of the current v-BCI and a-BCI systems. For example,
the signal modulation and demodulation methods in telecommunications can be adopted to develop new BCI paradigms with
more robust system performance [56].
Table I lists stimulus, brain response, and representative publications of the v-BCI and a-BCI systems according to the proposed taxonomy. The following findings illustrate the characteristics of the multiple target access methods in the current v-BCI
and a-BCI technology. First, it is clearly shown that TDMA and
FDMA are the two most popular methods in system design.
Specifically, TDMA has been widely used in the P300-based
BCI systems, while FDMA has been applied to the SSVEPand ASSR-based BCI systems. Second, CDMA has rarely been
used. However, the highest ITR in current BCI systems was obtained by the code-modulated VEP-based BCI system [57]. In
general, CDMA requires rapid brain responses to the stimulus
sequence. In practice, brain signal analysis and stimulus design
pose large challenges for any implementation of CDMA in a BCI
system. Third, the HMA method was recently introduced into
v-BCI studies. The representative studies show its potential for
improving BCI performance. In addition to the common characteristics in the v-BCI and a-BCI systems, Table I also indicates
the different properties of v-BCI and a-BCI systems. First, the
number of studies on v-BCI is much larger than a-BCI. Also, vBCI and a-BCI systems specialize in different aspects. The gaze
dependent v-BCI systems can reach very high ITR specifically
due to the advantage of high SNR of VEP signals. However,
for the independent BCI systems where the user cannot use
muscle control such as eye gazing to operate the system, the aBCI and v-BCI systems show comparable performance. Second,
the multiple target access methods for v-BCI are more diverse
than a-BCI. Currently, the CDMA, SDMA, and HMA methods
are missing in the a-BCI systems. It is obvious that v-BCI has
been more thoroughly investigated since it has been studied for
much longer time than the a-BCI systems. It is generally more
difficult to implement CDMA and SDMA in a-BCI systems.
Compared with VEP signals, sequential coding of ERP signals
in a-BCIs using a CDMA paradigm will be much slower due to
a larger interstimulus interval (ISI). In a-BCIs that use stimuli
from multiple locations, spatial modulations of EEG signals are
generally weak and difficult to detect. Although some a-BCIs
use spatial location to enhance the ERP signals [58], [59], this
review attributes these systems to the TDMA category since
no space-specific information was used for target identification.
This finding might also suggest that there is significant room for
improvement in a-BCI systems. For example, the HMA method
that combines TDMA and FDMA might be useful to improve
overall system performance.

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 5, MAY 2014

IV. CHALLENGES
A. Addressing BCI-Related Electrophysiological Issues
This review considered BCI systems as communication channels and categorized them according to the multiple target access
method used in system design. This new taxonomy facilitates
the comparison of v-BCI and a-BCI systems and also simplifies
the understanding of the design and implementation of a BCI
system from an engineering perspective. However, as the most
complex biological system, the human brain is much more complicated than a telecommunication system. Its intrinsic properties such as nonlinearity and nonstationarity pose big challenges
when trying to implement a robust BCI system. These electrophysiological issues seriously affect BCI performance. To build
a practical system, these issues must be taken into account when
designing and implementing a system.
1) Nonlinearity in EEG: The brain is a nonlinear system
in which population dynamics of neural ensembles can be observed [108]. Its activities such as EEG signals can be better characterized by nonlinear dynamic methods than linear
methods [109], [110]. The nonlinearity in EEG signals has to
be treated carefully in the v-BCI and a-BCI systems. In general, it could affect BCI performance in two opposite ways.
First, it could lead to additional information for improving classification. For example, nonlinearity exists in signal generation of SSVEPs in human visual cortex. The nonlinear resonance phenomena of SSVEPs can be distinctly characterized
by brain responses at frequencies identical, harmonic, and subharmonic to the stimulus frequency [111]. Therefore, the harmonic components can provide useful information additional to
the fundamental frequency component for detecting the stimulus frequency. The efficiency of combining multiple harmonic
components has been well demonstrated in the SSVEP-based
BCIs [11], [37], [95]. Second, some nonlinear properties in the
brain could degrade the task-related EEG signals and thereby
deteriorate the BCI performance. This situation commonly exists in ERP signals, which are highly sensitive to neurophysiological parameters [112]. For example, there is a limit to how
fast the brain can process incoming stimuli. When two stimuli
have to be processed within a short interval, the response to the
second stimulus is significantly slowed (psychological refractory period). Similarly, when two visual targets are presented
in rapid succession, people will often fail to detect the second
target (attentional blink). These effects show nonlinear modulation of the P3 component [113], [114]. To build a robust BCI
system, avoiding these events when they occur must be included
in system design.
2) Nonstationarity in EEG: The nonstationarity of brain activity in association with diverse mental and behavioral states
occurs continuously over time [115]. It can be caused by the
brain’s internal factors such as variabilities in neurophysiological states and psychological parameters, as well as external factors such as changes of electrode contact and electrode
position, movement artifacts, and environmental noises. Similar to other BCIs, a major challenge in the v-BCI and a-BCI
systems is the intersession nonstationarity in the EEG data
that often leads to deteriorated BCI performance. Specifically,

GAO et al.: VISUAL AND AUDITORY BRAIN–COMPUTER INTERFACES

intersession nonstationarity in EEG classification can be attributed to the differences between a training session and an
online session, and the changes across multiple online sessions
[116]. To address this problem, adaptive classification methods
that can automatically update the classifiers during online BCI
operations have been developed [117], [118]. In addition, zerotraining methods have attracted increasing attention in recent
BCI studies [76], [119], [120]. The zero-training methods aim to
solve the nonstationarity problem in feature extraction and classification by integrating information across multiple sessions or
subjects. Another challenge within a smaller time scale is the intertrial nonstationarity in EEG signals. The trial-to-trial variability can lead to variation of SNR in single-trial EEG signals [121].
Therefore, optimizing parameters for single-trial EEG signals
plays an important role in EEG classification. For example, a
typical problem in the ERP-based BCI is the number of trial repetitions required for target identification, which is crucial for reducing target detection time. In addition, the nonstationary problem may be alleviated by using advanced data analysis methods.
For example, stationary subspace analysis (SSA), which can decompose multivariate time series into stationary and nonstationary components, has been found applicable to BCI data [122].
B. Improving ITR
One of the major challenges in advancing v-BCI and a-BCI
technology is the performance bottleneck, which is mostly attributed to the poor SNR of EEG signals [55]. A variety of
metrics have been proposed to evaluate the performance of BCI
systems [123]. In current systems, ITR is the most widely used
metric. The ITR (in bits/minute) defined by Wolpaw et al. [55]
is calculated as follows:

  

1−P
60
∗
(1)
ITR = log2 M +P log2 P +(1−P ) log2
M −1
T
where M is the number of choices, P is the accuracy of target
detection, and T (in seconds/selection) is the average time for
a selection. More details of ITR estimation in online BCIs can
be found in [124]. According to (1), the methods to improve
ITR can be considered regarding to M, P , and T separately.
Although these three parameters always interact with each other
in real systems, to facilitate summarizing the existing studies,
this study considers the three factors separately.
1) Improving Target Detection Accuracy: In general, the target detection accuracy can be improved in two different ways:
1) improving the SNR of task-related EEG signals, and 2) maximizing the separability of multiple classes. To achieve these
goals, efforts have been made to increase the amplitude and
dimension of features in the task-related EEG signals. Besides,
advanced data analysis techniques such as signal processing and
machine learning approaches have also been widely employed
in current BCI systems [24], [26], [27], [125], [126].
a) Signal-to-Noise Ratio
Improving the SNR of EEG signals is done by increasing the
signal level and/or decreasing the noise level. First, SNR can
be improved through applying advance signal processing methods. Trial averaging, commonly used to improve the SNR in

1441

ERP analysis, has been widely used in current v-BCI and a-BCI
systems [55]. Recently, trial averaging across subjects has been
applied in a collaborative BCI to improve the performance of an
individual BCI [23], [77]. Spatial filtering can be used to project
multichannel EEG data into a low-dimensional spatial subspace
to eliminate task-irrelevant components and improve the SNR of
task-related EEG signals. For example, the canonical correlation
analysis (CCA) approach significantly improved the frequency
detection of SSVEP [89], [97], [127]. CCA maximizes the correlation between the SSVEP signals and predefined reference
signals [127]. Another widely used spatial filtering method is
independent component analysis (ICA) [64], [128]. ICA enhances the SNR of EEG signals by separating task-related EEG
components from the task-irrelevant EEG components and the
artifactual components [129], [130].
SNR can also be improved by eliciting enhanced task-related
EEG signals. The amplitude of ERP signals always correlates
to the user’s cognitive states associated with attention and emotion. Therefore, cognitive tasks can be employed in the stimulus
design to generate more robust ERP signals. This concept has
been proved highly efficient in recent studies. For example,
compared with a cue without spatial properties, the combination of both pitch properties and spatial location of the stimulus
in a discriminating cue significantly improved the system performance of a multiclass a-BCI [58]. In another a-BCI using
active mental response, the subject’s voluntary recognition of
the property of the target digits (e.g., left versus right side; male
versus female voice) enhanced the ability to discriminate between brain responses (N2 and LPC components) to target and
nontarget digits [39], [78]. In a motion VEP-based BCI, the
involvement of counting in target identification showed significantly improved amplitude of motion VEP signals compared
to gazing [12]. In a recent study, Lakey et al. [72] manipulated
attention in a P300-based BCI using a short mindfulness meditation induction (MMI) and found MMI subjects produced significantly larger P300 amplitudes than control subjects. Belitski
et al. [87] employed simultaneous visual and auditory stimuli
to enhance the P300 and thereby improved the performance of
the classic visual P300 speller. In an affective SSVEP-based
BCI, visual stimuli using emotional human faces significantly
enhanced the amplitude of the SSVEP signals compared with
the checkerboard stimuli [131].
b) Separability of Multiple Classes
Target detection accuracy depends on the separability of multiple classes. Machine learning techniques have been widely
used to improve target detection accuracy in BCI systems [132].
The techniques used in current BCIs include diverse methods for feature selection, feature combination, and classification [26], [132]. In system design, separability of multiple
classes can be improved by increasing the dimension of informative features in the task-related EEG signals. For example, in the
SSVEP-based BCI using frequency coding, multiple-frequency
coding has been used to build complex flickering stimuli to improve the separability of multiple classes [101], [102]. Recently,
the method of hybrid EEG signals has been proposed, combining multiple EEG signals that carry independent information. For example, Yin et al. [51] integrated random flashes and

1442

flickers to simultaneously evoke the P300 and SSVEP signals.
In another study, stimuli of facial images were used in the oddball paradigm to elicit the face-sensitive ERP component N170,
which was combined with P300 to enhance target detection [53].
In addition, another efficient way is to use complex coding methods such as the CDMA technology in system design. The BCI
based on code-modulated VEP used orthogonal m-sequences to
elicit VEP signals that could be easily discriminated by crosscorrelation analysis [6], [57].
2) Increasing Number of Classes: The number of classes
plays an important role in a BCI system. In general, the BCIs
with high ITR have a large number of classes [5], [61], [133].
Compared to other BCIs, v-BCI and a-BCI systems are more
capable of providing a large amount of classes to implement
complex applications. The P300 BCI and the SSVEP BCI are
two systems that can realize a large amount of classes [36], [37].
Obviously, MA methods facilitate the implementation of a large
number of classes in these two types of BCIs. The P300 BCI
systems typically use the TDMA method to code target stimuli. A row/column flashing approach has been commonly used
to implement a stimulus matrix such as the well-known P300
speller using a 6 × 6 matrix [5]. Recently, other stimulus presentation methods have been developed to improve the row/column
approach. For example, the method of flashing quasi-random
groups of characters realized a 7 × 12 matrix speller [68]. Several stimulus coding methods including FDMA and CDMA
have been adopted in the VEP-based BCI systems. For example, the BCI system using code-modulated VEP can realize
paradigms with 32 or 64 classes [6], [57]. Currently, frequency
coding is the most widely used method in the SSVEP BCI.
Multiple-frequency coding methods have also been used to increase the number of classes [99], [100]. In addition, mixed
coding approaches such as frequency-phase mixed coding [96]
and frequency-space mixed coding [52] have been developed in
recent studies.
3) Reducing Target Detection Time: Generally, target detection time can be reduced by considering the following aspects.
First, single-trial classification can be much more efficient than
trial averaging. Currently, machine learning based single-trial
analysis is widely used [126]. Second, adaptive methods can
reduce target detection time. For example, the method of adaptive number of trial repetitions, which is called “dynamic stopping” in [134], can significantly improve performance of the
ERP-based BCIs [66], [73]. The “smart stopping” method, in
which the time to stop trial repetitions was determined based
on the real-time monitoring of the SNR of the ERP signals,
functioned in a similar way [62]. In the SSVEP-based BCIs, the
data length of frequency detection was adjusted automatically
to meet the target detection criterion in each selection [11], [15].
Third, optimized stimulus presentation can reduce target detection time. This method has been well studied in the P300 BCIs.
One straightforward way is to reduce the duration of the ISI
between two flashes in stimulus presentation [65]. In practice, a
tradeoff between ISI and accuracy needs be made towards higher
system performance. Another way is to optimize the stimulus
coding method. For example, the traditional row/column coding method can be improved by coding quasi-random groups of

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 5, MAY 2014

characters [68]. In this way, the number of flashes per trial for
identifying a target character can be significantly reduced.
C. Implementing Real-Life Applications
Currently, moving a BCI system from the laboratory into reallife applications poses severe challenges for the BCI community [35], [135], [136]. Usability and user experience will play a
key role in widening the application of the BCI technology. The
following issues need to be addressed in a practical BCI system:
1) ease of use; 2) low-cost hardware and software; and 3) robust
system performance [137]. Compared to other BCIs that do not
require external stimulation, the v-BCI and a-BCI systems pose
more challenges in terms of system design and implementation.
Tackling these two topics for practical systems, this review focuses on three major challenges: 1) the development of a mobile
BCI platform; 2) methods to reduce fatigue; and 3) the design
of asynchronous system control. Then, it summarizes potential
applications of the v-BCI and a-BCI systems.
1) Mobile System Design: A mobile BCI platform technology can enable and facilitate numerous BCI applications
in real-world environments. The implementation of a mobile
BCI system should consider the following three major challenges. First, a mobile BCI requires mobile hardware solutions for EEG device, data processing platform, and stimulation device. Using bulky, expensive, wired hardware components will not only cause discomfort and inconvenience, but
will also affect the ability of users to perform routine tasks.
Recently, researchers have made rapid progress in the mobile
EEG technology featuring miniature wireless EEG amplifier
and dry electrode [138]–[140]. As a result, mobile BCIs have
emerged rapidly [141]. For example, a cell-phone based mobile
BCI system was demonstrated with a phone-dialing program
using SSVEPs [137]. A mobile P300-based a-BCI was demonstrated while subjects walked outdoors [86]. Second, the number
of electrodes needs to be reduced to facilitate system use and
reduce system cost. Different electrode selection methods have
been proposed in BCI studies [37], [71], [142]. For example, in
the SSVEP BCI, the selection of a bipolar electrode efficiently
extracted SSVEPs with a high SNR [15]. Third, the system
needs to be capable of solving the problem of artifacts in EEG
signals since movement artifacts and ambient noises are much
more severe in real-world environments. The emerging mobile
brain imaging (MOBI) technology [143] could help solve this
problem.
2) Fatigue Reduction: Mental fatigue refers to a temporary
inability to maintain optimal cognitive performance resulting
from prolonged periods of cognitive activity. Mental fatigue can
cause discomfort and decreased attention, and thereby degrades
the amplitude of EEG signals [144]. Since visual or auditory
stimulations are required in v-BCI and a-BCI systems, mental fatigue should be reduced as much as possible so that the
system will remain practical for daily use. In general, this can
be done by optimizing the physical properties of the stimulus.
Currently, visual fatigue is one of the biggest disadvantages of
v-BCI systems, significantly hindering their use in real-life applications. To solve this problem, researchers have made great

GAO et al.: VISUAL AND AUDITORY BRAIN–COMPUTER INTERFACES

efforts in optimizing the physical properties of the visual stimulus to reduce the discomfort. For example, different types of
stimulus patterns such as high-frequency stimulus [93], high
duty-cycle stimulus [94], and image-based stimulus [131] have
been proposed for reducing visual fatigue while maintaining robust performance in the SSVEP-based BCIs. In another study,
Hong et al. [61] investigated fatigue effect in two v-BCI systems
using N200 (i.e., motion-onset VEP) and visual P300, respectively. The N200 was found insensitive to fatigue caused by trial
repetitions, whereas the visual P300 showed significant amplitude decrease associated with visual fatigue. Recently, stimulus
optimization has also been employed in the a-BCI systems. In
one instance, because selective listening to natural stimuli is
much more comfortable than artificial auditory stimuli such as
pure tones, natural syllables were used to build an a-BCI [83].
3) Asynchronous System Design: Most current v-BCIs and
a-BCIs use synchronous control protocols where the period of
control is initiated by the system. However, asynchronous control protocols, in which the user makes self-paced decisions on
when to start or stop using the system [145], are more flexible
and natural. An important issue in asynchronous control is detecting idle states. Several methods have been developed to solve
this problem. First, detecting an idle state can be improved by
adding additional EEG features into stimulus design. For example, in an SSVEP BCI, Cheng et al. [11] designed an ON-OFF
button for activating/deactivating the visual stimuli so that the
system could switch between the idle and control states. Similarly, a brain switch based on ERD/ERS or brain hemodynamic
response was designed to turn on/off an SSVEP BCI within a
hybrid BCI system [20]. In an SSVEP-based brain switch, the
discrimination of idle and control states was improved by adding
additional stimuli with different frequencies to areas around the
target stimulus [146]. In an N200 BCI, the spatial information of
the speller matrix was integrated to provide a more precise description of the motion VEP response patterns, which then could
be used to detect the noncontrol state effectively [63]. Second,
idle state detection could also be improved by developing effective computational approaches for distinguishing between EEG
signals in idle and control states. For example, in a P300 BCI,
Zhang et al. [74] proposed a computational approach to model
target P300, nontarget P300, and noncontrol EEG signals and
then derived a recursive algorithm to detect control states based
on likelihood.
4) Clinical Applications: Due to the advantages such as
high ITR and little user training, the v-BCI and a-BCI systems have been applied to many clinical applications to help
patients with motor disabilities to communicate with their environments [147]. Most v-BCI systems depend on the muscle
control of eye to gaze at the target during system use. For patients who are able to move their eyes (e.g., patients with spinal
cord injury), these gaze-dependent systems provide an alternative solution to conventional assistive devices such as eyetracking systems. Although current gaze-dependent BCIs show
lower communication speeds than the eye-tracking systems,
they have some distinct properties that make them attractive
to users. For example, the SSVEP-based BCI, which is capable to have a large number of classes, can be totally calibration

1443

free [37]. As the performance of v-BCIs continues to improve,
the gaze-dependent BCIs could provide high communication
speed comparable to the eye-tracking technologies in the near
future. For totally locked-in patients, only the independent BCI
systems can satisfy their needs. The typical independent v-BCI
and a-BCI systems include v-BCI systems using selective visual
attention and a-BCI systems using selective listening. Currently,
gaze-independent v-BCIs and a-BCIs provide comparable BCI
performance in terms of number of targets and ITR [33]. Due to
a limited number of classes, most gaze-independent BCIs used
a two-level selection procedure in complex applications such as
spelling. This procedure introduces an additional workload and
therefore limits the communication speed.
Although the v-BCIs and a-BCIs have mainly been developed
towards clinical applications, very few studies have been carried
out in patients [6], [14]–[19], [71]. Currently, there are several
reasons that limit the applicability of the v-BCIs and a-BCIs
in clinical applications. First, conventional assistive technologies such as eye-tracking systems can provide more efficient
control than gaze-dependent BCIs. Second, gaze-independent
BCIs based on SCP and motor imagery provide alternative BCI
solutions to locked-in patients. Third, totally locked-in patients
typically have difficulties in learning how to use the BCI system [147]. Joint efforts between researchers and clinicians are
required to promote the development of v-BCIs and a-BCIs
more applicable for clinical uses.
5) Other Applications: The v-BCI and a-BCI systems also
have potential in many nonclinical applications [148]. Recently,
the concept of using BCI to improve human performance has
been demonstrated by several studies. For example, the P300
BCI using a rapid serial visual presentation (RSVP) paradigm
was used to improve human performance in target detection
[70]. Other nonclinical applications include mental state monitoring [136] and video gaming [149]. By solving the challenges
discussed above, the v-BCI and a-BCI technology could benefit a much larger population whether they are patients with
disabilities or not.
V. SUMMARY
In essence, a BCI is a system that aims to read the activity of
the human brain, commonly thought to be the most complex biological system in the world. Although knowledge of the human
brain has gradually increased, we still know very little about how
it works. The lack of knowledge of the underlying neural mechanisms continues to be a challenge when building and studying
BCI technology. By conducting an in-depth analysis of brain
signal modulation, MA methods, and the practical challenges
of v-BCI and a-BCI systems, this review aims to provide useful
guidelines for exploring the new paradigms and methodologies
that are being used to improve current technology.
The original purpose of the BCI technology was to provide a
tool to help the patients with motor disabilities to communicate
with their environments [55]. From a technical point of view,
a real-time platform for brain–computer interaction is a more
general definition of BCI. Under this definition, BCI includes all
technologies that use online brain signal analysis to influence

1444

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 5, MAY 2014

human interactions with computers, their environments, and
even other humans [30]. Compared with the term “interface”,
“interaction” puts more emphasis on the process of mutual action and influence between the brain and the computer. This
interactive platform can read user’s intentions and emotions in
real time and thereby improve the traditional human–computer
interaction (HCI) technology. By monitoring the user’s cognitive state in real time, it is possible to make prompt and effective
interventions to prevent declines in cognitive and behavioral performance. In addition, by actively exercising the brain, a BCI
intervention can also facilitate clinical practice in rehabilitation.
Furthermore, BCI can even be applied to improving behavioral
performance for healthy people. Indeed, emerging applications
such as passive BCI [21], emotional BCI [22], and BCI-based
neurorehabilitation [150] have shown great potential in the last
few years.
Finally, it has to be noted that there is still a long way to
go before the BCI technology can be effective, reliable, and
affordable enough to benefit a large population in daily life.
Future scientific and technical breakthroughs, which require
collaborative efforts among multidisciplinary teams of experts
in neuroscience, engineering, and clinical rehabilitation, will be
the key to achieving the goal.
ACKNOWLEDGMENT
The authors would like to thank Dr. A. Maye and Prof. F.
Yang for their critical comments on the paper.
REFERENCES
[1] G. Pfurtscheller, D. Flotzinger, and J. Kalcher, “Brain–computer
interface—A new communication device for handicapped persons,” J.
Microcomput. Appl., vol. 16, pp. 293–299, 1993.
[2] T. Elbert, B. Rockstroh, W. Lutzenberger, and N. Birbaumer, “Biofeedback of slow cortical potentials,” Electroencephalogr. Clin. Neurophysiol., vol. 48, pp. 293–301, 1980.
[3] J. J. Vidal, “Toward direct brain–computer communication,” Annu. Rev.
Riophys. Bioeng., vol. 2, pp. 157–180, 1973.
[4] J. J. Vidal, “Real-time detection of brain events in EEG,” Proc. IEEE,
vol. 65, no. 5, pp. 633–664, May 1977.
[5] L. A. Farwell and E. Donchin, “Talking off the top of your head-toward
a mental prosthesis utilizing event-related brain potentials,” Electroencephalogr. Clin. Neurophysiol., vol. 70, no. 6, pp. 510–523, 1988.
[6] E. E. Sutter, “The brain response interface: Communication through
visually-induced electrical brain responses,” J. Microcomput. Appl.,
vol. 15, pp. 31–45, 1992.
[7] J. C. Principe, “The cortical mouse: A piece of forgotten history in noninvasive brain–computer interfaces,” IEEE Pulse, vol. 4, no. 4, pp. 26–29,
Jul. 2013.
[8] J. R. Wolpaw, N. Birbaumer, W. J. Heetderks, D. J. McFarland,
P. H. Peckham, G. Schalk, E. Donchin, L. A. Quatrano, C. J. Robinson,
and T. M. Vaughan, “Brain–computer interface technology: A review of
the first international meeting,” IEEE Trans. Rehabil. Eng., vol. 8, no. 2,
pp. 164–173, Jun. 2000.
[9] K.-R. Müller, M. Krauledat, G. Dornhege, G. Curio, and B. Blankertz,
“Machine learning techniques for brain–computer interfaces,” Biomed.
Tech., vol. 49, no. 1, pp. 11–22, 2004.
[10] M. Middendorf, G. McMillan, G. Calhoun, and K. S. Jones, “Brain–
computer interfaces based on the steady-state visual-evoked response,”
IEEE Trans. Rehabil. Eng., vol. 8, no. 2, pp. 211–213, Jun. 2000.
[11] M. Cheng, X. Gao, S. Gao, and D. Xu, “Design and implementation of a
brain–computer interface with high transfer rates,” IEEE Trans. Biomed.
Eng, vol. 49, no. 10, pp. 1181–1186, Oct. 2002.

[12] F. Guo, B. Hong, X. Gao, and S. Gao, “A brain–computer interface using
motion-onset visual evoked potential,” J. Neural Eng., vol. 5, no. 4,
pp. 477–485, 2008.
[13] N. J. Hill, T. N. Lal, K. Bierig, N. Birbaumer, and B Schölkopf, “An
auditory paradigm for brain–computer interfaces,” in Advances in Neural
Information Processing Systems. Cambridge, MA: MIT Press, 2005,
pp. 569–576.
[14] E. W. Sellers and E. Donchin, “A P300-based brain–computer interface:
Initial tests by ALS patients,” Clin. Neurophysiol., vol. 117, pp. 538–548,
2006.
[15] Y. Wang, R. Wang, X. Gao, B. Hong, and S. Gao, “A practical VEPbased brain–computer interface,” IEEE Trans. Neural Syst. Rehabil.
Eng., vol. 14, no. 2, pp. 234–239, Jun. 2006.
[16] F. Piccione, F. Giorgi, P. Tonin, K. Priftis, S. Giove, S. Silvoni, G. Palmas,
and F. Beverina, “P300-based brain computer interface: Reliability and
performance in healthy and paralysed participants,” Clin. Neurophysiol.,
vol. 117, no. 3, pp. 531–537, Mar. 2006.
[17] A. Kübler, A. Furdea, S. Halder, E. M. Hammer, F. Nijboer, and
B. Kotchoubey, “A brain–computer interface controlled auditory eventrelated potential (P300) spelling system for locked-in patients,” Ann. NY
Acad. Sci., vol. 1157, pp. 90–100, 2009.
[18] E. W. Sellers, T. M. Vaughan, and J. R. Wolpaw, “A brain–computer interface for long-term independent home use,” Amyotroph. Lateral Scler.,
vol. 11, no. 5, pp. 449–455, 2010.
[19] D. Lulé, Q. Noirhomme, S. C. Kleih, C. Chatelle, S. Halder, A. Demertzi,
M.-A. Bruno, O. Gosseries, A. Vanhaudenhuyse, C. Schnakers,
M. Thonnard, A. Soddu, A. Kübler, and S. Laureys, “Probing command
following in patients with disorders of consciousness using a brain–
computer interface,” Clin. Neurophysiol., vol. 124, no. 1, pp. 101–106,
2013.
[20] G. Pfurtscheller, B. Z. Allison, G. Bauernfeind, C. Brunner, T. Solis
Escalante, R. Scherer, T. O. Zander, G. Mueller-Putz, C. Neuper, and
N. Birbaumer, “The hybrid BCI,” Front. Neurosci., vol. 4, 2010.
[21] T. O. Zander and C. Kothe, “Towards passive brain–computer interfaces:
Applying brain–computer interface technology to human–machine systems in general,” J. Neural Eng., vol. 8, no. 2, p. 025005, 2011.
[22] G. Garcia-Molina, T. Tsoneva, and A. Nijholt, “Emotional brain–
computer interfaces,” Int. J. Auton. Adapt. Commun. Syst., vol. 6, no. 1,
pp. 9–25, 2013.
[23] Y. Wang and T.-P. Jung, “A collaborative brain–computer interface for
improving human performance,” Plos One, vol. 6, no. 5, p. e20422, 2011.
[24] A. Bashashati, M. Fatourechi, R. K. Ward, and G. E. Birch, “A survey
of signal processing algorithms in brain–computer interfaces based on
electrical brain signals,” J. Neural Eng., vol. 4, no. 2, pp. R32–R57, 2007.
[25] S. Makeig, C. Kothe, T. Mullen, N. Bigdely-Shamlo, Z. Zhang, and
K. Kreutz-Delgado, “Evolving signal processing for brain–computer interfaces,” Proc. IEEE, vol. 100, pp. 1567–1584, May 2012.
[26] F. Lotte, M. Congedo, A. Lecuyer, F. Lamarche, and B. Arnaldi, “A
review of classification algorithms for EEG-based brain–computer interfaces,” J. Neural Eng., vol. 4, no. 2, pp. R1–R13, 2007.
[27] S. Lemm, B. Blankertz, T. Dickhaus, and K.-R. Müller, “Introduction
to machine learning for brain imaging,” Neuroimage, vol. 56, no. 2,
pp. 387–399, 2011.
[28] R. Tomioka and K.-R. Müller, “A regularized discriminative framework
for EEG analysis with application to brain–computer interface,” Neuroimage, vol. 49, no. 1, pp. 415–432, 2010.
[29] L. F. Nicolas-Alonso and J. Gomez-Gil, “Brain computer interfaces, A
review,” Sensors, vol. 12, no. 2, pp. 1211–1279, 2012.
[30] B. J. Lance, S. E. Kerick, A. J. Ries, K. S. Oie, and K. McDowell, “Brain
computer interface technologies in the coming decades,” Proc. IEEE,
vol. 100, pp. 1585–1599, May 2012.
[31] S. G. Mason, A. Bashashati, M. Fatourechi, K. F. Navarro, and
G. E. Birch, “A comprehensive survey of brain interface technology
designs,” Ann. Biomed. Eng., vol. 35, no. 2, pp. 137–169, 2007.
[32] M. van Gerven, J. Farquhar, R. Schaefer, R. Vlek, J. Geuze, A. Nijholt,
N. Ramsey, P. Haselager, L. Vuurpijl, S. Gielen, and P. Desain, “The
brain–computer interface cycle,” J. Neural Eng., vol. 6, no. 4, p. 041001,
2009.
[33] A. Riccio, D. Mattia, L. Simione, M. Olivetti, and F. Cincotti, “Eye-gaze
independent EEG-based brain–computer interfaces for communication,”
J. Neural Eng., vol. 9, no. 4, p. 045001, 2012.
[34] S. Moghimi, A. Kushki, A. Marie, and T. Chau, “A review of EEG-based
brain–computer interfaces as access pathways for individuals with severe
disabilities,” Assist. Technol., vol. 25, pp. 99–110, 2013.

GAO et al.: VISUAL AND AUDITORY BRAIN–COMPUTER INTERFACES

[35] J. R. Millán, R. Rupp, G. R. Müller-Putz, R. Murray-Smith,
C. Giugliemma, M. Tangermann, C. Vidaurre, F. Cincotti, A. Kübler,
R. Leeb, C. Neuper, K.-R. Müller, and D. Mattia, “Combining brain–
computer interfaces and assistive technologies: State-of-the-art and challenges,” Frontiers Neurosci., vol. 4, p. 161, 2010.
[36] R. Fazel-Rezai, B. Z. Allison, C. Guger, E. W. Sellers, S. C. Kleih,
and A. Kübler, “P300 brain computer interface: Current challenges and
emerging trends,” Front. Neuroeng., vol. 5, p. 14, 2012.
[37] Y. Wang, X. Gao, B. Hong, C. Jia, and S. Gao, “Brain–computer interfaces based on visual evoked potentials-Feasibility of practical system
designs,” IEEE Eng. Med. Biol. Mag., vol. 27, no. 5, pp. 64–71, Sep.
2008.
[38] T. S. Rappaport, Wireless Communication, Principle and Practice, 2nd
ed. Englewood Cliffs, NJ: Prentice-Hall, 2001.
[39] J. Guo, S. Gao, and B. Hong, “An auditory brain–computer interface
using active mental response,” IEEE Trans. Neural Syst. Rehabil. Eng.,
vol. 18, no. 3, pp. 230–235, Jun. 2010.
[40] D. Regan, Human Brain Electrophysiology: Evoked Potentials and
Evoked Magnetic Fields in Science and Medicine. New York: Elsevier, 1989.
[41] T. W. Picton, M. S. John, A. Dimitrijevic, and D. Purcell, “Human auditory steady-state responses,” Int. J. Audiol., vol. 42, no. 4, pp. 177–219,
2003.
[42] R. Näätänen, Attention and Brain Function. Hillsdale, NJ: Erlbaum,
1992.
[43] S. H. Patel and P. N. Azzam, “Characterization of N200 and P300: Selected studies of the event-related potential,” Int. J. Med. Sci., vol. 2,
no. 4, pp. 47–154, 2005.
[44] M. Falkenstein, J. Hohnsbein, and J. Hoormann, “Effects of choice
complexity on different subcomponents of the late positive complex
of the event-related potential,” Electroencephalogr. Clin. Neurophysiol.,
vol. 92, pp. 148–160, 1994.
[45] E. Jodo and Y. Kayama, “Relation of a negative ERP component to
response inhibition in a go/no-go task,” Electroenceph. Clin. Neurophysiol., vol. 82, no. 6, pp. 477–482, 1992.
[46] M. Kutas and S. A. Hillyard, “Reading senseless sentences-brain potentials reflect semantic incongruity,” Science, vol. 207, no. 4427, pp. 203–
205, 1980.
[47] S. T. Morgan, J. C. Hansen, and S. A. Hillyard, “Selective attention to
stimulus location modulates the steady-state visual evoked potential,”
Proc. Natl. Acad. Sci. USA, vol. 93, pp. 4770–4774, 1996.
[48] B. Ross, T. W. Picton, A. T. Herdman, and C. Pantev, “The effect of attention on the auditory steady-state response,” Neurol. Clin. Neurophysiol.,
vol. 22, pp. 1–4, 2004.
[49] G. Bin, X. Gao, Y. Wang, B. Hong, and S. Gao, “VEP-based brain–
computer interfaces: Time, frequency, and code modulations,” IEEE
Comput. Intel. Mag., vol. 4, no. 4, pp. 22–26, Nov. 2009.
[50] Y. Zhang, P. Xu, T. Liu, J. Hu, R. Zhang, and D. Yao, “Multiple frequencies sequential coding for SSVEP-based brain–computer interface,” Plos
One, vol. 7, no. 3, p. e29519, 2012.
[51] E. Yin, Z. Zhou, J. Jiang, F. Chen, Y. Liu, and D. Hu, “A speedy hybrid BCI spelling approach combining P300 and SSVEP,” IEEE Trans.
Biomed. Eng., vol. 61, no. 2, pp. 473–483, Feb. 2014.
[52] Z. Yan, X. Gao, and S. Gao, “Right-and-left visual field stimulation:
A frequency and space mixed coding method for SSVEP based brain–
computer interface,” Sci. China Inf. Sci., vol. 54, no. 12, pp. 2492–2498,
2011.
[53] Y. Zhang, Q. B. Zhao, J. Jin, X. Y. Wang, and A. Cichocki, “A novel BCI
based on ERP components sensitive to configural processing of human
faces,” J. Neural Eng., vol. 9, no. 2, p. 026018, 2012.
[54] M. Xu, H. Qi, B. Wan, T. Yin, Z. Liu, and D. Ming, “A hybrid BCI speller
paradigm combining P300 potential and the SSVEP blocking feature,”
J. Neural Eng., vol. 10, p. 026001, 2013.
[55] J. R. Wolpaw, N. Birbaumer, D. J. McFarland, G. Pfurtscheller, and
T. M. Vaughan, “Brain–computer interfaces for communication and control,” Clin. Neurophysiol., vol. 113, no. 6, pp. 767–791, 2002.
[56] Y. Kimura, T. Tanaka, H. Higashi, and N. Morikawa, “SSVEP-Based
brain–computer interfaces using FSK-modulated visual stimuli,” IEEE
Trans. Biomed. Eng., vol. 60, no. 10, pp. 2831–2838, Oct. 2013.
[57] G. Bin, X. Gao, Y. Wang, Y. Li, B. Hong, and S. Gao, “A high-speed BCI
based on code modulation VEP,” J. Neural Eng., vol. 8, no. 2, p. 025015,
2011.
[58] M. Schreuder, B. Blankertz, and M. Tangermann, “A new auditory multiclass brain–computer interface paradigm: Spatial hearing as an informative cue,” Plos One, vol. 5, no. 4, p. e9813, 2010.

1445

[59] M. Schreuder, T. Rost, and M. Tangermann, “Listen, you are writing!
Speeding up online spelling with a dynamic auditory BCI,” Front. Neurosci., vol. 5, p. 112, 2011.
[60] P. L. Lee, J. C. Hsieh, C. H. Wu, K. K. Shyu, S. S. Chen, T. C. Yeh, and
Y. T. Wu, “The brain computer interface using flash visual evoked potential and independent component analysis,” Ann. Biomed. Eng., vol. 34,
no. 10, pp. 1641–1654, 2006.
[61] B. Hong, F. Guo, T. Liu, X. Gao, and S. Gao, “N200-speller using
motion-onset visual response,” Clin. Neurophysiol., vol. 120, no. 9,
pp. 1658–1666, 2009.
[62] T. Liu, L. Goldberg, S. Gao, and B. Hong, “An online brain–computer
interface using non-flashing visual evoked potentials,” J. Neural Eng.,
vol. 7, no. 3, p. 036003, 2010.
[63] D. Zhang, H. Song, H. Xu, W. Wu, S. Gao, and B. Hong, “An N200
speller integrating the spatial profile for the detection of the non-control
state,” J. Neural Eng., vol. 9, no. 2, p. 026016, 2012.
[64] N. Xu, X. Gao, B. Hong, X. B. Miao, S. Gao, and F. Yang, “BCI competition 2003-data set IIb: Enhancing P300 wave detection using ICA-based
subspace projections for BCI applications,” IEEE Trans. Biomed. Eng.,
vol. 51, no. 6, pp. 1067–1072, Jun. 2004.
[65] E. W. Sellers, D. J. Krusienski, D. J. McFarland, T. M. Vaughan, and
J. R. Wolpaw, “A P300 event-related potential brain–computer interface
(BCI): The effects of matrix size and inter stimulus interval on performance,” Biol. Psychol., vol. 73, no. 3, pp. 242–252, 2006.
[66] A. Lenhardt, M. Kaper, and H. J. Ritter, “An adaptive P300-based online brain–computer interface,” IEEE Trans. Neural Syst. Rehabil. Eng.,
vol. 16, no. 2, pp. 121–130, Apr. 2008.
[67] M. S. Treder and B. Blankertz, “(C)overt attention and visual speller
design in an ERP-based brain–computer interface,” Behav. Brain Funct.,
vol. 6, no. 1, p. 28, 2010.
[68] J. Jin, B. Z. Allison, E. W. Sellers, C. Brunner, P. Horki, X. Wang,
and C. Neuper, “Optimized stimulus presentation patterns for an eventrelated potential EEG-based brain–computer interface,” Med. Biol. Eng.
Comput., vol. 49, no. 2, pp. 181–191, 2011.
[69] T. Kaufmann, S. M. Schulzl, C. Grünzinger, and A Kübler, “Flashing characters with famous faces improves ERP-based brain–computer
interface performance,” J. Neural Eng., vol. 8, no. 5, p. 056016,
2011.
[70] A. D. Gerson, L. C. Parra, and P. Sajda, “Cortically coupled computer
vision for rapid image search,” IEEE Trans. Neural Syst. Rehabil. Eng.,
vol. 14, no. 2, pp. 174–179, Jun. 2006.
[71] U. Hoffmann, J. M. Vesin, T. Ebrahimi, and K. Diserens, “An efficient
P300-based brain–computer interface for disabled subjects,” J. Neurosci.
Methods, vol. 167, no. 1, pp. 115–125, 2008.
[72] C. E. Lakey, D. R. Berry, and E. W. Sellers, “Manipulating attention via
mindfulness induction improves P300-based brain–computer interface
performance,” J. Neural Eng., vol. 8, no. 2, p. 025019, 2011.
[73] H. Serby, E. Yom-Tov, and G. F. Inbar, “An improved P300-based brain–
computer interface,” IEEE Trans. Neural Syst. Rehabil. Eng., vol. 13,
no. 1, pp. 89–98, Mar. 2005.
[74] H. Zhang, C. Guan, and C. Wang, “Asynchronous P300-based brain–
computer interfaces: A computational approach with statistical models,”
IEEE Trans. Biomed. Eng., vol. 55, no. 6, pp. 1754–1763, Jun. 2008.
[75] L. Acqualagna and B. Blankertz, “Gaze-independent BCI-spelling using
rapid serial visual presentation (RSVP),” Clin. Neurophysiol., vol. 124,
no. 5, pp. 901–908, 2013.
[76] P.–J. Kindermans, D. Verstraeten, and B. Schrauwen, “A Bayesian model
for exploiting application constraints to enable unsupervised training of
a P300-based BCI,” Plos One, vol. 7, no. 4, p. e33758, 2012.
[77] P. Yuan, Y. Wang, X. Gao, T. P. Jung, and S. Gao, in A Collaborative
Brain–Computer Interface for Accelerating Human Decision Making
(UAHCI/HCII, Part I, LNCS 8009), C. Stephanidis and M. Antona, Eds.
Berlin, Germany: Springer-Verlag, 2013, pp. 672–681.
[78] H. Xu, D. Zhang, M. Ouyang, and B. Hong, “Employing an active mental task to enhance the performance of auditory attention-based brain–
computer interfaces,” Clin. Neurophysiol., vol. 24, pp. 83–90, 2012.
[79] S. Kanoh, K. I. Miyamoto, and T. Yoshinobu, “A brain–computer interface (BCI) system based on auditory stream segregation,” J. Biomech.
Sci. Eng., vol. 5, pp. 32–40, 2008.
[80] D. S. Klobassa, T. M. Vaughan, P. Brunner, N. E. Schwartz,
J. R. Wolpaw, C. Neuper, and E.W. Sellers, “Toward a high-throughput
auditory P300-based brain–computer interface,” Clin. Neurophysiol.,
vol. 120, pp. 1252–1261, 2009.
[81] A. Furdea, S. Halder, D. J. Krusienski, D. Bross, F. Nijboer,
N. Birbaumer, and A. Kübler, “An auditory oddball (P300) spelling

1446

[82]
[83]
[84]

[85]

[86]
[87]
[88]
[89]
[90]
[91]

[92]
[93]
[94]
[95]

[96]
[97]

[98]
[99]

[100]
[101]
[102]
[103]

[104]

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 5, MAY 2014

system for brain–computer interfaces,” Psychophysiology, vol. 46,
pp. 617–625, 2009.
J. Höhne, M. Schreuder, B. Blankertz, and M. Tangermann, “A novel
9-class auditory ERP paradigm driving a predictive text entry system
Front,” Front. Neurosci., vol. 5, p. 99, 2011.
J. Höhne, K. Krenzlin, S. Dähne, and M. Tangermann, “Natural stimuli
improve auditory BCIs with respect to ergonomics and performance,” J.
Neural Eng., vol. 9, no. 4, p. 045003, 2012.
S. Halder, M. Rea, R. Andreoni, F. Nijboer, E. M. Hammer, S. C. Kleih,
N. Birbaumer, and A. Kubler, “An auditory oddball brain–computer
interface for binary choices,” Clin. Neurophysiol., vol. 121, pp. 516–
523, 2010.
I. Nambu, M. Ebisawa, M. Kogure, S. Yano, H. Hokari, and Y. Wada,
“Estimating the intended sound direction of the user: Toward an auditory
brain–computer interface using out of-head sound localization,” Plos
One, vol. 8, no. 2, p. e57174, 2013.
M. De Vos, K. Gandras, and S. Debener, “Towards a truly mobile auditory brain–computer interface: Exploring the P300 to take away,” Int. J.
Psychophysiol., in press.
A. Belitski, J. Farquhar, and P. Desain, “P300 audio-visual speller,” J.
Neural Eng., vol. 8, no. 2, p. 025022, 2011.
M. A. Lopez-Gordo, E. Fernandez, S. Romero, F. Pelayo, and A. Prieto,
“An auditory brain–computer interface evoked by natural speech,” J.
Neural Eng., vol. 9, no. 3, p. 036013, 2012.
G. Bin, X. Gao, Z. Yan, B. Hong, and S. Gao, “An online multi-channel
SSVEP-based brain–computer interface using a canonical correlation
analysis method,” J. Neural Eng., vol. 6, no. 4, p. 046002, 2009.
X. Gao, D. Xu, M. Cheng, and S. Gao, “A BCI-based environmental
controller for the motion-disabled,” IEEE Trans. Neural Syst. Rehabil.
Eng., vol. 11, no. 2, pp. 137–140, Jun. 2003.
E. C. Lalor, S. P. Kelly, C. Finucane, R. Burke, R. Smith, R. B. Reilly,
and G. McDarby, “Steady-state VEP-based brain–computer interface
control in an immersive 3D gaming environment,” EURASIP J. Appl.
Signal Process., vol. 19, pp. 3156–3164, 2005.
T. Tu, Y. Xin, X. Gao, and S Gao, “Chirp-modulated visual evoked
potential as a generalization of steady state visual evoked potential,” J.
Neural Eng., vol. 9, no. 1, p. 016008, 2012.
P. F. Diez, V. A. Mut, E. M. A. Perona, and E. L. Leber, “Asynchronous
BCI control using high-frequency SSVEP,” J. Neuroeng. Rehabil., vol. 8,
p. 39, Jul. 2011.
P. L. Lee, C. L. Yeh, J. Y. S. Cheng, C. Y. Yang, and G. Y. Lan, “An
SSVEP-based BCI using high duty-cycle visual flicker,” IEEE Trans.
Biomed. Eng., vol. 58, no. 12, pp. 3350–3359, Dec. 2011.
G. R. Müller-Putz, R. Scherer, C. Brauneis, and G. Pfurtscheller,
“Steady-state visual evoked potential (SSVEP)-based communication:
Impact of harmonic frequency components,” J. Neural Eng., vol. 2,
no. 4, p. 123, 2005.
C. Jia, X. Gao, B. Hong, and S. Gao, “Frequency and phase mixed coding
in SSVEP-based brain–computer interface,” IEEE Trans. Biomed. Eng.,
vol. 58, no. 1, pp. 200–206, Jan. 2011.
J. Pan, X. Gao, F. Duan, Z. Yan, and S. Gao, “Enhancing the classification
accuracy of steady-state visual evoked potential-based brain–computer
interfaces using phase constrained canonical correlation analysis,” J.
Neural Eng., vol. 8, no. 3, p. 036027, 2011.
N. V. Manyakov, N. Chumerin, and M. M. Van Hulle, “Multichannel
decoding for phase-coded SSVEP brain–computer interface,” Int. J.
Neural Syst., vol. 22, no. 5, p. 1250022, 2012.
H. J. Hwang, D. H. Kim, C. H. Han, and C. H. Im, “A new dualfrequency stimulation method to increase the number of visual stimuli for
multi-class SSVEP-based brain–computer interface (BCI),” Brain Res,
vol. 1515, pp. 66–77, 2013.
X. Chen, Z. Chen, S. Gao, and X. Gao, “Brain–computer interface
based on intermodulation frequency,” J. Neural Eng., vol. 10, p. 66009,
2013.
T. M. S. Mukesh, V. Jaganathan, and M. R. Reddy, “A novel multiple
frequency stimulation method for steady state VEP based brain computer
interfaces,” Physiol. Meas., vol. 27, no. 1, pp. 61–71, 2006.
K. K. Shyu, P. L. Lee, Y. J. Liu, and J. J. Sie, “Dual-frequency steadystate visual evoked potential for brain computer interface,” Neurosci.
Lett., vol. 483, no. 1, pp. 28–31, 2010.
D. Zhang, A. Maye, X. Gao, B. Hong, A. K. Engel, and S. Gao,
“An independent brain–computer interface using covert non-spatial visual selective attention,” J. Neural Eng., vol. 7, no. 1, p. 016010,
2010.
S. P. Kelly, E. C. Lalor, C. Finucane, G. McDarby, and R. B. Reilly,
“Visual spatial attention control in an independent brain–computer

[105]

[106]
[107]

[108]
[109]
[110]
[111]
[112]
[113]

[114]
[115]
[116]

[117]
[118]
[119]
[120]
[121]

[122]
[123]

[124]

[125]
[126]

interface,” IEEE Trans. Biomed. Eng., vol. 52, no. 9, pp. 1588–1596,
Sep. 2005.
B. Z. Allison, D. J. McFarland, G. Schalk, S. D. Zheng, M. M. Jackson,
and J. R. Wolpaw, “Towards an independent brain–computer interface using steady state visual evoked potentials,” Clin. Neurophysiol., vol. 119,
pp. 399–408, 2008.
H. Higashi, T. M. Rutkowski, Y. Washizawa, A. Cichocki, and T. Tanaka,
“EEG auditory steady state responses classification for the novel BCI,”
in Proc. 33rd Ann. Int. Conf. IEEE EMBS, 2011, pp. 4576–4579.
D. W. Kim, H. J. Hwang, J. H. Lim, Y. H. Lee, K. Y. Jung, and C. H. Im,
“Classification of selective attention to auditory stimuli: Toward visionfree brain–computer interfacing,” J. Neurosci. Methods, vol. 197, no. 1,
pp. 180–185, 2011.
T. M. Mckenna, T. A. Mcmullen, and M. F. Shlesinger, “The brain as a
dynamic physical system,” Neuroscience, vol. 60, no. 3, pp. 587–605,
1994.
C. J. Stam, “Nonlinear dynamical analysis of EEG and MEG: Review of
an emerging field,” Clin. Neurophysiol., vol. 116, no. 10, pp. 2266–2301,
2005.
K. -R. Müller, C. W. Anderson, and G. E. Birch, “Linear and nonlinear methods for brain–computer interfaces,” IEEE Trans. Neural Syst.
Rehabil. Eng., vol. 11, no. 2, pp. 165–169, 2003.
C. S. Herrmann, “Human EEG responses to 1–100 Hz flicker: Resonance
phenomena in visual cortex and their potential correlation to cognitive
phenomena,” Exp. Brain Res., vol. 137, no. 3–4, pp. 346–353, 2001.
S. J. Luck, G. F. Woodman, and E. K. Vogel, “Event-related potential
studies of attention,” Trends Cogn. Sci., vol. 4, no. 11, pp. 432–440,
2000.
H. Railo, M. Koivisto, and A. Revonsuo, “Tracking the processes behind
conscious perception: A review of event-related potential correlates of
visual consciousness,” Conscious. Cognit., vol. 20, no. 3, pp. 972–983,
2011.
S. Marti, M. Sigman, and S. Dehaene, “A shared cortical bottleneck
underlying attentional blink and psychological refractory period,” Neuroimage, vol. 59, no. 3, pp. 2883–2898, 2012.
D. Gribkov and V. Gribkova, “Learning dynamics from nonstationary
time series: Analysis of electroencephalograms,” Phys. Rev. E, vol. 61,
no. 6, pp. 6538–6545, 2000.
S. R. Liyanage, C. T. Guan, H. H. Zhang, K. K. Ang, J. X. Xu, and
T. H. Lee, “Dynamically weighted ensemble classification for nonstationary EEG processing,” J. Neural Eng., vol. 10, no. 3, p. 036007,
2013.
P. Shenoy, M. Krauledat, B. Blankertz, R. P. N. Rao, and K.-R. Müller,
“Towards adaptive classification for BCI,” J. Neural Eng., vol. 3, no. 1,
pp. R13–R23, 2006.
C. Vidaurre, C. Sannelli, K.-R. Müller, and B. Blankertz, “Machinelearning-based coadaptive calibration for brain–computer interfaces,”
Neural Comput., vol. 23, no. 3, pp. 791–816, 2010.
M. Krauledat, M. Tangermann, B. Blankertz, and K.-R. Müller, “Towards
zero training for brain–computer interfacing,” Plos One, vol. 3, no. 8,
p. e2967, 2008.
S. Fazli, M. Danóczy, J. Schelldorfer, and K.-R. Müller, “1-penalized
linear mixed-effects models for high dimensional data with application
to BCI,” Neuroimage, vol. 56, no. 4, pp. 2100–2108, 2011.
W. A. Truccolo, M. Z. Ding, K. H. Knuth, R. Nakamura, and
S. L. Bressler, “Trial-to-trial variability of cortical evoked responses:
Implications for the analysis of functional connectivity,” Clin. Neurophysiol., vol. 113, no. 2, pp. 206–226, 2002.
P. von Bünau, F. C. Meinecke, F. C. Király, and K.-R. Müller, “Finding stationary subspaces in multivariate time series,” Phys. Rev. Lett.,
vol. 103, no. 21, p. 214101, 2009.
M. Billinger, I. Daly, V. Kaiser, J. Jin, B. Allison, G. Müller-Putz, and
C. Brunner, “Is it significant? Guidelines for reporting BCI performance,” in Towards Practical Brain–Computer Interfaces, B. Z. Allison,
S. Dunne, R. Leeb, J. R. Millán, and A. Nijholt, Eds. Berlin, Germany:
Springer, 2013, pp. 333–354.
P. Yuan, X. Gao, B. Allison, Y. Wang, G. Bin, and S. Gao, “A study of the
existing problems of estimating the information transfer rate in online
brain–computer interfaces,” J. Neural Eng., vol. 10, no. 2, p. 026014,
2013.
B. Blankertz, R. Tomioka, S. Lemm, M. Kawanabe, and K.-R. Müller,
“Optimizing spatial filters for robust EEG single-trial analysis,” IEEE
Signal Process. Mag., vol. 25, no. 1, pp. 41–56, Jan. 2008.
B. Blankertz, S. Lemm, M. Treder, S. Haufe, and K.-R. Müller, “Singletrial analysis and classification of ERP components—A tutorial,” Neuroimage, vol. 56, no. 2, pp. 814–825, 2011.

GAO et al.: VISUAL AND AUDITORY BRAIN–COMPUTER INTERFACES

[127] Z. Lin, C. Zhang, W. Wu, and X. Gao, “Frequency recognition based
on canonical correlation analysis for SSVEP-based BCIs,” IEEE Trans.
Biomed. Eng., vol. 54, no. 6, pp. 1172–1176, Jun. 2007.
[128] A. Kachenoura, L. Albera, L. Senhadji, and P. Comon, “ICA: A potential
tool for BCI systems,” IEEE Signal Process. Mag., vol. 25, no. 1, pp. 57–
68, Jan. 2008.
[129] I. Winkler, S. Haufe, and M. Tangermann, “Automatic classification of
artifactual ICA-Components for artifact removal in EEG signals,” Behav.
Brain Funct., vol. 7, no. 1, p. 30, 2011.
[130] Y. Wang and T. P. Jung, “Improving brain–computer interfaces using independent component analysis,” in Towards Practical Brain–Computer
Interfaces, B. Z. Allison, S. Dunne, R. Leeb, J. R. Millán, and A. Nijholt,
Eds. Berlin, Germany: Springer, 2013, pp. 67–83.
[131] H. Bakardjian, T. Tanaka, and A. Cichocki, “Emotional faces boost up
steady-state visual responses for brain–computer interface,” Neuroreport, vol. 22, no. 3, pp. 121–125, 2011.
[132] K.-R. Müller, M. Tangermann, G. Dornhege, M. Krauledat, G. Curio, and
B. Blankertz, “Machine learning for real-time single-trial EEG-analysis:
From brain–computer interfacing to mental state monitoring,” J. Neurosci. Methods, vol. 167, no. 1, pp. 82–90, 2008.
[133] G. Dornhege, B. Blankertz, G. Curio, and K.-R. Müller, “Boosting bit
rates in noninvasive EEG single-trial classifications by feature combination and multiclass paradigms,” IEEE Trans. Biomed. Eng., vol. 51,
no. 6, pp. 993–1002, Jun. 2004.
[134] M. Schreuder, J. Höhne, B. Blankertz, S. Haufe, T. Dickhaus, and
M. Tangermann, “Optimizing event-related potential based brain–
computer interfaces: A systematic evaluation of dynamic stopping methods,” J. Neural Eng., vol. 10, no. 3, p. 036025, 2013.
[135] Y. Wang, X. Gao, B. Hong, and S. Gao, “Practical designs of brain–
computer interfaces based on the modulation of EEG rhythms,” in Brain–
Computer Interfaces, B. Graimann, B. Allison, and G. Pfurtscheller, Eds.
Berlin, Germany: Springer, 2010, pp. 137–154.
[136] B. Blankertz, M. Tangermann, C. Vidaurre, S. Fazli, C. Sannelli, S. Haufe,
C. Maeder, L. E. Ramsey, I. Sturm, G. Curio, and K. R. Mueller, “The
berlin brain–computer interface: Non-medical uses of BCI technology,”
Front. Neurosci., vol. 4, p. 198, 2010.
[137] Y. T. Wang, Y. Wang, and T. P. Jung, “A cell-phone-based brain–
computer interface for communication in daily life,” J. Neural Eng.,
vol. 8, no. 2, p. 025018, 2011.
[138] C. T. Lin, L. W. Ko, J. C. Chiou, J. R. Duann, R. S. Huang, S. F. Liang,
T. W. Chiu, and T. P. Jung, “Noninvasive neural prostheses using mobile
and wireless EEG,” Proc. IEEE, vol. 96, no. 7, pp. 1167–1183, Jul. 2008.
[139] Y. M. Chi, Y. T. Wang, Y. J. Wang, C. Maier, T. P. Jung, and
G. Cauwenberghs, “Dry and noncontact EEG sensors for mobile brain–
computer interfaces,” IEEE Trans. Neural Syst. Rehabil. Eng., vol. 20,
no. 2, pp. 228–235, Mar. 2012.
[140] C. Grozea, C. D. Voinescu, and S. Fazli, “Bristle-sensors—Low-cost
flexible passive dry EEG electrodes for neurofeedback and BCI applications,” J. Neural Eng., vol. 8, no. 2, p. 025008, 2011.
[141] C. T. Lin, L. W. Ko, M. H. Chang, J. R. Duann, J. Y. Chen, T. P. Su,
and T. P. Jung, “Review of wireless and wearable electroencephalogram
systems and brain–computer interfaces—A mini-review,” Gerontology,
vol. 56, no. 1, pp. 112–119, 2010.
[142] T. N. Lal, M. Schroder, T. Hinterberger, J. Weston, M. Bogdan,
N. Birbaumer, and B. Scholkopf, “Support vector channel selection in
BCI,” IEEE Trans. Biomed. Eng., vol. 51, no. 6, pp. 1003–1010, 2004.
[143] S. Makeig, K. Gramann, T. P. Jung, T. J. Sejnowski, and H. Poizner,
“Linking brain, mind and behavior,” Int. J. Psychophysiol., vol. 73, no. 2,
pp. 95–100, 2009.
[144] A. S. Boksem, T. F. Meijman, and M. M. Lorist, “Effects of mental fatigue on attention: An ERP study,” Cogn. Brain Res., vol. 25, no. 1,
pp. 107–116, 2005.
[145] S. G. Mason and G. E. Birch, “A brain-controlled switch for asynchronous control applications,” IEEE Trans. Biomed. Eng., vol. 47,
no. 10, pp. 1297–1307, Oct. 2000.
[146] H. Pan, Y. Q. Li, R. Zhang, Z. H. Gu, and F. Li, “Discrimination between
control and idle states in asynchronous SSVEP-based brain switches: A
pseudo-key-based approach,” IEEE Trans Neural Syst. Rehabil. Eng.,
vol. 21, no. 3, pp. 435–443, May 2013.
[147] J. N. Mak and J. R. Wolpaw, “Clinical applications of brain–computer
interfaces: Current state and future prospects,” IEEE Rev. Biomed. Eng.,
vol. 2, pp. 187–199, 2009.
[148] J. B. F. van Erp, F. Lotte, and M. Tangermann, “Brain–computer interfaces: Beyond medical applications,” IEEE Comput., vol. 45, no. 4,
pp. 26–34, Apr. 2012.

1447

[149] A. Nijholt, B. Reuderink, and D. Oude Bos, “Turning shortcomings into
challenges: Brain–computer interfaces for games,” in Intelligent Technologies for Interactive Entertainment, vol. 9, A. Nijholt, D. Reidsma,
and H. Hondorp, Eds. Berlin, Germany: Springer, 2009, pp. 153–168.
[150] J. J. Daly and J. R. Wolpaw, “Brain–computer interfaces in neurological
rehabilitation,” Lancet Neurol., vol. 7, no. 11, pp. 1032–1043, 2008.

Shangkai Gao (SM’94–F’07) graduated from the
Department of Electrical Engineering of Tsinghua
University, Beijing, China, in 1970, and received the
M.E. degree of biomedical engineering in 1982 in
same department of Tsinghua University.
She is now a Professor of the Department of
Biomedical Engineering in Tsinghua University. Her
research interests include neural engineering and
medical imaging, especially the study of braincomputer interface.
Prof. Gao is also a fellow of American Institute
for Medical and Biological Engineering (AIMBE). She is now the Editorial
Board Member of IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, Journal of Neural Engineering and Physiological Measurement, as well as the senior
editor of IEEE TRANSACTIONS ON NEURAL SYSTEM AND REHABILITATION ENGINEERING.

Yijun Wang (M’11) received the B.E. and Ph.D.
degrees in biomedical engineering from Tsinghua
University, Beijing, China, in 2001 and 2007,
respectively.
He is currently an Assistant Project Scientist at the
Swartz Center for Computational Neuroscience, University of California San Diego, La Jolla, CA, USA.
His current research interests include brain–computer
interface, biomedical signal processing, and machine
learning.

Xiaorong Gao (M’04) received the B.S. degree
in biomedical engineering from Zhejiang University, Hangzhou, China, in 1986, the M.S. degree in
biomedical engineering from Peking Union Medical
College, Beijing, China, in 1989, and the Ph.D. degree in biomedical engineering from Tsinghua University, Beijing, in 1992.
He is currently a Professor in the Department of
Biomedical Engineering, Tsinghua University. His
current research interests are biomedical signal processing and medical instrumentation, especially the
study of brain–computer interface.

Bo Hong (M’04) received the B.S. and Ph.D. degrees
in biomedical engineering from Tsinghua University,
Beijing, China, in 1996 and 2001, respectively.
From 2004 to 2005, he was a Visiting Faculty in
the Department of Biomedical Engineering and the
Center for Neural Engineering at Johns Hopkins University, USA. Since 2005, he has been an Associate
Professor with the Department of Biomedical Engineering, School of Medicine, Tsinghua University.
His current research interests are brain computer interface and neural information decoding.

