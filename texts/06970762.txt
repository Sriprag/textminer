IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

213

An Adaptive Filter for the Removal of Drifting
Sinusoidal Noise Without a Reference
John W. Kelly, Member, IEEE, Daniel P. Siewiorek, Fellow, IEEE, Asim Smailagic, Fellow, IEEE,
and Wei Wang, Member, IEEE

Abstract—This paper presents a method for filtering sinusoidal
noise with a variable bandwidth filter that is capable of tracking
a sinusoid’s drifting frequency. The method, which is based on
the adaptive noise canceling (ANC) technique, will be referred to
here as the adaptive sinusoid canceler (ASC). The ASC eliminates
sinusoidal contamination by tracking its frequency and achieving a narrower bandwidth than typical notch filters. The detected
frequency is used to digitally generate an internal reference instead of relying on an external one as ANC filters typically do.
The filter’s bandwidth adjusts to achieve faster and more accurate convergence. In this paper, the focus of the discussion and
the data is physiological signals, specifically electrocorticographic
(ECoG) neural data contaminated with power line noise, but the
presented technique could be applicable to other recordings as well.
On simulated data, the ASC was able to reliably track the noise’s
frequency, properly adjust its bandwidth, and outperform comparative methods including standard notch filters and an adaptive line
enhancer. These results were reinforced by visual results obtained
from real ECoG data. The ASC showed that it could be an effective
method for increasing signal to noise ratio in the presence of drifting sinusoidal noise, which is of significant interest for biomedical
applications.
Index Terms—Adaptive filter, frequency tracking, line noise,
neural signals, notch filter, variable bandwidth.

I. INTRODUCTION
TRONG sinusoidal contamination, such as power line
noise, can often be a problem in the analysis of signal
recordings. One of the most common sources of sinusoidal
noise is the power line frequency at 60 or 50 Hz. Line noise can
especially be problematic in physiological recordings such as
electrocorticographic (ECoG) neural signals [1], [2]. For ECoG
signals, fixed notch filters are a common practice for removing
line noise [3], [4]. Power line frequency varies around its average [5], though, so the notch must be wide enough to account
for this variation. Increasing the notch width has the unfortunate
side affect of removing additional signal.

S

Manuscript received August 11, 2014; revised November 18, 2014; accepted
November 20, 2014. Date of publication December 2, 2014; date of current version December 31, 2015. This work was supported by a National Science Foundation Graduate Research Fellowship under Grant 0946825, the Quality of Life
Technology Center under NSF Grant EEEC-0540865, the UPMC Rehabilitation
Institute, the National Institutes of Health under Grants 3R01NS050256-05S1
and 8KL2TR000146-07, and the Craig H. Neilsen Foundation.
J. W. Kelly, D. P. Siewiorek, and A. Smailagic are with the Department
of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA 15213 USA (e-mail: john.wade.kelly@gmail.com; dps@cs.cmu.edu;
asim@cs.cmu.edu).
W. Wang is with the Department of Physical Medicine and Rehabilitation, University of Pittsburgh, Pittsburgh, PA 15213 USA (e-mail: wangwei3@
pitt.edu).
Digital Object Identifier 10.1109/JBHI.2014.2375318

Filters that can track a drifting sinusoidal frequency [6] and
maintain a minimum filter bandwidth [7], [8] offer a superior
solution. In [9], an adaptive noise canceling (ANC) filter was
developed to accomplish both tasks, but this required manual
adjustment and a reference input. A phase-locked loop is another elegant solution for eliminating sinusoidal noise, but this
also typically requires a reference and additional hardware as
in [10]. An effective ANC filter without an external reference
was presented in [11], although its bandwidth was fixed and
it required an additional notch filter that did not adapt to the
sinusoidal frequency. The adaptive line enhancer (ALE) targets
sinusoidal noise and does not rely on a reference [12].
Other methods have been developed, such as empirical mode
decomposition (EMD) and discrete wavelet transforms (DWT),
that have proven effective for removing a wide range of noise
from physiological signals [13], [14]. These methods allow
noise to be localized in both the time and frequency domains so
they are excellent choices for broadband noise and physiological artifacts such as eye blinks. This manuscript is specifically
targeting continuous sinusoidal interference, though, and the a
priori knowledge of the noise can be used to better isolate it.
EMD and DWT methods can also be difficult to implement in
real-time systems.
This paper discusses a method that will be referred to as
the adaptive sinusoid canceler (ASC), which is capable of both
frequency tracking and a variable bandwidth in the absence of
a noise reference. The method adds minimal complexity to the
standard ANC filter configuration and is shown to be effective
with a generalized setup, requiring minimal expertise for use.
The ASC was first presented and initially validated in [15].
This paper expands upon that work. The algorithms for updating
both the filter’s frequency and bandwidth have been improved
since the original conference paper. New datasets were also generated that more accurately match specified multichannel signal
to noise ratios (SNR). A few experimental setups with the updated algorithms and data were repeated from the original paper,
but the results and discussion were greatly expanded with new
experiments that reveal more information on the performance
of the ASC. The ALE was also implemented and included in the
analysis. Finally, real ECoG signals were collected in addition
to the simulated data.
Relevant background methods are discussed in Section II.
The full implementation and details of the ASC are covered in
Section III. In order to obtain quantitative results, much of the
data used for analysis were simulated. For further verification,
real neural data was used, but these results can only be visually
presented since the true signal and noise are not known. The
performance of the ASC, standard notch filters, and an ALE

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

214

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

Fig. 1. System design for an ANC filter. D is the recorded signal that consists
of the true signal S plus noise N . A reference correlated with N is given by X ,
and the filter coefficients W are adapted by minimizing the output Ŝ so that N̂
most closely resembles N before being subtracted.

are compared in Section IV. The conclusion is presented in
Section V. Much of the introduction and background material
have been compressed since it would remain largely the same
as the original paper. For an expanded background discussion,
please refer to [15].
II. BACKGROUND
A. Adaptive Noise Canceler
The ANC filter is based largely on work done by Widrow
et al. [16] and has proven effective in removing noise that is
correlated with a known reference signal [17]. A typical ANC
filter is given in Fig. 1.
The least mean squares (LMS) equation, a common convergence method for adaptive filters, is given in (1), where W is the
filter coefficients and μ is the learning rate [18]. X and Ŝ represent the input signal and error, respectively, which for an ANC
filter are given by the noise reference and the output signal. For
ANC filters noise reference and the output signal, respectively,
as shown in the stability and convergence properties of this algorithm were first examined in [19], but many studies since then
have shown the stability properties of LMS to be a complicated
topic dependent on many factors [17]. Since these factors could
vary and the novel methods in this paper do not affect LMS
stability, it is left to the reader to ensure that the filter is stable
for a specific application.
Wk +1 = Wk + 2μŜk Xk .

(1)

For the case of sinusoidal noise, X is a sinusoid of the form
in (2) where fsam p is the sampling frequency, and B and φ are
the amplitude and phase of the sinusoid, respectively. In [20], it
was shown that an ANC filter in the case of a pure sinusoidal
reference approximates a notch filter centered at frequency fx
with bandwidth approximated by (3), where L is the length of
the filter. μ is the learnign rate from (1).
xk = B cos(2πfx k/fsam p + φ)
2

(2)

LμB fsam p
Hz.
(3)
2π
The accuracy of this approximation depends on the strength
of the time-invariant components of the filter’s transfer function
relative to the time-varying components. This ratio was also
shown in [20] to be given by (4). If fx is known beforehand to not
drift by a large amount then it is easy to minimize β by choosing
an L to make the numerator of (4) close to zero. L should then
be the nearest integer to any value that produces an integer
when multiplied by the normalized frequency (fx /fsam p ). As
BW =

Fig. 2. System design for an ALE. This filter operates the same way as the
ANC shown in Fig. 1, but a delayed version of the recorded signal is used as
the reference. Z −τ delays the signal by τ samples.

the range of possible values for fx increases or as the normalized
frequency approaches 0 or 0.5 (values at which the denominator
of β is close to zero), L must be increased to help ensure β is
small.
β=

sin(2πLfx /fsam p )
.
L sin(2πfx /fsam p )

(4)

When given a sinusoidal reference and an appropriate value of
L, the ANC technique with the LMS algorithm then converges
to a notch filter centered at the reference’s frequency with a
bandwidth dependent on μ. For drifting sinusoidal noise, this
method is superior to a fixed notch filter if an accurate reference
is available.
B. ALE
The ALE is a version of the ANC filter designed for cases
where a reference is unavailable and either the noise or the
signal is known to be periodic [12]. It has been found to be
useful for other tasks, though, such as eliminating temporally
correlated portions of a signal [21]. Here, it is known that the
noise is periodic. The ALE typically assumes that the signal
is not periodic, although if configured carefully it can still be
used as long as the signal period is not an integer multiple of
the noise period and vice versa. The ALE design is shown in
Fig. 2. Although prior work has shown convergence algorithms
and other parameters to have an effect on its performance [22],
it is not a difficult method to implement.
There are a few practical considerations to keep in mind with
the ALE. The key to most of these is remembering that the reference is the recorded signal shifted by τ , which the adaptive
filter can then shift an additional L in either direction. For removing periodic noise, this means that the range from τ − L
to τ + L should contain minimal values in the autocorrelation
function of S. It also means that same range should contain an
integer multiple of the period of N . These two considerations
allow the filter to match N̂ to the periodic N while minimizing
the effect of S that remains in N̂ . If L is greater than one halfcycle of N then the second condition is met no matter the value
of τ .
The ALE is effective at removing periodic noise, but it can
add a significant amount of signal distortion. Even if the filter is
able to perfectly remove N , it still contaminates the signal with
a delayed and filtered version of S. So based on a number of
factors such as the original SNR of the recording, the autocorrelation of S, the spectral shape of S near fN , and how precisely
fN is known, ALE may or may not outperform a standard notch
filter for the removal of sinusoidal noise.

KELLY et al.: ADAPTIVE FILTER FOR THE REMOVAL OF DRIFTING SINUSOIDAL NOISE WITHOUT A REFERENCE

215

been removed.
μ=
BW =

Fig. 3. System design for the ASC. The same basic structure as the ANC in
Fig. 1 is present, but here the reference is a generated sinusoid with a frequency
of f¯N̂ . This frequency is calculated by taking a MA of the distances between
ZCs in N̂ . The learning rate of the filter is also a function of f¯N̂ , as shown
by (9).

III. METHODS
A. ASC
The ASC, diagrammed in Fig. 3, implements an ANC scheme
that does not rely on an external reference.
1) Frequency Tracking: In Section II-A it was seen that in
Fig. 1, the path from D to Ŝ when X is sinusoidal is a notch
filter centered at fx with a bandwidth given by (6). A corollary to this property is that the path from D to N̂ is a bandpass filter matching the notch filter in center frequency and
bandwidth [20].
This property means that if the true line noise frequency (fN )
drifts slightly then a sinusoid correlated to N is still present
in N̂ . Since N̂ is bandpassed the estimated frequency, fN̂ , can
be calculated with a method as simple as measuring the time
between zero crossings (ZC). The time of a ZC can be estimated
using interpolation. Due to noise introduced by broadband signal
components, a moving average (MA) of length T is applied to
fN̂ to produce f¯N̂ .
Higher values of T produce smoother, less responsive estimates. Since the goal is to demonstrate a generalized filter,
T = 120 was used for all analysis. Regardless of the sampling
frequency of the data, new samples of fN̂ occur only at each ZC
of N̂ . So for fN = 60 Hz, which would produce 120 ZCs per
second, this window length would correspond to 1 s of data.
A reasonable estimate of fN is used to initialize the ASC. The
initial frequency used to generate the reference does not need to
be exact, and in the case of line noise a good estimate could easily
be provided. If a reasonable estimate for the noise frequency
is not known, then the filter might need to be initialized by
using a method such as spectral peak detection to determine
the initial reference frequency. Once the filter is initialized it
begins calculating f¯N̂ , which tracks and converges toward the
true fN . The speed and accuracy of this convergence depend on
the bandwidth of the filter, but this value is adapted through an
automated method as well.
2) Variable Bandwidth: To simplify the bandwidth calculation, the normalized u given below in (5) is used in place of
μ [18]. Any further reference to the learning rate is referring
to u. The use of u allows the filter bandwidth given in (3) to
be represented by (6), since for a sinusoid the signal power
(Px2 ) is known to be B 2 /2. The dependence on L and B has

u
LPx2

(5)

ufsam p
Hz.
π

(6)

The bandwidth of the notch filter from D to Ŝ, and of the
corresponding bandpass filter, is then controlled by u. This value
can be automatically adjusted based on the behavior of f¯N̂ . If
the estimate is not consistent, demonstrating that the ASC has
a poor confidence in its estimated reference frequency, then the
bandwidth should be increased. This increase helps maintain
the elimination of the sinusoidal noise in Ŝ, and at the same
time helps to decrease the attenuation of the line noise in N̂ ,
causing the measurement of the ZCs to be more accurate. As f¯N̂
approaches fN and becomes more consistent, u decreases and
the filter narrows around f¯N̂ . This decrease reduces the amount
of the broadband signal eliminated in Ŝ and passed through to
N̂ , both improving the output and increasing the accuracy of f¯N̂
(which in turn allows u to decrease further). The process repeats
in an iterative fashion as f¯N̂ tracks fN . Bounds were placed on
u so that the filter’s bandwidth remained between 0.2 and 4 Hz.
The relation between the changes in f¯N̂ and the filter bandwidth is shown in (7). This relation depends on GT , shown in
(8) where the operators maxT and minT represent the maximum and minimum value during the window T . Various other
measures were experimentally examined, and GT proved to be
a good tradeoff between stability and responsiveness. Measures
such as the derivative that use the rate of change of f¯N̂ were not
as consistent. Measures such as the standard deviation of f¯N̂ ,
or even a linear fit to all the points in the window, were fairly
consistent but did not respond as quickly to changes in fN . The
results of (7) were not highly susceptible to small fluctuations in
f¯N̂ , but still quickly responded when f¯N̂ began moving towards
a new value of fN .
BW = cGT (f¯N̂ ) Hz
GT (f¯N̂ ) = maxT (f¯N̂ ) − minT (f¯N̂ ).

(7)
(8)

The value of c is a free parameter that determines how much
the filter’s bandwidth responds to changes in f¯N̂ , and will be
referred to as the bandwidth sensitivity. The effect of bandwidth
sensitivity does depend somewhat on T , but this relationship is
not as strong as would be expected. Higher values of T calculate
GT over a greater distance, but they also add more smoothing
to f¯N̂ . These two behaviors to a large extent cancel each other
out, and a single value of c was found to be effective for various
values of T , fsam p , and fN . Again, though, the goal here is to
produce a generalized filter rather than demonstrating the effect
of fine-tuning parameters, so c = 20 was used for all results and
analysis of the ASC filter. This value of c was experimentally
determined to be suitable for a wide range of experimental
conditions.
Finally, combining (6) and (7) gives the ASC’s learning rate
u shown in (9). The end result is a notch filter that tracks fN
while minimizing its bandwidth through a process that first
increases bandwidth to locate a new value of fN , then narrows

216

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

its bandwidth around the new value.
cπGT (f¯N̂ )
u=
.
fsam p

(9)

B. Testing Data
1) Simulated Data: An ECoG signal simulator built in to
Craniux, a software package for brain–computer interface research, was used to generate eight channels of signals [23].
These signals had a sampling frequency of 1200 Hz and contained pink noise with a 1/f power falloff to simulate ECoG
baseline signals [24]. It is important to note that Craniux was
operating as a simulated real-time system with the filters integrated into it. So the ASC and the comparative methods were
operating as they would in an “online” 1200-Hz application.
Simulated power line noise N was added to S using (10), where
m is the harmonic number, fN is the fundamental line noise
frequency, and A is the amplitude. Two harmonics were added
(M = 2) in addition to the fundamental frequency and each was
given half the amplitude of the previous one.
N=

M

A
cos(2π(m + 1)fN + φ).
m
2
m =0

(10)

A in (10) was calculated to create a specified SNR between S
and N . Since the harmonics are noninterfering sinusoids their
total power is equal to the sum of their individual powers as
shown in (11). For a specific SNR, A is then calculated with
(12). Ps is the average power of S.
PN =

=

M

(A/2m )2
2
m =0
M  m
A2  1
2 m =0 4

2A2
(1 − (1/4)M +1 )
3

3Ps
A=
.
SNR
/10
d
b
2 ∗ 10
(1 − (1/4)M +1 )
=

(11)
(12)

At times the line noise fundamental frequency, fN , was controlled deterministically. For further analysis, it was also sometimes varied according to the Gauss–Markov process in (13)
as was done in [8]. ηΔ k is a random sample from a zero-mean
Gaussian distribution with variance ση2 .
fN ,Δ k + 1 = fN ,Δ k + ηΔ k .

(13)

2) Real Data: A small amount of real data was also used.
This data also had a sampling frequency of 1200 Hz and was collected from a human subject who was subdurally implanted with
a 32 channel ECoG grid over primary motor and sensorimotor
areas. Although the true, noise-free signal was not known in this
case, it is useful to at least qualitatively show that the ASC can
effectively remove line noise from real data. All data collection
and procedures were approved by the University of Pittsburgh’s
Institutional Review Board and informed consent was obtained
prior to implantation.

Fig. 4. Average autocorrelation of 10-s windows of S. The error bars represent
the standard deviation across all windows.

C. Experimental Parameters
The ASC was validated through comparison to more traditional removal methods for sinusoidal noise. These methods
include the ALE and a standard fixed-bandwith, fixed-frequency
notch filter. The notch filter was second order, the same as the
ASC filter. The methods were evaluated by calculating the error
after filtering, or the remaining noise, which was the difference between the true signal and the filtered signal. In this way
all mean squared error (MSE) and SNR calculations took into
account both the removal of the sinusoidal noise and any distortion that occurred to the signal. Unless otherwise noted, the
SNR before filtering was always 0 dB. All results presented for
the simulated data took the average across the eight channels of
data and all filtering methods operated on the same sets of data.
As stated previously, the ASC used c = 20 and T = 120 for
all conditions. For both the ALE and the ASC, L = 20 was used.
According to (4), this length should allow the ASC to perform
optimally by minimizing β. A length of 20 is also longer than
one half-cycle of N , which means the only consideration for
the ALE was to select τ to minimize the autocorrelation of S.
Since the signals were simulated this was done by taking the
mean of the autocorrelation of a 10-s window of S. The resulting
autocorrelation value at each lag, or time shift, is shown in Fig. 4.
From this figure, τ = 0.5 s was chosen as a sufficient delay.
Since it is expected that the fundamental frequency would
have a higher power and thus be easier to track than the harmonics, the ASC used multiples of the detected fundamental
frequency rather than tracking each harmonic individually. For
all notch filter methods implemented, corresponding filters were
also added for the harmonics.
IV. RESULTS AND DISCUSSION
A. Simulated Data
1) Internal State of the ASC: The overall performance of
the ASC depends heavily on the accuracy of its internal
adjustments, so the behavior of the ASC’s frequency tracking and variable bandwidth was examined first. To do so, the
frequency of the additive sinusoidal noise was adjusted at 30-s
intervals by increasingly larger amounts. Fig. 5 shows the internal behavior of the ASC as these changes occurred. As can be
seen, the filter was able to effectively track changes in the noise

KELLY et al.: ADAPTIVE FILTER FOR THE REMOVAL OF DRIFTING SINUSOIDAL NOISE WITHOUT A REFERENCE

Fig. 5. ASC frequency tracking and bandwidth as changes in noise frequency
occur. Shown is (top) the error in the ASC’s frequency estimate, (middle) the
ASC’s bandwidth as the frequency changes occur, and (bottom) the log-scaled
magnitude of changes in the noise frequency.

TABLE I
MSE BETWEEN THE ACTUAL AND ESTIMATED ASC FREQUENCY

ASC
FFT

σn = 0

σ n = 0.01

σ n = 0.1

5.0 × 10 −5
3.4 × 10 −3

9.8 × 10 −3
8.3 × 10 −3

2.9 × 10 −1
2.9 × 10 −1

frequency while adjusting its filter bandwidth accordingly. As a
reminder, the ASC’s bandwidth was bounded by 0.2 and 4 Hz.
The spikes in the frequency error correspond to the convergence period of the filter, and during these periods the bandwidth
of the filter increased to help keep the noise attenuated and to
allow the filter to more quickly find the new frequency. As the
changes in frequency get progressively larger so do the size and
then duration of the increases in bandwidth. This process is susceptible to noise, as evidenced partly by the small unexpected
increases in bandwidth seen between the two frequency changes
near 250 s.
2) ASC Frequency Tracking Performance: The frequency
tracking of the ASC needed a baseline to compare against, so a
spectral peak detection method was implemented and analyzed.
This method simply took an FFT of the signal and looked for
the frequency between 55 and 65 Hz where a peak occurred. To
examine the effectiveness of this method against the ASC’s frequency tracking the stochastic model for noise frequency given
in (13) was employed. The model was set up with Δk = 2 s and
ση = 0, 0.01, and 0.1. For ση = 0 the frequency remained at
60 Hz.
It is well known that the accuracy of an FFT’s frequency estimate increases with the length of its window, which corresponds
to the resulting number of frequency bins. When the goal is to
track frequency changes, though, longer windows could result
in missing quick changes. With this in mind, the spectral peak
detection method was tested using window sizes from 1 upto
10 s in 1-s increments. An increase in performance was seen
from 1 to 2 s, but after that the average results did not vary
significantly.

217

Fig. 6. Performance of the ASC with and without variable bandwidth. The
top three graphs show the MSE between the true signal and filtered signal. The
MSE was smoothed with a 100-ms-long MA filter to make the plots more visibly
clear. Shown is (top) variable bandwidth between 0.2 and 4 Hz, (top middle)
bandwidth set at 0.2 Hz, (bottom middle) bandwidth set at 4 Hz, and (bottom)
the log-scaled magnitude of changes in the line noise frequency.

The results for a 2-s window are given in Table I. Both methods perform similarly, with the ASC better at ση = 0 and spectral peak detection slightly better at ση = 0.01. It is expected
that there are times in which spectral peak detection or other
frequency estimation methods could produce better results than
the one used here by the ASC. A main benefit of the ASC in
its current form is that it does not add much complexity to the
standard ANC configuration.
3) ASC Variable Bandwidth Performance: Next, the effect
of the ASC’s variable bandwidth on performance was analyzed.
Since the variable bandwidth was bounded by 0.2 and 4 Hz, for
comparison the filter was set up to first have a fixed bandwidth
of 0.2 Hz, and then of 4 Hz. The resulting performance is shown
in Fig. 6. This figure was created using the same data as Fig. 5,
so these two figures can be examined together to better see
the relationship between speed of convergence and the ASC’s
variable bandwidth.
With a fixed 0.2 Hz bandwidth the filter could converge to a
low MSE, but convergence time significantly increased as the
magnitude of the changes in frequency increased. With a fixed
4-Hz bandwidth, the filter was very consistent and converged
quickly even at the larger frequency changes, but it was not able
to produce as low of an MSE. With the variable bandwidth the
filter still had more variance in its MSE than the fixed 4-Hz
bandwidth, but it was able to converge quickly and produce
a lower average MSE. The SNRs over the whole trial for the
variable, 0.2 Hz, and 4 Hz bandwidth were 20.2, 11.5, and
17.0 dB, respectively.
The results of the fixed 0.2 and 4 Hz bandwidths do not
necessarily indicate the performance that would be seen from
bandwidths in between these two values, but the boundary conditions were used here to illustrate that the variable bandwidth
method is able to retain some of the advantages of both the
extreme cases.
4) Deterministic Noise Frequency: For filters with a fixed
center frequency, their effectiveness depends on the distance

218

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

TABLE II
FILTERED SNR (dB) FOR DIFFERENT STANDARD DEVIATIONS IN THE NOISE
FREQUENCY MODEL

Var. f c , BW (ASC)
Var. f c , BW = 0.2
Var. f c , BW = 4
4-Hz Notch
ALE

σn = 0

σ n = 0.01

σ n = 0.1

25.3
25.1
17.2
17.2
4.6

22.8
22.0
17.2
–
4.5

17.2
6.9
17.0
–
4.3

Fig. 7. Performance of filters on a deterministically drifting sinusoid. The
x-axis shows the distance of the noise frequency from 60 Hz and the y-axis
shows the filtered SNR.

of the noise frequency from that center. Using the stochastic
model given by (13) with a limited number of samples could
give inconsistent results. So for comparison to a fixed 4-Hz notch
filter, which is a common method for removing line noise, the
frequency of the additive noise was increased from 60 Hz by
0.1 Hz every 2 min to measure the resulting SNR at specific
frequencies. The SNR after adding the noise was 0 dB.
As shown by Fig. 7, the performance of the standard notch
filter degraded as the frequency increased to 61 Hz even though
its bandwidth was 4 Hz. The ASC and ALE were able to maintain a steady SNR. The ASC produced the highest SNR even at
60 Hz, the ideal condition for the fixed notch filter. Note that
the SNR here also takes into account the time period during
which the ASC is adjusting to the new frequency, and the small
variance in the SNR is due to this convergent process and finite
data sample lengths.
The performance of ALE on this data was well below that of
the ASC. This was most likely due to the delayed portions of S
used by the filter impacting the output. Even if the autocorrelation is zero at the chosen lag, the delayed signal is still part of
N̂ and is subtracted out. This essentially adds random noise to
the signal that has the same shape as S.
5) Stochastic Noise Frequency: To measure the ASC’s performance on drifting sinusoidal noise, the stochastic model for
noise frequency given in (13) was once again employed with
Δk = 2 s and ση = 0, 0.01, and 0.1. The case of ση = 0 was
included so that a baseline comparison to a standard notch filter
could be made, and also since an adaptive filter such as the ASC
might be used in the case where it is unknown if a sinusoidal
noise frequency will actually drift or not. For each value of ση ,
5 min of data were generated and analyzed. The outcomes of
these experiments are given in Table II.
These results are consistent with Figs. 6 and 7. The first
column of Table II again indicates that the ASC outperformed a
traditional 4-Hz notch filter even under ideal circumstances for
the notch filter. This is because the frequency estimate is able
to converge to 60 Hz and then use its confidence in the noise
frequency to narrow its bandwidth and minimize distortion of the
signal. The ALE once again maintains consistent performance,
but not at the level of the ASC.

Fig. 8.

Performance of the ASC and the ALE as the initial SNR changes.

Of the frequency tracking methods, the variable bandwidth
produced the highest SNR across all three tested conditions. It is
interesting to note that, although by an insignificant amount, the
variable bandwidth ASC outperformed the variable frequency,
0.2-Hz bandwidth filter even at ση = 0. Since the frequency estimate is subject to noise, it is possible that the variable bandwidth
is an advantage even for a fixed unknown noise frequency since
the bandwidth can increase whenever the filter’s confidence in
its frequency estimate decreases.
At ση = 0.1, the 0.2-Hz bandwidth filter’s performance drops
significantly while the variable bandwidth ASC is able to keep
performance at the level of the 4-Hz bandwidth filter. The
4-Hz bandwidth filter performs well in all tested conditions,
but is unable to take advantage of the lower variances to converge more tightly around the line noise. The variable bandwidth
method is able to increase performance at the lower variances
and still maintain a good SNR at the highest variance.
A careful reader might note that results similar to those in
Table II and Fig. 7 were presented in [15], but that the numbers
are slightly different. For some of the results this is simply due
to modifications made to the ASC. It is also because all methods
were tested on new data sets that were generated with an initial
SNR that included all noise harmonics, while in [15] the initial
SNR was only measured between the signal and the noise at the
fundamental frequency.
6) Variable Initial SNR: With SNR in mind, it can be observed that the accuracy of the ASC’s frequency tracking and
bandwidth adjustments might depend heavily on the initial SNR
of the recording. To help determine this effect, 5 min segments
of data were generated with SNRs ranging from −40 to 40 dB.
The stochastic noise frequency model was used with ση = 0.01.
The results for both the ASC and the ALE for this data are shown
in Fig. 8.

KELLY et al.: ADAPTIVE FILTER FOR THE REMOVAL OF DRIFTING SINUSOIDAL NOISE WITHOUT A REFERENCE

The ASC was able to improve the signal quality for any initial
SNR below 10 dB, with its best performance coming at 0 dB.
Once the initial SNR got to 20 dB the ASC was unable to locate
the noise due to the broadband noise components in N̂ being
significant enough to make the frequency estimate unreliable.
As with a standard notch filter, though, even if the frequency
estimate were accurate it is doubtful that the SNR could be
improved at that point. The distortion caused by the filter would
most likely outweigh the noise removal.
For lower initial SNRs, the frequency estimate accuracy improved but the resulting SNR from the ASC still dropped sharply.
The penalty for the accuracy being off even a small amount is
much more severe in this case because the high power noise is
then not fully attenuated by the filter. The variance in the noise
frequency model was enough to cause momentary inaccuracies
in the frequency estimate that let some of the noise slip through.
Refer back to Table I to see that even with an initial SNR of 0
dB the frequency estimate MSE dropped by almost two orders
of magnitude from ση = 0 to ση = 0.01. For example, with
a −40-dB initial SNR and ση = 0, the ASC was still able to
converge to output an SNR of about 16 dB.
The ALE’s performance on the variable SNR data was more
consistent than that of the ASC, but still overall lower. Unsurprisingly, the ALE was not able to improve its performance
above about 5 dB for the higher initial SNRs, resulting in degraded signal qualities. At lower SNRs, the ALE’s performance
did not drop off as sharply as the ASC’s, with the ALE actually
having far superior results at an initial SNR of −40 dB. Since
the ALE is using the signal itself as a reference rather than generating its own, it always has the precise frequency of the noise
in its reference. By the very way in which it’s designed, the ALE
places a much higher value on removing the noise than it does
on preserving the signal. This trait causes the relative strength
of the ALE to increase as the initial SNR decreases.
7) Sinusoidal Signal Components: As a last test with simulated data, the ability of the ASC to discriminate between
sinusoidal noise and a neighboring sinusoidal signal component
was examined. In this test the assumption was made that the
initial frequency estimate is closer to the noise frequency than
to the sinusoidal signal component, otherwise the ASC would
latch on to the wrong sinusoid. The noise component was set
to a frequency of 60 Hz, while the signal component began at
a frequency of 70 Hz and every 2 min was moved closer to 60.
The results of this test are shown in Fig. 9. The initial SNR was
again set at 0 dB, which means that the sinusoidal noise component did have a slightly higher amplitude than the sinusoidal
signal component.
For the ASC, the main transition in performance in Fig. 9 occurred between about a 2 and 5 Hz frequency difference. Above
6 Hz the performance levels out, indicating that the sinusoidal
signal component has been left intact by the ASC. At the top
the performance is even slightly higher than in Fig. 7, which
is most likely because the sinusoidal signal component results
in a larger portion of the signal power being outside of and
unaffected by the notch filter. Below a 1 Hz difference the performance again levels out, indicating that the filter can no longer
discern between the two components. Until the ASC was able

219

Fig. 9. SNR resulting from filtering a signal with a sinusoidal component
near the sinusoidal noise component. The difference in frequency between the
components is given on a log scale.

Fig. 10. Spectral power of real ECoG data with line noise contamination.
Shown is (top) the original signal, (middle) the signal after filtering with the
ASC, and (bottom) the signal after filtering with the ALE.

to discriminate between the two frequencies and maximize its
performance, it behaved similarly to a 4-Hz-fixed notch filter.
The results of the ALE are also presented in Fig. 9, although
this test was not something for which the ALE was designed.
The ALE does not target a specific frequency, so it removed
both components. Although τ and L can be manipulated to get
the ALE to favor one component, this would in general not
be a worthwhile practice if that much information is known
beforehand about the relevant frequencies.
B. Real Data
Finally, the effectiveness of the ASC in removing line noise
from ECoG data was qualitatively shown on a small amount of
real data. These results offer initial evidence for the feasibility
of the filter on real data. Before any additional processing was
performed, the signals were bandpass filtered from 1 to 250 Hz.
Fig. 10 shows the FFT on 5 min of this data before and after
being filtered by both the ASC and the ALE. Standard notch
filters are not shown here since visibly, there would not be much
difference between them and the ASC.

220

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

Fig. 11. Coherence of the ECoG data with the output of (top) the ASC and
(bottom) the ALE.

In the original signal clear spikes are visible at 60 and 180 Hz,
with only a small one at 120 Hz. The ASC removed all of these
spikes, and the visible lower frequency portions of the signal
appear to be unaffected. The ALE greatly diminished, but did
not remove, all of the spikes. It also appears to have affected
other portions of the signal.
To get a closer look at the effect of the filtering on the real
data’s spectrum, the coherence of the data over the same 5min interval was calculated. The results are shown in Fig. 11.
The ASC’s coherence is what would be expected for a typical
notch filter, with sharp dips to 0 at each noise harmonic, and 1
everywhere else (the small dip below 1 Hz is a result of the signal
being bandpass filtered and having no real content below 1 Hz).
The ALE’s coherence shows significant effects on portions
of the spectrum outside of the noise harmonics. Surrounding 60
and 180 Hz, the coherence can be seen to drop. Additionally, the
lower frequency portion of the coherence resembles the inverse
of the original signal’s spectrum. This result can be expected
since the ALE subtracts out a shifted and filtered version of the
original signal.
V. CONCLUSION
This paper presented a filter, termed the ASC, designed to
effectively remove drifting sinusoidal noise while minimizing
signal distortion without the use of a reference signal. The results
obtained for the ASC were superior to those from traditional
notch filters and ALE.
The frequency tracking and variable bandwidth portion of the
ASC were shown to work well. The filtering performance was
shown to be excellent under varying conditions for the noise
frequency. Circumstances that could cause the performance of
an ASC to drop were also explored, including the initial SNR
being too low or too high or the signal having a sinusoidal
component close in frequency to the noise component. The
ASC performed within expectations for these situations and
comparable to or better than alternative methods. Finally, it was
shown to effectively remove line noise from a recording of real
ECoG data.
For a specific situation in which parameters such as the SNR,
the precise noise frequency, and maybe even a reference signal

are known beforehand, a better filter could probably be tailored
to meet that need. Indeed the ASC’s parameters could even be
fine-tuned to better suit some of the situations tested in this
paper. Under many circumstances, such as with a high SNR, it
is expected that the ASC’s current frequency tracking method
could be improved. In some situations spectral peak detection
might be a better option, or possibly the method discussed in
[11]. In the case that less information is known about the noise
and it is not even known to be sinusoidal, methods for more
general noise removal such as those based on EMD or wavelets
would be superior.
The ASC was shown to still be effective with the same parameters under a variety of conditions, though, and this versatility
and ease of use is part of what makes it an attractive option for
the removal of sinusoidal noise. The ASC could also be used in
most real-time systems, as here it operated in a simulated realtime system at 1200 Hz. Its performance shown in this paper
warrants further investigation and additional analysis is needed
to determine its full impact on applications of real signals.
REFERENCES
[1] P. Jiruska, R. Cmejla, A. D. Powell, W.-C. Chang, M. Vreugdenhil, and
J. G. R. Jefferys, “Reference noise method of removing powerline noise
from recorded signals,” J. Neurosci. Methods, vol. 184, no. 1, pp. 110–114,
Oct. 2009.
[2] A. K. Ziarani and A. Konrad, “A nonlinear adaptive method of elimination
of power line interference in ECG signals,” IEEE Trans. Biomed. Eng.,
vol. 49, no. 6, pp. 540–547, Jun. 2002.
[3] N. R. Anderson, T. Blakely, G. Schalk, E. C. Leuthardt, and D. W. Moran,
“Electrocorticographic (ECoG) correlates of human arm movements,”
Exp. Brain Res., vol. 223, no. 1, pp. 1–10, Nov. 2012.
[4] T. Blakely, K. J. Miller, R. P. N. Rao, M. D. Holmes, and J. G. Ojemann,
“Localization and classification of phonemes using high spatial resolution
electrocorticography (ECoG) grids,” in Proc. Conf. IEEE Eng. Med. Biol.
Soc., 2008, pp. 4964–4967.
[5] T. V. Baak. (2004). 60 Hz AC mains frequency accuracy measurement
[Online]. Available: http://www.leapsecond.com/pages/mains/
[6] M. Ta and V. DeBrunner, “Adaptive notch filter with time-frequency tracking of continuously changing frequencies,” in Proc. IEEE Conf. Acoustics,
Speech Signal Process., Mar. 2008, pp. 3557–3560.
[7] D. W. Mortara, “Digital filters for ECG signals,” in Proc. Comput. Cardiol.,
IEEE Comput. Society Press, 1997, pp. 511–514.
[8] D. Olguin, F. Bouchereau, and S. Martinez, “Adaptive notch filter for EEG
signals based on the LMS algorithm with variable step-size parameter,”
in Proc. Conf. Inf. Sci. Syst., 2005, pp. 16–18.
[9] M. Ferdjallah and R. E. Barr, “Adaptive digital notch filter design on the
unit circle for the removal of powerline noise from biomedical signals,”
IEEE Trans. Biomed. Eng., vol. 41, no. 6, pp. 529–536, Jun. 1994.
[10] M. M. Z. Zadeh, S. Niketeghad, and R. Amirfattahi, “A PLL based adaptive
power line interference filtering from ECG signals,” in Proc. CSI Int. Symp.
Artif. Intell. Signal Process., 2012, pp. 490–496.
[11] I. S. Badreldin, D. S. El-Kholy, and A. A. El-Wakil, “A modified adaptive
noise canceler for electrocardiography with no power-line reference,” in
Proc. Cairo Int. Biomed. Eng. Conf., 2010, pp. 5–8.
[12] J. Treichler, “Transient and convergent behavior of the adaptive line enhancer,” IEEE Trans. Acoustics, Speech, Signal Process., vol. 27, no. 1,
pp. 53–62, Feb. 1979.
[13] M. Blanco-Velasco, B. Weng, and K. E. Barner, “ECG signal denoising and
baseline wander correction based on the empirical mode decomposition.”
Computers in Biology and Medicine, vol. 38, no. 1, pp. 1–13, Jan. 2008.
[14] J. W. Kelly, D. P. Siewiorek, A. Smailagic, J. L. Collinger, D. J. Weber,
and W. Wang, “Fully automated reduction of ocular artifacts in highdimensional neural data,” IEEE Trans. Biomed. Eng., vol. 58, no. 3,
pp. 598–606, Mar. 2011.
[15] J. W. Kelly, J. L. Collinger, A. D. Degenhart, D. P. Siewiorek, A. Smailagic,
and W. Wang, “Frequency tracking and variable bandwidth for line noise
filtering without a reference,” in Proc. Conf. IEEE Eng. Med. Biol. Soc.,
2011, pp. 7908–7911.

KELLY et al.: ADAPTIVE FILTER FOR THE REMOVAL OF DRIFTING SINUSOIDAL NOISE WITHOUT A REFERENCE

[16] B. Widrow, J. Glover, J. McCool, J. Kaunitz, C. Williams, R. Hearn,
J. Zeidler, J. Eugene Dong, and R. Goodlin, “Adaptive noise cancelling:
Principles and applications,” Proc. IEEE, vol. 63, no. 12, pp. 1692–1716,
Dec. 1975.
[17] S. Haykin, Adaptive Filter Theory. Upper Saddle River, NJ, USA: Prentice
Hall, 1996.
[18] J. S. Lim and A. V. Oppenheim, Advanced Topics in Signal Processing.
Englewood Cliffs, NJ, USA: Prentice Hall, 1988.
[19] B. Widrow, P. E. Mantey, L. J. Griffiths, and B. B. Goode, “Adaptive
antenna systems,” Proc. IEEE, vol. 55, no. 12, pp. 2143–2159, Dec. 1967.
[20] J. R. Glover, “Adaptive noise canceling applied to sinusoidal interferences,” IEEE Trans. Acoustics, Speech, Signal Process., vol. 25, no. 6,
pp. 484–491, Dec. 1977.
[21] R. Ramli, A. Noor, and S. Samad, “A review of adaptive line enhancers
for noise cancellation,” Australian J. Basic App. Sci., vol. 6, no. 6,
pp. 337–352, 2012.
[22] S. Dhull, S. Arya, and O. P. Sahu, “Performance comparison of adaptive
algorithms for adaptive line enhancer,” Int. J. Comput. Sci., vol. 8, no. 3,
pp. 553–558, 2011.
[23] A. D. Degenhart, J. W. Kelly, R. C. Ashmore, J. L. Collinger, E. C.
Tyler-Kabara, D. J. Weber, and W. Wang, “Craniux: A LabVIEW-based
modular software framework for brain-machine interface research,” Comput. Intell. Neurosci., vol. 2011, art no. 363565(13 Pages), Jan. 2011,
DOI :10.1155/2011/363565.
[24] M. Keshner, “1/f noise,” Proc. IEEE, vol. 70, no. 3, pp. 212–218,
Mar. 1982.

John W. Kelly (S’04–M’14) received the B.S. degrees in both electrical and computer engineering in
2003 and the M.S. degree in electrical engineering in
2004 from North Carolina State University, Raleigh,
NC, USA. In 2013, he received the Ph.D. degree in
electrical and computer engineering from Carnegie
Mellon University, Pittsburgh, PA, USA.
His previous positions include multiple summer
internships and a job as a Software Developer at
Oak Ridge National Laboratory and a summer internship at Y-12 National Security Complex. His recent research interests include machine learning, signal processing, and brain–
computer interfaces.
Dr. Kelly was a Recipient of the National Defense Science and Engineering
Graduate Fellowship in 2008 and the NSF Graduate Research Fellowship in
2009.

Daniel P. Siewiorek (F’79) received the B.S. degree in electrical engineering from the University of
Michigan, Ann Arbor, MI, USA, in 1968, and the
M.S. and Ph.D. degrees in electrical engineering (minor in computer science) from Stanford University,
Palo Alto, CA, USA, in 1969 and 1972, respectively.
He is the Buhl University Professor of electrical
and computer engineering and computer science at
Carnegie Mellon University, Pittsburgh, PA, USA.
He has designed or been involved with the design of
nine multiprocessor systems and has been a key contributor to the dependability design of over two dozen commercial computing
systems. He leads an interdisciplinary team that has designed and constructed
over 20 generations of mobile computing systems. He has written nine textbooks
in the areas of parallel processing, computer architecture, reliable computing,
and design automation in addition to over 475 papers. He is currently the Director of the Quality of Life Technology NSF Engineering Research Center.
His previous positions include the Director of the Human Computer Interaction
Institute, Director of the Engineering Design Research Center, and Cofounder
and Associate Director of the Institute for Complex Engineered Systems.
Dr. Siewiorek is a Fellow of ACM and AAAS and is a Member of the National Academy of Engineering. He has served as the Chairman of the IEEE
Technical Committee on Fault-Tolerant Computing, and as the Founding Chairman of the IEEE Technical Committee on Wearable Information Systems. He
has been the Recipient of the AAEE Frederick Emmons Terman Award, the
IEEE/ACM Eckert-Mauchly Award, and the ACM SIGMOBILE Outstanding
Contributions Award.

221

Asim Smailagic (F’10) received the B.S. degree in
electrical engineering in 1973 and the M.S. and Ph.D.
degrees in computer science from the University of
Sarajevo, Sarajevo, Bosnia and Herzegovina, in 1976
and 1984, respectively. He completed postdoctoral
studies in computer science at Carnegie Mellon University, Pittsburgh, PA, USA, in 1988.
He is a Research Professor in the Institute for
Complex Engineered Systems, College of Engineering, and Department of Electrical and Computer Engineering, Carnegie Mellon University. He is also the
Director of the Laboratory for Interactive and Wearable Computer Systems. He
has written or edited several books in the areas of mobile computing, digital
system design, and VLSI systems and has given keynote lectures at over a
dozen representative international conferences. He has had editorship roles in
four IEEE Transactions journals—on mobile computing, parallel and distributed
systems, VLSI systems, and computers.
Dr. Smailagic is the Chair of the IEEE Technical Committee on Wearable
Information Systems. He has been a Program Chairman or Cochairman of IEEE
conferences over ten times. He received the 2000 Allen Newell Award for
Research Excellence from the CMU’s School of Computer Science, the 2003
Carnegie Science Center Award for Excellence in IT, and the 2003 Steve Fenves
Systems Research Award from the CMU’s College of Engineering. He also
received the Fulbright Postdoctoral Award.

Wei Wang (M’12) received the M.D. degree from
Peking University Health Science Center (formerly
Beijing Medical University), Beijing, China, in 1999.
In 2002, he received the M.Sc. degree in biomedical
engineering from the University of Tennessee Health
Science Center, Memphis, TN, USA, and in 2006 he
received the Ph.D. degree in biomedical engineering
from Washington University, St. Louis, MO, USA.
He is currently an Assistant Professor in the Department of Physical Medicine and Rehabilitation
with a Secondary Appointment in the Department of
Bioengineering, University of Pittsburgh, Pittsburgh, PA, USA. Prior to joining
the University of Pittsburgh, he served as a Senior Scientist at St. Jude Medical,
Inc., Los Angeles, CA, USA. His research interests include neural engineering,
motor neuroprosthetics, brain–computer interfaces, rehabilitation of movement
disorders, and motor system neurophysiology.
Dr. Wang currently holds a multidisciplinary clinical research scholar (NIH
KL2) award from the University of Pittsburgh and is the Chair of the IEEE
Engineering in Medicine and Biology Pittsburgh Chapter.

