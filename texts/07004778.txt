IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 2, MARCH 2016

615

A Novel Approach to Segment Skin Lesions in
Dermoscopic Images Based on a Deformable Model
Zhen Ma and João Manuel R. S. Tavares

Abstract—Dermoscopy is an imaging technique that has been
widely used in the diagnosis of skin lesions. However, its accuracy
largely depends on the dermatologist’s experience; thus, computeraided diagnosis techniques are required. In this paper, a novel
approach based on a deformable model is proposed to handle the
segmentation of skin lesions in dermoscopic images. The RGB color
space is converted so that the color information contained in the
images can be used effectively to differentiate normal skin and skin
lesions; and the differences in the color channels are combined together to define the speed function and the stopping criterion of
the deformable model. This novel approach is robust against the
noise, and provides an effective and flexible segmentation. Two
image databases were used to test the performance of the novel
approach and the segmentation results obtained were satisfactory.
Quantitative analysis on 250 dermoscopic images showed that the
novel algorithm outperformed other state-of-the-art algorithms.
Also, using comparative data, the reliability and the implementation issues of the approach are discussed in this paper.
Index Terms—Color spaces, image segmentation, level set
method, medical imaging, melanoma.

Fig. 1. (a) Dermoscopic image with a common nevi; (b)–(c) Two dermoscopic
images with melanoma; (d) Dermoscopic image with an atypical nevi.

I. INTRODUCTION
ELANOMA refers to malignant tumors in melanocytes.
Melanoma accounts for less than 20% among all cases
of skin cancer [1], [2], but it is one of the three cancers with
the highest mortality rate, and its incident is increasing rapidly
in the Caucasian population [3]–[5]. However, if melanoma is
detected in the early stages and treated properly, the survival
rate is very high [6], [7].
Dermoscopy is a noninvasive imaging technique that has been
developed to assist skin cancer diagnoses. A microscope with
incident light and oil immersion is used to visualize the subsurface structures of the skin. This technique enables more details
of colors and textures of the skin lesions to be observed. Fig. 1
shows four examples of dermoscopic images. Dermoscopy improves the detection rate of melanomas considerably compared
to inspection with the naked eye whose accuracy is only 60%
[6], [8]. Nevertheless, it has also been pointed out that the diagnostic accuracy using this technique largely depends on the

M

Manuscript received July 24, 2014; revised October 1, 2014 and December
1, 2014; accepted January 6, 2015. Date of current version March 3, 2016. This
work is funded by European Regional Development Funds (ERDF), through the
Operational Programme ‘Thematic Factors of Competitiveness’ (COMPETE),
and Portuguese Funds, through the Fundação para a Ciência e a Tecnologia (FCT), under the project: FCOMP-01-0124-FEDER-028160/PTDC/BBBBMD/3088/2012. The first author also thanks FCT for the post-doc grant:
SFRH/BPD/97844/2013.
The authors are with the Instituto de Engenharia Mecânica e Gestão Industrial
and the Faculdade de Engenharia da Universidade do Porto, 4200-465 Porto
Portugal (e-mail: zhen.ma@fe.up.pt, tavares@fe.up.pt).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2015.2390032

dermatologist’s experience [9], [10]. In order to eliminate this
subjectivity, computer-aided diagnoses (CAD) are needed. A
common CAD system is composed of three steps: image segmentation, feature extraction, and classification. Given that the
last two steps are based on the quantitative analysis of the segmented skin lesions, the accuracy of segmentation has a decisive
influence on the whole CAD system.
The appearance of skin lesions in dermoscopic images may
vary considerably depending on the skin condition. Also, the
influence of hair, skin texture, and air bubbles may blur the
boundary between the skin lesions and the surrounding healthy
skin. Consequently, segmentation of dermoscopic images is a
challenging task and a hurdle to overcome for an effective CAD
system. Many algorithms have been proposed to solve this problem [11], [12]. According to the technique used for segmentation, the current algorithms for dermoscopic images can be classified into three types: thresholding, clustering, and deformable
models. The majority belongs to the first two types.
The image segmentation algorithms based on thresholding
depend on quantitative differences between the skin lesions and
normal skin. For example, the fuzzy theory was combined with
thresholding techniques for segmentation in [13], and an algorithm based on statistical region merging was proposed in [14].
A dermatologist-like tumor extraction algorithm (DTEA) was
developed in [15] that combined the thresholding with the iterative region growing to carry out the segmentation; an improved
version of this latter algorithm was presented in [16]. In [17],
rough regions of skin lesions were first detected using a mixture
model and local entropy techniques; then, a global thresholding

2168-2194 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

616

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 2, MARCH 2016

technique based on Otsu’s method was applied to refine the
segmented regions. In [18], thresholding algorithms were
combined and their segmentation results were fused together
through an energy function to obtain a refined boundary of the
skin lesions.
For algorithms based on clustering, pattern recognition techniques, such as clustering and supervised classification, were
used to extract the features of skin lesions for segmentation.
For example, a 2-D color clustering algorithm was proposed
in [19]; in that algorithm, a histogram was calculated from the
two principal components of the CIE L∗ u∗ v∗ color space, and
a perceptron classifier was applied to obtain the centers of initial clusters; then, a modified fuzzy C-means algorithm was
used to segment the boundary of skin lesions. In [20], a neural network was trained based on the profiles of lesions in the
training sets and the segmentation results were satisfactory with
the assistance of a color normalization preprocessing step. An
unsupervised algorithm based on a modified JSEG algorithm
was proposed in [21]. In [22] and [23], dynamic programming
was used to solve the local minima and overlapping errors that
appeared in the segmentation process. Statistical information,
spatial interactions, and color clustering techniques were incorporated to assist the segmentation in [24]–[27].
The algorithms proposed in [28]–[33] are examples of the
third type. By using a deformable model, the segmentation is
treated as a curve evolution and the final status of the moving contour(s) is defined as the object boundary. Compared to
the first two types, the segmentation algorithms based on deformable models are more flexible to handle the influence of
noise, artifacts, and variations in illumination and color, and
their performance is more robust when segmenting images acquired under complex imaging conditions. Comparisons and
reviews of different segmentation algorithms can be found in
[12] and [34]–[37].
In this study, we focus on the segmentation of skin lesions
in dermoscopic images and propose a novel approach based
on a deformable model. Following the statistical features of
dermoscopic images in different color spaces, the contrasts between the lightness and saturation of the skin lesions and the
surrounding normal healthy skin were used as the segmentation
clues and were combined to generate the region-based external
forces. The color information of the dermoscopic images was
used to assist the segmentation and prevent overcontraction of
the curve evolution. Therefore, the initial curve can move toward
the boundary of skin lesions in a robust way.
In the next section, color spaces and deformable models are
reviewed; then, in Section III, the proposed approach is introduced, including the definitions of the initial conditions, speed
function, and stopping strategy; afterwards, numerical tests are
presented, and based on the quantitative analysis, implementation issues of the algorithm are discussed. Finally, in the last
section, the conclusions and perspectives of future work are
indicated.
II. BACKGROUND
Dermoscopic images are normally acquired by a hand-held
dermascope, with the color information represented in the 24-bit

RGB color space for display purposes. However, the majority of
the current segmentation algorithms were developed for grayscale images; a straight-forward method to segment the skin
lesions is to discard the color information and convert the color
dermoscopic images to gray-scale images, in such a way, the
image intensity of each pixel is calculated through a weighted
combination of the three RGB channels. Nevertheless, the appearance of skin lesions may vary considerably depending on
the skin condition, and in some cases, its main distinction to the
normal skin is the chromaticity that will be either lost or weakened when the color information is treated as a single intensity
value. Therefore, the RGB color space should be converted to
suitable color spaces so that the color information can be used
more effectively for segmentation.
A. Color Spaces
The RGB color space is the most common color space used
to store color information. Despite its popularity for display
purposes, the RGB color representation is unsuitable for many
image segmentation problems; one of the main reasons for this
difficulty is that the three color channels contain correlated information, and when the color varies, the change of each component
is not linear and difficult to predict. Therefore, it is hard to measure the difference between two colors in the RGB color space.
In order to solve this problem and to use the color information
more effectively, two color spaces of the CIE system—L∗ a∗ b∗
and L∗ u∗ v∗ models have been adopted. Both of them are variations of the CIE XYZ color space and are referred to as uniform
color models. In these two color spaces, the lightness component is separated from the color expression into channel L with
values ranging from 0 to 100; the separation is a big advantage
when processing dermoscopic images as the perceptual difference between colors is often influenced by lightness variations.
The values of u∗ and v ∗ in the L∗ u∗ v∗ model are the chrominance coordinates (u∗ , v ∗ ) representing the position of the color
in the uniform chromaticity scale diagram. The value of a∗ in
the L∗ a∗ b∗ model stands for the position of the color between
magenta (positive direction) and green (negative direction); and
the value of b∗ stands for the position of the color between yellow (positive direction) and blue (negative direction). Formulas
that are used to calculate these channels can be found in [38]
and [39].
Fig. 2 illustrates the different channels in the converted color
spaces by mapping the channel values into the range [0, 255];
in these channels, the differences between the normal skin and
skin lesions can be seen clearly.
B. Geometric Deformable Models
Deformable models are effective techniques for image segmentation and have a wide variety of applications such as in
medical image processing and analysis [11]. The main idea of
this technique is to model the segmentation as a process of a
curve evolution; thus, a proper speed function needs to be defined with which the initial curve can be driven to the desired
boundary. Based on the tracking approach of curve evolution,
deformable models can be divided into parametric models and
geometric models. The level set method [40] was adopted in

MA AND TAVARES: NOVEL APPROACH TO SEGMENT SKIN LESIONS IN DERMOSCOPIC IMAGES BASED ON A DEFORMABLE MODEL

617

III. SEGMENTATION
Deformable models are normally semiautomatic. However,
there are two issues that can appreciably affect their performance, and therefore, need to be well defined: the initial conditions and the values of the parameters used. The following
strategies were adopted in the proposed approach to achieve an
effective segmentation of skin lesions in dermoscopic images.
A. Initial Curve

Fig. 2. (a) Lightness channel in the CIE color systems of the image in Fig. 1(a);
(b) and (c) a and b channels of the image in Fig. 1(a) with their values mapped
to the range [0, 255] for illustration purpose; (d) and (e) u and v channels of the
image in Fig 1(a) mapped to the range [0, 255]. (f) Saturation channel of the
image in Fig. 1(a) mapped to the range [0, 255].

the geometric models to facilitate the computations: instead of
tracking the movement of each curve point, the curve is embedded into a higher dimensional level set function as its zero level
set. This implicit representation decreases the computational
complexity for tracking considerably. For 2-D image processing, the equation of motion for a geometric deformable model
is normally a level set equation written as
∂φ
+ F |∇φ| = 0
∂t

(1)

where φ (x, y, t) is the level set function with (x, y) the coordinates and φ (x, y, t) = 0 representing the curve at the time t;
F is the speed function with which the moving curve can stop
or reach a stable status at the boundary of the focused object.
The level set function φ (x, y, 0) is usually defined as the signed
distance function to the initial curves.
Compared with other image segmentation techniques, deformable models have several advantages when applied to dermoscopic images: the implicit representation of the moving
curve is a way to obtain the regions and the boundaries of
the skin lesions simultaneously, which is a desirable feature for
shape and color analysis; the robustness against the influence of
noise with the smoothing effects of the internal forces during the
curve evolution; and strategies can be integrated to guarantee
that the boundaries obtained have the desired properties, for
example, to have the same topology as the initial curve [41].

There are no general requirements on the position of the initial
curves in a geometric deformable model, since the evolution and
moving direction are determined by the speed function. However, for the segmentation of skin lesions, given that the colors of
skin lesions are frequently inhomogeneous, the evolving curves
can easily be attracted to the wrong inner boundaries if they
move inside the skin lesion regions. On the other hand, normal
healthy skin has a comparably homogeneous color distribution.
Hence, the curve evolution is limited to contraction in the novel
approach. In this way, the position of the initial curve is determined by the location of the skin lesion and is required to cover
the entire region of the skin lesion. The initial curve will then
move inwards until it arrives at the boundary of the skin lesion
where the lightness and color are different than normal healthy
skin.
Due to the complex imaging background of dermoscopic images, the initial curve is defined manually. The values of the
level set function φ (x, y, 0) are then defined as

d (x, y) ,
if the pixel is inside C
φ (x, y, 0) =
(2)
−d (x, y) ,
otherwise
where d (x, y) is the Euclidean distance of the pixel (x, y) to the
contour C; and the internal and external regions of the evolving
curve at the time t can be written as
ΩI = {(x, y) |φ (x, y, t) > 0}

(3)

ΩE = {(x, y) |φ (x, y, t) ≤ 0} .

(4)

B. Speed Function
The CIE L∗ a∗ b∗ and L∗ u∗ v∗ color models provide approximately uniform perceptual descriptions of colors. Among the
five channels in the two spaces, the lightness channel provides an important clue for segmentation. However, exclusively
using this channel can cause unreliable segmentation, a similar problem occurs when using a gray-scale image. Therefore
the color information is necessary for a correct segmentation.
The a∗ , b∗ , u∗ , and v ∗ channels are color coordinates, and are
unable to express in a simple way the chromatic differences
between normal skin and skin lesions quantitatively; also, various parameters are needed to map the chromatic changes when
using these channels. These factors can lead to less reliable
segmentations and they are more sensitive to imaging conditions; hence, these four channels are inappropriate to define the
speed function for segment dermoscopic images. Consequently,
a measure is needed that can combine the information from
the lightness and the colorfulness contained in the dermoscopic

618

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 2, MARCH 2016

image. Thus, color saturation is adopted to fulfill this bridging
role.
Saturation is a measure that describes the colorfulness of a
color relative to its lightness. This channel appears in many
color space models, such as HSL, HSV, and HSI; nonetheless,
it is not officially defined in the CIE system. There are various
definitions and formulas to calculate this channel; a widely used
one in computer vision is

0,
if R + G + B = 0
(5)
S=
m in(R ,G ,B )
otherwise.
1 − (R
+G +B )/3 ,
Let us make a general assumption that the lightness and saturation of the normal skin follow Gaussian distributions; then,
with the aforementioned definitions, the speed function of the
deformable model is proposed as
(6)
F (x, y) = PL (x, y) ∗ Ps (x, y) ∗ (1 + κ)


∇φ
is the curve curvature that serves as the inwhere κ = ∇ |∇φ|
ternal force to regularize the geometric properties of the moving
curve, and


1
(L (x, y) − μL )2
PL (x, y) = √
exp −
(7)
2σL2
2πσL


1
(S (x, y) − μS )2
PS (x, y) = √
exp −
(8)
2σS2
2πσS
where (μL , σL ) and (μS , σS ) are the means and standard deviations of the lightness and saturation values of the normal skin,
respectively.
With the initial curve covering the skin lesion, such a speed
function will lead the evolving curve to contract to the places
where either the lightness or the saturation is appreciably different from normal skin. The definition of the speed function
in (6) includes the statistical information of lightness and saturation channels of normal skin. Nevertheless, these values are
unknown prior to the segmentation. To obtain an approximation
of these four values, Otsu’s method [42] is applied to binarize the
image based on the lightness channel. Otsu’s method is adopted
here because in most cases, it can provide a suitable preliminary
classification based on the lightness difference between normal
skin and skin lesions [16], [21], [36]. In order to facilitate this
process, the intensity function I in the binary image is defined
as

0,
if pixel (x, y) represents normal skin
I (x, y) =
255, if pixel (x, y) represents skin lesion.
(9)
Correspondingly, the region of normal skin Ω0 and the region
of skin lesions Ω1 can be written as
Ω0 = {(x, y) |I (x, y) = 0}
Ω1 = {(x, y) |I (x, y) = 255} .

(10)
(11)

The values of μL , σL , μS , σS are then calculated in a narrow
band next to the initial curve defined as follows:
Ω0 = {(x, y) | − 50 < φ (x, y, 0) < 0} ∩ Ω0

(12)

where φ (x, y, 0) is the initial level set function defined in (2).
The region Ω 0 is composed of pixels that are classified as
representing normal skin in the binary image of (9) and is located
next to the initial curve; given that the skin lesions are completely
inside the initial curve, this region can provide an approximation
of the statistical distributions of the lightness and saturation of
the normal skin. These statistical values are then updated along
with the curve evolution.
C. Evolution
The speed function in (6) involves only the information of normal skin, as the appearance of the skin lesions are very varied.
As reviewed in Section II, the coordinates (a∗ , b∗ ) and (u∗ , v ∗ )
in the CIE L∗ a∗ b∗ and L∗ u∗ v∗ color spaces describe the positions
of a color relative to the color base and diagram. The locations
of these coordinates reflect the major perceptual difference between the normal skin and skin lesions; hence, the coordinates
of pixels representing normal skin should be near to each other
and have considerable distance to the ones representing skin
lesions. Accordingly, the image pixels can be classified into two
groups based on their distances to the centroids of normal skin
and skin lesions in the two color coordinate systems.
However, a similar problem as the one in Section III-B arises:
the centroids of the two groups are unknown. Also, the binary
image from Otsu’s method is unsuitable to be used here to calculate the centroids, because the centers obtained with such a preliminary classification may have large deviations to the true ones
and cause incorrect segmentations. Instead, since the skin le(t)
sions are inside the curves, a neighboring external region Ω0 of
the evolving curve at the time t is used to calculate the centroid of
(t)
normal skin in the color space, and the internal region Ω1
of the curve is used to calculate the centroid of the skin lesions
(t)

(13)

(t)

(14)

Ω0 = {(x, y) | − 50 < φ (x, y, t) < 0}
Ω1 = {(x, y) |φ (x, y, t) > 0} .

Accordingly, the centroids (a∗0 , b∗0 ) and (u∗0 , v0∗ ) of the normal
skin, and (a∗1 , b∗1 )and (u∗1 , v1∗ ) of the skin lesions are calculated
as
a∗0 =
u∗0 =
a∗1 =
u∗1 =

1



(t)

||Ω0 ||
1

(t )

p∈Ω 0



(t)
||Ω0 ||
(t )
p∈Ω 0

1



(t)

||Ω1 ||
1

a∗p , b∗0 =
u∗p , v0∗ =
a∗p , b∗1 =

(t )
p∈Ω 1



(t)
||Ω1 ||
(t )
p∈Ω 1

u∗p , v1∗ =

1



(t)

||Ω0 ||
1




(t)

||Ω1 ||
1

(15)

vp∗

(16)

b∗p

(17)

vp∗ .

(18)

(t )

p∈Ω 0

(t)
||Ω0 ||
(t )
p∈Ω 0

1

b∗p

(t )
p∈Ω 1



(t)
||Ω1 ||
(t )
p∈Ω 1

Along with the contraction of the curve, the centroids of
the skin lesions and the surrounding normal skin will become
more accurate. Meanwhile, a binary image can be generated

MA AND TAVARES: NOVEL APPROACH TO SEGMENT SKIN LESIONS IN DERMOSCOPIC IMAGES BASED ON A DEFORMABLE MODEL

using the following rule:
⎧
0,
if d0 (a∗ , b∗ ) < d1 (a∗ , b∗ )
⎪
⎪
⎨
and d0 (u∗ , v ∗ ) < d1 (u∗ , v ∗ ) (19)
I (t) (x, y) =
⎪
⎪
⎩
255,
otherwise
where a∗ , b∗ , u∗ , and v ∗ are the values of the corresponding
channels of the pixel (x, y), and d0 , d1 , d0 , and d1 are the Euclidean distances to the centroids of the normal skin and the
skin lesions in the CIE L∗ a∗ b∗ and CIE L∗ u∗ v∗ color spaces,
respectively, which are calculated as

d0 (a∗ , b∗ ) =
(a∗ − a∗0 )2 + (b∗ − b∗0 )2
(20)

(a∗ − a∗1 )2 + (b∗ − b∗1 )2
(21)
d1 (a∗ , b∗ ) =

d0 (u∗ , v ∗ ) =
(u∗ − u∗0 )2 + (v ∗ − v0∗ )2
(22)

(23)
d1 (u∗ , v ∗ ) =
(u∗ − u∗1 )2 + (v ∗ − v1∗ )2 .
Using these definitions, only the pixels of the colors that are
similar to normal skin in both the a∗ –b∗ and u∗ –v∗ planes are
assigned to the black color.
The binary image I (t) actually provides a classification of the
image pixels according to their colors; based on this classification, the distribution of the saturation values of normal skin
around the skin lesions can be more suitable than that from the
region defined in (12). Hence, the mean and standard deviation
of normal skin (μS , σS ) are calculated and updated during the
(t)
evolution in a subregion of Ω0 defined as
(t)
Ω 0

= {(x, y) |I

(t)

(x, y) = 0} ∩

(t)
Ω0 .

(24)

Then, the speed values defined in (6) are updated in order to
guide the curve toward the segmentation more accurately.
D. Stopping Criterion
In the ideal situation, the curve will move inwards with the
speed function defined in (6) until it arrives at the position where
either the lightness or the saturation is different from normal
skin. The quick decrease of the speed value will slow down
the movement of the curve and let it achieve a stable status.
However, due to the considerable variations in the lightness and
saturation values of normal skin, when the curve arrives at a
skin lesion, the decrease of speed values may not be enough
to attract the curve to the boundary; and further evolution will
let the curve leak into the skin lesions. Therefore, strategies are
needed to avoid this.
The white regions in the binary image I (t) represent the skin
lesions, and along with the curve evolution, this classification
will be refined and will concentrate on the real boundaries of
the skin lesions. To assure that the curve moves slowly when
close to the boundary of a skin lesion, the speed function in (6)
is modified to

αF (x, y) , if I (t) (x, y) = 255
∗
(25)
F (x, y) =
F (x, y) ,
if I (t) (x, y) = 0.

619

where α ∈ [0, 1] is a penalty to the speed values of the pixels
that are classified as the skin lesions at the time t. The modified speed function can attach the moving curve to the possible
boundary. The parameter α can be viewed as the color sensitivity of the segmentation: when α approaches zero, the curve
movement will be affected more by the changes of color and
will be more sensitive to the influence of noise and the initial
classification I (0) ; with the increase of α, the penalty to the
speed function is weakened, and the curve will have a greater
possibility to pass the wrongly classified pixels and cause leakage. From another point of view, this parameter is a mimic of
the perceptual differences among individuals, and by adjusting
its value, the segmentation becomes more flexible to follow the
dermatologists’ evaluation.
Additionally, once a curve moves into the region of a skin
lesion, the different colors of the skin lesion will dramatically
change the centroids of normal skin and the skin lesions in the
two color spaces. As a result, there will be a considerable amount
of pixels misclassified as the skin lesions, and the binary image
I (t) has a tendency to invert the black and white regions. Based
on this clue, the evolution is stopped once the area of the skin
lesions in I (t) increases appreciably.
Besides the aforementioned strategy, an index L D(t) is defined as




L D(t) = LΩ ( t ) − LΩ ( t ) 
0

(26)

1

where LΩ ( t ) and LΩ ( t ) are the mean lightness values of the
0

(t)

1

(t)

regions Ω0 and Ω1 defined in (13) and (14), respectively.
This index reflects the difference of the mean lightness values of the internal and external regions of the moving curve,
and its value should increase along with the curve evolution.
Hence, once the curve moves into the region of skin lesions, its
value has a tendency to decrease; then, the curve evolution is
stopped.

E. Summary of Procedure
In the proposed approach, the color information is incorporated into the segmentation process and is used to assist the
determination of the final status of evolution. Fig. 3 shows the
process of segmentation using the image shown in Fig. 1(a). The
procedure of the approach can be outlined as follows.
Preprocessing:
Smooth the original image by applying a median filter to each
channel of the RGB space.
Initialization:
Set t = 0.
Define the initial curve.
Compute the initial level set function φ (x, y, 0) using (2).
Apply Otsu’s method on the L∗ channel in the CIE L∗ a∗ b∗
space.
Compute the statistical values μL , σL , μS , σS based on the
region Ω0 defined in (12).

620

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 2, MARCH 2016

TABLE I
QUANTITATIVE ANALYSIS OF THE PROPOSED APPROACH
D (I 0 , I 1 )

Type

1

Benign
Melanoma1
All1
Benign2
Melanoma2
All2
1
2

Fig. 3. Illustration of the proposed approach with the image in Fig. 1(a):
(a) initial curve (red contour); (b) binary image generated with (18), which
is obtained by applying Otsu’s method; (c) binary image generated with (28)
based on the color coordinates when the curve begins to evolve in Fig. 3(a);
(d) binary image generated with (28) when the curve achieves stable status in
Fig. 3(e); (e) final location of the curve; (f) boundary obtained overlapped with
the ground truth of the skin lesion (white area), and the comparison values were
D (I0 , I1 ) = 0.0507, D 1 (C 0 , C 1 ) = 6.7629, D 1 (C 0 , C 1 ) = 6.268.

D 1 (C 0 , C 1 )

D 2 (C 0 , C 1 )

μ(%)

σ (%)

μ

σ

μ

σ

10.03
13.11
10.82
13.91
14.16
13.92

4.34
4.88
4.66
7.79
8.07
7.78

8.91
11.44
9.55
10.35
11.43
10.41

4.59
5.82
5.03
6.03
5.52
5.99

8.59
10.14
8.99
9.67
11.67
9.77

4.20
5.42
4.56
5.73
7.49
5.82

Images from the database in [18].
Images from the PH2 database.

as melanomas and 67 as benign nevi; the other is a challenging
dermoscopic image database called PH2 [43], in which 160
images captured the complete region of skin lesions with 8
images diagnosed as melanoma and 152 as either typical nevi or
atypical nevi. Hence, a total of 250 dermoscopic images were
used for numerical tests. In order to perform the quantitative
analysis, let us suppose that C is the boundary of the skin
lesions; then, a binary image IC can be defined correspondingly
as

0,
if (x, y) is outside C
IC (x, y) =
(27)
255, if (x, y) is inside C.
Afterwards, the region of the skin lesions is
Ω = {(x, y) |IC (x, y) = 255}
and the area of skin lesions can be defined as
Area (I) = ||Ω||.

Repeat:
Set t = t + 1.
Compute φ (x, y, t) according to (1).
Calculate the spatial color centers (a∗0 , b∗0 ),(u∗0 , v0∗ ), (a∗1 , b∗1 ),
and (u∗1 , v1∗ ) using (15)–(18).
Build the binary image I (t) with (19) and update the values
(t)
μS , σS with the region Ω 0 defined in (24).
Compute the speed function F with (25).
Until:
t > tm ax , or
the curve has achieved a stable status, or
the area of the white region in I (t) has a tendency to increase,
and L D(t) in (26) has a tendency to decrease.
IV. EXPERIMENT AND DISCUSSION
Due to interobserver errors, the ground truth of lesion boundaries in dermoscopic images does not exist in normal practice.
Therefore, the comparison with the manual segmentation by
experienced technicians is a common way to evaluate the performance of an algorithm and was adopted in this study.
A. Numerical Tests
Two image databases were used to test the effectiveness of the
proposed algorithm: one is the database used in [18], which is
composed of 90 dermoscopic images with 23 images diagnosed

(28)

(29)

With these definitions, the following three measures were
used to evaluate the difference between the ground truth and the
result obtained:
D (I0 , I1 ) = Area (I0 ⊕ I1 ) /Area (I0 )

(30)

D1 (C0 , C1 ) = D (p, C1 ), p ∈ C0

(31)

D2 (C0 , C1 ) = D (p, C0 ), p ∈ C1

(32)

where C0 is the ground true of the boundary, C1 is the boundary obtained by the algorithm, I0 and I1 are the binary images defined by C0 and C1 using (27), ⊕ is the exclusive or
(XOR) operator, D (p, C) is the point-to-contour distance that
can be calculated as D (p, C) = minp ∗ ∈C d (p, p∗ ) with d (p, p∗ )
the Euclidean distance between the two points, which is a similar
way used in the Hausdorff distance to define such a point-tocontour distance, and D (p, C) is the mean of this value. The
value of D (I0 , I1 ) reflects the deviation of the segmented regions of the skin lesion; while the contour-to-contour distance
in (31) and (32) reflect the differences between the boundaries.
The comparison of the results with α = 0.5 using the measures in (30)–(32) are listed in Table I. Although the performance
of the proposed algorithm using the second image database is
not as good as the performance with the database in [18], it still
achieves a very satisfactory result given that the images in PH2
have more complex backgrounds and contain more complicated
skin conditions. To make the evaluation more comprehensive

MA AND TAVARES: NOVEL APPROACH TO SEGMENT SKIN LESIONS IN DERMOSCOPIC IMAGES BASED ON A DEFORMABLE MODEL

621

TABLE II
COMPARISON DATA OF THE NINE STATE-OF-THE-ART ALGORITHMS IN [18]
Algorithm

[14]
[16]
[19]
[21]
[28]
[35]
[20]
[44]
[45]
New one

Benign

Melanoma

All

μ(%)

σ (%)

μ(%)

σ (%)

μ(%)

σ (%)

11.38
10.51
22.99
10.83
13.69
11.53
10.07
12.95
21.56
10.03

6.23
4.73
12.61
6.36
5.59
9.74
4.34
6.17
25.19
4.34

10.29
11.85
28.31
13.75
19.34
13.29
18.17
16.93
23.51
13.11

5.84
6.00
15.25
7.59
9.33
7.42
26.96
7.16
16.06
4.88

11.11
10.86
24.35
11.58
15.13
11.98
12.14
13.96
22.06
10.82

6.12
5.08
13.45
6.77
7.13
9.19
14.36
6.63
23.13
4.66

μ and σ are the mean and standard deviation of the measure D (I 0 , I 1 )
defined in (30).

and unbiased, Table II lists the data presented in [18] that describes the performance of nine state-of-the-art algorithms [14],
[16], [19], [20], [21], [28], [35], [44], [45] on the first database
with the measure defined in (30). The nine algorithms cover
all the three major effective segmentation techniques developed
for dermoscopic images. Among them, the ones in [14] and
[44] are thresholding based; [16], [19]–[21], [35], and [45] are
algorithms based on clustering techniques; and in [28], the algorithm is based on a deformable model. This table shows that the
proposed approach has the smallest mean error percentage on
images with benign skin lesions, and it achieved the best overall
performance in the first database.
Fig. 4 illustrates several examples in the two image databases,
from which one can see the robustness of the proposed approach
against the different imaging conditions and distinct types of
skin lesions.
B. Parameters and Initial Conditions
Tests on different image databases can show the adaptability of the proposed algorithm to distinct imaging conditions and
illustrate its robustness against their variances. To show the consistency of the approach, the value of α in (25) was fixed as 0.5
for both image databases. A notable point is that for a specific
image, changing this value can enhance the similarity of the
boundary obtained to the manual segmentation, which was used
as the ground truth. A case in point is shown in Fig. 5(c), where
the boundary obtained is very similar to the manual segmentation with a smaller α and the D (I0 , I1 ) decreases from 0.1641 to
0.0749. It is also worth pointing out that the parameter α in the
proposed algorithm is unlike the common parameters defined in
the deformable model-based approaches, which normally have a
substantial influence on the segmentation results and require
a delicate definition. The parameter α is used because it can
adjust the segmentation result flexibly, mimicking manual segmentations of different dermatologists as well as being a user
interaction tool in a CAD system.
The proposed algorithm is semiautomatic, as the initial curve
needs to be defined manually. The manual initialization was
adopted because the performance of the algorithm can be affected when the neighboring region of the initial curve involves
parts with significantly dissimilar colors to the normal skin.

Fig. 4. Examples of segmentation results: (a)–(c) segmented boundary (red
contour) with the ground truth (blue contour) of the images in Fig. 1(b)–(d), with
D (I0 , I1 ) = 0.0787, 0.0544, 0.1273, respectively; (d) and (e) performance of
the proposed approach on images with a strong influence of hairs, air bubbles
and blood vessels; the skin lesions in (d) and (f) are benign and the skin lesion
in (e) are melanoma with D (I0 , I1 ) = 0.1267, 0.1669, 0.1668.

Meanwhile, external influences, such as black frames and common nevus, often appear simultaneously in the image with the
skin lesion; a fully automatic process to exclude these influences
is not trivial under the complex background in dermoscopic
images and needs considerable preprocessing steps, which currently are not robust enough with the existing techniques. Controversially, a manual definition of the initial curve not only helps
to exclude these undesired influences, but also makes the segmentation more flexible and robust. Therefore, a manual initialization is a reasonable exchange for full automation. A common
concern is: How is the performance of the algorithm affected by
the location and size of the initial curve? There is no restriction
on the shape of the initial curve thanks to the deformable model
features; but the initial curve must cover the whole region of the
skin lesion. An interesting finding is that, with the premise that
the neighboring region of the initial curve is not seriously affected by unwanted influence, the initial curve has little influence
on the result obtained, except on the convergence time. Fig. 5
illustrates two examples: the different locations of the initial
curve caused small changes in the shapes of the final boundary;
this is more appreciable in Fig. 4(d), which is a more complex imaging but with the proposed algorithm, the major part
of the segmented region remains unchanged both qualitatively
and quantitatively. However, if the neighboring region of the
initial curve is seriously affected by unwanted influences, the
algorithm may not achieve satisfactory results. Meanwhile,
the size of the neighboring region of the initial curve determines
the statistical information of normal skin around the skin lesions.

622

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 2, MARCH 2016

and gives sound segmentation for further analysis of skin lesions. The current form of the novel approach is semiautomatic
as the initial curves need to be defined manually to avoid negative influence from the complicated imaging background. Future
work will continue to enhance the robustness of the approach
and study the influence of shape accuracy on the classification
of the skin lesions. For example, a preprocessing step such as the
pigment separation procedure proposed in [46] and [47] can be
a potential way to enhance the performance of a segmentation
algorithm. The discussions and techniques referred to in [48]
can also be useful when handling dermoscopic images.
ACKNOWLEDGMENT
The authors would like to thank Dr. M. E. Celebi for sharing
his image database and comparison data.
REFERENCES

Fig. 5. (a) Seven initial curves with different shapes and locations in Fig. 1(a).
(b) Boundaries obtained overlapped with each other, the mean and standard
deviation of D (I0 , I1 ) of these results are 0.0536 and 0.0022. (c) Seven initial
curves with different shapes and locations in Fig. 4(d). (d) Boundaries obtained
overlapped with each other; the mean and standard deviation of D (I0 , I1 ) of
these results are 0.1294 and 0.0073, respectively. (e) Boundaries obtained using
α = 0.2 (green contour) and α = 0.5 (red contour) with the same initial curve,
overlapped with the ground truth (blue contour).

A larger neighboring region around the initial curve can capture the variations of normal skin more accurately, but is more
likely to introduce unwanted influences. A bandwidth of 50 pixels as defined in (12) and (13) were used in the testing of both
databases and led to very satisfactory results.
V. CONCLUSION
A novel approach based on the deformable model is proposed here to segment skin lesions in dermoscopic images.
The proposed algorithm combines the information contained
in dermoscopic images, and defines the speed function based
on the lightness, saturation, and color information, with which
the evolving curve is guided to stop at the boundary of the skin
lesions. Numerical experiments illustrated the effectiveness of
the algorithm, and the implementation issues were discussed
based on the quantitative analysis.
Compared with other algorithms, the novel approach uses the
color information in the dermoscopic images efficiently and carries out the segmentation in a more robust and flexible manner.
The implementation of the novel approach is simple and the
segmentation results can easily be adjusted or refined through
the parameter of color sensitivity. The approach presented here
achieves very satisfactory results in challenging image databases

[1] R. S. Stern, “Prevalence of a history of skin cancer in 2007: Results of an
incidence-based model,” Arch. Dermatol., vol. 146, no. 3, pp. 279–282,
2010.
[2] American Cancer Society. Cancer facts & figures 2013. Available:
http://www.cancer.org/acs/groups/content/@epidemiologysurveilance/do
cuments/document/acspc-036845.pdf
[3] A. Jemal, R. Siegel, J. Xu, and E. Ward, “Cancer statistics, 2010,” CA,
Cancer J. Clin., vol. 60, no. 5, pp. 288–296, 2010.
[4] N. Howlader, A. M. Noone, M. Krapcho, J. Garshell, N. Neyman, S.
F. Altekruse, C. L. Kosary, M. Yu, J. Ruhl, Z. Tatalovich, H. Cho, A.
Mariotto, D. R. Lewis, H. S. Chen, E. J. Feuer, and K. A. Cronin.
(2012). SEER Cancer Statistics Review, 1975–2010. National Cancer Institute, Bethesa, MD, USA. [Online]. Available: http://seer.cancer.
gov/csr/1975_2009_pops09/
[5] A. Bleyer, M. O’Leary, R. Barr, and L. A. G. Ries, Cancer Epidemiology
in Older Adolescents and Young Adults 15 to 29 Years of Age, Including
SEER Incidence and Survival: 1975–2000, National Cancer Institute,
Bethesa, MD, USA, 2006.
[6] H. Pehamberger, A. Steiner, and K. Wolff, “In vivo epiluminescence microscopy of pigmented skin lesions. I. Pattern analysis of pigmented skin
lesions,” J. Amer. Acad. Dermatol., vol. 17, no. 4, pp. 571–583, 1987.
[7] C. M. Balch, A. C. Buzaid, S. J. Soong, M. B. Atkins, N. Cascinelli,
D. G. Coit, I. D. Fleming, J. E. Gershenwald, A. Jr. Houghton,
J. M. Kirkwood, K. M. McMasters, M. F. Mihm, D. L. Morton,
D. S. Reintgen, M. I. Ross, A. Sober, J. A. Thompson, and J. F. Thompson,
“Final version of the American Joint Committee on Cancer staging system
for cutaneous melanoma,” J. Clin. Oncol., vol. 19, no. 16, pp. 3635–3648,
2001.
[8] C. M. Grin, A. W. Kopf, B. Welkovich, R. S. Bart, and M. J. Levenstein.
“Accuracy in the clinical diagnosis of malignant melanoma,” Arch. Dermatol., vol. 126, no. 6, pp. 763–766, 1990.
[9] M. Binder, M. Schwarz, A. Winkler, A. Steiner, A. Kaider, K. Wolff,
and H. Pehamberger, “Epiluminescence microscopy. A useful tool for the
diagnosis of pigmented skin lesions for formally trained dermatologists,”
Arch. Dermatol., vol. 131, no. 3, pp. 286–291, 1995.
[10] H. Kittler, H. Pehamberger, K. Wolff, and M. Binder, “Diagnostic accuracy
of dermoscopy,” Lancet Oncol., vol. 3, no. 3, pp. 159–165, 2002.
[11] K. Korotkov and R. Garcia, “Computerized analysis of pigmented skin
lesions: A review,” Artif. Intell. Med., vol. 56, no. 2, pp. 69–90, 2012.
[12] M. E. Celebi, H. Iyatomi, G. Schaefer, and W. V. Stoecker, “Lesion border
detection in dermoscopy images,” Comput. Med. Imag. Grap., vol. 33,
no. 2, pp. 148–153, 2009.
[13] M. E. Yuksel and M. Borlu, “Accurate segmentation of dermoscopic images by image thresholding based on type-2 fuzzy logic,” IEEE Trans.
Fuzzy Syst., vol. 17, no. 4, pp. 976–982, Aug. 2009.
[14] M. E. Celebi, H. A. Kingravi, H. Iyatomi, Y. A. Aslandogan, W. V.
Stoecker, R. H. Moss, J. M. Malters, J. M. Grichnik, A. A. Marghoob,
H. S. Rabinovitz, and S. W. Menzies, “Border detection in dermoscopy
images using statistical region merging,” Skin Res. Technol., vol. 14, no. 3,
pp. 347–353, 2008.
[15] H. Iyatomi, H. Oka, M. Saito, A. Miyake, M. Kimoto, J. Yamagami,
S. Kobayashi, A. Tanikawa, M. Hagiwara, K. Ogawa, G. Argenziano,
H. P. Soyer, and M. Tanaka, “Quantitative assessment of tumor extraction

MA AND TAVARES: NOVEL APPROACH TO SEGMENT SKIN LESIONS IN DERMOSCOPIC IMAGES BASED ON A DEFORMABLE MODEL

[16]

[17]

[18]
[19]
[20]
[21]
[22]
[23]
[24]
[25]
[26]
[27]
[28]
[29]
[30]
[31]
[32]
[33]
[34]
[35]
[36]

[37]
[38]

from dermoscopy images and evaluation of computer-based extraction
methods for automatic melanoma diagnostic system,” Melanoma Res.,
vol. 16, no. 2, pp. 183–190, 2006.
H. Iyatomi, H. Oka, M. E. Celebi, H. Hashimoto, M. Hagiwara, M. Tanaka,
and K. Ogawa, “An improved Internet-based melanoma screening system
with dermatologist-like tumor area extraction algorithm,” Comput. Med.
Imag. Graph., vol. 32, no. 7, pp. 566–579, 2008.
Q. Abbas, I. F. Garcia, M. E. Celebi, W. Ahmad, and Q. Mushtaq, “Unified
approach for lesion border detection based on mixture modeling and local
entropy thresholding,” Skin Res. Technol., vol. 19, no. 3, pp. 314–319,
2013.
M. E. Celebi, Q. Wen, S. Hwang, H. Iyatomi, and G. Schaefer, “Lesion
border detection in dermoscopy images using ensembles of thresholding
methods,” Skin Res. Techno., vol. 19, no. 1, pp. e252–e258, 2013.
P. Schmid, “Segmentation of digitized dermatoscopic images by twodimensional color clustering,” IEEE Trans. Med. Imag., vol. 18, no. 2,
pp. 164–171, Feb. 1999.
G. Schaefer, M. I. Rajab, M. E. Celebi, and H. Iyatomi, “Colour and
contrast enhancement for improved skin lesion segmentation,” Comput.
Med. Imag. Graph., vol. 35, no. 2, pp. 99–104, 2011.
M. E. Celebi, Y. A. Aslandogan, W. V. Stoecker, H. Iyatomi, H. Oka, and
X. Chen, “Unsupervised border detection in dermoscopy images,” Skin
Res. Technol.,vol. 13, no. 4, pp. 454–462, 2007.
Q. Abbas, M. E. Celebi, I. Fondon, and M. Rashid, “Lesion border detection in dermoscopy images using dynamic programming,” Skin Res.
Technol.,vol. 17, no. 1, pp. 91–100, 2011.
Q. Abbas, M. E. Celebi, and I. Fondon, “Skin tumor area extraction
using an improved dynamic programming approach,” Skin Res. Technol.,
vol. 18, no. 2, pp. 133–142, 2012.
H. Zhou, G. Schaefer, A. Sadka, and M. E. Celebi, “Anisotropic mean
shift based fuzzy c-means segmentation of dermoscopy images,” IEEE J.
Sel. Topics Signal Process., vol. 3, no. 1, pp. 26–34, Feb. 2009.
A. Wong, J. Scharcanski, and P. Fieguth, “Automatic skin lesion segmentation via iterative stochastic region merging,” IEEE Trans. Inf. Technol.
Biomed., vol. 15, no. 6, pp. 929–936, Nov. 2011.
J. Gao, J. Zhang, M. G. Fleming, I. Pollak, and A. B. Cognetta, “Segmentation of dermatoscopic images by stabilized inverse diffusion equations,”
in Proc. IEEE Int. Conf. Image Process., 1998, pp. 823–827.
H. Ganster, A. Pinz, R. Röhrer, E. Wildling, M. Binder, and H. Kittler,
“Automated melanoma recognition,” IEEE Trans. Med. Imag., vol. 20,
no. 3, pp. 233–239, Mar. 2001.
B. Erkol, R. H. Moss, R. J. Stanley, W. V. Stoecker, and E. Hvatum, “Automatic lesion boundary detection in dermoscopy images using gradient
vector flow snakes,” Skin Res. Technol., vol. 11, no. 1, pp. 17–26, 2005.
Q. Abbas, I. Fondón, and M. Rashid, “Unsupervised skin lesions border
detection via two-dimensional image analysis,” Comput. Methods Programs Biomed., vol. 104, no. 3, pp. e1–e15, 2011.
H. Zhou, X. Li, G. Schaefer, M. E. Celebi, and P. Miller, “Mean shift
based gradient vector flow for image segmentation,” Comput. Vis. Image
Und., vol. 117, no. 9, pp. 1004–1016, 2013.
Q. Abbas, M. E. Celebi, and I. F. Garcia, “A novel perceptually-oriented
approach for skin tumor segmentation,” Int. J. Innov. Comput., Inf. Control,
vol. 8, no. 3, pp. 1837–1848, 2012.
M. Mete and N. M. Sirakov, “Lesion detection in dermoscopy images with
novel density-based and active contour approaches,” BMC Bioinformatics,
vol. 11, pp. S23-1–S23-13, 2010, Suppl. 6.
H. Zhou, G. Schaefer, M. E. Celebi, F. Lin, and T. Liu, “Gradient vector
flow with mean shift for skin lesion segmentation,” Comput. Med. Imag.
Grap., vol. 35, no. 2, pp. 121–127, 2011.
G. A. Hance, S. E. Umbaugh, R. H. Moss, and W. V. Stoeker, “Unsupervised color image segmentation with application to skin tumor borders,”
IEEE Eng. Med. Biol. Mag., vol. 15, no. 1, pp. 104–111, Jan./Feb. 1996.
R. Melli, C. Grana, and R. Cucchiara, “Comparison of color clustering
algorithms for segmentation of dermatological images,” Proc. SPIE Med.
Imag., vol. 6144, pp. 3S1–3S9, 2006.
M. Silveira, J. C. Nascimento, J. S. Marques, A. R. S. Marcal, T. Mendonca, S. Yamauchi, J. Maeda, and J. Rozeira, “Comparison of segmentation methods for melanoma diagnosis in dermoscopy images,” IEEE J.
Sel. Topics Signal Process., vol. 3, no. 1, pp. 35–45, Feb. 2009.
A. R. A. Ali and T. M. Deserno, “A systematic review of automated
melanoma detection in dermatoscopic images and its ground truth data,”
Proc. SPIE Med. Imag., 2012, pp. 8318–8854.
R. C. Gonzalez and R. E. Woods, Digital Image Processing. 3rd ed., New
York, NY, USA: Prentice-Hall, 2007.

623

[39] M. Sonka, V. Hlavac, and R. Boyle, Image Processing, Analysis, and
Machine Vision. 4th ed. Boston, MA, USA: Cengage Learning, 2014.
[40] S. J. Osher and J. A. Sethian, “Fronts propagating with curvaturedependent speed: Algorithms based on Hamilton-Jacobi formulations,”
J. Comput. Phys., vol. 79, no. 1, pp. 12–49, 1998.
[41] Z. Ma, R. N. M. Jorge, and J. M. R. S. Tavares, “A shape guided C-V model
to segment the levator ani muscle in axial magnetic resonance images,”
Med. Eng. Phys., vol. 32, no. 7, pp. 766–774, 2010.
[42] N. Otsu, “A threshold selection method from gray-level histograms,” IEEE
Trans. Syst. Man, Cybern., vol. 9, no. 1, pp. 62–66, Jan. 1979.
[43] T. Mendonca, P. M. Ferreira, J. S. Marques, A. R. S. Marcal, and J. Rozeira,
“PH2—A dermoscopic image database for research and benchmarking,”
in Proc. IEEE Eng. Med. Biol. Soc., 2013, pp. 5437–5440.
[44] R. Garnavi, M. Aldeen, M. E. Celebi, G. Varigos, and S. Finch, “Border
detection in dermoscopy images using hybrid thresholding on optimized
color channels,” Comput. Med. Imag. Graph., vol. 35, no. 2, pp. 105–115,
2011.
[45] H. Zhou, M. Chen, L. Zou, R. Gass, L. Ferris, L. Drogowski, and
J. M. Rehg, “Spatially constrained segmentation of dermoscopy images,”
in Proc. IEEE Int. Symp. Biomed. Imag., 2008, pp. 800–803.
[46] A. Madooei, M. S. Drew, M. Sadeghi, and M. S. Atkins, “Intrinsic melanin
and hemoglobin colour components for skin lesion malignancy detection,”
Med. Image Comput. Comput. Assist. Interv., vol. 15, pp. 315–322, 2012.
[47] S. Xu, “Skin lesion segmentation by using independent pigment concentration distribution,” J. Image Graph. (in Chinese), vol. 18, no. 11,
pp. 1452–1456, 2013.
[48] P. G. Cavalcanti and J. Scharcanski, “Macroscopic pigmented skin lesion
segmentation and its influence on lesion classification and diagnosis,”
Lecture Notes Comput. Vision Biomech., vol. 6, pp. 15–39, 2013.

Zhen Ma was born in Shandong, China, in 1982.
He received the B.S. degree in applied mathematics
from Inner Mongolia University, Hohhot, China, in
2004, the M.S. degrees in applied mathematics from
Beihang University, Beijing, China, in 2007, and the
Ph.D. degree in biomedical engineering from the University of Porto, Porto, Portugal, in 2012.
He is currently a Researcher at the Instituto de
Engenharia Mecânica e Gestão Industrial and the
Faculdade de Engenharia da Universidade do Porto,
Porto. His research interests include image processing, biomedical engineering, mathematical modeling, and parallel computing.

João Manuel R. S. Tavares was born in Porto, Portugal, in 1969. He received the B.S. degree in mechanical engineering in 1992, the M.S. degree in electrical
and computer engineering in 1995, and a Ph.D. degree in electrical and computer engineering in 2001,
all from the University of Porto, Porto.
From 1995 to 2000, he was a Researcher at the Institute of Biomedical Engineering, Porto. Since 2001,
he has been a Senior Researcher and a Project Coordinator at the Laboratory of Optical and Experimental
Mechanics, Institute of Mechanical Engineering and
Industrial Management, Porto. He was an Assistant Professor in the Department of Mechanical Engineering, Faculty of Engineering, University of Porto
between 2001 and 2011; and since then, he has been an Associate Professor in
the same department. His main research interests include computational vision,
computational mechanics, scientific visualization, human–computer interaction,
and new product development. He is the Coauthor of more than 550 articles in
national and international journals and conferences and a Coeditor of 30 international books and the Springer book series “Lecture Notes in Computational
Vision and Biomechanics,” and the Guest Editor of several special issues of
international journals.
Dr. Tavares has been a Cochairman of various international conferences, for
example, CompIMAGE 2006/2010/2012/2014, BioDENTAL 2009/2012/2014,
VipIMAGE 2007/2009/2011/2013/2015, and ICEBS 2013, and of numerous
minisymposia, workshops, and thematic sessions. He has been a member of several national and international journal editorial boards and is currently the Editorin-Chief of the journal “Computer Methods in Biomechanics and Biomedical
Engineering: Imaging & Visualization.”

