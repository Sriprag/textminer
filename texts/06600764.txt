IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 3, MAY 2014

969

A Spatiotemporal-Based Scheme for Efficient
Registration-Based Segmentation of Thoracic
4-D MRI
Y. Yang, E. Van Reeth, C. L. Poh, Member, IEEE, C. H. Tan, and I. W. K. Tham

Abstract—Dynamic three-dimensional (3-D) (four-dimensional,
4-D) magnetic resonance (MR) imaging is gaining importance in
the study of pulmonary motion for respiratory diseases and pulmonary tumor motion for radiotherapy. To perform quantitative
analysis using 4-D MR images, segmentation of anatomical structures such as the lung and pulmonary tumor is required. Manual
segmentation of entire thoracic 4-D MRI data that typically contains many 3-D volumes acquired over several breathing cycles is
extremely tedious, time consuming, and suffers high user variability. This requires the development of new automated segmentation
schemes for 4-D MRI data segmentation. Registration-based segmentation technique that uses automatic registration methods for
segmentation has been shown to be an accurate method to segment structures for 4-D data series. However, directly applying
registration-based segmentation to segment 4-D MRI series lacks
efficiency. Here we propose an automated 4-D registration-based
segmentation scheme that is based on spatiotemporal information
for the segmentation of thoracic 4-D MR lung images. The proposed
scheme saved up to 95% of computation amount while achieving
comparable accurate segmentations compared to directly applying
registration-based segmentation to 4-D dataset. The scheme facilitates rapid 3-D/4-D visualization of the lung and tumor motion and
potentially the tracking of tumor during radiation delivery.
Index Terms—Cancer, four-dimensional (4-D), image registration, image segmentation, magnetic resonance imaging (MRI).

I. INTRODUCTION
YNAMIC 3-D (4-D) magnetic resonance imaging (MRI)
is gaining importance in the study of pulmonary motion
for respiratory diseases and pulmonary tumor motion for radiotherapy [1], [2]. It has been shown that some of the elements
involved in pulmonary motion can be affected by disease, reducing respiratory mechanics [3], [4]. For example, tumor-bearing
hemithorax showed significant reduction of craniocaudal (CC)

D

Manuscript received February 2, 2013; revised April 30, 2013 and July 20,
2013; accepted September 5, 2013. Date of publication September 16, 2013; date
of current version May 1, 2014. This work was supported by Singapore National
Medical Research Council (NMRC) under Grant NMRC/NIG/1033/2010.
Y. Yang, E. Van Reeth, and C. L. Poh are with the School of Chemical and Biomedical Engineering, Nanyang Technological University, Singapore 637459 (e-mail: yang0262@e.ntu.edu.sg; eric.vanreeth@ntu.edu.sg;
clpoh@e.ntu.edu.sg).
C. H. Tan is with the Department of Diagnostic Radiology, Tan Tock Seng
Hospital, Singapore 308433 (e-mail: cherhengtan@gmail.com).
I. W. K. Tham is with the Department of Radiation Oncology, National
University Cancer Institute, Singapore 119228 (e-mail: Ivan_WK_Tham@
nuhs.edu.sg).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2013.2282183

displacement as compared to healthy hemithorax [5]. Dynamic
3-D MRI is an advanced noninvasive method that can continuously acquire 3-D volumes over time. It allows for real time
assessment of the lung volumes throughout all phases of the respiratory cycle, enabling the evaluation of diaphragmatic motion
and pulmonary tumor mobility [6]. The main advantage over
the existing method of 4-D computed tomography (CT) lies in
the fact that there is no ionizing radiation. Importantly, MRI
has multisequence capabilities that may allow for anatomic as
well as functional assessment (e.g., diffusion weighted and perfusion weighted imaging). The potential for MRI in imaging of
the lungs will continue to grow given the superior soft tissue
contrast and functional imaging capabilities of this modality.
Technical advances in radiation therapy delivery have enabled
oncologists to precisely target tumor and avoid normal tissue
using a technique termed as stereotactic ablative radiotherapy
(SABR). However, two limitations have been the inability to
accurately visualize and then track the tumor during radiation
delivery. More recently, 3-D approaches using MRI have been
proposed for both tracking [7] and gating [8]. Tracking refers
to the movement of the radiation dose delivery according to the
tumor motion, whereas gating refers to the switching on of the
radiation delivery only when the tumor moves within a permitted zone. Quantitative analysis of lungs and tumor during motion has become important for radiation therapy. Quantitative
volumetric assessment of the lungs using 4-D MRI has been
shown to correlate well with spirometric measurements [9].
To derive the volumetric measurements for quantitative analysis, precise segmentation of the structures of interests is required. However, manual segmentation of a 4-D dataset that
typically contains many 3-D volumes is extremely tedious and
time-consuming. Manual segmentation could also result in high
intra- and interuser variability. This requires the development
of new automated segmentation techniques or schemes for 4-D
MRI data segmentation. To this end, a few segmentation techniques have been proposed to segment 4-D CT/MRI cardiac and
thoracic images in a more automated manner. These techniques
include the use of deformable model [10], [11], statistical shape
model [12], [13], graph/watersheds cuts [14], [15], and image
registration [16]–[22]. Among these techniques, registrationbased segmentation approach has been a popular choice to
segment the 4-D dataset. Registration-based segmentation uses
registration methods to propagate template contours/surfaces of
target structures from a reference image/volume to the rest of
the images/volumes in a 4-D dataset and has achieved good segmentation results for 4-D CT/MRI images. Unlike segmentation

2168-2194 © 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

970

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 3, MAY 2014

Fig. 1. Different registration strategies: (a) registrations are performed from
the reference volume (v re f ) to every other target volumes; (b) registrations
are performed sequentially between adjacent volumes; (c) similar volumes are
grouped into N sets si . The reference volume (v re f ) is registered to each reprei
i
re f .
sentative v m
e d of volume set s and to each volume within the reference set s
i
Each representative v m e d is registered to each volume with the corresponding
volume set si .

approaches that use statistical prior knowledge, registrationbased framework does not require training phase using large
dataset but only requires the prior segmentation of the template
image/volume for subsequent propagation [19].
The general scheme of applying registration-based segmentation method to segment 4-D images is to register a reference volume (vref ) to the other target volumes using 3-D deformable registration to obtain the respective deformation fields
[see Fig. 1(a)] [21]. The reference volume will be segmented
separately and this segmented reference volume will then serve
as the template for propagation. The reference volume is usually segmented in a semiautomatic manner. To obtain the final
segmented target volumes, the corresponding deformation fields
are used to deform the template volume to match the target volumes. Fig. 2 illustrates the flowchart of this basic registrationbased segmentation scheme. However, the direct application
of registration-based segmentation to 4-D images over several
breathing cycles is inefficient. It is commonly admitted that the
larger the difference between the two volumes, the more iterations are required for registration to converge. If the reference
volume is chosen blindly and registered to the other volumes
within the 4-D dataset, the potential difference between volumes
to register can be large (e.g., for volumes at full-exhale and fullinhale phases). This would lead to large computational time. One
way to reduce computational time is to sequentially register ad-

Fig. 2.

Basic registration-based-segmentation scheme.

jacent volumes as illustrated in Fig. 1(b). Adjacent volumes are
believed to be similar. Thus, the number of iterations for registrations to converge is smaller. However, the propagated and
accumulated registration error may be very large for volumes
at later time frame [23]. Consequently, the registration scheme
shown in Fig. 1(a) is more commonly used.
In this paper, we propose a novel spatiotemporal-based
scheme for 4-D registration-based segmentation of thoracic 4-D
MR images. The scheme takes advantage of the periodicity of
the acquired volumes along the breathing cycles. Spatiotemporal information about diaphragm movement is derived directly
from the 4-D MR images to optimally choose the reference volume and to categorize the other volumes into subgroups based
on diaphragm positions. The tolerance parameter of registration
is subsequently adjusted based on the spatiotemporal information to speed up the registration convergence by reducing the
number of iterations required. The proposed scheme is fully
automatic after the initial segmentation of reference volume to
generate the template volume.
II. MATERIALS AND METHODOLOGY
A. Proposed Scheme
Limiting the number of iterations required during the registration step is central to the proposed approach. Our scheme aims
at performing registration between volumes that are acquired at

YANG et al.: SPATIOTEMPORAL-BASED SCHEME FOR EFFICIENT REGISTRATION-BASED SEGMENTATION OF THORACIC 4-D MRI

Fig. 4.
Fig. 3.

971

Generation of 2DST image.

Overall illustration of proposed scheme.

similar phases of the breathing cycle. Thus, the first step of the
proposed scheme consists of sorting the acquired volumes along
the breathing cycle through the generation of 2-D spatiotemporal (2DST) images, and grouping the volumes that have similar
diaphragm positions into N sets. Within each set, fast registrations are performed. A representative volume is chosen based on
relative diaphragm position in each set and each representative
volume is subsequently registered with the reference volume
from which the initial segmentation was obtained. The overall schematic is illustrated in Fig. 3. The following subsections
detail each step of our registration-based segmentation scheme.
1) Generate 2DST Image: The 2DST image shows the
prominent motion pattern of the diaphragm in CC direction [24].
Generation of 2DST image in this study is illustrated in Fig. 4.
The top diaphragm point (P (x, y, z)) of a 3-D volume within

the 4-D dataset is first defined by the user. A spatiotemporal
volume (STV) is then constructed by stacking coronal slices at
the same position z of each 3-D volume within the 4-D dataset.
A sagittal plane that passes through this point P (x, y, z) orthogonally intersects STV and defines a 2DST image (see Fig. 4).
After applying a simple hard threshold, the relative diaphragm
position is obtained from the binary 2DST image. A function d is
defined to represent the relative diaphragm position. The maximum exhalation position is set as 0 and the maximum inhalation
position is set as dm ax .
2) Group Volumes Based on Relative Diaphragm Position:
All volumes are grouped based on relative diaphragm position
derived from the previous step. The idea is to group similar volumes into one set [see Fig. 1(c)] so that most of the registrations
are performed between similar volumes within each set (si ).
The reference volume (vref ) is selected as the median position

972

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 3, MAY 2014

of all the volumes within a 4-D data series:
v = vref ,

if d (v) = median (d) .

(1)

The chosen reference volume is then segmented and the segmented reference volume will serve as the template. In this
study, we used an interactive active contour-based segmentation
method [25] available in “ITK-SNAP” [26], an open-source
program developed by Yushkevich et al. for semiautomatic segmentation of 3-D images, to delineate both lungs and tumor.
Volumes whose relative diaphragm displacements from vref
are not greater than x pixels are grouped together to form the
reference set (sref )
v ∈ sr e f ,

if d (vref ) − x ≤ d (v) ≤ d (vref ) + x

AND v = vref .

(2)

All other volumes are grouped into N sets of volumes (si , i =
1, 2, 3, . . ., N ) so that within each set, the relative diaphragm
displacement between any two volumes do not differ more than
2x + 1 pixels.
v ∈ si ,

if (i − 1)(2x + 1) ≤ d(v) ≤ i(2x + 1) − 1

AND v ∈
/ sr e f
i = 1, 2, . . . , N,


N = ceiling

dm ax + 1
2x + 1


.

(3)

i
A median volume (vm
ed ) was then selected to be the representative volume of each set (si )
  
(4)
v = vmi e d if d (v) = median d si .

This grouping step is illustrated in Fig. 5. We set x = 1 in this
study.
3) Perform a Series of Deformable Registrations and
Segment Target Volumes: After grouping volumes based on relative diaphragm position, registrations are performed. In order
to make the process efficient, registrations should be performed
between similar volumes. Thus the reference volume will be
registered to each volume within the reference set, and each
representative volume will then be registered to each volume
within its corresponding volume set. The only relatively large
computational cost will be in the registration of reference volume to each representative volume. For this purpose, a number
of registrations are performed as follows (see Figs. 1(c) and 3):
1) The reference volume (vref ) is registered to each volume
within the reference set (sref ). Deformation fields from
the reference volume to each volume within the reference
set (r(vref →sref )) are obtained.
2) The reference volume (vref ) is registered to each reprei
i
sentative volume (vm
ed ) of volume set (s ), generating
i
the deformation field (r(vref →vm ed )).
i
3) Each representative volume (vm
ed ) is registered to each
volume within its corresponding volume set (si ). Then
we get deformation fields from registering representative
volume to the volumes within the corresponding volume
i
j
j
i
j
i
set (r(vm
ed →v ), v ∈ s AND v = vm ed ).
From the combination of the computed deformation fields, it
is now possible to propagate the template volume, segmented

Fig. 5. Detailed steps of grouping similar volumes based on relative diaphragm
position.

using vref , to any volume of the 4-D dataset. We hypothesize
i
that the deformation from vref to any volume (v j = vm
ed ) can
be computed with a minimal error as



 i
 i

i
j
v ∈ si
r vref → v j = r vref → vm
ed + r vm ed → v
i
AND v j = vm
ed .

(5)

This hypothesis will be validated using the accuracy of the
automated segmentation results (see Section II-C.1).
B. Deformable Registration and Stopping Tolerance
The proposed scheme could be used for any deformable registration method. To demonstrate and evaluate the scheme, we implemented two widely used deformable registration algorithms
(i.e., demons and B-spline registration).
1) Demons Registration: Demons registration [27] iteratively deforms the reference volume by applying a displacement
vector dr in a voxel-by-voxel manner, according to (6),
	

(n )
(0)
(0)
∇vt
vref − vt
(n +1)
dr
=
(6)


	2 


 (0) 
2
(n )
(0)
vref − vt
+ 
∇vt 

where vref is the reference volume and vt is the target volume.
A Gaussian filter is applied to smooth the displacement field,
suppress noise and preserve the geometric continuity of the
deformed image. The overall deformation field r is updated

YANG et al.: SPATIOTEMPORAL-BASED SCHEME FOR EFFICIENT REGISTRATION-BASED SEGMENTATION OF THORACIC 4-D MRI

973

iteratively by
r(n +1) = r(n ) + dr(n +1) .

(7)

In this study, the stopping criterion for demons registration was
defined as
l(n −1) − l(n ) ≤ e

(8)

where e is the tolerance for registration to stop and l is the
relative norm defined by Gu et al. [28]
 
 (n +1) 


dr


(n )
(9)
l =  

 (n ) 

 .
r
2) B-Spline Registration: B-spline registration [29] deforms
an image by manipulating an underlying mesh of control points
based on B-splines. In this study, a uniform grid of control
points was automatically constructed with 8 control points along
each dimension. B-spline registration tries to minimize a cost
function associated with B-spline control point transformation
parameter φ
C (φ) = Csim ilarity [φ (vref ) , vt ] + λCsm o oth (φ)

(10)

where Csim ilarity is the image similarity and Csm o oth associates
with smoothness of the deformation. In this study, sum of square
difference (SSD) was used as image similarity measure and thin
sheet of metal bending energy [30] was used for smoothing. The
stopping criterion was calculated as
 
 dc 
  ≤ e.
(11)
 dφ 
In both registration approaches, the tolerance e determines when
the registration should stop and is inversely related to the number
of iterations. The hypothesis is that, with same level of registration accuracy, registration between two more similar volumes requires fewer iterations to converge thus smaller tolerance could
be set. We proved our hypothesis when registering pairs of volumes with different diaphragm displacements (i.e., the smaller
the difference in diaphragm displacement between the two volumes, the more similar the volumes are). A total of 11 pairs of
volumes from 2 patients were used to run the test [31]. After
each iteration of registration progress, automatically segmented
target volume was obtained for each pair of volumes. Dice similarity coefficient (DSC) values were calculated between the
automated segmentations and the ground truth. As the iteration
goes on, the registration will deform the reference image to be
more similar to the target image. As a result, the DSC value will
increase while the tolerance number e will decrease. When the
DSC value hit the “plateau,” tolerance number at that iteration
was noted down as the optimum value.
To determine the relationship between the tolerance e and
the relative diaphragm displacement, the plots of tolerance e
versus relative diaphragm displacement were fitted using exponential functions as shown in Fig. 6. The exponential functions
fitted well with R2 = 0.957 and 0.772 for Demons and B-spline
registration, respectively. As a result, we propose to adapt the
tolerance e with respect to the relative diaphragm distances between any two pairs of registered volumes (using the exponential
functions we obtained) to optimize the iteration number.

Fig. 6. Relationship between relative diaphragm displacement and optimal
tolerance e for (a) demons registration and (b) B-spline registration.

C. Evaluation
The basic registration-based segmentation scheme was implemented to benchmark the accuracy and computation amount
of our proposed scheme. As there is no criterion for the basic
scheme to choose the reference volume, two test cases were
implemented:
Best case: Choose the reference volume whose relative diaphragm position is the median of all the volumes. This is the
same way of choosing the reference volume as our proposed
scheme. The maximum diaphragm displacement between two
volumes is then dm ax /2.
Worst case: Choose the reference volume whose relative
diaphragm position is at the maximum exhalation phase (or
maximum inhalation phase) among all volumes. The maximum
diaphragm displacement between two volumes in this case is
dm ax .
1) Accuracy: To validate our hypothesis of (5), the accuracy
of the proposed and the basic segmentation schemes are evaluated by comparing the segmentation results with ground truths.
Three volumes within the 4-D dataset for each subject were
randomly chosen and segmented using ‘ITK-SNAP’ to serve
as the ground truths. These ground truths were verified by an
experienced clinician and edited where necessary. DSC is used
to quantify how well two segmentations, A and B match each
other [32]:
DSC =

2nA B
nA + nB

(12)

where nA B is the number of voxels that A and B have in
common, nA is the number of voxels within A, and nB is the
number of voxels within B. If two segmentations are identical,

974

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 3, MAY 2014

then DSC will be equal to 1. It will be 0 if A and B have no
common voxel.
2) Computation Amount: Our scheme is designed to limit
the computational complexity of applying registration-based
segmentation for 4-D dataset segmentation. In order to evaluate
the benefit of our scheme, the number of additions and multiplications were counted for the proposed scheme and for the
basic scheme. The percentage reduction of computation amount
is calculated as:
mbasic − mprop osed
× 100
(13)
reduction (%) =
mbasic
where mbasic and mprop osed consist of the number of additions
and multiplications for the basic scheme and for the proposed
scheme, respectively.
D. MRI Data
To evaluate and demonstrate the proposed scheme, 4-D MR
scans of the thorax of three healthy volunteers and three lung
cancer patients were acquired and analyzed. Institutional ethics
approval was obtained from Institutional Review Board (IRB).
Informed written consent was obtained from all subjects prior to
all examinations. Inclusion criteria were willingness and ability
to provide informed consent. Exclusion criteria were contraindications to MRI including claustrophobia, pacemakers and other
implanted electronic devices and pregnancy. All the scans were
acquired using a 3 T MR scanner (Siemens Magnetom Trio,
Germany) and a 6 channels body matrix coil. A controlledbreathing maneuver was applied during the scans. All subjects
were instructed to start breathing from maximum exhalation followed by continuous breathing in for 3 s and breathing out for
3 s. Each subject repeated this breathing in and out maneuver
for six times. Thirty 3-D volumes were acquired for each subject using a fast gradient-echo 3-D dynamic sequence (TWIST)
with parallel imaging algorithm GRAPPA PAT 2. All the scans
were acquired in coronal plane. Each volume has a resolution
of 128 × 128 × 36 pixels (2.81 × 2.81 × 4 mm3 ). The resulting
acquisition time was one volume per 0.9 s.
III. RESULTS
Both lungs and the tumor from all 6 subjects (30 volumes
per subject) were successfully segmented using the proposed
scheme. A total of 180 volumes were segmented. Representative
segmented images using proposed scheme were shown in Fig. 7.
A. Accuracy
Fig. 8(a) and (b) shows the DSC for left lung, right lung,
and tumor of all subjects for schemes using demons and
B-spline registration, respectively. Proposed scheme achieved
good segmentation accuracy, average DSCleft lung = 0.96 ±
0.01, DSCright lung = 0.96 ± 0.01, and DSCtum or = 0.83 ±
0.10 using demons registration and average DSCleft lung = 0.94
± 0.02, DSCright lung = 0.95 ± 0.01, and DSCtum or = 0.81 ±
0.10 using B-spline registration.
Friedman statistical test [33] is known for detecting differences in treatments across multiple test samples. The test

Fig. 7. Representative sample segmented images using proposed scheme.
(a) 2D slices and corresponding 3-D models. Contours in red: left lung; Contours
in green: right lung; contours in blue: tumor; contours in yellow: ground truth.
(b) Representative sample 3-D models constructed by automated segmented
images of Patient 1 showing the movement of lungs and tumor over time.

was carried out using SPSS 18.0 for Windows [34]. Results
showed that there are no significant differences between the
three schemes tested in terms of segmentation accuracy. This
implies that the proposed scheme achieved similar accuracy as
the basic scheme.
B. Computation Time/Amount
All the registration-based segmentations were performed using Windows XP, on an Intel Xeon Processor (dual core,
3.00 GHz) with 9 GB RAM. All the schemes were implemented using MATLAB version 7.1.1 (The Mathworks, Inc.,
Natick) [35]. As the focus was on evaluating the computational
improvement of the proposed scheme over the basic scheme,
the MATLAB implementations used in this study were not particularly optimized for reduced computational cost and memory
usage. Time for segmenting the entire 4-D data set of one subject
(thirty 3-D volumes) was around 35 min for proposed scheme,
70 min (best case) to 123 min (worst case) for basic scheme.
The average reduction of computation amounts (number of
additions and multiplications) of schemes using demons and
B-spline registration are shown in Fig. 9. When counting the
computational amount/time saving, the time counted includes
pre-processing steps such as generating the 2DST image, grouping the volumes, and identifying control points. In the case
of demons registration, the average reduction of computation
amounts ranged from 44.01 ± 10.42% (best case) to 66.12 ±
12.61% (worst case). Improvement was even better using

YANG et al.: SPATIOTEMPORAL-BASED SCHEME FOR EFFICIENT REGISTRATION-BASED SEGMENTATION OF THORACIC 4-D MRI

Fig. 8. Accuracy results (average Dice coefficient) of target structure segmentations for schemes using (a) demons registration and (b) B-spline registration.

975

Fig. 10. Plot of maximum diaphragm displacement of each subject against the
reduction of total computation amount for proposed scheme using (a) demons
registration and (b) B-spline registration.

IV. DISCUSSION

Fig. 9. Percentage reduction of computation amounts (addition and multiplication) between proposed scheme and basic scheme (both cases) using demons
registration and B-spline registration.

B-spline registration, with 81.23 ± 8.18% (best case) to 92.85 ±
5.37% (worst case). The computational amount of the additional
steps is negligible, for the ratio of computational amount of additional steps against the total amount less than 10−9 .
The plots of maximum diaphragm displacement of each subject against the reduction of total computation amount (number of additions plus number of multiplications) are shown in
Fig. 10.

Our proposed scheme has shown to be efficient in segmenting
4-D thoracic MR images, achieving reduction in computational
amount while maintaining good accuracy as compared to the
basic scheme. Limiting the number of iterations by adapting the
tolerance number to the relative diaphragm position has shown
to be effective in reducing the computation amount. Grouping
volumes based on relative diaphragm position has allowed only
similar volumes to be registered, preventing registration of volumes with large differences that will take longer to converge.
In the proposed scheme, apart from representative volumes
i
(vm
ed ), which are directly registered to the reference volume, the
deformation fields used to segment target volumes (v i ) within
set si are combined from two registration steps: deformation
fields from registering the reference volume to each representai
tive volume (r(vref →vm
ed )) and deformation fields from registering representative volumes to each volume within the cori
j
responding volume set (r(vm
ed →v )). In the basic scheme,
all target volumes are directly registered to the reference volume. Therefore, the deformation fields obtained are r(vref →v j ).
Since there is no significant difference between the proposed
scheme and the basic scheme in terms of segmentation accui
i
j
racy, it indicates that r(vref →vm
ed ) + r(vm ed →v ) is a good
j
approximation of r(vref →v ). It also shows that the propagation and accumulation of the registration error is negligible when

976

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 3, MAY 2014

only two steps of registration are performed. The volumes that
are close to the reference volume vref (in terms of relative diaphragm displacement) are grouped into the reference set sref .
In this way, vref can be directly registered to each volume within
sref . Thus the volumes within sref do not have to go through
i
i
j
the process r(vref →vm
ed ) + r(vm ed →v ). The computational
amount can be saved this way.
For all the schemes, a smaller DSC for the segmentation of
tumor was obtained, especially for Patient 2 (see Fig. 7). This is
likely due to the small size of the tumor. The voxel effects [36]
become very significant in each step of the scheme and in the
calculation of DSC. Any error in the deformable registration and
other procedures results in a relatively significant mismatch.
Our scheme introduces additional steps compared to the basic scheme. These steps are the generation of 2DST images
and the grouping of volumes based on relative diaphragm positions. However, the additional number of operations introduced
by these steps was largely compensated by the computational
complexity reduction made during the subsequent registration
steps.
From Fig. 10, it can be seen that when the range of the
diaphragm movement (dm ax ) increases, the reduction in complexity by using the proposed scheme increases. For the basic scheme, the reference volume has to be registered to every
volume with large differences (volumes at full-inhale and fullexhale phase), which increases the number of iterations for registration to converge. The larger the dm ax , the more iterations are
needed. By using the proposed scheme, the reference volume
i
needs to be registered only once to each representative (vm
ed )
of volume set (si ). The other registrations take place between
i
i
vm
ed and other volumes within s that are very similar. When
more volumes are acquired within one 4-D dataset, there will be
more volumes with large differences from the reference volume
(e.g., volumes at full-inhale and full-exhale phase) since the
lungs have a periodic motion pattern. Therefore, the improvement in terms of computation amount will be larger when the
proposed scheme is used for 4-D dataset with more volumes,
which makes the proposed scheme especially useful to study
the changes of pulmonary motion pattern over time. Moreover,
the improvement will be greater if the proposed scheme is applied on volumes with higher spatial resolution, where the organ
displacements are spread over a higher number of pixels.
In this study, when grouping similar volumes into sets we
have set the x number to be 1 so that the diaphragm position
between any two volumes do not differ more than 3 pixels. This
is due to the relatively low spatial resolution of the images used
in this study. With one pixel equals to 2.81 mm in the physical
space, we considered one pixel movement a large diaphragm
displacement. Also, by setting x equals to 1, there are enough
number of volumes within each set so that the efficiency of
the proposed scheme is optimized. For different applications,
especially for images with higher spatial resolution, one can set
the x number to be larger than 1 to avoid creating too many sets
with little differences between volumes within different sets and
too few volumes within each set.
The proposed scheme is designed to be suitable for parallel
computing. All the registrations can be performed independently

in a parallel manner. This can lead to even faster segmentation of
an entire 4-D dataset and fall into realistic computational times
in practice. Finally, the proposed scheme can also be potentially
used for segmentation of other organs having periodic motion,
such as heart and liver. For segmentation of 4-D cardiac data,
new spatiotemporal information has to be modeled instead of
the relative diaphragm displacement.
A limitation of this study is that the tolerance value for registration to stop is application dependent. Preliminary training
needs to be carried out for other applications (e.g., 4-D MRI
cardiac images, 4-D MRI liver images) to acquire relationship between tolerance number and spatiotemporal information.
Nonetheless, once this relationship is established, the scheme is
automatic.
V. CONCLUSION
This paper presents an accurate and computational-saving
registration-based segmentation scheme for 4-D thoracic MRI
data series. The scheme is fully automatic after initial segmentation to obtain the template volume. The proposed scheme incorporates spatiotemporal information about diaphragm movement to optimally choose the reference volume and to classify
the other volumes into subgroups. It also adaptively adjusts the
tolerance value based on spatiotemporal information in order
to lower the iteration number of registrations. The proposed
scheme does not depend on any particular registration method.
As demonstrated, it reduces computation amounts by up to 95%
while maintaining accurate segmentations.
REFERENCES
[1] J. Biederer, C. Hintze, M. Fabel, and J. Dinkel, “Magnetic resonance
imaging and computed tomography of respiratory mechanics,” J. Magn.
Resonance Imag., vol. 32, pp. 1388–1397, Dec. 2010.
[2] M. Wielputz and H. U. Kauczor, “MRI of the lung: State of the art,” Diagn
Interv Radiol., vol. 18, pp. 344–353, Jul.-Aug. 2012.
[3] K. Suga, T. Tsukuda, H. Awaya, K. Takano, S. Koike, N. Matsunaga, K.
Sugi, and K. Esato, “Impaired respiratory mechanics in pulmonary emphysema: Evaluation with dynamic breathing MRI,” J. Magn. Resonance
Imag., vol. 10, pp. 510–520, 1999.
[4] J. Ley-Zaporozhan, S. Ley, R. Eberhardt, O. Weinheimer, C. Fink, M.
Puderbach, M. Eichinger, F. Herth, and H. U. Kauczor, “Assessment of
the relationship between lung parenchymal destruction and impaired pulmonary perfusion on a lobar level in patients with emphysema,” Eur. J.
Radiol., vol. 63, pp. 76–83, 2007.
[5] C. Plathow, M. Klopp, C. Fink, A. Sandner, H. Hof, M. Puderbach, F.
Herth, A. Schmhl, and H. Kauczor, “Quantitative analysis of lung and
tumour mobility: Comparison of two time-resolved MRI sequences,” Brit.
J. Radiol., vol. 78, pp. 836–840, 2005.
[6] J. Dinkel, C. Hintze, R. Tetzlaff, P. E. Huber, K. Herfarth, J. Debus, H.
U. Kauczor, and C. Thieke, “4D-MRI analysis of lung tumor motion in
patients with hemidiaphragmatic paralysis,” Radiother Oncol, vol. 91,
pp. 449–454, Jun. 2009.
[7] S. Crijns, B. Raaymakers, and J. Lagendijk, “Proof of concept of MRIguided tracked radiation delivery: Tracking one-dimensional motion,”
Phys. Med. Biol., vol. 57, pp. 7863–7872, 2012.
[8] S. Crijns, J. Kok, J. Lagendijk, and B. Raaymakers, “Towards MRI-guided
linear accelerator control: Gating on an MRI accelerator,” Phys. Med.
Biol., vol. 56, pp. 4815–4825, 2011.
[9] C. Plathow, S. Ley, C. Fink, M. Puderbach, M. Heilmann, I. Zuna, and
H. U. Kauczo, “Evaluation of chest motion and volumetry during the
breathing cycle by dynamic MRI in healthy subjects: Comparison with
pulmonary function tests,” Investigative Radiol., vol. 39, pp. 202–209,
2004.

YANG et al.: SPATIOTEMPORAL-BASED SCHEME FOR EFFICIENT REGISTRATION-BASED SEGMENTATION OF THORACIC 4-D MRI

[10] Q. Duan, E. D. Angelini, and A. F. Laine, “Real-time segmentation by
active geometric functions,” Comput. Methods Programs Biomed., vol. 98,
pp. 223–30, Jun. 2010.
[11] J. M. Reinhardt, D. Kainmuller, R. Unterhinninghofen, S. Ley,
R. Dillmann, and J. P. W. Pluim, “Level set segmentation of the heart
from 4D phase contrast MRI,” in Proc. SPIE, Med. Imag.: Image Process., 2008, vol. 6914, pp. 6914141–6914148.
[12] S. P. O’Brien, O. Ghita, and P. F. Whelan, “A novel model-based 3D+time
left ventricular segmentation technique,” IEEE Trans. Med. Imag., vol. 30,
no. 2, pp. 461–474, Feb. 2011.
[13] B.-J. Leiner, J. Olveres, B. Escalante-Ramı́rez, F. Arámbula, and
E. Vallejo, “Segmentation of 4D cardiac computer tomography images
using active shape models,” in Proc. SPIE, Opt., Photon. Digit. Technol.
Multimedia Appl. II, 2012, vol. 8436, pp. 84361E1–84361E11.
[14] H. Lombaert, Y. Sun, and F. Cheriet, “Fast 4D segmentation of large
datasets using graph cuts,” in Proc. SPIE, Med. Imag.: Image Process.,
2011, vol. 7962, pp. 79622H1–79622H7.
[15] J. Cousty, L. Najman, M. Couprie, S. Clément-Guinaudeau, T. Goissen,
and J. Garot, “Segmentation of 4D cardiac MRI: Automated method
based on spatio-temporal watershed cuts,” Image Vis. Comput., vol. 28,
pp. 1229–1243, 2010.
[16] I. Sluimer, M. Prokop, and B. van Ginneken, “Toward automated segmentation of the pathological lung in CT,” IEEE Trans. Med. Imag., vol. 24,
no. 8, pp. 1025–1038, Aug. 2005.
[17] W. Lu, G. H. Olivera, Q. Chen, M. L. Chen, and K. J. Ruchala, “Automatic
re-contouring in 4D radiotherapy,” Phys. Med. Biol., vol. 51, pp. 1077–
1099, Mar. 7, 2006.
[18] Y. Yang, C. H. Tan, and C. L. Poh, “Visualization of lung using 4D magnetic resonance imaging,” in Int. Symp. Bioeng., Singapore, 2011, pp. 49–
55.
[19] X. Zhuang, C. Yao, Y. L. Ma, D. Hawkes, G. Penney, and S. Ourselin,
“Registration-based propagation for whole heart segmentation from compounded 3D echocardiography,” in Proc. IEEE Int. Symp. Biomed. Imag.:
From Nano Macro, 2010, pp. 1093–1096.
[20] S. Gaede, J. Olsthoorn, A. V. Louie, D. Palma, E. Yu, B. Yaremko, B.
Ahmad, J. Chen, K. Bzdusek, and G. Rodrigues, “An evaluation of an
automated 4D-CT contour propagation tool to define an internal gross
tumour volume for lung cancer radiotherapy,” Radiother Oncol, vol. 101,
pp. 322–328, Nov. 2011.
[21] M. Lorenzo-Valdes, G. Sanchez-Ortiz, R. Mohiaddin, and D. Rueckert,
“Atlas-based segmentation and tracking of 3D cardiac MR images using
non-rigid registration,” Med. Image Comput. Comput.-Assisted Intervention, vol. 2488, pp. 642–650, 2002.
[22] K. Wijesooriya, E. Weiss, V. Dill, L. Dong, R. Mohan, S. Joshi, and
P. Keall, “Quantifying the accuracy of automated structure segmentation
in 4D CT images using a deformable image registration algorithm,” Med.
Phys., vol. 35, pp. 1251–1260, 2008.
[23] R. Benjemaa and F. Schmitt, “Fast global registration of 3D sampled
surfaces using a multi-z-buffer technique,” Image Vis. Comput., vol. 17,
pp. 113–123, 1999.

977

[24] A. K. Sato, N. A. Stevo, R. S. Tavares, M. S. G. Tsuzuki, E. Kadota,
T. Gotoh, S. Kagei, and T. Iwasawa, “Registration of temporal sequences
of coronal and sagittal MR images through respiratory patterns,” Biomed.
Signal Process. Control, vol. 6, pp. 34–47, Jan. 2011.
[25] M. Kass, A. Witkin, and D. Terzopoulos, “Snakes: Active contour models,”
Int. J. Comput. Vis., vol. 1, pp. 321–331, 1988.
[26] P. A. Yushkevich, J. Piven, H. C. Hazlett, R. G. Smith, S. Ho, J. C. Gee,
and G. Gerig, “User-guided 3D active contour segmentation of anatomical
structures: Significantly improved efficiency and reliability,” Neuroimage,
vol. 31, pp. 1116–1128, 2006.
[27] J. P. Thirion, “Image matching as a diffusion process: An analogy with
Maxwell’s demons,” Med. Image Anal., vol. 2, pp. 243–260, 1998.
[28] X. Gu, H. Pan, Y. Liang, R. Castillo, D. Yang, D. Choi, E. Castillo,
A. Majumdar, T. Guerrero, and S. B. Jiang, “Implementation and evaluation of various demons deformable image registration algorithms on a
GPU,” Phys. Med. Biol., vol. 55, pp. 207–219, 2009.
[29] D. Rueckert, L. I. Sonoda, C. Hayes, D. L. G. Hill, M. O. Leach, and
D. J. Hawkes, “Nonrigid registration using free-form deformations: Application to breast MR images,” IEEE Trans. Med. Imag., vol. 18, no. 8,
pp. 712–721, Aug. 1999.
[30] G. Wahba, Spline Models for Observational Data. Philadelphia, PA:
SIAM, 1990.
[31] Y. Yang, E. Van Reeth, and C. L. Poh, “Adapting registration-basedsegmentation for efficient segmentation of thoracic 4D MRI,” in Proc.
IEEE Symp. Comput. Intell. Healthcare e-Health (CICARE), 2013, pp. 42–
45.
[32] L. R. Dice, “Measures of the amount of ecologic association between
species,” Ecology, vol. 26, pp. 297–302, 1945.
[33] D. J. Groggel, “Practical nonparametric statistics,” Technometrics, vol. 42,
pp. 317–318, 1998.
[34] PASW Statistics for Windows, Version 18.0 ed., SPSS Inc., Chicago, IL,
USA, 2009.
[35] MATLAB, Version 7.11.1 ed., The MathWorks Inc., Natick, MA, USA,
2010.
[36] D. A. Rajon, D. W. Jokisch, P. W. Patton, A. P. Shah, C. J. Watchman, and
W. E. Bolch, “Voxel effects within digital images of trabecular bone and
their consequences on chord-length distribution measurements,” Phys.
Med. Biol., vol. 47, pp. 1741–1759, 2002.

Authors’ photographs and biographies not available at the time of publication.

