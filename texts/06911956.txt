IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

1451

Segmentation of Tumor and Edema Along
With Healthy Tissues of Brain Using Wavelets
and Neural Networks
Ayşe Demirhan, Mustafa Törü, and İnan Güler

Abstract—Robust brain magnetic resonance (MR) segmentation
algorithms are critical to analyze tissues and diagnose tumor and
edema in a quantitative way. In this study, we present a new tissue segmentation algorithm that segments brain MR images into
tumor, edema, white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF). The detection of the healthy tissues is performed simultaneously with the diseased tissues because examining
the change caused by the spread of tumor and edema on healthy
tissues is very important for treatment planning. We used T1, T2,
and FLAIR MR images of 20 subjects suffering from glial tumor. We developed an algorithm for stripping the skull before the
segmentation process. The segmentation is performed using selforganizing map (SOM) that is trained with unsupervised learning
algorithm and fine-tuned with learning vector quantization (LVQ).
Unlike other studies, we developed an algorithm for clustering the
SOM instead of using an additional network. Input feature vector
is constructed with the features obtained from stationary wavelet
transform (SWT) coefficients. The results showed that average dice
similarity indexes are 91% for WM, 87% for GM, 96% for CSF,
61% for tumor, and 77% for edema.
Index Terms—Brain magnetic resonance (MR), image segmentation, learning vector quantization (LVQ), self-organizing feature
map, stationary wavelet transform (SWT).

I. INTRODUCTION
RAIN magnetic resonance (MR) image segmentation is
a very important and challenging task that is needed for
the purpose of diagnosing brain tumors and other neurological
diseases. Brain tumors have different characteristics such as
size, shape, location, and image intensities. They may deform
neighboring structures and if there is edema with the tumor,
intensity properties of the nearby region change. In adults, the
most common and cancer-causing tumor type is glial tumors that
have a high mortality rate. Over 90% of all tumors in persons
over 20 years are glial tumors [1]. They occur in the glial cells of
the brain and show a rapid growth by extending into the healthy
brain tissues.
Image segmentation is the separation of an image into segments called classes or subsets, according to one or more charac-

B

Manuscript received March 18, 2014; revised July 19, 2014 and September
22, 2014; accepted September 24, 2014. Date of publication September 26,
2014; date of current version July 23, 2015.
A. Demirhan and İ. Güler are with the Faculty of Technology, Electronics
and Computer Technology, Gazi University, Ankara 06560, Turkey (e-mail:
ayseoguz@gazi.edu.tr; iguler@gazi.edu.tr).
M. Törü is with the Department of Radiology, 29 Mayıs Hospital, Ankara
06460, Turkey (e-mail: mustafa.toru@29mayis.com.tr).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2360515

teristics or features, and enhancing areas of interest by separating them from the background and other areas [2]. Manual segmentation of brain MR images is a time consuming and tiring
process that can show differences when performed by different experts [3]. Segmentation of 1500–2000, 512 × 512 sized
brain images takes about 2–4 h [4] and brain tumor segmentations show 14%–22% differences when performed by different
experts [3]. Robust computerized segmentation algorithms can
help physicians to analyze and diagnose diseases of the brain by
examining tissues and structures in a quantitative manner. However, segmentation of the tissues of the brain, especially tumor
and edema is a quite difficult task because of the nonhomogeneous intensity distribution, background noise, complex shape,
unclear boundaries, and low intensity contrast between adjacent
brain tissues [5]. In the case of glial tumors, segmentation process is more complicated because of the heterogeneous form of
the tumor that consists necrotic (dead) and active part. The fact
that not all glial tumors have a clear boundary between necrotic
and active parts, and that some may not have any necrotic parts
also complicates segmentation [6].
There have been many different techniques proposed for the
segmentation of brain MR images due to the inherent difficulty of detection and quantification of the brain tissues [6]–
[18]. There are studies that segment brain tissues into three
components as white matter (WM), gray matter (GM), and
cerebrospinal fluid (CSF) [7]–[11]. Although this is useful for
diagnosing many neurological diseases, segmenting pathological regions of brain is crucial in patients with tumor and edema.
Studies that segment only tumor [12]–[17] and tumor and edema
together [6], [18] use patient data with different type of tumors. Various studies [6], [13], [14], [16] performed segmentation on patients with glial tumor. Unlike previous studies that
use wavelets and self-organizing map (SOM), we segmented
both healthy (GM, WM, and CSF) and pathological (tumor and
edema) tissues of the brain on patients with glial tumor in this
study.
Neural networks (NN) perform classification by learning
from data and do not use rule sets. NN can generalize using previous data and learn from past experience. They have
advantages like learning by themselves, tolerancing fault, and
searching for the optimum. They perform well on difficult, multivariate, nonlinear, and noisy domains, such as brain tissue
segmentation, where it becomes more difficult to use decision
trees, or rule-based systems. SOM is one of the most popular
NN that use an unsupervised competitive learning algorithm.
SOM automatically organizes itself according to the input data

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

1452

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

using a similarity factor like Euclidean distance. Topological
relationships of the SOM are conserved in the input and adjacent inputs are mapped to adjacent neurons [19]. Studies that
use SOM needs to cluster the output of the network because it
has more output neurons than the tissue types to be segmented.
Clustering the similar output neurons is usually performed by
using an additional NN that uses weight vectors as input [8],
[9], [13].
Reddick et al. [8] presented a method that uses SOM for
segmentation and a multilayer back propagation NN for classification of the output of the SOM. Their procedure uses T1, T2,
and proton density (PD) MR images to segment healthy brains
in to WM, GM, and CSF. They used seven of their labeled
studies to train and the remaining seven to test the second NN.
Each input vector of the classification network had an associated
manual classification, which corresponded to one of the intracranial tissue or background. Song et al. [9] combined SOM with
weighted probabilistic NN. Their method adopts SOM to overly
segment the T1 and T2 MR images. They estimated fractional
contributions of each reference vector to different target classes
and used the expert-picked training sets to calculate a posteriori probabilities of the reference vectors belonging to each of
the final target classes via Bayesian theorem. Their parametric approach assumes a probability density function (PDF) of
the tissues that lack accuracy and does not match real data distribution. Iftekharuddin et al. [13] used feed-forward NN with
automated Bayesian regularization as the classifier following
the SOM clustering.
Low signal-to-noise ratio or contrast-to-noise ratio decreases
the correct segmentation ratio regardless of the method used
[20]. As a solution to this problem, filtering methods that are
space-invariant like low-pass filtering is applied to the images.
Major drawbacks of the conventional filtering methods are blurring of the object boundaries and important features and suppression of fine structural details in the image, particularly small
lesions [21]. This limitation is resolved by the space-variant filters by using local and feature-dependent techniques. Examples
of these filters are local shape-adaptive template filtering, linear
least-squares error filtering, and anisotropic diffusion filtering.
Gerig et al. [20] compared the nonlinear anisotropic diffusion
filter that is proposed by Perona and Malik [22] with a wide
range of filters used to eliminate the random noise of the MR
image. They demonstrated that anisotropic diffusion filter blurs
homogeneous regions, increase the ratio of signal-to-noise and
sharpens the object borders. This filter also diminishes noise and
reduces partial volume effects, thus greatly reducing subsequent
operator-dependent errors in misclassified training points [21].
Accurate segmentation of the images relies on the automated
feature extraction methods that determine the best features to
distinguish different tissues. Wavelet transform is used broadly
in feature extraction for brain MR image segmentation, since
it provides well localization in both spectral and spatial domains [13], [23]. Translation-variant characteristic of discrete
wavelet transform (DWT) is its drawback. This leads it to extract
remarkably different features from the same two images with
only a slight realignment [24]. Stationary wavelet transform
(SWT) [25] is used to overcome this problem by removing the

down-sampling procedure from the DWT and produces an overcomplete representation. Since all the images are decomposed
by SWT and the original image have the same size, SWT coefficients and textural features that are extracted from them can
be used directly for segmentation without a need for projection
[26].
In this study, T1, T2, and FLAIR MR images of 20 patients
with glial tumor are used to segment the brain tissues. Patients
with glial tumor are studied because it is the most common type
of malignant brain tumors. Data of patients are obtained before
they undergo any surgery. Tumor and edema are segmented simultaneously together with WM, GM, and CSF in our study.
Due to the aforementioned advantages, nonlinear anisotropic
diffusion filter is used to eliminate noise. Then images are registered into one coordinate system, because the movement of
the head is a situation frequently encountered during the imaging process. Since our region of interest is the brain tissues,
skull is stripped using a method that utilizes thresholding and
morphological operations. One-level SWT is used to decompose images into subbands. Then spatial filtering methods are
performed to obtain feature vector. SOM is trained using the
unsupervised learning algorithm. In our methodology, there is
no need to use an additional NN for clustering the SOM. We developed an algorithm, based on the hit histograms of the BMUs
of the output neurons for the tissue types to be segmented using the manually labeled image regions. Regions corresponding
to WM, GM, CSF, tumor, and edema for the slice of interest,
where the tumor appears most prominent, in each of the 20 patients are selected manually by the radiology expert. By manual
segmentation, each input vector had an associated manual classification, which corresponded to one of the intracranial tissue.
The proposed algorithm utilizes the neighborhood relations of
the topology of the SOM. Following the unsupervised learning,
we used supervised learning vector quantization (LVQ) algorithm to tune the output neurons of the network by finding their
best position. Results are evaluated with Dice, sensitivity, and
specificity evaluation criteria that measure the overlap of the
manually segmented areas and segmentation results.
The rest of this paper is organized as follows. In Section II,
materials and methods utilized in this study are delineated. Brain
MR image datasets are presented. Employed methods and implementation details with parameters are given in the subsections. Section III is dedicated to computational experiments and
results.
II. MATERIALS AND METHODS
In this section, we give the materials, brain MR image
datasets, and methods used to perform brain MR tissue segmentation algorithm. Flow diagram of the overall algorithm that
covers both training and testing processes are given in Fig. 1.
The implementation details of the steps of the algorithm are
discussed in the following sections.
A. Brain MR Images
We worked with a dataset of 20 patients that have glial brain
tumors and have not gone under any surgery. The data were

DEMIRHAN et al.: SEGMENTATION OF TUMOR AND EDEMA ALONG WITH HEALTHY TISSUES OF BRAIN

Fig. 1.

1453

Flow diagram of the segmentation algorithm.
Fig. 2. From left to right T1, T2, and FLAIR MR images of the training
(a) A4, (b) A6, (c) A10 and test patients, (d) B3, (e) B6, and (f) B7.

acquired from the medical image database in the Department
of Radiology of the 29 Mayıs Hospital in Ankara, Turkey. The
entire database of the department was searched for brain MR
images with a report of tumor. Then the set was reduced to only
glial tumors. We used the T1 weighted (TR/TE: 1860/20), T2
weighted (TR/TE: 5750/130), and FLAIR (TR/TE: 8800/130)
MR sequences acquired on a 1.5 T General Electric MR machine. Contrast-enhanced T1 MR sequences are not used in this
study because some of the tumors were enhanced by contrast
whereas others do not. The total number of slices for all channels
were 20, field of view of 240 mm, slice thickness of 7.0 mm,
interslice gap of 1.5 mm, voxel resolution of 0.5 × 0.5 × 5.5
mm3 , and acquisition matrix size of 480 × 480. All the images
are 16 bits depth and 512 × 512 pixels size. The dataset is randomly divided into two sets as training and testing data. The slice
of interest in each of the 20 patients for all channels is picked
to be the one that the tumor appears most prominent. Sample
areas for WM, GM, CSF, tumor, and edema are selected and
labeled manually. Fig. 2 shows the training (a)–(c) and test (d)–
(f) patients used in this study. All images are selected randomly.
Variability of the used dataset can be seen from the figure.
B. Preprocessing
We normalized the intensity range of the images to [0 1]
range by dividing all intensity values to the maximum intensity value. To improve the signal-to-noise ratio, we applied

anisotropic diffusion filter to the images as a preprocessing step.
This powerful filter is defined as a diffusion process [22]. Inner
parts of the regions are smoothed and edges are preserved by
estimating local image structure and using edge strengths and
the noise degradation statistics [20]. Images of all patients are
registered to the same coordinate system. T1 weighted MR image is chosen as the reference image, and we have registered
the other channels on it within subjects using a robust affine
registration [27], [28].
C. Skull Stripping
Skull stripping, also known as whole brain segmentation,
is an important step to remove the noncerebral tissue such as
skin, skull, fat, muscle, and connective tissues, which are not
regions of interest in this study. We developed an algorithm that
combines thresholding and morphological operations using T1
weighted MR images. Stages of skull stripping algorithm are
given in Fig. 3.
D. Feature Extraction
We utilized SWT to extract features from the MR images
that will be used as input to the NN. SWT is invariant to translation. SWT coefficients will not change even if the signal is
shifted [24], [25]. In traditional wavelet transform, downsampling, and convolution with a filter is applied to the signal for

1454

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

deviation, and standard deviation as textural features by sliding
a 3 × 3 filter on the first-level wavelet approximation coefficients obtained using Daubechies (db2) wavelet for each slice
of interest. Sliding window size is chosen small to capture details and small lesions in the figure. Mean absolute deviation
is an energy measure that represents the regularity of the textures. Entropy is a measure of the randominity of the texture,
whereas energy specifies whether the texture is broader, finer, or
coarser. Entropy and energy can distinguish nonhomogeneous
and homogeneous areas. Standard deviation shows the average
contrast [26]. We normalized the feature vector before using it
as input to the SOM.
We have tried Haar, Symlet, and Coiflet wavelets for feature extraction along with the Daubachies wavelets. Daubechies
wavelets (db2) showed better performance than Symlet and
Coiflet wavelets for all tissue types. Results for db2 and Haar
were similar, but similarity indices obtained for edema using
db2 were higher than Haar.
E. SOM and LVQ
Fig. 3.

Stages of the skull stripping algorithm.

decomposition. Decomposed signal is 1/2n size, where n indicates the level of decomposition. 2n pixels in the original signal
is represented by a pixel in the decomposed signal. Therefore,
wavelet coefficients cannot be used for pixel-based segmentation without projection [29]. SWT has a fast iterative algorithm
and uses an overcomplete decomposition that constitutes a tight
frame. Decomposition filter is upsampled using (1) and convolved with the signal using (2) to obtain the coefficients of the
subsequent level, unlike the traditional wavelet transform that
downsamples the signal for decomposition of each level. [.]↑m
indicates the upsampling by a factor of m. For each iteration,
filters hi and gi are dilated by a factor of 2, by inserting proper
number of zero between filter taps
hi+1 (k) = [h]↑2 i
gi+1 (k) = [g]↑2 i

∗
∗

hi (k)
gi (k)


si+1 (k) = hi+1 (k) ∗ si (k) 
,
di+1 (k) = gi+1 (k) ∗ si (k) 

(1)
i = 0, 1, ..., I. (2)

The complexity of this algorithm is proportional to the number of samples, and it is the same for all iterations. Size of the
SWT decomposition coefficients obtained at any level is the
same with the original signal. Decomposition coefficients contain information about the middle frequencies. This information
is very useful for image segmentation [25], [26], [29].
Wavelet coefficients are useful for representing the characteristics of different frequency channels but insufficient in representing textural features alone, since local statistical information
is absent. To define the tissues, which have similar secondorder statistics and brightness, nonlinear spatial filtering techniques are applied to the wavelet coefficients. We exploited four
statistical parameters such as energy, entropy, mean absolute

We used SOM as the segmentation tool in this study. We
trained SOM to map the input image to the corresponding tissue
regions according to their characteristic features by considering
their natural grouping in the input space. This mapping reduces
the dimension and groups similar regions together that help to
understand high dimensional image data. SOM has two layers.
There are input nodes in the first layer and output nodes in the
second layer. Output nodes are in a form of two-dimensional
grid. There are adjustable weights between each and every output. A multidimensional observation, i.e., a feature vector, is
associated with each unit. The map attempts to represent features with optimal accuracy using a restricted set of clusters. At
the end of training process, the clusters become ordered on the
grid so that similar clusters are close to and dissimilar clusters
are far from each other. SOM clusters the data by having output
units compete for the current input feature vector during training. The unit closest to the input becomes the winning unit or
best matching unit (BMU) and weight vectors of this unit and its
neighbors are updated. Weight vector adjustment is calculated
by using
mi (t + 1) = mi (t) + hci (t).(x(t) − mi (t))

(3)

where x(t) is the input presented to the SOM and mi (t) is the
weight vector for the unit i. The hci (t) is a symmetric and
monotonically decreasing neighborhood function that specifies
how much the BMU signified by the subscript c and its neighbors
is updated [19].
We used hexagonal lattice with random initialization and unsupervised sequential training algorithm with Gaussian neighborhood function for training. We determined the number of map
units by a heuristic formula of 5 × data_length0.54321 [30]. We
clustered the images into five regions corresponding to WM,
GM, CSF, tumor, and edema. These clusters are then labeled
using the manually selected image regions. We developed an
algorithm for this purpose as depicted in Fig. 4.

DEMIRHAN et al.: SEGMENTATION OF TUMOR AND EDEMA ALONG WITH HEALTHY TISSUES OF BRAIN

1455

TABLE I
COMPARISON OF THE SKULL STRIPPING ALGORITHMS

Jaccard
Sensitivity
Specificity

Fig. 4.

SOM labeling algorithm.

We used supervised LVQ algorithm that uses labeled data for
fine-tuning the weight vectors of the trained and labeled SOM.
Best placement of the neurons for the problem is provided by
this process. The purpose of LVQ is to define class regions in
the input space by placing similarly labeled codebook vectors
into classes even if there is an overlap of class distributions
of the input samples at the class borders. It is recommended
to start learning with the LVQ1 algorithm, which converges
very fast, and continue with the LVQ3 algorithm using a low
initial value of learning to improve recognition accuracy [19].
Consequently, we used LVQ3 following the LVQ1 with running
length of 1000 and learning rate of 0.5. We used 0.2 for window
width parameter and 0.3 for relative learning parameter in LVQ3
algorithm.
F. Evaluation Method
Quality of imaging, difficulty of brain structures, and the
necessity of accurate segmentation make it difficult to qualifying the performance of the segmentation algorithms of brain
[26]. We used Dice similarity index, which is a region-based
coefficient that measures spatial overlap of ground truth (manual segmentation) and segmentation result [31], sensitivity, and
specificity to evaluate the results. Let TP be true positive, FN
be false negative, FP be false positive, and TN be true negative. Dice coefficient is calculated as (2∗ TP)/((2∗ TP) + FP +
FN). The sensitivity is TP/(TP + FN) and the specificity is TN/
(FN + TN).
III. RESULTS AND DISCUSSION
We give comparison of the developed algorithm to the other
methods and quantitative and qualitative experimental results
obtained from the system in this section.
Skull stripping algorithm developed in this study is compared to the well-known algorithms Brain Surface Extractor
(BSE) [32], Brain Extraction Tool (BET) [33], BET2, BrainVisa
[34], and FreeSurfer [35] according to Jaccard similarity index,

BSE

BET

BET2

BrainVisa

FreeSurfer

Developed
Algorithm

0.93
–
–

0.71
–
–

0.92
0.99
0.99

0.82
0.83
0.99

0.90
1.00
0.99

0.93
0.99
0.99

sensitivity, and specificity [36], [37]. Because the other studies give their results in Jaccard index, performance comparison
results are given as Jaccard index. All methods are evaluated
based on their performance on IBSR database [38] that contains
both T1-weighted MR images and their manual segmentations.
In Table I, performance of the developed algorithm is compared
to the other algorithms for 63 T1-weighted MR images of the
patient 205_3, that the results are available in all referenced
studies, of the IBSR database. Scores related to BSE and BET
can be found at [36] and scores related to BET, BrainVisa, and
FreeSurfer can be found at [37]. From the scores in Table I, it
can be seen that that our algorithm performs similar to the BSE,
whereas it outperforms other methods.
We give the Dice coefficient, sensitivity, and specificity performance measures that show the overlap of the automatic and
manual segmentation for the whole dataset in Table II. We denoted training dataset as A and test dataset as B. We used N/E
(not exist) expression for the patients who do not have edema.
It can be seen from Table II that the performance of the system
in segmenting the WM, GM, and CSF is quite high. In most
cases, we reached 100% segmentation accuracy for CSF. Mean
segmentation accuracies of the WM and GM are 91% and 87%,
respectively. We reached 77% true segmentation ratio for edema
and 61% for the tumor. The reasons of that segmenting the tumor
is a more challenging task are as follows:
1) Segmented tumor-type, glial tumors are very heterogeneous in nature and includes different types of regions
such as necrotic (dead or decaying) and active
2) There is no clear border between the necrotic and active
regions and some tumors contain necrotic areas whereas
other does not.
3) There are exceptional features of our comparatively large
dataset that our system does not capture entirely, such as
some tumors appear like edema or CSF when its protein
and blood content is high.
We give the visual results of each processing step for the
selected slice of interest, which shows the tumor and edema
most clearly for the patient A2 in Fig. 5. Fig. 5 (a)–(c) shows
the T1, T2, and FLAIR MR images and (d)–(f) is the skull
stripped versions of the images. Fig. 5(g)–(i) represents the
anisotropic diffusion filter applied images. Fig. 5(j) shows the
manually segmented sample areas, whereas Fig. 5(k) and (l)
shows the segmented images in grayscale and color. Tissue areas
are specified by arrows placed in the figure. In the segmented
image, we use blue to represent WM, turquoise for GM, yellow
for CSF, orange for edema, and dark red for tumor. These colors
are selected arbitrarily.

1456

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

TABLE II
MEASURES OF OVERLAP FOR THE SEGMENTED TISSUES AND THEIR MANUAL LABELING
Patient

WM Accuracy (%)
Dice
Sens.
Spec.

GM Accuracy (%)
Dice
Sens.
Spec.

CSF Accuracy (%)
Dice
Sens.
Spec.

Edema Accuracy (%)
Dice
Sens.
Spec.

Tumor Accuracy (%)
Dice
Sens.
Spec.

A1
A2
A3
A4
A5
A6
A7
A8
A9
A10

87.07
82.79
88.19
95.24
84.67
76.99
96.76
75.48
76.23
99.90

99.00
93.80
97.80
100
100
71.60
98.40
78.20
99.40
99.80

92.90
91.80
92
97.50
87.93
96.40
98.33
90.33
84.65
100

94.80
86.91
89.04
91.46
74.53
75.67
94.06
67.27
80.69
99.90

94.80
89.60
91
87.80
59.40
82.40
93.40
66.60
93.60
100

98.70
95.85
95.53
98.95
100
91.15
98.27
89.53
90.40
99.95

98.00
87.25
99.60
99.60
100
95.97
95.21
96.99
100
100

98.00
99.20
99.40
100
100
100
91.40
100
100
100

99.50
92.95
99.93
99.80
100
97.90
99.80
97.93
100
100

51.15
75.99
N/E
65.37
N/E
95.36
N/E
N/E
72.88
96.93

48.80
61.40
N/E
77.60
N/E
92.60
N/E
N/E
60.20
94.80

89.50
99.95
N/E
85.05
N/E
99.60
N/E
N/E
98.75
99.80

37.84
78.11
36.72
45.31
51.62
83.06
60.34
59.35
2.54
97.06

34.40
69.60
24.20
36.20
35
80.40
45.80
49.20
1.80
99.20

88.15
97.85
97.47
94.10
99.80
96.70
98
94.47
89.95
98.70

B1
B2
B3
B4
B5
B6
B7
B8
B9
B10
Average

93.55
84.40
98.62
96.13
95.60
96.62
98.23
96.15
96.38
97.55
90.83

100
86.00
99.80
99.40
100
100
99.80
99.80
98.40
99.40
96.03

96.55
95.55
99.13
97.53
97.70
98.25
99.15
97.40
98.07
98.53
95.49

93.85
85.25
97.97
83.43
91.18
97.02
98.58
68.16
85.07
94.11
87.45

93.00
95.40
96.40
72
92
97.80
97.40
51.80
75.20
89.40
85.95

98.70
92.90
99.87
99.80
97.55
99.05
99.95
99.93
99.47
99.80
97.27

88.73
99.40
99.70
100
99.90
97.09
68.36
99.70
97.66
99.90
96.15

100
99.20
100
100
100
100
99.80
100
100
100
99.35

93.65
99.90
99.80
100
99.95
98.50
76.95
99.80
98.40
99.93
97.73

92.64
77.49
N/E
N/E
72.51
66.21
83.31
N/E
N/E
N/E
77.26

86.80
65.40
N/E
N/E
89.40
58.00
71.40
N/E
N/E
N/E
73.31

99.85
99.15
N/E
N/E
85.70
95.70
100
N/E
N/E
N/E
95.73

77.85
69.80
91.59
27.14
43.60
63.75
11.49
22.63
79.35
71.50
60.92

68.20
71.20
85
16.81
31
67
7.80
16.20
77.60
56.20
53.51

98.25
91.80
99.80
97.67
97.20
89.20
93
91
94
99.67
95.34

Fig. 5. Segmentation results of each processing step for the patient A2:
(a) T1 weighted, (b) T2 weighted, (c) FLAIR MR images, (d)–(f) skull stripped
MR images, (g)–(i) anisotropic diffusion filter applied images, (j) manually
segmented sample areas, (k) grayscale, and (l) colored automatic segmentation
results.
Fig. 6. Segmentation results obtained from the patients that represent the
different failure modes.

Segmentation results that represent the different failure modes
are given in Fig. 6 in grayscale and color along with the manual
segmentation. Colors used in manual segmentation that represents sample tissue areas are pink for tumor, turquoise for edema,
red for WM, blue for GM, and green for CSF. Patients A7 depicts the case where part of tumor is misclassified as edema. The
reason for this is that tumors resemble edema if their protein or
blood content is extensive. Their T2-weighted signal properties
and intensity values look like each other. Healthy tissues for this

patient are well segmented; segmentation accuracy is very high
especially for CSF. Results for the patient A10, demonstrates a
successful detection of all tissue types by the system. Positions
and sizes of all the tissues are found correctly. Correct segmentation ratio of all tissue types are quite high for the patient B2
whereas some parts of the CSF regions are labeled as tumor.
For the patient B7, tumor area is misclassified as CSF, whereas

DEMIRHAN et al.: SEGMENTATION OF TUMOR AND EDEMA ALONG WITH HEALTHY TISSUES OF BRAIN

TABLE III
PERFORMANCE COMPARISON ON BRATS 2012 TRAINING
AND CHALLENGE DATASET

other methods for BRATS2012 dataset. Results obtained for
complete tumor was higher than core and enhancing tumors.

Training

IV. CONCLUSION

Position

1
2
3
4
5
6
7
8
9
10
11
12
13
14

User

Dice Scores

Darko Zikic
Syed Reza
Nick Tustison
Liang Zhao
Raphael Meier
Andac Hamamci
Stefan Bauer
Nagesh Subbanna
Thomas Taylor
Ayse Demirhan
Hoo-Chang Shin
Roman Niklaus
Flor Vasseur
Javier Juan Albarracin

Complete

Core

Enhancing

0.92
0.92
0.88
0.86
0.82
0.81
0.79
0.78
0.68
0.61
0.46
0.03
0.03
0.02

0.93
0.91
0.76
0.75
0.67
0.69
0.64
0.66
0.62
0.44
0.36
0.03
0.03
0.02

0.63
0.68
0.55
0.55
0.52
0.49
0.49
0.46
0.52
0.27
0.35
0.02
0.02
0.01

Challenge
Position

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

1457

User

Liang Zhao
Wei Yang
Bjoern Menze
Ines Njeh
Nagesh Subbanna
Darko Zikic
Stefan Bauer
Andac Hamamci
Bjoern Menze
Stefan Bauer
Raphael Meier
Ezequiel Geremia
Tammy Riklin Raviv
Ayse Demirhan
Hoo-Chang Shin

Dice Scores
Complete
0.82
0.82
0.78
0.77
0.75
0.75
0.75
0.72
0.69
0.66
0.65
0.62
0.54
0.36
0.30

Core
0.66
0.63
0.58
0.21
0.70
0.47
0.54
0.57
0.33
0.49
0.51
0.32
0.37
0.23
0.17

Enhancing
0.36
0.44
0.40
0.00
0.43
0.41
0.37
0.43
0.39
0.42
0.39
0.31
0.43
0.13
0.04

WM, GM, and edema are segmented correctly. Because this is
a cystic tumor, necrotic areas are evaluated erroneously as CSF.
This common problem for the cystic tumors can be resolved by
combining the prior knowledge to the system. In future work, we
will include additional features such as prior knowledge, shape,
and models to improve accurate and efficient segmentation ratio.
We compared our method with other state-of-the-art brain
segmentation methods using the publicly available BRATS 2012
training and challenge dataset (see Table III) [39]. The training
data consisted of T1, T1c, T2, and FLAIR MR scans of 10
low-grade and 20 high-grade and challenge data consisted of
4 low-grade and 11 high-grade glioma patients. Results are
given in Dice index. Three different segmentation performances
are evaluated; “complete” indicates discrimination performance
of edema, necrosis, nonenhancing tumor, and enhancing tumor
from everything else; “core” shows the performance of segmentation of necrosis, nonenhancing tumor, and enhancing tumor; “enhancing” values indicates segmentation performance
of the enhancing tumor. Our results are highlighted in bold.
Performance results are calculated by using the BRATS online
evaluation tool [39]. Table III shows that our method showed
comparable results for all three segmentation types with the

In this study, we segmented brain MR images into healthy
tissues such as GM, WM, and CSF along with the diseased tissues, tumor, and edema. Twenty patients suffering from the glial
tumor are used. We registered T1, T2, and FLAIR MR images
into one coordinate system after filtering with anisotropic diffusion filter. We developed an algorithm that combines threshold
and morphological operations for stripping the skull that is not
our region of interest in this study. Performance comparison of
the developed algorithm for skull stripping to the well-known
algorithms on IBSR database showed that our algorithm outperforms other methods.
We used SWT to decompose images into subbands. We performed spatial filtering methods on these subbands to obtain
feature vector that will be used as input to the SOM. Segmentation operation is performed by an unsupervised SOM network.
We developed an algorithm, based on the hit histograms of the
BMUs of the output neurons for clustering the SOM instead of
using an additional NN. Supervised LVQ algorithm is used to
calibrate the output neurons of the SOM. We used Dice similarity index, sensitivity and specificity to evaluate the performance
of the developed algorithm. We compared the results obtained
from the system to the regions manually selected by the radiology physician. The statistical analysis of the experimental
results has indicated that the developed algorithm can segment
brain MR images with good accuracy. Our overall procedure can
segment WM, GM, CSF, tumor, and edema from MR images
and requires 20 s for each MR volume. We compared our method
with the other state-of-the-art brain MR segmentation methods
with BRATS2012 dataset. Our method showed a moderate and
comparable performance on this dataset.
Our future work will focus on improving the segmentation
accuracy of the system by using additional features such as prior
knowledge, shape, and models.
REFERENCES
[1] D. D. Langleben and G. M. Segall, “PET in differentiation of recurrent
brain tumor from radiation injury,” J. Nucl. Med., vol. 41, pp. 1861–1867,
2000.
[2] A. Demirhan and İ. Güler, “Image segmentation using self-organizing
maps and gray level co-occurrence matrices,” J. Fac. Eng. Arch. Gazi
Univ., vol. 25, no. 2, pp. 285–291, 2010.
[3] M. Kaus, S. K. Warfield, F. A. Jolesz, and R. Kikinis, “Adaptive template
moderated brain tumor segmentation in MRI,” in Proc. Bildverarbeitung
für die Medizin, 1999, pp. 102–106.
[4] M. Straka, A. L. Cruz, A. Kochl, M. Sramek, M. E. Groller, and
D. Fleischmann, “3D watershed transform combined with a probabilistic
atlas for medical image segmentation,” in Proc. MIT2003, pp. 1–8.
[5] H.-H. Chang, D. J. Valentino, G. R. Duckwiler, and A. W. Toga, “Segmentation of brain MR images using a charged fluid model,” IEEE Trans.
Biomed. Eng., vol. 54, no. 10, pp. 1798–1813, Oct. 2007.
[6] J. J. Corso, E. Sharon, S. Dube, S. El-Saden, U. Sinha, and A. Yuille,
“Efficient multilevel brain tumor segmentation with integrated Bayesian
model classification,” IEEE Trans. Med. Imag., vol. 27, no. 5, pp. 629–640,
May 2008.
[7] J. R. Jiménez-Alaniz, V. Medina-Bañuelos, and O. Yáñez-Suárez, “Datadriven brain MRI segmentation supported on edge confidence and a priori

1458

[8]

[9]

[10]

[11]
[12]

[13]
[14]
[15]
[16]
[17]
[18]
[19]
[20]
[21]

[22]
[23]

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

tissue information,” IEEE Trans. Med. Imag., vol. 25, no. 1, pp. 74–83,
Jan. 2006.
W. E. Reddick, J. O. Glass, E. N. Cook, T. D. Elkin, and R. J. Deaton,
“Automated segmentation and classification of multispectral magnetic
resonance images of brain using artificial neural networks,” IEEE Trans.
Med. Imag., vol. 16, no. 6, pp. 911–918, Dec. 1997.
T. Song, M. M. Jamshidi, R. R. Lee, and M. Huang, “A modified
probabilistic neural network for partial volume segmentation in brain
MR image,” IEEE Trans. Neural Netw., vol. 18, no. 5, pp. 1424–1432,
Sep. 2007.
H. A. Vrooman, C. A. Cocosco, F. Lijn, R. Stokking, M. A. Ikram,
M. W. Vernooij, M. M. B. Breteler, and W. J. Niessen, “Multi-spectral
brain tissue segmentation using automatically trained k-nearest-neighbor
classification,” NeuroImage, vol. 37, pp. 71–81, 2007.
J. Alirezaie, M. E. Jernigan, and C. Nahmias, “Automatic segmentation of
cerebral MR images using artificial neural networks,” IEEE Trans. Nucl.
Sci., vol. 45, no. 4, pp. 2174–2182, Aug. 1998.
S. Ahmed, K. M. Iftekharuddin, and A. Vossough, “Efficacy of texture,
shape, and intensity feature fusion for posterior-fossa tumor segmentation
in MRI,” IEEE Trans. Inf. Technol. Biomed., vol. 15, no. 2, pp. 206–213,
Mar. 2011.
K. M. Iftekharuddin, J. Zheng, M. A. Islam, and R. J. Ogg, “Fractalbased brain tumor detection in multimodal MRI,” Appl. Math. Comput.,
vol. 207, pp. 23–41, 2009.
W. Dou, S. Ruan, Y. Chen, D. Bloyet, and J.-M. Constans, “A framework
of fuzzy information fusion for the segmentation of brain tumor tissues
on MR images,” Image Vision Comput., vol. 25, pp. 164–171, 2007.
N. Zhang, S. Ruan, S. Lebonvallet, Q. Liao, and Y. Zhu, “Kernel feature
selection to fuse multi-spectral MRI images for brain tumor segmentation,”
Computer Vision Image Understanding, vol. 115, pp. 256–269, 2011.
M. R. Kaus, S. K. Warfield, A. Nabavi, P. M. Black, F. A. Jolesz, and
R. Kikinis, “Automated segmentation of MR images of brain tumors,”
Radiology, vol. 218, pp. 586–591, 2001.
H. Khotanlou, “3D brain tumors and internal brain structures segmentation
in MR images,” Ph.D. dissertation, Informatique, Telecommun. Electron.,
Telecom ParisTech, Paris, France, 2008.
M. Prastawa, E. Bullitt, S. Ho, and G. Gerig, “A brain tumor segmentation framework based on outlier detection,” Med. Image Anal., vol. 8,
pp. 275–283, Jul. 2004.
T. Kohonen, The Self-Organizing Maps, 3rd ed. Berlin, Germany:
Springer-Verlag, 2002.
G. Gerig, O. Kubler, R. Kikinis, and F. A. Jolesz, “Nonlinear anisotropic
filtering of MRI data,” IEEE Trans. Med. Imag., vol. 11, no. 2,
pp. 221–232, Jun. 1992.
F. B. Mohamed, S. Vinitski, Scott H. Faro, C. F. Gonzalez, J. Mack, and
T. Iwanaga, “Optimization of tissue segmentation of brain MR images
based on multispectral 3D feature maps,” Magn. Reson. Imag., vol. 17,
no. 3, pp. 403–409, 1999.
P. Perona and J. Malik, “Scale-space and edge detection using anisotropic
diffusion,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 12, no. 7,
pp. 629–639, Jul. 1990.
Z. Zhou and Z. Ruan, “Multicontext wavelet-based thresholding segmentation of brain tissues in magnetic resonance images,” Magn. Reson. Imag.,
vol. 25, pp. 381–385, 2007.

[24] Y. Zhang, Z. Dong, L. Wu, S. Wang, and Z. Zhou, “Feature extraction of
brain MRI by stationary wavelet transform,” in Proc. Int. Conf. Biomed.
Eng. Comput. Sci., Wuhan, China, 2010, pp. 1–4.
[25] M. Unser, “Texture classification and segmentation using wavelet frames,”
IEEE Trans. Image Process., vol. 4, no. 11, pp. 1549–1650, Nov. 1995.
[26] A. Demirhan and İ. Güler, “Combining stationary wavelet transform and
self-organizing maps for brain MR image segmentation,” Eng. Appl. Artif.
Intell., vol. 24, pp. 358–367, 2011.
[27] R. A. Robb, Biomedical Imaging, Visualization and Analysis. Hoboken,
NJ, USA: Wiley, 2000.
[28] D. Rueckert, L. I. Sonoda, C. Hayes, D. L. G. Hill, M. O. Leach, and
D. J. Hawkes, “Nonrigid registration using free-form deformations: Application to breast MR images,” IEEE Trans. Med. Imag., vol. 18, no. 8,
pp. 712–721, Aug. 1999.
[29] S. C. Kim and T. J. Kang, “Texture classification and segmentation using
wavelet packet frame and Gaussian mixture model,” Pattern Recognit.,
vol. 40, pp. 1207–1221, 2007.
[30] E. Alhoniemi, J. Himberg, J. Parhankangas, and J. Vesanta.
(2010). SOM Toolbox for MATLAB [Online]. Available:
http://www.cis.hut.fi/projects/somtoolbox
[31] H.-H. Chang, A. H. Zhuang, D. J. Valentino, and W.-C. Chu, “Performance measure characterization for evaluating neuroimage segmentation
algorithms,” NeuroImage, vol. 47, no. 1, pp. 122–135, 2009.
[32] D. W. Shattuck, S. R. Sandor-Leahy, K. A. Schaper, D. A. Rottenberg,
and R. M. Leahy, “Magnetic resonance image tissue classification using
a partial volume model,” NeuroImage, vol. 13, pp. 856–876, 2001.
[33] S. M. Smith, “Fast robust automated brain extraction,” Hum. Brain. Mapp.,
vol. 17, pp. 143–155, 2002.
[34] Y. Cointepas, J. F. Mangin, L. Garnero, J. B. Poline, and H. Benali, “BrainVISA: Software platform for visualization and analysis of multimodality
brain data,” NeuroImage, vol. 13, no. 6, p. S98, 2001.
[35] D. E. Rex, D. W. Shattuck, R. P. Woods, K. L. Narr, E. Luders, K. Rehm,
S. E. Stoltzner, D. A. Rottenberg, and A. W. Toga, “A meta-algorithm for
brain extraction in MRI,” NeuroImage, vol. 23, pp. 625–637, 2004.
[36] J. G. Park and C. Lee, “Skull stripping based on region growing for
magnetic resonance brain images,” NeuroImage, vol. 47, pp. 1394–1407,
2009.
[37] J. Hwang, Y. Han, and H. Park, “Skull-stripping method for brain MRI
using a 3D level set with a speedup operator,” J. Magn. Reson. Imag.,
vol. 34, pp. 445–456, 2011.
[38] Center for Morphometric Analysis Neuroscience Center, Harvard Medical School. (2009). The Internet Brain Segmentation Repository (IBSR)
[Online]. Available: http://www.cma.mgh.harvard.edu/ibsr.
[39] B. Menze, A. Jakab, S. Bauer, M. Reyes, M. Prastawa, and
K. van Leemput. Challenge on multimodal brain tumor segmentation.
presented at MICCAI 2012 [Online]. Available: http://www.imm.dtu.dk/
projects/BRATS2012

Authors’ photographs and biographies not available at the time of publication.

