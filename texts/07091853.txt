IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

1053

PSF: A Unified Patient Similarity Evaluation
Framework Through Metric Learning
With Weak Supervision
Fei Wang, Member, IEEE, and Jimeng Sun

Abstract—Patient similarity is an important analytic operation
in healthcare applications. At the core, patient similarity takes an
index patient as the input and retrieves a ranked list of similar patients that are relevant in a specific clinical context. It takes patient
information such as their electronic health records as input and
computes the distance between a pair of patients based on those
information. To construct a clinically valid similarity measure,
physician input often needs to be incorporated. However, obtaining
physicians’ input is difficult and expensive. As a result, typically
only limited physician feedbacks can be obtained on a small portion
of patients. How to leverage all unlabeled patient data and limited
supervision information from physicians to construct a clinically
meaningful distance metric? In this paper, we present a patient
similarity framework (PSF) that unifies and significantly extends
existing supervised patient similarity metric learning methods. PSF
is a general framework that can learn an appropriate distance metric through supervised and unsupervised information. Within PSF
framework, we propose a novel patient similarity algorithm that
uses local spline regression to capture the unsupervised information. To speedup the incorporation of physician feedback or newly
available clinical information, we introduce a general online update
algorithm for an existing PSF distance metric.
Index Terms—Health informatics, metric learning, patient
similarity.

I. INTRODUCTION
EALTHCARE has undergone a tremendous growth in
the use of electronic health records (EHR) systems to
capture patient disease and treatment histories. However, these
systems store the data in a manner that makes it difficult for
clinicians to extract what is necessary to make clinical decisions
at the point-of-care [1]. To build an effective clinical decision
support system, we need to quantitatively measure the distance
between two patients in a specific medical context, which is
the core operation behind patient similarity [2], [3]. In general,

H

Manuscript received December 31, 2013; revised May 6, 2014; accepted June
24, 2014. Date of publication April 22, 2015; date of current version May 7,
2015.
F. Wang is with the Department of Computer Science and Engineering, University of Connecticut, Storrs, CT 06269 USA (e-mail: feiwang03@gmail.com).
J. Sun is with the Department of Computer Science and Engineering,
Georgia Institute of Technology, Atlanta, GA 30332 USA (e-mail: jimeng.
sun@gmail.com).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2015.2425365

patient similarity takes an index patient as a query, process the
underlying EHR data of a large number of patients, and return
a ranked list of patients who are similar.
Oftentimes, such patient similarity is context specific, i.e.,
for different diseases, a different patient similarity can/should
be defined. Recently, supervised patient similarity method and
its variations have been studied [4]–[6]. The main assumption
behind these methods is that it is possible to obtain sufficient
physician feedback for a large number of patients. However,
while all patients have EHR data, physician feedback is rare
and expensive to obtain. Often, physician feedback can only
be obtained for a small number of patients, which is considered
weak supervision information. Besides limited supervision from
physician, physician feedback often needs to be incorporated in
an online fashion in order to obtain valid results for the next
queries.
To address these challenges, we propose a general patient
similarity framework (PSF) that unifies all existing supervised
patient similarity measure and extend to broader formulation.
In particular, PSF leverages both unsupervised information (e.g.,
patient features similarity) and supervised information (i.e., limited physician feedback) that can instantiate to different similarity learning methods. Under the PSF framework, we introduce
a novel instantiation that uses local spline regression (LSR) to
model unsupervised information.
In clinical applications, new information such as physician
feedback and new patient or encounter records needs to incorporate in real time quickly. To update the learned patient similarity
efficiently, we introduce a general online update algorithm for
PSF based on matrix perturbation theory.
We use a large clinical dataset that has over 200 K patients over three years and over 12 millions of medical records
(claim, medication and lab combined). We evaluate the proposed
methods in the context of heart failure (HF) diagnosis. PSF variations significantly outperform the supervised patient similarity [4] (over 45% improvement in F-measure). Among all PSF
variations [with principal component analysis (PCA), Laplacian
embedding (LE) and locally linear embedding (LLE)], our proposed PSF using LSR performs the best, which outperforms
the second best PSF with local LE by 10% in F-measure. This
is because PCA explores only the global data structure, which
is inaccurate in the case when data distribution is fairly complicated. LE explores the local structure but the performance
is largely dependent on the choice of the width of the Gaussian kernel when constructing the graph Laplacian as pointed in
[7]. LLE only explores the linear local structure. LSR explores

2168-2194 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

1054

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

nonlinear local structures and thus can get richest information
from the data.
II. PSF
Throughout the paper, we assume a vector-based representation for each patient according to their EHRs [5], [6]. In the
following we will present the detailed algorithmic framework of
PSF, as well as an update algorithm for incrementally adjusting
existing similarity measures.
A. Similarity Assessment
Suppose we have a set of n patients X = {x1 , x2 , · · · , xn },
with xi ∈ RD being the profile vector of the ith patient and
D being the dimensionality of a patient feature vector. The
dissimilarity between xi and xj can be measured by the distance between them. Here we consider how to learn a good
distance measure that reflects the clinical patient similarity.
We assume the learned distance is the Euclidean distance in
some transformed space that the patient profiles are embedded
in. Such embedding can be either linear or nonlinear. We use
F = [f1 , f2 , · · · , fn ] with fi ∈ Rd to represent the embedded patient profile vectors, and usually d  D. As mentioned above,
in the medical scenario, typically we only have small amount of
supervision information provided by the physicians. Therefore,
we propose to learn F by minimizing the following objective:
J (F) = U(F) + λS(F)

(1)

where U(F) is an unsupervised term depends only on patient
feature characteristics, and S(F) is the supervised term derived
from physician feedback. Next we describe the concrete formulations of these terms.
1) Supervised Information: By consulting our medical advisor, we consider the supervision information is in the form of
whether a pair of patients are indeed similar to each other or not
in a given clinical context. Compared with the class label, this
type of supervision is weaker and easier to obtain. Following the
convention of semisupervised clustering, we call the supervision
indicating two patients are similar to each other must-links, and
the supervision indicating two patients are not similar to each
other cannot-links. In the following we will use M and C to
denote the must-link and cannot-link constraint sets. As the distance we learn is the Euclidean distance measured on F, we
construct S(F) by


fi − fj 2 − λC /|C|
fu − fv 2
S(F) = λM /|M|
(x i ,x j )∈M

(x u ,x v )∈C

(2)
where λM > 0 and λC > 0 are the reward and penalty for mustlink and cannot-link constraints, and | · | indicates the cardinality
of a set. We can further derive that

fi − fj 2 = tr(F MM F)
(3)
(x i ,x j )∈M



(x u ,x v )∈C

fu − fv 2 = tr(F MC F)

(4)

where MM ∈ Rn ×n with its (i, j)th entry
MM (i, j) =
⎧
−1, if i = j, (xi , xj ) ∈ M
⎪
⎨
ni , if i = j and xi appears in the constraints in M (5)
⎪
⎩
0, otherwise
where ni represents the number of times that xi appeared in the
patient pairs in M. MC ∈ Rn ×n with its (u, v)th entry
MC (u, v) =
⎧
−1, if u = v, (xu , xv ) ∈ C
⎪
⎨
nu , if u = v and xu appears in the constraints in C (6)
⎪
⎩
0, otherwise
where nu represents the number of times that xu appeared in
the patient pairs in C. Therefore S(F) becomes


(7)
S(F) = tr F SF
where
S = (λM /|M|)MM − (λC /|C|)MC .

(8)

Therefore the construction of S(F) is only related to the patients in M and C. Efficient algorithms for supervised patient
similarity have been proposed in [4]–[6]. However, the number
of such patients is usually small because it is expensive and time
consuming to obtain physician feedback. This is why we need
the unsupervised term U(F) as well.
2) Unsupervised Information: The goal is to utilize all unsupervised feature information, so that patients with similar
features are close to each other. Such intuition of U(F) can
be captured in many different ways. Some examples of U(F)
include:
1) PCA, which aims to maximize the data variance in the
embedded space and the corresponding U(F) is



fi − fj 2 = − tr F UPCA F
U(F) = − (1/n2 )
ij

(9)
where
UPCA = (1/n2 )(nI − ee )

(10)

and I ∈ Rn ×n is an identity matrix, and e ∈ Rn ×1 is an
all-one vector. In PCA, the embedding is linear with fi =
W xi , where W ∈ RD ×d is the projection matrix and n
is the number of patients.
2) LE [8], which aims at preserving the locality of the pairwise data relationships and the corresponding U(F) is



U(F) = (1/n2 )
ωij fi − fj 2 = tr F ULE F
ij

(11)
where ωij captures the local relationship between xi and
xj and
ULE = (1/n2 )(D − Ω)

(12)

FEI WANG AND SUN: PSF: UNIFIED PATIENT SIMILARITY EVALUATION FRAMEWORK THROUGH METRIC LEARNING WITH WEAK

where Ω ∈ Rn ×n is the data similarity matrix with its
(i, j)th entry equal to ωij , and D ∈ Rn ×n is a diagonal
matrix
with the ith element on its diagonal line equal to
	
ω
.
ij
j
3) LLE [9] [7], which is based on a linear neighborhood assumption that each data point can be linearly reconstructed
by its neighborhood points, thus U(F) is constructed by



2









 



γij fj 

U(F) = (1/n)

fi −

 = tr F ULLE F


i 

j :x j ∈Ni
(13)
where Ni is the neighborhood of xi and


ULLE = (1/n)((I − Γ) (I − Γ))

(14)

n ×n

where Γ ∈ R
is the local relationship matrix with its
(i, j)the entry equal to γij if xj ∈ Ni , and 0 otherwise.
The value of γij is obtained by solving the following
optimization problem:



2













x
−
γ
x
(15)
min
i
ij j 
 .
	


γ i j : j γ i j =1


i 

j :x j ∈Ni
4) LSR. This approach assumes that the embedded coordinate on the qth dimension for the data points in Ni can be
obtained by
fiqk = giq (xi k )

(16)

where xi k be the kth profile vector in neighborhood Ni ,
fi k = [fi1k , fi2k , · · · , firk ] be the intrinsic coordinates of
xi k , and giq can be obtained by minimizing the following
objective:
|Ni |

 q
2
q
fi k − giq (xi k ) + λRds (giq )
J (gi ) =

where matrix G = U + λS, U ∈ Rn ×n can be UPCA , ULap ,
ULLE , ULSR , λ > 0 is the tradeoff parameter, and S is the
supervised information matrix from (8).
According to the Ky Fan theorem [13], the optimal solution
to problem (20) can be obtained by performing eigenvalue decomposition to matrix G, such that the qth column of F is the
eigenvector of A whose corresponding eigenvalue is the qth
smallest. The optimal value of tr(F GF) should be the sum of
the smallest m eigenvalues. This means that the optimal value of
d (i.e., the dimensionality of the embeding space) is the number
of negative eigenvalues of G.
B. Patient Similarity Metric Update
So far, we present a general framework PSF to guide the development of different kind of patient similarity metrics. Next
we want to derive an online updating algorithmic framework
by incorporating incoming changes sequentially. The incoming
changes can be: 1) new supervised information such as physician feedback or 2) new unsupervised information such as new
patients or new encounter records. Next we introduce an update
algorithm that is based on matrix perturbation theory [14] to
achieve such a goal.
Suppose at time t we have matrix G, at time t + Δt changes
 = G + ΔG, then our problem
are incorporated so we have G
 given the
is how to efficiently obtain the eigensystem of G
eigensystem of G?
Let (μi , fi ) be one eigenvalue-eigenvector pair of matrix G,
and (
μi , 
fi ) be the corresponding eigenvalue-eigenvector pair of

G, then the matrix perturbation theory assumes
μ
i = μi + Δμi , 
fi = fi + Δfi .

(17)

where the detailed procedure of constructing ULSR can
be referred to [12].
3) Optimization: We can observe from the above examples
that generally U(F) takes the form


U(F) = tr F UF .
(19)
After J (F) is constructed, we can solve the following optimization problem to obtain the F matrix:
min J (F)

F  F=I

Δμi = fi ΔGf i .

(23)

This is the first order eigenvalue perturbation updating equation.
For eigenvector updating, we first assume
Δfi ≈

m


αij fj .

(24)

μk αik + fk ΔGf i = μi αik .

(25)

j =1

Then we can get
∀k = i,
Therefore
∀k = i,

αik =

fk ΔGf i
.
μi − μk

(26)

In order to get αii , we use the fact that

fi
fi = 1 ⇒ (fi + Δfi ) (fi + Δfi ) = 1
⇒ 1 + fi Δfi + O(Δfi 2 ) = 1 ⇒ αii = 0. (27)

(20)

where we add the constraint F F = I to avoid degenerated
solutions. J (F) can further be rewritten as


J (F) = tr F GF
(21)

(22)

By dropping the second order perturbation terms we can obtain
[6]

k =1

where λ > 0 is the regularization parameter, |Ni | is the
cardinality of Ni , and Rds (giq ) is a smoothness penalty on
d
[10], [11]. It can be derived that the total loss
giq in R	
1
J = n iq J (giq ) can be approximated by


(18)
U(F) = (1/n)tr F ULSR F

1055

Hence
Δfi =

 f  ΔGf i
k

k = i

μi − μk

fk .

(28)

1056

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

TABLE I
DATASET INFORMATION
Category
Diagnosis
Medication
Lab

Descriptions

Cardinality

ICD-9 codes
Medicine ingredients
All lab tests

10 379
1158
207

III. EXPERIMENTS
In this section we present the details of our experiments on
a real world dataset to demonstrate the effectiveness of the
PSF. We implemented PSF in MATLAB and we provided the
source code of PSF with LSR in https://sites.google.com/site/
feiwang03/services/PSF_LSR.m?attredirects=0&d=1.

Fig. 1.

Illustration of the case/control design.
TABLE II
PATIENT EVALUATION CATEGORIES

Retrieved
Nonretrieved

Relevant

Irrelevant

True Positives (TP)
False Negatives (FN)

False Positives (FP)
True Negatives (TN)

A. Dataset Description
The dataset we used for evaluating the performance of PSF
is collected from a real world medical group, which contains three-year longitudinal electronic medical records of over
208 K patients. There are over four million claim records, close
to four million lab test records, and over five million pharmacy
records. The patient features we used in our investigation are
categorized into three groups as shown in Table I. The patient
features are represented as three feature matrices by counting the
frequency of every individual feature, one for each type. Similar
to text processing [15], we also perform TF-IDF normalization
on each feature matrix.
We selected HF [16] as our target disease for conducting experimental evaluation. In our experimental design of early detection of HF, we followed the conventions used in prior work
[16] to define the case (the patients with confirmed HF diagnosis) and control patients (the patients without HF). A patient is
considered to have a confirmed HF diagnosis if he/she has at
least two ICD-9 codes associated with HF, and the HF diagnosis
date is defined as the date of the earliest HF diagnosis. We only
included patients aged 50–79 at the beginning of the three year
period. The prediction period is set to be six months, i.e., we
want to predict whether or not the patient will be diagnosed
as HF six months later based on the patient historical record.
The duration of the patient historical record, or the length of the
training period, is set to be one year. This means, for the selection of HF cases, we required the dataset to contain at least one
record 18 months before the HF diagnosis date. For selection
of controls, we first select the patients without any HF related
diagnosis, and we further required that the patient records span a
time duration of at least 18 months in our dataset. To ensure we
had complete records of patients for the duration of the experiment period, we also require the controls to be diagnosed with
at least one non-HF diagnosis code 18 months before their last
record date. Fig. 1 shows a graphical illustration of the case and
control definitions. Using these definitions, we obtained 344 HF
cases, 3602 controls.
Before we conducted the experiments, we asked our medical
advisor to identify the features that are most relevant with the

HF disease, from which we got a total of 127 features including
86 ICD9 codes, 27 lab tests and 14 medications.

B. Experiment Setting and Evaluation Metric
We examined the performance of the PSF system by first
selecting a query patient, and then look at the quality of the retrieved similar patients (according to the learned distance metric) by checking whether the similar patients belong to the same
group (HF versus non-HF) as the query patient. Under this
setting, we used precision, recall, accuracy and F-measure for
evaluation.
Before computing the evaluation metrics, we first construct a
contingency table shown in Table II according to the labels of
the retrieved and the query patients, where relevant means the
retrieved patient has the same label as the query patient, otherwise the retrieved patient is irrelevant. Then we adopt precision,
recall, accuracy and F-measure to evaluate the performance of
PSF. We randomly pick a case patient as the query patient, and
retrieve the K most similar patients from the database using the
learned distance metric. Finally we repeat this procedure 100
times independently and report the averaged evaluation metric
values as well as standard deviations.
For comparison purpose, we implemented the following
instantiations of PSF. Note that in all of them, the supervised method is based on locally supervised metric learning
(LSML) [4].
1) PSF(PCA). Using PCA style U(F) as introduced in Section II-A. This is equivalent to the implementation of the
Constraint Margin Maximization algorithm in [17].
2) PSF(Laplacian). Using Laplacian style U(F) as introduced in Section II-A. This is equivalent to the implementation of the Laplacian regularized metric learning
algorithm in [18].
3) PSF(LLE). Using LLE style U(F) in Section II-A.
4) PSF(LSR). Using LSR style U(F) in Section II-A.

FEI WANG AND SUN: PSF: UNIFIED PATIENT SIMILARITY EVALUATION FRAMEWORK THROUGH METRIC LEARNING WITH WEAK

1057

TABLE III
PERFORMANCE COMPARISON OF DIFFERENT METHODS

PSF(LSR)
PSF(LLE)
PSF(Laplacian)
PSF(PCA)
LSML

Precision

Recall

Accuracy

F-measure

0.6728 ±0.0153
0.6013±0.0186
0.5587± 0.0158
0.4870 ±0.0208
0.4608±0.0215

0.4670±0.0162
0.4270± 0.0205
0.3879±0.0176
0.3485± 0.0166
0.3297 ±0.0182

0.9379 ± 0.0134
0.9248± 0.0182
0.9046 ±0.0188
0.9177± 0.0160
0.9178±0.0167

0.5396±0.0180
0.4780± 0.0201
0.4320±0.0170
0.3897± 0.0189
0.3758 ±0.0212

5) LSML. This one only uses supervised information, and
no unsupervised information.The approach is described
in [4], which is served as the baseline method.
C. Results on Similarity Assessment
1) Effect of Unsupervised Information: We first tested the
performance of those various algorithms on patient similarity
assessment. In the first set of experiments, we compare the algorithm performance with fixed parameter settings. The number
of retrieved patients is set to 200 for all methods. We also randomly pick ten patients from the patient set and use their label
to derive the must-link set M and cannot-link set C, which will
be used for all methods. λM = λC = 1. For PSF(LSR), we use
the second order polynomial splines, and the neighborhood size
is set to ten. For PSF(LLE), the neighborhood size is set to ten
as well. For PSF(Laplacian), we use the ten-nearest neighborhood graph to construct the Laplacian and use the local scaling
method [19] to compute the width of the Gaussian weights. For
LSML, the size of the homogeneous and heterogeneous neighborhoods are set to ten. For all those methods, we embedded the
data in ten-dimensional space.
The experimental results are shown in Table III, where the
values are averaged from 100 independent runs. From the table
we can clearly observe: 1) The PSF based methods clearly outperform pure supervised method LSML, thanks to the unsupervised information. 2) Our proposed PSF(LSR) algorithm clearly
outperforms other PSF based methods and LSML baseline. The
performance gain given by PSF(LSR) is over 10% in terms of
F-measure compared to the second best method and over 40%
improvement over supervised baseline LSML. 3) The nonlinear
embedding methods [PSF(LSR), PSF(LLE), PSF(Laplacian)]
outperform linear embedding methods [PSF(PCA)], which suggests the manifold of patient feature vectors is nonlinear. 4) The
local learning methods [PSF(LSR), PSF(LLE), PSF(Laplacian)]
perform better than global learning methods [PSF(PCA)].
2) Effect of Parameters: In the second set of experiments,
we tested how the performance measures of the algorithms PSF(LSR), PSF(LLE), PSF(Laplacian), PSF(PCA), and LSML
- vary with respect to the embedded dimensionality d, which
changes from 2 to 100. The results are shown in Fig. 2, which
includes the performance curve averaged over 100 independent
runs along with their standard deviations. From the figure we can
observe that: 1) With the increase of the dimensionality of the
embedding space, the performance of those algorithms become
better. 2) We can observe a clear elbow point on each curve at
the dimensionality of around 20, which suggests the intrinsic

Fig. 2. Variation of the algorithm performance (y-axis) with respect to the
dimensionality (x-axis). All curves are averaged over 100 independent runs.
The standard deviations are provided as well. From the figure we can see that
with the increase on the feature dimensions, the algorithm performance will also
increase and become saturated at some certain point. (a) Precision. (b) Recall.
(c) Accuracy. (d) F-measure.

dimensionality of the patient profile manifold. 3) PSF(LSR)
still performs the best among all methods in all settings, which
confirms its superiority and robustness.
In the third set of experiments, we tested how the algorithm
performance varies with respect to the size of the retrieved list,
which varies from 50 to 500. The dimensionality of the embedding space is set to 20 in this case. The results are demonstrated
in Fig. 3, which includes the performance curve averaged over
100 independent runs along with their standard deviations. This
figure demonstrates that: 1) Most of the relevant patients are
within the top 200 retrieved patient list, that’s why there are
drops on the recall and F-measure curves after the size 200.
2) No matter how large the retrieved patient list is, PSF(LSR)
always performs better than other competitors.
3) Experiments on PSF(LSR): Next, we picked the best performer, PSF(LSR) to test its parameter sensitivity, including the
size of the local neighborhood and the degree of the polynomial
spline, where the final dimensionality of the embedding space
is set to ten and the size of the retrieved patient list is set to 200.
Fig. 4 shows the results of PSF(LSR) performance versus local neighborhood size summarized from 100 independent runs.
From these curves we can observe a trend that after size 20, if
the neighborhood size is still increasing, the performance will
decrease. This is because the manifold that the patient profile
vectors reside on is highly nonlinear with many twists and turns.
When applying the local learning based methods, we are actually making use of the concatenation of those local neighborhood patches to approximate the complex nonlinear manifold.
Therefore, if the size of the neighborhood is set to be too large,
the neighborhood patch will not be attached to the surface of the
manifold, but rather confuse the regions with high curvatures.
Consequently this will deteriorate the algorithm performance as
the intrinsic coordinates cannot be properly learned.
Fig. 5 illustrates the results of PSF(LSR) performance versus
the degree of the local polynomial splines summarized from 100

1058

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

Fig. 3. Variation of the algorithm performance (y-axis) with respect to the
size of the retrieved patient list (x-axis). All curves are also summarized over
100 independent runs. (a) shows the curve of precision, so the x-axis is the value
of the denominator. Larger denominator will always cause small value. If the
similar patients are ranked top in the list, there will always be certainly a peak
precision. (b) shows the curve of recall value, where the denominator is the
actual number of relevant patients, which is a constant that will not change. So
with the increase on the size of the retrieved patient list, the nominator of recall
will increase (because more relevant patients can be found) but the denominator
never change, thus the recall value will increase monotonically. (c) shows the
curve of accuracy, which is evaluated on both retrieved and nonretrieved patients,
thus with the increase on the size of the retrieved list there could be a value peak.
(d) shows the curve of F-measure, which is some combination of precision and
recall, thus we can observe on those F-measure curves there are some tradeoffs
on the precision and recall curves.

Fig. 4. Variation of the algorithm performance (y-axis) with respect to the
size of the local neighborhood (x-axis). (a) Precision. (b) Recall. (c) Accuracy.
(d) F-measure.

independent runs. From the figure we can see that the algorithm
performance increases with the increasing on the polynomial
degree. After degree 2, the algorithm performance improves
slowly. This suggests that overfitting may occur. Therefore, in
order to guarantee good generalization ability of the algorithm,
adopting the second order polynomial splines is enough.

Fig. 5. Variation of the algorithm performance (y-axis) with respect to the
degree of the local polynomial splines (x-axis). (a) Precision. (b) Recall. (c)
Accuracy. (d) F-measure.

D. Effectiveness of Physician Feedback
We also designed a set of experiments to examine the effectiveness of the PSF framework when different amount of
supervised expert feedbacks are provided. As introduced in Section II-B, we have the following two different settings.
1) Batch Mode. We collect all experts’ feedback in one batch
and then apply our algorithm to update the patient similarity metric.
2) Sequential Mode. We collect experts’ feedback round by
round. The patient similarity metric will be updated after
each round.
We simulated the experts’ feedback by checking the patient
labels in the retrieved list, i.e., we randomly picked a number
of retrieved patients and add them along with the query patient into the similar/dissimilar patient sets S and D. For batch
mode experiments, we picked ten to 150 patients from the retrieved list and use their class label as feedback information.
For sequential mode experiments, we simulated ten consecutive rounds of feedbacks, at each round we randomly pick ten
similar patients from the retrieved list and use their labels as
feedback. Fig. 6 shows the results on batch mode experiments,
from which we can see that with the increasing on the number
of feedback rounds, the algorithm performance boosts. Similar
phenomenon can be observed from Fig. 7, which illustrates the
results of sequential mode experiments demonstrating that with
the algorithm performance improves with the increasing on the
number of feedback rounds. The curves in both figures are averaged from 100 independent runs. This validates the effectiveness
of the proposed perturbation-based algorithm.
E. Results on Disease Prognosis
We also designed a set of experiments to test the performance
using PSF on disease prognosis. The goal is to predict whether
a patient will be diagnosed with HF or not six months later (i.e.,
will be a case or not). We randomly partitioned the patient population into a training and a testing set with 4:1 proportion, and

FEI WANG AND SUN: PSF: UNIFIED PATIENT SIMILARITY EVALUATION FRAMEWORK THROUGH METRIC LEARNING WITH WEAK

1059

TABLE IV
PERFORMANCE COMPARISON ON DISEASE PROGNOSIS

PSF(LSR)
PSF(LLE)
PSF(Laplacian)
PSF(PCA)
LSML

Precision

Recall

Accuracy

F-measure

0.4587
0.3736
0.2998
0.2293
0.2139

0.6735
0.5947
0.5750
0.4874
0.4576

0.9123
0.8786
0.8609
0.8456
0.8430

0.5458
0.4279
0.3842
0.3107
0.3031

set to ten. We report the averaged prediction performance over
100 independent runs in Table IV, in which PSF(LSR) is again
better than all others.
IV. CONCLUSION
Fig. 6. Variation of the algorithm performance versus numbers of the expert
feedbacks in one batch. (a) Precision. (b) Recall. (c) Accuracy. (d) F-measure.

Fig. 7. Variation of the algorithm performance versus numbers of sequential
expert feedback rounds. (a) Precision. (b) Recall. (c) Accuracy. (d) F-measure.

report the experimental results averaged results over 100 independent runs. The training set is used to learn the local spline
embeddings as well as those regression functions. For each
patient in the testing set, we will first identify its local neighborhood on the training data manifold, and obtain its intrinsic
coordinates by the local spline functions of that neighborhood.
Then we find the K training patients that are most similar to
the testing patients according to the Euclidean distance between
their intrinsic coordinates. Finally we predict whether the testing
patient is a case or not using a K-nearest neighbor classifier. In
this way, we convert the disease prognosis problem into a classification problem. To evaluate the classification performance, we
use the classification precision, recall, accuracy and F-measure.
Similar as in the experiments in Section III-C, we compare the performance of PSF(LSR), PSF(LLE), PSF(Laplacian),
PSF(PCA) and LSML. We apply the method introduced in [20]
to obtain the intrinsic coordinates of the testing patients for
LLE, LE and PCA. For ED, we just use the Euclidean distance
on the original coordinates to identify the neighborhoods for the
testing patients. The dimensionality for the embedding space is

We present a general PSF that incorporates both unsupervised information (patient features) and supervised information
(physician feedback) to learn a patient similarity measure. PSF
unifies all existing patient similarity methods and extended to
more general formulation of patient similarity. Under PSF, we
propose a new patient similarity construction based on LSR
for unsupervised information. We also propose an algorithmic
framework that can incrementally update the existing patient
similarity measure from PSF using matrix perturbation theory.
We evaluate PSF on a clinical prediction task using a large
patient dataset. The proposed PSF methods significantly outperform the existing supervised patient similarity approach by
over 40% improvement on F-measure. Among all the PSF variations, our proposed PSF with LSR performs, which confirms
its effectiveness in clinical patient similarity applications. This
implies that: 1) utilizing the data with no supervision could
also be helpful in terms of getting a better similarity estimate;
2) exploring the nonlinear structure of the local neighborhood
as in LSR is helpful because the data are usually much more
complicated than we thought.
REFERENCES
[1] M. H. Gabriel, M. F. Furukawa, E. B. Jones, J. King, and L. K. Samy.
(2013). Progress and challenges with the implementation and use of electronic health records among critical access hospitals [Online]. Available:
http://healthit.gov/sites/default/files/cahdata_brief12.pdf
[2] A. Gottlieb, G. Y. Stein, E. Ruppin, R. B. Altman, and R. Sharan, “A
method for inferring medical diagnoses from patient similarities,” BMC
Med., vol. 11, no. 1, pp. 194–203, 2013.
[3] J. Sun, F. Wang, J. Hu, and S. Edabollahi, “Supervised patient similarity
measure of heterogeneous patient records,” ACM SIGKDD Explorations
Newsletter, vol. 14, no. 1, pp. 16–24, 2012.
[4] J. Sun, D. Sow, J. Hu, and S. Ebadollahi, “Localized supervised metric learning on temporal physiological data,” in Proc. Int. Conf. Pattern
Recog., 2010, pp. 4149–4152.
[5] F. Wang, J. Sun, and S. Ebadollahi, “Integrating distance metrics learned
from multiple experts and its application in patient similarity assessment,”
in Proc. SIAM Int. Conf. Data Mining, 2011, pp. 59–70.
[6] F. Wang, J. Sun, J. Hu, and S. Ebadollahi, “iMet: Interactive metric learning
in healthcare application,” in Proc. SIAM Int. Conf. Data Mining, 2011,
pp. 944–955.
[7] F. Wang and C. Zhang, “Label propagation through linear neighborhoods,”
IEEE Trans. Knowl. Data Eng., vol. 20, no. 1, pp. 55–67, Jan. 2008.
[8] M. Belkin and P. Niyogi, “Laplacian eigenmaps for dimensionality
reduction and data representation,” Neural Comput., vol. 15, no. 6,
pp. 1373–1396, 2003.

1060

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

[9] S. T. Roweis and L. K. Saul, “Nonlinear dimensionality reduction by
locally linear embedding,” Science, vol. 290, no. 5500, pp. 2323–2326,
Dec. 2000.
[10] J. Duchon, “Splines minimizing rotation-invariant semi-norms in sobolev
spaces constructive theory of functions of several variables,” in Constructive Theory of Functions of Several Variables. New York, NY, USA:
Springer-Verlag, 1977.
[11] G. Wahba, Spline Models for Observational Data. Philadelphia, PA, USA:
SIAM, 1990.
[12] S. Xiang, F. Nie, C. Zhang, and C. Zhang, “Nonlinear dimensionality
reduction with local spline embedding,” IEEE Trans. Knowl. Data Eng.,
vol. 21, no. 9, pp. 1285–1298, Sep. 2009.
[13] H. Zha, X. He, C. H. Q. Ding, M. Gu, and H. D. Simon, “Spectral relaxation
for k-means clustering,” in Proc. Neural Inform. Process. Syst., 2001,
pp. 1057–1064.
[14] G. W. Stewart and J.-G. Sun, Matrix Perturbation Theory (Computer
Science and Scientific Computing). New York, NY, USA: Academic, 1990.
[15] G. Salton and M. J. McGill, Introduction to Modern Information Retrieval.
New York, NY, USA: McGraw-Hill, 1983.

[16] J. Wu, J. Roy, and W. F. Stewart, “Prediction modeling using ehr data:
Challenges, strategies, and a comparison of machine learning approaches,”
Med. Care, vol. 48, no. 6, pp. S106–S113, 2010.
[17] F. Wang, S. Chen, T. Li, and C. Zhang, “Semi-supervised metric learning
by maximizing constraint margin,” in Proc. 17th ACM Int. Conf. Inform.
Knowl. Manag., 2008, pp. 1457–1458.
[18] S. C. H. Hoi, W. Liu, and S.-F. Chang, “Semi-supervised distance metric
learning for collaborative image retrieval,” in Proc. IEEE Conf. Comput.
Vis. Pattern Recog., 2008, pp. 1–7.
[19] L. Z. Manor and P. Perona, “Self-Tuning spectral clustering,” in Proc.
Neural Inform. Process. Syst., 2004, pp. 1601–1608.
[20] Y. Bengio, J. Paiement, P. Vincent, O. Delalleau, N. Le Roux, and
M. Ouimet, “Out-of-sample extensions for LLE, isomap, MDS, eigenmaps, and spectral clustering,” in Proc. Neural Inform. Process. Syst.,
2004, pp. 177–184.

Authors’ photographs and biographies not available at the time of publication.

