Journal of Informetrics 1 (2007) 123–130

A rational indicator of scientific creativity
José M. Soler
Departamento de Fı́sica de la Materia Condensada, C-III, Universidad Autónoma de Madrid, E-28049 Madrid, Spain
Received 31 August 2006; received in revised form 31 October 2006; accepted 31 October 2006

Abstract
A model is proposed for the creation and transmission of scientific knowledge, based on the network of citations among research
articles. The model allows to assign to each article a non-negative value for its creativity, i.e. its creation of new knowledge. If the
entire publication network is truncated to the first neighbors of an article (the n references that it makes and the m citations that it
receives), its creativity value becomes a simple function of n and m. After splitting the creativity of each article among its authors,
the cumulative creativity of an author is then proposed as an indicator of her or his merit of research. In contrast with other merit
indicators, this creativity index yields similar values for the top scientists in two very different areas (life sciences and physics), thus
offering good promise for interdisciplinary analyses.
© 2007 Elsevier Ltd. All rights reserved.
Keywords: Citation analysis; Citation network; Knowledge flow; Research merit; Scientific creativity

1. Introduction
Evaluating the scientific merit and potential, of tenure and professorship candidates, is perhaps the most critical single
activity in the academic profession. In countries and institutions with a long scientific tradition, selection committees
are generally well trained and trusted to balance wisely the vast variety of factors that may influence the decision,
in the sense of optimizing the long-term scientific output. In less established environments, decisions are frequently
perceived as arbitrary, and the use of objective indicators and procedures may be necessary to obtain a wide consensus
(Moed, 2005).
The most traditional indicator of research output, the number of published papers, has been progressively substituted
by the number of citations received by those papers, when this impact indicator has become widely available and easy
to obtain (Garfield, 1964; ISI-Thomson, 2006). Different combinations of both magnitudes have been proposed (Rinia,
van Leeuwen, van Vuren, & van Raan, 1998) like those in the SPIRES database (SPIRES, 2006). The field has been
recently revitalized by the proposal by Hirsch (2005) of yet another combination, the so-called h index, which has gained
a rapid popularity, partly because the ISI-Thomson Web of Knowledge database (ISI-Thomson, 2006) provides a handy
tool to sort articles by their number of citations. Apart from that comparative handiness, there is little objective evidence
for the relative advantages of different indexes, which are generally motivated in terms of “impact” or “influence”.
However, it must not be forgotten that the task of a scientist is to create useful knowledge (in its broadest sense), not
merely to produce an impact. It is therefore desirable to derive some rational measure of the magnitude and quality

E-mail address: jose.soler@uam.es.
1751-1577/$ – see front matter © 2007 Elsevier Ltd. All rights reserved.
doi:10.1016/j.joi.2006.10.004

124

J.M. Soler / Journal of Informetrics 1 (2007) 123–130

of research output, rooted in a plausible model of the creation and transmission of scientific knowledge (Rinia, van
Leeuwen, Bruins, van Vuren, & van Raan, 2002).
2. Creativity model
Basic scientific knowledge, as opposed to technological or industrial knowledge, is created by the minds of scientists
and expressed almost exclusively as research articles. The knowledge is transmitted to other scientists, who read previous
articles and acknowledge this transmission in the form of references (in what follows, I will call references of an article
those made to previous papers, and citations those received from posterior papers). Thus, the output knowledge of an
article comes partly from previous work, which is simply transmitted, and partly from the creation of new knowledge
by the authors. However, there are many possible reasons why references are made (Cozzens, 1989; Garfield, 1964;
Gilbert, 1977; Merton, 1968). Furthermore, some of the references of an article may be more important than others.
Thus, it is rather uncertain to what extent a given reference reflects the use of previous knowledge. Therefore, in the
present model, I will simply assume that each reference reflects the transmission of a different non-negative value xij
of knowledge, with probability P(xij ), from the cited article i to the citing article j. The maximum entropy principle
(Tribus, 1969) dictates that, in the absence of any a priori information, other than the average value x = 1/α, the
probability is given by P(x) = α e−αx .
Consider the network formed by all published papers connected by their citations. The growth, connectivity, and
statistical properties of this and similar networks have been the subject of much recent work (Albert & Barabasi, 2002;
Redner, 2005). To model the flow of knowledge on this supporting network (Rinia et al., 2002), we may assign random
flow numbers xij to all citations, with probability P(xij ). Flow conservation implies that the articles’ knowledge-creation
values ci (that I will simply call creativities) obey


ci =
(1)
xij −
xki
j

k

I will discard negative knowledge as meaningless.1 Thus, I will require that ci ≥ 0 ∀i, and reject the sets {xij } that
2,3,4 The final values c will then be averages over all valid sets {x }, with a relative weight
violate this condition.
i
ij

P({xij }) ∝ exp(−α ij xij ).
Some attention must be paid to the definition of knowledge that is being used. It might seem that all the knowledge created by an article must be present already when it is published. However, this would make it difficult to
judge the relative importance of the knowledge created by different papers. Therefore, I rather consider the amount
of “used knowledge” (and therefore useful). The situation is very similar in commercial software development: the
economic value of a computer library does not materialize when it is written, but when licenses of it are sold, presum1 An ironic observer might object to this assumption, arguing that many articles contribute only to confusion, and that some citations are in fact
critical. I find this questionable, since most readers will filter efficiently this “negative” knowledge, simply ignoring it. Also, even wrong ideas can
stimulate new valid ones. In any case, critical references cannot be easily distinguished from positive ones, but their average effect might be taken
into account by renormalizing the mean flow value x.
2 Since new, non-negative knowledge is created in every article and transmitted to the future, the total flow of knowledge must increase with
time. Such an increase may be absorbed in three ways: by an increase in the number of articles published per year, by an increase in the number of
references per article, and by an increase in the average flow per citation x. The increase of the rate of publications is indeed a large effect, while
that of citations per paper is much weaker, if positive at all. In any case, it is not clear whether those two effects combined can fully account for the
transmission of the new knowledge predicted by the model. Thus, it may be necessary to adjust self-consistently a function α(t), of time t. In this
work, I have taken α = constant = 1.
3 Some of the basic scientific knowledge “leaks” out of the academic research literature in various forms: as knowledge absorbed by scientists
who read the articles but do not cite them; as established knowledge transmitted to textbooks and no longer cited in research articles (oblivion by
incorporation); as technological knowledge translated to patents, that may cite the literature but that are not included in databases of basic research
(Narin, Hamilton, & Olivastro, 1997); and as industrial knowledge translated to unpublished manufacture methods and products. It seems reasonable
to assume that this “hidden” flow of knowledge is proportional on average to the “visible” flow shown by citations. Therefore, in order to account
for the hidden flow, we may multiply the visible output flow of each article (first term of Eq. (1)) by a factor (1 + γ), where γ is a phenomenological
adjustable parameter. In the simplified model of this work I have taken γ = 0.
4 The boundary problem posed by recent papers, that have had no time to transmit their knowledge, may be addressed by not imposing flow
conservation on them, or by assigning to them an average number of additional expected citations, that will be a decreasing function of their age.
In any case, it is clear that any figure of merit based on citations will not be as reliable for very recent papers as for old ones.

J.M. Soler / Journal of Informetrics 1 (2007) 123–130

125

ably to create new software. Similarly, I am counting every “copy” of the knowledge, used in every new paper that
cites it.
This economic analogy can be pursued further. Thus, I will argue that, to a large extent, the citation network acts
as a market in which citing and cited articles act, respectively, as buyers and sellers of scientific knowledge. At first
sight, it might seem that the price of existing knowledge is zero, since it costs nothing to read and cite a published
article. However, there are practical limits to the number of references that can be made. These limits are dictated by
journal conditions, by the community citation practices, and, most importantly, by the authors limited time to read
new articles, and memory to remember them. Therefore, authors are forced in practice to select a limited number of
references, that are most relevant to their works. As in any market, the limited resources determine the “prices”, in this
case the flows of knowledge assigned to each citation.
Some of the general qualitative features of the model, as an indicator of research merit, may be expected a priori:
articles with less citations than references will have a positive but small creativity value; articles with a large output
(very cited) and a small input (not many references) will have the largest creativities; in contrast, the merit of review
articles will be much more moderate than that shown by their raw impact factor (citation count); the differences between
the creativities of authors in very large and active fields (with large publication and citation rates), and those in smaller
and less active fields, will be largely attenuated, as compared to other merit indicators, since the basic measure is the
difference between citations and references, which should be roughly zero in all fields; self-citations will be largely
discounted, since they will count both as a negative contribution (to the citing paper) and a positive one (to the cited
paper); citations received from a successful article (i.e. a very cited one itself) will be more valuable than those made
by a poorly cited one (Chen, Xie, Maslov, & Redner, 2006; Pinski & Narin, 1976). In particular, citations by uncited
papers will add no value at all, since no knowledge can flow through them; more generally, articles that generate
a divergent citation tree (e.g. the DNA paper of Watson and Crick) will have a large creativity, while those leading
ultimately to a dead end (e.g. the cold fusion paper of Fleischmann and Pons) will have a small one, even if they had
the same number of direct citations.
3. Simpliﬁed model
The quantitative analysis of the model presented above is an interesting challenge that will be addressed in the
future. In this work, I am rather interested in simplifying the model to allow the easy generation of a practical indicator
of merit of research. The simplified model will keep many of the general features discussed above, though not all
(in particular, it will loose the last two properties mentioned above). Thus, I propose to truncate the citation network
beyond the first neighbors of any given paper, i.e. to consider only its n references and m citations, and to impose
the conservation of flow, Eq. (1), only in the central node i. The average value x can be used as a convenient unit
of knowledge, so that α = 1 and P(x) = e−x . The probability that an article, with n references and m citations, has a
creativity c is then, for n, m > 0:
P(c|n, m) = N

−1



∞
· · · dx1 · · ·dxn dy1 · · ·dym δ(c + x − y) e−x−y

(2)

0



with x = ni=1 xi and y = m
j=1 yj , where xi are the input flows (references) and yj are the outputs (citations). δ(x) is
Dirac’s delta function and N is a normalization factor given by

N=

∞
· · · dx1 · · ·dxn dy1 · · ·dym θ(y − x) e−x−y

(3)

0

where θ(x) is the step function. Using a convenient change of variables, the integrals can be evaluated as
 ∞
N=
0

dx dy xn−1 ym−1
θ(y − x) e−x−y
(n − 1)!(m − 1)!

(4)

126

J.M. Soler / Journal of Informetrics 1 (2007) 123–130

Fig. 1. Probability that an article, that has made n = 30 references and has received m citations, has created a value c of scientific knowledge. It was
obtained from Eq. (6).

P(c|n, m) = N −1

 ∞
0

dx dy xn−1 ym−1
δ(c + x − y) e−x−y
(n − 1)!(m − 1)!

(5)

The result is
P(c|n, m) =

n e−c 1 F1 (1 − m, 2 − n − m; 2c)
n + m − 1 2 F1 (1, 1 − m; 1 + n; −1)

(6)

where 1 F1 and 2 F1 are hypergeometric functions, which can be expanded as a finite series (Gradshteyn & Rydhik,
1980). Fig. 1 shows some typical probability distributions.
The average value of c,
∞
dc c P(c|n, m),

c(n, m) =

(7)

0

is, for n, m > 0:
m−1

k
k=0 ((n + m − 2 − k)!/(m − 1 − k)!)(k + 1)2
.
c(n, m) = m−1
k=0 ((n − 1)!(n + m − 1)!)/((n + k)!(m − 1 − k)!)

(8)

It is represented in Fig. 2 for some typical values of n and m. As expected, c(n, m) increases with m and it decreases
with n. It obeys c(0, m) = m, c(n, 0) = 0, c(n, 1) = 1, and c(n, m) ≥ max(1, m − n) ∀m > 0. For the present purposes, a

Fig. 2. Circles: mean creation of knowledge (creativity) of an article with n references and m citations, calculated from Eq. (8) (in units of the mean
transmission of knowledge reflected by one reference). Solid lines: fits given by Eq. (9). Dashed lines: m − n.

J.M. Soler / Journal of Informetrics 1 (2007) 123–130

reasonably accurate fit is, for m > 0:
n
c(n, m)  m − n +
A eaz + B ebz

127

(9)

where z = (m − 1)/(n + 5), A = 0.986, B = 0.014, a = 1.08, and b = 6.3. The accumulated creativity of an author with Np
published papers is then defined as
Ca =

Np

c(ni , mi )
i=1

ai

(10)

where ai is the number of authors of paper i. Notice that, being positive and cumulative, Ca can only increase with time
and with the number of published papers.
In order to find in practice the creativity of an author (among many other merit indicators), one can follow these
steps: (1) download the programs ﬁlter and merit from this author’s web page (Soler, 2006), and compile them if
necessary. (2) Perform a “General search” in the ISI-Thomson Web of Science database (ISI-Thomson, 2006) for
the author’s name, using the appropriate filters. (3) Select the required records. Usually the easiest way is to check
“Records from 1 to last one” and click on “ADD TO MARKED LIST” (if you find too many articles, you may have to
mark and save them by parts, say (1–500) → file1, (501–last one) → file2); (4) click on “MARKED LIST”. (5) Check
the boxes “Author(s)”, “Title”, “Source”, “keywords”, “addresses”, “cited reference count”, “times cited”, “source
abbrev.”, “page count”, and “subject category”. Do not check “Abstract” nor “cited references”, since this would slow
down considerably the next step. (6) Click on “SAVE TO FILE” and save it in your computer. (7) Click on “BACK”,
then on “DELETE THIS LIST” and “RETURN”, and go to step 2 to make another search, if desired. (8) If you suspect
that there are two or more authors with the same name, use the ﬁlter program to help in selecting the papers of the
desired author. (9) Run the merit program to find the merit indicators. Mind for hidden file extensions, possibly added
by your navigator, when giving file names in this and previous step.
4. Results and discussion
Table 1 shows several indexes of merit of top scientists in life sciences and physics, taken from Hirsch’s selection
(Hirsch, 2005). It may be seen that the h index of all biologists is larger than that of all physicists, and their average
number of publications and citations is 1.5–2.5 times larger. In contrast, the two creativity distributions are remarkably
similar, with averages that differ only ∼15%, well below the standard deviation of both distributions. This offers the
promise of direct interdisciplinary comparisons, without any field normalization, a highly desirable characteristic of
any index of merit.
Although it is a natural consequence of the idea of knowledge flow, the fact that the references of an article will
result in lowering the merit assigned to it, is admittedly striking. It is thus appropriate to recognize that this is partly
due to a deliberate intent of measuring creativity rather than productivity (or, in economic terms, added value rather
than sales). To illustrate the point, imagine that two scientists, Alice and Bob, address independently an important and
difficult problem in their field. Bob takes an interdisciplinary approach and discovers that a method developed in a
different field just fits their need. Simultaneously, Alice faces the problem directly and re-invents the same method
by herself (thus making less references in her publication and achieving a higher creativity index).5 All other factors
being equal, both papers will receive roughly the same number of citations, since they transmit the same knowledge to
their field. But, while it may be argued that Alice’s work was more creative in some sense, it might also be argued that
Bob’s approach is better, since it additionally shows the relationship with a different field. Thus, although I believe that
Ca genuinely correlates with scientific creativity, I would not argue that this is necessarily the most valuable research
ability in general.
Eventually, the usefulness of different merit indicators will depend on how well they correlate with real humanmade selections (Cole & Cole, 1971; Rinia et al., 1998). Thus, Table 1 shows also a “productivity index” Pa (not a
probability), given by the author’s share of the citations received by her/his papers. Notice that, in the model proposed,
5

This is somewhat hypothetical since good citation practice (frequently enforced by the referees) requires that previous relevant work is cited,
independently of whether it was actually used.

128

J.M. Soler / Journal of Informetrics 1 (2007) 123–130

Table 1
Several merit indicators of the 10 most cited scientists in life sciences and physics (Hirsch, 2005)
Name

Np

Nc (103 )

h

Pa (103 )

Ca (103 )

B. Vogelstein
S.H. Snyder
S. Moncada
P. Chambon
R.C. Gallo
D. Baltimore
R.M. Evans
T. Kishimoto
C.A. Dinarello
A. Ullrich

447
1144
693
987
1247
657
428
1621
992
615

144.4
138.3
106.2
98.1
95.9
95.3
78.8
77.5
74.3
73.0

154
194
145
153
154
162
130
134
138
122

34.1
48.2
32.5
23.0
17.9
33.0
21.2
14.6
26.3
13.6

32.0
38.9
27.8
17.7
13.8
28.2
18.3
10.2
19.2
10.9

883
364

98.2
24.1

149
19

26.4
10.1

21.7
9.1

342
999
254
444
625
1096
918
358
446
469

56.7
53.5
53.1
38.8
37.4
37.0
34.3
32.6
29.8
24.9

96
109
111
88
94
88
92
80
88
75

39.1
14.2
39.9
32.7
14.3
12.8
7.4
26.7
19.0
12.2

36.9
10.3
35.9
29.3
10.6
7.8
5.8
23.9
14.3
9.9

595
286

39.8
10.4

92
11

21.8
11.3

18.5
11.3

Average
Standard deviation
P.W. Anderson
A.J. Heeger
E. Witten
S. Weinberg
M.L. Cohen
M. Cardona
A.C. Gossard
P.G. deGennes
M.E. Fisher
G. Parisi
Average
Standard deviation

Np , number of papers published; Nc , number of citations received
byNpthose papers; h, number of papers with h or more citations (Hirsch index)
m /a , where ai and mi are the number of authors and of citations received
(Hirsch, 2005); Pa , author’s knowledge-productivity index, Pa =
i=1 i i
by paper i; Ca , author’s creativity index, Eq. (10). The data were obtained in April 2006.

Table 2
Several indicators of some of the main multidisciplinary, review and non-review physics journals
Journal

Np

Nr /Np

Nc /Np

C/Np

Nature
Science
PNAS

IF

3676
2449
2133

10
14
31

67
74
112

59
63
84

28.8
24.4
9.8

Rev. Mod. Phys.
Adv. Phys.
Surf. Sci. Rep.
Rep. Prog. Phys.
Phys. Rep.

20
8
5
29
81

284
391
159
198
166

327
149
61
90
90

160
18
3
32
22

13.4
12.7
10.3
6.2
5.6

Phys. Rev. Lett.
Phys. Rev. D
Nucl. Phys. B
Appl. Phys. Lett.
J. Chem. Phys.
Phys. Rev. B

1904
1049
620
1819
2040
3488

18
27
37
13
37
27

59
23
42
34
37
35

44
11
24
26
16
18

6.0
3.9
3.3
3.3
3.1
2.8

Np , number of “papers” (documents) published in year 1990, in all the sections included in the Science Citation Index database; Nr , number of
references made by those papers;
NNcp, number of citations received by those papers until May 2006 (August 2006 for PNAS); C, sum of the creativities,
c(ni , mi ); IF, impact factor in 1998 (center of the period 1990–2006), as defined by the Journal of Citation
Eq. (8), of those papers, C =
i=1
Reports (ISI-Thomson, 2006). For the non-review physics journals (last group), the indicators (other than Np and IF) have been obtained from a
random sample of their Np papers, rather than from the whole set.

J.M. Soler / Journal of Informetrics 1 (2007) 123–130

129

Nc is the total output flow of knowledge from the author’s papers, while Pa is her/his share of it. It may be seen that
Pa also allows reliable interdisciplinary comparisons. It may be concluded that the main difference between the two
communities is the larger average number of authors per article in the life sciences, which is taken into account in both
Pa and Ca , but not in the other indexes.
Knowledge-productivity and creativity indicators can be used also for groups, institutions, or journals. Thus, Table 2
shows them for some leading journals. As expected, most review journals have considerably smaller creativities than
productivities (dramatically smaller in some cases). Still, Reviews of Modern Physics has the largest creativity index
of all the journals studied, showing that collecting, processing, and presenting knowledge in a coherent way can by
itself create much new useful knowledge.
Finally, in a world of strong competition for positions and founds, a negative merit assignment to references might
result in a tendency to reduce them below what would be scientifically desirable and professionally fair. A possible
solution is to use, in Eq. (8), a fixed value of n (equal to the journal reference intensity, i.e. the average number of
references per article in that journal), to calculate the creativities for competitive-evaluation purposes. This would spoil
a few desirable properties of the model (like the discount of self-citations), but most of its effects would probably be
rather mild, since the number of references per paper has a much smaller variance than the number of citations. Thus,
the root mean squared difference between the creativities of Table 1, calculated using the average references of the
journals, rather than the actual references of each article, is only ∼4%.
5. Conclusion
In conclusion, I have proposed an index of research merit based on creativity, defined as the creation of new scientific
knowledge, in a plausible model of knowledge generation and transmission. It is calculated easily from the citations
and references of the author’s articles, and it is well suited for interdisciplinary comparisons. An advantage of such an
index is that its meaning may be more easily perceived, by policy makers and the general public, as a measure of a
scientist’s social and economic service to the community.
Acknowledgements
I would like to acknowledge very useful discussions with J.V. Alvarez, J.R. Castillo, R. Garcı́a, J. Gómez-Herrero,
L. Seijo, and F. Yndurain. This work has been founded by Spain’s Ministry of Science grants BFM2003-03372 and
FIS2006-12117.
References
Albert, R., & Barabasi, A. L. (2002). Statistical mechanics of complex networks. Reviews of Modern Physics, 74, 47–97.
Chen, P., Xie, H., Maslov, S., Redner, S. (2006). Finding scientific gems with Google. Preprint arXiv: physics/0604130.
Cole, J., & Cole, S. (1971). Measuring quality of sociological research—Problems in use of science citation index. American Sociologist, 6,
23–29.
Cozzens, S. E. (1989). What do citations count? The retoric 1st model. Scientometrics, 15, 437–447.
Garfield, E. (1964). Science citation index-new dimension in indexing—Unique approach underlies versatile bibliographic systems for communicating + evaluating information. Science, 144, 649–654.
Gilbert, G. N. (1977). Referencing as persuasion. Social Studies of Science, 7, 113–122.
Gradshteyn, I. S., & Rydhik, I. M. (1980). Table of integrals, series, and products. Orlando: Academic Press.
Hirsch, J. E. (2005). An index to quantify an individual’s scientific research output. Proceedings of the National Academy of Sciences, 102,
16569–16572.
Institute for Scientific Information-Thomson Scientific (2006). Webpage: http://isiknowledge.com.
Merton, R. K. (1968). The Matthew effect in science. Science, 159, 56–63.
Moed, H. F. (2005). Citation analysis in research evaluation. Dordrecht: Springer.
Narin, F., Hamilton, K. S., & Olivastro, D. (1997). The increasing linkage between US technology and public science. Research Policy, 26,
317–330.
Pinski, G., & Narin, F. (1976). Citation influence for journal aggregates of scientific publications—Theory, with application to literature of physics.
Information Processing and Management, 12, 297–312.
Redner, S. (2005). Citation statistics from 110 years of physical review. Physics Today, 58(6), 49–54.

130

J.M. Soler / Journal of Informetrics 1 (2007) 123–130

Rinia, E. J., van Leeuwen, T. N., Bruins, E. E. W., van Vuren, H. G., & van Raan, A. F. J. (2002). Measuring knowledge transfer between fields of
science. Scientometrics, 54, 347–362.
Rinia, E. J., van Leeuwen, T. N., van Vuren, H. G., & van Raan, A. F. J. (1998). Comparative analysis of a set of bibliometric indicators and central
peer review criteria—Evaluation of condensed matter physics in The Netherlands. Research Policy, 27, 95–107.
Soler, J. M. (2006). Webpage: http://www.uam.es/jose.soler/tools.
SPIRES. (2006). Webpage: http://www.slac.stanford.edu/spires/hep/.
Tribus, M. (1969). Rational descriptions, decisions, and designs. New York: Pergamon Press.

