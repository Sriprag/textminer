Journal of Biomedical Informatics 60 (2016) 309â€“318

Contents lists available at ScienceDirect

Journal of Biomedical Informatics
journal homepage: www.elsevier.com/locate/yjbin

A categorical analysis of coreference resolution errors in biomedical
texts
Miji Choi a,b, Justin Zobel a, Karin Verspoor a,â‡‘
a
b

Department of Computing and Information Systems, The University of Melbourne, Melbourne, Australia
National ICT Australia (NICTA), Victoria Research Laboratory, Australia

a r t i c l e

i n f o

Article history:
Received 9 October 2015
Revised 19 February 2016
Accepted 20 February 2016
Available online 27 February 2016
Keywords:
Coreference resolution
Natural language processing
Text mining
Error analysis

a b s t r a c t
Background: Coreference resolution is an essential task in information extraction from the published
biomedical literature. It supports the discovery of complex information by linking referring expressions
such as pronouns and appositives to their referents, which are typically entities that play a central role in
biomedical events. Correctly establishing these links allows detailed understanding of all the participants
in events, and connecting events together through their shared participants.
Results: As an initial step towards the development of a novel coreference resolution system for the
biomedical domain, we have categorised the characteristics of coreference relations by type of anaphor
as well as broader syntactic and semantic characteristics, and have compared the performance of a
domain adaptation of a state-of-the-art general system to published results from domain-specific
systems in terms of this categorisation. We also develop a rule-based system for anaphoric coreference
resolution in the biomedical domain with simple modules derived from available systems. Our results
show that the domain-specific systems outperform the general system overall. Whilst this result is
unsurprising, our proposed categorisation enables a detailed quantitative analysis of the system
performance. We identify limitations of each system and find that there remain important gaps in the
state-of-the-art systems, which are clearly identifiable with respect to the categorisation.
Conclusion: We have analysed in detail the performance of existing coreference resolution systems for
the biomedical literature and have demonstrated that there clear gaps in their coverage. The approach
developed in the general domain needs to be tailored for portability to the biomedical domain. The specific framework for class-based error analysis of existing systems that we propose has benefits for identifying specific limitations of those systems. This in turn provides insights for further system development.
Ã“ 2016 Elsevier Inc. All rights reserved.

1. Introduction
Text mining techniques play an important role not only in
processing the rapidly growing scientific literature, but also in
discovering hidden knowledge in the life sciences literature. These
methods have conventionally been used to extract biomolecular
concepts such as genes, proteins, and chemical compounds from
biomolecular literature [1]. Recently, researchers in the field of
biomedical text mining have shifted their interests toward the
extraction of biomedical interactions (relations and events)
involving genes, drugs and diseases, and other biological named
entities [2â€“4].

â‡‘ Corresponding author.
E-mail addresses: jooc1@student.unimelb.edu.au (M. Choi), jzobel@unimelb.
edu.au (J. Zobel), karin.verspoor@unimelb.edu.au (K. Verspoor).
http://dx.doi.org/10.1016/j.jbi.2016.02.015
1532-0464/Ã“ 2016 Elsevier Inc. All rights reserved.

Complex biological processes are widely described using biological networks, consisting of sets of interacting relationships
between biomedical entities [5â€“8]. Gene regulatory and signal
transduction networks capture the interaction between genes
and proteins, and metabolic pathways contain knowledge of functional behaviour involving proteins and chemical compounds.
Many comprehensive biomedical knowledge resources, such as
PharmGKB [9], HMDB [10], and Reactome [11], use manual literature curation for deriving information of interacting relationships,
as well as take advantage of text mining techniques for automatic
extraction of such biomolecular interaction information [12,13].
In natural language texts, including biomedical publications, it
is common to refer meaningful entities using linguistic â€˜â€˜short cutsâ€
to avoid repeating names or complex descriptions. For instance,
anaphoric expressions such as pronouns (i.e., it, they) and definite
references (i.e., the protein, these genes) may be used to indirectly
refer to entities that previously introduced in the same text. This

310

M. Choi et al. / Journal of Biomedical Informatics 60 (2016) 309â€“318

use of anaphoric mentions in written natural language is one of the
major obstacles for systems that aim to identify biomolecular
interactions from the biomedical literature, limiting information
extraction system performance [14â€“17]. These systems typically
rely on annotated mentions of biomedical entities as the anchors
for identifying interactions, and are also typically sentencebound (i.e., they detect interaction statements only within a single
sentence). These two characteristics together indicate why resolving indirect entity references can improve interaction extraction â€“
recognising additional references to biomedical entities (where the
reference may cross a sentence boundary) will enable more
interactions to be found.
An example is shown in Fig. 1. The pronoun It (it) in the second
and fifth sentences is used to represent tepoxalin, a chemical entity
mentioned in the first sentence. The interaction involving inhibited
between tepoxalin, and lymphocyte proliferation in the fourth sentence can be straightforwardly identified by event extraction systems, since the entities that are the subject (tepoxalin) and the
argument (lymphocyte proliferation) of the interaction are clearly
identifiable as biomedical concepts. On the other hand, the inhibition event, (it-inhibited-the production of LTB4) in the fifth sentence
that indirectly refers to tepoxalin using the pronoun it might be
missed by those systems without a coreference resolution module,
since it is not a direct biomedical entity mention.
For performance evaluation of coreference resolution systems,
standard metrics of precision, recall, and F-score based on gold
standard corpora are widely used. The evaluation metrics provide
quantitative results of systems, such as numbers of correct
answers performed by systems. However, such aggregate metrics
do not give insight into system failures. Detailed investigation of
where systems fail is a critical process to identify specific opportunities for improving the performance of systems [18].
In this paper, we present a categorisation of both anaphoric
expressions, and coreference relations involving those anaphors.
This categorisation results in a structured framework that is used
to measure performance of existing coreference resolution systems, and enables detailed and systematic error analysis of those
systems.
We assess existing coreference resolution systems; a stateof-the-art system in the general domain, and biomedical
domain-specific systems. These systems have been evaluated on
an annotated corpus of biomedical texts divided according to

coreference type. We identify those specific areas where existing
systems need to improve performance for coreference resolution
in the biomedical domain. We also describe a simple coreference
resolution system we have developed targeting the biomedical
domain, which directly addresses weaknesses of existing systems,
and achieves improved performance.

2. Background
The task of coreference resolution is a natural language processing task in which the objective is to determine coreference links in
a text, i.e., to identify all reference mentions that refer to the same
entity. Since the task is a critical process as a subtask of information extraction (IE) [19], many approaches to this task have been
developed since MUC-6 in 1995. Machine learning approaches
have been employed, and have shown their ability to resolve coreference links by producing meaningful performance on test data
[20,21]. However, those approaches are dependent on annotated
training corpora, and tend to show poor performance on new data
[22].
On the other hand, it has been demonstrated that rule-based
methods are more robust than machine learning approaches
[23,24]. An unsupervised sieve-like framework developed by Lee
et al. [24] at Stanford (hereafter referred as the Stanford system),
extending the work of Raghunathan et al. [25], was developed to
determine coreference links. This system achieved the best performance on the CoNLL-2011 shared task on coreference [26]. The
system identifies all mentions such as pronouns, noun phrases,
and named entity mentions in the process of mention detection
aiming for high recall, as well as targeting precision with a collection of deterministic rule-based models to determine identical
mentions and head-word matched strings, and pronominal coreference links.
There have been attempts to adapt coreference resolution
techniques developed for the general domain to the biomedical
literature. Whilst the CoNLL-2011 task [26] is designed to detect
identical mentions that refer to the same entities and events in
newswire texts, the task of coreference resolution in the biomedical domain is mainly to determine coreference relations between
mentions (antecedents) and pronominal mentions (anaphors)
such as pronouns, and demonstrative noun phrases. Anaphoric

Fig. 1. Example passage involving coreference (PMID-8707445) in the BioNLP-CR-Train data.

311

M. Choi et al. / Journal of Biomedical Informatics 60 (2016) 309â€“318

Table 1
The published performance [28] of the six participating systems (â„) of the BioNLP 2011 â€“ Protein Coreference task, and performance of our Simple system, Miwa et al. [31] and
Nguyen et al. [32] systems (GTag = Genia Tagger, CTag = CNC Tagger, SVM = Support Vector Machine, McCCJ = McCloskyâ€“Charniakâ€“Johnson Parser, Stanford = Stanford Parser,
SD = Stanford Dependency Conversion). All results based on BioNLP 2011 Protein Coreference Test data, and the highest values in bold.
Lexical processing

Syntactic processing

Approach

Protein links (P/R/F)

â„

UTurku (TEES) [33]
â„
UUtah [29]
â„
ConcordU [34]
â„
UZurich [35]
â„
USzeged
â„
UCDSCI

Porter
GTag
â€“
LingPipe
CTag,Morpha
GTag,LingPipe

McCCJ + SD
Enju
McCCJ + SD
Pro3Gres
McCCJ
â€“

SVM
SVM
Rule-based
Rule-based
SVM
SVM

67.2/14.4/23.8
73.3/22.2/34.1
63.2/19.4/29.7
55.5/21.5/31.0
3.5/3.2/3.3
0.3/0.7/0.4

Miwa et al. [31]
Nguyen et al. [32]
Simple

â€“
â€“
â€“

Enju
Enju
Stanford

Rule-based
Rule-based
Rule-based

62.7/50.4/55.9
50.2/52.5/51.3
46.3/50.0/48.1

coreference expressions are often used in published literature to
refer biomedical entities, and some of those expressions are used
in statements describing significant biomedical interactions and
events. Since those coreference expressions are ignored by most
event extraction systems, and are a primary cause for reduced system recall, the coreference issue has recently received attention in
the biomedical domain [14,27].
There has been a community-wide effort to address coreference
issues in the biomedical literature in a series of BioNLP shared
tasks in 2011 and 2013. The Protein Coreference task, which
involves identification of anaphoric coreference links related to
protein and gene entities, was organised as a supporting task at
the BioNLP Shared Task 2011 (BioNLP-STâ€™11) [27,28]. Six research
teams participated in the task, although only four systems produced meaningful performance, as summarised in Table 1. However, the overall performance of each system was interestingly
quite low. On the task of identifying coreference relations where
an antecedent involves specific protein and gene names, the UUtah
system [29] achieved the best performance of F-score 34% with
73% precision and 22% recall. This system employed Reconcile
[30], a general coreference resolution system in the newswire
domain, by modifying several components adaptable to the
biomedical texts. This study also shows that employment of a
general-purpose coreference system is suitable for domain adaptation, but the low recall indicates a need for further improvement.
After BioNLP-STâ€™11, Miwa et al. [31] developed a novel coreference resolution system using a rule-based approach, aiming for
integration with the event extraction system EventMine. Several
rules for detection of coreference links were inspired by Raghunathan et al. [25]. Performance of this coreference resolution system is better than the UUtah system, significantly improving the
recall to 50.4% from 22.2% as seen in Table 1, but decreasing precision. Nguyen et al. [32] also implemented a coreference system
using a rule-based approach through an analysis of the Protein
Coreference task at BioNLP 2011. Semantic information was used
for resolution of specific anaphors. For example, several proteinspecific keywords such as binding, interaction and activity were
used to determine the semantic type of pronouns, whilst common
head words, such as protein, gene and molecule were considered to
detect definite noun phrases.
The semantic information contributed to improve the overall
performance by increasing the recall. However, there still remain
challenges such as the violation of a number-agreement constraint
in the gold standard annotations, and parse errors, which influence
the detection of correct antecedents. Coreference resolution was
also incorporated into the GENIA Event Extraction shared task at
BioNLP 2013 [4], but the task was not attempted by any participating teams.
In the Protein Coreference task [27], three different strategies
are employed for evaluation of coreference links, and system

results are mainly measured based on their ability to detect coreference links that involve protein and gene mentions in antecedents. A correct coreference relation is a link connecting an
anaphoric mention to its antecedent, based on gold annotations.
The matching criteria of mention boundaries are loose, so partial
matches of antecedents are accepted as long as they include the
correct protein and gene mentions. On the other hand, the
CoNLL-2011 shared task [26] in the general domain measures a
coreference link that exactly matches mention spans with the gold
annotations. For CoNLL, the unweighed average of existing metrics,
such as MUC, B-CUBED, CEAF and BLANC are computed to evaluate
participating systems [36].
For the task of coreference resolution, most systems include
components for mention detection and coreference determination.
Firstly, texts are syntactically parsed, and noun phrases and pronouns are identified based on syntactic parsing information. All
noun phrases are selected, and named-entity mentions relevant
to the domain (such as proteins, genes, or person names) are identified using a NER module for antecedent candidates. In the coreference resolution step, an antecedent is determined from
antecedent candidates for a given anaphoric mention using one
of several approaches. A rule-based approach employed by Miwa
et al. [31], Nguyen et al. [32] and Lee et al. [24] systems uses a
set of linguistic and syntactic rules such as number-agreement
constraints, or shared head words, whilst a machine learning
approach (Turku Event Extraction System [33]) uses a variety of
features such as syntactic dependencies, token/sentence level
information such as POS tags, and named entities to train a classification model. Most systems for biomedical event extraction that
address coreference resolution use rule-based methods [37,38].
Since syntactic parsing is typically an essential process supporting coreference resolution, most systems also employ existing syntactic parsers. Of the systems in Table 1, the ConcordU and TEES
systems use the McClosky Charniak-Johnson (McCCJ) parser that
is based on the Stanford dependency parser [39] and trained for
the biomedical literature using GENIA corpus. The UUTah, Nguyen
et al., and Miwa et al. systems utilise the Enju parser [40], based on
predicate-argument structures.
3. Systems in practice
In our study, we have evaluated performance of three existing
coreference resolution systems, and one new system that we introduce as a baseline. We consider:
1. the general domain Stanford CoreNLP system [41] (hereafter
referred to as Stanford system),
2. the Turku Event Extraction System with the provided CO11
classification model [33], a biomedical domain-specific event
extraction system (hereafter referred to as the TEES system),

312

M. Choi et al. / Journal of Biomedical Informatics 60 (2016) 309â€“318

3. a novel coreference resolution system developed for the
biomedical literature by Miwa et al. [31],
4. a simple rule-based system for biomedical texts that we provide
for comparison (hereafter referred to as the Simple system).
The Stanford system, also introduced in Section 2, consists of
two processes: mention detection, and coreference resolution. All
noun phrases, pronouns, and named entity mentions such as types
of PERSON, LOCATION, or PRODUCT are identified in the mention
detection step. Then, a collection of sieve-like rules are used to
determine coreference links. Those sieves are defined as follows
[42]:







Speaker Identification Sieve: match speakers.
Exact String Match Sieve: detect identical mentions.
Relaxed String Match Sieve: detect partially matched mentions.
Precise Constructs Sieve: determine appositive relations.
Strict Head Match Sieves: link mentions sharing headwords.
Relaxed Head Match Sieve: loosen the entity head match
heuristic.
 Pronoun Resolution Sieve: determine referents of pronouns.
For example, identical mentions, and strings that share the
same head-word, are detected in the Exact string match sieve
and the Strict head match sieve, respectively. The Precise constructs sieve determines appositive relations such as acronym
and relative pronouns, and general pronouns are also linked to
their corresponding antecedents in the Pronoun match sieve. For
each sieve-model, a variety of linguistic, syntactic and semantic
rules are applied.
In contrast, the TEES system uses a machine learning approach,
specifically a Support Vector Machine (SVM), to classify coreference relations in the biomedical context, using a model trained
with the training corpus of the Protein Coreference task at
BioNLP-STâ€™11 [28]. The McCCJ parser [43,44] is used, and syntactic
parsing information is used as features. As one of the participating
systems in the Protein Coreference task, the TEES system achieved
the second highest precision as described in Table 1, even though
the main goal of the TEES system is not coreference resolution,
but general biomedical event extraction. We evaluate the TEES system in this study, since it is the only participating system publicly
available amongst participating systems in the Protein Coreference
task.
The system developed by Miwa et al. [31] uses a rule-based
approach, and contains three processes; mention detection, antecedent candidate detection, and coreference link detection. In the
mention detection step, all noun phrases and pronouns are
extracted based on syntactic parsing information using the Enju
parser [40], and irrelevant anaphoric mentions (such as noun
phrases not starting with the, these, and pleonastic it, or personal
pronoun we) are filtered out by a set of rules. For antecedent candidates, all noun phrases extracted in the mention detection step

are collected. Several rules are used to rank the antecedent candidates, and the top ranked antecedent is linked to a corresponding
anaphoric mention in the step of coreference link detection. This
system is not publicly available, but the authors provided us with
the output of the system over the BioNLP-STâ€™11 development data.
These outputs were the basis for their published results on this
data [31]; we use them directly in our analysis.
We have also developed a rule-based coreference system, tailored to the requirements of the BioNLP-STâ€™11 coreference corpus
(hereafter referred as the Simple system). The Simple system aims
to identify anaphoric mentions, and determines their antecedents
with simple syntactic and semantic rules. The system consists of
three elementary stages: data preprocessing, identification of anaphoric mentions, and determination of antecedents. First, input
texts are parsed by the Stanford parser [45], and all noun phrases
are selected based on the syntactic parsing results. Second,
biomedical entities such as gene and protein names are identified
using a biomedical NER module, BANNER [46]. Then, anaphoric
mentions such as pronouns and definite noun phrases are selected.
Personal pronouns such as we and you are discarded considering
that our task of coreference resolution is limited to biomedical
entities. The pleonastic it is also filtered out using syntactic patterns. For definite noun phrases, the system detects noun phrases
containing a list of predefined head words, such as gene, protein,
factor, molecule, element, family, inhibitor and receptor. This list
has been adapted from the approach implemented by Nguyen
et al. [32], which identified these as the top common head words
for definite noun phrases in the biomedical literature. Thirdly,
the system collects antecedent candidates for the identified anaphoric mentions amongst noun phrases selected in the preprocessing stage within a given sentence window size, since antecedents
are mostly prior and close to anaphoric mentions. The default window size is 3 in our system, which means three sentences prior to
an anaphoric mention are considered for identification of its antecedent. Finally, for determination of antecedents, we apply two
simple rules to filter the candidates of antecedents (Rule 1, 3),
and one rule specifically for definite noun phrases (Rule 2). These
rules are as follows.
Rule 1. Number agreement rule: Candidates that do not agree in
number (singular, plural) with an anaphor are discarded. For
example, plural noun phrases in candidates such as CD3, CD2,
and CD28, or changes are filtered out for the anaphor its in the
second sentence in Fig. 2.
Rule 2. Semantic information rule: In the case of a definite noun
phrase anaphor, antecedent candidates that are not biomedical
entities are discarded. Specifically, we only keep candidates that
are entity mentions identified by BANNER as a protein. For
example, for the biomedical noun phrase these receptors in
the example text S2 shown in Fig. 2, the noun phrase CD3,
CD2, and CD28, which is identified as protein entities, is
retained, but the signalling pathways and T cells are discarded.

Fig. 2. Example sentences explain those rules above used for development of the Simple system. Noun phrases inside in brackets are candidates of antecedent, whilst
mentions in bold are anaphors, and underlined noun phrases are antecedents for these anaphors.

313

M. Choi et al. / Journal of Biomedical Informatics 60 (2016) 309â€“318

Rule 3. Closest candidate preference rule: The closest candidate is
selected. For example, HS1 phosphorylation is preferred as an
antecedent for the possessive pronoun its in the second sentence rather than other candidates such as CD3 and the tyrosine
phosphorylation in the first sentence in Fig. 2.
The syntactic constraints used in the Simple system are motivated by the approach of the Stanford system, which links pronominal coreference mentions to their antecedents with constraints for
attributes such as number, gender, person, and NER label [42]. The
gender constraint is not considered here, since the anaphoric mentions that we take into account do not involve gender. Instead of
the person attribute, our system assigns biomedical entities to definite noun phrases. We use a biomedical NER component to identify proteins and genes, and these mentions labelled from BANNER
are preferentially considered as an antecedent for the definite noun
phrases containing relevant entity mentions such as gene, protein,
receptor and molecule. This semantic rule is motivated by the
approach implemented by Nguyen et al. [32].
For evaluation of existing systems, we have used the coreference annotations of biomedical texts provided by the Protein
Coreference task at BioNLP 2011 [27] implemented in the GENIA
project [47]. The training corpus (BioNLP-CR-Train) contains
2300 coreference relations that consist of an anaphor and an
antecedent pairs annotated from 800 PubMed journal abstracts.
The development dataset (BioNLP-CR-Dev) containing 473 coreference relations annotated from 150 PubMed journal abstracts
was used for evaluation across the categorisation. We use both
these datasets as gold standard corpora (BioNLP-CR-Gold); we
have not used it for training but solely for testing and analysis.
The official test corpus for the task is unavailable for detailed
analysis.
For evaluation, we adopt the evaluation metrics as used in the
BioNLP 2011 Protein Coreference task. The metrics, consisting of
precision (the percentage of system responses that are correct),
recall (the percentage of correct responses that are returned) and
F-score (the harmonic mean of precision and recall), are used to
measure existing systems in two aspects: (1) Protein mode, which
assesses determination of coreference relations where antecedents
embed protein entities and (2) Surface mode, which assesses all
coreference relations, regardless of whether antecedents refer to
protein entities. We provide a summary of system performance
evaluated in Protein mode in Table 4. Surface mode was used for
analysis of system performance across categories as illustrated in
Table 5.

4. Proposed measurement by categorisation
We have analysed anaphoric coreference expressions in the
BioNLP-CR-Train data, categorising them into nine types described
in Table 2. Regarding Surface mode, relative pronouns such as
which, that, or where account for 55% of the BioNLP-CR-Train data,
and the category of possessive pronouns such as its, and their occupies around 18%. There are 338 definite noun phrase (15%) beginning with the, or these, for example the protein, this gene, or these
complexes, and a few indefinite noun phrase (0.5%), for example a
nuclear factor. There are also 34 uncategorised mentions including
22 proper nouns, such as SP-A, NF-kappa B, and most lymphokine
genes. On the other hand, the Surface relations mainly consist of
relative pronouns (31%), definite noun phrases (28%), and possessive pronouns (25%) involving protein and gene entities.
In addition to the linguistic categorisation of anaphoric coreference mentions, we have also categorised coreference relations
between anaphors and their antecedents with syntactic and
semantic characteristics described as below. We summarise these

Table 2
Statistics of anaphor types in the surface mode and the protein mode on the BioNLPCR-Train data.
Category

Number of
surface links

Number of
protein links

Example

Relative pronoun
Possessive
pronoun
Demonstrative
pronoun
Personal
pronoun
Reflexive
pronoun
Other pronoun
Definite noun
phrase
Indefinite noun
phrase
Uncategorised

1255 (55%)
415 (18%)

269 (31%)
219 (25%)

which, that, where
its, their

50 (2%)

13 (1.5%)

this, that, these

180 (8%)

84 (10%)

it, they, them

13 (0.5%)

7 (0.8%)

itself, themselves

4 (0.2%)
338 (14.7%)

9 (1%)
244 (28%)

11 (0.5%)

14 (2%)

both, other, either
the protein, these
genes
a nuclear factor

34 (1.5%)

13 (1.5%)

Total

2300

872

SP-A, most
lymphokine genes

five categories of coreference relations, and their examples in
Table 3.
 Including protein: Antecedents embed protein named entities,
which means anaphors refer to specific proteins and genes.
 Including coordinating conjunction: Antecedents embed coordinating conjunctions such as and and or, which means that
anaphors refer to more than one entity.
 Cross-sentence: An anaphor and its antecedent are linked
across sentence boundaries.
 Identical string: The exact string of an anaphor is repeated as an
antecedent, which means the anaphor and its antecedent are
identical.
 Head-word match: Both an anaphor and its antecedent have the
same head word.
Amongst 2300 coreference pairs in the BioNLP-CR-Train data,
560 pairs involve proteins and genes in antecedents, and 217 pairs
have antecedents with complex structures, including one or more
coordinating conjunctions such as and and or. In 389 pairs, an anaphor refers to its antecedent across a sentence, and 43 pairs have
identical anaphor and antecedent strings. Anaphors in identical
pairs tend to be mainly definite noun phrase. Amongst 383 coreference links where anaphors are definite noun phrases, indefinite
noun phrases and uncategorised mentions, 254 pairs consist of
an anaphor and an antecedent that share head words, for example,
this receptor (anaphor), and the p75 tumour necrosis factor receptor
(antecedent).
We compare performance of the four existing coreference resolution systems on the BioNLP-CR-Dev data in Table 4. Those systems were evaluated across the categorisation of anaphor types
as described in Table 2. Since the Miwa system is not currently
available, we requested the output (raw data) of the system over
the development dataset; this output underlies the summary performance results in Table 3 of the relevant paper [31] whilst raw
outputs for the test dataset are not available. To enable comparison
of these systems on the same data, we studied the performance of
each system in detail only over the development dataset.
The Stanford system, which is the general coreference resolution system, achieved poor performance of F-score 12% (precision
9.4%, and recall 16.8%) for identification of coreference relations
in the protein link. This is not surprising, due to the differing task
definition implemented in the system as compared to the BioNLPCR-Dev data. The system was designed to identify coreference links

314

M. Choi et al. / Journal of Biomedical Informatics 60 (2016) 309â€“318

Table 3
Characteristics of coreference relations with analysis of the BioNLP-CR-Train data.
Type

Number Example

Including protein

560

We have analysed the expression of IL-2Ralpha, c-myc, and pim-1 genes in anti-CD3-activated human T lymphocytes. The
induction of these genes is associated with. . . [PMID-10068671]

Including coordinating
conjunction

217

Activation of T lymphocytes to produce cytokines is regulated by the counterbalance of protein-tyrosine kinases and proteintyrosine phosphatases, many of which have a high degree of substrate. . . [PMID-10206983]

Cross-sentence

389

We found that NFATx1 DNA binding activity and interaction with AP-1 polypeptides . . .suggesting the presence of intrinsic
transcriptional activation motifs in both regions. We also identified a potent inhibitory sequence within its N-terminal domain. . .
[PMID-9121455]

Identical relation

43

The level of mRNA expression of the NM23 gene is significantly lower in cell lines . . .Moreover, cell lines derived from tumours of
patients with a disease-free survival of more than 24 months (24â€“58 months) express the NM23 gene at higher levels. . . [PMID7909963]

Head-word match

254

Despite overwhelming evidence that enhanced production of the p75 tumour necrosis factor receptor (p75TNF-R) accompanies
development of specific human inflammatory pathologies such as multi-organ failure during sepsis, inflammatory liver disease,
pancreatitis, respiratory distress syndrome, or AIDS, the function of this receptor remains. . . [PMID-9763613]

Table 4
Comparison of performance of existing systems in the protein mode regarding to anaphoric classes on the BioNLP-CR-Dev dataset.
Class

Number

Simple (P/R/F)

Miwa et al. (P/R/F)

TEES (P/R/F)

Stanford (P/R/F)

Relative pronoun
Possessive pronoun
Demonstrative pronoun
Personal pronoun
Reflexive pronoun
Other pronoun
Definite noun phrase
Indefinite noun phrase
Uncategorised

68
58
6
25
â€“
â€“
38
4
3

72.7/82.4/77.2
59.3/60.3/59.8
35.3/100.0/52.2
84.0/84.0/84.0
â€“
â€“
50.0/31.6/38.7
â€“
â€“

75.0/83.8/79.2
66.7/51.7/58.3
â€“
57.7/60.0/58.8
â€“
â€“
60.0/15.8/25.0
â€“
â€“

91.3/30.9/46.2
89.5/29.3/44.2
â€“
100.0/16.0/27.6
â€“
â€“
â€“
100.0/75.0/85.7
â€“

â€“
45.7/36.2/40.4
â€“
38.5/20.0/26.3
â€“
â€“
9.1/21.1/12.7
â€“
â€“

Overall (P/R/F)

202

63.4/64.4/63.9

68.8/53.5/60.2

90.0/22.3/35.7

9.4/16.8/12.1

where an anaphor is a personal pronoun, or a definite noun phrase,
rather than the biological entities of relevance in the data.
In contrast, the TEES system, a domain-specific system developed using a machine learning approach, achieved the highest precision in overall performance amongst these systems. It achieved
the highest F-score (85.7%) in the coreference pairs where the anaphor is an indefinite noun phrase, whilst the other three systems
failed to identify coreference links of this type. However, the system achieved lower recall overall, leading to an F-score of 35.7%.
The TEES system achieved even lower recall than the general system in the classes of possessive and personal pronouns.
The Simple and Miwa et al. domain-specific systems have been
developed using a rule-based approach. These two systems
achieved higher performance overall than the Stanford and TEES
systems. With a set of rules including syntactic and semantic constraints, those rule-based systems identified more correct coreference links. With a substantial increase of recall, the Miwa et al.
system outperformed the previous systems that participated in
the Protein Coreference task at BioNLP 2011.
We summarise the performance of these systems based on the
standard metrics of precision, recall and F-score, presented in
terms of the categorisation of anaphor types and the category of
characteristics of coreference links in Table 5. Significance testing
is not considered for this analysis due to the small number of data
points in some categories; significance testing for categories that
have more data was carried out and is discussed in Section 5.
Our observations of several aspects that resulted in low performance of those systems, using the class-based analysis, are
described as below.
Failure of the Stanford system to generalise to the biomedical literature. Whilst the BioNLP-CR-Dev corpus contains only 3 identical
coreference links, the Stanford system identified 349 coreference
links of this type; these were all treated as false positives by the
evaluation measurement. The system also identified a large number of uncategorised coreference links, which are all considered

to be false positives. Our analysis in Table 5 shows no relative pronouns are identified by the system. This is a result of the corpus
used to develop this system, the OntoNotes [48] corpus, which
does not contain relative pronouns.
Limiting analysis to withinâ€“sentence relation. No tested system
handles coreference relations that cross sentence boundaries well.
As shown in the Cross-sentence columns of Table 5, the TEES system completely failed to identify those coreference relations, and
the Miwa et al. system and our Simple system achieved F-score
20.2% and 12.4%, respectively, for this category. In contrast, the
two systems achieved higher performance for the Internalsentence category with F-score 62.1% and 53.3%. It can be observed
that most coreference relations involving definite noun phrases
occur across sentence boundaries. This limitation consequently
impacted performance on Definite noun phrase coreference;
explaining the lower performance in this class, as seen in Table 4.
Disregard of identical relation. Rule-based and biomedical
domain-specific systems such as the Miwa et al. system and our
Simple system do not handle the Identical type of coreference
relation at all. On the other hand, the Stanford system identified
several identical coreference links. Since the task of the Stanford
system is to identify all mentions that refer the same entities,
identical mentions are detected in the Exact string match sieve
by priority. Note again, however, that there are only three of this
type of relation annotated in the BioNLP-CR-Dev data, so this
functionally hurts the precision of the Stanford system in this
category.
Disregard of head-word matched relation. There are 26 headword matched relations in the BioNLP-CR-Dev data, and they
involve definite noun phrases. TEES failed to identify any of these
relations, whilst the Miwa et al. system and our Simple system also
achieved low performance of F-score 12.5% and 20.7% respectively.
The recall of the Miwa et al. system and our Simple system, 7.7%
and 11.5% respectively, is below the recall of 23.1% of the general
Stanford system for these coreference relations.

Table 5
Analysis of performance across category by existing systems; Stanford, TEES, Miwa et al., our Simple system, and the domain entity adapted variant of Stanford, Stanford-BioNER, comparing to the gold standard corpus (the BioNLP-CRDev data). This analysis is conducted with the surface mode. (TP: True positive, FP: False positive, P: Precision, R: Recall, F: F-score, CS: Cross sentence, IS: Internal sentence, HM: Head-word match, IP: Including protein, IC: Including
coordinating conjunctions, IR: Identical relation, Rel P: Relative Pronoun, Pos P: Possessive Pronoun, Dem P: Demonstrative Pronoun, Per P: Person Pronoun, Ref P: Reflexive Pronoun, Oth P: Other Pronoun, Def NP: Definite NounPhrase,
Ind NP: Indefinite NounPhrase, Non: Uncategorised).
Gold Standard
CS

IS

HM

Stanford
IP

TEES

Miwa et al.

Simple

Stanford-BioNER

IR

CS

IS

HM

IP

IC

IR

CS

IS

HM

IP

IC

IR

CS

IS

HM

IP

IC

IR

CS

IS

HM

IP

IC

IR

CS

IS

HM

IP

IC

IR

0

269

0

51

16

0

TP
FP
FN

0
0
0

0
0
269

0
0
0

0
0
51

0
0
16

0
0
0

0
0
0

90
16
179

0
0
0

14
5
37

2
0
14

0
1
0

0
1
0

193
70
76

0
0
0

34
26
17

6
14
16

0
0
0

0
6
0

175
117
94

0
0
0

33
29
18

7
10
9

0
0
0

0
0
0

0
0
269

0
0
0

0
0
51

0
0
16

0
0
0

Pos P

12

75

0

43

2

0

TP
FP
FN

1
23
11

7
24
68

0
0
0

6
24
37

0
13
2

0
2
0

0
0
12

27
4
48

0
0
0

15
2
28

2
1
0

0
0
0

5
5
7

35
42
40

0
0
0

20
13
23

1
5
1

0
0
0

2
14
10

24
47
51

0
0
0

18
42
25

0
5
2

0
0
0

0
25
12

7
24
68

0
0
0

5
25
38

0
12
2

0
2
0

Dem P

1

8

0

2

3

0

TP
FP
FN

0
1
1

0
1
8

0
0
0

0
1
2

0
0
3

0
1
0

0
0
1

0
0
8

0
0
0

0
0
2

0
0
3

0
0
0

0
0
1

0
0
8

0
0
0

0
0
2

0
0
3

0
0
0

0
15
1

6
9
2

0
0
0

1
8
1

2
5
1

0
0
0

0
1
1

0
1
8

0
0
0

0
1
2

0
0
3

0
0
0

Per P

5

30

0

15

5

0

TP
FP
FN

3
46
2

2
17
28

0
0
0

2
7
13

0
7
5

0
34
0

0
0
5

9
1
21

0
0
0

3
0
12

1
0
4

0
0
0

3
10
2

17
17
13

0
0
0

11
9
4

3
1
2

0
0
0

3
6
2

17
14
13

0
0
0

10
8
5

4
3
1

0
0
0

3
45
2

2
18
28

0
0
0

2
5
13

0
7
5

0
34
0

Ref P

0

1

0

0

0

0

TP
FP
FN

0
1
0

0
0
1

0
0
0

0
1
0

0
0
0

0
0
0

0
0
0

1
1
0

0
0
0

0
0
0

0
0
0

0
0
0

0
0
0

0
0
1

0
0
0

0
0
0

0
0
0

0
0
0

0
0
0

1
0
0

0
0
0

0
0
0

0
0
0

0
0
0

0
1
0

0
0
1

0
0
0

0
1
0

0
0
0

0
0
0

Oth P

0

1

0

0

0

0

TP
FP
FN

0
0
0

0
0
1

0
0
0

0
0
0

0
0
0

0
0
0

0
0
0

0
0
1

0
0
0

0
0
0

0
0
0

0
0
0

0
0
0

0
0
1

0
0
0

0
0
0

0
0
0

0
0
0

0
10
0

0
13
1

0
0
0

0
4
0

0
8
0

0
0
0

0
0
0

0
0
1

0
0
0

0
0
0

0
0
0

0
0
0

Def NP

36

27

26

25

13

1

TP
FP
FN

7
141
29

1
40
26

6
30
20

4
72
21

1
28
12

0
29
1

0
0
36

1
1
26

0
0
26

0
1
25

0
0
13

0
0
1

1
5
35

4
6
23

2
4
24

3
4
22

4
2
9

0
0
1

3
12
33

5
12
22

3
0
23

5
19
20

4
5
9

0
0
1

7
141
29

1
41
26

6
3
20

4
70
21

1
28
12

0
30
1

Ind NP

1

2

0

3

0

0

TP
FP
FN

0
9
1

0
13
2

0
2
0

0
9
3

0
2
0

0
6
0

0
0
1

2
0
0

0
0
0

2
0
1

0
0
0

0
0
0

0
0
1

0
0
2

0
0
0

0
0
3

0
0
0

0
0
0

0
0
1

0
0
2

0
0
0

0
0
3

0
0
0

0
0
0

0
9
1

0
12
2

0
2
0

0
8
3

0
2
0

0
6
0

Non

3

2

0

3

1

2

TP
FP
FN

0
536
3

0
122
2

0
37
0

0
176
3

0
95
1

0
277
2

0
0
3

0
0
2

0
0
0

0
0
3

0
0
1

0
0
2

0
1
3

0
2
2

0
0
0

0
0
3

0
1
1

0
0
2

0
0
3

0
0
2

0
0
0

0
0
3

0
0
1

0
0
2

0
529
3

0
111
2

0
37
0

0
190
3

0
87
1

0
27
2

Total

58

415

26

142

40

3

P
R
F

1.4
19.0
2.7

4.4
2.4
3.1

8.0
23.1
11.9

4.0
8.5
5.4

0.7
2.5
1.1

0
0
0

0
0
0

85.0
31.3
45.8

0
0
0

81.0
23.9
37.0

83.3
12.5
21.7

0
0
0

29.0
15.5
20.2

64.3
60.0
62.1

33.3
7.7
12.5

56.7
47.9
51.9

37.8
35.0
36.4

0
0
0

11.3
13.8
12.4

51.8
54.9
53.3

100.0
11.5
20.7

37.9
47.2
42.0

32.1
42.5
36.6

0
0
0

1.3
17.2
2.4

4.6
2.4
3.2

8.0
23.1
11.9

3.5
7.7
4.9

0.7
2.5
1.1

0
0
0

M. Choi et al. / Journal of Biomedical Informatics 60 (2016) 309â€“318

IC

Rel P

315

316

M. Choi et al. / Journal of Biomedical Informatics 60 (2016) 309â€“318

contains a high-affinity binding site for its cytoplasmic inhibitor, I kappa B alpha. . ..

Table 6
Comparison of false negatives between our Simple system and Miwa et al. system
across types of anaphor in the protein mode on the BioNLP-CR-Dev dataset.
Class

Number

Simple

Miwa et al.

Intersection

Relative pronoun
Possessive pronoun
Demonstrative pronoun
Personal pronoun
Reflexive pronoun
Other pronoun
Definite noun phrase
Indefinite noun phrase
Uncategorised

68
58
6
25
â€“
â€“
38
4
3

12
23
â€“
4
â€“
â€“
26
4
3

11
28
6
10
â€“
â€“
32
4
3

6
15
â€“
3
â€“
â€“
22
4
3

Overall (P/R/F)

202

72

94

53

In this example, both systems identify a coreference relation
between the anaphor its and the heterodimeric p50-p65 NF-kappa
B complex as its antecedent. This noun phrase is a closer mention
than the correct antecedent in the BioNLP-CR-Dev data, RelA
(p65) (in bold).
5.3. Inadequateness of significance testing
The analysis in Table 5 is presented without statistical significance testing due to the small number of data points (less than
60) in most categories. We present in Table 7 the significance testing results only for five categories â€“ Relative pronoun, Possessive
pronoun, Definite noun phrase, Internal-sentence relation and
Including-protein relation â€“ that have larger numbers of data
points (>60), as well as the total of all categories. For t-test calculation, we randomly selected 30 data from each system result,
and computed F-score for these random subsets. We repeated this
30 times. Across all of these comparisons, differences between the
Stanford and the Stanford-BioNER systems and the other three systems (TEES, Miwa et al., and Simple) are significant, whilst only a
small number of differences are significant between these the
domain-specific systems. Non-significant differences between systems are italicised in Table 7 and all other differences are significant at the 95% confidence interval. However, the numbers of
these categorisations are still small and not sufficient for a reliable
statistical significance test. We provide the results, but caution that
the significance testing may not be reliable for our dataset.

5. Discussion
Table 6 provides a breakdown of the false negatives of our Simple system and the Miwa et al. system. Amongst 202 coreference
relations involving protein and gene entities in the BioNLP-CRDev data, 53 coreference relations are ignored by both systems.
Each system also failed to identify coreference relations involving
indefinite noun phrases, as well as other uncategorised relations.
A total of 15 coreference relations where the anaphor is a possessive pronoun, and 22 coreference relations involving definite noun
phrases, are not detected by either system. We study definite noun
phrases in more detail in the next section.
5.1. Failure of definite noun phrase
Coreference resolution involving definite noun phrases is not an
easy task in the biomedical domain. As seen in Table 4, each system
achieved lower F-score on coreference resolution involving definite
noun phrases as compared to other classes of anaphor. Both our
Simple system and the Miwa et al. system failed to identify a common set of 22 definite noun phrases out of 38 in the BioNLP-CRDev data. The unhandled definite noun phrases are long mentions
consisting of more than three words, such as this labile inhibitor, the
inductions of the IE genes, or this guanine nucleotide binding protein.
It seems that such rule-based systems have a trouble with anaphoric mentions that are longer definite noun phrases.

5.4. Benefits of proposed categorisation system
In this research, we introduce a framework to categorise syntactic and semantic characteristics of coreference relations annotated
in a biomedical corpus, identifying specific types of anaphoric
mentions. As shown in Table 5, we have also analysed the performance of several existing systems based on this framework, and
were able to understand the failures of those coreference resolution systems in detail.
We have identified that the Stanford system mainly finds identical relations, and does not resolve indirect anaphoric mentions
and their antecedents. This indicates that the system has been
designed to address a resolution task with different scope and
emphasis than evident in the BioNLP coreference corpus. We have
also observed that the TEES system is limited to determination of
coreference relations where anaphoric mentions and their antecedents occur within a single sentence.
In addition to such detailed error analysis, the proposed
framework gives us insights into strategies to achieve further
improvement. Differentiated approaches based on each type of

5.2. Bias toward selection of candidates closest to antecedent
Most rule-based coreference resolution systems determine an
antecedent by considering the candidates closest to an anaphor
in the linear sequence of the text. The following example is a case
in which both our Simple system and Miwa et al. system identified
an incorrect coreference relation.
. . .RelA (p65) functions as the critical transactivating component of [the heterodimeric p50-p65 NF-kappa B complex] and

Table 7
Results of paired t-test for coreference resolution systems. At the 95% confidence interval, a score of 1:699 indicates a significant difference. Italicised numbers are not significant
whilst all other differences are significant. A: Stanford system, B: TEES, C: Miwa et al., D: Simple system, and E: Stanford BioNER (Rel.: Relative, Pos.: Possessive, Def. NP: Definite
NounPhrase, IS: Internal sentence, IP: Including protein).
Rel. pronoun
A
A
B
C
D

B

Pos. pronoun
C

19.85

D
55.45
3.73

E
35.14
0.87
5.88

n/a
19.85
55.45
35.14

IS relation
A
B
C
D

20.03

A

B

Def. NP
C

16.04

D
20.54
0.20

E
10.59
7.98
9.56

IP relation
37.00
0.53

28.98
3.41
8.24

4.29
20.02
36.93
28.90

15.89

A

2.46
17.14
19.79
11.18

B

C

D

E

7.85

3.14
7.77

6.23
11.21
2.84

5.04
7.80
3.19
6.28

15.95

28.75
1.91

24.40
2.33
7.40

0.37
15.95
28.66
24.23

All
26.15
2.00

20.34
0.84
9.56

2.85
16.11
19.79
20.91

M. Choi et al. / Journal of Biomedical Informatics 60 (2016) 309â€“318

an anaphoric mention can be considered. For example, syntactic
parsing information is crucial for determination of coreference
relations involving relative pronouns, since a majority of their
antecedents appear directly before the relative pronouns, or close,
that is, within a 10-character span within a sentence boundary. On
the other hand, 36 out of 63 coreference relations involving definite noun phrases are linked across sentences as seen in Table 5.
By taking advantage of the framework, we can identify where
existing systems need to improve performance. We expect that a
differentiated approach, in which individual types of coreference
relations are specifically addressed, will help to improve the ability
to automatically resolve coreference expressions in the published
biomedical literature.
5.5. Challenges of domain adaptation
5.5.1. Different scope in coreference resolution task
The Stanford system generally performs poorly on coreference
resolution in biomedical annotated corpora. This is not a surprising
result, since the Stanford system was developed for more general
English text, including tasks such as speaker identification and
coreference chain (a set of coreferring expressions) identification
in the newswire text, and hence emphasises identical relations.
The gold standard corpora we have tested, in contrast, consist of
coreference relations where anaphoric mentions are mainly
pronominal mentions such as relative pronouns, personal pronouns, and definite noun phrases. Many of the Stanford system
false positives found in our analysis are linguistically valid coreference relationships, but they are nevertheless treated as false positives with respect to the gold standard corpora. The BioNLP-ST
coreference corpora define a different scope for the coreference
resolution task than the Stanford system.
5.5.2. Controlling the NER module
Performance differences between the Stanford system and
domain-specific systems are substantial as described in Table 4.
The Stanford system is at a distinct disadvantage without the use
of domain-specific NER. Therefore, we performed an additional
experiment in which we retrained the NER classifier for biological
entities with the gold standard annotations as the BioNLP-CRTrain data using the Stanford named entity recognizer system
[49]. We replaced the system-generated NER module in the Stanford system with the biomedical NER classification model, in order
to study the impact specifically of entity recognition on the coreference resolution task.
In order to assess the impact of the domain-tailored Stanford
system, we have evaluated the modified Stanford system with
the biomedical NER classification module on the gold corpus. However, this change barely impacted the overall performance of the
system, as shown in Table 5. This result clearly shows that making
use of a domain-specific NER module is not sufficient. We speculate that deterministic rules relevant to domain-specific knowledge are required for coreference resolution. For example,
entities labelled with proteins and genes preferred as antecedents
for definite noun phrases, since the number of coreference relations involving definite noun phrases including protein entities is
244 out of 338 coreference relations involving definite noun
phrases in the BioNLP-CR-Train data as summarised in Table 2
(Stanford-BioNER columns). For future work, we will further investigate domain-specific rules for adaptation of the Stanford system
to the biomedical domain.
5.6. Performance comparison between rule-based and supervised
approaches
Our analysis shows that performance difference between systems using a machine learning approach and a rule-based

317

approach is substantial amongst domain-specific systems for
coreference resolution. The TEES and UUtah systems using supervised approaches achieved higher precision than rule-based systems. The TEES system achieved overall precision of 90% on the
BioNLP-CR-Dev data as shown in Table 4. In particular, the system
is dominant for the resolution of indefinite noun phrases which are
ignored by rule-based systems. This system also achieved precision
of 85% at the Internal-sentence relation, and 81% at the Includingprotein relation in detail as seen in Table 5. However, the TEES system achieved lower recall, reducing system performance overall.
On the other hand, rule-based systems outperformed the supervised systems with an absolute increase of recall, but achieved
lower precision than the supervised systems. Rules tailored to
specific cases derived from the gold standard corpora can enable
improvements in recall; thus more targeted or more sophisticated
rules are required for further improvements in certain types of
coreference mentions such as indefinite noun phrases, that existing
rule-based systems have not considered.
6. Conclusion
In this article, we have propose a framework based on our analysis of coreference annotations in the biomedical literature that
categorises anaphoric mentions by type, and also categorises coreference relations in terms of the characteristics of their antecedents.
This proposed framework has benefits for detailed error analysis of
performance of existing coreference resolution systems, as we
identify limitations of those systems in reference to the categorisation. This in turn provides insights for further study.
We have used our framework to compare the performance of a
state-of-the-art general system with domain-specific systems on
coreference resolution in a biomedical corpus. It is observed that
the main factor that decreases performance of the general system
is the different scope of the task definition for coreference resolution
between the newswire domain and the biomedical domain. The general system put more focus on the tasks of speaker identification and
coreference chain identification, whilst the biomedical corpus we
have used for evaluation consists of pairs of an anaphor and its antecedent, and the anaphors are mainly pronouns and definite noun
phrases. The false positives by the general system found in our analysis are linguistically valid coreference relationships, but they are
treated as false positives regarding to the biomedical corpus.
In spite of this difference in scope, the general system has
demonstrated superior recall performance to that of domainspecific systems with a sophisticated rule-based approach on certain coreference resolution cases, involving the Cross-sentential
and Head-word matched relations. However, the general system
we have tested is inappropriate for direct application in the
biomedical domain, since the manually created rules are dependent on the general texts, and domain-specific information is
essential for coreference resolution in the biomedical domain.
As a result of our study, we can identify several promising directions for improvement in biomedical coreference resolution. In
particular, there is still much scope to better resolve definite noun
phrases. With domain-specific knowledge, sophisticated
approaches for handling coreference relations involving cross sentence boundaries and head-word matches would be expected to
yield significant performance gains.
Acknowledgements
We thank Riza Batista-Navarro and Sophia Ananiadou for providing the output of the Miwa et al. (2012) coreference resolution
system. This work was supported by the Australian Federal and
Victorian State governments and the Australian Research Council

318

M. Choi et al. / Journal of Biomedical Informatics 60 (2016) 309â€“318

through the ICT Centre of Excellence program, National ICT Australia (NICTA), through a scholarship to Miji Choi. The project also
receives funding from the Australian Research Council through a
Discovery Project Grant, DP150101550.

References
[1] A.M. Cohen, W.R. Hersh, A survey of current work in biomedical text mining,
Brief. Bioinf. 6 (1) (2005) 57â€“71.
[2] J.-D. Kim, T. Ohta, S. Pyysalo, Y. Kano, J. Tsujii, Overview of bionlpâ€™09 shared
task on event extraction, in: Proceedings of the Workshop on Current Trends in
Biomedical Natural Language Processing: Shared Task, Association for
Computational Linguistics, 2009, pp. 1â€“9.
[3] J.-D. Kim, S. Pyysalo, T. Ohta, R. Bossy, N. Nguyen, J. Tsujii, Overview of bionlp
shared task 2011, in: Proceedings of the BioNLP Shared Task 2011 Workshop,
Association for Computational Linguistics, 2011, pp. 1â€“6.
[4] J.-D. Kim, Y. Wang, Y. Yasunori, The genia event extraction shared task, 2013
edition-overview, in: ACL 2013, 2013, p. 8.
[5] U. Stelzl, U. Worm, M. Lalowski, C. Haenig, F.H. Brembeck, H. Goehler, M.
Stroedicke, M. Zenkner, A. Schoenherr, S. Koeppen, et al., A human proteinprotein interaction network: a resource for annotating the proteome, Cell 122
(6) (2005) 957â€“968.
[6] K.-I. Goh, M.E. Cusick, D. Valle, B. Childs, M. Vidal, A.-L. BarabÃ¡si, The human
disease network, Proc. Nat. Acad. Sci. 104 (21) (2007) 8685â€“8690.
[7] A.L. Hopkins, Network pharmacology: the next paradigm in drug discovery,
Nat. Chem. Biol. 4 (11) (2008) 682â€“690.
[8] A.-L. Barabasi, Z.N. Oltvai, Network biology: understanding the cellâ€™s functional
organization, Nat. Rev. Genet. 5 (2) (2004) 101â€“113.
[9] M. Hewett, D.E. Oliver, D.L. Rubin, K.L. Easton, J.M. Stuart, R.B. Altman, T.E.
Klein, PharmGKB: the pharmacogenetics knowledge base, Nucl. Acids Res. 30
(1) (2002) 163â€“165.
[10] D.S. Wishart, D. Tzur, C. Knox, R. Eisner, A.C. Guo, N. Young, D. Cheng, K. Jewell,
D. Arndt, S. Sawhney, et al., HMDB: the human metabolome database, Nucl.
Acids Res. 35 (suppl. 1) (2007) D521â€“D526.
[11] G. Joshi-Tope, M. Gillespie, I. Vastrik, P. Dâ€™Eustachio, E. Schmidt, B. de Bono, B.
Jassal, G. Gopinath, G. Wu, L. Matthews, et al., Reactome: a knowledge base of
biological pathways, Nucl. Acids Res. 33 (suppl. 1) (2005) D428â€“D432.
[12] S. Ananiadou, S. Pyysalo, J. Tsujii, D.B. Kell, Event extraction for systems
biology by text mining the literature, Trends Biotechnol. 28 (7) (2010) 381â€“
390.
[13] C. Li, M. Liakata, D. Rebholz-Schuhmann, Biological network extraction from
scientific literature: state of the art and challenges, Brief. Bioinf. 15 (5) (2014)
856â€“877.
[14] M. Miwa, R. SÃ¦tre, J.-D. Kim, J. Tsujii, Event extraction with complex event
classification using rich features, J. Bioinf. Comput. Biol. 8 (01) (2010) 131â€“
146.
[15] J.-D. Kim, T. Ohta, S. Pyysalo, Y. Kano, J. Tsujii, Extracting bio-molecular events
from literatureâ€”the BIONLP09 shared task, Comput. Intell. 27 (4) (2011) 513â€“
540.
[16] C. Li, M. Liakata, D. Rebholz-Schuhmann, Biological network extraction from
scientific literature: state of the art and challenges, Brief. Bioinf. 15 (5) (2014)
856â€“877, http://dx.doi.org/10.1093/bib/bbt006. <http://bib.oxfordjournals.
org/content/15/5/856.full.pdf+html>, <http://bib.oxfordjournals.org/content/
15/5/856.abstract>.
[17] J.A. Vanegas, S. Matos, F.A. Gonzalez, J.L. Oliveira, An overview of biomolecular
event extraction from scientific documents, Comput. Math. Meth. Med.
<http://downloads.hindawi.com/journals/cmmm/aip/571381.pdf>.
[18] T. Groza, K. Verspoor, Automated generation of test suites for error analysis of
concept recognition systems, in: Proceedings of Australasian Language
Technology Association Workshop, Melbourne, Australia, 2014, pp. 23â€“31.
[19] C. Aone, S.W. Bennett, Evaluating automated and manual acquisition of
anaphora resolution strategies, in: Proceedings of the 33rd Annual Meeting on
Association for Computational Linguistics, Association for Computational
Linguistics, 1995, pp. 122â€“129.
[20] W.M. Soon, H.T. Ng, D.C.Y. Lim, A machine learning approach to coreference
resolution of noun phrases, Comput. Linguist. 27 (4) (2001) 521â€“544.
[21] V. Ng, C. Cardie, Improving machine learning approaches to coreference
resolution, in: Proceedings of the 40th Annual Meeting on Association for
Computational Linguistics, Association for Computational Linguistics, 2002,
pp. 104â€“111.
[22] J. Zheng, W.W. Chapman, T.A. Miller, C. Lin, R.S. Crowley, G.K. Savova, A system
for coreference resolution for the clinical narrative, J. Am. Med. Inf. Assoc. 19
(4) (2012) 660â€“667.
[23] A. Haghighi, D. Klein, Simple coreference resolution with rich syntactic and
semantic features, Proceedings of the 2009 Conference on Empirical Methods
in Natural Language Processing, vol. 3, Association for Computational
Linguistics, 2009, pp. 1152â€“1161.
[24] H. Lee, Y. Peirsman, A. Chang, N. Chambers, M. Surdeanu, D. Jurafsky, Stanfordâ€™s
multi-pass sieve coreference resolution system at the CoNLL-2011 shared task,
in: Proceedings of the Fifteenth Conference on Computational Natural
Language Learning: Shared Task, Association for Computational Linguistics,
2011, pp. 28â€“34.

[25] K. Raghunathan, H. Lee, S. Rangarajan, N. Chambers, M. Surdeanu, D. Jurafsky,
C. Manning, A multi-pass sieve for coreference resolution, in: Proceedings of
the 2010 Conference on Empirical Methods in Natural Language Processing,
Association for Computational Linguistics, 2010, pp. 492â€“501.
[26] S. Pradhan, L. Ramshaw, M. Marcus, M. Palmer, R. Weischedel, N. Xue, CoNLL2011 shared task: modeling unrestricted coreference in ontonotes, in:
Proceedings of the Fifteenth Conference on Computational Natural Language
Learning: Shared Task, Association for Computational Linguistics, 2011, pp. 1â€“
27.
[27] N. Nguyen, J.-D. Kim, J. Tsujii, Overview of the protein coreference task in
BioNLP shared task 2011, in: Proceedings of the BioNLP Shared Task 2011
Workshop, Association for Computational Linguistics, 2011, pp. 74â€“82.
[28] J.-D. Kim, N. Nguyen, Y. Wang, J. Tsujii, T. Takagi, A. Yonezawa, The genia event
and protein coreference tasks of the BioNLP shared task 2011, BMC Bioinf. 13
(suppl. 11) (2012) S1.
[29] Y. Kim, E. Riloff, N. Gilbert, The taming of reconcile as a biomedical coreference
resolver, in: Proceedings of the BioNLP Shared Task 2011 Workshop,
Association for Computational Linguistics, 2011, pp. 89â€“93.
[30] V. Stoyanov, C. Cardie, N. Gilbert, E. Riloff, D. Buttler, D. Hysom, Coreference
resolution with reconcile, in: Proceedings of the ACL 2010 Conference Short
Papers, Association for Computational Linguistics, 2010, pp. 156â€“161.
[31] M. Miwa, P. Thompson, S. Ananiadou, Boosting automatic event extraction
from the literature using domain adaptation and coreference resolution,
Bioinformatics 28 (13) (2012) 1759â€“1765.
[32] N. Nguyen, J.-D. Kim, M. Miwa, T. Matsuzaki, J. Tsujii, Improving protein
coreference resolution by simple semantic classification, BMC Bioinf. 13 (1)
(2012) 304.
[33] J. BjÃ¶rne, T. Salakoski, Generalizing biomedical event extraction, in:
Proceedings of the BioNLP Shared Task 2011 Workshop, Association for
Computational Linguistics, 2011, pp. 183â€“191.
[34] H. Kilicoglu, S. Bergler, Adapting a general semantic interpretation approach to
biological event extraction, in: Proceedings of the BioNLP Shared Task 2011
Workshop, Association for Computational Linguistics, 2011, pp. 173â€“182.
[35] D. Tuggener, M. Klenner, G. Schneider, S. Clematide, F. Rinaldi, An incremental
model for the coreference resolution task of BioNLP 2011, in: Proceedings of
the BioNLP Shared Task 2011 Workshop, Association for Computational
Linguistics, 2011, pp. 151â€“152.
[36] M. Recasens, L. MÃ rquez, E. Sapena, M.A. MartÃ­, M. TaulÃ©, V. Hoste, M. Poesio, Y.
Versley, Semeval-2010 task 1: coreference resolution in multiple languages,
in: Proceedings of the 5th International Workshop on Semantic Evaluation,
Association for Computational Linguistics, 2010, pp. 1â€“8.
[37] K. Ravikumar, K.B. Wagholikar, H. Liu, Towards pathway curation through
literature mining â€“ a case study using pharmGKB, in: Proceedings of Pacific
Symposium of Biology, World Scientific, 2014, pp. 352â€“363.
[38] K. Taha, Extracting various classes of data from biological text using the
concept of existence dependency, IEEE J. Biomed. Health Inf. 6 (2) (2015)
1918â€“1928.
[39] M.-C. De Marneffe, C.D. Manning, The Stanford typed dependencies
representation, in: Coling 2008: Proceedings of the workshop on CrossFramework and Cross-Domain Parser Evaluation, Association for
Computational Linguistics, 2008, pp. 1â€“8.
[40] Y. Miyao, J. Tsujii, Probabilistic disambiguation models for wide-coverage
HPSG parsing, in: Proceedings of the 43rd Annual Meeting on Association for
Computational Linguistics, Association for Computational Linguistics, 2005,
pp. 83â€“90.
[41] C.D. Manning, M. Surdeanu, J. Bauer, J. Finkel, S.J. Bethard, D. McClosky, The
stanford CoreNLP natural language processing toolkit, in: Proceedings of 52nd
Annual Meeting of the Association for Computational Linguistics: System
Demonstrations, 2014, pp. 55â€“60.
[42] H. Lee, A. Chang, Y. Peirsman, N. Chambers, M. Surdeanu, D. Jurafsky,
Deterministic coreference resolution based on entity-centric, precisionranked rules, Comput. Linguist. 39 (4) (2013) 885â€“916.
[43] E. Charniak, M. Johnson, Coarse-to-fine n-best parsing and MaxEnt
discriminative reranking, in: Proceedings of the 43rd Annual Meeting on
Association for Computational Linguistics, Association for Computational
Linguistics, 2005, pp. 173â€“180.
[44] D. McClosky, Any Domain Parsing: Automatic Domain Adaptation for Natural
Language Parsing, Ph.D. Thesis, Brown University, 2010.
[45] M.-C. De Marneffe, B. MacCartney, C.D. Manning, et al., Generating typed
dependency parses from phrase structure parses, in: Proceedings of LREC, vol.
6, 2006, pp. 449â€“454.
[46] R. Leaman, G. Gonzalez, et al., Banner: an executable survey of advances in
biomedical named entity recognition, in: Pacific Symposium on Biocomputing,
vol. 13, 2008, pp. 652â€“663.
[47] J.-D. Kim, T. Ohta, Y. Tateisi, J. Tsujii, Genia corpusa semantically annotated
corpus for bio-textmining, Bioinformatics 19 (suppl. 1) (2003) i180â€“i182.
[48] E. Hovy, M. Marcus, M. Palmer, L. Ramshaw, R. Weischedel, Ontonotes: the 90%
solution, in: Proceedings of the Human Language Technology Conference of
the NAACL, Companion Volume: Short Papers, Association for Computational
Linguistics, 2006, pp. 57â€“60.
[49] J.R. Finkel, T. Grenager, C. Manning, Incorporating non-local information into
information extraction systems by gibbs sampling, in: Proceedings of the 43rd
Annual Meeting on Association for Computational Linguistics, Association for
Computational Linguistics, 2005, pp. 363â€“370.

