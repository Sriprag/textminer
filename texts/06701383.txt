824

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 3, MAY 2014

Web-Based Workflow Planning Platform Supporting
the Design and Execution of Complex Multiscale
Cancer Models
Vangelis Sakkalis, Stelios Sfakianakis, Eleftheria Tzamali, Kostas Marias, Member, IEEE,
Georgios Stamatakos, Member, IEEE, Fay Misichroni, Eleftherios Ouzounoglou, Student Member, IEEE,
Eleni Kolokotroni, Dimitra Dionysiou, David Johnson, Steve McKeever, and Norbert Graf

Abstract—Significant Virtual Physiological Human efforts and
projects have been concerned with cancer modeling, especially in
the European Commission Seventh Framework research program,
with the ambitious goal to approach personalized cancer simulation based on patient-specific data and thereby optimize therapy decisions in the clinical setting. However, building realistic
in silico predictive models targeting the clinical practice requires
interactive, synergetic approaches to integrate the currently fragmented efforts emanating from the systems biology and computational oncology communities all around the globe. To further
this goal, we propose an intelligent graphical workflow planning
system that exploits the multiscale and modular nature of cancer
and allows building complex cancer models by intuitively linking/interchanging highly specialized models. The system adopts
and extends current standardization efforts, key tools, and infrastructure in view of building a pool of reliable and reproducible
models capable of improving current therapies and demonstrating
the potential for clinical translation of these technologies.
Index Terms—Cancer systems biology, clinical translation, computational oncology, personalized medicine, scientific workflows.

I. INTRODUCTION

T

HE extreme complexity of the natural phenomenon of
cancer in conjunction with the prevalence of the disease

Manuscript received April 30, 2013; revised September 4, 2013 and November 15, 2013; accepted December 20, 2013. Date of publication January 2, 2014;
date of current version May 1, 2014. This work was supported in part by the
European Commission under the Transatlantic Tumor Model Repositories - TUMOR (FP7-ICT-2009.5.4-247754) and the Computational Horizons In Cancer
- CHIC (FP7-ICT-2011.5.2-600841) projects.
V. Sakkalis, S. Sfakianakis, E. Tzamali, and K. Marias are with the Institute of Computer Science, Foundation for Research & Technology—Hellas,
GR-70013 Heraklion, Greece (e-mail: sakkalis@ics.forth.gr; ssfak@ics.forth.
gr; tzamali@ics.forth.gr; kmarias@ics.forth.gr).
G. Stamatakos, F. Misichroni, E. Ouzounoglou, E. Kolokotroni, and D.
Dionysiou are with the Institute of Communication and Computer Systems,
School of Electrical and Computer Engineering, National Technical University of Athens, GR-15780 Athens, Greece (e-mail: gestam@central.ntua.gr;
faymisi@central.ntua.gr; elouzou@central.ntua.gr; ekolok@central.ntua.gr;
dimdio@esd.ece.ntua.gr).
D. Johnson is with the Department of Computing, Imperial College London,
London, SW7 2AZ, U.K. (e-mail: david.johnson@imperial.ac.uk).
S. McKeever is with the Department of Informatics and Media, Uppsala University, 75120 Uppsala, Sweden (e-mail: steve.mckeever@im.uu.se).
N. Graf is with the Department of Pediatric Hematology and Oncology, Saarland University Hospital, 66421 Homburg, Germany (e-mail:
Norbert.Graf@uniklinikum-saarland.de).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2013.2297167

have dictated the development of highly demanding mathematical and computational cancer models aiming at optimizing the
individualized clinical decisions. Already a great diversity of
cancer related models exist, focusing on various aspects of this
complex phenomenon at different levels [1]. In the past decade,
it has become evident that multiscale methods need to be applied to cancer modeling. This is to address the various phases
and scales using several levels of biocomplexity [2].
In general, two strategies to model the multiscale cancer phenomenon may be identified. The bottom-up approach that follows an inductive synthesis tactic when trying to predict the
tumor growth by focusing on linking together the elementary
biological components of the underlying mechanisms and the
top-down deductive decomposition design that phenotypically
models the whole system without specifying in great detail the
lower scales in terms of biocomplexity, e.g., molecular scale.
Obviously, the second approach is much easier to manipulate
and much closer to clinical translation.
In the computational oncology domain, microscopic models
attempt to describe the individual cell dynamics focusing on the
subcellular and cellular levels. On the other hand, the macroscopic models focus on tissue-level and assume that the solid
tumor behavior can be predicted by simulating the behavior of
a group of cells and their global interaction with the surrounding and underlying tissue properties [3]–[6]. In order to produce
accurate and reliable models both approaches are equally important. In other words, one should be able to fine tune macroscopic
models using microscopic meaningful parameters.
From the mathematical point of view, such approaches to address the multifaceted cancer phenomenon may be grouped into
three main categories; the continuous and discrete methods, as
well as the hybrid approaches [7]–[9]. Continuous approaches
describe both cancer cell populations and their microenvironment (such as nutrients or signaling cues) using continuous
variables formulating a system of partial differential equations,
whereas discrete approaches describe cells as discrete elements
that can change states and evolve in discretized time based on
the changing dynamics (ruled by deterministic or probabilistic
laws), i.e., cellular automaton models [9] and agent-based models [10]. Hybrid approaches combine the benefits of continuous
and discrete mathematics and offer the possibility of integrating
phenomena of different time and length scales (from the tissue
scale, for example, modeling neovascularization, to intracellular processes such as cell signaling and progression through

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

SAKKALIS et al.: WEB-BASED WORKFLOW PLANNING PLATFORM SUPPORTING THE DESIGN AND EXECUTION

the cell cycle). These models describe cancer cells as discrete
variables and the tumor microenvironment using continuous,
reaction–diffusion equations as opposed to the typical discrete
models.
Digging deeper into the mathematical foundations of most
clinically oriented continuous models one has to deal with different numerical methods for approximating the solutions to
PDEs (e.g., finite differences or finite elements) that involve
different assumptions and convergence rates [11].
It is obvious from the above that there is no single gold standard or all-encompassing model that achieves the best possible
results in all heterogeneous cancer types under study. What
is most critical to the success of computational oncology, and
more specifically to the success of in silico systems modeling,
is to promote the interaction and collaboration among modelers, experimentalists, clinicians, and other specialists so as to
develop advanced multicompartmental models of cancer development and response to treatment. Efforts on an international
and even intercontinental level have already started in the course
of the TUMOR project as a proof of concept and the results are
promising [12].
The systems biology community has been particularly active in standardizing the way to formulate, store, exchange,
and integrate biological models with growing number of community driven initiatives [13] to harmonize the development
of the various standards and formats in systems biology, e.g.,
COMBINE [14]. However, there has not yet been any formal
standardization efforts specifically tailored to the cancer modeling specific needs, aside from the TumorML language [15] that
has been delivered out of the TUMOR project.
In addition, there are still important problems when dealing
with scale and model linking. In order to translate models in
the clinical setting as decision support tools, we should migrate
from systems biology models to clinically driven models that are
motivated by actual clinical problems and questions. Also, it is
necessary to involve large and diverse communities of scientists
closely collaborating with clinicians in the model development
and validation process.
In this paper, we present a web-based scientific workflow
planning platform (see Section IV) designed to support the development of complex multiscale cancer models aiming toward
engaging the wide cancer modeling audience (modelers, computational biologists, and clinicians) and encouraging scientists to
collaborate constructively. The underlying foundation involves
a dedicated model repository, parsing SBML, and TumorML
information, as well as executing both SBML and proprietary
models.
II. MODEL DESCRIPTION STANDARDS
To build the envisioned workflow environment, we had to select existing standards wherever possible and design new ones
to cover missing domains. The idea is to facilitate model linking
with no extra effort to port existing models to a new framework,
or reimplementing them, both costly and error prone activities.
Hence, the need to fuse disparate models together, in the presented platform, is addressed using the Systems Biology Markup

825

Language (SBML) to model the biochemical processes at the
molecular scales, whereas the higher and more clinically relevant scales, specific to cancer modeling, are addressed using the
newly developed TumorML markup language.
A. SBML
Among the numerous standards related to model description
at the subcellular level, CellML [16] and SBML [17] are the
most widely accepted. Both attempt to describe the structure
and underlying mathematics of subcellular models. SBML is
more specific and constrained in exchanging information about
pathway and reaction models and uses successive hierarchical
declarations of model constituents. There is also a wide community supporting SBML and tools to convert CellML to SBML.
We prefer SBML mainly based on its constrained nature, which
allows the language to be adopted quickly and evolve with the
requirements of the representation and understanding of systems
biology.
B. TumorML
The higher scale models enrolled in our environment are described using TumorML [15], an XML-based markup language
for describing cancer models. The development of TumorML
contributes to enabling some of the key interoperability aims
within the TUMOR project.
First, by annotating cancer models with appropriate document
metadata, digital curation is facilitated in order to make publishing, search, and retrieval of cancer models easier for researchers
and clinicians using the TUMOR digital repository. Second,
markup will be used to describe abstract interfaces to published
implementations allowing execution frameworks to run simulations using published models. Finally, TumorML markup facilitates the composition of compound models, regardless of scale
and source, enabling multiscale models to be developed in a
modular fashion, and models from all around the globe may be
integrated with any related models in the TUMOR transatlantic
platform. The TumorML model description will also incorporate and integrate with the MIRIAM guidelines [18] in order to
provide reference correspondence, attribution annotation, and
external resource semantic annotation to the described models.
III. MODEL EXECUTION
There are two main execution frameworks in the TUMOR
platform. The first is based on the SBML description of a model
whereas the second one is more generic in the sense that a model
can be provided as a self-contained executable. An SBML description of a model is a declarative artifact. It describes the
mathematics required, typically in the form of ordinary differential equations (ODEs), to implement the model and nothing
else. In order to implement the model, a solver is required to numerically resolve the equations and execute the corresponding
reactions based on the kinetic laws and the prescribed parameter
values. This solver can be a simulation environment, a compiler
that links the SBML file with numerical library and generates
a standalone executable or a partial evaluator that attempts to

826

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 3, MAY 2014

unfold the ODEs with respect to known solving algorithms. In
general, the SBML models can be classified as deterministic or
stochastic, with the latter using Monte Carlo simulation and related methods. The TUMOR execution infrastructure supports
deterministic and stochastic models, through the incorporation
of the COPASI simulator [19]. The use of COPASI software
allows the parsing of SBML models and their execution but
nevertheless there are a couple of parameters that need to be
specified prior to the execution:
1) the simulation time for the model;
2) the algorithm to be used, e.g., deterministic, stochastic, or
hybrid.
These parameters are not specified by SBML but they are
essential in order for the models to produce the desired results.
In order to support flexibility, the users can input values for both
parameters at runtime. These parameter values are then passed
to the COPASI solver for simulating the models.
In the more generic case, the model is provided with no
information on its internals. The supplied code, either in binary
or in source format, should be able to be run as a command line
program with its inputs and outputs specified either as command
line options or as files. For example, if the execution framework
(as in our case) is a Linux 64-bit environment, the supplied
executable code should be compliant with it. Of course, in the
case where the source code of the model is available in the form
of a scripting language, like Python or Perl, there are fewer
restrictions imposed to the model creators.
Irrespective of the models’ type (SBML or generic/command
line formats), TumorML offers a generic metadata “envelope”
to describe both their interface, i.e., input parameters and output results, and execution requirements. The interface definition
provides valuable information for linking models in the workflow editor, based on the required input and the generated output.
On the other hand, the execution information is utilized from the
workflow’s runtime, when the models are simulated or executed.
IV. WORKFLOW DESIGN
Systems biology presents a new way to study biological systems shifting from a “reductionist” approach to a more holistic
one [20]. In this new perspective, the complex biological systems are not studied by the isolated analysis of their components
but through their investigation as whole integrated systems with
dynamic relationships among their parts.
As a first step, we argue that the use of scientific workflows
is a legitimate way to achieve this holistic view of systems
biology. In general, a workflow can be described as a sequence
of operations or tasks needed to manage a business process or a
computational activity. The latter definition can also be applied
to scientific workflows, which are meant to decompose complex
scientific experiments into a series of repetitive computational
steps that could be run on supercomputers or distributed on a
cloud system [21].
The proposed new scientific workflow management system
has been designed and built focusing exactly on the requirements
imposed by the domain users and scenarios. The main objectives
of this new workflow design system are the following.

1) To provide an easy, intuitive, and secure environment for
the design of integrative, predictive, computational models represented as scientific workflows. The activities or
steps in these workflows represent computational models
in the microscopic or macroscopic level that interact by
exchanging information through their adjustable parameters.
2) To follow a “Software as a Service” (SaaS) deployment approach. In particular, the system is accessible through the
WWW using state-of-the-art web protocols and follows a
cloud-based architecture in order to alleviate installation
and maintenance costs.
3) To support the visual representation of the models and their
simulation/execution at the workflow runtime by building
on the TumorML model descriptions.
4) To build upon an extensible architecture where the models
are stored in potentially disparate model repositories [22].
In terms of its architecture, the TUMOR workflow management system consists of two components:
1) The workflow editor (or designer), which is a web application, accessible through the users’ web browser. This is the
graphical front-end for the editing of the workflows, the
invocation of their execution, and the visualization of the
results. A depiction of its interface can be found in Fig. 1.
2) The workflow engine, which is responsible for the management and the execution of the workflows, the communication with the model repositories, etc.
The workflow designer depicts each model as a box with its
abstract interface (inputs and outputs) as little circles attached
to the model (see Fig. 1). The integration of the models into
a scientific workflow is then driven by the user through the
introduction of connecting lines between two model outputs and
inputs, in a familiar box-and-arrows diagram. The connecting
lines therefore represent “data-flow,” i.e., the flow of data from
an output of the source model to an input of the destination
model. At the workflow level, inputs of models that are “free”
(i.e., not connected) are used as inputs to the whole workflow
at the workflow evaluation (execution) phase. Similarly, not
connected outputs of models are used to provide the high level
results of the workflow execution.
The connections between two models representing flow of
data and information are not arbitrary but rather constrained
based on the information that the TumorML descriptions of
the models provide. In particular, the connected parameters are
checked both at the syntactic and the semantic level. At the syntactic level, the workflow designer validates that the parameters
to be connected have the same data type, e.g., they both represent
an integer or a character (string) value. At the semantic level,
the designer takes advantage of the semantic, MIRIAM-based,
annotation of the parameters in the TumorML descriptions in
order to make sure that they represent the same physiological
or biological entity. Additional checks include the validation
of the units used for the parameters and the range of values.
When the user tries to connect two models based on their outputs and inputs by the familiar “drag-and-drop” operation, the
application provides information on the matching parameters by
highlighting the corresponding connectors. Therefore, the users

SAKKALIS et al.: WEB-BASED WORKFLOW PLANNING PLATFORM SUPPORTING THE DESIGN AND EXECUTION

Fig. 1.

827

Proposed workflow designer represents each model as a box with its abstract interface (inputs and outputs) as little circles attached to the model.

can get an immediate visual indication when a connection between two models is legitimate or not, based on syntactic (e.g.,
data type) and the semantic (e.g., units, high level ontology
annotation).
The search and discovery of the models is supported by the
workflow engine, which has been configured to contact a certain
list of model repositories. As noted previously, the model repositories need to comply with specific architectural constraints,
notably the use of TumorML for describing the models and a
set of web service interfaces for querying the models, based on
the TumorML defined metadata, and retrieving their definitions.
In addition to this model query and retrieval functionality, the
workflow engine is responsible for the user authentication, the
storage and retrieval of the workflow definitions, and, last but not
least, the execution of the user defined workflows. The execution
of the workflow is implemented by first performing a topological sort of the workflow, since the constructed workflows are
in the form of directed acyclic graphs, in order to determine
the proper ordering of the model executions based on their data
dependencies (connections). Subsequently, the TumorML descriptions of the models are again consulted in order to identify
their execution requirements, and especially whether they are
realized as SBML or standalone, program-based, models. In the
case of the SBML models, the user is asked to provide additional simulation information, as explained previously, such as
the simulation time and the algorithm to be used. Alternatively,

the system validates that it can execute the standalone, command line program that represents the model. Such validation
includes the check for the execution framework compatibility
of the binary files (e.g., Linux 64-bit), since this is the currently
supported operating system and machine architecture.
When the user provides the input parameter values for the
workflow and any additional execution information needed, the
workflow engine starts the evaluation of each model based on
the given parameter values and the outputs of the preceding
models. During the execution of the workflow, the user is able
to “log out” of the application and the execution will continue
in a “headless” manner, i.e., running in the background, in the
server’s premises. On the other hand, if the user wants, they can
even monitor the execution of the workflow and have a visual
indication of which models are currently running and which are
about to be launched.
The results of the workflow are available after its successful
completion along with a detailed listing of all the intermediate
results and files produced. Therefore, an execution trace is produced and kept for future reference in the user’s account in order
to facilitate reproducibility and validation of the workflow.
V. EXEMPLAR CLINICAL SCENARIO
To test the presented framework and better evaluate the outcome, a complex clinically relevant scenario is presented as
a test case. The scenario addresses the case of glioblastoma

828

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 3, MAY 2014

receptor (EGFR) signaling, cancer metabolism, and the Oncosimulator, are indicated as different colored boxes.
The presented example reflects the multiscale fusion of three
independently developed cancer models (as depicted in Fig. 1),
in an attempt to link microscopic, genotype–phenotype characteristics of cancer cells into a macroscopic, tissue-level cancer model. Reprogramming of signaling, gene regulatory, and
metabolic pathways has been usually observed in cancer cells
affecting proliferation, migratory response, and other phenotypic characteristics [23], [24]. Furthermore, these microscopic
characteristics affect tumor evolution, morphology, invasion and
metastasis, as well as tumor response to treatment.
Although not incorporated in the presented case, it should
be stressed out that in a realistic scenario, cells are in a constant interaction with their microenvironment, which dynamically shapes their molecular pathways and phenotypic properties. Furthermore, tumors usually consist of heterogeneous
cell populations with different traits. Therefore, depending on
the structure and variables of the macroscopic model different instances of the subcellular modeling components (e.g.,
EGFR signaling and cancer metabolism) corresponding to alternative environmental conditions or/and genetic traits could be
incorporated.
A. EGFR Signaling Pathway-Based Model
The EGFR has been implicated in several cancers including lung cancer, breast cancer, and glioblastoma, yet the EGFR
activity itself is not capable of predicting the phenotype of cancer cells. As shown in Fig. 2 (top box), a microscopic, EGFR
gene-protein interaction network-based model has been developed [25]. Given initial concentrations of important molecules
in tumor microenvironment such as glucose, oxygen, and transforming growth factor α (TGFα), the model predicts whether the
cell proceeds to proliferation or migration. Specifically, when
the change in PLCγ concentration, an enzyme that lies downstream of EGFR pathway, is below the migration-threshold, then
cells prefer to proliferate than migrate. This key enzyme (depicted with a red arrow in Fig. 2) can be used to directly link
EGFR signaling and metabolism through its regulatory effect
on the rate of the metabolic reactions it catalyzes.
Fig. 2. First compartment of the simulated tumor evolution is the EGFRrelated molecular entity, which forms a gene-protein interaction network (grey
top box, modified figure from [25], with permission from Elsevier). The PLCγ,
a downstream element of the EGFR pathway is used to constrain the rates of
its corresponding metabolic reactions in the second genome-scale metabolic
modeling compartment (middle box, modified figure reprinted by permission
from Macmillan Publishers Ltd: Nat. Rev. Cancer [24], copyright 2004). The
metabolic model estimates the proliferation rate of the glycolytic cancer cells
providing a microscopic parameter to the tissue-level, macroscopic cytokinetic
model (lower box).

multiforme combined modality treatment using radiation therapy and chemotherapy with temozolomide. The anonymized
data were provided by the Institute of Pathology, University
Hospital of Saarland, Germany. Schematically, the simulated
modular tumor is illustrated in Fig. 2. The different modules,
which include glioblastoma-specific epidermal growth factor

B. Cancer Metabolic Model
Fig. 2 (middle box) shows the metabolic alteration of highly
proliferating cancer cells to inefficient-glycolysis regardless of
whether oxygen is present (aerobic glycolysis). This metabolic
reprogramming can be modeled utilizing genome-scale computational modeling approaches [26]. Based on the work of Shlomi
et al. [26], a genome-scale human metabolic network reconstruction consisting of 1496 ORFs, 3742 reactions, and 2766
metabolites [27], is used in order to account for the interconnectivity of the metabolic reactions. In addition, differentially expressed metabolic genes in glioblastoma multiforme [28], [29]
are used as flux constraints in the corresponding metabolic reactions for the construction of a cancer-specific model. The
concentration of PLCγ enzyme that is predicted by the EGFRsignaling-based model is also used to constrain the rates of

SAKKALIS et al.: WEB-BASED WORKFLOW PLANNING PLATFORM SUPPORTING THE DESIGN AND EXECUTION

829

the corresponding metabolic reactions. The model predicts the
reaction rates of the interconnected metabolic network, thus allowing the estimation of important cellular properties such as
oxygen and glucose uptake, lactate production, and cellular proliferation rate of cancer cells, which can feed the macroscopic
modeling approaches. The metabolic model also shows that the
proliferation rate is decreased when the PLCγ-related fluxes increase [30], in accordance with the observed tradeoff between
migration and proliferation.
C. Oncosimulator: The Macroscopic Tumor Model
In the Oncosimulator [31], the tumor region and surrounding
tissue(s) are represented by a 3-D cubic mesh of “geometrical
cells” (GCs, the elementary volume of the mesh). The GCs that
belong to the tumor region (occupied GCs) are assumed to contain a population of biological cancer cells. The cancer cells
residing within each occupied GC are distributed into five cell
categories, i.e., the stem (unlimited mitotic potential), limited
mitotic potential (LIMP), terminally differentiated, apoptotic
(cells that have died through apoptosis) and necrotic (cells that
have died through necrosis). Each stem or LIMP cell can be either proliferating residing in any of the cell cycle phases (G1, S,
G2, M) or dormant (G0). The macroscopic model adopts a cytokinetic model, which incorporates the biological mechanisms
of cell cycling, quiescence, differentiation, and loss (spontaneous, starvation-induced, and treatment-induced) [32]. The cytokinetic model regulates the transition between the considered
cell categories/phases. The morphological rules [32] that govern
cell movement throughout the tumor volume, aim at a realistic,
conformal to the initial shape of the tumor, simulation of expansion and shrinkage, in the cases of untreated tumor growth and
chemotherapy/radiotherapy treatment, respectively. The proliferation rate of cancer cells that is estimated by the previously described microscopic, signaling-metabolic interconnected models is used as input parameter to the macroscopic tumor model
(depicted with a green arrow in Fig. 2). Based on the tumor
imaging data, the occupied GCs are defined and the cancer cell
populations residing therein are initialized by assuming a typical cancer cell density of 106 biological cells/mm3 [32]. The
glioma imaging data module in Fig. 1 performs a set of image
processing tasks in order to isolate the tumor region of interest
that will be used as an input to the oncosimulator. This work has
been extensively addressed in [33] and [34]. The output of the
model is the time evolution of the various total cell categories
populations that comprise the tumor, allowing the evaluation
of treatment effectiveness in terms of treatment-induced tumor
regression.
D. Workflow Execution for the Exemplar Scenario
The three models are combined together into a scientific
workflow that can be seen in Fig. 1. The connections among
the models have an exact correspondence with the biological
interactions depicted in Fig. 2. The EGFR signaling pathwaybased model is realized through SBML, and therefore, it is
simulated using COPASI. The cancer metabolic model has been
implemented as a MATLAB script and executed by a server

Fig. 3. Final output of the scientific workflow combining the EGFR signaling,
the cancer metabolic model, and the Oncosimulator. Tumor cells increase until
therapy is applied where a steep decrease in the population is observed. The
effect of PLCγ rate on tumor evolution is also depicted. The output of all three
models is illustrated in the lower trace (PLC-g = 0.4), whereas the output of the
metabolic model (unconstrained with respect to PLCγ related reactions) and
the Oncosimulator is illustrated in the upper trace (PLC-g = 0).

installation of the MATLAB engine. Finally, the Oncosimulator
is provided as compiled C++ code that accepts its parameters
via input files or command line options. The output of the Oncosimulator is the final output of the workflow after a small
transformation step specified as a Unix shell script to produce
the evolution of the tumor in an image format.
Fig. 3 shows the effect on tumor evolution of changing a microscopic parameter (that is PLCγ flux constraint in metabolic
model) that drastically affects cellular proliferation time. As
mentioned previously, PLCγ rate is the outcome of EGFR signaling pathway and is used to constrain the corresponding reactions of the metabolic model. In the first example (depicted
with a dotted red line), the metabolic model is unconstrained
with respect to PLCγ molecule, contrary to the second example
(depicted with a dotted blue line), which shows the combined
outcome of the EGFR signaling, cancer metabolic model, and
the Oncosimulator.
VI. DISCUSSION
In this paper, we argue in favor of the adoption of the scientific
workflow paradigm for the implementation of complex models
in the domain of computational biomodeling.
We believe that this is a new application domain for the
workflow methodology, where workflows can prove to be extremely useful. There are already some popular workflow management systems, for the bioinformatics domain. Taverna [35]
is probably the most well-known and recently has augmented
its desktop version with a social networking website where the
users can share their Taverna-based workflows [36]. Galaxy is
a complete web-based workflow management system that features a user friendly, intuitive, “drag-and-drop” workflow editing

830

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 3, MAY 2014

functionality [37]. A detailed comparison of the currently available generic workflow systems may be found in [38].
However, neither of these tools focuses primarily on the VPH
community concerned with cancer modeling. Our rationale is
based on designing a tool to integrate models that have been individually tested and their integration addresses a valid workflow,
in the sense that the biomechanisms involved are compatible. In
the current design, the tool supports linking of models provided
by different research groups located worldwide and in order to
grant the accuracy of model simulations, the tool currently does
not allow feedback from one compartment to another allowing
parameters (e.g., in the microscopic model) to be re-estimated.
The decision to build a new work flow environment, as
opposed to reusing an existing one, was made after a thorough evaluation of existing workflow managing systems and
the project requirements of the TUMOR project in regard to
the computational oncology domain. The most important factor
for this decision was the particular architectural considerations
and more specifically the requirements for integrating different model repositories with dynamic content that is frequently
updated [39]. The adoption of a full web-based deployment
approach was also very important for this decision as realistic modeling platforms take even more advantage of cloud and
SaaS models of computation.
The proposed workflow planning software is provided as
“open source” upon request. More information may be found at
http://tumor-project.eu.
VII. CONCLUSION
Scientific workflows are important infrastructures for the implementation of in silico modeling in cancer research. In this
paper, we have described the design and a prototype implementation of a scientific workflow management system to support
research in computational oncology. The proposed model linking mechanism is expected to simplify the integration of existing cancer models currently developed individually and curated from sole and diverse communities. In the current version,
models described in SBML and TumorML may be linked and
executed. The final system will need of course to be evaluated
and further validated by the research community but in any case
it will be distributed as an open source software and provided
as an open access service over the WWW.
REFERENCES
[1] G. Stamatakos, “In silico oncology part I: Clinically oriented cancer
multilevel modeling based on discrete event simulation,” in Multiscale
Cancer Modeling, T. Deisboeck and G. Stamatakos, Eds. Boca Raton,
FL, USA: CRC Press, 2011, pp. 407–436.
[2] T. S. Deisboeck, Z. Wang, P. Macklin, and V. Cristini, “Multiscale cancer
modeling,” Annu. Rev. Biomed. Eng., vol. 13, no. 1, pp. 127–155, Aug.
2011.
[3] A. Roniotis, V. Sakkalis, I. Karatzanis, M. E. Zervakis, and K. Marias, “Indepth analysis and evaluation of diffusive glioma models,” IEEE Trans.
Inf. Technol. Biomed., vol. 16, no. 3, pp. 299–307, May 2012.
[4] V. Sakkalis, A. Roniotis, C. Farmaki, I. Karatzanis, and K. Marias, “Evaluation framework for the multilevel macroscopic models of solid tumor
growth in the glioma case,” in Proc. IEEE 32nd Eng. Med. Biol. Soc.
Conf., Buenos Aires, Argentina, 2010, pp. 6809–6812.

[5] A. Roniotis, G. C. Manikis, V. Sakkalis, M. E. Zervakis, I. Karatzanis, and
K. Marias, “High grade glioma diffusive modeling using statistical tissue
information and diffusion tensors extracted from atlases,” IEEE Trans.
Inf. Technol. Biomed., vol. 16, no. 2, pp. 255–263, Mar. 2011.
[6] P. P. Delsanto, C. A. Condat, N. Pugno, A. S. Gliozzi, and M. Griffa, “A
multilevel approach to cancer growth modeling,” J. Theor. Biol., vol. 250,
no. 1, pp. 16–24, Jan. 2007.
[7] L. B. Edelman, J. A. Eddy, and N. D. Price, “In silico models of cancer,”
Wiley Interdiscip. Rev. Syst. Biol. Med., vol. 2, no. 4, pp. 438–459, Jul./Aug.
2010.
[8] K. A. Rejniak and A. R. Anderson, “Hybrid models of tumor growth,”
Wiley Interdiscip. Rev. Syst. Biol. Med., vol. 3, no. 1, pp. 115–125, Jan./Feb.
2010.
[9] T. Alarcσn, T. Alarcón, H. M. Byrne, and P. K. Maini, “Towards wholeorgan modelling of tumour growth,” Prog. Biophys. Mol. Biol., vol. 85,
no. 2–3, pp. 451–472, Jun./Jul. 2004.
[10] Z. Wang, C. M. Birch, J. Sagotsky, and T. S. Deisboeck, “Cross-scale,
cross-pathway evaluation using an agent-based non-small cell lung cancer
model,” Bioinformatics, vol. 25, no. 18, pp. 2389–2396, Sep. 2009.
[11] A. Roniotis, K. Marias, V. Sakkalis, G. Stamatakos, and M. Zervakis,
“Comparing finite elements and finite differences for developing diffusive
models of glioma growth,” in Proc. IEEE 32nd Eng. Med. Biol. Soc. Conf.,
Buenos Aires, Argentina, 2010, pp. 6797–6800.
[12] V. Sakkalis, S. Sfakianakis, K. Marias, G. Stamatakos, F. Misichroni, D.
Dionysiou, S. McKeever, D. Johnson, T. S. Deisboeck, and N. Graf, “The
TUMOR project: integrating cancer model repositories for supporting predictive oncology,” presented at the Abstract Booklet VPH 2012 Integrative
Approaches Comput. Biomed., London, U.K., 2012.
[13] BioSharing Standards. (2009). [Online]. Available: http://www.
biosharing.org/standards.
[14] COMBINE—The Computational Biology Network. [Online]. Available:
http://mbine.org/
[15] D. Johnson, S. McKeever, G. Stamatakos, D. Dionysiou, N. Graf, V.
Sakkalis, K. Marias, Z. Wang, and T. S. Deisboeck, “Dealing with diversity
in computational cancer modeling,” Cancer Inf., vol. 12, pp. 115–124,
2013.
[16] C. M. Lloyd, M. D. Halstead, and P. F. Nielsen, “CellML: Its future,
present and past,” Prog. Biophys. Mol. Biol., vol. 85, no. 2–3, pp. 433–
450, Jun./Jul. 2004.
[17] M. Hucka, F. Bergmann, S. Hoops, S. M. Keating, S. Sahle, and
D. J. Wilkinson, “The Systems Biology Markup Language (SBML):
Language Specification for Level 3 Version 1,” Nature Precedings,
2010, doi:10.1038/npre.2010.4123.1.
[18] N. L. Novére, A. Finney, M. Hucka, U. S. Bhalla, F. Campagne, J. ColladoVides, E. J. Crampin, M. Halstead, E. Klipp, P. Mendes, P. Nielsen,
H. Sauro H, B. Shapiro, J. L. Snoep, H. D. Spence, and B. L. Wanner, “Minimum information requested in the annotation of biochemical
models (MIRIAM),” Nat. Biotech., vol. 23, no. 12, pp. 1509–1515, Dec.
2005.
[19] S. Hoops, S. Sahle, R. Gauges, C. Lee, J. Pahle, N. Simus, M. Singhal, L. Xu, P. Mendes, and U. Kummer, “COPASI—A complex pathway
simulator,” Bioinformatics, vol. 22, no. 24, pp. 3067–3074, Dec. 2006.
[20] A. C. Ahn, M. Tewari, C. Poon, and R. S. Phillips, “The limits of reductionism in medicine: Could systems biology offer an alternative?” PLoS
Med., vol. 3, no. 6, p. e208, May 2006.
[21] A. Belloum, E. Deelman, and Z. Zhao, “Scientific Workflows,” Scientific
Programming, vol. 14, no. 3, p. 171, 2006.
[22] S. Sfakianakis, V. Sakkalis, K. Marias, G. Stamatakos, S. McKeever,
T. S. Deisboeck, and N. Graf, “An architecture for integrating cancer
model repositories,” in Proc. IEEE 34th Eng. Med. Biol. Soc. Conf., San
Diego, CA, USA, 2012, pp. 6628–6631.
[23] M. G. Vander Heiden, “Understanding the Warburg effect: The metabolic
requirements of cell proliferation,” Science, vol. 324, no. 5940, pp. 1029–
1033, May 2009.
[24] R. A. Gatenby and R. J. Gillies, “Why do cancers have high aerobic glycolysis?” Nat. Rev. Cancer, vol. 4, no. 11, pp. 891–899, Nov. 2004.
[25] C. Athale, Y. Mansury, and T. S. Deisboeck, “Simulating the impact of
a molecular ‘decision-process’ on cellular phenotype and multicellular
patterns in brain tumors,” J. Theor. Biol., vol. 233, no. 4, pp. 469–481,
Apr. 2005.
[26] T. Shlomi, T. Benyamini, T. Benyamini, E. Gottlieb, R. Sharan, and E.
Ruppin, “Genome-scale metabolic modeling elucidates the role of proliferative adaptation in causing the Warburg effect,” PLoS Comput. Biol.,
vol. 7, no. 3, p. e1002018, Mar. 2011.

SAKKALIS et al.: WEB-BASED WORKFLOW PLANNING PLATFORM SUPPORTING THE DESIGN AND EXECUTION

[27] N. C. Duarte, S. A. Becker, N. Jamshidi, I. Thiele, M. L. Mo, T. D. Vo,
R. Srivas, and B. O. Palsson, “Global reconstruction of the human
metabolic network based on genomic and bibliomic data,” Proc. Nat.
Acad. Sci. USA, vol. 104, pp. 1777–1782, Feb. 6, 2007.
[28] A. Wolf, S. Agnihotri, and A. Guha, “Targeting metabolic remodeling in
glioblastoma multiforme,” Oncotarget, vol. 1, no. 7, pp. 552–562, Nov.
2010.
[29] C. Colin, N. Baeza, C. Bartoli, F. Fina, N. Eudes, I. Nanni, P. M. Martin,
L. Ouafik, and D. Figarella-Branger, “Identification of genes differentially
expressed in glioblastoma versus pilocytic astrocytoma using suppression
subtractive hybridization,” Oncogene, vol. 25, no. 19, pp. 2818–2826,
May 2006.
[30] E. Tzamali, V. Sakkalis, and K. Marias, “The effects of near optimal
growth solutions in genome-scale human cancer metabolic model,” in
Proc. IEEE Int. Conf. BioInformatics BioEng., Larnaca, Cyprus, 2012,
pp. 626–631.
[31] G. S. Stamatakos, E. Kolokotroni, D. Dionysiou, C. Veith, Y. J. Kim, A.
Franz, K. Marias, J. Sabczynski, R. Bohle, and N. Graf, “In silico oncology: Exploiting clinical studies to clinically adapt and validate multiscale
oncosimulators,” in Proc. IEEE 35th Annu. Int. Conf. Eng. Med. Biol.
Soc., Osaka, Japan, Jul. 3–7, 2013, pp. 5545–5549.
[32] G .S. Stamatakos, E. A. Kolokotroni, D. D. Dionysiou, E. Ch. Georgiadi,
and C. Desmedt, “An advanced discrete state-discrete event multiscale
simulation model of the response of a solid tumor to chemotherapy: Mimicking a clinical study,” J. Theor. Biol., vol. 266, no. 1, pp. 124–139, Sep.
2010.
[33] C. Farmaki, K. Marias, V. Sakkalis, and N. Graf, “Spatially adaptive
active contours: a semi-automatic tumor segmentation framework,” Int. J.
Comput. Assist. Radiol. Surg., vol. 5, no. 4, pp. 369–384, 2010.

831

[34] E. Skounakis, C. Farmaki, V. Sakkalis, A. Roniotis, K. Banitsas, N. Graf,
and K. Marias, “DoctorEye: A clinically driven multifunctional platform,
for accurate processing of tumors in medical images,” Open Med. Informatics J., vol. 4, pp. 105–115, 2010.
[35] T. Oinn, M. Addis, J. Ferris, D. Marvin, T. Carver, M. R. Pocock, and A.
Wipat, “Taverna: a tool for the composition and enactment of bioinformatics workflows,” Bioinformatics, vol. 20, no. 17, pp. 3045–3054, Jun.
2004.
[36] C. A. Goble and D. C. De Roure, “myExperiment: social networking for
workflow-using e-scientists,” in Proc. 2nd Workshop Workflows Support
Large-Scale Sci., Monterey, CA, USA, 2007, pp. 1–2.
[37] J. Goecks, A. Nekrutenko, J. Taylor, and The Galaxy Team, “Galaxy:
A comprehensive approach for supporting accessible, reproducible, and
transparent computational research in the life sciences,” Genome Biol.,
vol. 11, no. 8, p. R86, 2010.
[38] M. Abouelhoda, M. Ghanem, and S. Alaa, “Meta-workflows: Patternbased interoperability between Galaxy and Taverna,” in Proc. 1st Int.
Workshop Workflow Approaches New Data-Centric Sci., 2010.
[39] S. Sfakianakis, V. Sakkalis, K. Marias, G. Stamatakos, S. McKeever,
T. Deisboeck, and N. Graf, “An architecture for integrating cancer model
repositories,” in Proc. IEEE 34th Annu. Int. Conf. Eng. Med. Biol. Soc.,
San Diego, CA, USA, Aug. 28–Sep. 1, 2012, pp. 6628–6631.

Authors’ photographs and biographies not available at the time of publication.

