IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 6, NOVEMBER 2014

1903

A Syntactic Two-Component Encoding Model for the
Trajectories of Human Actions
Saiyi Li, Mario Ferraro, Terry Caelli, Fellow, IEEE, and Pubudu N. Pathirana, Senior Member, IEEE

Abstract—Human actions have been widely studied for their
potential application in various areas such as sports, pervasive
patient monitoring, and rehabilitation. However, challenges still
persist pertaining to determining the most useful ways to describe
human actions at the sensor, then limb and complete action levels of
representation and deriving important relations between these levels each involving their own atomic components. In this paper, we
report on a motion encoder developed for the sensor level based on
the need to distinguish between the shape of the sensor’s trajectory
and its temporal characteristics during execution. This distinction
is critical as it provides a different encoding scheme than the usual
velocity and acceleration measures which confound these two attributes of any motion. At the same time, we eliminate noise from
sensors by comparing temporal and spatial indexing schemes and
a number of optimal filtering models for robust encoding. Results
demonstrate the benefits of spatial indexing and separating the
shape and dynamics of a motion, as well as its ability to decompose
complex motions into several atomic ones. Finally, we discuss how
this specific type of sensor encoder bears on the derivation of limb
and complete action descriptions.
Index Terms—Curvature, decomposition, encoding model, human action, noise, sensor level, speed, torsion.

I. INTRODUCTION
CTIONS as much as language can express ideas and communication not only in humans but also by various other
species to the extent that recent work suggests there are strong
links between motor and language areas of the human brain [1].
While there are a few studies that have shown the application
of the language of action in various areas [2]–[5], it is also a
key to apply pervasive motion sensing technologies to clinical
kinematics, which is rarely studied.
In previous work, especially in the field of human action
recognition, a variety of approaches have been applied to represent human actions. For instance, Ren et al. [6] employed
the silhouette of a dancer to represent his/her performance by
extracting local features to control animated human characters.

A

Manuscript received September 16, 2013; revised December 12, 2013; accepted January 27, 2014. Date of publication February 4, 2014; date of current
version November 3, 2014. This project was funded by National ICT Australia
and Deakin University.
S. Li is with the Department of Electrical Engineering, Deakin University,
Geelong VIC 3216, Australia (e-mail: saiyi@deakin.edu.au).
M. Ferraro is with the Department of Physics, University of Turin, Torino
10124, Italy (e-mail: ferraro@to.infn.it).
T. Caelli is with the Victoria Research Laboratory, NICTA and with the
Department of Electrical and Electronic Engineering, The University of Melbourne, Parkville VIC 3010, Australia (e-mail: terry.caelli@nicta.com.au).
P. N. Pathirana is with the Department of Electrical Engineering, Deakin
University, Geelong VIC 3216, Australia (e-mail: pubudu.pathirana@deakin.
edu.au).
Digital Object Identifier 10.1109/JBHI.2014.2304519

Wang et al. [7] obtained the contour of a walker from his/her
silhouette to represent the walking motion. A spatiotemporal silhouette representation, the silhouette energy image, and a variability action models were used by Ahmad et al. [8] to represent
and classify human actions. In both visual-based and nonvisualbased human action recognition, differential features such as
velocity and acceleration, where motion statistics, their spectra,
and a variety of clustering and smoothing methods have been
used to identify motion types. A two-stage dynamic model was
established by Kristan et al. [9] to track the center of gravity of
subjects in images. Velocity was employed as one of the features
by Yoon et al. [10] to represent the hand movement for the purpose of classification. Further, Panahandeh et al. [11] collected
acceleration and rotation data from an inertial measurement unit
(IMU) mounted on a pedestrian’s chest to classify the activities
with a continuous hidden Markov model (HMM). Ito [12] estimated human walking motion by monitoring the acceleration
of the subject with 3-D acceleration sensors. Moreover, angular
features, especially joint angle and angular velocity, have been
used to monitor and reconstruct articulated rigid body models
corresponding to action states and types. Zhang et al. [13] fused
various raw data into angular velocity and orientation of upper
arm to estimate its motion. Donno et al. [14] collected angle
and angular velocity data from a goniometer to monitor the motions of human joints. Angle degree was also utilized by Gu
et al. [15] to recognize human motions to instruct a robot. Amft
et al. [16] detected the feeding phases by constructing HMM
with the angle feature from the lower arm rotation. Only a few
have considered a similar approach of trajectory shape features
such as curvature and torsion. For example, Zhou et al. [17]
extracted the trajectories of upper limb and classified its motion
by computing the similarity of these trajectories.
However, there still remain challenges in developing formal
descriptions and robust computational procedures for the automatic interpretation and representation of human actions. The
majority of studies employed a variety of human motion encoders to recognize or decompose general movement, such as
reaching, waving hands, jumping, walking, and so on. Few of
them investigate details in each general movement, for example,
the even smaller atomic components included in these general
movements which are of importance for syntactic and structural
descriptions of human movements in detail, especially in clinic
and rehabilitation environment, where the details of movements
of body parts require a form of motion language or, at least,
syntax.
A detailed example of current work is the POETICA system
of Aloimonos et al. [18] which integrates formal generative
action language with sensor (IMU) velocity and acceleration

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

1904

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 6, NOVEMBER 2014

Fig. 1. Three-level syntactic description framework for building language for
human action.

measures. Specifically, Guerra-Filho et al. [19] used velocity and
acceleration to represent and divide human actions into atomic
motions as the phonemes for a human action language. They also
extracted atomic components using velocity, acceleration, and
joint angle—motion “phonemes”, in [20]. Sant’Anna et al. [4]
analysed of gait motion in the elderly was performed using a
motion language based on accelerometers. Moreover, joint angle
have also been used pervasively to find primitives of human
actions [21], [22].
It is interesting to note that in some cases, motion primitives
belonging to the same type of action may share the same motion trajectory with various dynamics and orientations, such as
shaking hands, while sometimes, although the trajectories of two
motions are similar, they are two different motions due to various dynamics, like walking and running. Therefore, it is most
important to separate the shape from the dynamics of human
actions. Furthermore, it is important to have motion encoders
that are capable of uniquely encoder the shape and dynamics
invariant to the limbs absolute position and pose.
In light of the above, this paper develops three contributions
to these issue.
1) A two-component action encoding model is proposed to
separate a complex motion trajectory into its shape and dynamics, which extend the earlier work of Caelli et al. [23],
where only preliminary modelling and signal processing
was performed.
2) A spatial indexing scheme is introduced to index the trajectory of a motion since the shape component of the
proposed model is based on the arc-length of a trajectory.
Compared with the temporal indexing scheme, a shape
model can be computed more precisely by using spatial
indexing scheme.
3) Three commonly used filters, including least-squares
Gaussian filter (LS), Savitsk–Golay filter (SG), and optimal Kalman filter (KF), are compared to choose the best
one for our proposed encoding model.
4) The bridge between our study and canonical actions is
built to show the potential application of the proposed
encoding model, which is shown in the last experiment
by decomposing some complex motions into predefined
atomic motions.
More generally, this paper is embedded in a more general
three-level description framework (see Fig. 1) involving L1 sensor, L2 limb, and L3 complete action descriptions—and their

relations—that fit within specific contexts. In our context, this is
clinical kinematics such as rehabilitation and patient monitoring.
Albeit the main focus here is the development of robust computational methods for computing unique, invariant, and useful
sensor “atomic states” or motion primitives, for the sensor (L1 )
level and how they apply to other levels. A simple example:
consider the right elbow flexion exercise involving the planar
movement of the right arm as described in PhysioAdvisor [24].
Bend and straighten your elbow as far as you can go without
pain and provided you feel no more than a mild to moderate
stretch. Repeat 10–20 times provided the exercise is pain free.
This implies that the arm limbs have required states as well
as the sensors measuring the displacement in ways that would
enable automated valuation as to if the exercise is performed
correctly. For example, it is more or less independent of speed,
smoothness, etc.
The rest of this paper is arranged as follows. The twocomponent encoding model is introduced in Section II, followed by two trajectory indexing schemes, namely temporal and spatial schemes, to compute the proposed encoding
model. In Section IV, three filters are explored and compared
to deal with noise in the raw data, followed by the introduction of switching continuous HMM in Section V to demonstrate
the benefits of the proposed encoder in action recognition. In
Section VI, a potential human action alphabet for human actions
is introduced based on this encoder and experimentally expired
in Section VII followed by the conclusion.
II. TWO-COMPONENT ENCODER THEORY
In differential geometry, the shape of a curve is described
by the Frenet–Serret equations [25], [26], a system of linear
differential equations. Let p be a point in R3 , with position vector
r = (x, y, z), moving along a trajectory γ; the simplest form of
the Frenet–Serret equations arises when γ is parameterized by
arc-length s, whose infinitesimal element ds is defined as


(1)
ds = dx2 + dy 2 + dz 2 .
In this parameterization, the tangent vector


dx(s) dy(s) dz(s)
dr(s)
=
,
,
u=
ds
ds
ds
ds

(2)

is the unit vector and its derivative is a vector normal to u whose
norm is the curvature κ; this result is the first Frenet–Serret
equation
du
= κ(s) · n
(3)
ds
where n, the unit vector, corresponds to the principal normal
vector. Curvature, thus, measures the amount of arc-rate of
change of u and can be computed via the formula
 
 du 

(4)
κ(s) = 
 ds  .
Vectors u and n, thus, define a plane, the osculating plane, and
the orientation of γ in space can be now completely specified
once a third unit vector is given, the binormal vector, defined as
b = u × n.

(5)

LI et al.: SYNTACTIC TWO-COMPONENT ENCODING MODEL FOR THE TRAJECTORIES OF HUMAN ACTIONS

1905

The system of Frenet–Serret equations can now be completed:

A. Temporal Index

dn
= −κ(s)u + τ · b
(6)
ds
db
= −τ (s)n.
(7)
ds
where the torsion τ measures how the curve winds out of the
plane,

This method assumes that each position (x, y, z) is indexed
by time resulting in a position vector [23]:

db
· n.
(8)
ds
These equations are the basis for the fundamental theorem of
curves which proves that a curve parameterized by arc-length s
is uniquely defined up to rigid motion and that κ, τ encode the
curve in a way invariant (or blind) to rotations and translations.
This is because the position vector r can be computed at each
s by first integrating the Frenet–Serret equations to obtain the
tangent, normal, and binormal vectors given an initial orientation
(thus losing the invariance to rotations) and next by integration
of (2); the resulting vector, r, depends on the initial position,
i.e., it is not invariant to translations.
The role of k and τ can be better understood if one considers
the Taylor expansion around, say, s = 0, retaining just the first
four terms
τ (s) = −

s3
s2
r(s) = r(0) +su(0)+κ(0) n(0) + κ(0)τ (0) b(0)+O(4).
2
6
(9)
The first two terms provide the best linear approximation of
the curve near r(0) and the curvature at s = 0 modulates the departure from linearity in the osculating plane. Finally, the torsion
appears in the last and smallest term of the expansion controls
the deviation of r from the osculating plane. Note that, in a
neighborhood of s = 0, the largest variation is along u followed
by lesser variations along n and b, respectively. Suppose we
sample the curve from a set of experimental data. If the neighborhood is small enough, then u, n, b are, respectively, the first,
second, and third principal direction of the sample distribution.
Curvature and torsion encode solely the shape of the curve
and provide nothing about the speed of the point p, since the
arc-length parameterization uses velocity v as a unit vector. In
order to have a complete, invariant description of the motion
encoding of both the shape and the kinematic dynamics of point
p, we need to know the speed v at each position—noting that v
is a scalar and, as such, is invariant under rigid motion. In other
words, we need the relation between time t and s, provided by
the equations
 
 ds 
(10)
v =   .
dt
This becomes more explicit when considering temporal parameterization of γ.
III. ENCODING METHODS
It is possible to compute the trajectory shape and dynamics
(kinematics) using two different indexing schemes for γ: one
with respect to discrete time sampling, (δt), or with respect to
discrete spatial/distance (δs)—as follows.

r(t) = ((x(t), y(t), z(t)))

(11)

where t = kδt, k = 0, . . . , T for a constant δt, while the corresponding δs = (δx2 + δy 2 + δz 2 )1/2 is variable.
From r(t) quantities such as {κ(t), τ (t)} and v can be computed, via finite differences schemes, as follows: compute first


δx δy δz
, ,
v = (vx , vy , vz ) ≈
(12)
δt δt δt
then


a = (ax , ay , az ) ≈

and
da
≈
dt



δvx δvy δvz
,
,
δt δt δt

δax δay δaz
,
,
δt δt δt


(13)


.

Thus, v can be obtained from
 
 2  2 	1/2
2
dy
dz
dx
+
+
v=
dt
dt
dt

(14)

(15)

and κ(t), τ (t) from
κ(t) =

v × a
,
v3

τ=

(v × a) · da/dt
v × a2

(16)

respectively. However, computations of (15) and (16) requires
performing up to third-order numerical differentiation and, so,
filtering must be performed to deal with noise.
B. Spatial Index
Here, we separate the trajectory shape from its dynamics right
from the initial encoding by considering r as a function of s.
The coordinates
r(s) = (x(s), y(s), z(s))

(17)

are sampled at values of s = kδs, k = 0, . . . , S with δs constant,
and so δt becomes a function of s and not vice versa as in the
temporal indexing scheme.
In this case, the computations are as follows.
First,



δx δy δz
,
,
δs δs δs
u≈ 

 δ x 2 
 δ y 2  δ z 2 1/2
+
+
δs
δs
δs
=

(δx, δy, δz)
[(δx)2 + (δy)2 + (δz)2 ]1/2

where the division ensures u = 1.
Then,


δux δuy δuz
du
≈
,
,
ds
δs δs δs

(18)

(19)

1906

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 6, NOVEMBER 2014

IV. DEALING WITH NOISE
One of the major problems with collecting data from kinematic sensors is noise, particularly when the relevant information involves differential operators of different orders. Precisely
because the trajectories correspond to actions the ideal filter
is one that retains important amplitudes while removing small
variations due to noise. In the following, we explored and compared LS Gaussian, SG, and optimal KF with this in mind.
A. LS Gaussian Filter
Fig. 2. Shape model. Here, the locus of points in the 2-D κ-τ space corresponds to a 3-D trajectory positions.

The LS Gaussian filter is a nonlinear LS fitting regime minimizing the noise in a raw dataset and smoothing the curve by
using one or a mixture of Gaussians. The fitting process is updated by minimizing the sum of the squared errors between the
raw dataset and the fitting equation. Here, the raw dataset is a
set of paired data defined by {Yk , Xk } , k = 1, 2, . . . , K as the
indexing number [27]. The estimated values of Yk is notated as
Yˆk =

N


(an e−(

X k −b n
cn

)2

)

(22)

n =1

where k = 1, 2, . . . , K is the indexing number and N is the
order of the filter (the number of Gaussians). an , bn and cn , n =
1, 2, . . . , N are the parameters chosen to minimize ε [27]:
ε=

Fig. 3. Dynamic model.Here, the speed along the trajectory, v, is indexed over
time, t.

and



n≈

δux
δs

δu

, δ sy , δδusz
 du 
 

K


(Yk − Yˆk )2 , k = 1, 2, . . . , K

and


(20)

min ε = min

a i ,b i ,c i

a i ,b i ,c i

ds

giving
b=

u×n
.
u × n

(23)

k =1

(21)

Note that derivatives of n and b can be computed from u,
and application of (4) and (8) provide values of κ(s) and τ (s),
respectively.
The speed v can be computed by making use of (10) and it
can then be indexed as v(s); alternatively, since the interval δs
is fixed for any s, we can encode the speed by using the time
intervals δt(s) variable with s.
We have shown that an action (trajectory shape and dynamics) can be uniquely encoded in a way invariant to rigid motion
in the space (κ, τ, v) and we can define simple and complex
single sensor actions as contours in this domain. It is sometimes
convenient to encode the trajectory shape separate from dynamics in a 2-D κ-τ space and plot the dynamics, v, separately, as
shown in Figs. 2 and 3. However, there are a few canonical
trajectory shapes worth noting including linear (κ = 0, τ = 0),
planar (κ = const, τ = 0), screw (κ = const, τ = const), and
spiral (κ = 0, τ = 0), actions. Accordingly, a uniform rectilinear motion is encoded by the point (0, 0, v0 ), a circular uniform
motion by (κ0 , 0, v0 ), and a motion with constant speed along
a helix by a point (κ0 , τ0 , v0 ). Obviously, in general, curves are
mapped to curves in the κ, τ, v space.

= min

a i ,b i ,c i

K


(Yk − Yˆk )2

k =1
K



Yk −

N



(−

ai e

X k −b i
ci

	2

)2 

. (24)

n =1

k =1

Here, k is the indexing number and N is order of fitting
equation.
A solution introduced in [27], [28] is to compute the partial
derivatives of the error and set the result to 0:
ε = 0

(25)

∂ 
∂ cn ]

where,  =
,
,
and n = 1, 2, . . . , N is the order. This solution can be used in both linear and nonlinear LS
methods (see [27] for more details).
However, LS filters have known disadvantages. First, it is particularly sensitive to outliers, especially the extreme values [27]
and, second, it is essentially a smoothing filter which does not
attempt to preserve steep gradients or important discontinuities
so critical in kinematics. To this end, higher-order moments
need to be included via filters such as the SG-LS polynomial
filters.
[ ∂ ∂a n

∂
∂ bn

B. SG Filter
The SG filter is designed to preserve such higher order moments by approximating the underlying function using a bestfitting polynomial moving window. Since the process uses LS

LI et al.: SYNTACTIC TWO-COMPONENT ENCODING MODEL FOR THE TRAJECTORIES OF HUMAN ACTIONS

Pt|t = APt|t A + Sw

fitting, it involves matrix inversion to derive the coefficients of a
fitted polynomial that form a convolution kernel defined by their
sampling interval (window size) and polynomial order [29]. The
result is a set of LS polynomial filters which can be applied to
each of the x(t), y(t), z(t) recordings of the form:
X(t) = SG(n, m) ∗ x(t)

(26)

Y (t) = SG(n, m) ∗ y(t)

(27)

Z(t) = SG(n, m) ∗ z(t)

(28)

where ∗ denotes convolution, n, m refer to the window size and
order of the polynomial, respectively.
The most important benefit of such polynomial approximations is that higher-order derivatives can be determined
algebraically from the derived polynomial coefficients. The
norms of velocity, V (t), acceleration, A(t) can then be computed using these coefficients for each position parameter,
(X(t), Y (t), Z(t)), as

V (t) = Xt (t)2 + Yt (t)2 + Zt (t)2
(29)

A(t) = Xtt (t)2 + Ytt (t)2 + Ztt (t)2 .
(30)
V and A provide an invariant (to absolute pose and position)
description of the dynamics of a curve, but not its shape. Again,
the reason for separating dynamics from shape features is that a
known action can have the same shape but different dynamics—
even when repeated by the same person.
An experiment was done (refer to Section VII-A) to compare
the performance of SG and LS filter to show why and how SG
filter outperforms the other one.

1907

(34)

Kt+1 = Pt+1|t C  (CPt+1|t C  + Sv )−1

(35)

x̂t+1|t+1 = x̂t+1|t + Kt+1 (yt+1 − C x̂t+1|t )

(36)

Pt+1|t+1 = Pt+1|t − Kt+1 CPt+1|t .

(37)

Here, the x̂ is the estimated state.
After filtering the system, a backward process was used for
smoothing, defined by
−1
Lt = Pt|t A Pt+1|t

(38)

x̂t|T = x̂t|t + Lt (xt+1|T − x̂t+1|T )
Pt|T = Pt|t + Lt (Pt+1|T −

Pt+1|t )L
t .

(39)
(40)

The Expectation–Maximization (EM) algorithm was then
used to optimize this forward–backward process, by computing the maximum log-likelihood,
max log L(Sw , Sv ) = max log P (y0:K ; Sw , Sv ).

S w ,S v

S w ,S v

(41)

The probability of yt+1 was computed from observations
y0 , . . . , yt :
P (yt+1 |y0:t ) =

1
d/2

|Σy t + 1 |t |1/2

(2π)



− 12 (y t + 1 −ŷ t + 1 |t ) Σ y t + 1 |t (y t + 1 −ŷ t + 1 |t )

×e

(42)

where
ŷt+1|t = C x̂t+1|t

C. Kalman Filter
The third type of filter examined was the class of KF varying
from the normal linear to extended and unscented versions to
accommodate for nonlinearities in the data. Although the extended KF linearizes inherent nonlinearities and the unscented
allows for more robust sampling and estimation [30], we have
found that the standard (optimal) KF performed as well as the
others, so we have compared this with the previous two filters.
The normal KF smooths the data by adapting the Kalman gain
online in order to minimize the error in fitting a single Gaussian
error model.
In the KF, the system is described by
xt = Axt−1 + But + wt

(31)

yt = Cxt + vt .

(32)

Here, xt is the tth state of the system, yt is the tth observation of the system, A is the state-transition matrix, B is
the control-input matrix, C is the observation matrix, wt is
the process noise, and vt is the measurement noise. Moreover,
Sw = E(wt (wt ) ) corresponds to the process noise covariance
and Sv = E(vt (vt ) ) is the measurement noise covariance.
In order to filter the system based on observations from the
system alone, the following forward process equations have
been used
x̂t+1|t = Ax̂t|t

(33)

Σy t + 1 |t = CPt+1|t C  + Σt .

(43)

Using Bayes’ rule, we then can write the likelihood of y0:K
as
P (y0 , . . . , yT ) = P (y0 )

T


P (yt |y0:t−1 )

t=1

=

t


1
d/2

(2π)

t=1

|Σy t + 1 |t |1/2


− 12 (y t + 1 −ŷ t + 1 |t ) Σ −1
y

×e

t + 1 |t

(y t + 1 −ŷ t + 1 |t )

.

(44)
The log-likelihood can then be computed as

log L =
log P (yt+1 |y0:t ) .
t

The optimal Sw and Sv are computed as
Sw =

T −1


1 
x̂t+1|T − Ax̂t|T x̂t+1|T − Ax̂t|T
T t=0
 
+ At Pt|T A
t + Pt+1|T − Pt+1|T Lt A − ALt Pt+1|T



(45)

1908

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 6, NOVEMBER 2014



1 
yt − C x̂t|T yt − C x̂t|T + CPt|T C  .
T + 1 t=0
T

Sv =

(46)
A series of experiments (stated in Section VII-B and
VII-C) were then performed to determine the best combination
of indexing and noise filtering schemes for computing shape
and kinematics for a given sensor.
V. COMPLEX MOTION DECOMPOSITION USING SWITCHING
CONTINUOUS HMMS
To syntactically describe complex motions, it is of importance
to segment and classify them into smaller atomic units. In this
paper, switching continuous HMMs [31] will be investigated to
perform motion segmentation and classification simultaneously
that use atomic motion components to identify complex actions.
A. Building Model for Atomic Motions
Since a HMM involves two major sets of variables: hidden
states and observations, it is essential to determine these variables. For states, because they are hidden, it is more critical
to know the number of states rather than what they are. While
for observations, a Gaussian mixture model (GMM) is used,
in the continuous HMM case, to model the observations where
each observation symbol corresponds to a Gaussian component
of the mixture model. The GMM is the weighted sum of M
component Gaussian densities defined by
p(x|λ) =

M


ωi g(x|μi , Σi )

(47)

i=1

where ωi , μi , and Σi correspond to the weight, mean, and
covariance of the ith Gaussian model and x is multidimensional
vector. The EM algorithm is then used to estimate these GMM
parameters: ω, μ, and Σ.
As is typical of HMM estimation, each HMM atomic model
uses, again, the EM algorithm with randomly set initial guesses
and updated using training data till an optimal (MAP) solution
is obtained [32], thereby establishing a HMM notated as λ =
{A, B, π}. Here, A is a state transition probability distribution
with A = {as i s j }, i, j ∈ [1, N ] (si is the ith state at time t, sj
is the jth state at time t + 1, and N is the total number of
states).
 B is observation symbol probability distribution with
B = bos ik , i ∈ [1, N ], k ∈ [1, M ] (si is the ith state at time t
and ok is kth observation symbol). π is initial state distribution
with π = {πi } , i ∈ [1, N ]. This version of the EM model is
implemented efficiently using the Forward–Backward algorithm
[33].
B. Complex Motion Decomposition
In the previous section (Section V-A), the approach for building a HMM for one atomic motion is introduced. Since a complex motion may contain Q types atomic motions, it is essential
to build HMM for each type of atomic motions, the collection
of these HMMs is notated as Λ = {λ1 , λ2 , . . . , λQ }.

To decompose this complex motion based on its shape, it
should be represented by {κt , τt } , t = 1, 2, . . . , T . Decomposing the motion is actually solving the following problem using
the forward algorithm defined by
arg max p(κt , τt |λq)

(48)

q

where t = 1, 2, . . . , T and q = 1, 2, . . . , Q. The change of q
means the change of atomic motions, thereby segmenting and
classifying the complex motion into predefined atomic motions.
VI. CANONICAL ACTIONS AND THE ACTION ALPHABET
Though the aforementioned derivations describe two components (trajectory shape and dynamics) of complex human
motions, approaches for symbolic representation or the classification of these components are not provided, which will be
more practical for those who need to monitor, analyze, or describe these motions [23]. For example, in situations where it
is important to describe how a patient should perform specific
rehabilitation exercises or even how a specific limb is not performing normally, it is necessary to have a description of the
action that fits with current understanding of motor programs
and processes underlying normal action productions. In fact,
the challenge to construct generative languages for actions has
become a focus in recent years in both human kinematics and
robotics via the POETICA project [34].
To this end, we have developed a “point screw decomposition”
to generate basic “atomic” action descriptions at least for the
sensor movements. This method is related to, but not identical
with, screw kinematics for rigid bodies as developed over the
past two centuries for mechanical motions encoding in terms
of the rotations and translations of rigid bodies about a given
screw axis (see, for example, McCarthy [35] for a treatment in
spherical kinematics terms). It is not aimed at the descriptions
of actions at the next level of specific limb movement types and
their relations in kinesiology but it is intended to underpin the
inference of such actions.
It must first be noted that the curvature and torsion of a
helical (screw) motion is constant [36]. For this reason, then,
any point, at time t, in κτ space (κ(t), τ (t)) can be interpreted
as corresponding to an screw action such that if the motion
remains at a “fixed point” (does not move) in the κτ plane
then, during this time period, its 3-D trajectory corresponds to
a constant point screw whose shape is defined by the κ and τ
values at that point. Specifically, for a helix defined by
r(t) = (a cos(t), a sin(t), bt)

(49)

it is easy to shown that
b
a
,
τ= 2
.
(50)
a2 + b2
a + b2
Similarly, the radii of first (curvature-type) and second
(torsion-type) curvatures, a, b are defined by
κ
τ
a= 2
,
b= 2
.
(51)
κ + τ2
κ + τ2
These latter relations in (51) illustrate the relationship between κ, τ values and the types of point screw actions (such as
κ=

LI et al.: SYNTACTIC TWO-COMPONENT ENCODING MODEL FOR THE TRAJECTORIES OF HUMAN ACTIONS

1909

TABLE I
SENSOR MOTION TYPES

TABLE II
COMPARISON BETWEEN SG AND LS

Fig. 4. Three motions used in experiments of this paper. (a) and (b) are for
linear motion. (c) and (d) are for planar motion. (e) and (f) are for helical motion.

“left-handed” and “right-handed”) [23] which can be used to estimate an atomic motion. Equally, one single point screw action
or helix can be utilized to approximate temporally contiguous
points that are close in a κτ space or curve. Contiguity in local
shape and time is the basis of our method to encoding such motions. Consequently, in the following section, our aim was [23]:
1) to describe atomic motions with a sequence of point screws
(specific κ, τ values) “states”;
2) to determine how to relate the types of point screws and
their dynamics, given the variabilities that occur in the
execution of such actions by humans;
3) to explore the approaches to compile efficient criteria for
the encoding, prediction, and recognition of complex single sensor actions via their point screw decompositions.
Again, it must be emphasized that we have chosen to encode
sensor motions by two sets of invariant descriptors: κτ and speed
(v) signatures.
Nevertheless, as a result of this formulation, we propose a few
basic (canonical) motion types, as shown in Table I. As for directions, each such motion can be, for planar: forward/backward;
planar: clockwise/anticlockwise, and helical:left-handed/righthanded screw actions.
VII. EXPERIMENTS AND RESULTS
In this section, four experiments were done to compare filters
and indexing schemes, as well as illustrate the application of
two-component encoding model. To quantify the performance,
standard deviation, correlation coefficient, and mean square error (MSE) were used in the following subsections. First of all, as
shown in Section VI, curvatures and torsions for linear, planar,
and helical motion should be constants; standard deviations of
the noise (outliers) in curvatures and torsions were employed to
show how computed curvatures and torsions related to expected
values. Moreover, correlation coefficient and MSE were used
in the first experiment (refer to Section VII-A) to show the distortion of the filtered trajectories and the raw one. Moreover, in
these experiments, all the parameters, such as the spatial intervals, orders of LS Gaussian filter, orders and window sizes of

SG filter, and so on, were selected by minimizing the standard
deviations of curvatures and torsions of related trajectories.
In terms of the abbreviations, NF means that no filter was applied (the results were computed based on raw data), while SG,
LS, and KF are for Savitzky–Golay filter, least-square Gaussian
filter, and Kalman filter, respectively.
A. Comparison Between SG Filter and LS Gaussian Filter
The first experiment was done to illustrate how the SG and
LS smoothed the trajectory of a helical motion collected from
a Microsoft Kinect with sampling rate of 30 frames per second,
which was composed of the 3-D positions of right wrist with
total 118 samples (indexed by temporal scheme) performed by
a healthy subject.
From the Table II, it can be seen that SG filter results in
the smaller standard deviation of curvature and torsion with
less distortion (higher correlation coefficient and lower MSE
with respect to the raw trajectory) and shorter computing time.
By comparison, the LS filter yields curvature and torsion with
standard deviations much higher than SG with lower value of
the correlation coefficient and higher MSE than those of SG;
moreover, LS has a longer computational time. All in all, when
suitable parameters are selected, the SG filter appears to outperform LS in generating curvature and torsion with minimized
errors (standard deviations).
B. Computability of the Two-Component Model
In this experiment, these two components were computed for
a variety of actions including two linear and two planar motions
(with 121, 121, 215, and 277 samples indexed by time) of the
R
, sampling 3-D positions of
right wrist by using the Kinect	
joints at 30 Hz. Fig. 4 shows how these motions were captured—
as it was with all the experiments in this paper.
In Table III, the first column shows the 3-D action trajectories
while the second Shape column is divided in two corresponding
to the κ, τ values as a function of time. The third Dynamics
column shows the speed v over time. The rows refer to different

1910

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 6, NOVEMBER 2014

TABLE III
SHAPE AND DYNAMICS FOR FOUR MOTIONS

In each left figure, the color changes from black to grey with time.

motions and only trajectories with zero torsion have been considered. Here, spatial indexing and SG filtering have been used
in the calculations.
For linear motions, the Shape column reflects the shape of
the motion trajectories independent of their dynamics. In these
cases, curvature and torsion for linear motion should be 0 since
there was no rotation or twist. Graphs of curvature and torsion
as functions of time show this to be the case for most of the time,
with points located away from 0 occurring mainly at the beginning and at the end of the motion, that is, at points of temporal
discontinuity. The shape computation results were consistent
with this with points mostly clustered around the origin of the
κ, τ plane. In terms of the dynamic computation results, the
speed was used, rather than velocity vectors because, as noted
in Section III-A, they can be recovered from κ, τ , i.e., the shape
component of our model. Graphs of speed versus time show
two different kind of motions. In the first upward motion, an
initial increase of speed was followed by an interval in which v
varied a little around a constant value and decreased when the
motion stopped. In the second downward motion, v increased
linearly, uniformly accelerating up to the end, and then rapidly
decreasing to zero. Thus, although the motions had different locations and direction they had very similar shapes (in the sense
of κ, τ values) while exhibiting different dynamics. The third
and fourth rows in Table III show results for two planar motions forming closed curves with different directions (tangent
vectors) and locations. In both cases, the curvature is relatively

small for large portions of the paths while the torsion should be
zero since there was no twist in these motions.
The results were affected by the fact that curvature and torsion
are very sensitive to noise, so that values κ show a spread in the
range from 0 to 200 m−1 . Although values of τ are more noise
than that of κ, they fluctuate around 0 m−1 , which generally
follows the expectation shown in Table I.
However, most of the significant outliers occurred at the beginning and end of the motion or in points where sharp cusps
occurred in the trajectory as, for instance, where there were two
peaks in the bottom part of the left planar motion 1 or in the left
hand side of motion 2.
Finally, computed v values showed very similar dynamics
(independently of their shape); here, not surprisingly, v values
were more scattered than in the linear case due to the inaccuracy
of the Kinect and the difficulty of the subject accurately outlining the specified action. In spite of this, this first experiment
demonstrates that the system can encode the shape and dynamics of an action reliably albeit somewhat noisy at the beginning
or end of an action as expected from the nature of the filtering
computations involved.
In addition, a simulation was implemented to illustrate the
independence between the shape model and the dynamic model.
In this part, two helical trajectories with the same shape but
R
. For the first
different dynamic were simulated with MATLAB	
trajectory, the speed was constant, while in the second trajectory,
the speed varied. In the first, second, third, and fourth quarter

LI et al.: SYNTACTIC TWO-COMPONENT ENCODING MODEL FOR THE TRAJECTORIES OF HUMAN ACTIONS

1911

TABLE IV
PARAMETERS USED TO GENERATE THE STANDARD DEVIATION FOR FILTERS
PROCESSING TRAJECTORIES WITH TEMPORAL (FIRST FOUR ROWS) AND
SPATIAL (LAST FOUR ROWS) INDEXING SCHEME

Fig. 5. Two helical trajectories with the same orientation and shape, but
two different dynamics. The color of the trajectory in (a) with constant speed
(roughly 0.1 m/s) changes from black to gray with time, and the different line
styles and colors of the trajectory in (b) indicates the change of velocities. The
legend on the right side of (b) shows the approximate speed of different parts of
the trajectory in (b).

(a)

(b)

Fig. 6. Shape models: (a) for trajectory in Fig. 5(a); (b) for trajectory in
Fig. 5(b).

(a)

(b)

Fig. 7. Dynamic models: (a) for trajectory in Fig. 5(a); (b) for trajectory in
Fig. 5(b).

of the second trajectory, the speed was 10, 30, 5, and 40 times
as much as that in the first trajectory, respectively. These two
trajectories were shown as Fig. 5.
The two trajectories were the same and then they shared the
same curvature and torsion (shape model) as shown in Fig. 6.
However, the dynamics of these two trajectories were different,
as could be proved by investigating their dynamic models, as
shown in Fig. 7.
From Fig. 7(a), we can see that the average speed of trajectory
is around 0.1 m/s. In Fig. 7(b), the speed for the first quarter
(from 1 to 50 s) is approximately 1 m/s, which is ten times
as much as that of the average of first trajectory. Similarly, it is
clear that in second (50 to 100 s), third (100 to 150 s), and fourth
(150 to 200 s) quarters, the speeds are 3 m/s, 0.5 m/s, and 4 m/s,
separately. This result is corresponding to the expectation in the
beginning of the simulation.

Here, L and P are for the linear and planar motion, respectively. (the same in the rest tables).

TABLE V
THE COMPARISON OF CURVATURES AND TORSIONS FOR FOUR TRAJECTORIES
INDEXED BY TEMPORAL AND SPATIAL INDEXING SCHEMES AND FILTERED BY
SG, LS AND KF

Here, C is for curvature and T is for torsion.

C. Comparisons Between The Combinations of Various
Indexing Schemes and Filtering Approaches
In this experiment, we have more carefully examined the performance of the indexing and filtering methods for these linear
and planar actions mentioned in the previous experiment, again,
with the purpose of determining the best way to minimize noise.
The indexing schemes (temporal and spatial) were used in conjunction with three filtering methods (LS, SG, KF) where, in
each case, optimal parameters were used for comparison purposes. At the same time, sets of data generated from trajectories
without applying any filter (NF) was used for comparison. Here,
we select one linear and one planar motion for result demonstration.
Table IV summarizes the parameters used by the filters to
process trajectories with temporal and spatial indexing scheme,
respectively. As can be seen, the orders and window sizes for
the SG smoothing filter changed from time for two motions
indexed with temporal indexing scheme, while keeping almost
the same when spatial indexing scheme was applied. Moreover,
the reason order 8 was used for LS filter is that although the
lower orders gave a smoother trajectory, it was distorted, like
that in Table II. In terms of the KF, the optimal iteration number
varied considerably.
Table V illustrates the standard deviations of curvatures and
torsions of two trajectories, namely linear (L) and planar (P), indexed with temporal and spatial indexing scheme and denoised
with three filters. By comparing the performance between temporal and spatial indexing schemes (top four rows and bottom
four rows), it can be seen that the spatial indexing scheme outperforms the temporal one by generating curvatures and torsions
with smaller standard deviations. Moreover, SG outperforms LS

1912

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 6, NOVEMBER 2014

TABLE VI
TRAJECTORIES AND DECOMPOSITION OF COMPLEX MOTIONS

In each top figure, the color changes from black to gray with time in the trajectories.

and KF since the trajectory in each row filtered by SG has the
smallest standard deviations of curvatures and torsions. It is
also noteworthy that some numbers, such as the torsion for linear motion without applying filters, are extremely large, which
is caused by some outliers in these trajectories.

D. Motion Decomposition Using Switching Continuous
Hidden Markov Model (SCHMM)
Based on the conclusion of Experiment 1, it is clear that our
two-component model can be used for motion decomposition.
With the help of the result of the second experiment, the noise in
R
,
raw data collected by a typically noisy sensor like the Kinect	
can be significantly reduced. So, in the third experiment, we explored how the two-component model can be used to segment
action data into such components using a standard HMM formulation [31]. In this experiment, a continuous Gaussian hidden
R
Markov model (CHMM) [31] was implemented in MATLAB	
based on Bayes Net Toolbox [37], where three HMMs were
constructed for linear, planar, and helical motions, respectively,
and the segmentation into these three motion classes was determined by MAP criteria, that is, at any given time, the HMM
was selected which produced the highest Viterbi score [31].
For testing, four complex motions being various combinations
of linear, planar, and helical motions were analysed—all based
purely on their curvature and torsion values and having different
dynamics.
Three linear motions (89, 94, 87 samples indexed by spatial
indexing scheme with spatial interval of 0.015 m), three planar
motions (113, 122, 116 samples indexed by spatial indexing
scheme with spatial interval of 0.04 m), and two helical motions (142, 147 samples indexed by spatial indexing scheme
with spatial interval of 0.04 m) were selected as training data
sets to construct three HMMs for linear, planar, and helical motions, respectively. Already, these can define quite complex and
different actions depending on how the motion components are
sequenced. Six Gaussian mixtures and clusters were used as
six observation symbols in each HMM along with six (latent)
states. These parameters resulted in excellent recognition rates
compared with other values we explored.

After building HMMs for trajectories of various atomic motions, four complex motions combining these atomic motions
were used to illustrate the performance of trajectory decomposition with two-component encoding model, spatial indexing scheme, and SG filter. Before decomposing these complex motions automatically with the proposed approach, we
manually segmented them into different atomic motions and
counted the samples in each segment as reference for computing recognition rate. The trajectory of these four complex motions and the examples of decomposition graphs are shown as
follows.
Table VI illustrates the performance of the SCHMM with
shape models as features. The first complex motion consisted
of linear motion and a planar motion and was indexed by spatial indexing scheme with spatial interval of 0.007 m. From the
classification/segmentation results, it is easy to see that the first
0.14 m of this motion is linear while the remainder corresponds
to a planar motion. For motion 2, the first 0.154 m is classified
as planar, followed by planar motion of around 0.161 m, linear
motion of about 0.35 m, and planar motion of approximately
0.14 m. In this diagram, the change from linear to planar motion
after about 0.8 m is caused by the small planar motion included
in the linear motion. After all, it is very hard for a human being
to do an exact linear motion. Moreover, the third complex motion is compounded with one helical motion and a linear motion.
This sequence can be told from the classification diagram easily,
while the unexpected change in the last part is caused by the
same reason as the previous motion. The last motion was combined by a helical, a planar, and a linear motion, which could be
reflected from the classification graph.
At the end of the experiment, 70 different complex motions
combining linear, planar, and helical motions conducted by ten
healthy people in lab environment were tested to gather the classification rate. Each person not only performed four motions
listed in Table VI, but also did three more trajectory composing linear, planar, and helical atomic motions while different
from predefined four motions. The average classification rate
for linear motions was around 89.2%; for planar motions, it was
roughly 90.6%; while for helical motions, it was approximately
92.2%. There are two major factors may lead to this result.
R
,
First of all, the noise coming from testing subjects and Kinect	

LI et al.: SYNTACTIC TWO-COMPONENT ENCODING MODEL FOR THE TRAJECTORIES OF HUMAN ACTIONS

which is unlikely to be eliminated completely by filters, may
negatively influence the classification rate and, next, it is very
hard for a person to make an exact linear, planar, or helical
motion. Therefore, it is reasonable to expect that some parts of
linear motion to be classified as a planar, and analogously, parts
of planar trajectory to be classed as helical, especially when one
motion changes to another, as well as at the beginning and end
of complex motions, such as cases 2, 3, and 4 in Table VI.
VIII. DISCUSSION AND CONCLUSION
A. Discussion
From the experiments done in this paper, it can be found
that the proposed two-component model is very sensitive to
noise. More specifically, outliers from motion capture devices,
tremors, or pathological motion changes in trajectories may result in extreme curvatures and torsions. That is the reason why
filters are applied . However, since the scope of this paper is
to introduce a new encoding model for human complex motion
trajectory decomposition, rather than evaluating motor performance, the preliminary experiments were done with motion
trajectories captured from healthy people. In terms of applying this two-component model to trajectories captured from
patients, there would be two potential approaches to deal with
tremors and pathological motion changes. One is that they can
be treated as noise and filtered with various filters. The other
method is to build HMM for atomic motions of patients and use
these HMMs, instead of using atomic motion HMMs trained
with trajectories of healthy people, to decompose more complex motions of patients.
In terms of intersubject differences, they are not very obvious. The analysis of the recognition rate for 70 motions used in
the last experiment shows that the standard deviations for the
recognition rate of linear, planar, and helical motion are approximately 2.3%, 2.1%, and 1.7%. In other words, it is possible
to train HMMs for atomic motions with training data from one
person and decompose motion trajectories with another one.
However, since this result is collected from healthy people, the
recognition rate for patients’ data may drop slightly and intersubject differences may be more obvious.
As a supplementary, another classification approach, named
discrimination classification, was tested and it has been found
not as suitable as SCHMM because of its lower average recognition rate (65.8%, 68.3%, and 73.1% for linear, planar, and
helical motion, respectively).
Finally, the aim of the HMM presented in Section VII-D is
to determine in general the ability of the encoding model in
decomposing complex motions, and then model resolution is
outside the scope of this experiment. Theoretically, the model
resolution is seven samples for both temporal and spatial indexing schemes for computing a pair of curvature and torsion
for recognition and classification. Therefore, characterized segments should at least be seven by temporal interval in time or
seven by spatial interval in space. In future work, we intend to
perform a wider range of complex motions with healthy people
and other suffering from various conditions to explore in more
the characteristic of this two-component encoding model.

1913

B. Conclusion
Similar to learning a language, extracting fundamental motion components in ways that reflect the type of motion attributes
of interest is essential to building a linguistic framework for human actions. In this paper, we have explored the new approach
to represent basic sensor outputs invariant to pose and extract
atomic sensor motions with the two-component (shape and dynamics) encoding model in a robust fashion. The experiments
have shown that the proposed encoder is reliable with the appropriate filtering and that the spatial indexing scheme outperforms
its temporal counterpart while the SG filter is able to eliminate
the noise from the raw data to a large degree. More importantly,
we have illustrated that our model can be implemented to quite
accurately extract predefined atomic sensor motions.
REFERENCES
[1] F. Pulvermüller, “Brain mechanisms linking language and action,” Nature
Rev. Neurosci., vol. 6, no. 7, pp. 576–582, 2005.
[2] J. Weng, “Symbolic models and emergent models: A review,” IEEE Trans.
Auton. Mental Develop., vol. 4, no. 1, pp. 29–53, Mar. 2012.
[3] A. Cangelosi, G. Metta, G. Sagerer, S. Nolfi, C. Nehaniv, K. Fischer,
J. Tani, T. Belpaeme, G. Sandini, F. Nori, L. Fadiga, B. Wrede, K. Rohlfing,
E. Tuci, K. Dautenhahn, J. Saunders, and A. Zeschel, “Integration of action
and language knowledge: A roadmap for developmental robotics,” IEEE
Trans. Auton. Mental Develop., vol. 2, no. 3, pp. 167–195, Sep. 2010.
[4] A. Sant’Anna and N. Wickstrom, “Developing a motion language: Gait
analysis from accelerometer sensor systems,” in Proc. 3rd Int. Conf. Pervas. Comput. Technol. Healthcare, 2009, pp. 1–8.
[5] G. Salvi, L. Montesano, A. Bernardino, and J. Santos-Victor, “Language
bootstrapping: Learning word meanings from perception—Action association,” IEEE Trans. Syst., Man, Cybern. B: Cybern., vol. 42, no. 3,
pp. 660–671, Jun. 2012.
[6] L. Ren, G. Shakhnarovich, J. K. Hodgins, H. Pfister, and P. Viola, “Learning silhouette features for control of human motion,” ACM Trans. Graph.
(ToG), vol. 24, no. 4, pp. 1303–1331, 2005.
[7] L. Wang, T. Tan, H. Ning, and W. Hu, “Silhouette analysis-based gait
recognition for human identification,” IEEE Trans. Pattern Anal. Mach.
Intell., vol. 25, no. 12, pp. 1505–1518, Dec. 2003.
[8] M. Ahmad and S.-W. Lee, “Recognizing human actions based on silhouette energy image and global motion description,” in Proc. 8th IEEE Int.
Conf. Autom. Face Gesture Recog., 2008, pp. 1–6.
[9] M. Kristan, S. Kovacic, A. Leonardis, and J. Pers, “A two-stage dynamic
model for visual tracking,” IEEE Trans. Syst., Man, Cybern. B: Cybern.,
vol. 40, no. 6, pp. 1505–1520, Dec. 2010.
[10] H.-S. Yoon, J. Soh, Y. J. Bae, and H. Seung Yang, “Hand gesture recognition using combined features of location, angle, and velocity,” Pattern
Recog., vol. 34, no. 7, pp. 1491–1501, 2001.
[11] G. Panahandeh, N. Mohammadiha, A. Leijon, and P. Handel, “Continuous
hidden Markov model for pedestrian activity classification and gait analysis,” IEEE Trans. Instrum. Meas., vol. 62, no. 5, pp. 1073–1083, May
2013.
[12] T. Ito, “Walking motion analysis using 3d acceleration sensors,” in Proc.
2nd UKSIM Eur. Symp. Comput. Model. Simulat., 2008, pp. 123–128.
[13] Z. Zhang and J. Wu, “A novel hierarchical information fusion method for
three-dimensional upper limb motion estimation,” IEEE Trans. Instrum.
Meas., vol. 60, no. 11, pp. 3709–3719, Nov. 2011.
[14] M. Donno, E. Palange, F. Di Nicola, G. Bucci, and F. Ciancetta, “A new
flexible optical fiber goniometer for dynamic angular measurements: Application to human joint movement monitoring,” IEEE Trans. Instrum.
Meas., vol. 57, no. 8, pp. 1614–1620, Aug. 2008.
[15] Y. Gu, H. Do, Y. Ou, and W. Sheng, “Human gesture recognition through a
kinect sensor,” in Proc. IEEE Int. Conf. Robot. Biomimet., 2012, pp. 1379–
1384.
[16] O. Amft, H. Junker, and G. Troster, “Detection of eating and drinking arm
gestures using inertial body-worn sensors,” in Proc. IEEE 9th Int. Symp.
Wearable Comput., 2005, pp. 160–163.
[17] H. Zhou, H. Hu, H. Liu, and J. Tang, “Classification of upper limb motion
trajectories using shape features,” IEEE Trans. Syst. Man, Cybern. C,
Appl. Rev., vol. 42, no. 6, pp. 970–982, Nov. 2012.

1914

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 6, NOVEMBER 2014

[18] Welcome to poeticon++. Access: 12 July, 2013. (2012). [Online]. Available: http://www.poeticon.eu
[19] G. Guerra-Filho and Y. Aloimonos, “A language for human action,” Computer, vol. 40, no. 5, pp. 42–51, 2007.
[20] G. Guerra-Filho, C. Fermuller, and Y. Aloimonos, “Discovering a language
for human activity,” presented at the AAAI Fall Symp. Anticipat. Cognit.
Embodied Syst., Washington, DC, USA, 2005.
[21] L. Reng, T. B. Moeslund, and E. Granum, “Finding motion primitives in
human body gestures,” in Gesture in Human-Computer Interaction and
Simulation. New York, NY, USA: Springer-Verlag, 2006, pp. 133–144.
[22] O. Jenkins and M. Mataric, “Deriving action and behavior primitives
from human motion data,” in Proc. IEEE/RSJ Int. Conf. Intell. Robots
Syst., 2002, vol. 3, pp. 2551–556.
[23] T. Caelli, A. McCabe, and G. Binsted, “On learning the shape of complex
actions,” in Visual Form 2001. New York, NY, USA: Springer-Verlag,
2001, pp. 24–39.
[24] Elbow stretches. Access: 12 July, 2013. (2008). [Online]. Available:
http://www.physioadvisor.com.au/8113050/elbow-stretches-elbowexercise-physio-advisor.htm
[25] F. Frenet, “Sur les courbes à double courbure,” J. de Mathématiques pures
et appliquées, vol. 17, pp. 437–447, 1852.
[26] J.-A. Serret, “Sur quelques formules relatives à la théorie des courbes à
double courbure,” J. de Mathématiques pures et appliquées, vol. 16, pp.
193–207, 1851.
[27] H. Abdi, “The method of least squares,” in Encyclopedia of Measurement
and Statistics. Thousand Oaks, CA, USA: SAGE, 2007.
[28] A. Nealen and T. Darmstadt. (2004). “An as-short-as-possible introduction
to the least squares, weighted least squares and moving least squares
methods for scattered data approximation and interpolation,” [Online].
Available: URL: http://www.nealen.com/projects
[29] A. Savitzky and M. J. Golay, “Smoothing and differentiation of data by
simplified least squares procedures,” Anal. Chem., vol. 36, no. 8, pp. 1627–
1639, 1964.
[30] J. J. LaViola, Jr., “A comparison of unscented and extended Kalman filtering for estimating quaternion motion,” in Proc. IEEE Amer. Control
Conf., 2003, vol. 3, pp. 2435–440.
[31] L. R. Rabiner, “A tutorial on hidden Markov models and selected applications in speech recognition,” Proc. IEEE, vol. 77, no. 2, pp. 257–286,
Feb. 1989.
[32] H. L. Van Trees, Detection, Estimation, and Modulation Theory. New
York, NY, USA: Wiley, 2004.
[33] L. E. Baum, “An inequality and associated maximization technique in
statistical estimation for probabilistic functions of a Markov process,”
Inequalities, vol. 3, pp. 1–8, 1972.
[34] K. Pastra, P. Dimitrakis, E. Balta, and G. Karakatsiotis, “Praxicon and its
language-related modules,” in Proc. Compan. Vol. 6th Hellen. Conf. Artif.
Intell., 2010, pp. 27–;32.
[35] J. McCarthy, “The differential geometry of curves in an image space of
spherical kinematics,” Mech. Mach. Theory, vol. 22, no. 3, pp. 205–211,
1987.
[36] M. P. Do Carmo and M. P. Do Carmo, Differential Geometry of Curves
and Surfaces. Englewood Cliffs, NJ, USA: Prentice-Hall, vol. 2, 1976.
[37] K. Murphy, “The Bayes net toolbox for MATLAB,” Comput. Sci. Statist.,
vol. 33, no. 2, pp. 1024–1034, 2001.

Saiyi Li received the B.Sc. degree in communication
and transportation from Harbin Institute of Technology, Shandong, China, in 2008, and the M.S. degree
in applied information technology from Monash University, Melbourne, VIC, Australia, in 2010. He is
currently working toward the Ph.D. degree in electronic engineering at Deakin University, Geelong,
VIC, Australia.
His research interests include rehabilitation engineering and machine learning.

Mario Ferraro received the Laurea degree in theoretical physics from the University of Torino, Turin,
Italy, in 1973.
He has worked in several laboratories in England,
Germany, Canada, United States, and Australia,
working on fuzzy sets theory, human vision, invariant
pattern recognition, and computational vision. Currently, he is an Associate Professor of physics at the
University of Torino. His research interests include
shape analysis, gaze shift theory, cellular biophysics,
and statistical mechanics.

Terry Caelli (F’02) received the Honors degree in
mathematics and psychology and the Ph.D. degree
in human and machine vision from the University of
Newcastle, Callaghan, NSW, Australia.
He is currently a Senior Principal Researcher at
National ICT Australias (NICTA) and part of the
Control and Signal Processing Research Group. His
expertise lies in human and machine signal processing, computer vision, and pattern recognition. He is
a Fellow of the International Association for Pattern
Recognition (FIAPR). He has spent 15 years in North
American universities and research institutes. He returned from Canada to join
NICTA in 2004.

Pubudu N. Pathirana (SM’08) was born in 1970 in
Matara, Sri Lanka, and was educated at Royal College
Colombo, Colombo, Sri Lanka. He received the B.E.
degree (first class honors) in electrical engineering
and the B.Sc. degree in mathematics in 1996, and the
Ph.D. degree in electrical engineering from the University of Western Australia, Crawley, WA, Australia,
in 2000, all sponsored by the government of Australia
on EMSS and IPRS scholarships, respectively.
He was a Postdoctoral Research Fellow at Oxford
University, Oxford, U.K., a Research Fellow at the
School of Electrical Engineering and Telecommunications, University of New
South Wales, Sydney, NSW, Australia, and a Consultant to the Defence Science
and Technology Organization (DSTO), Canberra, VIC, Australia, in 2002. He
was a Visiting Associate Professor at Yale University, New Haven, CT, USA, in
2009. Currently, he is an Associate Professor with the School of Engineering,
Deakin University, Geelong, VIC, Australia, and his current research interests
include mobile/wireless networks, rehabilitation robotics, and radar array signal
processing.

