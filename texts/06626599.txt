1478

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

Design and Development of a Virtual Reality
Simulator for Advanced Cardiac Life
Support Training
Akshay Vankipuram, Prabal Khanal, Aaron Ashby, Mithra Vankipuram, Ashish Gupta, Denise DrummGurnee,
Karen Josey, and Marshall Smith

Abstract—The use of virtual reality (VR) training tools for medical education could lead to improvements in the skills of clinicians
while providing economic incentives for healthcare institutions.
The use of VR tools can also mitigate some of the drawbacks
currently associated with providing medical training in a traditional clinical environment such as scheduling conflicts and the
need for specialized equipment (e.g., high-fidelity manikins). This
paper presents the details of the framework and the development
methodology associated with a VR-based training simulator for
advanced cardiac life support, a time critical, team-based medical
scenario. In addition, we also report the key findings of a usability study conducted to assess the efficacy of various features of this
VR simulator through a postuse questionnaire administered to various care providers. The usability questionnaires were completed
by two groups that used two different versions of the VR simulator.
One version consisted of the VR trainer with it all its features and
a minified version with certain immersive features disabled. We
found an increase in usability scores from the minified group to the
full VR group.
Index Terms—Advanced cardiac life support (ACLS), design,
medical training, usability, virtual reality (VR).

I. INTRODUCTION
HE advent of high-speed networks and powerful computing systems has increased the dissemination of graphically
intensive applications and software for purposes beyond the
more traditional uses such as recreational gaming. The ability
of gaming mediums and principles to provide easy access to
users and increase their engagement, while disseminating information and skill training necessary for game-play, has attracted
the attention of educators and led to much debate and research on

T

Manuscript received March 15, 2013; revised June 24, 2013 and August
19, 2013; accepted September 30, 2013. Date of publication October 9, 2013;
date of current version June 30, 2014. This work was supported by TATRC,
Department of Defense, and Award #W81XWH-08-2-0186.
A. Vankipuram, P. Khanal, A. Ashby, and M. Vankipuram are with the
Biomedical Informatics, Arizona State University, Phoenix, AZ 85004 USA
(e-mail: akshay1087@gmail.com; prabalkhanal@gmail.com; aarona@asu.edu;
mvankipu@asu.edu).
A. Gupta is with the Department of Management, University of Tennessee
Chattanooga, Chattanooga, TN 37403 USA (e-mail: gupta@utc.edu).
D. DrummGurnee, K. Josey, and M. Smith are with the SimET Center,
Banner Health, Phoenix, AZ 85006 USA (e-mail: Denise.DrummGurnee@
bannerhealth.com;
Karen.Josey@bannerhealth.com;
Mark.Smith@
bannerhealth.com).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2013.2285102

its adoption for teaching curriculum [1], [2]. For example, serious games have been used to provide students and trainees with
an engaging way to learn in addition to developing the skills,
abilities, and critical knowledge required for real-world application [3]. Building these types of games in interactive computing
environments [4], [5] has led to the widespread adoption and
use of these educational games for skills training and knowledge acquisition.
In the field of medical care, virtual reality (VR) has been used
to create clinical scenarios that provides individuals and teams
the opportunity to practice skills and procedures in simulated
environments [6], [7]. In this type of professional training, the
user’s learning is maximized if the VR system provides real-time
performance feedback and summative assessment. For example,
VR simulators for surgical training track parameters such as
smoothness of hand motion and instrument penetration depth for
real-time analysis and presentation to the trainee. The collective
performance results for one or more training sessions can also
be conveyed to the user for a summative assessment of their
progress, including a comparative ranking of the performance
or proficiency of other medical professionals. In the case of
training systems designed for mastery of a specific protocol or
procedure, useful real-time and summative measures include:
adherence to protocol, time to initiate key events, failure to
perform critical tasks, and communication patterns.
This paper focuses on a VR simulation platform designed to
provide a cost effective alternative to collocated team training.
Advanced cardiac life support (ACLS) is a protocol that provides guidance on the clinical interventions that need to be provided during cardiac arrests and respiratory failures. The time
sensitive tasks need to be performed by newly formed teams
of clinicians who need to coordinate their actions to save the
patient. Training clinicians in such a protocol typically involves
assembling trainees in a VR simulation training center and utilizing manikins to train clinicians in teams. Noncollocated VR
training eliminates the requirement for all team members to
have to travel to a single location, often missing valuable work
hours. It also increases accessibility, simplifies scheduling, and
provides the possibility for periodic recertification in the critical
protocol. Additionally, VR simulations can be less expensive to
build, operate, and maintain in the long term.
VR training does have certain disadvantages. Clinicians may
at times be overwhelmed by the technology used that may deter
them from using the system. Second, maintenance of such a
system would require trained computer engineers and may be

2168-2194 © 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

VANKIPURAM et al.: DESIGN AND DEVELOPMENT OF A VIRTUAL REALITY SIMULATOR

difficult for clinicians to maintain. However, with the ability to
provide frequent remote training, the advantages of using VR
may outweigh the downsides.
ACLS training is presently conducted in traditional face-toface settings in a majority of hospitals. One of the main goals
of this study is to propose the design, development, and testing of a new virtual worlds environment for conducting such
trainings remotely and more conveniently. We first present the
design and development of a VR trainer for ACLS with results
from a pilot experiment conducted to assess usability of the system. First, we cover some background information on ACLS,
its usage, state-of-art method of training delivery and its drawbacks. Next, we look at relevant work that has been done broadly
in the field of simulation in healthcare. We present the design
rationale for our simulator and identify specific technological
challenges in implementing the proposed design framework.
The required technologies are identified in the conceptual design and development sections. Finally, the adoption of new
methods of healthcare training requires the system to present
an efficient and engaging alternative to the status-quo. To that
end, we present the findings of a usability study conducted to
understand the impact of the features of the simulator.
II. BACKGROUND
ACLS refers to a set of time sensitive and clinical teambased procedural interventions that are intended to be employed
to provide life-saving measures during cardiac arrests and respiratory failures. These procedures require extensive medical
knowledge and skill. According to 2010 protocol guidelines
laid out by the American Heart Association [8], ACLS may
only be administered by qualified medical professionals such
as nurses, physicians, paramedics, etc. Administration of the
protocols by trained professionals has been shown to increase
patient outcomes as much as 20% [9]. When a patient requires
these measures a code is called.
The ACLS code is a high stress, time critical scenario that
requires each team member to have complete medical knowledge of various protocols and the ability to collaborate on tasks
and communicate with team members. Errors in conducting the
procedures or lapses in communication could be potentially fatal for the patient. An ACLS team is comprised of five to six
members depending on the size of the institution or the number
of personnel available. As soon as the code begins, each medical team member randomly assumes a role that defines the tasks
they will be performing during the resuscitation process. These
roles are: leader, compressor, medicator, defibrillator, respirator,
and airway manager. The names of these roles were defined by
us for the purposes of this simulator to identify the personnel
associated with the tasks. The protocol does not specifically
provide names to the roles. The tasks required according to the
protocol are expected to be performed sequentially on the patient suffering from a cardiac arrest within the prescribed time
frame and using proper protocol.
Mock codes are conducted by hospitals to provide protocol training for medical personnel using clinical simulation exercises [10]. Clinical simulation involves procedural steps for

1479

each protocol that are performed on a patient substitute, which
is typically a human analog (i.e., manikin). One or more instructors may be present during the training to observe team’s
performance as they work on the required set of tasks. Each
scenario takes approximately 5 min. After completing the session, instructors provide an evaluation of the team’s performance
through a debriefing session.
There are however, some specific drawbacks of clinical simulation that we attempt to address in this paper.
1) The aspects of team interaction are not addressed by the
training. Even high-fidelity manikins only provide data
about the specific tasks that were performed on it. However, the role played by team members in the success or
failure of a session are hard to determine. The simulated
3-D environment allows for full control over the information presented to the users and gathered from them.
2) The mock code instructor faces a number of problems
such as needing to capture a large amount of information
and keeping track of multiple, synchronously occurring
tasks in order to provide effective feedback. These aspects
are greatly simplified by our ACLS simulation due to the
automated capture of activities and storage in an online
database.
3) High-fidelity manikins are expensive, curtailing their
ubiquity in hospitals, due to which a team of ACLS
trainees is required to convene at specified locations to receive training. This usually means that clinicians at most
receive training twice a year. Moreover, this also causes
scheduling conflicts for clinicians whose schedules are often very busy. This remote trainer enable supplementing
current training methods with remote periodic training to
ensure clinicians are up-to-date on the protocols.
III. RELATED WORK
A. VR-Based Training in Medicine
VR has been shown to be effective in training psychomotor and surgical skills, specifically laparoscopic skills. Multiple
studies have shown that VR simulators can be used to predict expertise in surgeons as well as train and assess skills [6], [7], [11].
Mantovani et al. [12] describe the potential benefits of VR-based
training to healthcare education as being able to provide experiential and active learning.
Distributed virtual environments, also known as collaborative
virtual environments (CVE), are powerful simulated environments capable of providing some or all of the features of VR
training mentioned previously. CVEs can be used to create a
process framework for computer-supported collaborative learning tools that have many important benefits in education [13]
and is different in several respects to e-learning, which is much
more straightforward but probably a less effective concept [14].
Based on fidelity, current medical simulation technology can
be classified into several different categories [15]: low fidelity,
simulated patients, screen-based computer simulations, complex task trainers, and realistic patient simulators. One example of a form of VR-based collaborative platform is described
by Chodos et al. [15] using two case studies of virtual world

1480

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

training systems developed for healthcare education. The first
being an emergency medical technician (EMT)/emergency
room (ER) scenario simulation implemented in a prototype built
using Second-Life [16] with the goal of providing procedural
training to EMT students and attempting to enhance their communication skills. The second case study is based on a system
called “InterD 410,” which is a virtual environment aimed at
creating a communication skills instructional program. One of
the drawbacks of the virtual with limited visual fidelity is that
they do not encourage users to reuse them. To encourage these,
simulations need to be designed to be immersive and engaging.
Immersive VR systems have been developed to deal with
different aspects of training such as skill or behavioral modification. Kizony et al. [17] present a VR simulator designed to
facilitate neurological rehabilitation in patients. Colt et al. [18]
found that the use of a virtual bronchoscopy simulation led to
significant improvement in novice dexterity and accuracy. Dev
et al. [19] designed a computer-based virtual emergency department simulator to train medical residents in managing trauma
effectively. A primary focus of this system was distance training,
teamwork, and leadership. A study of the user training in this
environment compared to training on a human patient simulator
showed comparable improvement from pretest to posttest.
Parab [20] developed a prototype VR simulator to provide
distance training for the ACLS protocol. This simulator was the
predecessor for this study and the current simulator described in
this paper includes some of the features from the prototype. The
simulator was developed on the Active Worlds platform [21]
and allowed users participate in a virtual mock code. Some
of the main drawbacks of this simulator were 1) the low visual
fidelity of the Active Worlds platform, 2) all the users were given
a static view of the environment, 3) simulation administrators
had no access to the data captured, and 4) no in-simulation
voice communication methodology was available. The virtual
world was hosted on the Active world’s server, which limited the
functionality provided to the developers. The system described
in this study was designed in an attempt to address these issues.
In addition, we attempt to provide an engaging and productive
experience while incorporating aspects of team training.
IV. CONCEPTUAL DESIGN
A. Overview
To address the issues stated earlier, certain technological challenges had to be addressed. These include the following.
1) Situational Awareness in VR: Capturing user’s performance as part of a team involves the ability for each user to
be physically aware of every other user in the simulated environment. To achieve this, we required a 3-D rendering engine
capable of creating complex high-fidelity (visual and auditory)
environments while provide a framework for almost complete
customization. We used the Unreal Development Toolkit based
on the UnrealEngine as it allowed us to implement all of the
aforementioned.
2) Cardiopulmonary Resuscitation (CPR) Training: Performing and accurately measuring CPR parameters such as
depth, rate of compressions and recoil is critical to the

Fig. 1.

ACLS VR Architecture.

successful delivery of ACLS training. To achieve this, a custom setup for a haptic joystick was created to simulate CPR and
capture the data. The joystick was interfaced with the Unreal
Development Kit (UDK).
3) Database Support: A comprehensive database needed to
be created and interfaced with the UDK to capture and retrieve
all the information required form the simulation in real time. In
addition, we provided an offline report generation feature using
the data collected by the database to allow users to potentially
track progress and compare the performance.
4) Communication Support: All the users needed to be given
the ability to communicate vocally in real time within the simulated environment using a popular voice over IP (VOIP) software
called TeamSpeak.
5) Network Support for Multiuser VR Simulation: All aspects of the simulation needed to be tailored to fit a network
model owing to the need to allow users to run simulations from
remote locations simultaneously. The components required to
achieve this were the UDK server, voice server, and database
server together in a central location and have the users connect
to it.
B. Framework
The VR environment consists of the six roles that make up an
ACLS team as shown in Fig. 1. These roles occupy specific locations within the VR environment. The locations of these roles
approximately reflect positions occupied by the corresponding
roles in the real world. These details were determined by interviewing protocol experts. Each remote user performs a specific
role in the team by controlling the corresponding virtual role.
The tasks associated with each role in the scenario may be
performed by remote users in the real world. Remote users could
log into the environment from distributed locations. The users
interact with the environment and receive feedback in the form
of animations and messages. Each role has a unique heads-up
display (HUD) that is used as a part of the feedback delivery
system as well as a method for performing certain actions by
clicking on icons. In the real world, an example of a common
HUD is the dashboard behind the steering wheel of a car. It
provides information about the current performance of the car

VANKIPURAM et al.: DESIGN AND DEVELOPMENT OF A VIRTUAL REALITY SIMULATOR

Fig. 2.

1481

(Left) CPR role screenshot, (Right) haptic joystick setup.

(mileage in miles per hour and engine revolutions per minutes),
in addition to parameters that show long-term status of the car
(fuel and temperature gauge, for example). Similarly in our
simulation, the HUD comprises of the visual feedback elements
that describe current status of the patient and team performance.
The feedback elements also include six red bars representing
each of the six users that glow green indicating the source of the
speech.
Each user role is represented within the virtual environment
by an avatar (a 3-D human analog visually representing tasks
performed by the users).
C. System Design
Each user connected to the VR simulation has access to a
unique user interface (UI) as shown in Fig. 1. Each UI includes
a graphical user interface (GUI) consisting of the role specific
HUD, the feedback system, a method for interuser communications via headsets using the TeamSpeak VOIP API [22] and a
modified Novint Falcon haptic joystick [23] required to perform
CPR.
The communication is voice activated and hands free and
each user can speak to all other users in the VR environment.
The current speaker is identified according to their ACLS role
and this information is displayed on HUD of all users.
The haptic module was developed in order to simulate the tactile feedback experienced by a person performing compression.
In addition, the device was designed to interface with the VR environment for precision measurement, real-time feedback, and
performance assessment. The design of this module was based
on prior work done by Khanal and Kahol [24], who integrated
the joystick into a virtual world. A human chest provides a
considerable amount of resistive force when compressed during
CPR. Manikin simulators typically emulate this phenomenon
through the simple incorporation of a large spring. A spring was
harvested from a Laerdal CPR manikin [25] spring and shortened for insertion into the base of the haptic joystick head as
seen in Fig. 2.
The next layer of the architecture consists of the feedback
mechanisms in the form of real-time on-screen messaging, realtime performance evaluation, and finally, sound-based feedback,
i.e., cues corresponding to sounds heard in a real environment.

Fig. 3. VR Screenshot with a local message (black font) and a global message
(yellow font) showing the leader role.

The messages were of two types: affirmatory and persuasive.
Affirmatory messages were displayed in a white colored font and
confirm to the user that a particular task or action was completed.
Persuasive messages (black font seen in Fig. 3) remind the user
to perform a certain action or coordinate with a team member.
Persuasive messages were unique to every user, and therefore,
only displayed locally for each role. Affirmative messages, on
the other hand, consist of messages that are both local and
global.
The final layer consists of the three server-side modules:
the primary UDK server, a voice communication server, and
a MySQL server. The system was designed using server-client
architecture. The simulated environment and the voice and
database modules were hosted on a server and each of the six
clients had access to the features of each module. All data from
simulator are stored in the online MYSQL database using cSQL
libraries [26].
D. Platform
The ACLS simulator was implemented using the UnrealEngine3 via the UDK [27]. The UDK is a free game development kit for noncommercial purposes and provides a means
to create, edit, and deploy high-fidelity 3-D environments with
sounds, animations, feedback via HUDs and menus, and allows
for the integration of custom third party software libraries using
C++ dynamic linked libraries. This results in the developers
having complete control over all information collected in the
simulation and also gives users the ability to rapidly customize
the scenario when required. Furthermore, the UDK allows for
the creation of scenarios at a higher level of fidelity than other
mainstream virtual world development softwares.
V. DEVELOPMENT METHODOLOGY
A. UI
The primary input devices for all users were the mouse and
keyboard. The compressor and airway manager roles were also
provided with the haptic device for performing chest compressions. The ACLS simulation GUI consists of all the visual

1482

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

elements incorporated into the simulation. The main components of the GUI are as follows.
1) Environmental Assets and Avatars: The VR environment
is rendered centrally on the dedicated UDK server, and then,
replicated to all clients. The setting for the VR-based training
has been designed to resemble a standard hospital room, stocked
with the minimum amount of medical equipment required to
successfully complete the two VR mock code scenarios. The
avatars were purchased and all other objects within the environment were created using Autodesk Maya [28]. The environment
also consisted of audio cues such as charging the defibrillator and the hissing of oxygen gas escaping from wall mounted
nozzle.
2) Role Specific Points of View and HUD: The HUD is the
primary visual interface provided to the user to interact with
the environment. This ACLS simulator included a unique HUD
for each of the six roles. Each user was also provided with
various icons that could be triggered anytime to perform the
tasks associated with that role. These icons are shown on the top
of the screen in Figs. 2 and 3.
3) Messages and Feedback: Real-time feedback was provided in the form of sounds, animations, and text messages that
flash across the center of the screen for 3 s. Sounds and animations are part of the feedback system as they convey auditory
and visual cues regarding performance of a task.
B. Haptic Joystick Module
The haptic joystick was integrated into the simulation by
creating a plugin using the Novint SDK. The positional data
sent from the device are scaled to track the depth and recoil
of compressions, which are then displayed in the form of a
compression meter seen on the bottom left corner of Fig. 2. The
rate is calculated for every interval of time taken to complete 30
compressions.
C. Communication Module
The TeamSpeak 3 (TS3) SDK libraries were integrated into
the development environment. The main purpose of creating an
internal communication module is that the identity of the user
who is currently speaking can be determined and conveyed to
all other users.
The communication module was not always active because
it is susceptible to echoing and feedback noise. To prevent this,
communication was initialized when the user began speaking.
TS3 allows for voice activity detection and triggers communication when the voice activity level exceeds a set threshold. The
identity of current speaker was determined by detecting which
client initialized the voice communication and is then simultaneously conveyed to other users by an on screen widget found
on the top right corners of Fig. 3.
D. Networking and Multiplayer
An important part of the framework for a team trainer is the
system’s ability to support multiple users simultaneously. UDK
allows developers the freedom to create a custom dedicated

server on which to host the game, and this is important so that
all users connected to the system can see certain actions and
events occur when instigated by a single user. This is needed so
that all users are aware of and have the ability to respond to the
events in the environment. However, this functionality must be
triggered manually so that all users can see the event.
E. Database Module
All information from within the simulation can be stored in
the database. Such as, task initiated times, roles, tasks descriptions, details of medications, CPR rate and depth of compressions, etc.
This data can be used to create a repository of ACLS team
performance in order to study trends for multiple teams over
multiple sessions or to give summative feedback on a single
session.
VI. USABILITY STUDY AND RESULTS
A. Study Design
Ninety-six ACLS-certified clinicians were recruited for this
study to conduct usability testing of the system. Subjects for the
study were clinicians from Banner Health network and were required to be ACLS certified at the time of the experiment. There
were no other exclusion criteria. All these participants were organized into 16 different teams; each consisting of six randomly
assigned members to represent six key roles: leader, medicator, defibrillator, airway manager, respirator, and compressor.
Each of these roles was assigned to perform a set of tasks in
accordance with the ACLS guidelines. The 16 teams were randomly further split into two groups that interacted with two
different versions of the VR simulator (one having all persuasive features and the other with a limited set of persuasive features). The usability testing of these two variations of game
was conducted in the Simulation education and Training Center
(SIMET) at Banner Good Samaritan Medical Center in Phoenix,
AZ, USA.
The participants were initially asked to view a 20 min tutorial
video unique to each role. The video consisted of the simulation with a voice-over discussing various aspects and features
available to the user performing a particular role. This was followed by a 30-min session where the participants were asked to
run through four to five virtual mock codes each approximately
5 min in length. The length of the mock codes was set at 5 min
since this is the length of a mock code when conducted as part of
regular ACLS training and certification. After the session, the
participants were required to fill out a usability questionnaire
(ease of use [29] and system usability). The usability questions
are shown below and were marked on a Likert scale of 1–5
(1—strongly negative; 5—strongly positive).
In order to understand the effect of persuasive components
on the usability of the system, the groups were given two versions of the ACLS VR simulator. The fully persuasive VR
simulator consisted of all the components mentioned in the
methodology Section V. The minimally persuasive VR simulator was equipped with limited persuasive elements. The highly

VANKIPURAM et al.: DESIGN AND DEVELOPMENT OF A VIRTUAL REALITY SIMULATOR

1483

TABLE I
USABILITY QUESTIONNAIRE

Fig. 4.

Mean scores comparison (ease of use).

Fig. 5.

Mean scores comparison (usability).

persuasive VR simulator included persuasive messaging, which
could improve the sense of anticipation and urgency among
users as well as alerts and messages box were also included to
prevent the users from seeing any global affirmatory messages.
The communication bar on the top right corner of the screen
was also included that informed the user about whom they were
speaking. Such features were not included in the minimally
persuasive VR game.
B. Results and Discussion
An analysis of the average usability score for each of the
six questions asked showed that the ratings for the minimally
persuasive group exceeded that of the persuasive group for both
variables (ease of use and usability paired t-test) as seen in Figs.
4 and 5.
Persuasive features, such as, the communication indicator and
global messages were incorporated into the simulation in order
to foster a sense of situational awareness as well as guidance
within the simulation for the user. However, the usability scores
suggest that overall the persuasive messaging may have caused
unanticipated breaks that distracted the users. The medicator
role is the only role that shows a slightly higher usability score
for the persuasive group. A closer at the user responses indicates
that question U2 (learning to operate) from Table I was higher
(3.75– 3) for the persuasive group only in the case of the medicator role. This could indicate that the complexity associated
with the medicator role required the persuasive guidance to help
the users learn the role.

Our observations of numerous ACLS trainings suggest that
there is high level of interruption activity going on during the
training sessions, which may be detrimental to the performance
of ACLS team members. Low level of communication and interaction among team members are undesirable as well [30], [31].
It is, therefore, important to design the VR that integrates various
design features such that they minimize the need for frequent
messaging. This could be accomplished using effective persuasive and visualization elements.
The persuasive messages in the feedback system were created
to provide timely feedback for commonly occurring scenarios.
A number of combinations of possible feedback mechanisms
were not modeled into the simulation since they occur relatively
infrequently. The current simulation could not convey a realtime performance score to the users due to the lack of a validated
scoring technique for ACLS procedure. The simulation also did
not inform the users if the patient was saved by the team. The
VR simulator may be improved to support additional features
that provide better support for the fast-paced procedure.
VII. CONCLUSION AND FUTURE WORK
This study describes the design and development of an immersive VR ACLS simulator for use in distributed and noncollocated settings by care providers. The system records all
task-specific information such as CPR feedback for each user
playing a specific role, which is typically missing in regular
ACLS training. The usability study showed that the persuasive
features lead to unanticipated distractions for the users from
their ongoing tasks. However, in the case of a complex role
such as that of a medicator, the learning was enhanced by the
presence of persuasive components.
The next step is to conduct a validation study using clinicians at Banner Health. This means designing experiments to
assess content and construct validity. Future work on the simulator could involve design improvements related to adding an
extended scoring metric based on the data collected from interactions with the system. This scoring metric can then be incorporated into future versions of the simulator to provide real-time
performance feedback for the whole team. Current ACLS VR
simulator models only two different scenarios. More sophisticated scenarios could be built into the VR simulator to extend it
to include different causes described in the guidelines. This will
extend the scope of the simulator and offer more comprehensive training. Furthermore, as the results of the usability study

1484

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

suggest, further studies are needed to understand the efficacy of
messaging system itself.
The knowledge of and expertise in ACLS protocols are required skills for most medical professionals. The VR simulator
presented in this study offers a convenient mechanism for offering ACLS training to care providers in an immersive, multiuser
setting that also allows for users to train from remote locations.
ACKNOWLEDGMENT
The authors would like to thank L. Tinker, B. Wasem, N.
Foote, M. Kasperski, and P. Farrer from Banner Health SimET
Center, Phoenix, AZ, USA for their feedback during the development of the simulator.
REFERENCES
[1] K. Squire and H. Jenkins, “Harnessing the power of games in education,”
Insight, vol. 3, pp. 5–33, 2004.
[2] K. Squire, “Video games in education,” Int. J. Intell. Games Simul., vol. 2,
pp. 49–62, 2003.
[3] M. D. Aguilera and A. Mendiz, “Video games and education: (Education
in the Face of a “Parallel School”),” Comput. Entertain., vol. 1, pp. 1–10,
2003.
[4] M. D. Dickey, “Game design and learning: a conjectural analysis of how
massively multiple online role-playing games (MMORPGs) foster intrinsic motivation,” Educational Technol. Res. Develop., vol. 55, pp. 252–273,
2007.
[5] T. Susi, M. Johannesson, and P. Backlund, “Serious games—An
overview,” School of Humanities and Informatics, Universtiy of Skövde,
Skövde, Sweden, Rep. HS-IKI-TR-07-001, 2007.
[6] M. Neal, E. Seymour, P. Anthony, G. Gallagher, M. Sanziana, A. Roman,
M. Michael, K. O’Brien, M. Vipin, K. Bansal, M. Dana, K. Andersen,
and R. M.> Satava, “Virtual reality training improves operating room
performance,” Ann. Surg., vol. 236, pp. 458–464, 2002.
[7] T. P. Grantcharov, V. B. Kristiansen, J. Bendix, L. Bardram, J. Rosenberg,
and P. Funch-Jensen, “Randomized clinical trial of virtual reality simulation for laparoscopic skills training,” Brit. J. Surg., vol. 91, pp. 146–150,
2004.
[8] R. W. Neumar, C. W. Otto, M. S. Link, S. L. Kronick, M. Shuster, C.
W. Callaway, P. J. Kudenchuk, J. P. Ornato, B. McNally, S. M. Silvers,
R. S. Passman, R. D. White, E. P. Hess, W. Tang, D. Davis, E. Sinz,
and L. J. Morrison, “2010 american heart association guidelines for cardiopulmonary resuscitation and emergency cardiovascular care science,”
Circulation, vol. 122, pp. S729–S767, 2010.
[9] M. A. Moretti, L. A. M. Cesar, A. Nusbacher, K. B. Kern, S. Timerman,
and J. A. Ramires, “Advanced cardiac life support training improves longterm survival from in-hospital cardiac arrest,” Resuscitation, vol. 72,
pp. 458–465, 2007.
[10] D. B. Wayne, “Mastery learning of advanced cardiac life support skills
by internal medicine residents using simulation technology and deliberate
practice,” J. Gen. Internal Med., vol. 21, pp. 251–256, 2006.
[11] N. Taffinder, C. Sutton, R. Fishwick, I. McManus, and A. Darzi, “Validation of virtual reality to teach and assess psychomotor skills in laparoscopic surgery: Results from randomized controller studies using the
MIST VR laparoscopic simulator,” in Proc. Med. Meets Virtual Reality,
1998, pp. 124–130.

[12] F. Mantovani, G. Castelnuovo, A. Gaggioli, and G. Riva, “Virtual reality training for health-care professionals,” CyberPsychol. Behav., vol. 6,
pp. 389–395, 2003.
[13] T. Tsiatsos, K. Andreas, and A. Pomportsis, “Evaluation framework for
collaborative educational virtual environments,” Educational Technol.
Soc., pp. 65–77, 2010.
[14] G. Stahl, T. Koschmann, and D. Suthers, Computer Supported Collaborative Learning: An Historical Perspective. Cambridge, U.K.: Cambridge
Univ. Press, 2006.
[15] D. Chodos, E. Stroulia, P. Boechler, S. King, P. Kuras, M. Carbonaro,
and E. de Jong, “Healthcare education with virtual-world simulations,”
presented at the 2010 ICSE Workshop on Software Engineering in Health
Care, Cape Town, South Africa, 2010.
[16] Linden Research Inc. (2003, Mar. 8, 2013). Second Life. [Online]. Available: http://secondlife.com/
[17] R. Kizony, N. Katz, and P. L. Weiss, “Adapting an immersive virtual
reality system for rehabilitation,” J. Vis. Comput. Animation, vol. 15,
pp. 261–268, 2003.
[18] H. G. Colt, S. W. Crawford, and O. Galbraith, “Virtual reality bronchoscopy simulation: A revolution in procedural training,” Chest, vol. 120,
pp. 1333–1339, 2001.
[19] P. Dev, P. Youngblood, W. L. Heinrichs, and L. Kusumoto, “Virtual worlds
and team training,” Anesthesiol. Clinics, vol. 25, pp. 321–336, 2007.
[20] S. Parab, “Time critical team training in Virtual Worlds” Masters Thesis,
Dept. Comput. Sci., Arizona State Univ., Phoenix, AZ, USA, 2010.
[21] Active Worlds Inc. (2013, Mar. 8). Active Worlds. [Online]. Available:
http://www.activeworlds.com/
[22] TeamSpeak Systems GmbH. (2013, Mar. 8). TeamSpeak 3. [Online]. Available: http://www.teamspeak.com/
[23] Novint Technologies Inc. (2013, Mar. 8). Novint Falcon. [Online]. Available: http://www.novint.com/index.php/novintfalcon
[24] P. Khanal and K. Kahol, “Interactive haptic virtual collaborative training
simulator to retain CPR skills,” in Ambient Media and Systems, Portugal,
2011, pp. 70–77.
[25] Laerdal. (Mar. 8, 2013). Resusci Anne Basic. [Online]. Available:
http://www.laerdal.com/us/doc/73/Resusci-Anne-Basic
[26] LAKSHYA. (Mar. 8, 2013). cSQL Database. [Online]. Available:
http://www.csqldb.com/
[27] Epic Games. (Mar. 8, 2013). Unreal Development Toolkit. [Online]. Available: www.udk.com
[28] Autodesk Inc. (2013, Mar. 8). Autodesk Maya. [Online]. Available:
http://usa.autodesk.com/maya/
[29] V. Venkatesh, M. G. Morris, G. B. Davis, and F. D. Davis, “User acceptance of information technology: Towards a unified view,” MIS Quart.,
vol. 27, pp. 425–478, 2003.
[30] R. S. Baron, “Distraction–conflict theory: Progress and problems,” in
Advanced in Experimental Social Psychology, L. Berkowitz, Ed. New
York, NY, USA: Academic Press, 1986.
[31] A. Gupta, H. Li, and R. Sharda, “Should I send this message? Understanding the impact of interruptions, social hierarchy and perceived task complexity on user performance,” Decision Support Syst., vol. 55, pp. 135–
145, 2013.

Authors’ photographs and biographies not available at the time of publication.

