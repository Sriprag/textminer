1874

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 6, NOVEMBER 2014

Segmentation of the Blood Vessels and Optic Disk
in Retinal Images
Ana Salazar-Gonzalez, Djibril Kaba, Yongmin Li, and Xiaohui Liu

Abstract‚ÄîRetinal image analysis is increasingly prominent as a
nonintrusive diagnosis method in modern ophthalmology. In this
paper, we present a novel method to segment blood vessels and
optic disk in the fundus retinal images. The method could be used
to support nonintrusive diagnosis in modern ophthalmology since
the morphology of the blood vessel and the optic disk is an important indicator for diseases like diabetic retinopathy, glaucoma, and
hypertension. Our method takes as first step the extraction of the
retina vascular tree using the graph cut technique. The blood vessel
information is then used to estimate the location of the optic disk.
The optic disk segmentation is performed using two alternative
methods. The Markov random field (MRF) image reconstruction
method segments the optic disk by removing vessels from the optic
disk region, and the compensation factor method segments the optic disk using the prior local intensity knowledge of the vessels. The
proposed method is tested on three public datasets, DIARETDB1,
DRIVE, and STARE. The results and comparison with alternative
methods show that our method achieved exceptional performance
in segmenting the blood vessel and optic disk.
Index Terms‚ÄîGraph cut segmentation, optic disk segmentation,
retinal images, vessel segmentation.

I. INTRODUCTION
HE segmentation of retinal image structures has been of
great interest because it could be used as a nonintrusive
diagnosis in modern ophthalmology. The morphology of the
retinal blood vessel and the optic disk is an important structural indicator for assessing the presence and severity of retinal
diseases such as diabetic retinopathy, hypertension, glaucoma,
hemorrhages, vein occlusion, and neovascularization. However,
to assess the diameter and tortuosity of the retinal blood vessel
or the shape of the optic disk, manual planimetry has commonly
been used by ophthalmologists, which is generally time consuming and prone to human error, especially when the vessel
structures are complicated or a large number of images are acquired to be labeled by hand. Therefore, a reliable automated
method for retinal blood vessel and optic disk segmentation,

T

Manuscript received August 21, 2013; revised January 16, 2014 and November 28, 2013; accepted January 17, 2014. Date of publication January 27, 2014;
date of current version November 3, 2014.
A. Salazar-Gonzalez was with the Department of Computer Science, Brunel
University, Middlesex, UB8 3PH, London, U.K. She is now with Access IS,
Reading, RG6 1AZ, U.K.
D. Kaba, Y. Li, and X. Liu are with the Department of Computer Science,
Brunel University, Middlesex, UB8 3PH, London, U.K. (e-mail: kabadjibril@
gmail.com).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2302749

which preserves various vessel and optic disk characteristics, is
attractive in computer-aided diagnosis.
An automated segmentation and inspection of retinal blood
vessel features such as diameter, color, and tortuosity as well
as the optic disk morphology allows ophthalmologists and eye
care specialists to perform mass vision screening exams for early
detection of retinal diseases and treatment evaluation. This could
prevent and reduce vision impairments, age-related diseases,
and many cardiovascular diseases, as well as reduce the cost of
the screening.
Over the past few years, several segmentation techniques have
been employed for the segmentation of retinal structures such
as blood vessels and optic disks and diseases like lesions in
fundus retinal images. However, the acquisition of fundus retinal
images under different conditions of illumination, resolution
and field of view (FOV), and the overlapping tissue in the retina
cause a significant degradation of the performance of automated
blood vessels and optic disk segmentations. Thus, there is a need
for a reliable technique for retinal vascular tree extraction and
optic disk detection, which preserves various vessel and optic
disk shapes. In the following segment, we briefly review the
previous studies on the blood vessel segmentation and optic
disk segmentation separately.
II. RELATED WORKS
Two different approaches have been deployed to segment the
vessels of the retina: the pixel-processing-based methods and
tracking-based methods [1].
The pixel-processing-based approach performs the vessel
segmentation in a two-pass operation. First, the appearance of
the vessel is enhanced using detection processes such as morphological preprocessing techniques and adaptive filtering. The
second operation is the recognition of the vessel structure using
thinning or branch-point operations to classify a pixel as a vessel
or background (Bg). These approaches process every pixel in
the image and apply multiple operations on each pixel. Some
pixel processing methods use neutral networks and frequency
analysis to define pixels in the image as vessel pixels and Bg
pixels. Typical pixel processing operations are shown by Hoover
et al. [2], Mendoca et al. [3], Soares et al. [4], Staal et al. [5],
Chaudhuri et al. [6], and Zana et al. [7].
The second set of approaches for vessel segmentation are referred to as vessel tracking, vectorial tracking, or tracing [1]. In
contrast to the pixel-processing-based approaches, the tracking
methods detect first initial vessel seed points, and then track
the rest of the vessel pixels through the image by measuring
the continuity proprieties of the blood vessels. This technique is
used as a single-pass operation, where the detection of the vessel

This work is licensed under a Creative Commons Attribution 3.0 License. For more information, see http://creativecommons.org/licenses/by/3.0/

SALAZAR-GONZALEZ et al.: SEGMENTATION OF THE BLOOD VESSELS AND OPTIC DISK IN RETINAL IMAGES

structures and the recognition of the structures are simultaneously performed.
The tracking-based approaches included semiautomated tracing and automated tracing. In the semiautomated tracing methods, the user manually selects the initial vessel seed point. These
methods are generally used in quantitative coronary angiography analysis and they generally provide accurate segmentation
of the vessels. In fully automated tracing, the algorithms automatically select the initial vessel points and most methods use
Gaussian functions to characterize a vessel profile model, which
locates a vessel point for the vessel tracing. They are computationally efficient and more suitable for retinal image processing.
Examples of the tracking-based approaches are presented by Xu
et al. [8], Maritiner-perez et al. [9], Staal et al. [5], and Zhou
et al. [10].
Both pixel processing and tracking approaches have their own
advantages and limitations over each other. The pixel processing approaches can provide a complete extraction of the vascular
tree in the retinal image since they search all the possible vessel pixels across the whole image. However, these techniques
are computationally expensive and require special hardware to
be suitable for large image dataset. The presence of noise and
lesions in some retinal images causes a significant degradation in the performance of the pixel processing approaches as
the enhancement operation may pick up some noise and lesions as vessel pixels. This could lead to false vessel detection
in the recognition operation. On the other hand, the tracking
approaches are computationally efficient and much faster than
the pixel processing methods because they perform the vessel
segmentation using only the pixels in the neighborhood of the
vessels structure and avoid the processing of every pixel in the
image. Nevertheless, these methods lack in extracting a complete vascular tree in the case where there are discontinuities in
the vessel branches. Furthermore, the semiautomated tracking
segmentation methods need manual input, which requires time.
The optic nerve head is described as the brightest round area
in the retina where the blood vessels converge with a shape
that is approximately elliptical and has a width of 1.8 ¬± 0.2 mm
and height 1.9 ¬± 0.2 mm [11]. The convergence feature of blood
vessels into the optic disk region is generally used to estimate the
location of the optic disk and segment it from the retinal image.
But the intrusion of vessels in the optic disk region constitutes
computational complexity for the optic disk segmentation as it is
breaking the continuity of its boundary. To address this problem,
several methods have been employed such as those presented
by Chrastek et al. [12], Lowell et al. [13], Welfer et al. [14], and
Aquino et al. [15].
Chrastek et al. [12] presented an automated segmentation of
the optic nerve head for diagnosis of glaucoma. The method
removes the blood vessel by using a distance map algorithm;
then, the optic disk is segmented by combining a morphological operation, Hough transform, and an anchored active contour
model. Lowell et al. [13] proposed a deformable contour model
to segment the optic nerve head boundary in low-resolution
retinal images. The approach localizes the optic disk using a
specialized template matching and a directionally sensitive gradient to eliminate the obstruction of the vessel in the optic disk

Fig. 1.

1875

Vessel segmentation algorithm.

region before performing the segmentation. Welfer et al. [14]
proposed an automated segmentation of the optic disk in color
eye fundus image using an adaptive morphological operation.
The method uses a watershed transform marker to define the
optic disk boundary, and the vessel obstruction is minimized by
morphological erosion.
These techniques are performed using morphological operations to eliminate the blood vessels from the retinal image. However, the application of morphological operations can modify the
image by corrupting some useful information.
In our optic disk segmentation process, the convergence feature of vessels into the optic disk region is used to estimate its
location. We then use two automated methods [Markov random
field (MRF) image reconstruction and compensation factor] to
segment the optic disk.
The rest of the paper is organized as follows. The blood vessel
segmentation is discussed in Section III. Section IV provides the
detailed description of the optic disk segmentation. Section V
presents the experimental results of our method with comparisons to other methods. Conclusions are drawn in Section VI.
The preliminary results of the three components of the approach,
namely the blood vessel segmentation, optic disk segmentation
using the graph cut and MRF, respectively, were presented separately in [16]‚Äì[18]. More details of the approach can be found
in the Ph.D. thesis [19].
III. BLOOD VESSEL SEGMENTATION
Blood vessels can be seen as thin elongated structures in the
retina, with variation in width and length. In order to segment
the blood vessel from the fundus retinal image, we have implemented a preprocessing technique, which consists of an effective
adaptive histogram equalization and robust distance transform.
This operation improves the robustness and the accuracy of the
graph cut algorithm. Fig. 1 shows the illustration of the vessel
segmentation algorithm.
A. Preprocessing
We apply a contrast enhancement process to the green channel
image similar to the work presented in [20]. The intensity of the
image is inverted, and the illumination is equalized. The resulting image is enhanced using an adaptive histogram equalizer,

1876

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 6, NOVEMBER 2014

TABLE I
WEIGHT ASSIGNMENT OF THE EDGES IN THE GRAPH

Fig. 2. Preprocessing. (a) h = 45, r = 3, (b) h = 45, r = 6, (c) h = 81, r =
3, (d) h = 81, r = 6, (e) distance map, and (f) sample of a vessel with arrows
indicating the vessel gradients.

given by
‚éûr
 s (I (p) ‚àí I (p ))
‚é† ¬∑M
=‚éù
h2

‚éõ

IEnhanced

A graph G (ŒΩ, ) is defined as a set of nodes (pixels) ŒΩ and a set
of undirected edges  that connect these neighboring nodes. The
graph included two special nodes, a foreground (Fg) terminal
(source S) and a Bg terminal (sink T ).  includes two types
of undirected edges: neighborhood links (n-links) and terminal
links (t-links). Each pixel p ‚àà P (a set of pixels) in the graph
presents two t-links {p, S} and {p, T } connecting it to each
terminal, while a pair of neighboring pixels {p, q} ‚àà N (number
of pixel neighbors) is connected by an n-link [21]. Thus,

{{p, S}, {p, T }, ŒΩ = P ‚à™ {S, T }}.
(2)
=N
p‚ààP

(1)

p ‚ààR (p)

where I is the green channel of the fundus retinal color image, p


denotes a pixel, and p is the neighborhood pixel around p. p ‚àà
R(p) is the square window neighborhood with length h. s(d) =
1 if d > 0, and s(d) = 0 otherwise with d = s (I (p) ‚àí I (p )).
M = 255 value of the maximum intensity in the image. r is
a parameter to control the level of enhancement. Increasing
the value of r would also increase the contrast between vessel
pixels and the Bg as seen in Fig. 2. The experimental values of
the window length was set to h = 81 and r = 6.
A binary morphological open process is applied to prune the
enhanced image, which discards all the misclassified pixels in
Fig. 2(d). This approach significantly reduces the false positive,
since the enhanced image will be used to construct the graph for
segmentation.
A distance map image is created using the distance transform
algorithm. This is used to calculate the direction and the magnitude of the vessel gradient. Fig. 2(e) and (f) shows the distance
map of the whole image and a sample vessel with arrows indicating the direction of the gradients, respectively. From the
sample vessel image, we can see the center line with the brightest pixels, which are progressively reduced in intensity in the
direction of the edges (image gradients). The arrows in Fig. 2(f)
are referred to as vector field, which are used to construct the
graph in the next sections.
B. Graph Construction for Vessel Segmentation
The graph cut is an energy-based object segmentation approach. The technique is characterized by an optimization operation designed to minimize the energy generated from a given
image data. This energy defines the relationship between neighborhood pixel elements in an image.

An edge e ‚àà  is assigned a weight (cost) We > 0. A cut is
defined by a subset of edges C ‚àà , where G (c) = ŒΩ, \C
separating the graph into Fg and Bg with C defined as |C| =

e‚ààC We
The max-flow algorithm is used to cut the graph and find the
optimal segmentation. Table I assigns weight to the edges  in
the graph [21], where

Bp,q ,
(3)
K = 1 + maxp‚ààP
{p,q }

and F and B represent the subsets of pixels selected as the
Fg and Bg, respectively. Thus, F ‚äÇ P and B ‚äÇ P such that
F ‚à© B = 	. Bp,q defines the discontinuity between neighboring pixels, and its value is large when the pixel intensities. Œª > 0
is a constant coefficient, which we will define in the energy formulation of the graph.
The graph cut technique is used in our segmentation because
it allows the incorporation of prior knowledge into the graph
formulation in order to guide the model and find the optimal
segmentation. Let us assume A = (A1 , Ap , . . . , AP ) is a binary
vector set of labels assigned to each pixel p in the image, where
Ap indicate assignments to pixels p in P . Therefore, each assignment Ap is either in the Fg or Bg. Thus, the segmentation is
obtained by the binary vector A and the constraints imposed on
the regional and boundary proprieties of vector A are derived
by the energy formulation of the graph defined as
E (A) = Œª ¬∑ R (A) + B (A)

(4)

where the positive coefficient Œª indicates the relative importance
of the regional term (likelihoods of Fg and Bg) RA against the
boundary term (relationship between neighborhood pixels) BA .
The regional or the likelihood of the Fg and Bg is given by

Rp (Ap )
(5)
R (A) =
p‚ààP

SALAZAR-GONZALEZ et al.: SEGMENTATION OF THE BLOOD VESSELS AND OPTIC DISK IN RETINAL IMAGES

Fig. 4.

Fig. 3. Retinal blood vessel segmentation using the traditional graph. (a) Seeds
initialization of the input image, (b) Œª = 20, (c) Œª = 50, and (d) Œª = 100.

and the boundary constraints are defined as

Bp,q ¬∑ œÜ (Ap , Aq )
B (A) =

(6)

p,q ‚ààN

where œÜ (Ap , Aq ) = 1 for Ap 
= Aq and 0 otherwise,
Bp,q = exp(‚àí

(Ip ‚àí Iq)2
1
.
)¬∑
2œÉ 2
dist(p, q)

(7)

Rp (Ap ) specifies the assignment of pixel p to either the Fg
or the Bg. Bp,q defines the discontinuity between neighboring
pixels, and its value is large when the pixel intensities Ip and Iq
are similar and close to zero when they are different. The value
of Bp,q is also affected by the Euclidean distance dist(p, q)
between pixels p and q.
During the minimization of the graph energy formulation
in (4) to segment thin objects like blood vessels, the second
term (boundary term) in (4) has a tendency to follow short
edges known as ‚Äúthe shrinking bias‚Äù [22]. This problem causes
a significant degradation of the performance of the graph cut
algorithm on thin elongated structures like the blood vessels.
Fig. 3 shows an example of the blood vessel segmentation using
the traditional graph formulation [23]. From Fig. 3, it can be
seen that the blood vessel segmentation follows short edges,
and tends to shrink in the search for the cheapest cost. It can
also be noticed that Œª in (4) controls the relation between the
boundary and regional terms. Increasing the value of Œª, the
likelihood of the pixels belonging to the Fg and Bg (t-links)
gains strength over the regional term (n-links), which slightly
improves the segmentation result as shown in Fig. 3(d).
To address the aforementioned problem, the segmentation of
blood vessels using the graph cut requires a special graph formulation. One of the methods used to address the shrinking bias
problem is to impose an additional connectivity prior, where the
user marks the constraint connectivity [22]. In order to achieve
full automated segmentation, we used the method presented
in [23], which overcomes the ‚Äúshrinking bias‚Äù by adding the
mechanism of vectors flux into the construction of the graph.

1877

Flux of vectors v passing through a given surface S.

The incorporation of vectors flux can improve edge alignment
and allows the segmentation of thin objects like blood vessels
by keeping a balance between shrinking (length) and stretching
(vectors flux) along the boundary. Fig. 4 shows a flux of vectors
v passing through a given surface S. Our method takes the image
gradients of rough blood vessels from the preprocessing step as
vectors v shown in Fig. 2(f), and the flux (magnitude and direction) of these vectors is incorporated into the graph construction
and optimized. Thus, the shrinking effect of the minimization
energy on the boundary term is equilibrated with the spreading
effect of vectors v flux.
It has been shown in [23] that the class of the Finsler metrics
can describe geometric proprieties of the discrete cut metric on
regular grids and the Finsler length can be represented by the
sum of two terms. Those terms represent the symmetric and
antisymmetric parts of the cut metric. The symmetric part of
the cut defines the standard geometric length of contour and it
is independent of its orientation. The antisymmetric part of the
cut metric represents the flux of a given vector field through the
contour [23].
To address ‚Äúthe shrinking bias‚Äù problem shown in Fig. 3,
we have constructed a graph consisting of a symmetric part g +
(shrinking) and an antisymmetric part g ‚àí (stretching) by incorporating the flux of vector v into the graph construction. The
symmetric part g + of the graph corresponds to a cut geometric
length and is related directly to the n-link connections and the
antisymmetric part g ‚àí is equal to the flux of the vector field v
over the cut geometric and it is used to derive the t-links. Thus,
the blood vessels can be segmented by keeping a good balance
between shrinking and stretching (flux) throughout the image
boundary.
1) Symmetric Part of the Graph: It is used to assign weights
on the n-link connections (edges between neighboring pixels).
Let us consider a neighbor system of a graph described by a
set of edges ek , where 1 ‚â§ k ‚â§ N , for N number of neighbors.
Let us define ek as the shortest vector connecting two pixels in
the direction of k, Wk+ (p) as the weight of the edge ek at pixel
	 + (p) as a set of the edge weights at pixel p for all
p, and W
k
directions. The corresponding edge weights are defined by
1
D √ó g+
2
where D is an N √ó N matrix with entries defined as
œâ+ =

Dii = ‚àí

sin(Œ±i+1 ‚àí Œ±i‚àí1 )
sin(Œ±i+1 ‚àí Œ±i )sin(Œ±i ‚àí Œ±i‚àí1 )

(8)

(9)

1878

Fig. 5.

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 6, NOVEMBER 2014

Neighborhood system for a grid in the graph.

‚éß
‚é®
Dij =

1
sin (Œ±j ‚àí Œ±i )
‚é©
0

if j + 1 ¬± 1 mod N
for other entries

where Œ±k is the angle of the edge ek with respect to the positive
axis X as shown in Fig. 5.
In our implementation, we consider a grid map of 16 neighbors with edges ek , k = 1, 2, . . . , 16 as shown in Fig. 5. For each
	 + (p) is
pixel p in the green channel image, the edge weight W
k
+
computed according to (8). g is calculated using the pixel
intensity difference between two given nodes by


‚àí(Ip ‚àí Iq )2
g + = K ¬∑ exp
.
(10)
œÉ2
g + has a high value for pixels of similar intensities, when
Ip ‚àí Iq < œÉ. However, if the pixels are very different Ip ‚àí Iq >
œÉ, the value of g + is small, which represents a poor relation
between the pixels; hence, they belong to different terminals
[24].
2) Antisymmetric Part of the Graph: We used the term antisymmetry because the flux (stretching) of the vector field v
over the cut geometric balanced the shrinking of blood vessels
during the segmentation. This antisymmetric part of the graph
is defined by the flux of the vector field v over the cut geometric. It is used to assign weights on the t-links (edges between
a given pixel and the terminals) to balance the shrinking effect
seen in Fig. 3. Specific weights for t-links are obtained based on
the deposition of vector v. Different decompositions of vector
v may result in different t-links whose weights can be interpreted as an estimation of divergence. In our implementation,
we decomposed the vector v along grid edges with the n-links
oriented along the main axes, i.e., in the X- and Y -directions.
Thus, vector v can be decomposed as v = vx ux + vy uy , where
ux and uy are unit vectors in the X- and Y -directions, respectively. This decomposition leads to the t-link weights defined
as
 

Œ¥2 
(11)
tp = [ vxright ‚àí vxleft + vyup ‚àí vxdown ]
2
where vxright and vxleft are the components of vector v in the
X-direction taken at the right and left neighbors of pixel P ,

Fig. 6. Vessel segmentation using the decomposition of vector v: (a) input
retinal image, (b) blood vessel segmentation using horizontal (X -axis) decomposition of vector v, (c) blood vessel segmentation using vertical (Y -axis)
decomposition of vector v, and (d) blood vessel segmentation result using the
decomposition of vector v along the X- and Y-axes.

respectively. vyup and vydown are in the Y -direction of vector v
taken at the top and down neighbors of pixel P . Œ¥ is the size of
the cell in the grid map (see Fig. 5). We add edge (s ‚Üí p) with
weight C ‚àó (‚àítp) if tp < 0, or edge (p ‚Üí t) with weight C ‚àó tp
otherwise. The parameter C is related to the magnitude of the
vector v; thus, the pixels in the center of the blood vessel have a
higher connection to the source (Fg) than the pixels in the edge
of the blood vessels. Because the distance map is calculated on
the pruned image and vector v is only defined for the pixels
detected as blood vessels in the rough segmentation, for the rest
of the pixels in the image, the initialization of t-link weights
is set as (p ‚Üí s) with weight t = 0 and (p ‚Üí t) with weight
t = K, where K is the maximum weight sum for a pixel in the
symmetric construction. Fig. 6 shows the segmentation results
of the blood vessels using different decomposition of the vector
v generating different t-link weights.
IV. OPTIC DISK SEGMENTATION
The optic disk segmentation starts by defining the location
of the optic disk. This process used the convergence feature of
vessels into the optic disk to estimate its location. The disk area
is then segmented using two different automated methods (MRF
image reconstruction and compensation factor). Both methods
use the convergence feature of the vessels to identify the position
of the disk. The MRF method is applied to eliminate the vessel
from the optic disk region. This process is known as image
reconstruction and it is performed only on the vessel pixels to
avoid the modification of other structures of the image. The
reconstructed image is free of vessels and it is used to segment
the optic disk via graph cut. In contrast to MRF method, the
compensation factor approach segments the optic disk using
prior local intensity knowledge of the vessels. Fig. 7 shows
the overview of both the MRF and the compensation factor
methods.

SALAZAR-GONZALEZ et al.: SEGMENTATION OF THE BLOOD VESSELS AND OPTIC DISK IN RETINAL IMAGES

1879

Fig. 7. (a) MRF image reconstruction method diagram and (b) compensation
factor method diagram.

A. Optic Disk Location
Inspired by the method proposed in [14], which effectively
locates the optic disk using the vessels, we use the binary image
of vessels segmented in Section III to find the location of the
optic disk. The process iteratively traces toward the centroid of
the optic disk. The vessel image is pruned using a morphological
open process to eliminate thin vessels and keep the main arcade.
The centroid of the arcade is calculated using the following
formulation:
Cx =

K

xi
i=1

K

Cy =

K

yi
K
i=1

Fig. 8. Optic disk detection. (a) Retinal image green channel with 1% of the
brightest region selected in green color, (b) binary segmented blood vessel,
(c) binary segmented blood vessel after pruning, and (d) sequence of points
from the centroid to vessel convergence point (optic disk location).

(12)

where xi and yi are the coordinates of the pixel in the binary
image and K is the number of pixels set to 1 (pixels marked as
blood vessels) in the binary image.
Given the gray scale intensity of a retinal image, we select 1%
of the brightest region. The algorithm detects the brightest region
with the most number of pixels to determine the location of the
optic disk with respect to the centroid point (right, left, up, or
down). The algorithm adjusts the centroid point iteratively until
it reaches the vessel convergence point or the center of the main
arcade (center of the optic disk) by reducing the distance from
one centroid point to next one in the direction of the brightest
region, and correcting the central position inside the arcade
accordingly. Fig. 8 shows the process of estimating the location
of the optic disk in a retinal image. It is important to notice that
the vessel convergence point must be detected accurately, since
this point is used to automatically mark Fg seeds. A point on
the border of the optic disk may result in some false Fg seeds.
After the detection of the vessel convergence point, the image
constrained a region of interest (ROI) including the whole area
of the optic disk to minimize the processing time. This ROI is
set to a square of 200 √ó 200 pixels concentric with the detected
optic disk center. Then, an automatic initialization of seeds (Fg
and Bg) for the graph is performed. A neighborhood of 20 pixels
of radius around the center of the optic disk area is marked as
the Fg pixels, and a band of pixels around the perimeter of the
image are selected as the Bg seeds in Fig. 9.
B. Optic Disk Segmentation With MRF Image Reconstruction
The high contrast of blood vessels inside the optic disk presented the main difficulty for its segmentation as it misguides
the segmentation through a short path, breaking the continuity
of the optic disk boundary. To address this problem, the MRF-

Fig. 9. Optic disk detection. (a) ROI image, (b) initialization of the foreground
F, and the background B of the ROI image.

based reconstruction method presented in [25] is adapted in our
study. We have selected this approach because of its robustness.
The objective of our algorithm is to find a best match for some
missing pixels in the image; however, one of the weaknesses
of the MRF-based reconstruction is the requirement of intensive computation. To overcome this problem, we have limited
the reconstruction to the ROI, and using prior segmented retina
vascular tree, the reconstruction was performed in the ROI. An
overview diagram of the optic disk segmentation with the MRF
image reconstruction is shown in Fig. 7.
Let us consider a pixel neighborhood w(p) defined as a
square window of size W , where pixel p is the center of the
neighborhood. I is the image to be reconstructed and some
of the pixels in I are missing. Our objective is to find the
best approximate values for the missing pixels in I. So, let
d(w1, w2) represent a perceptual distance between two patches
that defines their similarity. The exact matching patch corresponds to d(w , w(p)) = 0. If we define a set of these patches
as Œ©(p) = {œâ  ‚äÇ I : d(œâ  , œâ(p)) = 0}, the probability density
function of p can be estimated with a histogram of all center
pixel values in Œ©(p). However, since we are considering a finite
neighborhood for p and the searching is limited to the image
area, there might not be any exact matches for a patch. For

1880

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 6, NOVEMBER 2014

Fig. 10. MRF reconstruction applied to retinal images. Top: original grayscale images. Bottom: reconstructed images using the MRF-based method.

this reason, we find a collection of patches, whose match falls
between the best match and a threshold. The closest match is
calculated as œâb est = argminœâ d(œâ(p), œâ) ‚äÇ I. All the patches
œâ with d(œâ(p), œâ) < (1 + )d(œâ(p), œâb est ) are included in the
collection œâ  . d(w , w(p)) is defined as the sum of the absolute differences of the intensities between patches, so identical
patches will result in d(w , w(p)) = 0. Using the collection of
patches, we create a histogram and select the one with the highest mode. Fig. 10 shows sample results of the reconstruction.
The Fgs and the Bgs seeds are initialized in the reconstructed
image, which are then used in graph cut formulation to segment
the optic disk. Similar to Fig. 9, the initialization of the Fgs and
Bgs seeds is performed using the reconstructed image.
The graph cut algorithm described in Section III-B is used
to separate the Fg and the Bg by minimizing the energy function over the graph and producing the optimal segmentation of
the optic disk in the image. The energy function of the graph
in (4) consists of regional and boundary terms. The regional
term (likelihoods of Fg and Bg) is calculated using (5), while
the boundary term (relationship between neighboring pixels) is
derived using (6). A grid of 16 neighbors N is selected to create
links between pixels in the image Im. The max-flow algorithm
is used to cut the graph and find the optimal segmentation.
C. Optic Disk Segmentation With a Compensation Factor
In contrast to the MRF image reconstruction, we have incorporated the blood vessels into the graph cut formulation by
introducing a compensation factor V ad. This factor is derived
using prior information of the blood vessel.
The energy function of the graph cut algorithm generally
comprises boundary and regional terms. The boundary term
defined in (6) is used to assign weights on the edges (n-links) to
measure the similarity between neighboring pixels with respect
to the pixel proprieties (intensity, texture, and color). Therefore,
pixels with similar intensities have a strong connection. The
regional term in (5) is derived to define the likelihood of the
pixel belonging to the Bg or the Fg by assigning weights on the
edges (t-link) between the image pixels and the two terminals

Fig. 11. Optic disk segmentation with the compensation factor V ad method:
(a) V ad = 20, (b) V ad = 100, (c) V ad = 150, and (d) V ad = 250.

Bg and Fg seeds. In order to incorporate the blood vessels into
the graph cut formulation, we derived the t-link as follows:

‚àí ln Pr (Ip \ Fgseeds )
if p 
= vessel
(13)
Slink =
‚àí ln Pr (Ip \ Fgseeds ) + V ad if p = vessel

‚àí ln Pr (Ip \Bgseeds ) if p 
= vessel
Tlink =
(14)
‚àí ln Pr (Ip \Bgseeds ) if p = vessel
where p is the pixel in the image, Fgseeds is the intensity distribution of the Fg seeds, Bgseeds represents the intensity distribution
of the Bg seeds, and V ad is the compensation factor given as
V ad = maxp‚ààvessel {‚àí ln Pr (Ip \Bgseeds )}.

(15)

The intensity distribution of the blood vessel pixels in the
region around the optic disk makes them more likely to belong
to Bg pixels than the Fg (or the optic disk pixels). Therefore, the
vessels inside the disk have weak connections with neighboring
pixels making them likely to be segmented by the graph cut as
Bg. We introduce in (13) a compensation vector to all t-links
of the Fg for pixels belonging to the vascular tree to address
this behavior. Consequently, vessels inside the optic disk are
classified with respect to their neighborhood connections instead
of their likelihood with the terminals Fg and Bg seeds. Fig. 11
shows sample of images segmented by the compensation factor.
The segmentation of the disk is affected by the value of V ad,
and the method achieves poor segmentation results for low value
of V ad. However, when the value of the V ad increases, the
performance improves until the value of V ad is high enough to
segment the rest of the vessels as Fg.
V. RESULTS
For the vessel segmentation method, we tested our algorithm
on two public datasets, DRIVE [5] and STARE [2] with a total
of 60 images. The optic disk segmentation algorithm was tested
on DRIVE [5] and DIARETDB1 [26], consisting of 129 images
in total. The performances of both methods are tested against a
number of alternative methods.
The DRIVE consists of 40 digital images which were captured
from a Canon CR5 nonmydriatic 3CCD camera at 45‚ó¶ FOV. The
images have a size of 768 √ó 584 pixels. The dataset includes

SALAZAR-GONZALEZ et al.: SEGMENTATION OF THE BLOOD VESSELS AND OPTIC DISK IN RETINAL IMAGES

masks to separate the FOV from the rest of the image. It included
two sets of hand-labeled images (set A and set B) for the blood
vessel. Set A offers the manually labeled images for all the
images in the dataset, whereas set B provides the manually
labeled images for half of the dataset. To test our method, we
adopt the set A hand labeling as the benchmark. We manually
delimited the optic disk to test the performance of the optic disk
segmentation algorithm.
The STARE dataset consists of 20 images captured by a TopCon TRV-50 fundus camera at 35‚ó¶ FOV. The size of the images is
700 √ó 605 pixels. We calculated the mask image for this dataset
using a simple threshold technique for each color channel. The
STARE dataset included images with retinal diseases selected
by Hoover et al. [2]. It also provides two sets of hand-labeled images performed by two human experts. The first expert labeled
fewer vessel pixels than the second one. To test our method, we
adopt the first expert hand labeling as the ground truth.
The DIARETDB1 dataset consists of 89 color images with 84
of them containing at last one indication of lesion. The images
were captured with a digital fundus camera at 50‚ó¶ FOV and had
a size of 1500 √ó 1152 pixels. Hand-labeled lesion regions are
provided in this dataset by four human experts. However, the
DIARETDB1 dataset only includes the hand-labeled ground
truth of lesions but not the blood vessels and the optic disk.
For this reason, we were unable to compare the performance
of the blood vessel segmentation on the DIARETDB1 dataset.
Nevertheless, we were able to create the hand-labeled ground
truth of an optic disk to test the performance of the optic disk
segmentation.
To facilitate the performance comparison between our method
and alternative retinal blood vessels segmentation approaches,
parameters such as the true positive rate (TPR), the false positive
rate (FPR), and the accuracy rate (ACC) are derived to measure
the performance of the segmentation [5]. The ACC is defined
as the sum of the true positives (pixels correctly classified as
vessel points) and the true negatives (nonvessel pixels correctly
identified as nonvessel points), divided by the total number of
pixels in the images. The TPR is defined as the total number
of true positives, divided by the number of blood vessel pixels
marked in the ground true image. The FPR is calculated as
the total number of false positives divided by the number of
pixels marked as nonvessel in the ground true image. It is worth
mentioning that a perfect segmentation would have an FPR of 0
and a TPR of 1. Our method and all the alternative methods used
the first expert hand-labeled images as a performance reference.
Most of the alternative methods use the whole image to measure the performance. In [5], all the experiments are carried out
on the FOV without considering the performance in the dark
area outside the FOV. The method in [3] measures the performance on both the whole image and the FOV. The dark Bg
outside the FOV in the retinal image is easy to segment. It is
an advantage in measuring the true negatives pixels when the
whole image is considered. We have calculated the percentage
of pixels outside the FOV in the images for the two datasets,
which represents approximately 25% of the pixels in the whole
image. However, it does not affect all the measurement metrics,
except when the true negative value is involved (e.g., ACC). On

1881

TABLE II
PERFORMANCE COMPARISON IN THE STARE DATASET

TABLE III
PERFORMANCE COMPARISON OF HEALTHY VERSUS DISEASE IMAGES
IN THE STARE DATASET

the other hand, most of the methods use the whole image to
measure their performance, making the comparison fair.
A. Results of the Blood Vessel Segmentation Algorithm
on the STARE Dataset
Tables II and III show performance comparison results of
our approach with recent alternative methods in terms of TPR,
FPR, and ACC on the STARE dataset. The performance results
of the second expert hand labeled and the method proposed by
Martinez-Perez et al. [9] and Staal et al. [5] are taken from [9].
The results of the methods proposed by Mendonca et al. [3]
and Hoover et al. [2] are taken from [3], and the approaches
of Chaudhuri et al. [6], Kaba et al. [27] Marin et al. [28], and
Zhang et al. [29] were generated from their original manuscripts.
The performance results of segmentation for Zhang et al. [29],
Chaudhuri et al. [6], and Soares et al. [30] on both healthy and

1882

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 6, NOVEMBER 2014

Fig. 12. DRIVE dataset: (a) and (d) retinal images, (b) and (e) our segmentation results, and (c) (and e) manually labeled results.

unhealthy images were taken from [29]. The testing includes
all the 20 fundus images except the method proposed by Staal
et al. [5] which used 19 out of the 20 (ten healthy and nine
unhealthy) images.
In Table II, the second human expert hand-labeled image
is considered as the target performance level with average
TPR = 0.7887, given the first human expert hand-labeled image as benchmark. Thus, our method needs an improvement of
10.64% in average true positive, whereas Mendon et al., Staal
et al., Chaudhuri et al., Hoover et al., Kaba et al., MartinezPerez et al., and Zhang et al. have a room of improvement
of 19.55%, 19.81%, 28.17%, 22.00%, 23.06%, 14.45%, and
17.74%, respectively.
Considering the value of average TPR as a performance measure, our proposed approach reaches better performance than
all the other methods. However, with the average ACC, our
method is only marginally inferior to the methods presented by
Staal et al. [5], Kaba et al. [27], Marin et al. [28], and Zhang
et al. [29], but as mentioned previously, Staal et al. [5] used 19
of the 20 images. Compared to the methods proposed by Hoover
et al. [2], Martinez-Perez et al. [9], and Chaudhuri et al. [6], our
approach outperforms the ACC of these techniques and it has
approximately the same value of ACC as Mendonca et al. [3].
Table III compares the performance of the healthy subject images against the unhealthy subject images on the STARE dataset.
The results of the experiments show that the unhealthy ocular
images cause a significant degradation of the performance of
automated blood vessel segmentation techniques. An overview
of the results shows that in both healthy and unhealthy images,
our proposed method achieves a better overall average TPR performance than all the other methods. However, the average ACC
value is comparable to the performance of Soares et al. [30] and
Zhang et al. [29]. It outperforms the ACC of Mendonca et al. [3],
Hoover et al. [2], and Chaudhuri et al. [6] in both healthy and
unhealthy images.
Figs. 12 and 13 show the segmented images and the manually labeled images for the DRIVE and the STARE datasets,
respectively.

Fig. 13. STARE dataset: (a) and (d) retinal images, (b) and (e) our segmentation results, and (c) and (e) manually labeled results.

B. Results of the Blood Vessel Segmentation Algorithm
on the DRIVE Dataset
The performance of the segmentation of our method on the
DRIVE dataset is compared with alternative methods: Zhang
et al. [29], Soares et al. [30], Zana et al. [7], Garg et al. [31],
Perfetti et al. [32], and Al-Rawi et al. [33] taken from [29]. The
results of the second human expert B and the method proposed
by Niemeijer et al. [34], Mendonca et al. [3], and Staal et al. [5]
were acquired from [3]. The results of the methods proposed by
Cinsdikici et al. [35] and Jiang et al. [36] were generated from
Marin et al. [28], and finally, the results of the methods by Ricci
et al. [37], Soares et al. [30], and Martinez-Perez et al. [9] were
acquired from their original manuscripts.
The second human expert B hand-labeled image [3] is considered as the target performance level with average (TPR =
0.7761 and ACC = 0.9473) given the first human expert A
hand-labeled image as reference (benchmark). Table IV shows
the performance of our method against the aforementioned
methods on the DRIVE dataset. Our method needs an overall
improvement of 2.49% and 0.61% in average TPR and average
ACC, respectively.
On the other hand, with an average TPR of 0.7512, our method
achieves better performance than all the other methods with
respect to the average TPR value. The average accuracy achieved
with our approach on DRIVE outperforms Jiang et al. [36],
Cinsdikici et al. [35], Zana et al. [7], Garg et al. [31], Zhang
et al. [29], and Martinez et al. [9]. But it is marginally inferior to
the methods proposed by Al-Rawi et al. [33], Ricci et al. [37],
and Mendonca et al. [3], and it is comparable to Soares et al.
[30], Marin et al. [28], Niemeijer et al. [34], and Staal et al. [5].
It is important to note that the methods presented by Ricci
et al. [37], Soares et al. [30], Marin et al. [28], Niemeijer
et al. [34], and Staal et al. [5] used supervised techniques that
generally depend on the training datasets; thus to achieve good
results, classifier retraining is required before performing any
experimentation on new datasets.
An overview of the testing results on DRIVE shows that our
method offers a reliable and robust segmentation solution for

SALAZAR-GONZALEZ et al.: SEGMENTATION OF THE BLOOD VESSELS AND OPTIC DISK IN RETINAL IMAGES

1883

TABLE IV
PERFORMANCE COMPARISON IN THE DRIVE DATASET

Fig. 14. (a) Optic disk segmentation results of DIARETDB1 images: first row
topology cut, second row graph cut, third row compensation factor algorithm,
fourth row MRF image reconstruction algorithm, and fifth row hand labeled.
(b) Optic disk segmentation results of DRIVE images: first row topology cut,
second row graph cut, third row compensation factor algorithm, fourth row MRF
image reconstruction algorithm, and fifth row hand labeled.

blood vessels. It is clearly observed that our approach reaches
better performance in terms of the average TPR.
C. Results of Optic Disk Segmentation on the DIARETDB1
and DRIVE Datasets
The performance results of our approach are compared to
the alternative methods: the adaptive morphological approach
by Welfer et al. [14], the traditional graph cut technique by
Boykov et al. [24], and the topology cut technique proposed
by Zeng et al. [38]. Unfortunately, it was not possible to test
our method against a large number of alternative methods, since
most of the methods do use a unique benchmark to measure
the results of the optic disk segmentation; therefore, this makes
the comparison of the results difficult. Further comparison is
made between our two optic disk segmentation methods (the
compensation factor and the MRF image reconstruction). All
the methods are tested on the same datasets (DIARETDB1 and
DRIVE) of 109 fundus retinal images in total, including those
with a discernable optic disk.
The optic disk segmentation performance is evaluated by the
overlapping ratio Oratio and the mean absolute distance (MAD).
The overlapping ratio is defined to measure the common area
between the optic disk region in the ground truth and the optic disk region segmented by our method. It is defined by the
following formulation:

G S

Oratio =
G S

(16)

where G represents the true optic disk boundary (manually labeled region) and S is the optic disk boundary segmented by

our method. MAD is defined as
 n

m
1 1
1 
MAD (Gc , Sc ) =
d(gci , S) +
d(sci , G)
2 n i=1
m i=1
(17)
where Gc and Sc are the contours of the segmented regions
of the ground truth and our algorithm, respectively. d(ai , B) is
the minimum distance from the position of the pixel ai on the
contour A to the contour B. A good segmentation implies a high
overlapping ratio and a low MAD value.
The sensitivity of our method on DIARETDB1 and DRIVE
is defined as
Sensitivity =

Tp
Tp + Fn

(18)

where T p and F n are the number of true positives and the
number of false negatives, respectively. The sensitivity indicates
the detection of the Fg pixels by the segmentation method.
Fig. 14(a) and (b) show the optic disk segmentation results
of topology cut technique [38], traditional graph cut technique
[24], and both our methods: the optic disk segmentation with
the compensation factor and the optic disk segmentation with
the MRF image reconstruction on DIARETDB1 and DRIVE,
respectively. Considering the ground truth images, it is clear
that both our methods perform better than alternative methods:
topology cut technique [38] and traditional graph cut technique
[24]. The topology cut technique achieved acceptable results
in the brighter images, characterized by vessels that are more
likely to belong to the Fg (similar intensity as the optic disk).
However, the traditional graph cut technique tends to segment
only the brightest region of the disk; this is due to the intrusion
of the blood vessels in the optic disk region, which misguide the
segmentation algorithm to follow a short path.
Table V shows the performance of our proposed methods
with alternative methods on the DIARETDB1 images. The

1884

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 6, NOVEMBER 2014

TABLE V
PERFORMANCE COMPARISON ON THE DIARETDB1 DATASET

TABLE VI
PERFORMANCE COMPARISON ON THE DRIVE DATASET

compensation factor V ad and the MRF image reconstruction segmentation algorithms achieve the overlapping ratios of
0.7594 and 0.7850, and outperform the approaches in [14], [24],
and [38]. However, considering the performance in terms of a
mean absolute distance, MRF image reconstruction algorithm
reaches the lowest value 6.55 and performs better than all the
other methods. Both our methods achieve the highest average
sensitivity with 87.50% for the MRF image reconstruction and
86.75% for the compensation factor V ad in 96.7% on the DIARETDB1 images.
Table VI shows the performance results of our methods
with other alternative methods in terms of Oratio, MAD, and
Sensitivity on DRIVE images. An overview of the segmentation results shows that our proposed methods achieved the highest overlapping ratio with the minimum MAD value compared
to the traditional graph cut method [24] and the topology cut
method [38], except for the adaptive morphologic method [14],
which is marginally inferior to the compensation factor algorithm in terms of MAD. However, an increase in the overlapping ratio does not necessarily mean a decrease of MAD value.
Thus, the value of MAD alone is not enough to measure the
performance of segmentation results, but it provides a good reference of the contour matching with the ground truth contour
reference.
For further performance comparison, we used the cumulative histogram to compare the overlapping ratio of our proposed
method against topology Cut [38] and graph cut [24]. This is
done by performing each segmentation method against the human expert hand labeled, and the cumulative histogram represents the frequency of the Oratio value. A perfect segmentation
is achieved when the value of Oratio = 1 and the area under the
curve is equal to zero. Figs. 15 and 16 show the plots of the cumulative histograms of the overlapping ratio for topology cut [38]
and graph cut [24], compensation factor and MRF image reconstruction on DIARETDB1 and DRIVE datasets, respectively.
The overview of the graphs shows that the compensation factor
and MRF image reconstruction methods achieve the minimum

Fig. 15.
images.

Cumulative histogram for the overlapping ratio of DIARETDB1

Fig. 16.

Cumulative histogram for the overlapping ratio of DRIVE images.

area under the graph; hence, our method outperforms all other
methods. In general, the MRF image reconstruction method
reaches better results on DRIVE images, while the compensation factor method produces better segmentation results on the
DIARETDB1 dataset.
Based on the assumption in Niemeijer et al. [39], which considers a minimum overlapping ratio Oratio > 50% as a successful segmentation, the compensation factor algorithm with
86.52% success performs better on DRIVE than DIARETDB1
and the segmentation of MRF image reconstruction with 90.00%
achieves better results than the compensation factor algorithm
on DRIVE.
VI. DISCUSSIONS AND CONCLUSION
We have presented a novel approach for blood vessels and
optic disk segmentation in retinal images by integrating the
mechanism of flux, MRF image reconstruction, and compensation factor into the graph cut method. The process also involves
contrast enhancement, adaptive histogram equalization, binary
opening, and distance transform for preprocessing.
We have evaluated the performance of vessel segmentation
against ten other methods including human manual labeling
on the STARE dataset and 15 other methods including human manual labeling on the DRIVE dataset. For the optic disk

SALAZAR-GONZALEZ et al.: SEGMENTATION OF THE BLOOD VESSELS AND OPTIC DISK IN RETINAL IMAGES

segmentation, we have evaluated the performance of our method
against three other methods on the DRIVE and DIARETDB1
datasets.
Tables II, III, and IV show performance comparison in terms
of the average TPR, FPR, and ACC. According to these results,
our vessel segmentation algorithm reaches acceptable results
and outperforms all other methods in terms of average TPR
on both STARE and DRIVE images. In terms of average accuracy, our method outperforms Hoover et al. [2], MartinezPerez et al. [9], and Chaudhuri et al. [6] on STARE images.
On DRIVE, it performs better than Jiang et al. [36], Cinsdikici
et al. [35], Zana et al. [7], Garg et al. [31], Zhang et al. [29], and
Martinez et al. [9]. Nevertheless, our method is marginally inferior to the methods presented by Staal et al. [5], Kaba et al. [27],
Marin et al. [28], and Zhang et al. [29] on STARE, and AlRawi et al. [33], Ricci et al. [37], Mendonca et al. [3], Soares
et al. [30], Marin et al. [28], and Staal et al. [5] on DRIVE. Although Soares et al. [30], Marin et al. [28], Staal et al. [5], and
Ricci et al. [37] seem to achieve higher accuracy, as supervised
techniques, they generally depend on the training datasets; thus
to achieve excellent results, classifier retraining is required before performing any experimentation on new datasets. Further
studies in [28] proved that these methods perform well when
both training and testing are applied on the same dataset, but
the performance deteriorates when the method is tested and
trained on different datasets. Since these methods are sensitive
to the training datasets, deploying them for practical use in retinal blood vessel segmentation would need further improvement
as segmentation algorithms must work on retinal images taken
under different conditions to be effective.
Our proposed method incorporates the prior knowledge of
blood vessels to perform the segmentation, and it can be applied
on retinal images from multiple sources and under different
conditions without a need for training. This can be seen in the
results achieved by this method on both the STARE and DRIVE
datasets.
For the optic disk segmentation, Tables V and VI present
the performance of our method on DIARETDB1 and DRIVE
images. The results show that our methods of using the compensation factor and the MRF image reconstruction achieved the
best overall performance. The results also show that the MRF
image reconstruction algorithm outperforms the compensation
factor algorithm by 2.56% and 11.5% on the DIARETDB1 and
DRIVE images, respectively. However, it is important to notice
that the MRF image reconstruction algorithm depends on the
vessel segmentation algorithm; for example, if the vessel segmentation algorithm achieved a low performance on severely
damage retinal image, the reconstruction would not define a
meaningful optic disk region, and hence the segmentation will
fail.
Furthermore, the proposed method addresses one of the main
issues in medical image analysis, ‚Äúthe overlapping tissue segmentation.‚Äù Since the blood vessels converse into the optic disk
area and misguide the graph cut algorithm through a short path,
breaking the optic disk boundary, to achieve good segmentation
results, the MRF image reconstruction algorithm eliminates vessels in the optic disk area without any modification of the image

1885

structures before segmenting the optic disk. On the other hand,
the compensation factor incorporates vessels using local intensity characteristics to perform the optic disk segmentation. Thus,
our method can be applied in other medical image analysis applications to overcome ‚Äúthe overlapping tissue segmentation.‚Äù
Our future research will be based on the segmentation of retinal diseases (lesions) known as ‚Äúexudates‚Äù using the segmented
structures of the retina (blood vessels and optic disk). Thus, a Bg
template can be created using these structures. Then, this template can be used to perform the detection of suspicious areas
(lesions) in the retinal images.
ACKNOWLEDGMENT
The authors would like to thank V. Kolmogorov for providing
the software MaxFlow-v3.01 to compute the graph cut.
REFERENCES
[1] K. Fritzsche, A. Can, H. Shen, C. Tsai, J. Turner, H. Tanenbuam,
C. Stewart, B. Roysam, J. Suri, and S. Laxminarayan, ‚ÄúAutomated model
based segmentation, tracing and analysis of retinal vasculature from digital fundus images,‚Äù in State-of-The-Art Angiography, Applications and
Plaque Imaging Using MR, CT, Ultrasound and X-rays. Boca Raton,
FL, USA: CRC Press, 2003, pp. 225‚Äì298.
[2] A. Hoover, V. Kouznetsova, and M. Goldbaum, ‚ÄúLocating blood vessels
in retinal images by piecewise threshold probing of a matched filter response,‚Äù IEEE Trans. Med. Imag., vol. 19, no. 3, pp. 203‚Äì210, Mar. 2000.
[3] A. M. Mendonca and A. Campilho, ‚ÄúSegmentation of retinal blood vessels
by combining the detection of centerlines and morphological reconstruction,‚Äù IEEE Trans. Med. Imag., vol. 25, no. 9, pp. 1200‚Äì1213, Sep. 2006.
[4] J. Soares, J. Leandro, R. Cesar, H. Jelinek, and M. Cree, ‚ÄúRetinal vessel
segmentation using the 2-D gabor wavelet and supervised classification,‚Äù
IEEE Trans. Med. Imag., vol. 25, no. 9, pp. 1214‚Äì1222, Sep. 2006.
[5] J. Staal, M. D. Abramoff, M. Niemeijer, M. A. Viergever, and B. van Ginneken, ‚ÄúRidge-based vessel segmentation in color images of the retina,‚Äù
IEEE Trans. Med. Imag., vol. 23, no. 4, pp. 501‚Äì509, Apr. 2004.
[6] S. Chaudhuri, S. Chatterjee, N. Katz, M. Nelson, and M. Goldbaum, ‚ÄúDetection of blood vessels in retinal images using two-dimensional matched
filters,‚Äù IEEE Trans. Med. Imag., vol. 8, no. 3, pp. 263‚Äì269, Sep. 1989.
[7] F. Zana and J.-C. Klein, ‚ÄúSegmentation of vessel-like patterns using mathematical morphology and curvature evaluation,‚Äù IEEE Trans. Image Process., vol. 10, no. 7, pp. 1010‚Äì1019, Jul. 2001.
[8] L. Xu and S. Luo, ‚ÄúA novel method for blood vessel detection from retinal
images,‚Äù Biomed. Eng. Online, vol. 9, no. 1, p. 14, 2010.
[9] M. E. Martinez-Perez, A. D. Hughes, S. A. Thom, A. A. Bharath, and
K. H. Parker, ‚ÄúSegmentation of blood vessels from red-free and fluorescein
retinal images,‚Äù Med. Image Anal., vol. 11, no. 1, pp. 47‚Äì61, 2007.
[10] L. Zhou, M. S. Rzeszotarski, L. J. Singerman, and J. M. Chokreff, ‚ÄúThe
detection and quantification of retinopathy using digital angiograms,‚Äù
IEEE Trans. Med. Imag., vol. 13, no. 4, pp. 619‚Äì626, Dec. 1994.
[11] C. Sinthanayothin, J. F. Boyce, H. L. Cook, and T. H. Williamson, ‚ÄúAutomated localisation of the optic disk, fovea, and retinal blood vessels
from digital colour fundus images,‚Äù Brit. J. Ophthalmol., vol. 83, no. 8,
pp. 902‚Äì910, 1999.
[12] R. Chrastek, M. Wolf, K. Donath, H. Niemann, D. Paulus, T. Hothorn,
B. Lausen, R. Lammer, C. Y. Mardin, and G. Michelson, ‚ÄúAutomated
segmentation of the optic nerve head for diagnosis of glaucoma,‚Äù Med.
Image Anal., vol. 9, no. 1, pp. 297‚Äì314, 2005.
[13] J. Lowell, A. Hunter, D. Steel, A. Basu, R. Ryder, E. Fletcher, and
L. Kennedy, ‚ÄúOptic nerve head segmentation,‚Äù IEEE Trans. Med. Imag.,
vol. 23, no. 2, pp. 256‚Äì264, Feb. 2004.
[14] D. Welfer, J. Scharcanski, C. Kitamura, M. D. Pizzol, L. Ludwig, and
D. Marinho, ‚ÄúSegmentation of the optic disk in color eye fundus images
using an adaptive morphological approach,‚Äù Comput. Biol. Med., vol. 40,
no. 1, pp. 124‚Äì137, 2010.
[15] A. Aquino, M. E. GeguÃÅndez-Arias, and D. Marƒ±ÃÅn, ‚ÄúDetecting the optic disk
boundary in digital fundus images using morphological, edge detection,
and feature extraction techniques,‚Äù IEEE Trans. Med. Imag., vol. 29,
no. 11, pp. 1860‚Äì1869, Nov. 2010.

1886

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 6, NOVEMBER 2014

[16] A. Salazar-Gonzalez, Y. Li, and X. Liu, ‚ÄúOptic disk segmentation by incorporating blood vessel compensation,‚Äù in Proc. IEEE SSCI, Int. Workshop
Comput. Intell. Med. Imag., 2011, pp. 1‚Äì8.
[17] A. G. Salazar-Gonzalez, Y. Li, and X. Liu, ‚ÄúRetinal blood vessel segmentation via graph cut,‚Äù in Proc. IEEE 11th Int. Conf. Contr. Autom. Robot.
Vis., 2010, pp. 225‚Äì230.
[18] A. Salazar-Gonzalez, Y. Li, and D. Kaba, ‚ÄúMrf reconstruction of retinal
images for the optic disk segmentation,‚Äù in Health Information Science.
New York, NY, USA: Springer-Verlag, 2012, pp. 88‚Äì99.
[19] A. G. S. Gonzalez, ‚ÄúStructure analysis and lesion detection from retinal
fundus images,‚Äù Ph.D. dissertation, Dept. Comput. Sci., Brunel Univ.,
West London, U.K., 2011
[20] D. Wu, M. Zhang, and J. Liu, ‚ÄúOn the adaptive detection of blood vessels
in retinal images,‚Äù IEEE Trans. Biomed. Eng., vol. 53, no. 2, pp. 341‚Äì343,
Feb. 2006.
[21] Y. Y. Boykov and M.-P. Jolly, ‚ÄúInteractive graph cuts for optimal boundary
&amp; region segmentation of objects in N-D images,‚Äù in Proc. IEEE 8th
Int. Conf. Comput. Vis., 2001, vol. 1, pp. 105‚Äì112.
[22] S. Vicente, V. Kolmogorov, and C. Rother, ‚ÄúGraph cut based image segmentation with connectivity priors,‚Äù in Proc. IEEE Conf. Comput. Vis.
Pattern Recogn., 2008, vol. 1, pp. 1‚Äì8.
[23] V. Kolmogorov and Y. Boykov, ‚ÄúWhat metrics can be approximated by
geo-cuts, or global optimization of length/area and flux,‚Äù in Proc. 10th
IEEE Int. Conf. Comput. Vis., 2005, vol. 1, pp. 564‚Äì571.
[24] Y. Boykov and G. Funka-Lea, ‚ÄúGraph cuts and efficient N-D image segmentation,‚Äù Int. J. Comput. Vis., vol. 70, no. 2, pp. 109‚Äì131, 2006.
[25] A. Efros and T. Leung, ‚ÄúTexture synthesis by non-parametric sampling,‚Äù
in Proc. IEEE Int. Conf. Comput. Vis, 1999, pp. 1033‚Äì1038.
[26] T. Kauppi, V. Kalesnykiene, J. Kamarainen, L. Lensu, I. Sorri, A. Raninen,
R. Voitilainen, H. Uusitalo, H. Kalviainen, and J. Pietila, ‚ÄúDiaretdb1 diabetic retinopathy database and evaluation protocol,‚Äù in Proc. Brit. Mach.
Vis. Conf., 2007, pp. 1‚Äì10.
[27] D. Kaba, A. G. Salazar-Gonzalez, Y. Li, X. Liu, and A. Serag, ‚ÄúSegmentation of retinal blood vessels using gaussian mixture models and
expectation maximisation,‚Äù in Health Information Science. New York,
NY, USA: Springer-Verlag, 2013, pp. 105‚Äì112.
[28] D. Marƒ±ÃÅn, A. Aquino, M. E. GeguÃÅndez-Arias, and J. M. Bravo, ‚ÄúA new
supervised method for blood vessel segmentation in retinal images by
using gray-level and moment invariants-based features,‚Äù IEEE Trans. Med.
Imag., vol. 30, no. 1, pp. 146‚Äì158, Jan. 2011.
[29] B. Zhang, L. Zhang, L. Zhang, and F. Karray, ‚ÄúRetinal vessel extraction
by matched filter with first-order derivative of gaussian,‚Äù Comput. Biol.
Med., vol. 40, no. 4, pp. 438‚Äì445, 2010.
[30] J. V. Soares, J. J. Leandro, R. M. Cesar, H. F. Jelinek, and M. J. Cree,
‚ÄúRetinal vessel segmentation using the 2-D gabor wavelet and supervised
classification,‚Äù IEEE Trans. Med. Imag., vol. 25, no. 9, pp. 1214‚Äì1222,
Sep. 2006.
[31] S. Garg, J. Sivaswamy, and S. Chandra, ‚ÄúUnsupervised curvature-based
retinal vessel segmentation,‚Äù in Proc. IEEE 4th IEEE Int. Symp. Biomed.
Imag.: Nano Macro, 2007, pp. 344‚Äì347.
[32] R. Perfetti, E. Ricci, D. Casali, and G. Costantini, ‚ÄúCellular neural networks with virtual template expansion for retinal vessel segmentation,‚Äù
IEEE Trans. Circuits Syst. II, Exp. Briefs,, vol. 54, no. 2, pp. 141‚Äì145,
Feb. 2007.
[33] M. Al-Rawi, M. Qutaishat, and M. Arrar, ‚ÄúAn improved matched filter
for blood vessel detection of digital retinal images,‚Äù Comput. Biol. Med.,
vol. 37, no. 2, pp. 262‚Äì267, 2007.
[34] M. Niemeijer, J. Staal, B. van Ginneken, M. Loog, and M. D. Abramoff,
‚ÄúComparative study of retinal vessel segmentation methods on a new
publicly available database,‚Äù in Proc. SPIE Med. Imag. Int. Soc. Opt.
Photon., 2004, pp. 648‚Äì656.
[35] M. G. Cinsdikici and D. Aydƒ±n, ‚ÄúDetection of blood vessels in ophthalmoscope images using mf/ant (matched filter/ant colony) algorithm,‚Äù Comput. Methods Prog. Biomed., vol. 96, no. 2, pp. 85‚Äì95, 2009.
[36] X. Jiang and D. Mojon, ‚ÄúAdaptive local thresholding by verificationbased multithreshold probing with application to vessel detection in retinal
images,‚Äù IEEE Trans. Pattern Anal. Mach. Intell., vol. 25, no. 1, pp. 131‚Äì
137, Jan. 2003.
[37] E. Ricci and R. Perfetti, ‚ÄúRetinal blood vessel segmentation using line
operators and support vector classification,‚Äù IEEE Trans. Med. Imag.,
vol. 26, no. 10, pp. 1357‚Äì1365, Oct. 2007.
[38] Y. Zeng, D. Samaras, W. Chen, and Q. Peng, ‚ÄúTopology cuts: A novel
min-cut/max-flow algorithm for topology preserving segmentation in n-d
images,‚Äù J. Comput. Vis. Image Understand., vol. 112, no. 1, pp. 81‚Äì90,
2008.

[39] M. Niemeijer, M. D. AbraÃÄmoff, and B. Van Ginneken, ‚ÄúSegmentation of
the optic disk, macula and vascular arch in fundus photographs,‚Äù IEEE
Trans. Med. Imag., vol. 26, no. 1, pp. 116‚Äì127, Jan. 2007.

Ana Salazar-Gonzalez was born in Irapuato, Guanajuato, Mexico, in 1979. She received the B.S. degree
in electronics engineering in 2003, and the M.S. degree in signal processing from the Universidad de
Guanajuato, Guanajuato, Mexico, in 2006. She received the Ph.D. degree in computer science from
Brunel University, London, U.K, in 2012.
Since 2003, she has been dedicated to the design and development of image processing systems.
Her research interests include medical image analysis, OCR systems, and image processing for security
documents under different wavelength lights. Currently, she is an Engineer at
Access IS, Reading, U.K., designing and developing OCR systems and protocols of validation for security documents (passports, visas, ID cards, driving
licences, etc.).

Djibril Kaba received the M.Eng. and B.Eng. degrees in electronics engineering from Kings‚Äô College University, London, U.K., in 2010. He is currently working toward the Ph.D. degree in the Department of Computer Science, Brunel University, West
London, U.K.
From 2010 to 2011, he worked as a Business
Analyst for ITSeven, London, U.K. Since 2011, he
has been a Teaching Assistant in the Department of
Computer Science, Brunel University, London, U.K.
His research interests include computer vision, image
processing, pattern recognition, medical image analysis, and machine learning.

Yongmin Li received the M.Eng. and B.Eng. degrees
in control engineering from Tsinghua University, Beijing, China, in 1990 and 1992, respectively, and the
Ph.D. degree in computer vision from Queen Mary
University of London, London, U.K., in 2001.
Between 2001 and 2003, he worked as a Research
Scientist at the British Telecom Laboratories, Suffolk,
U.K. He is currently a Senior Lecturer in the Department of Computer Science, Brunel University, West
London, U.K. His current research interests include
automatic control, nonlinear filtering, computer vision, image processing, video analysis, medical imaging, machine learning, and
pattern recognition.

Xiaohui Liu received the B.Eng. degree in computing
from Hohai University, Nanjing, China, in 1982 and
the Ph.D. degree in computer science from HeriotWatt University, Edinburgh, U.K., in 1988.
He is currently a Professor of computing at Brunel
University, West London, U.K., where he directs the
Centre for Intelligent Data Analysis, conducting interdisciplinary research concerned with the effective
analysis of data. He also a Professor of computing
at King Abdulaziz Unviersity, Jeddah 21589, Saudi
Arabia. He is a Charted Engineer, Life Member of
the Association for the Advancement of Artificial Intelligence, Fellow of the
Royal Statistical Society, and Fellow of the British Computer Society. He has
over 100 high quality journal publications in biomedical informatics, complex
systems, computational intelligence, and data mining. His H-index is over 40.

