IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

355

A Virtual Reality System for PTCD Simulation Using
Direct Visuo-Haptic Rendering of Partially
Segmented Image Data
Dirk Fortmeier1 , Student Member, IEEE, Andre Mastmeyer1 , Julian Schröder, and Heinz Handels, Member, IEEE

Abstract—This study presents a new visuo-haptic virtual reality
(VR) training and planning system for percutaneous transhepatic
cholangio-drainage (PTCD) based on partially segmented virtual
patient models. We only use partially segmented image data instead
of a full segmentation and circumvent the necessity of surface or
volume mesh models. Haptic interaction with the virtual patient
during virtual palpation, ultrasound probing and needle insertion
is provided. Furthermore, the VR simulator includes X-ray and ultrasound simulation for image-guided training. The visualization
techniques are GPU-accelerated by implementation in Cuda and
include real-time volume deformations computed on the grid of the
image data. Computation on the image grid enables straightforward integration of the deformed image data into the visualization
components. To provide shorter rendering times, the performance
of the volume deformation algorithm is improved by a multigrid
approach. To evaluate the VR training system, a user evaluation
has been performed and deformation algorithms are analyzed in
terms of convergence speed with respect to a fully converged solution. The user evaluation shows positive results with increased user
confidence after a training session. It is shown that using partially
segmented patient data and direct volume rendering is suitable for
the simulation of needle insertion procedures such as PTCD.
Index Terms—Haptic rendering, needle insertion, virtual reality,
visualization.

I. INTRODUCTION
IRTUAL reality (VR) surgery simulation with needle insertion [1]–[4] is a current field of research, which deals
with the topics of visual and haptic rendering (visuo-haptics) as
well as the generation of virtual patient models. The downside
of most systems is their lack of being able to simulate an intervention on new patient data image just in time because of the
need for detailed segmentation and modeling of the patient’s
anatomy.
Previously, we have presented a lumbar puncture simulator
“AcusVR” [5] being a valuable training and planning tool. This

V

Manuscript received August 25, 2014; revised October 29, 2014; accepted
December 3, 2014. Date of publication December 18, 2014; date of current
version December 31, 2015. This work was supported by the German Research
Foundation (DFG, HA 2355/11-1).
D. Fortmeier is with the Institute of Medical Informatics and the Graduate
School for Computing in Medicine and Life Sciences, University of Luebeck,
23562 Luebeck, Germany (e-mail: dirk.fortmeier.DE@ieee.org).
A. Mastmeyer, J. Schröder, and H. Handels are with the Institute of
Medical Informatics, University of Luebeck, 23562 Luebeck, Germany
(e-mail: mastmeyer@imi.uni-luebeck.de; julian.schroeder@studium.fau.de;
handels@imi.uni-luebeck.de).
This paper has supplementary downloadable material available at http://
ieeexplore.ieee.org.
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2381772
1 Equal main contribution by two first authors.

Fig. 1. Schematic visualization of the virtual patient model, showing needle
and ultrasound probe placement in the intercostal spaces for PTCD and cross
section coplanar to the US-imaging plane with dilated hepatic duct (target
structure). The needle can be guided on a trail attached to the probe. Puncturing
of risk structures such as blood vessels should be avoided.

system consisted of a Geomagic Phantom Premium 1.5 6-DOF
haptic device and a combination of shutter glasses and a CRTmonitor for VR immersion. A user study was conducted and
training was shown to be effective [5]. However, AcusVR relied on a time-consuming complete manual segmentation of the
patients anatomy, which can take up to 40 h for a single patient
dataset. Visualization of dynamic effects such as the deformation of tissue during interventions was not available and fixed
3-D polygonal models were used.
Percutaneous transhepatic cholangio-drainage (PTCD) is a
needle insertion intervention in which dilated bile ducts, caused
by cholestasis, are punctured to relieve the patient by a drainage
[6]. Cholestasis can be caused by, e.g., gallstones or tumors in
the common hepatic bile duct. To reach the target (right hepatic
bile duct, RHD), the needle often is inserted between the sixth
and seventh ribs (intercostal spaces) and through the liver. Upto-date intervention techniques make use of an ultrasound (US)
probe with an attached needle guide (see Fig. 1) that helps to
keep the needle on a path inside the US image plane.
This paper concentrates on a visuo-haptic simulation framework for the training and planning of the first steps of PTCD
regarding needle navigation. A prerequisite is 3-D CT imaging of the liver before the intervention. The motivation to train
this intervention patient-specifically beforehand with a VR system is that VR training is considered to be a benefit for apprentices and can improve the preparation of the surgeon for
real interventions. Following this assumption, it can reduce the
number of needle repositionings, and thus the duration of the
intervention and healing times, as well as patient dose because
of lower X-ray exposure.

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

356

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

For haptic and visual immersion, we present the implementation of image-based deformation algorithms into the framework
with interactive direct volume rendering of patient data, US and
X-ray simulation with contrast agent injection. The framework
uses partially segmented 3-D CT image data for direct visual
and haptic rendering without relying on the creation of surface
representations or volumetric meshes.
In contrast to mesh-based approaches of needle insertion simulation [7]–[10], our methods do not use meshes, but rather approaches that are directly computed on regular grids. Favorably,
no meshing procedure is needed and no remeshing operations
have to be performed at run-time. Also, patient image data is
given as regular grids and graphics hardware can deal efficiently
with this kind of structure.
The major contributions of this study are a comprehensive
presentation of the direct visuo-haptic rendering components
and an improvement of the method used for computation of
soft tissue deformations, which can be applied for needle or
palpation-induced deformations. Additionally, a user study supporting the utility of our framework was performed. It is shown
that direct visuo-haptic rendering approaches are valid means
for simulation of PTCD. To our knowledge, our system is the
first featuring a complete needle insertion simulation framework
solely using a voxel-based representation for all visuo-haptic
interaction and includes simulation of deformation caused by
interaction in all visual representations.
The paper is organized as follows: First, related work is described. In the following Section III, an overview of the VR
simulator and its hardware and software components is given.
Then, in Section IV, methods for the haptic simulation and visualization of needle insertion, palpation and US probing based
on partially segmented data are presented. Section V gives details on the evaluation of the framework including a user study.
Finally, results are presented in Section VI and discussed in
Section VII.
II. RELATED WORK
Simulation of haptic interaction in surgery training is discussed in [11] and different haptic devices and fields of application are presented. General patient-specific simulation systems
are reviewed in [12].
Regarding needle puncture, current simulations feature insertion of needles into blood vessels [1]–[2], for liver biopsy
[3]–[4], or prostate brachytherapy [13]. Closely related to the
system presented here is the ImaGiNe-S system [14], detailed
in [15] and [16]. In [15], a simulator for US-guided liver lesion needle punctures using two haptic devices for US probe
and needle, respectively, is described. They use surface models
created by the marching cubes algorithm and refrain from direct volume rendering due to slow processing times. In [16], a
simulator for percutaneous transhepatic cholangiography (PTC)
is presented, which relies on surface models as well. The major differences in comparison to our system are that our setup
uses partially segmented image data and direct volume rendering with visualization of local deformations in all visualization
components.

Fig. 2. Haptic workbench and simulation: 1) main rendering window, 2) X-ray
rendering window, 3) US rendering window and 4) haptic device handle.

The haptic force feedback modeling of needle insertion has
been surveyed in [17]. A method for volume-based rendering of
needle insertion is presented in [5]. Recent simulations concerning virtual palpation by using a haptic device include [1], [2],
[18], [19]. In [1], palpation is used to determine the insertion site
for femoral artery puncture leading to regional anesthesia using
a Phantom Omni 3-DOF haptic device. A special palpation pad
has been created as a custom replacement of the stylus interface
of the Omni and it has been shown that this pad approach is more
natural than using the stylus. For the same kind of intervention,
a different approach is taken in [2]. There, palpation is simulated
in an augmented reality scene and the user directly palpates an
artificial silicone interface with his fingers. The haptic response
of the interface is provided by two Novint Falcon devices and a
hydraulic end effector.
Simulation of soft tissue deformations is a major research
area by itself. For needle insertion simulation, the studies of [7],
[8] are of major importance. There, the finite element method
is used and thus the virtual patients are represented by a tetrahedrical mesh data structure. Remeshing, i.e., manipulation of
the tetrahedrical structure, at run-time is used to make the needle comply to the structure of the mesh and to provide more
elements close to the needle. Since FE methods are computationally intensive, update rates as needed for haptic interaction
(500–2000 Hz) are hard to achieve. To mitigate the problem
and enable high update rates, multirate compliant mechanisms
[10] can be used making it possible to use FEM simulation for
haptic force feedback computation. A framework for interactive
simulation of cutting and deformations using FEM and direct
volume rendering was recently presented in [20].
Real-time simulation of angiography was addressed by [21]
and real-time fluoroscopy simulation for PTC in [16]. Simulation of US imaging based on CT data is presented in [22]–[24].
III. SIMULATOR OVERVIEW
The hardware setup of the simulation system consists of a
visuo-haptic workbench using stereoscopic 3-D (see Fig. 2).
Using the haptic input device a user can steer virtual tools in the
VR environment.

FORTMEIER1 et al.: A VIRTUAL REALITY SYSTEM FOR PTCD SIMULATION USING DIRECT VISUO-HAPTIC RENDERING OF PARTIALLY

After the creation of a new patient model in a preprocessing
step, the crucial parts of a virtual PTCD intervention can be
trained and planned. The workflow consists of the following
sequence: 1) virtual palpation, 2) US probing and 3) puncturing
with the needle. Finally, 4) a button press checks for the emission
of contrast agent into the bile ducts by using X-ray simulation.
After changing from palpation to the US tool, the needle can be
snapped into a guide at the side of the US probe and the puncture
is performed by guided advance of the needle into the patient’s
body. When a risk structure is hurt by the needle tip, the user
is notified by turning the simulation window background red,
a successful insertion is indicated by a green background and
contrast agent spreading out in the bile ducts is visualized in the
X-ray viewport. This way, a successful puncture of the bile ducts
is indicated, and the training ends. In reality, the replacement
of the needle by a catheter for drainage would follow, which is
much easier than the needle placement and therefore neglected.
The deformation of soft tissue in the CT volume data using palpation, US device and needle insertion is computed and
displayed in real time.
To assess skill improvement using the system, two different
modes are offered to the user: The first is a “free planning mode,”
where the operator can search for needle trajectories. Scoring is
then based on needle insertion duration and hit/miss of the target
structure. In the second mode, needle trajectory accuracy while
puncturing along predefined reference paths can be assessed
(“reference path mode”). Reference paths can be generated by a
path planning concept [25] or specified by medical experts and
are kept as “bookmarks.”
IV. VISUO-HAPTIC RENDERING OF PARTIALLY SEGMENTED
IMAGE DATA
After the creation of a virtual patient model, it is presented to
a trainee in a visuo-haptic environment using direct rendering
of the volume data. In the following, first the representation
of the patient data is described and then we present the haptic
algorithms and methods for real-time visual rendering, X-ray
and US simulation.
A. Patient Data and Property Tree
The patient data representations used in the simulation consist of a tree-like description of tissue properties, partial segmentations of a patient’s volumetric image data and the CT
image data itself. Each node in the tree corresponds to a distinct
tissue type or class of tissues. Furthermore, transfer functions
can be defined for individual nodes of the property tree, relating
Hounsfield values to haptic simulation parameters or color information for the volume rendering. Inheritance from parent nodes
make it unnecessary to define tissue properties for each element
of the tree (see Fig. 3). The haptic parameters were tuned by two
medical experts with profound experience in PTCD punctures
to ensure face validity for a reference patient. Different tissues
and interfaces have been punctured repeatedly on reproducible
application relevant paths and the parameters have been adjusted
by request of the experts.

357

Fig. 3. Explanation of the property tree: If a parameter of a voxel is needed,
first, the corresponding structure is determined by a present segmentation (x1 )
or heuristic (x2 ). Then the parameter is looked up in the tree. In this example,
k is defined as a fixed value for the liver segmentation or otherwise as a transfer
function for the root element. The transfer function is evaluated using the CT
value of the voxel.
skin
Additionally, tissue thresholds tbfatone , tfat
skin and tair have to
be determined, which are used to roughly classify a voxel given
its Hounsfield value. Since these thresholds are patient-specific,
new patient data has to be prepared by histogram matching of
the new CT image onto the reference image data. Furthermore,
creation of partial segmentations is necessary. This step consists
of the segmentation and modeling of key structures by manual
or semiautomatic methods, i.e., liver, liver vessels (bile ducts,
blood vessels) and intercostal fascia.

B. Needle Haptics With Proxy-Based Rendering of Partially
Segmented Data
For rendering of needle forces, a proxy based approach [26]
is used. The virtual needle tip x is connected to a virtual proxy
p via a spring and Hooke’s law f (d) = k · d with d = p − x
and spring constant k is used to compute force feedback. The
needle is assumed to be bending free, which is a reasonable simplification for US-guided PTCD where relatively stiff needles
(≤ 18 gauge) are used.
Characteristic forces as occurring in needle insertion are simulated by manipulation of the proxy’s position [5]. Needle shaft
forces are modeled by projecting the proxy position onto the
direction of insertion, which results in forces fixing the haptic
device handle on the virtual insertion path.
Simulation of the resistance of tissue surfaces to needle puncture is achieved by keeping the proxy on the tissue’s surface until
the spring generates a force higher than a tissue specific threshold TN . According to Hooke’s law, the spring model has a linear
characteristic when needle tip and proxy positions diverge at a
tissue border. Another variant for computation of needle forces
is a more realistic nonlinear spring force [27]. Following this
approach, we use a second degree polynomial

d 
(1)
a2 d2 + a1 d + a0
f (d) =
d
with d = p − x being the indentation of the surface at a tissue border. As a novelty, the parameters a0 , a1 and a2 are set
in a way that the surface puncture event occurs at the same
indentation and with the same force as it would happen with
the linear spring, which was evaluated to provide realistic force
output at organ borders in our reference system [5]. Between

358

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

Fig. 5. (a) Needle in undeformed state of the virtual patient as defined by
the proxy. (b) Needle steered by the haptic device in the current deformed
configuration of the tissue. Connecting x and p by a spring is used to calculate
force feedback.
Fig. 4. Force output for a surface using the nonlinear spring with different
settings for a 1 .

first contact of the needle tip with a tissue border and the puncture event, forces below the linear spring forces are computed
with a nonlinear slope (see Fig. 4). The maximum friction force
R when moving the needle within a homogeneous tissue corresponds and determines the parameter a0 = R, whereas the
user-specified parameter a1 ∈ [0, k] given in [N/m] influences
the linear term and has to be estimated heuristically. The last
parameter, namely
a2 =

k · (k − a1 )
|TN − a0 |

(2)

results from the parameters a0 and a1 , the spring stiffness constant k of the linear model and the surface resistance force TN .
A low value for a1 thus enforces a lower slope at the beginning
of the force curve, i.e., increases the influence of the quadratic
term. Using this spring model, we aim to achieve a more realistic haptic rendering at organ capsules with a force curve that
corresponds better to the model and ex vivo bovine liver needle
insertion measurements from [27]. Note that setting a1 = k is
equivalent to using a linear spring.
Inside an organ, friction of different tissues is rendered by
delaying the proxy movement and adjusting the spring constant
k of the virtual spring and a maximal friction force value R by
a stick-slide approach [28] in the form

d
x + Rk d
, if d · k > R

p =
(3)
p,
otherwise
with p being the new proxy position and with d = p − x being
the offset of the old proxy position and device position.
As explained in Fig. 3, the property tree provides the parameters R, k and TN in form of a transfer function or constant
values valid in a classified region. In the case of a fully segmented patient, where each tissue in the patient’s image has a
distinct label, the tissue parameters are looked up in the property tree: First, the current label l(p) and CT image value I(p)
are determined at the proxy position. For each haptic parameter,
the following is done: Starting at the tree node that matches the
label, the tree is traversed upwards until a node with a constant
value or transfer function defining the parameter of interest is
found. If during traversal a node containing a transfer function is
found, then it is evaluated for the CT value at the proxy position,

giving the haptic parameter. The proxy position corresponds to
the needle tip in the undeformed state of the virtual patient, i.e.,
the undeformed image of the patient at time of image acquisition, as illustrated in Fig. 5. Another possibility would be to
determine the parameters at the device tip. The reason the proxy
is preferred is the assumption that the spatial relation of tip and
proxy define the deformation of the tissue. Thus, fetching the
parameters at the proxy position in the undeformed image data
is equivalent to fetching the parameters in a deformed state of
the image.
To reduce the preparation time needed for segmentation in
practice, partially segmented data Lpt can be used for determination of the label and the matching tree node. For segmented
regions, the lookup of parametric values is done as in the fully
segmented case. In image regions where the label information
is incomplete, a heuristic is used to guess the missing labels.
This heuristic requires CT image data for which the intensities
have been adapted to the reference patient image data, making
the used thresholds implicitly patient-specific. It depends on the
image gray value I(p), and the current insertion depth d
⎧
lrisk ,
if I(p) ∈ [−∞, tfat
⎪
skin ) ∧ d > δ
⎪
⎪
⎪
⎪
fat
⎪
⎪lskin , if I(p) ∈ [tskin
air , tskin ) ∧ d ≤ δ
⎪
⎨
b one
if I(p) ∈ [tfat
(4)
h(I(p), d) = lfat ,
skin , tfat )
⎪
⎪
⎪
⎪
lb one , if I(p) ∈ [tbfatone , ∞]
⎪
⎪
⎪
⎪
⎩
lair ,
otherwise.
The constant δ is a minimal insertion depth after which the
detection of unspecified risk structures lrsc should start. This is
necessary to prevent the algorithm to classify the patient’s skin
surface as a risk structure. Here, the value used in our evaluation
have been empirically set to δ = 5.0 mm.
With this heuristic, the final equation to estimate a distinct
label in real time (2000 Hz) for a position p in the image is

if Lpt (p) = 0
Lpt (p),
(5)
l(p, d) =
h(I(p), d), otherwise.
Tissue borders are rendered in case two different labels are
detected in two successive rendering steps. From the haptics
perspective, this motivates to have explicit segmentation models
available for structures involved in haptically important tissue
transitions, e.g., the fascia.

FORTMEIER1 et al.: A VIRTUAL REALITY SYSTEM FOR PTCD SIMULATION USING DIRECT VISUO-HAPTIC RENDERING OF PARTIALLY

C. Haptic Simulation of Palpation and US Probe Interaction
In practice, palpation is applied to determine the insertion
point of the needle, while US or X-ray imaging is used to
guide the needle inside the human body [6]. Therefore, a
method for haptic rendering of intercostal space palpation is
needed.
Using the US device, the probe is aligned on the skin between
the rib bones (intercostal space). Our approach [19] is based
on Euclidean distance maps of threshold-segmented structures.
These can be obtained by segmentation thresholds tskin
air and
tbfatone giving the distance maps Dskin and Db one . They are used
to calculate forces acting on fixed points that are distributed on
the surfaces of tools or the tip of the virtual finger. For each of
these points x, penalty force terms fskin and fb one that model
the surface of the patient and bone structures are applied. Each
of the forces is in the form
fi = vi · fi (Di (x))

(6)

with vi being the direction of the force and fi a nonlinear
function relating the Euclidean distance of the point x to the
surface i ∈ {skin, bone} to the force’s magnitude.
For the skin surface force, the normalized gradient of the
distance map Dskin is used. Similarly, for the force direction
of the hard structure force, the normalized gradient of Db one
is reoriented toward the skin surface in case it points in the
opposite direction of vskin , giving the force direction.
Furthermore, their friction on the surfaces is computed by
a proxy-based scheme, which is similar to the simulation
of friction of the needle. The relation of proxy and contact node then again is used to calculate a force ffriction .
Based on these three components, the total force on a node is
the sum
f = fskin + fb one + ffriction .

(7)

By using this force, torque can be computed by the cross product
of the force and the lever arm formed by the haptic device
position and the position of the node. Averaging the forces
and torques of all nodes in contact gives the force and torque
displayed to the user via the haptic device.
D. Direct Volume Rendering of the Deformable Patient’s Body
Most recent surgery simulations use indirect volume rendering methods (polygonal models) for the visualization of a
patient’s medical image data. Indirect volume rendering relies
on the creation of a surface representation in a preprocessing
step, often based on a segmentation of anatomical structures.
On the contrary, direct volume rendering by ray casting is a
well-known field [29] and can be used to visualize image data
without preprocessing steps.
To improve realism, visualization of soft tissue deformations
occurring during the interaction with the patient is desirable.
Since these deformations are limited to a small neighborhood
around the interacting tools, we use our method presented in
[30] to compute deformations of a cubical voxel subvolume J
consisting of 643 voxels on the grid Ω. There, deformations on
the image data are computed by a physically motivated linear-

359

elastic or diffusive relaxation process influenced by a material
function that prohibits the deformation of hard structures. Generally speaking, the result of the algorithms is a displacement
field u : Ω → R3 computed by minimizing an energy functional
using iterative explicit integration by application of a differential
operator T
ui+1 = ui + T ui .

(8)

The displacement field has to be inverted and then can be used
to resample J by trilinear interpolation. Instead of calculating
u, the inverse u−1 can be computed directly. The method’s main
limitation are relatively long run times needed for convergence.
To reduce the time needed for convergence, two methods are
used to speed up the relaxation process of needle or palpation induced deformations: 1) the chainmail algorithm and 2) a
multigrid method. The chainmail method is an efficient way to
simulate deformations on regular grids [31], [32] and was used
for palpation-induced deformations in [19], [33]. The main idea
is to assume that the movement of elements of a soft body is
spatially limited by constrains similar to rings of chain mail.
Despite being efficient, the plausibility in terms of physical
correctness of the resulting deformations is limited and typical
visual diamond-shaped artifacts arise.
In contrast to this, the multigrid approach relies on the deformation models as proposed in our previous study [30]. Multigrid methods are often applied in image registration [34], [35]
or finite element simulation [36]. Instead of only computing on
a single mesh or grid, different resolutions are used for computation and the intermediate solutions from lower resolutions
are used as initial solutions for the higher resolutions. Here, the
multigrid method is implemented using three levels (L0 , L1 , and
L2 ) and works as follows: In each time step of the simulation,
the grid of deformations from the previous iteration in the same
resolution as the image data (L0 = 643 ) is resampled twice by
reducing the resolution by a factor of two. With i being the grid
level and wi the associated grid dimension, the resampling can
be defined recursively as
Li (x, y, z) = Li−1 (2x, 2y, 2z) , x, y, z ∈ {1, ..., wi }.

(9)

This way, the grid of deformations L1 with 323 elements and
L2 with 163 elements, respectively, are computed.
Then, the relaxation algorithm of [30] is applied to L2 several
times followed by a redistribution of the deformations onto L1 .
After applying the relaxation to L1 and redistribution onto L0 ,
final relaxation steps are performed on L0 . The redistribution
can be defined as
x y z 
, ,
Li (x, y, z) = Li+1
, x, y, z ∈ {1, ..., wi }. (10)
2 2 2
To visualize the deformed volume data, a custom volume renderer was developed to render the resulting deformed subvolume combined with the original undeformed image by ray casting. This renderer uses a piecewise-linear visual RGBA transfer
function c(v) = (r(v), g(v), b(v), a(v))
 which is composed
of visual transfer functions from the property tree, to relate the
Hounsfield values along a viewing ray to color information. The
weight αi ∈ [0..1] of each of the n transfer functions from the

360

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

property tree can each be adjusted by the user. The combined
transfer function is defined as
⎞ ⎛ ⎞⎤
⎡⎛
0
ri (v)
⎟ ⎜ ⎟⎥
⎢⎜
	
⎢⎜ gi (v) ⎟ ⎜ 0 ⎟⎥
⎜
⎟ ⎜ ⎟⎥
(11)
αi ai (v) ⎢
c(v) =
⎢⎜ b (v) ⎟ + ⎜ 0 ⎟⎥
⎠ ⎝ ⎠⎦
⎣⎝ i
1≤i≤n
0

1

for a given gray value v.
To give the user the possibility to inspect the internal structures of the patient interactively, an additional ’clipping mode’
can be used: A plane, which is defined by the position and orientation of the current tool is used to hide parts of the patients
that lie on one side of the plane. Elements on the plane can be
tagged by the labeling function as used in the haptic rendering and displayed according to the element’s color given by the
property tree or by a color coding of target (green) and risk structures (red). Another rendering mode is provided, which uses a
simple windowing function for the volume rendering, which is
supposed to be intuitive for users familiar with windowing of
medical image data.
To improve depth perception, simple shadow rendering of the
tools is incorporated in the volume rendering.
E. Simulation of X-Ray and Contrast Agent Injection
The ray casting method is adapted for an additional simulation of fluoroscopy imaging with contrast agent injection based
on the patient’s partial segmentations and 3-D CT image data.
The contrast agent is injected by the needle during insertion to
augment visibility of the punctured liver vessels.
Here, we model the resulting image intensity of the pixels as a
function of the total attenuation factor a from the Beer-Lambert
law I =
I0 e−a as proposed by [37]: The total attenuation factor a = x i ∈R μ(xi )Δx is given by the attenuation coefficient
μ(xi ) for each point on a ray R and the distance Δx between
the sampling points. Attenuation coefficients are computed from
Hounsfield units based on the attenuation coefficient for water
[38]. Given a photon energy of 0.1 MeV, we use the attenuation
coefficient μwater = 0.17 m−1 as a basis. Furthermore, attenuation of injected contrast agent has to be estimated at run-time.
In fluoroscopy, iodine is often used as a contrast agent since it
2
has a high attenuation coefficient of μc (x) = 1.9 cmg ρ(x) for a
given density ρ(x) of the contrast agent. We model the density
of the contrast agent by a diffusion process on a grid given by
the hepatic duct segmentation, which gives a total attenuation
factor
	
(μ(xi ) + μc (xi ))
(12)
a = Δx
x i ∈R

for a single ray.
Initially, all density values of the grid representing the hepatic
duct segmentation are set to zero. In case the puncture needle
enters the hepatic duct, contrast agent is automatically injected
by increasing the density of the contrast agent at the needle
tip by a fixed amount. In each time step of the simulation, the
contrast agent propagation is simulated by explicit integration of

the diffusion equation ρt+τ = ρt + τ Δρt on the grid of contrast
agent density with ρt being the density of contrast agent at time
t and τ being the time step.
F. Simulated US
US-guided needle puncture is often used for accessing peripheral lesions and vessels in the liver [6]. In contrast to using
X-ray techniques, no radiation dose is applied and this technique lowers the number of needle repositionings noticeably.
In our simulator, the virtual US head features a needle guide.
Training and planning with this advanced tooling can improve
the efficiency and effectiveness of the operator on a new patient.
The methods of [22], [23] and [24] served as references for
our US simulation based on CT data. We added the use of partial
segmentations to further enhance the realism of the simulation.
Moreover, for didactic reasons assisting visualization of certain
object borders and Doppler mode simulation is available. Basically, we use a parallelized ray casting technique implemented
in Cuda for the US image fan, which is composed of many
radially emerging rays. For one ray and the final image, the
computation can be divided into six steps, which can be found
in the Appendix. One new aspect in the simulation pipeline is the
amplification of the returned signal using simulated time gain
control (TGC) [see step 4, (15) in the Appendix]. Moreover, optional color overlays and colored borders indicating target and
risk structures can be enabled for various structures.
Using Doppler-mode, the dynamic flow of blood can be seen
inside the arteries and veins, which is important for the surgeon’s needle navigation around these structures. In our simplified Doppler-US simulation, we use a blood pressure p (t) curve
as a velocity indicator
 

(13)
v(t) = 2 · p(t)/ρ b l o o d
and in a HSL color model modulate the hue of the color overlay
following the time dependent velocity. Arteries are presented
in a red-to-yellow color gradient, and veins are displayed in a
blue-to-cyan gradient. At the segmented blood vessel voxels,
the Doppler color overlay flashes with a pulse rate of 80 beats
per minute and a phase shift of 1/3 periods between arteries and
veins.
G. Implementation Details
As illustrated in Fig. 6, all described visualization components
are implemented and parallelized using Nvidia Cuda. The parallelization for the computation of deformations is described in
[30], columns of J are assigned to Cuda blocks, with threads for
each element of a column. For the ray casting, blocks are defined
as rectangular image regions with each thread corresponding to
a ray. In our implementation of US simulation, one ray corresponds to a block, with a thread for each sampling point. The
results from the visualizations are copied to the framebuffer
using OpenGL/Cuda interoperability. To achieve this, custom
rendering elements have been implemented that fit into the rendering pipeline of the visualization toolkit (VTK) library. Based
on the properties of the haptic device and haptic algorithms,

FORTMEIER1 et al.: A VIRTUAL REALITY SYSTEM FOR PTCD SIMULATION USING DIRECT VISUO-HAPTIC RENDERING OF PARTIALLY

Fig. 6.

Overview of software and hardware components of the simulator.

the virtual tools also are rendered using VTK/OpenGL by
rasterization. This combined visualization runs on a single
thread at interactive rates.
A CPU thread executes the haptic algorithms at a high rate of
2000 Hz. The haptic algorithms are implemented in C++ with an
interface to the haptic device using the OpenHaptics low-level
API (HDAPI) [39].
The main obstacle we faced during the integration of the
components was the combination of the volume rendering with
the rasterization. This was mainly caused by the fact that Cuda
does not give direct access to the depth buffer. It was solved by
copying the resulting depth buffer from the volume rendering to
the render buffer by using a GLSL fragment shader.
V. EVALUATION
For needle insertion force calculations, the targeted rendering
rate of 2000 Hz is easily achieved and is not worth a detailed
performance study. An evaluation of palpation rendering performance can be found in [19]. In contrast, the visualization
aspects regarding volume rendering of deformations, X-ray and
US simulation deserve detailed evaluation in terms of rendering performance and visual plausibility. Furthermore, the whole
system is assessed in a user study.
A. Performance Evaluation of Visual Rendering
The performance of the visual rendering has been tested on a
workstation with Nvidia GTX 680 graphics hardware in terms
of rendering time per frame. To this aim, a scripted sequence of
the initial PTCD steps palpation, US probing, needle insertion
and X-ray inspection has been performed n = 10 times. The
duration of each of the steps is set to 6 s. Volume rendering uses
a resolution of 5122 pixels and X-ray rendering a resolution of
2562 pixels. The size of the subvolume used for deformation
computation is set to 643 voxels.

361

To compare and analyze the benefits gained from the chainmail algorithm and the multigrid approach, the behavior in a setting that reflects intercostal space palpation with an indentation
of the skin surface of 14 mm and 36 contact nodes distributed
on the virtual finger’s tip is analyzed. To this aim, we compare our unoptimized method from [30] to the speedup gained
by the chainmail and multigrid approach. This comparison is
performed separately for both the diffusive approximation and
the linear-elastic relaxation formulation for soft tissue deformations as proposed in [30]. Overall, we compare six relaxation
methods (unoptimized, chainmail and multigrid; each with the
diffusive and linear elastic relaxation). For both the chainmail
and multigrid optimizations, a single, initial iteration is followed
by unoptimized steps, because further iteration did not change
the result.
For u(x, t) being the elements of the displacement field after
a processing time t using one of the six methods for computing
deformations, we measured the mean-squared difference (MSD)
of the successive steps and a fully converged unoptimized
solution
1 	
u(x, t) − u(x, ∞)2
(14)
em sd (t) =
|Ω|
x∈Ω

with u(x, ∞) corresponding to a fully converged solution of
the unoptimized processes [see (8)]. We use u(x, ∞) under
the assumption that it represents valid ground truth, which is
reasonable since processing speed is evaluated here and not
deformation accuracy. In this experiment, the chainmail and
the multigrid methods are applied once, followed by a series
of unoptimized relaxation steps. This is done to show that the
algorithms indeed have found an initial solution that can be
improved in further iterations. In the actual simulator, only the
chainmail approach would be handled in this fashion since the
multigrid method already includes several unoptimized relaxation steps. For the multigrid method, the number of iterations
on the levels L0 , L1 and L2 are set to four, eight and 16.
Additionally, qualitative results of the rendering methods and
relaxation approaches are given.
B. Qualitative User Evaluation
A user study covering visuo-haptic rendering and to further
confirm general validity and user acceptance was conducted
with 16 (nine female, seven male) medical students (fifth year)
prior to their one year practical hospital training. Medical students well represent a target user group in terms of medical
training with our simulator. Each trainee was given a time window of 30 to 60 min. Before starting with the training, each
subject has been introduced to the simulator to reach the same
level of ability. The instructor showed a single puncture in “free”
and “reference path mode” to the trainee. The trainees then were
able to get scores from three tries in both modes each.
After the training, each subject was handed out a four point
Likert-scale questionnaire [40] to evaluate the simulation system. The motivation for using four points on the scale is to
have the subjects clearly decide for a more positive or negative
tendency regarding the question.

362

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

TABLE I
QUESTIONNAIRE GIVEN TO THE MEDICAL STUDENTS (N = 16) WITH RESULTING MEDIAN, MEAN AND STANDARD DEVIATIONS OF THE SCORES

Fig. 7. Boxplots of rendering times during a scripted test sequence. Everything
below the blue line indicates real-time capable update rates (25 Hz).

The questionnaire shown in Table I is divided into the three
sections:
1) User previous knowledge, experience and confidence
(Q1–Q3).
2) User perception of the system including visual and haptic
rendering (Q4–Q13).
3) General final user evaluation of the system and confidence
after training (Q14–Q19).
For comparison of user confidence before and after the training session we use the Wilcoxon-signed rank test (Q1 versus
Q16). The user evaluation has been performed on a workstation
running on an Intel Xeon W3550@ 3.07 GHz with 32-GB RAM
with a Nvidia Quadro 4000 Graphics Card. The image data for
the virtual patient model had a resolution of 256 × 256 × 236
elements. Volume rendering uses an image plane resolution of
5122 pixels and X-ray rendering a resolution of 2562 pixels.
For simulation of deformations, the chainmail method has been
used.
VI. RESULTS
A. Visual Rendering Performance
1) Quantitative: Fig. 7 shows box-plotted rendering times
in the described sequence (see Section V-A). In the first phase,
the patient’s tissue is deformed by palpation, which increases

Fig. 8. MSDs of deformations between stepwise solutions of the deformation
algorithms and a fully converged solution during a 50-ms period for diffusive
relaxation (upper) and linear-elastic relaxation (lower). One initial step of the
chainmail and the multigrid approach is followed by a series of unoptimized
relaxation steps.

the processing times noticeable. The same holds for the second
phase with additional computations needed for US simulation.
Deformations caused by the needle and contrast agent diffusion
are responsible for the increase in computation time in the third
phase. The X-ray simulation needs increased computation time
as clearly can be seen in the last phase. Generally, the rendering
is capable of real-time resp. interactive rendering using the GTX
680 graphics card.

FORTMEIER1 et al.: A VIRTUAL REALITY SYSTEM FOR PTCD SIMULATION USING DIRECT VISUO-HAPTIC RENDERING OF PARTIALLY

363

Fig. 9. Different volume renderings of the virtual patient with enabled “clipping mode”: 1) using a combined transfer function, 2) using different opacity values
for the transfer functions, 3) target and risk structure overlay, 4) labeling function and 5) a windowing transfer function.

The image in Fig. 10(b) is simulated with a transducer frequency f = 3 MHz and a fan-beam angle of 30º.
Concerning deformations caused by palpation, Fig. 11 shows
the benefit of the multigrid method, which avoids the diamond
shaped artifacts shown by the chainmail approach. Also, the
unoptimized method after a fixed number of 16 relaxation steps
has been applied is shown. A higher number of relaxation steps
would inhibit real-time capabilities and thus the need for optimization in case of palpation is demonstrated.
B. User Evaluation
Fig. 10. (a) Simulated X-ray image with contrast agent spreading in the bile
ducts. (b) Simulated US image with augmented target (green) and risk (red)
structures, the yellow dotted line shows the predicted path of the inserted needle.

Deformation algorithm performance is presented in Fig. 8. To
reflect the real-time capable behavior of the algorithms, only the
first 50 ms are plotted. It is shown that the multigrid approach
easily outperforms both the chainmail and the unoptimized version.
2) Qualitative: Screenshots of the visualization components
are shown in Figs. 9 and 10. We show volume rendering with
enabled “clipping mode” using: 1) the combined visual transfer
function from the property tree, 2) a different combination of
transfer functions with decreased opacity values for the transfer
functions of “skin” and “soft tissue,” 3) an overlay of target and
risk structures, 4) the labeling function and 5) a rendering based
on a windowing transfer function. Using the visual transfer
function, the skin layer can be clearly distinguished from other
soft tissue and bony structures. Visual rendering side effects
occur at borders of the structures that are filled with air (lungs,
intestine): These are rendered similar to the skin surface but are
classified as risk structure [see (4)]. This effect is also visible
when using the overlay and labeling functions.
In the X-ray simulation [see Fig. 10(a)], the needle has been
inserted in the bile duct for several seconds and contrast agent
already has spread out.
Fig. 10(b) shows a sample image of the US simulation. The
shape of the bile ducts can be well perceived. They are characterized by dark, reflection-free areas. There also is a bony
structure in the field of view, the rib, behind which a typical
shadow shows out.

Table I shows the results of the user evaluation. Most students
were unconfident to perform a real first PTCD (Q1). Questions judging the simulator have been answered positively, i.e.,
the median and mean of each answer is below the four-point
Likert-scale midpoint of 2.5 (Q2–Q18). The attitude toward intuitiveness and realism of the force-feedback of the simulation
has been judged the least favorable (Q5–Q7) with the highest standard deviations. Visual rendering of the skin surface is
still positively judged, but has the lowest score regarding visual rendering (Q8). Improvements of the visual perception by
stereoscopic 3-D and shadow rendering is overall rated as good
(Q9–Q10). The X-ray and US simulation were rated very good
regarding the purpose of training and planning (Q11–Q12). The
scoring system is regarded helpful (Q13) but not as meaningful
(Q14). Application of the simulator in the real world is viewed
as promising (Q2–Q4, Q15–Q16). Overall, the technical realization has been judged very positively (Q18). To estimate the
training effect and trainee confidence before and after the training, the results of Q1 and Q16 are statistically compared using a
Wilcoxon-signed rank test. The result is significant (p < 0.01).
VII. DISCUSSION
In the following, we will discuss general findings concerning
the visuo-haptic system and the results from the user evaluation.
Deformations are clearly visible on the surface of patients
when palpating or using the US tool, and internal deformations
caused by lateral movements or tissue indentation can clearly be
seen when using the “clipping mode” or US probing. Deformation methods for needle insertion without using chainmail have
been presented in [30] and deformations caused by palpation using chainmail in [33]. Here, we combined these approaches and

364

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

Fig. 11. Rendering of the palpation from the simulation, deformations computed by (a) multigrid method, (b) chainmail and (c) unoptimized version with a
number of relaxation steps that still enables real-time interaction. Obviously, (a) is the best result since (b) contains diamond-shaped artifacts resulting from the
chainmail algorithm and the number of relaxation steps in (c) do not result in realistic deformation, demonstrating the need for an optimization.

introduced a multigrid approach into our framework and showed
its favorable visual plausibility and computational speed. Besides, chainmail causes diamond-shaped artifacts and is not
physically motivated making the multigrid approach the appropriate choice.
Regarding the X-ray simulation, the quality of the rendered
bile ducts augmented by contrast agent is limited by the resolution of the image data. The diameter of the segmented vessels usually is only a few voxels wide and thus the rendered
structures have blocky edges. Nevertheless, the X-ray simulation creates convincing output and would profit from higher CT
image resolution.
For the raycasting, relatively small resolutions of the resulting image were used in the user evaluation setup but the
rasterization-based rendering of the interacting tools is done in
the full resolution of the display, mitigating the impression of
low-resolution rendering.
Well-known US-typical artifacts, such as speed-displacement
and multiple reflexion are not modeled in our US simulation,
but it delivers realistic image quality well suited for training
and planning use. However, for the US visualization as for the
whole concept of the simulator the dedicated segmentation of
some key structures is still necessary.
The user evaluation shows that haptic interaction and force
feedback is rated differently by 16 students (see Table I, Q6–
Q7). We consider 16 individuals and two medical experts to
be sufficient to give a valid first impression of the system. The
high standard deviation shows that the ease of using the device differs for individual students. Another aspect confirmed
by the supervising instructors is a slightly easier introduction of
the simulator to male students. This might be due to the increased computer gaming affinity and experience of our male
student sample. Furthermore, the feedback that important structures are not felt distinctively could be explained by the fact
that in contrast to the puncturing of the fascia, a strongly salient
haptic feature, the surface forces of the liver and the bile ducts
are not as high. The test persons had no puncture experience
before using the simulator and tend to have a high expectation
to feel all tissue interfaces very saliently. However, our medical
experts confirmed the salient fascia puncture event and the much
less pronounced puncture events of the other structures. Con-

struct validity was not evaluated explicitly in this study, but the
instructors observed a prominent difference, when our PTCDexperienced medical experts used the system compared to the
students. As our system currently only features one haptic device, switching from the virtual US tool to the needle tool fixes
the former at its current position. It is difficult to model a coupled US probing and needle insertion adequately with a single
haptic device. Using a single device also limits the application
of specifically adapted interfaces. The Phantom Omni used in
other studies [1], [2] better supports customization, i.e., replacing the stylus by a needle base or using a palpation pad, but
lacks 6-DOF haptic feedback. In our simulation, palpation takes
place first. Using a stylus for this is not optimal (see [1]), but
since palpation is mainly used for coarse orientation to successfully find intercostal spaces, we think it will not lead to negative
training effects. The palpation is followed by US probing, for
which a stylus interface is appropriate. We are confident that
more advanced haptics hardware (with multiple 6-DOF haptic
devices) could mitigate the problem in the future. The confidence of the user is shown to increase significantly during the
training process, which is a good hint for effective training. In
terms of visual rendering, the users did not consider the rendering of the patients skin surface fully realistic (see Table I, Q8),
but nevertheless, visualization of the patient by volume rendering is successful, both regarding the visual quality as well as
frame rate of visual rendering. Real-time rendering is achieved
easily using a Nvidia GTX 680, interactive rates are guaranteed
for the workbench setup used in the user study. The methods for
increasing depth perception, namely stereoscopic 3-D and tool
shadow rendering, can be regarded to be helpful. In general, the
supporting imaging simulations (X-ray, US) were received very
well by the students and can be considered a valuable part of
the simulation (Q11, Q12). However, not all aspects relevant to
real US are modeled, i.e., multiple reflexions or speed displacement correction per ray-tracing instead of ray-casting. Overall,
it is shown that direct visuo-haptic rendering can be performed
by completely relying on image data defined on its underlying
natural regular grid data structure without the traditional representation by surface or volume meshes and rasterization-based
rendering. For a truly patient specific simulation framework, a
method for the fast modeling of the virtual patient is needed.

FORTMEIER1 et al.: A VIRTUAL REALITY SYSTEM FOR PTCD SIMULATION USING DIRECT VISUO-HAPTIC RENDERING OF PARTIALLY

Using manual segmentation methods, this can take several
hours, but methods for time-efficient semiautomatic segmentation are currently under development.
As for the predecessor of the system, the 6-DOF high force
haptic device and workbench is still the dominant cost factor
($50k) in terms of hardware components. It can easily cost
more than ten times the sum of the other components, which are
usual consumer electronics.
VIII. CONCLUSION AND FUTURE STUDY
In this paper, we showed that our new visuo-haptic rendering
techniques for puncture atlases are valid means for PTCD simulation. A larger user evaluation study regarding concept and
face validity is on our schedule as well as a thorough evaluation
of the haptic force output with an already proposed framework
[25]. Virtual patient modeling is a further aspect to be addressed
in a separate publication.
Visuo-haptic rendering solely based on image data and segmentation without incorporation of surface and tetrahedral
meshes is shown to be successful, and we are confident that
future graphic hardware generations will enable usage of full
resolution CT image data (5122 pixels, thin slices). Also, more
powerful graphics hardware could lay the foundations for faster
and more accurate image-based deformation algorithms with
more complex constitutive models and unique material properties to handle heterogeneities of different soft tissue types;
currently, only hard and soft tissues are distinguished.
Given a fast visual rendering, the possibilities of using headmounted displays could be investigated. Current developments
as the Oculus Rift or Sony’s Project Morpheus might enable lowcost solutions applicable within our framework. Another interesting aspect would be the comparison of surface-based virtual
patients and our new approach in a user study. Within our framework we are able to represent both variants. The US simulation
methods could be augmented by a ray-tracing technique and by
incorporating Navier–Stokes fluid simulation for more realistic
Doppler-mode simulation. The contrast agent simulation could
be also adapted to the blood vessels. Finally, respiratory motion
using 4-D CT data or 4-D motion models [41] of the lungs and
the adjacent liver will be included in the visuo-haptic simulation.

365

The transmission is given by [43] assuming normal inclination
T (xi ) =

4 · Z(xi ) · Z(xi+1 )
.
Z(xi+1 ) + Z(xi )

The values of Z (xi ) and Z (xi+1 ) are taken from neighbored
points on the ray, Z (xi ) corresponds to the current point xi and
Z (xi+1 ) to its successor more inside the body.
For the absorption μ (xi ), the partial segmentations resp. the
interval heuristics are used, detailed value ranges for μ are given
in [43]. In case of intervals given in [43], we choose the interval
midpoint as μ-value.
Step 2: The algorithm used for the normalized local energy
calculation Ia after absorption, using Ia (x0 ) = 1, spacing s
between the samples and frequency f , is
Ia (xi ) = Ia (xi−1 ) · T (xi ) · exp(−μ(xi ) · s · f /10).
Step 3: The reflection coefficient R (xi ) is estimated as proposed by [22] assuming normal inclination to a tissue interface

2
Z(xi+1 ) − Z(xi )
.
R (xi ) =
Z(xi+1 ) + Z(xi )
The cos (φ)2 term for the modified Lambert’s cosine law
Ir = Ia · cos (φ)n [22] is estimated as

2
d · ∇Z(xi )
cos (φ)2 =
d · ∇Z(xi )
where d is the direction vector of the ray and ∇Z (xi ) is the
gradient of local impedance neighborhood Z (xi ). Thus, φ corresponds to the angle between the ray and the surface gradient.
The Lambert’s cosine law with the modified term using n = 2
tries to model a mixture of diffuse and accentuated specular
reflection.
According to [22], using Lambert’s modified cosine law for
diffuse reflection and the reflection coefficient R, the terms can
be combined yielding the reflected energy
Ir (xi ) = Ia (xi ) · cos (φ)2 · R (xi ) .
The resulting energy at the transducer Ie and the intensity
before TGC finally is

APPENDIX

Ie (xi ) = Ir (xi ) · Ia (xi ).

For completeness, the five steps that are performed for one
ray of a ray fan and the final US image compilation step are
given here.
Step 1: First, the conversion from Hounsfield values to densities ρ (xi ) at ray position xi takes place using the distinction of
cases from [42], where HU intervals are converted to densities
ρ by piecewise linear functions.
The impedance, i.e., Z-values in each pixel are calculated
using the formerly obtained densities ρ

Step 4: For simulated TGC, a heuristic function f (d) =
exp(−c · d · f /10.0)2 is used, where the time gain factor initialized as c = 0.55 can be set by the user on the GUI, d describes
the distance to the transducer and f is the transducer frequency
used. The resulting amplified signal to display at a pixel xi is
set to

Z(xi ) = α1 ρ(xi ) + α2 ρ(xi )2 + α3 ρ(xi )3
with α1 = 349.281, α2 = −0.151261 and α3 = 0.00117651
[22].

Itgc (xi ) = I0 ·

Ie (xi )
f (|xi − x0 |).

(15)

Step 5: Logarithmic rescaling delivers better visualization of
low energies and is defined as [22], [23]
Iout (xi ) =

log(a · Itgc (xi ) + 1)
log(a + 1)

366

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 20, NO. 1, JANUARY 2016

with a = 106 determining the amplification of weak signals.
Step 6: The fan image is linearly interpolated from the individual rays and postprocessing for additive Perlin noise [44]
and blurring by folding with a standard Gaussian filter kernel
(σ = 2 mm) takes place.
ACKNOWLEDGMENT
The authors would like to thank clinical partner P. Wellhöner,
colleague O. Maier, students P. Behringer, J. Beuke, T. Hecht
and S. Köhnen and all participants of the user study.
REFERENCES
[1] S. Ullrich, and T. Kuhlen, “Haptic palpation for medical simulation in
virtual environments,” IEEE Trans. Vis. Comput. Graph., vol. 18, no. 4,
pp. 617–625, Apr. 2012.
[2] T. Coles, N. John, D. Gould, and D. Caldwell, “Integrating haptics with
augmented reality in a femoral palpation and needle insertion training
simulation,” IEEE Trans. Haptics, vol. 4, no. 3, pp. 199–209, May/Jun.
2011.
[3] P. F. Villard, F. P. Vidal, L. Ap Cenydd, R. Holbrey, S. Pisharody, S.
Johnson, A. Bulpitt, N. W. John, F. Bello, and D. Gould, “Interventional
radiology virtual simulator for liver biopsy,” Int. J. Comput. Assist. Radiol.
Surg., vol. 9, pp. 255–267, Jul. 2013.
[4] D. Ni, W. Chan, J. Qin, and Y. Chui, “A virtual reality simulator for
ultrasound-guided biopsy training,” IEEE Comput. Graph. Appl., vol. 31,
no. 2, pp. 36–48, Mar./Apr. 2011.
[5] M. Färber, F. Hummel, C. Gerloff, and H. Handels, “Virtual reality simulator for the training of lumbar punctures,” Methods Inf. Med., vol. 48,
no. 5, pp. 493–501, 2009.
[6] L. Lin, Practical Clinical Ultrasonic Diagnosis. Singapore: World Scientific, 1997.
[7] N. Chentanez, R. Alterovitz, D. Ritchie, L. Cho, K. K. Hauser, K.
Goldberg, J. R. Shewchuk, and J. F. O’Brien, “Interactive simulation
of surgical needle insertion and steering,” in Proc. ACM SIGGRAPH,
Aug. 2009, pp. 88-1–88-10.
[8] S. DiMaio and S. Salcudean, “Needle steering and motion planning in
soft tissues,” IEEE Trans. Biomed. Eng., vol. 52, no. 6, pp. 965–974, Jun.
2005.
[9] C. Duriez, C. Guebert, M. Marchal, S. Cotin, and L. Grisoni, “Interactive simulation of flexible needle insertions based on constraint models,” in Proc. Med. Image Comput. Comput.-Assisted Intervention, 2009,
pp. 291–299.
[10] I. Peterlik, M. Nouicer, C. Duriez, S. Cotin, and A. Kheddar, “Constraintbased haptic rendering of multirate compliant mechanisms,” IEEE Trans.
Haptics, vol. 4, no. 3, pp. 175–187, May 2011.
[11] T. Coles, D. Meglan, and N. John, “The role of haptics in medical training
simulators: A survey of the state of the art,” IEEE Trans. Haptics, vol. 4,
no. 1, pp. 51–66, Jan. 2011.
[12] W. I. M. Willaert, R. Aggarwal, I. Van Herzeele, N. J. Cheshire, and F. E.
Vermassen, “Recent advancements in medical simulation: Patient-specific
virtual reality simulation,” World J. Surg., vol. 36, no. 7, pp. 1703–1712,
Jul. 2012.
[13] O. Goksel, K. Sapchuk, W. J. Morris, and S. E. Salcudean, “Prostate
brachytherapy training with simulated ultrasound and fluoroscopy images,” IEEE Trans. Biomed. Eng., vol. 60, no. 4, pp. 1002–1012,
Apr. 2013.
[14] F. Bello, A. Bulpitt, D. A. Gould, R. Holbrey, C. Hunt, N. W. John, S.
Johnson, R. Phillips, A. Sinha, F. P. Vidal, P.-F. Villard, and H. Woolnough,
“ImaGiNe-S: Imaging guided needle simulation,” in Proc. Eurograph.
Short Areas Papers Med. Prize Awards, 2009, pp. 5–8.
[15] F. P. Vidal, N. W. John, A. E. Healey, and D. A. Gould, “Simulation of
ultrasound guided needle puncture using patient specific data with 3D
textures and volume haptics,” Comput. Animation Virtual Worlds, vol. 19,
no. 2, pp. 111–127, 2008.
[16] P. F. Villard, F. P. Vidal, C. Hunt, F. Bello, N. W. John, S. Johnson, and D. A.
Gould, “A prototype percutaneous transhepatic cholangiography training
simulator with real-time breathing motion,” Int. J. Comput. Assist. Radiol.
Surg., vol. 4, pp. 571–578, 2009.
[17] N. Abolhassani, R. Patel, and M. Moallem, “Needle insertion into soft
tissue: A survey,” Med. Eng. Phys., vol. 29, no. 4, pp. 413–431, 2007.
[18] S. Yasmin and A. Sourin, “Image-based virtual palpation,” Trans. Comput.
Sci., vol. 7848, pp. 61–80, 2013.

[19] D. Fortmeier, A. Mastmeyer, and H. Handels, “An image-based multiproxy palpation algorithm for patient-specific VR-simulation,” in Proc.
Med. Meets Virtual Reality, 2014, pp. 107–113.
[20] S. Li, Q. Zhao, and S. Wang, “Interactive deformation and cutting simulation directly using patient-specific volumetric images,” Comput. Animation Virtual Worlds, vol. 25, no. 2, pp. 155–169, 2014.
[21] X. Wu, J. Allard, and S. Cotin, “Real-time modeling of vascular flow for
angiography simulation,” in Proc. Med. Image Comput. Comput.-Assisted
Intervention, 2007, pp. 557–565.
[22] T. Reichl, J. Passenger, O. Acosta, and O. Salvado, “Ultrasound goes
GPU: Real-time simulation using CUDA,” Proc. SPIE, vol. 7261, pp.
1–10, 2009.
[23] O. Kutter, A. Karamalis, W. Wein, and N. Navab, “A GPU-based framework for simulation of medical ultrasound,” Proc. SPIE, vol. 7261, pp.
1–9, 2009.
[24] W. Wein, S. Brunke, A. Khamene, M. Callstrom, and N. Navab, “Automatic CT-ultrasound registration for diagnostic imaging and image-guided
intervention,” Med. Image Anal., vol. 12, no. 5, pp. 577–585, 2008.
[25] A. Mastmeyer, T. Hecht, D. Fortmeier, and H. Handels, “Ray-casting based
evaluation framework for haptic force-feedback during percutaneous transhepatic catheter drainage punctures,” Int. J. Comput. Assist. Radiol. Surg.,
vol. 9, pp. 421–431, 2014.
[26] D. C. Ruspini, K. Kolarov, and O. Khatib, “The haptic display of complex
graphical environments,” in Proc. ACM SIGGRAPH, 1997, pp. 345–352.
[27] A. M. Okamura, C. Simone, and M. D. O’Leary, “Force modeling for
needle insertion into soft tissue,” IEEE Trans. Biomed. Eng., vol. 51,
no. 10, pp. 1707–1716, Oct. 2004.
[28] V. Hayward, and B. Armstrong, “A new computational model of friction
applied to haptic rendering,” Experiments Robotic VI, New York, NY:
Springer, 2000, pp. 404–412.
[29] K. Engel, M. Hadwiger, J. M. Kniss, A. E. Lefohn, C. R. Salama, and D.
Weiskopf, Real-Time Volume Graphics. New York, NY, USA: Taylor and
Francis, 2006.
[30] D. Fortmeier, A. Mastmeyer, and H. Handels, “Image-based soft tissue deformation algorithms for real-time simulation of liver puncture,” Current
Med. Imag. Rev., vol. 9, no. 2, pp. 154–165, 2013.
[31] S. F. Gibson, “3D chainmail: A fast algorithm for deforming volumetric
objects,” in Proc. Interactive 3D Graph., 1997, pp. 149–154.
[32] F. Rössler, T. Wolff, and T. Ertl, “Direct GPU-based volume deformation,”
in Proc. CURAC, 2008, pp. 65–68.
[33] D. Fortmeier, A. Mastmeyer, and H. Handels, “Image-based palpation
simulation with soft tissue deformations using chainmail on the GPU,” in
Proc. German Conf. Med. Image Comput., 2013, pp. 140–145.
[34] E. Haber and J. Modersitzki, “A multilevel method for image registration,”
SIAM J. Sci. Comput., vol. 27, no. 5, pp. 1594–1607, 2006.
[35] J. Ashburner, “A fast diffeomorphic image registration algorithm,” Neuroimage, vol. 38, no. 1, pp. 95–113, 2007.
[36] C. Dick, J. Georgii, and R. Westermann, “A real-time multigrid finite
hexahedra method for elasticity simulation using CUDA,” Simul. Model.
Practice Theory, vol. 19, no. 2, pp. 801–816, 2011.
[37] D. B. Russakoff, T. Rohlfing, K. Mori, D. Rueckert, A. Ho, J. R. Adler,
Jr., and C. R. Maurer, Jr., “Fast generation of digitally reconstructed
radiographs using attenuation fields with application to 2D-3D image
registration,” IEEE Trans. Med. Imag., vol. 24, no. 11, pp. 1441–1454,
Nov. 2005.
[38] G. Sherouse, K. Novins, and E. Chaney, “Computation of digitally reconstructed radiographs for use in radiotherapy treatment design,” Int. J. Rad.
Oncology Biol. Phys., vol. 18, pp. 651–658, 1990.
[39] B. Itkowitz, J. Handley, and W. Zhu, “The openhaptics toolkit: A library for
adding 3D touch navigation and haptics to graphics applications,” in Proc.
Eurohaptics Conf., Symp. Haptic Interfaces Virtual Environ. Teleoperator
Syst., 2005, pp. 590–591.
[40] R. Likert, “A technique for the measurement of attitudes,” Arch. Psych.,
vol. 140, 1932.
[41] J. Ehrhardt, R. Werner, A. Schmidt-Richberg, and H. Handels, “Statistical modeling of 4D respiratory lung motion using diffeomorphic image registration,” IEEE Trans. Med. Imag., vol. 30, no. 2, pp. 251–265,
Sep. 2011.
[42] U. Schneider, E. Pedroni, and A. Lomax, “The calibration of CT hounsfield
units for radiotherapy treatment planning,” Phys. Med. Biol., vol. 41,
no. 1, pp. 111–124, 1996.
[43] J. Bushberg, J. Seibert, E. Leidholdt, and J. Boone, The Essential Physics
of Medical Imaging. Philadelphia, PA, USA: Wolters Kluwer, 2011.
[44] K. Perlin, “Improving noise,” ACM Trans. Graph., vol. 21, no. 3,
pp. 681–682, Jul. 2002.
Authors’ photographs and biographies not available at the time of publication.

