IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 3, MARCH 2016

519

Single Versus Multiple Events Error Potential
Detection in a BCI-Controlled Car Game
With Continuous and Discrete Feedback
Alex Kreilinger∗ , Hannah Hiebel, and Gernot R. Müller-Putz, Member, IEEE

Abstract— Objective: This work aimed to find and evaluate a
new method for detecting errors in continuous brain–computer
interface (BCI) applications. Instead of classifying errors on a
single-trial basis, the new method was based on multiple events
(MEs) analysis to increase the accuracy of error detection. Methods: In a BCI-driven car game, based on motor imagery (MI), discrete events were triggered whenever subjects collided with coins
and/or barriers. Coins counted as correct events, whereas barriers were errors. This new method, termed ME method, combined
and averaged the classification results of single events (SEs) and
determined the correctness of MI trials, which consisted of event
sequences instead of SEs. The benefit of this method was evaluated
in an offline simulation. In an online experiment, the new method
was used to detect erroneous MI trials. Such MI trials were discarded and could be repeated by the users. Results: We found that,
even with low SE error potential (ErrP) detection rates, feasible
accuracies can be achieved when combining MEs to distinguish erroneous from correct MI trials. Online, all subjects reached higher
scores with error detection than without, at the cost of longer times
needed for completing the game. Conclusion: Findings suggest that
ErrP detection may become a reliable tool for monitoring continuous states in BCI applications when combining MEs. Significance:
This paper demonstrates a novel technique for detecting errors in
online continuous BCI applications, which yields promising results
even with low single-trial detection rates.
Index Terms—Brain–computer interface (BCI), continuous
feedback, electroencephalogram (EEG), error potential (ErrP).

I. INTRODUCTION
ESEARCH on brain–computer interfaces (BCIs) based on
electroencephalography (EEG) is still attracting an ever
increasing number of investigators, although the term was first
coined in 1973 [1]. A main focus of the work today is to make
these BCIs more practical for potential end users. This objective

R

Manuscript received January 28, 2015; revised May 9, 2015 and July 15,
2015; accepted July 28, 2015. Date of publication August 7, 2015; date of
current version February 16, 2016. This work was supported by the European
ICT Programme Project FP7-224631 Tools for Brain–Computer Interaction
(TOBI). Asterisk indicates corresponding author.
∗ A. Kreilinger is with the Institute for Knowledge Discovery, Graz University
of Technology, 8010 Graz, Austria, and also with BioTechMed-Graz, 8010 Graz,
Austria (e-mail: alex.kreilinger@tugraz.at).
H. Hiebel and G. R. Müller-Putz are with the Institute for Knowledge Discovery, Graz University of Technology and also with BioTechMed-Graz, Graz,
Austria.
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2015.2465866

requires easy-to-use applications, which are stable over time and
can guarantee reliable and accurate performance. One way to
improve the performance of BCIs is to carry out long-term training to increase proficiency. Unfortunately, this is not guaranteed
to work for each individual end user [2]–[6]. The long training time can successfully be reduced by using a large feature
space and machine learning techniques. However, equipping an
increased number of required electrodes can be time consuming
as well [7]. BCIs can also be designed to adapt to the user with
so-called adaptive BCIs [8].
Another possibility to increase the performance is to automatically detect errors from recorded brain waves after reactions
to particular decisions, and thereby, permit the BCI system to
either correct or inhibit erroneous commands. Distinct errors
committed or observed by a person cause detectable potentials,
so-called error potentials (ErrPs) [9], [10]. Depending on the
way these potentials are generated they are defined as either
observation [11], feedback [12], response [13], or interaction
ErrPs [14]. Interaction ErrPs can be detected at the region over
the anterior cingulate cortex (ACC) [15] and can be measured
after a person witnesses a false execution of an intended command. From the user’s perspective, an interaction ErrP occurs
whenever a command was misinterpreted by the control interface used. In contrast to the other types of ErrPs, which either
do not require the involvement of the user or do not emerge in
self-paced scenarios, the interaction ErrP seems to be the best
choice for increasing performance in BCI applications for end
users.
These interaction ErrPs can be used to increase the performance of BCIs by detecting specific reactions to errors that differ from reactions to correct events. False actions can be inhibited, which leads to increased accuracies of BCI-driven systems.
Several studies have already mentioned the technical capabilities of error correction for various paradigms [14], [16]. The
paradigms used in these experiments have in common that they
are designed to work well for ErrP processing. That is, in a discrete feedback, time- and phase-locked ErrPs can be detected by
evaluating time periods after discrete events. However, modern
BCI applications are no longer limited to discrete applications
where only one discrete decision can be made at one given point
in time. Instead, continuously controlled applications gain importance as they offer a more natural implementation of BCI for
activities of daily living. Relevant examples are a continuously
moving wheelchair for mobility [17] or a neuroprosthesis for
grasp and elbow functions [18]. Other useful scenarios can be
the application of BCIs in games [19] or in virtual reality [20].

0018-9294 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

520

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 3, MARCH 2016

An attempt to detect errors offline in a continuous feedback
application has already been made in [21] by using a space
game. However, the game was controlled manually and not
using BCI and instead of EEG the authors chose to use electrocorticography. Errors could be caused by forced deviations
from the intended movement or by collisions with obstacles.
These errors could be detected above chance level within a 6-s
window around the event. A replication of the study with EEG
was conducted in [22]. Here, errors were detected by using temporal and spectral features in time- and phase-locked and asynchronous analyses. The asynchronous analysis achieved results
above random but was still inferior to the time- and phase-locked
approach. Moreover, analysis was carried out with offline data
only.
This study aimed to find and evaluate a feasible method to
use ErrP detection in continuous applications online. The timeand phase-locked nature of ErrPs needed for analyzing temporal
features was exploited by showing discrete feedback on top of
ongoing continuous feedback. This study serves as a follow-up
to [23] where this approach was already addressed: A continuous feedback in form of a moving artificial arm was coupled
with additional discrete events as triggers and ErrPs were successfully found in offline analysis. However, the accuracy for
single-trial detection of these ErrPs was not sufficient to be
feasible in online applications.
In this study, we demonstrate a new method that can be used in
continuous BCI applications without relying on single-trial error
detections. In a continuous, BCI-driven car game based on motor
imagery (MI) [24] subjects observed multiple discrete events
while moving the car continuously. Although each single event
(SE) was classified individually, a decision was only reached
after a series of multiple events (MEs) were witnessed by the
users. This new method is termed the ME method, whereas the
old standard method based on single trials, or in this case events,
is referred to as the SE method.
In the course of the experiments, we also analyzed the impact
of different types of feedback: visual feedback alone versus
visual and acoustic feedback.
II. METHODS
This study describes a series of experiments and analyses.
These include sessions for training MI, a car game controlled
continuously with MI, analyses to detect ErrPs after observing discrete events, simulations with the new method based on
MEs, and a session where the new method is used to determine
false actions in the car game online. The order in which these
experiments and analyses were carried out is outlined in Fig. 1.
Subjects, Hardware, and Recording
Five female and five male subjects (24.9 ± 2.3 years) participated in the study. All subjects had previous BCI experience
and were reported to be able to control MI-based BCIs. They
were selected intentionally to reduce long initial BCI training
time in order to not unnecessarily drain their concentration level.
Data were recorded with two g.USBamps (Guger Technologies
OEG, Graz, Austria). The 32 Ag/AgCl-electrodes were placed

Fig. 1. Order of the experiments and analyses. Experiments with the subjects
were divided into two sessions on different days. Subsequent analyses were
carried out with data collected during these experiments.

on the scalps of the subjects according to a dense 10–20 system.
Thereby, all of the important regions for MI (C3, Cz, C4) and
ErrP detection (the area over the ACC at channels Fz and Cz)
were covered. All channels were monopolar recorded with a
reference electrode at the left mastoid and ground on the right
mastoid. The sample rate was set to 512 Hz with a high-pass
filter at 0.5 Hz, a low-pass filter at 100 Hz, and a notch filter at
50 Hz.
A. Training of Subjects and Calibration of MI Classifiers
1) Experiment Setup: The first part of the experiments was
conducted to train the subjects in using a BCI and to subsequently calibrate MI classifiers. Two to four training runs with
the standard Graz-BCI paradigm [24] were carried out. Subjects
were asked to perform MI of the two required classes (right hand
versus both feet), in total 20 trials per class in each run. One
trial lasted 7 s: appearance of the cross at 0 s, appearance of the
cue at 2 s, disappearance of the cue at 3.25 s, and end of the trial
with the disappearance of the cross at 7 s. Subjects were asked
to maintain active MI between 3.25 and 7 s. As a rule, only two
runs were carried out. However, subjects who produced a noticeable amount of noisy trials were asked to repeat one or two
runs.
2) Analysis: All 32 electrodes were used to perform common average reference (CAR) spatial filtering. The relevant
channels for this filtering were at electrode positions C3, Cz,
and C4. ERD/S maps [25], [26] were used to visualize distinct
patterns. The patterns were based on variations of band power
in certain frequency bands related to active MI. Based on the
maps, the best frequency bands on channels C3, Cz, or C4 were
selected. Per subject, 1–3 frequency bands were selected by this
means. These frequency bands were situated mainly in the alpha
(8–12 Hz) and beta (13–30 Hz) range on channel C3. The best
point in time was found with a 10×10 cross validation, which
was repeated in steps of 100 ms within the active MI period
(3.25–7 s). This point in time was used to generate the final
individual linear discriminant analysis (LDA) classifier for each
subject.

KREILINGER et al.: SINGLE VERSUS MULTIPLE EVENTS ERROR POTENTIAL DETECTION IN A BCI-CONTROLLED CAR GAME

521

B. Online Car Game Without ErrP Detection 1
1) Experiment Setup: The generated classifier from training
data (see Section II-A) was applied to let subjects control the
movement of a car in a game. The car was moving at a constant speed on a vertically scrolling street. Subjects could move
the car to the left by performing feet MI and to the right by
performing right-hand MI. Control was active all the time, not
just in predefined periods of time. The car continuously moved
farther away from the center the more distinctly the current MI
task was detected by the classifier, which was represented by the
amplitude of the MI classifier output (CO). However, the car’s
movement was limited by the outermost lanes. Coins appeared
randomly on the left or the right side of the street. For each
coin appearing, a barrier appeared on the opposite side of the
street. Coins were defined as targets and subjects were asked
to collect as many as possible while avoiding barriers in the
process.
The game consisted of six runs with 20 trials left (coins on
the left side) versus 20 trials right (coins on the right side).
One of the subjects, S04, had to stop after four runs caused by
fatigue and lack of concentration; the others performed in all
six runs. During each trial, a maximum of four coins could be
collected, but also the same number of barriers on the opposite
side. The side of the coins and barriers remained constant within
a trial. A mixed collection of objects was possible when the MI
performance during the trial was unstable, e.g., two coins on
one side followed by two barriers on the other side. Coins and
their associated barriers appeared at intervals of one second. In
total, a trial lasted 8 s beginning with the crossing of a starting
line at second 0, followed by collectible objects at seconds 3, 4,
5, 6, and ending with the crossing of the finishing line after 8 s.
All these events appeared 4 s earlier on the top of the screen.
That is, the vertical scrolling speed was set in such a way that
the car needed 4 s to reach new objects on the street. Thereby,
subjects were able to prepare for oncoming events.
The paradigm allowed a maximum collection of 960 coins
within all six runs. Each time a coin was collected, the score
increased by +1 and decreased by −1 when colliding with a
barrier. However, negative scores were not possible. The minimum score was limited to zero in order to not discourage the
subjects. Every collision with a coin or a barrier was confirmed
by a short feedback event. The impact of the type of feedback was examined by testing two different modalities. Half of
the runs were recorded with acoustic (short beeps with differently high frequencies) and visual (temporarily increased size
and change of color of the car) feedback combined (“Sound”
modality); the other half used only visual feedback without any
sound (“NoSound” modality). The sequence of these two different run modalities was randomized for each subject individually
in order to avoid possible learning effects. The discrete feedback
events were chosen to be neutral for coin and barrier collisions:
instead of linking the bright green flashing color and the higher
frequency sound to coins, the sounds and flashes were merely
dependent on the side of the street where the current collision
occurred. Pictures of the car game depicting several random
situations can be seen in Fig. 2.

Fig. 2. Different situations during the car game. (a) Start of a trial: new objects
appear at the top of the screen and subjects can begin performing the correct
MI task to move toward the coin. In this case, the MI target is on the left side.
(b), (c) Collisions with barriers and coins on the right. The color and type of
sound is the same for all collisions on the right side, independent from the type
of object. (d) Left side collisions have a different visual and acoustic feedback.
Crossing the finishing line ends the current MI trial.

2) Analysis: Reactions to discrete events (collisions with
coins and barriers) were analyzed for possible ErrPs. Channels
Fz, Cz, and Pz were spatially filtered with CAR and temporally
filtered with an 8-Hz low-pass filter. Only data within a 1-s window following the discrete events were evaluated. Data were
separated into two different classes, the time windows containing either reactions to correct events or to errors. Features were
selected with a discriminant power (DP) algorithm [27]. This
algorithm analyzed each point in time successively and counted
the values (EEG amplitudes) of each class that were outside of
the distribution of the respective other class. Up to 30 of the
best points in time were used as features. The actual number of
features was determined by repeating a 10×10 cross-validation
procedure with each number of features. After cross validating
the results, the detection rates for the best number of features
of correct and erroneous events for each subject were calculated individually. The results for both classes were averaged
to mitigate potential bias effects caused by the typically much
lower number of error events. These results are based on detecting SEs and the according method to obtain the SE detection
rate or accuracy is the SE method. The corresponding measure is
termed “SE_Acc_CV” (SE accuracy calculated via cross validation). Data were analyzed separately for the according feedback
modalities “Sound” and “NoSound.”
To analyze potential differences in SE_Acc_CV caused by the
applied feedback modalities, a paired-samples t-test with the independent variable “feedback modality” (“Sound,” “NoSound”)
was conducted (with a significance level of 0.05). Average
SE_Acc_CV (%) was used as dependent variable. Since the
results of the t-test did not show a statistically significant difference between both modalities, the SE_Acc_CV evaluation was
repeated for a third pseudomodality named “Combined,” which
comprised all data, and therefore, a larger pool of trials.

522

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 3, MARCH 2016

The MI performance was obtained by calculating the percentage of collected coins out of all collisions with objects on the
street. This part of the study was shown in a preliminary version
in [28].
C. Simulating the Effect of ErrP Detection based on MEs
Offline
This section aims to show the potential benefits of a new
ME analysis in an offline simulation based on data collected in
Section II-B.
1) The ME Method Offline: The new approach was to combine consecutive SEs for the analysis. The car game was especially designed to force multiple collisions with objects during
one single MI trial. The reactions caused by these collisions were
classified with LDA classifiers as in the analysis in Section IIB2. The CO was positive for a detected error and negative for a
correct response. The higher the absolute value the more distinct
was the classification. In the new ME method, all classification
results of SEs within one MI trial were combined for evaluating the whole MI trial. There were four possible outcomes in a
single MI trial, which had to be evaluated differently.
1) Events only occurred on one side of the road: In this case,
all SE classification results were averaged. If the averaged
CO was positive (erroneous), the original MI target (the
side of the road with the coins) was determined to be on
the opposite side of where the event collections occurred.
2) Events occurred on both sides of the road with a majority on one side: Classification results from events on
the minority side were inverted (multiplied by −1), and
then averaged with the other classification results. For example, three events occurred on the left side, all of them
errors. One event was on the right side, which was correct.
With correct classifications the left side events would all
lead to positive COs, whereas that on the right side would
be negative. Inverting this CO increases the number of
averages to four without giving the one SE on the right
side more weight. Since all four COs now are positive, the
averaged result clearly indicates that the MI trial was, in
fact, mostly erroneous.
3) Events occurred on both sides an equal amount of times:
COs on both sides were averaged individually. The side
with the lower average was selected as the original MI
target. An example for this outcome is also shown in
Fig. 3.
4) No events occurred at all: In this rare case, it was not possible to determine the target and the MI trial was removed
from the simulation.
2) Simulation and Analysis: The capability of this new approach to correctly determine the original MI targets was tested
in the offline simulation. As the detection rates of this novel technique were no longer based on SEs, the basis of how to report
the performance of the approach had to be adapted. MEs indicated whether an MI trial as a whole was correct, and thereby,
the original MI target could be determined. The measure to define the accuracy of this determination was the ratio of correctly
identified MI trial targets to the whole number of MI trials, from

Fig. 3. Possible scenario for the offline simulation. The same number of objects were collected on each side. Each response is classified separately, resulting
in different COs. Detected ErrPs result in positive COs and are visualized as red
waveforms. Correct events result in negative COs and are visualized as green
waveforms. Both sides’ COs are averaged and the side with the higher positive
value is identified as erroneous. Although not all individual COs are correct
(the second event on the left side is a misclassification), the correct intended
direction can be identified after averaging. The MI trial in this example can be
classified as “right side.”

here on referred to as “ME_Acc.” This ME_Acc was compared
to the detection rates obtained by analyzing SEs, “SE_Acc.”
Additionally, ME_Acc was compared to the original MI performance (in the offline simulation termed “MI_Acc”), which was
obtained by analyzing the rate of collected coins to collected
objects in total. The reasoning behind this comparison was to
find out whether the capability of the ME method to determine
original targets of MI trials might even be on par with the original MI performance. To mitigate any influence from potential
overfitting, data were separated between runs. Each run was
used as a test set on which an ErrP LDA classifier, calculated
with data from the other runs, was applied. All three measures
were calculated in each test set. For ME_Acc, all MI trials were
evaluated with the new ME method. For SE_Acc, all SE classifications were evaluated again. For MI_Acc, all coin collections
were compared to the total number of events. The results were
then averaged over all corresponding runs.
Equations (1)–(3) demonstrate how these three measures were
calculated in the offline simulation. In (1), true positive (TP) and
false negative (FN) values represent correctly and incorrectly
classified errors (reactions to collisions with barriers), respectively. True negative (TN) and false positive (FP) values represent correct and incorrect classifications of reactions to coin
collections, respectively. The equation basically describes the
balanced accuracy, which is the mean of sensitivity and specificity. In (2), CorrLeft and CorrRight represent the numbers of
correctly classified MI targets, whereas AllLeft and AllRight
give the whole number of MI trials. In (3), the number of collected coins is compared to the sum of Coins and Barriers. All
measures are averaged over the number of test runs n.


TP i
TN i
n
1  TP i +FN i + TN i +FP i
· 100
(1)
SE Acc =
n i=1
2
1  CorrLefti + CorrRighti
· 100
n i=1 AllLefti + AllRighti
n

ME Acc =

(2)

KREILINGER et al.: SINGLE VERSUS MULTIPLE EVENTS ERROR POTENTIAL DETECTION IN A BCI-CONTROLLED CAR GAME

Coinsi
1
MI Acc =
· 100
n i=1 Coinsi + Barriersi



n

(3)

The simulation was carried out for the two feedback modalities “Sound” and “NoSound.” Based on the findings of the t-test
described in Section II-B2, which indicated that the modality
had no effect on ErrP detection rates, the simulation was also
carried out with all data as in the “Combined” pseudomodality.
To investigate potential differences in classification accuracy
depending on method and feedback modality, a 3 × 2 ANOVA
for repeated measures was performed with the within-subjects
factors “method” (“SE,” “ME,” “MI”) and “feedback modality”
(“Sound,” “NoSound”). The averaged accuracy (SE_Acc: detection rate of SEs in %; ME_Acc: rate of correctly identified
MI trials that included at least one event in %; MI_Acc: proportion of correct events in %) served as dependent variable. A
Kolmogorov–Smirnov test was used to check if data followed
a normal distribution. Sphericity assumption was assessed by
using the Mauchley’s sphericity test. In all statistical analyses,
the probability of a Type I error was maintained at 0.05. For
posttests of significant ANOVA effects, Bonferroni corrections
for multiple comparisons were applied.
D. Online Car Game Without ErrP Detection 2
On a second session, after analyzing data from day 1 and performing the offline simulation, selected participants performed
the car game again. This experiment served as precursor for the
subsequent online application of ErrP detection.
1) Selection of Subjects: Not all subjects participated; inclusion criteria were based on data from previous sections. The MI
performance threshold was set to 70 % because of the minimum
correct response rate needed for a feasible BCI application [29].
The level for the error detection rate to be potentially beneficial
depends on the initial MI performance and can be calculated
with (4)–(7) based on Wolpaw’s definition in [27] and [30]. The
original bit rate per trial BR depends only on the MI performance, whereas the new bit rate BRn with applied error detection to inhibit detected commands depends on the percentage
of transmitted commands pec and the increased accuracy of the
system pn . Remaining variables in the equations are as follows:
p describes the original MI performance; c the detection rate of
correct commands; e the detection rate of errors; Nc the number
of classes. The minimum error detection rate needed to theoretically increase the original bit rate can be calculated individually
for each subject. For example, at an MI performance of exactly
70 % the bit rate already increases at an error detection rate of
58.9 %; for an MI performance of 90 % the error detection rate
has to be at least 73.9 % to have a beneficial effect. Six of the
ten subjects could fulfill the criteria of having an MI performance >70 % and accordingly high error detection rates, based
on ME_Acc and MI_Acc values found in the offline simulation
with the modality “Sound.” Unfortunately, two of them were no
longer available, leaving four subjects for the final part.
pec = p · c + (1 − p) · (1 − e)
p·c
pn =
pec

523

(4)
(5)

BR = log2 (Nc ) + p · log2 (p) + (1 − p) · log2

1−p
Nc − 1



(6)


BRn = pec · log2 (Nc ) + pn · log2 (pn )

+ (1 − pn ) · log2

1 − pn
Nc − 1


(7)

2) Experiment Setup: The purpose of this experiment was
to generate new ErrP classifiers for the final online task with
applied ErrP detection. The setup was similar to the setup explained in Section II-B. The MI classifiers generated in Section II-A2 were reused to avoid time-intensive MI training. The
subjects merely performed one short setup run consisting of
three left and three right MI trials to adapt the bias of the MI
classifier if necessary. The car game was carried out again, but
now with only half of the trials, since the used modality was
chosen to be “Sound” exclusively for this and the following experiment. S01 performed only four runs due to a relatively high
amount of barrier collections, thereby generating enough data
for ErrP classification but later subjects were asked to carry out
six runs.
3) Analysis: ErrP classifiers were generated from the newly
recorded data, following the method used in Section II-B2. The
MI performance of the subjects in the car game was measured
in terms of collected coins and barriers.
E. Online Car Game With ErrP Detection
The final experiment was carried out on the same day as the
car game without ErrP detection in Section II-D with the same
four remaining subjects. The aim was to demonstrate the feasibility of the new ME method in an online experiment alongside
the evaluation in the offline simulation.
1) Experiment Setup: In this experiment, the car game was
enhanced by embedding the new ME method. The ME method
was used to evaluate each single MI trial after the car had crossed
the finishing line. There was one important difference compared
to how the method was used in the offline simulation. The aim
was now no longer the determination of the original MI target but
to determine whether the MI trial on the whole was erroneous.
In case of an erroneous MI trial, the score of the whole MI trial
was discarded and the subject had the chance to repeat the trial.
Another difference was that MI trials with an equal number
of events on both sides were no longer evaluated. Otherwise,
the procedure for the evaluation of one MI trial followed the
explanation in Section II-C1. An example for an MI trial with
three errors and one correct event is demonstrated in Fig. 4.
To summarize, an MI trial had a chance to be discarded and
repeated if one of the two following situations occurred.
1) All events occurred on one side of the road and the average
CO for all events was positive.
2) Events occurred on both sides of the road with one majority side with more events. The average CO of the events
on the majority side and the inverted COs of the minority
side were positive.

524

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 3, MARCH 2016

TABLE I
MI PERFORMANCE CALCULATED BY GENERATED LDA CLASSIFIERS

Subject

Fig. 4. One possible online scenario. The subject collides with three barriers
and then picks up one coin on the opposite side. Each reaction to a collision is
classified separately and results in a positive or negative number, with positive
numbers indicating the detection of an ErrP. ErrPs are further visualized as red
waveforms and reactions to correct events as green waveforms. In this example,
the first reaction is misclassified as correct, the rest of the collisions are classified
correctly. The left side is the majority side with more collections. The CO of
the one collision on the right side is multiplied by −1. Because the result after
averaging all COs is a positive number, the whole MI trial has to be discarded
and can be repeated.

The car game with online ErrP detection consisted of six runs
with 20 MI trials each, with ten targets on the left and ten targets
on the right. As opposed to the previous car game sessions,
negative scores were possible in this experiment.
2) Analysis: The functionality of the online ErrP detection
with the ME method was evaluated by comparing two different
outcomes: the actual outcome after applied ErrP detection versus the outcome that would have been achieved without ErrP
detection. This was possible because, without activated ErrP
detection, each run would have stopped exactly after the 20th
trial. Therefore, the score after 20 trials, including discarded MI
trials, was saved at this point for later analysis. Active ErrP detection could prolong a run for as many trials necessary to have
20 trials that were not discarded as erroneous. The expected
outcome of the experiment was to trade a longer time needed
for completion in order to achieve improved accuracy.
The goal of the ME method in the online experiment was
to detect erroneous MI trials. The corresponding performance
measure had to be calculated differently than in the offline simulation. This measure, called “ME_Acc_Online” was calculated
based on (8). Here, TP and FN indicate the numbers of detected
and missed erroneous MI trials. TN and FP represent the numbers of detected or misclassified correct MI trials. MI trials that
were not eligible for being discarded due to an equal number of
events on both sides were excluded from this calculation.


TP
TN
TP+FN + TN+FP
· 100
(8)
ME Acc Online =
2
III. RESULTS
A. Training of Subjects and Calibration of MI Classifiers
All the subjects performed short MI training to generate data
for setting up LDA classifiers to control the car game in all later
experiments. Individual results are listed in Table I. The best
accuracies and points in time in relation to the start of the trial

S01
S02
S03
S04
S05
S06
S07
S08
S09
S10

Best
Accuracy [%]

Best
Time [s]

Upper Ten
Percent [%]

Median
Accuracy [%]

74.0
98.5
80.6
81.2
97.5
86.2
96.5
88.0
86.6
78.9

6.1
5.5
5.2
4.5
5.4
3.8
4.6
4.9
3.4
3.6

72.7
95.3
80.0
79.8
96.5
84.1
95.3
87.1
85.1
74.3

68.3
88.2
73.4
76.2
94.4
75.1
87.7
83.2
64.2
58.1

Best Accuracy and Best Time demonstrate the peak performances at the
best individual points in time during active MI. Upper Ten Percent shows
the level of performance which was exceeded for ten percent of points in
time tested within the active MI period. The Median Accuracy serves as
an additional measure of performance.

at second 0 were determined in a cross-validation procedure. As
one single outlier with a high accuracy at one single point in
time could whitewash the individual performance, the table also
shows the threshold exceeded by at least 10 % of all classification accuracies and the median accuracy within the active MI
period (3.25–7 s). These results served as a prediction of how
well subjects would be able to control the car game. Their MI
performance was closely related to the expected error rate when
controlling the game.

B. Online Car Game Without ErrP Detection 1
The results of this part consist of the online MI performance
and offline ErrP detection analysis based on the SE method. The
first was determined by the scored points during the car game.
The second was found by cross-validating ErrP classifications.
The online score was increased by +1 for each collected coin and
reduced by −1 for each collision with a barrier. Subjects could
also miss all objects within a trial. In this case, the score was not
altered and neither a positive nor a negative feedback occurred.
Furthermore, the score could never fall below zero points. MI
performance influenced the subsequent offline analysis as the
number of correct and erroneous trials for ErrP detection was
equal to the number of collected coins and barriers. Table II
shows the score, number of collected coins versus barriers, the
MI performance and the error rate (100 %−MI performance) for
each participant. The table shows results from all data combined,
that is “Sound” and “NoSound.” Fig. 5 visualizes these results
sorted from highest to lowest score.
The performance-depending rate of errors evoked differently strong ErrPs for the ten subjects. The error-minus-correct
waveforms—the ErrPs—for all the participants are demonstrated in Fig. 6. Three channels, Fz, Cz, and Pz, are shown
for the two modalities “Sound” and “NoSound.” The most notable effect is visible over Fz and Cz, the channels directly over
the ACC. On average, there is a measurable negativity about
400 ms after the moment of a collision with a barrier.

KREILINGER et al.: SINGLE VERSUS MULTIPLE EVENTS ERROR POTENTIAL DETECTION IN A BCI-CONTROLLED CAR GAME

TABLE II
RESULTS OF THE CAR GAME IN TERMS OF TOTAL SCORE OUT
OF 960 MAXIMUM POINTS (640 FOR S04) AND COIN:BARRIER
COLLECTION RATE FOR EACH PARTICIPANT

Subject
S01
S02
S03
S04
S05
S06
S07
S08
S09
S10

Total
Score

Coins:
Barriers

MI Performance [%]

Error
Rate [%]

409
718
588
189
722
202
703
751
100
265

599:192
782:65
709:127
367:185
797:75
489:310
774:72
823:72
404:349
541:302

75.7
92.3
84.8
66.5
91.4
61.2
91.5
92.0
53.7
64.2

24.3
7.7
15.2
33.5
8.6
38.8
8.5
8.0
46.3
35.8

The MI Performance shows the percentage of collected coins and the
Error Rate the percentage of collisions with barriers.

525

TABLE III
COMPARISON OF SE ERROR/CORRECT ACCURACIES (SE_ACC) VERSUS MI
TRIAL DETECTION RATES BASED ON ME ANALYSIS (ME_ACC) AND ORIGINAL
MI PERFORMANCES (MI_ACC)
Sound [%]

NoSound [%]

Combined [%]

Subject

SE_
Acc

ME_
Acc

MI_
Acc

SE_
Acc

ME_
Acc

MI_
Acc

SE_
Acc

ME_
Acc

MI_
Acc

S01
S02
S03
S04
S05
S06
S07
S08
S09
S10
mean
± std

66.7
78.9
53.9
60.9
67.2
61.5
76.4
64.7
51.0
48.9
63.0
9.9

81.7
93.3
68.3
70.0
86.7
69.2
93.3
89.2
55.8
56.7
76.4
14.3

72.9
92.3
82.0
68.6
91.2
61.1
90.7
90.5
53.1
66.7
76.9
14.3

59.6
65.7
60.2
55.0
75.9
52.8
70.3
61.0
59.7
49.3
61.0
8.0

71.7
88.3
79.2
58.8
91.7
52.5
85.0
92.5
60.0
51.7
73.1
16.3

78.3
92.3
87.5
65.2
91.5
61.1
92.3
93.4
53.1
61.3
77.6
15.9

62.5
71.3
54.0
57.2
71.5
56.3
74.2
61.2
57.8
51.3
61.7
8.0

76.7
84.2
68.3
65.6
87.9
59.2
89.6
85.4
62.5
54.6
73.4
12.9

75.6
92.3
84.8
66.9
91.4
61.1
91.5
91.9
53.1
64.0
77.3
15.0

The values show offline simulation results and are averaged over all runs that belong
to the corresponding modalities. Bold numbers indicate subjects that have an MI_Acc
above 70 % and would benefit from ErrP detection based on the two methods SE or ME,
as suggested by individual bit rate calculations.

Fig. 5. Barplot showing scores and individual collection rates of coins and
barriers in sorted order from highest to lowest score.

modality and 61.1 ± 8.0 % for “NoSound.” The results of the ttest, which was used to compare SE_Acc_CV between “Sound”
and “NoSound,” showed no significant difference (t(9) = 0.51,
p = .620). An additional analysis was thus conducted with all
the data combined (“Combined”). Here, SE_Acc_CV was on
average 61.2 ± 8.5 %. The new ME method was not yet applied
in this analysis.
C. Simulating the Effect of ErrP Detection based on MEs
Offline

Fig. 6. Recorded ErrPs for all individual subjects and averaged waveforms,
shown specifically for (a) “Sound” and (b) “NoSound” modalities. Point in time
0 ms is the time of the collision with an object on the street. The measured ErrPs
are shown for three different channel locations: Fz, Cz, and Pz.

An offline analysis of “Sound” and “NoSound” data yielded
SE_Acc_CV results for correct and erroneous trials above
chance level for all subjects except S09 and S10 in at least one
modality. The chance level was on average 54.4 % (“Sound”)
and 54.3 % (“NoSound”), depending on the number of trials
per class [31]. Feature extraction and cross validation were
performed individually for each modality. The comparison of
SE_Acc_CVs for feedback with and without sound brought
forth following results: the average SE_Acc_CV for detecting
correct and erroneous trials was 62.1 ± 9.3 % for the “Sound”

The results of the offline simulation show the advantages of
the new ME method over the standard SE method. The simulation analyzed both methods by using the same LDA classifiers. In the SE method, these classifiers were solely used
on SEs, whereas in the ME method consecutive SEs within
whole MI trials were combined as MEs. The simulation analyzed data from Section II-B. The results are demonstrated in
Table III. Data were at first separated according to the two main
modalities “Sound” and “NoSound.” Later, the whole dataset
was also analyzed in the “Combined” modality. This modality,
although included in the simulation, was not analyzed statistically as it included data of both other modalities. Values in the
columns labeled “SE_Acc” demonstrate individual ErrP detection rates obtained with the standard SE method. “ME_Acc”
demonstrates the detection rates for the correct determination
of original MI trial targets that were obtained with the new ME
method. “MI_Acc” shows the MI performances achieved by the
subjects via controlling the car. All these values were averaged
over all the runs (three runs for “Sound” and “NoSound,” and
six runs for “Combined”), which explains the small differences
between MI performance in Table II and MI_Acc in Table III.
ME_Acc values in Table III indicate how many MI trials can be
correctly identified when only looking at reactions to a sequence
of discrete events.

526

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 3, MARCH 2016

TABLE IV
RESULTS FROM THE REPEATED CAR GAME WITHOUT ONLINE
ERRP DETECTION

Subject

Coins:
Barriers

MI Performance [%]

Error
Rate [%]

SE_Acc_
CV [%]

S01
S02
S05
S07

188:107
253:101
428:19
420:56

63.7
71.5
95.7
88.2

36.3
28.5
4.3
11.8

62.1
67.7
71.5
75.0

The maximum score is 480 points (320 for S01). The ratio
of coins versus barriers determines the MI Performance (percentage of coins) and the Error Rate (percentage of barriers).
SE_Acc_CV depicts the ErrP classification accuracies found
in an offline analysis based on the SE method with a 10×10
cross-validation procedure.

The bold numbers in Table III highlight the subjects that can
potentially benefit from online ErrP detection, based on the bit
rate calculations from Section II-D1. The number of subjects is
higher in column “ME_Acc” than in column “SE_Acc” for all
modalities. In the case of the modality “Sound,” which was used
in later experiments, six out of ten subjects potentially benefit
from ErrP detection based on the ME method, while only three
would benefit from using the standard SE method.
ANOVA results concerning simulations of “Sound” and
“NoSound” data revealed a significant main effect “method”
(F(2,18) = 21.61, p < .001). Posttests showed a significantly
higher accuracy for “ME” (M = 74.78, SD = 14.70) and “MI”
(M = 77.26, SD = 15.03) than for “SE” (M = 61.98, SD =
8.19). Accuracy did not differ significantly between “ME” and
“MI.” The main effect “feedback modality” did not reach statistical significance (F(1,9) = 0.79, p = .396). The interaction
effect “method × feedback modality” was also not significant
(F(2,18) = 1.46, p = .259).
D. Online Car Game Without ErrP Detection 2
The reason for repeating the car game without ErrP detection
was to generate new ErrP classifiers. The results are summarized
in Table IV, including the number of collected coins and barriers and the directly associated MI performance and error rate.
Column “SE_Acc_CV” describes error detection rates that were
achieved in a 10 × 10 cross-validation based on the SE method.
E. Online Car Game With ErrP Detection
After the new ErrP classifiers were generated based on the
SE method, participants were able to control the car game with
online ErrP detection based on the new ME method. Their performance during this application is demonstrated in Table V.
The results demonstrate the individual increased numbers of
scored points when using error detection compared to the score
reached after exactly 20 trials including the points from discarded erroneous MI trials. As an inevitable side effect, the
number of MI trials needed for completion was also increased.
The performance of the ME method in the online experiment
was also measured by the detection rate of erroneous and correct
MI trials. The corresponding measure is the “ME_Acc_Online”

TABLE V
RESULTS OF THE FINAL ONLINE APPLICATION WITH ACTIVATED ONLINE
ERRP DETECTION
Subject:
Trials without ErrP
Trials with ErrP
Δ Trials [%]
Score without ErrP
Score with ErrP
Δ Score [%]
TP
FN
FP
TN
ME_Acc_Online [%]

S01

S02

S05

S07

120
166
+38.3
170
182
+7.1
14
15
32
84
60.3

120
145
+20.8
164
180
+9.8
15
9
10
85
76.0

120
126
+5.0
374
388
+3.7
3
2
3
113
78.7

120
126
+5.0
353
367
+4.0
2
0
4
114
98.3

The table demonstrates the increased number of MI trials needed due
to discarded trials after ErrP detection and the relation of scored points
with and without ErrP detection. The TP, FN, FP, and TN detection,
as well as the percentage of correct classifications based on the ME
method (ME_Acc_Online) are given for all trials that were eligible
for ErrP detection, not including MI trials with an equal number of
collected coins and barriers.

calculated from the TP, FN, FP, and TN numbers that count the
true or false detections of correct and erroneous MI trials.
IV. DISCUSSION
A. Training of Subjects and Calibration of MI Classifiers
This part was performed to calibrate MI classifiers for all the
following experiments on day 1 and day 2, see Fig. 1. The results
in Table I indicate that all participants were able to successfully
perform MI in this computer-driven paradigm. All subjects had
“Upper Ten Percent” MI detection rates higher than 70 %, which
is said to be needed for feasible BCI control [29]. The MI LDA
classifiers, which were generated for each subject, were used in
all subsequent experiments.
B. Online Car Game Without ErrP Detection 1
In the second experiment on day 1, data for ErrP detection
analyses and simulations were collected. MI performance
was measured in terms of the percentage of collected coins.
Most subjects were able to maintain their level of performance
from the previous MI training part. These values can be
compared by looking at “Upper Ten Percent” in Table I and
“MI Performance” in Table II. Only subjects S04, S06, S09, and
S10 performed noticeably worse in the continuous car game.
The main difference in difficulty that might be the cause for
this decreased performance is the need for maintaining MI for
the longer time necessary in order to collect all the coins. For
some subjects this difficulty was also reflected in low “Median
Accuracy” values in Table I.
All reactions to positive and negative events (coins and barriers) were analyzed in terms of shape and detectability. The used
method was based on the analysis of SEs, the SE method. As expected, the most pronounced ErrPs were generated by subjects
with a low error rate, except for S03 who did not generate distinct
ErrPs even though the error rate was as low as 15.2 %. When
considered in total the characteristic waveforms of the ErrP

KREILINGER et al.: SINGLE VERSUS MULTIPLE EVENTS ERROR POTENTIAL DETECTION IN A BCI-CONTROLLED CAR GAME

were not as pronounced as hoped for. The measured ErrPs were
different to the interaction ErrPs described in [14] (a negative
peak followed by a positive and another negative peak). However, there was an error-related negativity about 400–500 ms
after objects were picked up, as well as a positive peak around
200 ms at channels Fz and Cz, as shown in Fig. 6. Corresponding
SE_Acc_CVs were only slightly above 60 %. There are three
causes that might explain the indistinct manifestation and low
classification rate of recorded ErrPs. First, subjects were able
to see where the car was moving, and therefore, were not exceptionally surprised when colliding with barriers. Second, the
time between objects on the street was constant as there was always exactly 1 s between objects. Therefore, the surprise could
have been further reduced. These two issues might be mitigated
by designing a paradigm in which the discrete feedback events
are not as easily predictable. A possible solution could be to
deliver a discrete feedback, which depends on the amplitude of
the CO: the time between consecutive discrete feedback events
could be decreased when the amplitude of the CO increases
and vice versa. Third, subjects could have been distracted by
maintaining control of the car with MI and by the multitude
of visual and acoustic stimuli presented during the game. This
theory is backed by a reported negative correlation of workload
and amplitude of event-related potentials [32].
We were interested to see if the added acoustic feedback
could make discrete events more pronounced. Although, on a
descriptive level, “Sound” modality resulted on average in a
slightly higher SE_Acc_CV than “NoSound,” the difference
did not reach statistical significance. As visual feedback is the
most important part of the car game, this outcome is not surprising. Nevertheless, “Sound” modality was chosen as the only
modality used in experiments performed on day 2.
C. Simulating the Effect of ErrP Detection based on MEs
Offline
The offline simulation expanded the analysis performed in
Section II-B2 based on data collected during the car game on
day 1. Simulations were carried out for “Sound” and “NoSound”
separately and with all the data in the “Combined” modality. The
main goal of the simulation was to show the benefits of the new
ME method compared to the SE method. In the simulation,
each single run was classified with the classifiers calculated
from data of the other runs. Classification was carried out with
both methods: SE and ME. SE_Acc describes the detection
rates of correct and erroneous SEs, while ME_Acc describes the
percentage of correctly determined original targets of MI trials.
ME_Acc can, therefore, be compared to the detection rates of
SEs, as they are both determined by ErrP classifiers. ME_Acc
can also be compared to the MI performance, MI_Acc, as both
determine how well MI targets were able to be identified.
All relevant information is demonstrated in Table III. Here,
the most important outcome is the difference between the values in columns “SE_Acc” and “ME_Acc.” Although necessarily
describing detection rates on two different layers (SEs versus
whole MI trials determined via MEs), the comparison strongly
suggests that even with low SE detection rates, ErrP detection

527

can still be useful. With the new ME method, a series of SEs
can be combined to determine whether a sequence of events is
correct or erroneous. The columns “MI_Acc” mainly serve as
reference points to compare the MI performances to the detection rates of original targets of MI trials with the ME method.
ANOVA results showed that these two measures were not different. In some cases, the determinations based on the ME method
were even higher than the MI performances. This means that
these subjects would have reached a higher score, if, after each
MI trial, the just achieved score had been discarded and replaced
by the determination found by the ME method. By this means,
the score would always either increase by +4 or decrease by −4
for correct or false determinations, respectively.
D. Online Car Game Without ErrP Detection 2
The second instance of the car game without ErrP detection
on day 2 with the “Sound” modality yielded slightly different
results compared to the first instance. The “SE_Acc_CV” values
in Table IV can be compared to the offline simulation results in
Table III, column “Sound/SE_Acc.” The SE_Acc_CV decreased
for subjects S01, S02, and S07 and increased for S05. Still,
these SE detection rates were assumed to be high enough for
the following online application with the ME method, given
the increase from SE_Acc to ME_Acc, which was found in the
simulation. The MI performance remained on a very high level
for subjects S05 and S07 but decreased noticeably for S01 and
S02. S01’s MI performance decreased below the initial inclusion
criterion of 70 %. However, the subsequent experiment with
online ErrP detection was carried out within the same session
on day 2, thereby preventing S01 from being excluded.
E. Online Car Game With ErrP Detection
Finally, the new ME method was used to detect ErrPs online
in the car game. MI classifiers from the MI training performed
on day 1 (see Section II-A) were used to control the car. ErrP
classifiers were recalculated directly before starting the experiment, based on data collected in the repeated car game without
ErrP detection; see Section II-D. The reason for choosing to update only the ErrP classifiers was based on the additional time
needed to recalibrate MI classifiers. Moreover, for the study
design optimized MI control was not of importance and ERD
patterns used for MI classification were shown to be relatively
stable over time [33].
The results in Table V summarize the effects of the ErrP
detection based on the ME method. As expected, a higher accuracy was bought with more time needed to complete the 20
MI trials of each run. An MI trial was only counted if it was not
determined to be erroneous. Of course, the MI performance of
the individual subject and the performance of the ErrP detection
classifier were both accountable for how much time was really
needed for completion: if a subject committed more errors, more
MI trials had to be discarded and repeated; if the ErrP detection resulted in many FP detections, many MI trials had to be
repeated for no reason.
The scores achieved could be improved for all of the four
subjects, the two medium performers gaining the greatest

528

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 3, MARCH 2016

benefits. Yet, even the two high performers could still increase
their scores by about 4 %, although there was not much room
for improvement. The maximum score was 480 points, which
would have required picking up every single coin on the road,
and the two high performers already scored about 380 points.
A very positive outcome was the low number of FPs, which
when they happened, were especially frustrating for the subjects because correct MI trials had to be repeated. For all subjects but S01, the ME_Acc_Online was similarly higher than
the SE_Acc_CV as already shown in the offline simulation with
SE_Acc and ME_Acc. A possible explanation for why S01’s
ME_Acc_Online was not as good could be the MI performance,
which was also lower on day 2 than on day 1.
V. CONCLUSION
We were able to demonstrate a feasible new ErrP detection
method based on MEs: the ME method. This method was specifically designed to work in continuous BCI-controlled applications. Detection rates of ongoing states, in this case, MI trials,
were compared to the SE detection rates achieved with the standard SE method. For all subjects, the combination of MEs lead
to better results than the detection of SEs.
The functionality of the ME method was also tested in an
online experiment. Here, all of the subjects were able to increase
their score in a car game with a tradeoff of a longer time needed
caused by repeating MI trials.
The experiments showed that the incorporation of error detection is possible in continuous applications even with low SE ErrP
detection rates. As long as there is a way to generate discrete
events during continuous control, ErrP detection can basically
be included in any kind of feedback. Possible examples for the
future include a BCI-controlled neuroprosthesis that gives discrete information about the current movement in certain short
intervals. If the direction is not intentional for a time, the ErrPs
accumulated by the discrete events could be used as a safety
mechanism to stop the movement or to alter its direction.
With this new technique of combining MEs for error detection, otherwise unused applications might regain interest if their
performance can be improved to permit reasonable functionality.
ACKNOWLEDGMENT
We thank University of Glasgow for providing the car game.
REFERENCES
[1] J. J. Vidal, “Toward direct brain-computer communication,” Annu. Rev.
Biophys. Bioeng., vol. 2, pp. 157–180, 1973.
[2] N. Birbaumer et al., “A spelling device for the paralysed,” Nature,
vol. 398, pp. 297–298, 1999.
[3] V. Kaiser et al., “Long-term BCI training for grasp restoration in a patient diagnosed with cervical spinal cord injury,” in Proc. 5th Int. BrainComput. Interface Conf., Graz, Austria, 2011, pp. 112–115.
[4] G. R. Müller-Putz et al., “EEG-based neuroprosthesis control: A step
towards clinical practice,” Neurosci. Lett., vol. 382, pp. 169–174, 2005.
[5] G. Pfurtscheller et al., “Brain oscillations control hand orthosis in a
tetraplegic,” Neurosci. Lett., vol. 292, pp. 211–214, 2000.
[6] G. Pfurtscheller et al., “‘Thought’-control of functional electrical stimulation to restore hand grasp in a patient with tetraplegia,” Neurosci. Lett.,
vol. 351, pp. 33–36, 2003.

[7] B. Blankertz et al., “The Berlin brain-computer interface: EEG-based
communication without subject training,” IEEE Trans. Neural Syst. Rehabil. Eng., vol. 14, no. 2, pp. 147–152, Jun. 2006.
[8] C. Vidaurre et al., “Co-adaptive calibration to improve BCI efficiency,”
J. Neural Eng., vol. 8, pp. 025009-1–025009-8, 2011.
[9] M. Falkenstein et al., “ERP components on reaction errors and their
functional significance: A tutorial,” Biol. Psychol., vol. 51, pp. 87–107,
2000.
[10] R. Chavarriaga et al., “Errare machinale est: The use of error-related
potentials in brain-machine interfaces,” Front. Neurosci., vol. 8, art. no.
208 (13 pages), 2014.
[11] H. T. V. Schie et al., “Modulation of activity in medial frontal and motor
cortices during error observation,” Nature Neurosci., vol. 7, pp. 549–554,
2004.
[12] W. H. R. Miltner et al., “Event-related brain potentials following incorrect
feedback in a time-estimation task: Evidence for a ‘generic’ neural system
for error-detection,” J. Cogn. Neurosci., vol. 9, pp. 788–798, 1997.
[13] W. J. Gehring et al., “The error-related negativity: An event-related brain
potential accompanying errors,” Psychophysiology, vol. 27, p. S34, 1990.
[14] P. W. Ferrez and J. del R. Millán, “Error-related EEG potentials generated
during simulated brain-computer interaction,” IEEE Trans. Biomed. Eng.,
vol. 55, no. 3, pp. 923–929, Mar. 2008.
[15] D. H. Mathalon et al., “Anatomy of an error: ERP and fMRI,” Biol.
Psychol., vol. 64, no. 1–2, pp. 119–141, 2003.
[16] B. Dal Seno et al., “Online detection of P300 and error potentials in a BCI
speller,” Comput. Intell. Neurosci., vol. 2010, art. no. 307254 (5 pages),
2010.
[17] F. Galan et al., “A brain-actuated wheelchair: Asynchronous and noninvasive brain-computer interfaces for continuous control of robots,” Clin.
Neurophysiol., vol. 119, pp. 2159–2169, 2008.
[18] A. Kreilinger et al., “BCI and FES training of a spinal cord injured enduser to control a neuroprosthesis,” in Proc. Biomed. Tech. Conf., Graz,
Austria, 2013, pp. 1007–1008.
[19] B. van de Laar et al., “Experiencing BCI control in a popular computer
game,” IEEE Trans. Comput. Intell. AI Games, vol. 5, no. 2, pp. 176–184,
Jun. 2013.
[20] A. J. Doud et al., “Continuous three-dimensional control of a virtual
helicopter using a motor imagery based brain-computer interface,” PLoS
ONE, vol. 6, pp. e26322-1–e26322-10, 2011.
[21] T. Milekovic et al., “Detection of error related neuronal responses
recorded by electrocorticography in humans during continuous movements,” PLoS ONE, vol. 8, pp. e55235-1–e55235-20, 2013.
[22] M. Spüler and C. Niethammer, “Error-related potentials during continuous
feedback: Using EEG to detect errors of different type and severity,” Front.
Hum. Neurosci., vol. 9, art. no. 155 (10 pages), 2015.
[23] A. Kreilinger et al., “Error potential detection during continuous movement of an artificial arm controlled by brain-computer interface,” Med.
Biol. Eng. Comput., vol. 50, pp. 223–230, 2012.
[24] G. Pfurtscheller and C. Neuper, “Motor imagery and direct brain-computer
communication,” Proc. IEEE, vol. 89, no. 7, pp. 1123–1134, Jul. 2001.
[25] B. Graimann et al., “Visualization of significant ERD/ERS patterns
in multichannel EEG and ECoG data,” Clin. Neurophysiol., vol. 113,
pp. 43–47, 2002.
[26] G. Pfurtscheller and F. H. Lopes da Silva, “Event-related EEG/MEG synchronization and desynchronization: Basic principles,” Clin. Neurophysiol., vol. 110, pp. 1842–1857, 1999.
[27] P. W. Ferrez, “Error-related EEG potentials in brain-computer interfaces,”
Ph.D. dissertation, Ecole Polytechnique Federale de Lausanne, Lausanne,
Switzerland, 2007.
[28] A. Kreilinger et al., “Detection of error potentials during a car-game
with combined continuous and discrete feedback,” in Proc. 5th Int. BrainComput. Interface Conf., 2011, pp. 204–207.
[29] A. Kübler et al., “Brain-computer communication: Self-regulation of slow
cortical potentials for verbal communication,” Arch. Phys. Med. Rehabil.,
vol. 82, pp. 1533–1539, 2001.
[30] J. Kronegg et al., “Analysis of bit-rate definitions for brain-computer
interfaces,” presented at the Int. Conf. Human-computer Interaction, Las
Vegas, NV, USA, 2005.
[31] G. R. Müller-Putz et al., “Better than random? A closer look on BCI
results,” Int. J. Bioelectromagn., vol. 10, pp. 52–55, 2008.
[32] B. Z. Allison and J. Polich, “Workload assessment of computer gaming
using a single-stimulus event-related potential paradigm,” Biol. Psychol.,
vol. 77, no. 3, pp. 277–283, 2008.
[33] E. V. Friedrich et al., “Long-term evaluation of a 4-class imagery-based
brain-computer interface,” Clin. Neurophysiol., vol. 124, no. 5, pp. 916–
927, 2013.

KREILINGER et al.: SINGLE VERSUS MULTIPLE EVENTS ERROR POTENTIAL DETECTION IN A BCI-CONTROLLED CAR GAME

Alex Kreilinger received the M.Sc. degree in electrical engineering with focus on biomedical engineering
from the Graz University of Technology, Graz, Austria, in 2008.
From 2008–2013, he worked as a Researcher at
the Institute for Knowledge Discovery, Graz University of Technology. He has been working at the Artificial Vision Center, Medical University of Graz, Graz,
since 2013 and is currently writing his dissertation in
the field of hybrid BCIs, neuroprostheses, and error
potentials at the Graz University of Technology. His
research interests include BCI technology and assistive technology in general.
His work involved close collaborations with spinal cord injured patients who
can be assisted by BCIs and neuroprostheses, as well as blind people who benefit
from retinal implants.

Hannah Hiebel received the M.Sc. degree in psychology with focus on neuropsychology from the
University of Graz, Graz, Austria, in 2013.
From 2009-2013, she worked as a Research Assistant at the Institute for Knowledge Discovery, Graz
University of Technology, Graz. After her graduation, she was with the Department of Psychology
(neuropsychology), University of Graz, as a Research
Associate until 2014.
Subsequently, she worked at a rehabilitation clinic
specialized in the treatment of patients with neurological disorders and received a postgraduate diploma as a Clinical and Health
Psychologist. Since March 2015 she has been working as a Researcher at the Institute for Knowledge Discovery, Graz University of Technology. Her research
interests include BCI research, clinical BCI applications, EEG-controlled neuroprostheses, stroke rehabilitation, the human motor and somatosensory system,
and the functional role of dynamic brain oscillations.

529

Gernot R. Müller-Putz (M’13) received the M.Sc.
and the Ph.D. degrees from the Graz University of
Technology (TU Graz), Graz, Austria, in 2000 and
2004, respectively, and the “venia docendi” for medical informatics from the faculty of computer science,
TU Graz, 2008.
He is the Head of the Institute for Knowledge Discovery, TU Graz, and its associated BCI Lab. Since
October 2014, he has been a full Professor for semantic data analysis. He has gained extensive experience
in the field of biosignal analysis, brain–computer interface (BCI) research, EEG-based neuroprosthesis control, hybrid BCI systems, the human somatosensory system, and assistive technology over the past
15 years. He has also managed several national and international projects and is
currently partner in 2 EU FP7 projects (BackHome, ABC) and the Coordinator
of BNCI Horizon 2020. Recently, he received a Horizon 2020 project, MoreGrasp, which will be coordinated by him. Furthermore, he organized and hosted
six international BCI Conferences over the last 13 years in Graz, the last one in
Sept. 2014 in Graz.
Dr. Müller-Putz is a Steering Board Member for the International BCI Meeting, which takes place in the US usually every three years (last time in 2013).
He is the Review Editor of Frontiers in Neuroprosthetics, and since 2014, he
has been an Associate Editor of the Brain-Computer Interface Journal and of
the IEEE TRANSACTIONS OF BIOMEDICAL ENGINEERING.

