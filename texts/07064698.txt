2158

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 9, SEPTEMBER 2015

Hierarchical Spectral Consensus Clustering for
Group Analysis of Functional Brain Networks
Alp Ozdemir, Marcos Bolaños, Edward Bernat, and Selin Aviyente∗

Abstract—A central question in cognitive neuroscience is how
cognitive functions depend on the integration of specialized widely
distributed brain regions. In recent years, graph theoretical
methods have been used to characterize the structure of the brain
functional connectivity. In order to understand the organization
of functional connectivity networks, it is important to determine
the community structure underlying these complex networks.
Moreover, the study of brain functional networks is confounded
by the fact that most neurophysiological studies consists of data
collected from multiple subjects; thus, it is important to identify
communities representative of all subjects. Typically, this problem
is addressed by averaging the data across subjects which omits the
variability across subjects or using voting methods, which requires
a priori knowledge of cluster labels. In this paper, we propose a
hierarchical consensus spectral clustering approach to address
these problems. Furthermore, new information-theoretic criteria
are introduced for selecting the optimal community structure.
The proposed framework is applied to electroencephalogram
data collected during a study of error-related negativity to better
understand the community structure of functional networks
involved in the cognitive control.
Index Terms—Consensus clustering, electroencephalogram
(EEG), Fiedler vector, functional connectivity, spectral clustering.

I. INTRODUCTION
UNCTIONAL connectivity is defined as the statistical
dependence between spatially remote neurophysiological
events [1] and is the key to understanding how the coordinated
and integrated activity of the human brain takes place [2]. In
recent years, many studies have suggested synchronization of
neuronal oscillations as one plausible mechanism in the interaction of spatially distributed neural populations [3]. Moreover,
it has been shown that synchronization between different brain
regions plays an important role in different cognitive and emotional processes [4], [5], as well as in various neurological and
psychiatric disorders [6]–[9]. Synchronization refers to inter-

F

Manuscript received October 2, 2014; revised March 10, 2015; accepted
March 10, 2015. Date of publication March 20, 2015; date of current version August 18, 2015. This work was in part supported by the National Science Foundation under Grants No. CCF-0728984, CAREER CCF-0746971,
and CCF-1218377. Asterisk indicates corresponding author.
A. Ozdemir is with the Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI 48824 USA (email:
ozdemira@msu.edu)
M. Bolaños is with CNA Corporation (e-mail: bolanosm@cna.org).
E. Bernat is with the Department of Psychology, University of Maryland,
1147 Biology/Psychology Building College Park, MD 20742. (email: ebernat@
umd.edu)
∗ S. Aviyente is with the Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI 48824 USA (e-mail:
aviyente@egr.msu.edu).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2015.2415733

dependencies among activities of different neuronal assemblies
and requires the need to focus on the temporal dynamics of neural networks in the millisecond range. Therefore, neuroimaging
techniques with high temporal resolution, such as electroencephalogram (EEG) [6], [10] and magnetoencephalogram [11],
are the most appropriate tools.
Although phase synchrony is successful at quantifying pairwise interactions, it cannot completely describe the complex
relationship between function and organization of the brain.
Recently, research in the area of complex networks, in particular graph theoretic methods, has been used to characterize the
relationship between the topology and the function of the brain
[12]–[15]. The bivariate relationships between neuronal populations are represented as graphs, where the nodes correspond
to the individual sites, and the edges to the strength of the interaction quantified by functional connectivity measures. The
conventional approach to functional connectivity graph analysis extracts topological metrics either on the entire graph, i.e.,
global metrics, or at each node, i.e., local metrics. At the large
topological scale, the small-world organization, whereby both
integration (relatively high global efficiency/low path length)
and segregation (relatively high local efficiency/clustering coefficient) of information between brain regions are supported,
has been investigated thoroughly [16], [17]. The small-world
model has also been shown to be significantly altered in various brain disorders and pathologies, such as schizophrenia [18],
autism [19], spinal cord injuries [20], and Alzheimers disease
[21]. At the local scale, the centrality or the degree of individual
nodes can be computed and used to characterize the brain graph
reorganization during different tasks and events. Although the
global and local indices summarize the key aspects of the connectivity networks, they do not provide any information about
the intermediate scale of network organization, which is more
accurately described by the community structure of the network [22], [23]. A community structure in a graph is defined
as a densely connected set of nodes with sparse connections
between communities in the network. It is hypothesized that
the community structure of complex biological networks is indicative of robustness [22] and contributes to functionality [24]
by compartmentalizing specific functions within certain cortical
regions without perturbing the rest of the network [25]. Intracluster associations are thought to describe the segregation of
information processing, while the intercluster associations testify to the integration of information processing across distant
brain regions [26]–[28].
Identification of communities in the functional connectivity
graphs has been originally addressed using methods like
principle component analysis [29] and independent component
analysis [30], which put nonphysiological constraints in the

0018-9294 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

OZDEMIR et al.: HIERARCHICAL SPECTRAL CONSENSUS CLUSTERING FOR GROUP ANALYSIS OF FUNCTIONAL BRAIN NETWORKS

obtained components, such as orthogonality and independence.
Recently, methods from spectral graph clustering have been
used to detect communities [31], [32] by mapping the functional connections to a multidimensional subspace defined
by a set of eigenvectors. However, these methods require a
priori knowledge about the number of clusters and do not
reveal a hierarchical decomposition of the network. Meunier
et al. [33]–[35] argue that most complex networks, including
functional connectivity networks, possess a multiscale community characteristic, i.e, are hierarchically decomposable into
a finite number of modular levels. Therefore, a hierarchical
decomposition of functional connectivity graphs is a more
natural representation than conventional clustering approaches
for community detection in brain networks.
A key challenge in identifying the community structure of
brain networks is determining a common structure across multiple subjects. This study either focuses on obtaining the community structure for the average connectivity network or on analyzing each subject individually and obtaining a common community structure using consensus clustering techniques [36].
Averaging neglects the variance across subjects and can be influenced by the outliers. Consensus clustering, also known as
clustering ensembles, yields a stable and robust final clustering
that is in agreement with the individual clusterings through a
consensus function [37], [38]. Therefore, in this paper, we will
introduce a hierarchical consensus-based approach, in which the
best community structure is identified by combining information shared across multiple subjects.
In this paper, we first quantify functional connectivity using
a new time-varying measure of phase synchrony, and apply
it to multichannel EEG data to quantify pairwise synchrony.
The resulting connectivity matrices are treated as weighted
undirected graphs representing each subject. We then introduce
a new hierarchical graph partitioning method based on spectral
graph theory, in particular the Fiedler bipartitioning method
[39]. This partitioning method is combined with two novel information theoretic criteria, homogeneity and completeness, to
introduce a nongreedy consensus-based hierarchical algorithm,
the Fiedler consensus clustering algorithm (FCCA), that is
designed to reveal multiple levels of community organization
common across subjects. Next, an information-theoretic quality
measure is introduced to identify the optimal community
structure. Finally, the proposed approach is applied to EEG
data collected during a study of cognitive control in the brain
based on the error-related negativity (ERN) to test the approach
on a known biological signal.
II. BACKGROUND
A. Time-Varying Measure of Phase Synchrony
Phase synchronization within different frequency bands
across the brain has been shown to be a plausible mechanism explaining neuronal integration [3], [40]. Two commonly
used measures for quantifying time-varying phase synchrony are
Hilbert transform and complex wavelet transform [41]–[43]. It
has been observed that the two approaches are similar in their
results with the wavelet-based methods giving higher resolution

2159

phase synchrony estimates over time and frequency, especially
at the low-frequency range [41]. Although the wavelet-based
phase synchrony estimates address the issue of nonstationarity,
they suffer from the resolution tradeoff, i.e., the frequency resolution is high at low frequencies and low at high frequencies.
For this reason, there is a need for high time–frequency resolution phase distributions that can better track dynamic changes in
phase synchrony. In this study, pairwise functional connectivity
will be quantified using a recently introduced time–frequency
phase estimation method based on reduced interference Rihaczek distribution (RID-Rihaczek) [44], [45].
RID-Rihaczek is given by



C(t, ω) =

exp

−(θτ )2
σ





θτ
exp j
A(θ, τ )e−j (θ t+τ ω ) dτ dθ
2

(1)
where exp (−(θτ )2 /σ) is the Choi–Williams
kernel
used
to
fil
ter out the cross terms, A(θ, τ ) = x(u + τ2 )x∗ (u − τ2 )ej θ u du
is the ambiguity function of the signal, and exp(jθτ /2) is the
kernel corresponding to the Rihaczek distribution [46]. The
phase difference between two signals based on this complex
distribution is computed as

	
C1 (t, ω)C2∗ (t, ω)
Φ12 (t, ω) = arg
(2)
|C1 (t, ω)||C2 (t, ω)|

where C1 (t, ω) and C2 (t, ω) refer to the complex energy distributions of the two signals x1 (t) and x2 (t), respectively, and a
synchrony measure quantifying the intertrial variability of the
phase differences, phase-locking value (PLV), is defined as




N


1 




(3)
exp(jΦk12 (t, ω))

PLV(t, ω) =




N

k =1

where N is the number of trials and Φk12 (t, ω) is the timevarying phase estimate between two signals recorded at different
electrodes for the kth trial. If the phase difference varies little
across the trials, PLV is close to 1. Compared to the existing
synchrony measures, in our previous work, we have shown that
RID-Rihaczek-based phase synchrony measure is more robust to
the noise, has uniformly better time–frequency resolution with
less bias, and perform superior at detecting actual synchrony
within a group of oscillators [44].
B. Graph Theory
Recent developments in the quantitative analysis of complex
networks, based largely on the graph theory, have been rapidly
translated to studies of the brain network organization [47],
[48]. In this approach, the different regions of the brain correspond to the nodes in the network, and the pairwise functional
connectivity corresponds to the edges of the network. An undirected, connected, weighted graph G = (V, E, W) consisting
of a finite set of N nodes, V = {vi |i ∈ {1, 2, . . . , N }}, and a
set of edges E associated with each node pair, and a weighted
adjacency matrix W can be used to represent these functional
connectivity networks. For a binary graph, wij ∈ {0, 1} and for
a weighted graph, wij ∈ [0, 1]. In an undirected graph, the edge
weights are represented by a symmetric weighted adjacency

2160

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 9, SEPTEMBER 2015

matrix W = [wij ], where i, j ∈ {1, 2, . . . , N }. The sum of all

elements along the ith row of matrix W, di = N
j =1 wij is
the degree of node vi . When m graphs representing the same
network are available, their adjacency matrices are represented
as the set W = {W r }, where r ∈ {1, 2, . . . , m}.

vector generates a community structure, in which the intracluster nodal relationships are maximally “strong.” Repeating this
partitioning process to the subsequent subclusters, reveals a hierarchical configuration of the network structure.
D. Consensus Clustering

C. Spectral Clustering
A commonly used approach to identifying the community
structure within graphs is spectral clustering thanks to its simple
implementation and promising performance. Given a weighted
and undirected graph G , the spectrum of the graph is represented
by the eigenvalues and eigenvectors of the graph Laplacian
matrix L = D − W, where W is the adjacency matrix and
D is the degree matrix containing degrees of nodes along the
diagonal [49], [50]. Different versions of the Laplacian matrix,
i.e., the symmetric normalized and the random walk normalized
versions, have been used leading to different versions of the
spectral clustering algorithm. In this paper, we use the symmetric
version of the normalized Laplacian matrix defined as L =
D−1/2 (D − W)D−1/2 , which yields more robust clustering
solutions [31].
Since the normalized Laplacian matrix is a square, symmetric,
and positive semidefinite matrix, its eigenvectors and eigenvalues are described by the equation L ui = λui and the eigenvectors, {u1 , u2 , . . . , uN } are orthonormal and the eigenvalues
{λ1 , λ2 , . . . , λN } are positive and real. Spectral clustering algorithm finds the spectrum of G through the eigendecomposition
of its Laplacian matrix, and embeds the original vertices in
G to a low-dimensional spectral domain formed by the graph
spectrum. Typically, a subset of eigenvectors, {u1 , u2 , . . . , uk },
where k < N , is extracted, and an optimization technique is
iteratively applied to cluster centers within the data using algorithms, such as k-means, fuzzy k-means [51], generalized
synchronization cluster analysis [32], the Ng–Jordan–Weiss algorithm [52], or power iteration clustering (PIC) [53]. This
transformation enhances the intrinsic relationship among the
original vertices leading to improved cluster identification in
the new low dimensional space [31], [32], [49], [54].
An alternative to spectral clustering is to evaluate only one
eigenvector for the purpose of bipartitioning, i.e., identifying a
minimal cut of the graph. This eliminates the problem of searching for the optimal set of eigenvectors. According to Holzrichter
and Oliveira [55], the optimal minimal cut of a graph is defined by the eigenvector u2 , associated with the second smallest
nonzero eigenvalue λ2 of the Laplacian matrix. This eigenvector
is referred to as the Fiedler vector uF , and defines a set of two
clusters {C1 , C2 }, where

C1 , if uF (i) ≥ 0
vi ∈
(4)
C2 , if uF (i) < 0.
The Fiedler partition can be iteratively applied to each successive partition in order to achieve a clustering with k > 2. In
this paper, the partitioning of a graph using the Fiedler vector will be referred to as FiedlerPartition(G), which partitions
the nodes of graph G into two clusters, G1 and G2 such that
G1 ∪ G2 = V . Partitioning the graph according to the Fiedler

In many clustering problems, it is common to apply different
algorithms to the same data, and then use a consensus method
to combine the results [56]. In this paper, a similar framework
for obtaining a common community structure from multiple
graphs is proposed. Three popular consensus clustering methods
are consensus averaging, majority voting, and the hypergraph
partitioning algorithm (HPGA). The first approach averages m
 = [w
adjacency matrices to obtain W
ij ], where
1  (r )
w .
m r =1 ij
m

w
ij =

(5)

This approach is computationally efficient but loses the intersubject variability.
The second commonly used approach for obtaining a common community structure across multiple graphs is to identify
the community structure of each individual graph, and then combine the information across the multiple community structures
to identify a global community structure. The combination of
community structure across multiple graphs or clustering solutions has been accomplished through different functions, such
as majority voting [57], mixture-model approach [58], and disagreement minimization methods [38].
Finally, HGPA is used to extract a common clustering structure [37], [59]. HGPA treats each cluster across all base clusterings as a hyperedge within a single global graph. The algorithm
is a multilevel graph partitioning system, which partitions this
graph in three steps: 1) Compress the graph by collapsing hyperedges, 2) partition the compressed graph using a minimum
cut objective function, and 3) decompress the partitions and
repeat the process. HGPA has a computational complexity of
O(kN h), where h is the number of hyperedges. However, its
overall complexity is dependent upon the total complexity of the
clustering algorithms used to obtain the base clusterings. HGPA
has the disadvantage of generating clusters of approximately
equal sizes, even though in real networks, equally sized clusters
are unlikely.
E. Modularity
The most commonly used cluster quality measure, modularity [60], compares a community structure to the expected
community structure of a random graph such that there exists a
high number of edges within clusters and low number of edges
between clusters. Modularity for a weighted graph is defined as

	
di dj
1 
(6)
wij −
σij
Q=
2z ij
2z
such that z is the sum of all edge weights in the graph and
σij = 1, if vi and vj are in the same cluster and 0 otherwise.
Unfortunately, this definition of modularity does not always

OZDEMIR et al.: HIERARCHICAL SPECTRAL CONSENSUS CLUSTERING FOR GROUP ANALYSIS OF FUNCTIONAL BRAIN NETWORKS

result in the highest value for the true community structure
[61], and can reveal a suboptimal structure due to the simplistic
di dj
random model computed through 2z
in the modularity equation [62].
F. Cohen’s Kappa
One of the most commonly used measures to quantify the
quality of an observed cluster with respect to the true structure
is Cohen’s Kappa measure. Cohen’s Kappa [63] is a measure of
agreement between two observers and is defined as
κ=

po − p e
1 − pe

(7)

where po is the probability of observed agreement and pe is the
probability of expected agreement.
Cohen’s Kappa measure can also be used to quantify the
agreement between the ground truth clustering map (A) and the
clustering map (B) obtained from the clustering algorithm as in
Table I. Ai,j is equal to 1 if nodes i and j are assigned to the
same cluster and 0 otherwise. Similarly, Bi,j is equal to 1 if
nodes i and j are assigned to the same cluster and 0 otherwise.
In Table I, a is the number of node pairs, which are correctly
identified as being in the same cluster, b is the number of node
pairs, which are falsely identified as being in the same cluster, c
is the number of node pairs, which are falsely identified as not
being in the same cluster, and d is the number of node pairs,
which are correctly identified as not being in the same cluster.
Based on this observation, p0 and pe can be computed as
po =

a+d
a+b+c+d

f 1 × f 2 + g1 × g2
pe =
.
(a + b + c + d)2

(8)

Standard error of Kappa statistic is also known and is defined
as [64]

po (1 − po )
SE(κ) =
.
(9)
(a + b + c + d)(1 − pe )2
III. INFORMATION THEORETIC CLUSTER QUALITY MEASURE
One problem with hierarchical clustering algorithms is how
to determine the optimal number of clusters. In this section, we
introduce a new measure to quantify the quality of the resulting clusters in the absence of “ground truth” information, i.e.,
knowledge about the actual cluster structure.
A. Inter- and Intraedge Distribution
By the definition of a cluster, the pairwise connections within
a cluster must be stronger than the intercluster connections. In
this paper, we propose measures that evaluate the quality of a
particular clustering structure based on the distribution of the
inter- and intraedge distributions across m graphs. These distributions will be defined similar to probability mass functions
(pmfs). Prior to defining the pmfs of intracluster and intercluster
edges, a function that maps the continuous edge values to a dis(r )
(r )
(r )
crete alphabet is defined as f : Wi → Si , where Wi =

2161

(r )

{wij ∈ [0, 1]} refers to the ith row of the rth adjacency matrix,
(r )

(r )

Si = {sij ∈ {1, 2, . . . , N }}, and r ∈ {1, 2, . . . , m}. The elements of each row of the connectivity matrix across subjects
are mapped to discrete integer values between 1 and N to eliminate the variation of edge strengths across subjects and extract
only relational information about the pairwise edge strengths.
We propose to use the rank function to do this mapping such
that the node pair with the largest edge weight is assigned a 1
and the weakest node pair is assigned N .
When a particular cluster set C = {c1 , c2 , . . . , ck } is identified, the pmf of intracluster ranks for a particular cluster ct is
defined as


Fcintra
(β)
intra
t
Pc t (β) = N
(10)
intra
β =1 Fc t (β)
where
Fcintra
(β) =
t

N
m 


δ(srij , β) | vi , vj ∈ ct

(11)

r =1 i,j

t ∈ {1, 2, . . . , k}, β ∈ {1, 2, . . . , N }, and

1, if x = y
δ(x, y) =
0, otherwise.
This function computes the frequency with which node pairs
with varying strengths of connectivity are assigned to the same
community.
Similarly, the pmf of intercluster ranks for cluster ct is defined
as


Fcinter
(β)
inter
t
Pc t (β) = N
(12)
inter
β =1 Fc t (β)
where
Fcinter
(β) =
t

N
m 


δ(srij , β) | vi ∈ ct ; vj ∈
/ ct .

(13)

r =1 i,j

This function computes the frequency with which node pairs
with varying strengths of connectivity are assigned to different
communities.
B. Homogeneity and Completeness
The next step is to quantify homogeneity and completeness,
two principal characteristics which determine the quality of clustering. A homogeneous cluster contains only data points which
belong to the same class, while a complete cluster contains all
possible data points within the sample space (see Fig. 1).
Similar measures, such as F-measure [65] and V-measure
[66], have been used in the literature to quantify the quality of
a cluster. Both measures, however, require a priori knowledge
of class labels. In most cases, this “ground truth” is unknown
and, therefore, alternative measures of the cluster accuracy are
needed. In this paper, we propose new homogeneity and completeness measures, which depend on the edges’ strength, and
we quantify the quality of a clustering structure using the harmonic mean of the homogeneity and completeness measures
similar to V-measure.

2162

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 9, SEPTEMBER 2015

IV. FIEDLER CONSENSUS CLUSTERING APPROACH
Since the literature has consistently demonstrated that the
Fiedler vector is highly effective in partitioning graphs [68],
[69], in this paper, we use the Fiedler vector for performing consensus clustering across multiple weighted graphs. The original
connectivity matrices are bipartitioned into two clusters using
the Fiedler partitioning method. This results in a cluster matrix
for the rth subject T r such that

1, if nodes vi , vj are in the same cluster
r
T (i, j) =
0, otherwise

Fig. 1. Illustration of variations in homogeneity and completeness in a group
of objects, where the true number of communities is 3. (a) High homogeneity
and low completeness. (b) High completeness and low homogeneity. (c) High
homogeneity and completeness.

In this paper, we use the observation that homogeneity is inversely related to the variance of edge ranks within a cluster.
If a particular cluster is homogeneous, then we would expect
the pairwise connection strengths among the members of that
cluster to be close to each other; thus, implying the ranks of
the weights to have small variance. We propose to quantify this
variation through a measure of normalized entropy such that the
lowest homogeneity score is obtained for a cluster containing
a uniform distribution of ranks or large variation among the
edge weights, and the maximum homogeneity score is obtained
for a cluster containing only one rank. Therefore, a normalized
entropy measure of the cluster’s intracluster rank distribution
would be indicative of homogeneity. However, as cluster size
gets smaller the intracluster rank distribution will naturally become more concentrated thus increasing the homogeneity. To
account for this, we introduce a normalization term in the def
H (P intra )
,
inition of homogeneity as follows: Hc t = αC t 1 − log2cNt
where αC t = |CNt | , and this measure is always between 0 and 1.
Similarly, we define a metric using relative entropy between
the intercluster rank and intracluster rank distributions to quantify completeness. Rank distributions for interedges and intraedges are expected to be different from each other to maximize completeness. The similarity between two distributions
is commonly quantified using divergence measures. In this paper, we propose to use the Jensen–Shannon divergence measure [67] since it is symmetric and bounded. With respect to
completeness, a divergence measure approaching 1 is synonymous with increased completeness. Completeness of a cluster is,
, Pcinter
), where JS (p, q) =
therefore,
defined as Cc t = JS(Pcintra
t
t


p(i)
q(i)
1
i p(i)log2 0.5(p(i)+q(i)) +
i q(i)log2 0.5(p(i)+q(i)) . Av2

erage completeness, Ĉ = k1 kt=1 Cc t and average homogeneity

Ĥ = k1 kt=1 Hc t are computed across all clusters.
Similar to the balanced F-score, our quality measure U for
the final clustering structure is defined as the harmonic mean of
the average completeness and average homogeneity as follows:
U=

2
Ĉ−1

+ Ĥ−1

.

(14)

and r = {1, 2, . . . , m}. In order to find the common community
structure across multiple graphs, we introduce a cooccurence

T r (i,j )
and P (i, j) ∈ [0, 1].
matrix P, where P (i, j) = m
r =1
m
P (i, j) is the probability that a pair of nodes are members of
the same cluster across multiple graphs. The adjacency matrix
reflects the strength of a direct relationship between a node pair,
whereas P reflects the likeliness that a pair of nodes are in the
same cluster across all subjects.
The Laplacian matrix of P is computed and the Fiedler vector
is found to form a bipartition of P into a community structure
composed of clusters c1 and c−1 . Since P represents the probability that a node pair should be clustered together, the Fiedler
partition of P represents the community structure common to
all graphs. The initial partition set, C = {c1 , c−1 }, contains two
clusters but if k > 2 is desired, the process can be repeated by
selecting a cluster in C to partition. In this case, c1 or c−1 is
selected based on the ζ values of each cluster. At each step of
partitioning, weighted sum of homogeneity and completeness
are computed to select the cluster to be partitioned at the next
level
ζC t = ĈC t γ + ĤC t (1 − γ)

(15)

where γ ∈ [0, 1]. For each cluster, a set of ζ values are created
by choosing a range of γ ∈ [0, 1]. The cluster whose ζ values
are lower than others’ for a majority of γ values is selected for
partitioning.
Next, submatrices are extracted from the original connectivity matrices such that they only contain the nodes of the chosen
cluster. These submatrices are used to derive the new sub cooccurence matrix Py , where y = 1 if cluster c1 was selected and
y = −1, if cluster c−1 was selected. The Fiedler partition will
result in two new clusters cy1 and cy−1 . The final cluster set is
C = {c−y , cy1 , cy−1 }, which is a concatenation of the two new
clusters with the original cluster that was not chosen for bipartitioning. Algorithm 1 describes this process for obtaining
community structures for a given number of clusters.
V. RESULTS
In this section, we will evaluate the effectiveness of the proposed FCCA for revealing the hierarchical community structure
across multiple graphs. The optimal community structure will
be identified by maximizing the quality measure U , which is
the harmonic mean of the homogeneity Ĥ and the completeness
scores Ĉ as defined in Section-III.

OZDEMIR et al.: HIERARCHICAL SPECTRAL CONSENSUS CLUSTERING FOR GROUP ANALYSIS OF FUNCTIONAL BRAIN NETWORKS

Algorithm 1: FCCA
1: Input: m N × N dimensional graphs,
G = {G1 , G2 , . . . , Gm } with vertices
r
: vi vj ,
V = {v1 , v2 , . . . , vN } and edges E r = {wij
∈ V } such that Gr = (V, E r ) and r = {1, 2, . . . , m}.
2: Input: Number of clusters, k.
3: Output: k clusters C = {c1 , c2 , . . . , ck }, where cj ⊂ V .
4: C = ∅
5: for t = 2 to k do
6:
P 	 = 0|V |×|V |
7:
for r = 1 to m do
8:
submatrix Ĝr ⊂ Gr |Ĝr = (V, E r )
9:
(V1 , V2 ) = SubRoutine(Fiedler Partition(Ĝr ))
10:
P 	 (i, j) = P 	 (i, j) + T r (i, j) where

r

T (i, j) =
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:

1,

if nodes vi , vj ∈ V1 or vi , vj ∈ V2

0,

otherwise

end for
	
P = Pm
(V1 , V2 ) = SubRoutine(Fiedler Partition(P ))
C = C ∪ {V1 , V2 }.
if t 
= k then
score = 0t×1
for γ = 0 : 0.1 : 1 do
Λ = [ζ1 (γ)|ζ2 (γ)|...|ζt (γ)]
j = minq {Λ(q)} and q ∈ {1, 2, . . . , t}
score(j) = score(j) + 1
end for
V = ci |i = minq {score(q)} and
q ∈ {1, 2, . . . , t}
r
: vi , vj ∈ V }
E r = {wij
C = C\{ci }
end if
end for

Algorithm 2: Fiedler Partition
1: Input: graph G = (V, E).
2: Output: Vertex sets V1 and V2 .
3: Compute Normalized Laplacian Matrix, L, of G.
4: Compute |V | eigenvectors, u, and eigenvalues, λ, of L.
5: Order eigenvalues in ascending order:
λ1 ≤ λ2 ≤ ... ≤ λ|V | .
6: uF = ui where i = minq {λq }|λq 
= 0.
7: Sort elements of uF and find uF (i) which has
maximum gap with ensuing element
8: for j = 1 to |V | do
9:

V1 , if uF (j) ≤ uF (i)
vj ∈
V2 , if uF (j) > uF (i)
10: end for

2163

Fig. 2. Average of quality metric (U ) and modularity (Q) measure corresponding to defined clustering structures in a three cluster network with respect
to the ratio of the number of nodes in cluster 1 to the number of nodes in the
rest of the network over 100 trials. (a) Quality. (b) Modularity.

First, we will compare the traditional modularity measure
versus the proposed quality measure in determining the optimal number of clusters for the FCCA. Then, we will compare
the FCCA to other consensus clustering approaches including
averaging, voting, and HGPA for different types of network
structure: varying intercluster strengths, outliers within a group,
and overlapping clusters. Finally, the proposed clustering algorithm and the quality measure will be used to identify the
community structure, which best describes the multivariate relationships across multiple subjects from connectivity graphs
obtained from EEG data. For the evaluation of computational
complexity, we note that all data analysis has been performed
on a 2.4-GHz Intel Core i5 processor running Windows 7.
A. Quality Versus Modularity
Simulated networks consisting of 63 nodes and composed of
three equal sized clusters were generated 100 times to evaluate the performance of the proposed quality measure, U , against
modularity metric for determining the true community structure.
The weights of the intracluster edges were selected from a truncated Gaussian distribution in [0, 1] with a mean of μintra = 0.6
and a standard deviation of σintra = 0.1. Similarly, intercluster
edge weights were selected from a truncated Gaussian distribution with a mean of μinter = 0.1 and a standard deviation of
σinter = 0.2.
To compare the robustness of the quality metric with the modularity metric for identifying unequal size clusters, the number
of nodes in the first cluster (c1 ) was gradually increased from 21
to 49, while the sizes of the other two clusters (c21 and c22 ) were
decreased from 21 to 7. In order to evaluate the performance of
the proposed quality measure and the standard modularity metric, all four possible partitionings of a three cluster network are
considered, i.e., the three two-cluster structures (c1 and c21 as
one single cluster versus cluster c12 , c1 and c22 as one single
cluster versus cluster c21 , and c21 and c22 as one single cluster versus c1 ) and the true three cluster structure. As seen in
Fig. 2, the proposed quality metric always has its highest value
for the true community structure; thus, successfully identifying
the correct community structure for each test condition, while
modularity tends to merge small clusters.

2164

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 9, SEPTEMBER 2015

TABLE I
AGREEMENT TABLE FOR THE OBSERVERS USED FOR COMPUTING
THE KAPPA SCORE

TABLE III
AVERAGE COHEN’S KAPPA AND AVERAGE STANDARD ERROR FOR IDENTIFYING
COMMUNITIES IN A GROUP OF NETWORKS WITH OUTLIERS
Method

FCCA

TABLE II
AVERAGE COHEN’S KAPPA AND AVERAGE STANDARD ERROR FOR IDENTIFYING
A COMMUNITY STRUCTURE IN SIMULATED FOUR-COMMUNITY NETWORKS
WITH VARYING INTERCLUSTER STRENGTH

FCCA

κ

Ave.

time
(sec.)
κ

Voting

time
(sec.)
κ

HGPA

time
(sec.)
κ
time
(sec.)

0.4

0.5

0.6

0.7

0.9992
±1.4352 × 10 −5
1.1106
±0.1415
1
±0
0.1763
±0.0219
0.9968
±1.9523 × 10 −4
9.1640
±1.2854
0.8385
±0.0092
1.6020
±0.3354

1
±0
1.2224
±0.2651
1
±0
0.1991
±0.0299
1
±0
11.1266
±1.0163
0. 8576
±0.0080
1.2207
±0.1861

1
±0
1.2709
±0.1516
1
±0
0.2131
±0.0223
0.9905
±0.0011
14.3203
±2.1477
0.9276
±0.0050
1.2711
±0.1441

0.9690
±0.0040
1.4901
±0.4153
0.9921
±0.0014
0.2100
±0.0347
0.8938
±0.0073
41.6633
±4.2908
0.8101
±0.0107
2.0018
±0.4222

B. Evaluation of FCCA for Varying Intercluster Strength
Hundred simulated networks consisting of 64 nodes and composed of four communities of equal size were generated 100
times to evaluate the performance of FCCA for varying intercluster edge strength, i.e., varying the noise levels in the community structure. The weights of the intracluster edges were
selected from a truncated Gaussian distribution in [0, 1] with a
mean of μintra = 0.8 and a standard deviation of σintra = 0.1. The
weights of the intercluster edges were selected from a truncated
Gaussian distribution in with a mean of μinter and a standard deviation of σinter = 0.2. In order to evaluate the algorithms under
different intercluster connectivity strengths, μinter was increased
gradually from 0.4 to 0.7.
Using the proposed Fiedler consensus algorithm, the averaging method, the voting method, and HGPA, the networks were
evaluated for 2 ≤ k ≤ 10 communities. The best community
structure was selected using the proposed quality measure, U .
The accuracy of the resulting structure was quantified by Cohen’s Kappa statistic, which computes the agreement with the
true community structure. Overall success was determined by
computing the average Kappa value over 100 trials.
As shown inTable II, an FCCA and an averaging method are
more robust than other algorithms for varying intercluster edge
strengths. These two algorithms accurately identified almost all

κ

Ave.

time
(sec.)
κ

Voting

time
(sec.)
κ

HGPA

time
(sec.)
κ

μ inter

Method

Outlier Rate

time
(sec.)

15%

20%

25%

30%

1
±0
0.9672
±0.1819
1
±0
0.1716
±0.0313
1
±0
9.0646
±0.9299
0.5177
±0.0149
1.6271
±0.1875

1
±0
0.9168
±0.1163
0.7143
±0.0118
0.1739
±0.0254
1
±0
8.9715
±0.5380
0.5164
±0.0150
1.5554
±0.1626

1
±0
0.9429
±0.1245
0.7143
±0.0118
0.1771
±0.0281
1
±0
9.0036
±0.7468
0.4848
0.0154
1.2809
±0.1719

0.7143
±0.0118
1.0095
±0.1127
0.7143
±0.0118
0.1627
±0.0206
0.9304
±0.0031
10.4778
±2.7145
0.4554
±0.0158
1.2043
±0.0924

clusters in all cases for μinter ≤ 0.7 . Moreover, an FCCA is computationally more efficient than voting and HGPA approaches.
C. Robustness to Outlier Graphs
In a lot of real-world settings, the community structure across
a population may not always be the same, i.e., there may be
outliers in the group. In this section, we generate simulations
to evaluate the performance of the different clustering methods in the case of outlier graphs. Hundred simulated networks
consisting of 64 nodes were generated 100 times using two different community structures. The majority of the networks had
a three-cluster structure, where nodes 1 to 16 formed the first
cluster, nodes 17 to 48 formed the second cluster, and the last 16
formed the third cluster. The elements of the connectivity matrices ranged between 0 and 1. The weights of the intracluster
edges were selected from a truncated Gaussian distribution with
a mean of μintra = 0.6 and a standard deviation of σintra = 0.1.
Similarly, intercluster edge weights were selected from a truncated Gaussian distribution with a mean of μinter = 0.3 and a
standard deviation of σinter = 0.2. Outlier networks were constructed to have two communities, in which nodes 1 to 32 formed
the first cluster and nodes 33 to 64 formed the second cluster. The
edge weights were selected from a truncated Gaussian distribution with the intracluster edges having a mean of μintra = 0.8
and a standard deviation of σintra = 0.1, while the intercluster
edge weights had a mean of μinter = 0.1 and a standard deviation
of σinter = 0.2. To evaluate the robustness of the algorithms to
outliers, the ratio of the outlier networks to the whole group was
increased gradually from 15% to 30%.
Similar to the previous section, all networks were evaluated
for 2 ≤ k ≤ 10 communities, and the best community structure was selected by choosing k, which maximizes the quality
measure U . Accuracy of the different clustering algorithms was
quantified by computing the average Kappa value across 100 trials. As shown in Table III, an FCCA and the voting approach are
more accurate in identifying the true community structure in the

OZDEMIR et al.: HIERARCHICAL SPECTRAL CONSENSUS CLUSTERING FOR GROUP ANALYSIS OF FUNCTIONAL BRAIN NETWORKS

2165

TABLE IV
AVERAGE COHEN’S KAPPA AND AVERAGE STANDARD ERROR FOR IDENTIFYING
OVERLAPPING CLUSTERS IN SIMULATED NETWORKS
Method

FCCA

# of Intercluster Edges

κ

Ave.

time
(sec.)
κ

Voting

time
(sec.)
κ

HGPA

time
(sec.)
κ
time
(sec.)

75

100

125

0.9964
±3.9437 × 10 −4
1.3631
±0.3329
0.9754
±0.0025
0.2186
±0.0560
0.9938
±6.1236 × 10 −4
11.8611
±1.9694
0.8682
±0.0074
1.5070
±0.2811

0.9887
±0.0013
1.2449
±0.2767
0.9424
±0.0052
0.2214
±0.0577
0.9694
±0.0022
15.0078
±2.8988
0.8374
±0.0094
1.5480
±0.2081

0.9539
±0.0048
2.5533
±1.0191
0.8825
±0.0080
0.3817
±0.1246
0.9444
±0.0047
26.5411
±6.1363
0.7732
±0.0117
1.7893
±0.2913

case of outlier graphs. Although the voting approach is more
robust against the outliers, its high computational complexity
makes the FCCA a useful alternative.
D. Detecting Overlapping Communities
Communities in a network may not always be distinctly separable from each other and may have an overlapping structure.
In order to evaluate the performance of the different clustering
algorithms in the case of overlapping communities, 100 simulated networks consisting of 64 nodes and composed of four
equal size communities were generated 100 times. The weights
of the intracluster edges were selected from a truncated Gaussian
distribution with a mean of μintra = 0.8 and a standard deviation of σintra = 0.1. Similarly, intercluster edge weights were
selected from a truncated Gaussian distribution with a mean of
μinter = 0.1 and a standard deviation of σinter = 0.2. To provide
overlap between communities, a subset of the intercluster edges
between each pair of communities was selected from the same
distribution as the intracluster edges. The number of strong intercluster edges was increased gradually from 75 to 125.
As in previous simulations, all networks were evaluated for
2 ≤ k ≤ 10 communities and the optimal k was selected based
on the maximizing the quality measure. Overall success was
determined by computing the average Kappa value over 100
trials. As seen in Table IV, an FCCA is more robust to overlapping communities in the network compared to the other
methods.
E. Community Structure of the Brain During ERN
The time-varying phase synchrony measure is applied to a
set of EEG data containing the ERN [70], [71]. The ERN is an
event-related potential (ERP) that occurs following performance
errors in a speeded reaction time task. Previously reported EEG
data [72] from 63-channels (10/20 system) were utilized. This
included 91 undergraduate students (34 male) from the University of Minnesota (one of the original 92 participants were
dropped due to artifacts rendering computation of the time–

Fig. 3. Cluster structures obtained by the FCCA. (a) Error (k = 10).
(b) Correct (k = 7).

frequency phase synchrony values problematic). Full methodological details of the recording are available in the previous
report [72]. The task was a common speeded-response letter
(H/S) flanker, where error and correct response-locked trials
from each subject were utilized. A random subset of correct trials was selected to equate the number of error relative to correct
trials for each participant. The EEG data are preprocessed by
the spherical spline current-source density (CSD) waveforms
to sharpen ERP scalp topographies and reduce volume conduction [73]. The CSD has fewer assumptions than many inverse
transforms, attenuates volume conduction, and represents independent sources near the cortical surface [74]. Our previous
work indicates that there is increased phase synchrony associated with ERN for the theta frequency band (4–7 Hz) and ERN
time window (25–75 ms) for error responses compared to correct responses [44]. For each subject and response type, the
pairwise average PLV within the ERN time window and theta
frequency band was computed using 4 across trials yielding a
63 × 63 connectivity matrix indicating the average synchrony
between brain regions.
First, the proposed Fiedler consensus clustering approach, averaging and voting methods were applied to the set of error and
correct data in order to identify an optimal community structure. Hierarchical decomposition of the networks were evaluated
for 2 < k < 15, and the optimum k was selected by maximizing the quality metric U . The clustering results can be seen in
Figs. 3 (FCCA) and 4 (averaging and voting methods; see Fig.
4(a) and (b), respectively). For FCCA, error responses were

2166

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 9, SEPTEMBER 2015

Fig. 4. Cluster structures obtained by (a) averaging, error (k = 9), and correct
(k = 5); (b) voting, error (k = 9), and correct (k = 5).

TABLE V
MEAN AND STANDARD DEVIATION OF QUALITY METRIC (U ) COMPUTED TO
QUANTIFY THE CONSISTENCY BETWEEN THE GROUP’S COMMUNITY
STRUCTURE AND INDIVIDUAL SUBJECTS’ COMMUNITY STRUCTURE FOR EACH
SUBJECT, EACH RESPONSE TYPE, AND THE THREE
CONSENSUS CLUSTERING METHODS
Method

U

Error
Correct

Averaging

Voting

FCCA

0.0483 ± 0.0031
0.0454 ± 0.0050

0.0524 ± 0.0040
0.0426 ± 0.0054

0.0567 ± 0.0054
0.0504 ± 0.0042

best represented by a structure composed of ten communities
[see Fig. 3(a)], and correct responses with seven communities
[see Fig. 3(b)], while averaging and voting methods identify
nine communities for error responses and five communities for
correct responses (see Fig. 4). As it can be seen, the averaging method yields two large clusters for both error and correct
conditions unable to discriminate between error and correct responses and resolve the different subnetworks. Similarly, the
voting method yields a large cluster for both error and correct
responses with a couple of small frontal and lateral subnetworks.
The proposed method, on the other hand, provides a more detailed view of the network separating the medial and lateral
clusters from each other.
The obtained clusters from the three consensus clustering approaches are evaluated on each subject’s network to quantify the
agreement between the common cluster structure and each subject’s connectivity graph. This agreement is quantified through
the quality metric, U . As seen in Table V, the community structure obtained by FCCA is more appropriate for each subject and
yields a statistically significant higher score for both error and
correct conditions (p < 0.025).

From Fig. 3, we can see that the clusters identified by FCCA
are more segregated and differentiated for errors relative to correct responses. For example, in the correct condition one large
cluster 1 accounts for the majority of prefrontal and motor regions, with a small cluster 5 consistent with separable activity
in left-PFC regions. For errors, on the other hand, separable
clusters are apparent relative to left 1 and right 2 motor areas,
and left (4, 8) and right 5 lateral-PFC regions (consistent with
a priori hypotheses). Interestingly, one cluster in the error condition 6 and one in the correct 4 center on medial-frontal sites
including FCz and Cz 6, consistent with the time-domain ERN
and correct-related negativity (CRN) component topographies,
respectively. Activity in parietal-occipital regions was characterized with similar clusters for both correct 2 and error conditions
(3, 7).
An overall statistical assessment of the intermodular relationships revealed that the grand mean was significantly greater
for the Error relative to Correct conditions (t(90) = 2.16, p <
0.033), while the same comparison for intramodular pairs was
not (t(90) < .5). This provides support for the inference of increased functional connectivity related to error processing relative to correct. Next, to provide detailed information about
these relationships, average intramodular and intermodular synchronies were computed for correct and error communities (presented in Fig. 5). These maps illustrate the amount of integration
between different clusters. To provide statistical assessment of
the intermodular relationships within the error and correct conditions, t-tests were performed for each intermodular bivariate
pair relative to the grand mean of the intermodular pairs. Resulting t-values and Bonferroni corrected p-values are presented in
Fig. 3(b) and (c), respectively. While it was not appropriate to
directly compare error-correct differences between individual
clusters (as they were derived from separate cluster analyses),
several observations about the individual clusters within error
or correct conditions provide some interesting information at
this level of analysis. First, motor-related clusters in the error
condition (1, 2) were significantly more related to each other
than the across cluster average. Next, occipital clusters in both
the error (3, 7) and correct 2 conditions evidenced decreases
relative to the mean, suggesting a decrease in connectivity with
visual processing areas during the ERN and CRN. For lateralPFC regions, the smaller left-laterized clusters (8 and 5, respectively, for error and correct conditions) were significantly
associated with significantly increased connectivity with prefrontal areas and decreased connectivity with parietal occipital
areas. Another a priori effect of interest was that both error and
correct medial-frontal clusters (6 and 4, respectively) showed
significant increases with left lateral-PFC clusters (4 and 5,
respectively).
Fig. 6 illustrates the hierarchical structure obtained from the
FCCA for both response types. For the error response, the initial
partition yields one large frontal and one parietal cluster. Further
decomposition provides the detailed construction of the frontal
cluster. Similarly, for the correct response, the initial partition
yields one frontal and one parietal partition with the subsequent partitions decomposing the frontal cluster into smaller
sub-networks.

OZDEMIR et al.: HIERARCHICAL SPECTRAL CONSENSUS CLUSTERING FOR GROUP ANALYSIS OF FUNCTIONAL BRAIN NETWORKS

2167

Fig. 5. (a) Average phase synchrony between clusters for error response (k = 10), and correct response (k = 7). (b) t-values for intermodular bivariate pair
relative to the grand mean of the intermodular pairs of ERN and CRN conditions and (c) corresponding p-values.

VI. CONCLUSION
In this paper, we proposed a new graph theoretic community
detection approach to provide a detailed view of the organizational structure underlying the functional brain connectiv-

ity network through EEG recordings across multiple subjects.
The main contributions include the hierarchical implementation of Fiedler-vector-based graph clustering, the introduction of
an accurate and computationally efficient consensus clustering

2168

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 9, SEPTEMBER 2015

Future work will consider exploring single [78] and distributed dipole [79] source solutions to the inverse problem for
extending this approach to the source domain.
REFERENCES

Fig. 6. Hierarchical structure for obtained by the FCCA (a) Error. (b) Correct
responses.

TABLE VI
COMPUTATION TIME FOR COMMUNITY STRUCTURES OBTAINED BY THE FCCA,
AVERAGING, AND VOTING METHODS
Method

time
(sec.)

Error
Correct

Averaging
2.7104
2.3326

Voting
198.1623
212.5764

FCCA
11.8576
13.7596

approach, the introduction of a new information-theoretic cluster quality measure, U , and a detailed study of the brain network
involved in error processing.
First, the well-known Fiedler-vector-based graph bipartitioning method has been implemented to obtain a hierarchical decomposition of the functional connectivity networks. This hierarchical implementation is supported by previous work that
suggests a hierarchical structure for functional connectivity networks [33]–[35]. Second, the proposed partitioning approach is
modified to account for multiple subjects by first obtaining an
initial bipartition of each subject’s connectivity network, and
then by iteratively partitioning the cooccurrence matrix across
subjects. As shown through simulations and real data, FCCA
is computationally more efficient than voting (Table VI) and
is more accurate than averaging, in the case of outliers and
overlapping community structures. Moreover, the application of
FCCA to EEG data produced clusters consistent with published
work [75], [76], whereas voting and averaging methods failed
to partition the frontal cluster into physiologically meaningful
lateral and medial frontal communities. Finally, a new cluster
quality measure U based on optimizing the tradeoff between
maximizing the divergence between clusters and minimizing
the entropy of individual clusters was introduced to select the
optimal number of clusters. This measure provides an alternative to the standard modularity measure, which is known to fail
for unequal cluster sizes and weighted networks [77].

[1] L. Lee et al., “A report of the functional connectivity workshop, Dusseldorf
2002,” Neuroimage, vol. 19, no. 2, pp. 457–465, 2003.
[2] C. Stam et al., “Graph theoretical analysis of magnetoencephalographic
functional connectivity in Alzheimer’s disease,” Brain, vol. 132, no. 1,
pp. 213–224, 2009.
[3] F. Varela et al., “The brainweb: Phase synchronization and large-scale
integration,” Nature Rev. Neurosci., vol. 2, no. 4, pp. 229–239, 2001.
[4] V. Krause et al., “Functional network interactions during sensorimotor
synchronization in musicians and non-musicians,” Neuroimage, vol. 52,
no. 1, pp. 245–251, 2010.
[5] Q. Luo et al., “Visual awareness, emotion, and gamma band synchronization,” Cerebral Cortex, vol. 19, no. 8, pp. 1896–1904, 2009.
[6] M. A. Kramer et al., “Synchronization measures of the scalp electroencephalogram can discriminate healthy from Alzheimer’s subjects,” Int. J.
Neural Syst., vol. 17, no. 2, pp. 61–69, 2007.
[7] M. Arthuis et al., “Impaired consciousness during temporal lobe seizures is
related to increased long-distance cortical–subcortical synchronization,”
Brain, vol. 132, no. 8, pp. 2091–2101, 2009.
[8] K. Maharajh et al., “Fluctuation of gamma-band phase synchronization within the auditory cortex in schizophrenia,” Clin. Neurophysiol.,
vol. 121, no. 4, pp. 542–548, 2010.
[9] J. Altenburg et al., “Seizure detection in the neonatal EEG with synchronization likelihood,” Clin. Neurophysiol., vol. 114, no. 1, pp. 50–55,
2003.
[10] M. G. Knyazeva et al., “Topography of EEG multivariate phase synchronization in early Alzheimer’s disease,” Neurobiol. Aging, vol. 31, no. 7,
pp. 1132–1144, 2010.
[11] J. Żygierewicz et al., “Event-related desynchronization and synchronization in MEG: Framework for analysis and illustrative datasets related
to discrimination of frequency-modulated tones,” J. Neurosci. Methods,
vol. 168, no. 1, pp. 239–247, 2008.
[12] J. R. Petrella, “Use of graph theory to evaluate brain networks: A clinical
tool for a small world?” Radiology, vol. 259, no. 2, pp. 317–320, 2011.
[13] B. C. Van Wijk et al., “Comparing brain networks of different size
and connectivity density using graph theory,” PLoS One, vol. 5, no. 10,
p. e13701, 2010.
[14] X.-N. Zuo et al., “Network centrality in the human functional connectome,” Cerebral Cortex, vol. 22, no. 8, pp. 1862–1875, 2012.
[15] M. Boersma et al., “Network analysis of resting state EEG in the developing young brain: Structure comes with maturation,” Hum. Brain Mapping,
vol. 32, no. 3, pp. 413–425, 2011.
[16] M. E. Lynall et al., “Functional connectivity and brain networks in
schizophrenia,” J. Neurosci., vol. 30, no. 28, pp. 9477–9487, 2010.
[17] B. C. Bernhardt et al., “Graph-theoretical analysis reveals disrupted smallworld organization of cortical thickness correlation networks in temporal
lobe epilepsy,” Cerebral Cortex, vol. 21, no. 9, pp. 2147–2157, 2011.
[18] Y. Liu et al., “Disrupted small-world networks in schizophrenia,” Brain,
vol. 131, no. 4, pp. 945–961, 2008.
[19] P. Barttfeld et al., “A big-world network in ASD: Dynamical connectivity
analysis reflects a deficit in long-range connections and an excess of shortrange connections,” Neuropsychologia, vol. 49, no. 2, pp. 254–263, 2011.
[20] F. D. V. Fallani et al., “Cortical functional connectivity networks in normal
and spinal cord injured patients: Evaluation by graph analysis,” Hum.
Brain Mapping, vol. 28, no. 12, pp. 1334–1346, 2007.
[21] K. Supekar et al., “Network analysis of intrinsic functional brain connectivity in Alzheimer’s disease,” PLoS Comput. Biol., vol. 4, no. 6,
p. e1000100, 2008.
[22] M. Chavez et al., “Functional modularity of background activities in normal and epileptic brain networks,” Phys. Rev. Lett., vol. 104, no. 11,
p. 118701, Mar 2010.
[23] M. Valencia et al., “Complex modular structure of large-scale brain networks,” Chaos, Interdiscip. J. Nonlinear Sci., vol. 19, no. 2, p. 023119,
2009.
[24] R. Guimera and L. A. N. Amaral, “Functional cartography of complex
metabolic networks,” Nature, vol. 433, pp. 895–900, 2005.
[25] M. Kirschner and J. Gerhart, “Evolvability,” Proc. Nat. Acad. Sci.,
vol. 95, no. 15, pp. 8420–8427, 1998.
[26] R. S. J. Frackowiak et al., Human Brain Function, 2nd ed. New York, NY,
USA: Academic, 2003.

OZDEMIR et al.: HIERARCHICAL SPECTRAL CONSENSUS CLUSTERING FOR GROUP ANALYSIS OF FUNCTIONAL BRAIN NETWORKS

[27] O. Sporns et al., “The human connectome: A structural description of the
human brain,” PLoS Comput. Biol., vol. 1, no. 4, p. e42, Sep. 2005.
[28] S. L. Bressler, “Large-scale cortical networks and cognition,” Brain Res.
Rev., vol. 20, no. 3, pp. 288–304, 1995.
[29] R. Baumgartner et al., “Comparison of two exploratory data analysis
methods for fMRI: Fuzzy clustering versus principal component analysis,”
Magn. Reson. Imag., vol. 18, no. 1, pp. 89–94, 2000.
[30] A. Meyer-Baese et al., “Comparison of two exploratory data analysis
methods for fMRI: Unsupervised clustering versus independent component analysis,” IEEE Trans. Inf. Technol. Biomed., vol. 8, no. 3,
pp. 387–398, Sep. 2004.
[31] U. Von Luxburg, “A tutorial on spectral clustering,” Stat. Comput.,
vol. 17, no. 4, pp. 395–416, 2007.
[32] C. Allefeld, “Eigenvalue decomposition as a generalized synchronization
cluster analysis,” Int. J. Bifurcation Chaos, vol. 17, no. 10, pp. 3493–3497,
2008.
[33] D. Meunier et al., “Hierarchical modularity in human brain functional
networks,” Front. Neuroinformat., vol. 3, no. 37, 2009.
[34] C. Zhou et al., “Hierarchical organization unveiled by functional connectivity in complex brain networks,” Phys. Rev. Lett., vol. 97, no. 23,
p. 238103, 2006.
[35] L. Zemanová et al., “Structural and functional clusters of complex brain
networks,” Phys. D, Nonlinear Phenom., vol. 224, no. 1, pp. 202–212,
2006.
[36] D. Meunier et al., “Modular and hierarchically modular organization of
brain networks,” Front. Neurosci., vol. 4, 2010.
[37] A. Strehl and J. Ghosh, “Cluster ensembles—A knowledge reuse framework for combining multiple partitions,” J. Mach. Learn. Res., vol. 3,
pp. 583–617, 2003.
[38] A. Gionis et al., “Clustering aggregation,” ACM Trans. Knowl. Discovery
Data, vol. 1, no. 1, p. 4, 2007.
[39] M. Fiedler, “A property of eigenvectors of nonnegative symmetric matrices and its application to graph theory,” Czechoslovak Math. J., vol. 25,
no. 4, pp. 619–633, 1975.
[40] E. Rodriguez et al., “Perception’s shadow: Long-distance synchronization
of human brain activity,” Nature, vol. 397, no. 6718, pp. 430–433, 1999.
[41] M. L. Van Quyen et al., “Comparison of Hilbert transform and wavelet
methods for the analysis of neuronal synchrony,” J. Neurosci. Methods,
vol. 111, no. 2, pp. 83–98, 2001.
[42] P. Tass et al., “Detection of n:m phase locking from noisy data: application
to magnetoencephalography,” Phys. Rev. Lett., vol. 81, no. 15, p. 3291,
1998.
[43] J.-P. Lachaux et al., “Estimating the time-course of coherence between
single-trial brain signals: An introduction to wavelet coherence,” Neurophysiol. Clin./Clin. Neurophysiol., vol. 32, no. 3, pp. 157–174, 2002.
[44] S. Aviyente et al., “A phase synchrony measure for quantifying dynamic
functional integration in the brain,” Hum. Brain Mapping, vol. 32, no. 1,
pp. 80–93, 2011.
[45] S. Aviyente and A. Y. Mutlu, “A time-frequency-based approach to phase
and phase synchrony estimation,” IEEE Trans. Signal Process., vol. 59,
no. 7, pp. 3086–3098, Jul. 2011.
[46] A. Rihaczek, “Signal energy distribution in time and frequency,” IEEE
Trans., Inf. Theory, vol. 14, no. 3, pp. 369–274, May 1968.
[47] C. J. Stam and J. C. Reijneveld, “Graph theoretical analysis of complex
networks in the brain,” Nonlinear Biomed. Phys., vol. 1, no. 1, pp. 1–19,
2007.
[48] E. Bullmore and O. Sporns, “Complex brain networks: Graph theoretical
analysis of structural and functional systems,” Nature Rev. Neurosci.,
vol. 10, no. 3, pp. 186–198, 2009.
[49] J. Forman et al., “Spectralnet—An application for spectral graph analysis
and visualization,” BMC Bioinformat., vol. 6, no. 1, p. 260, 2005.
[50] S. White and P. Smyth, “A spectral clustering approach to finding communities in graphs,” in Proc. SIAM Int. Conf. Data Min., 2005, pp. 76–84.
[51] A. K. Jain, “Data clustering: 50 years beyond k-means,” Pattern Recog.
Lett., vol. 31, no. 8, pp. 651–666, 2010.
[52] A. Y. Ng et al., “On spectral clustering: Analysis and an algorithm,” in
Advances in Neural Information Processing Systems. Cambridge, MA,
USA: MIT Press, 2001, pp. 849–856.
[53] F. Lin and W. W. Cohen, “Power iteration clustering,” in Proc. 27th Int.
Conf. Mach. Learn., 2010, pp. 655–662.
[54] C. Ding and X. He, “Linearized cluster assignment via spectral ordering,”
in Proceedings of the Twenty-First International Conference on Machine
Learning. New York, NY, USA: ACM, 2004, p. 30.

2169

[55] M. Holzrichter and S. Oliveira, “A graph based method for generating
the Fiedler vector of irregular problems,” Lecture Notes Comput. Sci., vol.
1586, pp. 978–985, 1999.
[56] N. Nguyen and R. Caruana, “Consensus clusterings,” in Proc. IEEE 7th
Data Min. Int. Conf., 2007, pp. 607–612.
[57] A. P. Topchy et al., “Analysis of consensus partition in cluster ensemble,”
in Proc. IEEE 4th Data Min., Int. Conf., 2004, pp. 225–232.
[58] A. P. Topchy et al., “A mixture model of clustering ensembles,” SIAMJ.,
pp. 379–390, 2004.
[59] G. Karypis et al., “Multilevel hypergraph partitioning: Application in
VLSI domain,” IEEE Trans. Very Larg Scale Integr. Syst., vol. 7, no. 1,
pp. 69–529, 1999.
[60] M. E. Newman, “Modularity and community structure in networks,” Proc.
Nat. Acad. Sci., vol. 103, no. 23, pp. 8577–8582, 2006.
[61] K. Steinhaeuser and N. V. Chawla, “Identifying and evaluating community structure in complex networks,” Pattern Recog. Lett., vol. 31, no. 5,
pp. 413–421, 2010.
[62] M. Ovelgonne and A. Geyer-Schulz, “Cluster cores and modularity maximization,” in Proc. Data Min. Workshops, Int. Conf., 2010, pp. 1204–1213.
[63] J. Cohen, “A coefficient of agreement for nominal scales,” Educ. Psychol.
Meas., vol. 20, no. 1, pp. 37–46, 1960.
[64] J. B. Garner, “The standard error of Cohen’s Kappa,” Statist. Med.,
vol. 10, no. 5, pp. 767–775, 1991.
[65] C. J. Rijsbergen, “Information retrieval,” J. Amer. Soc. Inf. Sci., vol. 30,
no. 6, pp. 374–375, 1979.
[66] A. Rosenberg and J. Hirschberg, “V-measure: A conditional entropybased external cluster evaluation measure,” in Proc. Joint Conf. Empirical
Methods Natural Lang. Process. Comput. Natural Lang. Learn., 2007,
pp. 410–420.
[67] J. Lin, “Divergence measures based on the Shannon entropy,” IEEE Trans.
Inf. Theory, vol. 37, no. 1, pp. 145–151, Jan. 1991.
[68] M. C. V. Nascimento and A. C. P. L. F. de Carvalho, “Spectral methods
for graph clustering—A survey,” Eur. J. Oper. Res., vol. 211, no. 2, pp.
221–231, 2011.
[69] S. Yu et al., “Optimized data fusion for k-means Laplacian clustering,”
Bioinformatics, vol. 27, pp. 118–126, Jan. 2011.
[70] M. Falkenstein et al., “Effects of crossmodal divided attention on late
ERP components. II. Error processing in choice reaction tasks,” Electroencephalogr. Clin. Neurophysiol., vol. 78, no. 6, pp. 447–455, 1991.
[71] W. J. Gehring et al., “A neural system for error detection and compensation,” Psychol. Sci., vol. 4, no. 6, pp. 385–390, 1993.
[72] J. R. Hall et al., “Externalizing psychopathology and the error-related
negativity,” Psychol. Sci., vol. 18, no. 4, pp. 326–333, 2007.
[73] J. Kayser and C. E. Tenke, “Principal components analysis of Laplacian
waveforms as a generic method for identifying ERP generator patterns: II.
Adequacy of low-density estimates,” Clin. Neurophysiol., vol. 117, no. 2,
pp. 369–380, 2006.
[74] C. E. Tenke and J. Kayser, “Generator localization by current source
density (CSD): Implications of volume conduction and field closure at
intracranial and scalp resolutions,” Clin. Neurophysiol., vol. 123, no. 12,
pp. 2328–2345, 2012.
[75] M. Bolaños et al., “A weighted small world network measure for assessing functional connectivity,” J. Neurosci. Methods, vol. 212, no. 1,
pp. 133–142, 2013.
[76] J. F. Cavanagh et al., “Prelude to and resolution of an error: EEG phase
synchrony reveals cognitive control dynamics during action monitoring,”
J. Neurosci., vol. 29, no. 1, pp. 98–105, 2009.
[77] S. Fortunato and M. Barthelemy, “Resolution limit in community detection,” Proc. Nat. Acad. Sci., vol. 104, no. 1, pp. 36–41, 2007.
[78] C. M. Michel et al., “EEG source imaging,” Clin. Neurophysiol., vol. 115,
no. 10, pp. 2195–2222, 2004.
[79] C. S. Herrmann et al., “Cognitive functions of gamma-band activity: Memory match and utilization,” Trends Cognit. Sci., vol. 8, no. 8, pp. 347–355,
2004.

Authors’ photographs and biographies not available at the time of publication.

