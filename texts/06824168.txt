2760

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 11, NOVEMBER 2014

Noncontact Monitoring Breathing Pattern, Exhalation
Flow Rate and Pulse Transit Time
Dangdang Shao, Yuting Yang, Chenbin Liu, Francis Tsow, Hui Yu, and Nongjian Tao∗

Abstract—We present optical imaging-based methods to
measure vital physiological signals, including breathing frequency
(BF), exhalation flow rate, heart rate (HR), and pulse transit time
(PTT). The breathing pattern tracking was based on the detection
of body movement associated with breathing using a differential
signal processing approach. A motion-tracking algorithm was implemented to correct random body movements that were unrelated to breathing. The heartbeat pattern was obtained from the
color change in selected region of interest (ROI) near the subject’s
mouth, and the PTT was determined by analyzing pulse patterns
at different body parts of the subject. The measured BF, exhaled
volume flow rate and HR are consistent with those measured simultaneously with reference technologies (r = 0.98, p < 0.001 for
HR; r = 0.93, p < 0.001 for breathing rate), and the measured
PTT difference (30–40 ms between mouth and palm) is comparable
to the results obtained with other techniques in the literature. The
imaging-based methods are suitable for tracking vital physiological
parameters under free-living condition and this is the first demonstration of using noncontact method to obtain PTT difference and
exhalation flow rate.
Index Terms—Mobile health, photoplethysmography (PPG),
physiological signal detection, pulse transit time (PTT), remote
sensing, respiration.

I. INTRODUCTION
ONITORING vital physiological signals such as heart
rate (HR), pulse transit time (PTT), and breathing pattern, are basic requirements in the diagnosis and during the
course of treatment of various diseases [1], [2]. Traditionally,
these signals are measured only in hospital and clinical settings.
An important recent trend is the development of portable devices
for tracking the vital physiological signals noninvasively based
on optical methods known as photoplethysmography (PPG).
These portable devices, when combined with cell phones, tablets
or other mobile devices, provide an opportunity to everyone to
monitor one’s vital signs anytime and anywhere [3]–[5]. These
mobile device-based efforts can be divided into two approaches.

M

Manuscript received February 1, 2014; revised May 16, 2014; accepted April
30, 2014. Date of publication June 2, 2014; date of current version October
16, 2014. The work was supported in part by the National Science Foundation.
Asterisk indicates corresponding author.
D. Shao and F. Tsow are with the Biodesign Institute, Arizona State University, Tempe, AZ 85287-5801 USA (e-mail: dshao2@asu.edu; Tsing.Tsow@
asu.edu).
Y. Yang, C. Liu, and H. Yu are with the School Chemistry and Chemical Engineering, State Key Lab Analytical Chemistry Life Science, Nanjing University, Nanjing 210093, Jiangsu, China (e-mail: yyang194@asu.edu;
chenbin.liu@gmail.com; Hui.Yu.2@asu.edu).
∗ N. Tao is with the Biodesign Institute, Arizona State University, Tempe,
AZ 85287-5801 USA (e-mail: Nongjian.Tao@asu.edu).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2014.2327024

The first one is optical detection of a person’s finger pressed
against the devices or the cameras built in the mobile devices to
perform PPG [6]. While useful, this approach requires steady
physical contact of one’s finger with the PPG devices [7], [8] or
the cameras, which makes it impractical for continuous monitoring of the physiological signals under free-living conditions.
The term “free-living” refers to conditions under which the measurements taken require no special attention or action from the
user and there is no inconvenience caused by any extra physical burden. Another optical approach is based on noncontact
mode [9]. Heart and breathing rates were obtained from the
images of faces [10], [11], upper arms [12], and palms [13]
recorded with digital cameras, including smartphone cameras
[14] and webcams. In addition to heart and breathing rates,
heart rate variability (HRV) was also analyzed [15], [16] from
facial videos. More recently, a near-IR enhanced camera was
used to obtain HR from a subject’s facial area and breathing rate
from the subject’s chest area [17].
Despite the attractive features of imaging-based noncontact approach, the signals extracted from the images contain
noise from various sources [18]. To combat the noise issue,
Poh et al. [15], [16] used an independent component analysis
(ICA) method that separates a multivariate signal into additive
subcomponents by assuming the mutual statistical independence
of the non-Gaussian source signals. Using ICA, they demonstrated the detection of HR, which typically varies between 0.8
and 3 Hz. Verkruysse et al. [10] determined a movement artifact
map by averaging the powers at bandwidths around the HR.
These efforts helped to minimize unwanted noise in the measured HR signals. However, it is much more challenging to track
breathing pattern, especially breath-by-breath, because breathing frequency (BF) is much lower than the HR. In a typical
ambient environment, low frequency noise, particularly noise
associated with body movement, is much greater than noise at
high frequencies.
This paper describes new methods for noncontact monitoring of several physiological signals in real time by maximizing the signals and minimizing the noise due to unwanted body movement. In addition to HR and BF, we also
obtained the exhalation volume flow rate and cardiac PTT.
Exhalation flow rate is an important physiological parameter and proportional to a subject’s metabolic rate [19]. PTT
is related to blood pressure as well as pulse wave velocity (PWV), and is an indicator of cardiovascular parameters,
such as arterial elasticity and stiffness [20], [21]. Traditionally,
PWV has been measured using a galvanometer [22] and ultrasound techniques [23], [24]. Recently, PTT was determined by
performing simultaneous ECG and PPG [25]–[27]. Babchenko

0018-9294 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

SHAO et al.: NONCONTACT MONITORING BREATHING PATTERN, EXHALATION FLOW RATE AND PULSE TRANSIT TIME

2761

Fig. 2. Left: A zoomed-in image showing subject’s right shoulder. Right:
Derivative image with respect to vertical direction, where the shoulder edge is
shown as a bright line.

Fig. 1.

Schematic illustration of experimental setup.

et al. [28] used contact pulse oximetry to determine the PTT
difference between left index finger and left second toe. The
PTT difference is related to the change in arterial distensibility
due to epidurally induced sympathetic block. The acquisition of
PTT related information has the potential to measure parameters that can help diagnose cardiovascular diseases. This paper
demonstrates the first noncontact optical imaging method to determine PTT difference, along with breath-by-breath breathing
pattern and exhalation flow rate. Since the method presented
in this paper does not require contact with the subject’s body
or any extra devices to measure PTT and exhalation flow rate,
it has the advantage of providing an easy and burden-free way
to measure these parameters when compared to the currently
available methods which, to the best of the authors’ knowledge,
are mainly contact based. Finally, we carried out a small-scale
pilot study on subjects with different profiles to demonstrate the
robustness of the methods.
II. METHODS
We monitored multiple physiological signals, including HR,
BF, exhalation flow rate and PTT, by processing images, that
were captured with digital cameras, using different algorithms.
For example, we detected HR and PTT by tracking the image
intensity change of the subject’s skin, BF and exhaled breath
volume (VE) by tracking the subtle body movements associated
with breathing. We describe detailed algorithms and methods
below.
A schematic illustration of the experimental setup is shown
in Fig. 1. Different digital cameras, including Logitech colored
Webcam (HD 720p), Pike black and white camera (F-032B)
and Pike color camera (F-032C), were used to capture videos
of each subject’s face, palms, and upper body. These cameras
(colored or black and white) have different inherent noise, but
they all produced satisfactory results in terms of determining
the physiological parameters. The videos were taken indoors
under ambient light condition, using ordinary 60 W fluorescent
lamps at a height of 5 m for illumination. More controlled light
sources, including LEDs and desk lamps, were also used, but
no evident improvement in the signals was detected as they all

provided sufficient illumination of the subjects. The subjects
were asked to sit at a distance of approximately 50 cm from
the camera lens. As long as good quality and clear focus were
guaranteed for the image, distance between the camera and the
subject did not affect the signals within a range of 30 to 80 cm.
All the videos and data were analyzed with a Matlab-based
user interface. The user interface was able to show the live
video of the user, allow the selection of ROIs, perform signal
processing of the data in the ROIs to determine the heartbeat and
breathing signals independently, and display the results in real
time. The test results were also saved in Matlab format files that
can be used for further data analysis, e.g., for PTT difference
estimation.
For heartbeat monitoring, a video of a study subject’s face was
recorded for typically 30 s in each experiment and fast Fourier
transform (FFT) was performed on the intensity signal averaged
over all the pixels in each selected ROI to obtain the frequency
spectrum of the detected physiological signal. Note that longer
recording times may produce better results, but make the process
less user-friendly due to longer testing duration required.
Unlike HR monitoring, the breathing pattern was determined
by detecting and analyzing the body movement associated with
breathing. Different parts of the body move with breathing differently. Chest and abdomen may have the largest movement
with breath [17], but these regions are not easily accessible to
camera for imaging under natural and free-living conditions. For
this reason, the face, the neck, and upper body are preferred as
sites for measuring breathing pattern. A region of 40 × 40 pixels
around the edge of shoulder was selected to be the ROI for
breathing detection [Fig. 2] (left panel). The ROI size was chosen after considering an optimal size that was large enough
to capture the complete range of possible shoulder movement
due to breathing activity while at the same time was sufficiently
small so that it could still sensitively track small shoulder movements due to breathing. Then the derivative of the ROI was taken
along vertical direction to obtain a differential image of the ROI.
Shoulder edge in this differential image was revealed as a bright
line [Fig. 2] (right panel).
The line location indicates the position of the shoulder edge.
To accurately determine the shoulder position, the differential
image of the selected ROI was divided into two equal portions
along the shoulder edge. The derivative of the ROI of the top
portion is referred to as dA and that of the bottom portion as
dB. When the shoulder moves up and down with breathing, dA

2762

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 11, NOVEMBER 2014

Fig. 4.
Fig. 3.

Obtaining PTT difference from two PPG signals.

Motion tracking algorithm workflow.

increases (or decreases) and dB decreases (or increases). The
vertical movement of shoulder can be determined by
dI =

dA − dB
.
dA + dB

(1)

The difference, dA − dB, in (1) is sensitive to the vertical
movement and is immune to common noise in dA and dB.
Dividing dA − dB by dA + dB further reduces noise associated with the intensity fluctuations of the light source. For example, if the light changes, dA and dB will change in a similar way,
and the normalization will remove the effects of light intensity
instability. dI is calculated for every frame, and plotted against
time after applying a low-pass filter with a cut-off frequency of
2 Hz.
The accuracy of breathing pattern measurement may be affected by large body movements unrelated to breathing during
these measurements. We implemented a motion-tracking algorithm to correct such motion artifacts based on the phase correlation method [29]. The algorithm checked the shift of the
ROIs due to the body movement approximately every 2 s and
corrected it by updating new locations of the ROIs [Fig. 3]. Suppose the original location of one pixel was (x, y), the updated
location would be

xnew = x + shift x
(2)
ynew = y + shift y
where shift_x and shift_y were the location differences along the
horizontal and vertical directions calculated by phase correlation
method.
In this paper, noncontact optical imaging method was also
used to determine PTT related information. The variations in
PTT of different body parts were obtained by analyzing the
time difference of PPG signals measured simultaneously for
these parts. The PTT difference (more details in Section III-D)
can be obtained from the time difference between the peaks
of two PPG signals in the same heartbeat cycle. Fig. 4 is a
representative plot that depicts the method to calculate PTT
difference
PTT Diﬀerence = t2 − t1 .

(3)

To validate the heartbeat and breathing pattern measurement
results, we carried out simultaneous measurements of the physiological signals with different reference technologies. For HR
measurement, we used a Zephyr ECG. The HR was measured
in beats per minute (BPM) and the ECG raw data can be obtained from output files generated by Zephyr. For breathing
pattern measurement, we used two reference technologies, viz.,
a Zephyr wearable device and an Oxycon metabolic analysis
instrument. The Zephyr device used a movement sensor integrated in a belt wrapped around the user’s chest and reported
user’s breathing rate in BPM. Since the Zephyr device does not
provide exhaled breath volume data, the Oxycon instrument was
used to measure both breathing frequency (unit: BPM) and exhaled breath volume (unit: L) via a turbine flow meter attached
to a mask worn by the user. To validate PTT results, we used
several feature extraction algorithms, and EPIC motion sensors
(PS25451).
III. RESULTS AND DISCUSSION
A. Heartbeat Monitoring
Using the methods described in Section II, the FFT spectrum
of the ROI revealed the heartbeat signal as a peak at a frequency
corresponding to the HR. In order to optimize the signal-to-noise
ratio (SNR), the results of red, green, and blue channels were
compared, and the green channel was found to give the largest
peak amplitude in the FFT spectrum, which corresponds to
the strongest heartbeat signal [see Fig. 5(a)]. One of the possible reasons is that oxygenated hemoglobin absorbs green light
more than red and penetrates deeper into the skin compared to
blue light. This finding is supported by previous reports [10].
Since the SNR may also depend on the selection of ROI, we
extracted the peak amplitude from each pixel and plotted it on
a colormap to analyze the variation of the heartbeat signal in
different regions of the face [see Fig. 5(b)]. The regions around
lips and nose have larger heartbeat amplitudes, which is consistent with the fact that these regions have more blood vessels.
Note that eye regions and face edges also appear to have large
heartbeat amplitudes, which are due to body movement, rather
than real heartbeat signals. This conclusion is supported by the
SNR colormap, obtained by normalizing the peak amplitude of

SHAO et al.: NONCONTACT MONITORING BREATHING PATTERN, EXHALATION FLOW RATE AND PULSE TRANSIT TIME

2763

Fig. 6. Breathing pattern detection by shoulder movement tracking. Left: An
ROI is selected on each shoulder (red box), and each ROI is divided into two
subregions, A and B, along vertical direction. Right: Corresponding breathing
cycles from the ROIs using differential detection method.

Fig. 5. (a) Original image with an ROI (blue rectangle) near the mouth is
shown on the left. An FFT spectrum of the ROI is shown on the right. Red,
green, and blue lines represent the R, G, and B color channels, respectively,
and the green channel gives the strongest heartbeat signal. (b) Colormap of
FFT peak amplitude in each pixel at heartbeat frequency (HR). The color scale
from blue to red indicates the FFT peak amplitude at HR. (c) SNR colormap at
HR. (d) Heartbeat waveform obtained with the presented method. (e) Heartbeat
detection validation. Heartbeat waveform obtained with a commercial device
(Zephyr).
Fig. 7. Different breathing patterns are obtained by using differential detection
method.

each pixel in the FFT spectrum with the noise level near the
peak (4). The noise is defined as the average power of the noise
spectrum around the HR peak
SNR =

peak amplitude at HR
.
noise

(4)

The SNR colormap shows that the regions around the eyes
and edges of face have rather low SNR values [see Fig. 5(c)].
The signal analysis described earlier allowed us to conclude
that the region around the lips gives the strongest and the most
stable heartbeat signal. For real-time determination of HR, we
thus selected the region around the lips with an ROI size of
40 × 80 pixels, and analyzed the green channel of the ROI for
heartbeat detection. The green channel signal was first averaged
within the ROI and then processed by a low-pass filter with a cutoff frequency of 2 Hz. Background noise at high frequency was
removed accordingly. Fig. 5(d) shows the heartbeat signal thus
obtained. As mentioned earlier, a Zephyr wearable device was
used to obtain heartbeat waveforms as a reference to validate the
results. The HR calculated from the ECG measured by Zephyr
is comparable to the HR obtained with our methods. Both of
these are about 1 Hz, as shown in Fig. 5(e).
B. Breathing Pattern Monitoring
An example of breathing waveforms obtained with the
method described in Section II is shown in Fig. 6. A region

of 40 × 40 pixels around the edge of each shoulder was selected to be the ROI for breathing detection [see Fig. 6] (left
panel). The downhill cycles correspond to exhalation periods
when the thoracic cavity is shrinking and the shoulders move
downward, whereas the uphill cycles correspond to inhalation
periods when the thoracic cavity is expanding and the shoulders
move upward. The breathing patterns obtained from the left and
the right shoulders are consistent with each other [see Fig. 6]
(right panel).
To further demonstrate the reliability of the method for realtime monitoring of breathing pattern, the subject was instructed
to change breathing pattern intentionally. Initially, the subject
breathed normally for six cycles, followed by four cycles of
deep breathing and then eight cycles of rapid breathing. The
results shown in Fig. 7 demonstrate that our method successfully
captures the breathing pattern variations.
The effectiveness of the motion-tracking algorithm is shown
in Fig. 8(a), which compares the results with and without
the motion-tracking algorithm. Without applying the motiontracking algorithm, the measured breathing signal was overwhelmed by the body movement. In contrast, the breathing
pattern was clearly observed after the implementation of the
motion-tracking algorithm. The algorithm worked effectively
since the breathing-related body movement of the shoulders has
small amplitude and is primarily in the vertical direction, which

2764

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 11, NOVEMBER 2014

Fig. 9. Correlation between the exhaled breath volumes obtained from the
differential detection method and the commercial device, Oxycon. In the differential detection method, the exhaled breath volume is taken from the shoulder
movement, or dI. Data from six tests can be fit with a linear curve. For every
unit of dI, the volume change is about 0.15 L.

Fig. 8. (a) Effectiveness of motion tracking algorithm for breathing pattern
detection. Left: Image of a study subject with a selected ROI on the right
shoulder. When the motion-tracking algorithm is enabled, the ROI follows the
body movement (blue box). In contrast, when the motion-tracking algorithm is
disabled, the ROI is fixed in the image and the shoulder may move out of the ROI
(red box). Right: Breathing patterns with (blue curve) and without (red curve)
the motion-tracking algorithm. (b) Comparison of breathing patterns obtained
with the presented method (red line) and Zephyr (black line). (c) Comparison
of breathing patterns obtained with the presented method (red line) and Oxycon
device (black line).

is different from the relatively large body movement that may
occur in all directions and at different time scales from regular
breathing.
The breathing pattern measured with our image processing
method results in signal waveforms that are consistent with those
obtained using the Zephyr [see Fig. 8(b)] and the Oxycon [see
Fig. 8(c)] devices in terms of both BF and relative breathing
amplitude.

Fig. 10. PTT difference among different body parts. (a) PTT definition for
three parts of the body. (b) Corresponding ROIs of three parts. (c) PPG signals
obtained from the ROIs. Time delay was about 30 ms between PPG signals
obtained from mouth and palm.

C. Determination of Exhaled Breath Volume Flow Rate

D. Pulse Transit Time

The amplitude of the breathing-related shoulder movement is
associated with the exhaled breath volume per breathing cycle,
or VE. The relationship was examined by plotting the amplitude
versus exhalation flow volume obtained with the Oxycon instrument. Six tests were carried out, and in each test, the subject
changed the exhalation rate. Fig. 9 shows a plot of the breathing
amplitude (from the differential signal, dI) of the tests versus
the exhaled breath volume obtained with the Oxycon instrument, which shows linear relationship (R2 = 0.81) between dI
and the exhaled breath volume.
The exhalation flow rate can be calculated by dividing the
exhaled breath volume by exhalation time

We detected the PTT delays among different body parts. In
Fig. 10(a), the PTT from heart to mouth, and to left and right
palms are indicated by t1, t2, and t3 independently. The ROI
selections of three parts from the video sample are shown in
Fig. 10(b) as three rectangles with different colors. Fig. 10(c)
shows the PPG signals obtained from the ROIs. Time delays
were found between PPG signals from different parts of body
in every heart cycle. The PPG signal detected from mouth area
(blue curve) arrived earlier than the PPG signals detected from
the two palm areas (red and green curves). A sample of the
delay is shown in Fig. 10(c) to illustrate PTT difference between
mouth and palm. PTT difference was not obvious between left
and right palms, which is consistent with the observation by
Jago and Murray [25] with a contact method.
Several signal processing algorithms were evaluated to determine the PTT difference among different body parts. The first
algorithm was based on comparing peak locations of different

exhalation ﬂow rate =

exhaled breath volume
.
exhalation time

(5)

This observation demonstrates a method to remotely determine exhalation flow rate under free-living condition.

SHAO et al.: NONCONTACT MONITORING BREATHING PATTERN, EXHALATION FLOW RATE AND PULSE TRANSIT TIME

2765

Fig. 11. Estimate peak location for single cycle of PPG signal by using linear
curve fitting method. Take one cycle from PPG signal (a) and use two linear
curves (black dashed lines) to fit the original signal from the left part (red) and
the right part (blue) independently (b). The point of intersection of two linear
curves (green arrow) is the estimated peak location in that particular heartbeat
cycle.
Fig. 12. Bland–Altman plots showing the average of the HR measured with
a commercial pulse oximetry and the presented method, plotted against the
difference between them.

TABLE I
PPG DELAY ESTIMATION RESULTS AMONG DIFFERENT SITES
PTT Difference

Test No.
1
2
3
4
5
6
7
8
9

Heart Rate
(bpm)

From mouth to
left palm (ms)

From mouth to
right palm (ms)

72
78
78
72
72
71
106
96
96

22.50
34.50
28.36
30.39
23.35
33.97
25.99
34.56
34.13
29.75
16%

22.28
32.37
29.35
32.23
27.82
35.64
28.26
36.04
35.61
31.07
15%

Average
SD/Average

The values are calculated based on linear curve fitting method.
The estimated delay values obtained from facial area to two
palm areas are similar, about 30–31 ms.

PPG signals by linear curve fitting method (see Fig. 11). Matlab
function “polyfit” was used to predict a linear curve from the
observed signal
p(t) = p1 t + p2 .

result from all the available heartbeat cycles in that time period.
Each test lasted for 30 s.
Matlab functions “findpeaks” and “xcorr” were also used to
estimate the PTT difference value. Function “findpeaks” provides the peak location of the input data by searching for the
local maximum value of the sequence. Function “xcorr” realizes
phase shift estimation between two signals by taking their convolution and searching for the delay that gives the largest convoluted result. However, the standard deviations of the calculated
PTT differences obtained from these two methods were higher
than the standard deviation obtained from the first one (linear
curve fitting method). Therefore, the first method was used to
estimate the PTT differences among different body parts. Test
results in Table I show that the PTT difference between palm and
mouth is about 30 ms. The results are consistent with the values
of PTT difference between ears and fingers reported by other researchers [23]–[25]. The accuracy of PTT difference calculation
can be further improved at faster video frame rates (current value
is 120 frames/s) that help to provide more accurate PPG peak
locations.

(6)
E. Small-Scale Pilot Study

In (6), p1 and p2 are the coefficients of the first order polynomial p(t) that fits to the detected PPG signal.
Fig. 11(a) is an original PPG signal sample obtained from
one subject. One heartbeat cycle (indicated by red dashed rectangle) was selected for further analysis. The peak location of
the selected signal was estimated by fitting two linear curves
on the rising (left part) and falling edge (right part) of the signal [see Fig. 11(b)]. The point of intersection (indicated by the
green arrow) of two linear curves is the estimated peak location. PTT differences were determined by comparing the peak
locations of PPG signals obtained at different body parts (e.g.,
mouth and palm).
Nine tests conducted on one subject were analyzed to obtain
the average value of PTT difference between mouth and palm
areas (see Table I). PTT difference for each test was an average

To demonstrate the robustness of the developed methods to
monitor physiological signals, a small-scale pilot study was
conducted for statistical analyses. Ten subjects were enrolled in
the Institutional Review Board (IRB) study approved by Arizona
State University. The subjects were of different genders (six
males, four females), age (27.3 ± 4.5 years old, mean ± SD),
ethnic profiles and skin colors. Informed consents were obtained
from all subjects following approved protocol.
Bland–Altman plots were used to compare presented physiological signal detection methods with reference technologies. Fig. 12 shows the Bland–Altman plot for HR detection.
The differences between presented noncontact method and a
commercial pulse oximetry (y-axis) were plotted against the
average of the two methods (x-axis). The mean difference
was 0.86 bpm with 95% limits of agreement (±1.96 standard

2766

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 11, NOVEMBER 2014

Fig. 13. Bland–Altman plots showing the average of the breathing rate measured with a commercial device Zephyr and the presented method, plotted
against the difference between them.
TABLE II
PTT DIFFERENCE ESTIMATION RESULTS FOR FOUR SUBJECTS
PTT Difference

Subject No.

Gender

1
2
3
4

Female
Female
Male
Male

Average
SD/Average

From mouth to
left palm (ms)

From mouth to
right palm (ms)

29.75
35.02
32.96
42.03
34.94
15%

31.07
32.06
41.67
43.29
37.02
17%

The calculated values were based on linear curve fitting method.
The average PTT difference between mouth and palm areas was
about 35 ms from mouth to left palm and 37 ms from mouth to
right palm.

deviation) at −2.47 bpm and 4.19 bpm. The root-mean-square
error (RMSE) was 1.87 bpm and r was 0.98 (p < 0.001). Fig. 13
shows the Bland–Altman plot for breathing rate detection. The
differences between presented noncontact method and Zephyr
(y-axis) were plotted against the average of the two methods (x-axis). The mean difference was 0.02 breaths/min with
95% limits of agreement (±1.96 standard deviation) at −2.40
breaths/min and 2.45 breaths/min. RMSE was 1.20 breaths/min.
and r was 0.93 (p < 0.001).
Both the presented method and the reference technologies
can introduce errors in the test results. For statistical analyses,
p < 0.05 is considered to be a significant correlation between
the two compared methods. We, therefore, concluded that the
overall error rates were acceptable.
Pilot study was also conducted for PTT difference calculation.
Ten tests were conducted on four subjects. The average PTT
difference between mouth and palm areas was about 30–40 ms
(see Table II).
IV. CONCLUSION
We have demonstrated optical imaging-based methods for
noncontact monitoring of various physiological signals, including BF, exhalation flow rate, HR and PTT, by detecting facial

color changes associated with blood circulation and body movement associated with breathing. By implementing differential
detection and motion-tracking algorithms, we have accurately
tracked the BF and exhalation volume flow rate, which are robust against moderate body movements unrelated to breathing.
The physiological signals measured by the imaging methods
are consistent with those obtained using reference technologies.
We have also demonstrated for the first time that the difference
in PTT can be determined with a noncontact imaging method
and the results are comparable to those reported by other literature. Furthermore, we carried out a small-scale pilot study
involving subjects of different ethnic profiles, sex and ages
to demonstrate the basic principle of our optical imaging
methods.
The imaging method requires only ambient light using lowcost CMOS imagers (e.g., webcam), which is suitable for tracking physiological parameters under normal indoor conditions.
The method can be readily adapted to various mobile platforms
with a built-in camera, such as cell phones, tablets, etc. The
use of personal mobile devices reduces the privacy concerns
associated with imaging-based detection. Because the approach
is noninvasive, an additional benefit is that the results truly reflect the person’s health status, reducing the known “white coat
effect”—a phenomenon in which patients exhibit elevated blood
pressure in a clinical setting. The noncontact imaging method
also has the potential to measure more physiological parameters
such as blood pressure, blood oxygen saturation, and PWV. Our
current experiments were all conducted with the subject sitting
on a chair. The subject was allowed moderate movements. We
anticipate challenges if the subject has significant movements.
However, we also believe that more accurate motion-tracking
algorithms can be created in the future to overcome the limitation of current method. Nevertheless, our current algorithms
provide accurate tracking of multiple physiological parameters
for people who sit relatively still (e.g., watching TV, reading
books and working on a computer).
ACKNOWLEDGMENT
The authors would like to thank Y. Guan, W. Wang, X. Shan,
X. Xian, and E. Forzani for discussions.
REFERENCES
[1] S. Yu and J. Cheng, “A wireless physiological signal monitoring system
with integrated bluetooth and WiFi technologies,” in Proc. IEEE Eng.
Med. Biol. Soc., Shanghai, China, 2005, pp. 2203–2206.
[2] R. Paradiso, “Wearable health care system for vital signs monitoring,”
in Proc. IEEE Conf. Inform. Technol. Appl. Biomed., Prato, Italy, 2003,
pp. 283–286.
[3] C. G. Scully, J. Lee, J. Meyer, A. M. Gorbach, D. Granquist-Fraser, and
Y. Mendelson, “Physiological parameter monitoring from optical recordings with a mobile phone,” IEEE Trans. Biomed. Eng., vol. 59, no. 2,
pp. 303–306, Feb. 2012.
[4] B. Won and H. Park, “A touchscreen as a biomolecule detection platform,”
Angew. Chem. Int. Ed., vol. 51, no. 3, pp. 748–751, Jan. 2012.
[5] C. C. Y. Poon, Q. Liu, H. Gao, W. Lin, and Y. Zhang, “Wearable intelligent
systems for E-Health,” JCSE, vol. 5, no. 3, pp. 246–256, Sep. 2011.
[6] V. Chandrasekaran, “Measuring vital signs using smart phones,” M.S.
thesis, Dept. Computer Science, Univ. of North Texas, Denton, TX, USA,
pp. 6–16, 2010.

SHAO et al.: NONCONTACT MONITORING BREATHING PATTERN, EXHALATION FLOW RATE AND PULSE TRANSIT TIME

[7] J. Pickett, P. Amoroso, D. V. Nield, and D. P. Jones, “Pulse oximetry and
ppg measurements in plastic surgery,” in Proc. IEEE Int. Conf. Eng. Med.
Biol. Soc., Chicago, USA, 1997, vol. 5, pp. 2330–2332.
[8] P. K. Baheti and H. Garudadri, “An ultra low power pulse oximeter sensor based on compressed sensing,” in Proc. 6th Int. Workshop Wearable
Implantable Body Sens. Netw., Berkeley, USA, Jun. 2009, pp. 144–148.
[9] M. Garbey, N. Sun, A. Merla, and I. Pavlidis, “Contact-free measurement
of cardiac pulse based on the analysis of thermal imagery,” IEEE Trans.
Biomed. Eng., vol. 54, no. 8, pp. 1418–1426, Aug. 2007.
[10] W. Verkruysse, L. O. Svaasand, and J. S. Nelson, “Remote plethysmographic imaging using ambient light,” Opt. Exp., vol. 16, no. 26,
pp. 21434–21445, Dec. 2008.
[11] C. Takano and Y. Ohta, “Heart rate measurement based on a time-lapse
image,” Med. Eng. Phys., vol. 29, no. 8, pp. 853–857, Oct. 2006.
[12] S. Hu, J. Zheng, V. Chouliaras, and R. Summers, “Feasibility of imaging photoplethysmography,” in Proc. Int. Conf. Biomed. Eng. Informat.,
Sanya, China, May 2008, pp. 72–75.
[13] Y. Sun, S. Hu, V. Azorin-Peris, R. Kalawsky, and S. Greenwald, “Noncontact imaging photoplethysmography to effectively access pulse rate
variability,” J. Biomed. Opt., vol. 18, no. 6, pp. 061205, Jun. 2013.
[14] S. Kwon, H. Kim, and K. S. Park, “Validation of heart rate extraction
using video imaging on a built-in camera system of a smartphone,” in
Proc. IEEE Ann. Int. Conf. Eng. Med. Biol. Soc., Seoul, South Korea,
Aug. 28–Sep. 1, 2012, pp. 2174–2177.
[15] M. Z. Poh, D. J. McDuff, and R. W. Picard, “Advancements in noncontact, multiparameter physiological measurements using a webcam,” IEEE
Trans. Biomed. Eng., vol. 58, no. 1, pp. 7–11, Jan. 2011.
[16] M. Z. Poh, D. J. McDuff, and R. W. Picard, “Non-contact, automated
cardiac pulse measurements using video imaging and blind source separation,” Opt. Exp., vol. 18, no. 10, pp. 10762–10774, May 2010.
[17] F. Zhao, M. Li, Y. Qian, and J. Z. Tsien, “Remote measurements of
heart and respiration rates for telemedicine,” PLOS ONE, vol. 8, no. 10,
p. e71384, Oct. 2013.
[18] A. Reisner, P. Shaltis, D. McCombie, and H. Asada, “Utility of the photoplethysmogram in circulatory monitoring,” Anesthesiology, vol. 108, no.
5, pp. 950–958, May 2008.
[19] J. B. de V. Weir, “New methods for calculating metabolic rate with special
reference to protein metabolism,” J. Physiol., vol. 102, nos. 1/2, pp. 1–9,
Aug. 1949.

2767

[20] M. Nitzan, B. Khanokh, and Y. Slovik, “The difference in pulse transit
time to the toe and finger measured by photoplethysmography,” Physiol.
Meas., vol. 23, no. 1, pp. 85–93, Feb. 2002.
[21] P. Boutouyrie, M. Briet, C. Collin, S. Vermeersch, and B. Pannier, “
Assessment of pulse wave velocity,” Artery Res., vol. 3, no. 1, pp. 3–8,
Dec. 2008.
[22] J. C. Bramwell and A. V. Hill, “Velocity of transmission of the pulsewave and elasticity of arteries,” Lancet, vol. 199, no. 5149, pp. 891–892,
May 1922.
[23] S. I. Rabben, N. Stergiopulos, L. R. Hellevik, O. A. Smiseth, S. Slordahl,
S. Urheim, and B. Angelsen, “An ultrasound-based method for determining pulse wave velocity in superficial arteries,” J. Biomech., vol. 37, no.
10, pp. 1615–1622, Oct. 2004.
[24] P. J. Brands, J. M. Willigers, L. A. F. Ledoux, R. S. Reneman, and A. P. G.
Hoeks, “A noninvasive method to estimate pulse wave velocity in arteries
locally by means of ultrasound,” Ultrasound Med. Biol., vol. 24, no. 9,
pp. 1325–1335, Nov. 1998.
[25] J. R. Jago and A. Murray, “Repeatability of peripheral pulse measurements
on ears, fingers and toes using photoelectric plethysmography,” Clin. Phys.
Physiol. Meas., vol. 9, no. 4, pp. 319–329, Nov. 1988.
[26] J. Allen and A. Murray, “Age-related changes in peripheral pulse timing characteristics at the ears, fingers and toes,” Physiol. Meas., vol. 16,
no. 10, pp. 711–717, Oct. 2002.
[27] C. D. Maria, E. Sharkey, A. Klinge, D. Zheng, A. Murray,
J. O’Sullivanand, and J. Allen, “Feasibility of monitoring vascular ageing
by multi-site photoplethysmography,” in Proc. Comput. Cardiology, 2012,
pp. 817–820.
[28] A. Babchenko, E. Davidson, D. Adler, Y. Ginosar, V. Kurz, and M. Nitzan,
“Increase in pulse transit time to the foot after epidural anaesthesia treatment,” Med. Bio. Eng. Comput., vol. 38, no. 6, pp. 674–679, Nov. 2000.
[29] S. Jin and G. Koh, “A robust image tracker based on phase correlation and
fourier-mallin transform,” in Proc. Int. Conf. Control Autom. Syst., Seoul,
Korea, Oct. 2008, pp. 1028–1031.

Authors’ photographs and biographies not available at the time of publication.

