1614

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

Brain–Computer Interface Classifier for Wheelchair
Commands Using Neural Network With Fuzzy
Particle Swarm Optimization
Rifai Chai, Student Member, IEEE, Sai Ho Ling, Senior Member, IEEE, Gregory P. Hunter, Member, IEEE,
Yvonne Tran, and Hung T. Nguyen, Senior Member, IEEE

Abstract—This paper presents the classification of a three-class
mental task-based brain–computer interface (BCI) that uses the
Hilbert–Huang transform for the features extractor and fuzzy particle swarm optimization with cross-mutated-based artificial neural network (FPSOCM-ANN) for the classifier. The experiments
were conducted on five able-bodied subjects and five patients with
tetraplegia using electroencephalography signals from six channels, and different time-windows of data were examined to find
the highest accuracy. For practical purposes, the best two channel
combinations were chosen and presented. The three relevant mental tasks used for the BCI were letter composing, arithmetic, and
Rubik’s cube rolling forward, and these are associated with three
wheelchair commands: left, right, and forward, respectively. An
additional eyes closed task was collected for testing and used for
on–off commands. The results show a dominant alpha wave during
eyes closure with average classification accuracy above 90%. The
accuracies for patients with tetraplegia were lower compared to
the able-bodied subjects; however, this was improved by increasing the duration of the time-windows. The FPSOCM-ANN provides
improved accuracies compared to genetic algorithm-based artificial neural network (GA-ANN) for three mental tasks-based BCI
classifications with the best classification accuracy achieved for
a 7-s time-window: 84.4% (FPSOCM-ANN) compared to 77.4%
(GA-ANN). More comparisons on feature extractors and classifiers
were included. For two-channel classification, the best two channels were O1 and C4, followed by second best at P3 and O2, and
third best at C3 and O2. Mental arithmetic was the most correctly
classified task, followed by mental Rubik’s cube rolling forward
and mental letter composing.
Index Terms—Artificial neural network (ANN), brain–computer
interface (BCI), electroencephalography (EEG), Hilbert–Huang
transform (HHT), particle swarm optimization (PSO).

Manuscript received June 11, 2013; revised October 5, 2013 and December
1, 2013; accepted December 8, 2013. Date of publication December 12, 2013;
date of current version September 2, 2014.
R. Chai, S. H. Ling, G. P. Hunter, and H. T. Nguyen are with the Centre for Health Technologies, Faculty of Engineering and Information Technology, University of Technology, Sydney, N.S.W. 2007, Australia (e-mail:
Rifai.Chai@student.uts.edu.au; Steve.Ling@uts.edu.au; Greg.Hunter@uts.
edu.au; Hung.Nguyen@uts.edu.au).
Y. Tran is with the Centre for Health Technologies University of Technology, Sydney, N.S.W. 2007, Australia, and also with the Rehabilitation
Studies Unit, University of Sydney, Sydney, N.S.W. 2008, Australia (e-mail:
Yvonne.Tran@uts.edu.au).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2013.2295006

I. INTRODUCTION
ONINVASIVE brain–computer interface (BCI) using
electroencephalography (EEG) to measure electrical brain
signals that reflect user intentions can be used to provide a new
nonmuscular output for communication and control to create
a human–computer interfacing technology [1]–[3]. Compared
to invasive BCI [4], EEG is still the preferable tool of BCI in
terms of portability and cost benefit. To improve mobility of
individuals with severe disability such as cervical spinal cord
injury (SCI) or tetraplegia, brain stem stroke, and amyotrophic
lateral sclerosis, BCI provides an alternative method for handsfree-powered wheelchair control [5]. Here, at least three basic
commands are needed to move the wheelchair left, right, and
forward [6]–[8].
Currently, EEG-based BCIs can be divided into two strategies
for control: selective attention and spontaneous mental signal.
For the selective attention strategy, BCI relies on external stimuli
which might be uncomfortable for severely disable individuals
who need to focus on external stimuli and the environment
simultaneously. This is not the case for BCIs which rely on
spontaneous mental signals initiated by the users themselves.
BCIs that use sensory-motor rhythm (SMR) form one of the
examples of spontaneous mental strategy, based on the eventrelated desynchronization/synchronization which are produced
by imagining hand, foot, or tongue movements with corresponding EEG electrodes positioned primarily over the motor cortex
regions [9]–[11].
There have been many reports in research using SMR-based
BCI; however, there are still some people who are unable to
use this, as in BCI illiteracy phenomenon [12]. Selective motor
imagery task defects in severely disabled patients were also reported [13]. Furthermore, individuals who have been paralyzed
or are amputees for a number of years may be unable to perform
motor imagery mental tasks effectively [14], [15]. People who
have motor cortex impairment such as particular stroke patients
will be problematic using the SMR. Thus, nonmotor imagery
mental tasks can be used to provide more options for disabled
groups [6], [16]–[19].
The other possible solution is by improving accuracy classification via computational intelligence with improved features
extraction and classification algorithms [20]–[22]. Features extraction based on fast Fourier transform (FFT) has been used
widely in the EEG-based BCI. However, the Hilbert–Huang
transform (HHT) has been shown to provide a better result

N

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

CHAI et al.: BRAIN–COMPUTER INTERFACE CLASSIFIER FOR WHEELCHAIR COMMANDS

1615

TABLE I
ABLE-BODIED SUBJECTS AND PATIENTS WITH TETRAPLEGIA DETAILS

Fig. 1.

Components of mental task-based BCI.

compared to conventional FFT to tackle nonlinear and nonstationary signals of mental tasks for EEG-based BCI [19]. For
the classification algorithm, artificial neural network (ANN)
is known as a nonlinear classification method and has been
used to handle the mental task-based BCI [6], [18], [19]. A
genetic algorithm-based ANN (GA-ANN) has been applied to
optimize the ANN training in the mental task-based BCI [18],
[19]. Recently, an improved optimization technique using fuzzy
particle swarm optimization with the cross-mutated operation
(FPSOCM) was proposed [23]. In FPSOCM, the fuzzy inertia
weight that provides nonlinearity characteristics can offer an
enhanced searching quality; the cross-mutated (CM) operation
can effectively handle the drawback of trapping in local optima. This paper explores further use of the FPSCOCM-ANN
algorithm in BCI applications.
The contributions of this paper are as follows: first, this
paper combines the neural-network classifier with the fuzzy
particle swarm optimization with cross-mutated operation
(FPSOCM-ANN) for a three class of mental task-based BCI
classification. The features extraction method is based on the
HHT. For comparison purposes, different classifiers and feature
extractors are included to find the best algorithms with the highest accuracy. The nonmotor imagery mental tasks used are letter
composing, arithmetic, and figure Rubik’s cube rolling forward,
which can be mapped for three wheelchair commands: left,
right, and forward. An additional eyes closed task is recorded
as well for testing an on–off command. Second, most of the
results of the mental task-based BCI were from experiments on
able-bodied subjects only. This paper includes five able-bodied
subjects and five patients with tetraplegia. Third, different timewindows of data are investigated to find the best data windowing
with an improved result of classification accuracy. Fourth, for
practical reasons, results of combinations of two-channel classification are presented to find the two channels of EEG signals
suitable for mental task-based BCI.
The structure of this paper is as follows: Section II covers the methodology: general structure, data collection, feature
extraction methods, and classification algorithms. Section III
describes results and discussion, followed by Section IV for the
conclusion.
II. METHODOLOGY
A. General Structure
Fig. 1 illustrates the basic components for the nonmotor imagery mental task-based BCI for this paper. This starts from
data collection by using EEG, followed by a signal preprocessing module: window segmentation and digital filters. Next, a

Fig. 2.

Experiment setup of EEG-BCI with patients with tetraplegia.

features extraction module transforms the signals into useful
features. The features are processed into a classification algorithm, in this case, an ANN which includes optimization, training, and classification tasks. The outputs classification can be
mapped to the three wheelchair steering commands.
B. Experimental Data Collection
The Human Research Ethics Committee of University of
Technology, Sydney, approved this study. A total of ten participants were involved: five able-bodied subjects (S1–S5) aged
between 25 and 35 years; five patients with tetraplegia (T1–T5)
aged between 45 and 80 years who suffer a high-level of SCI in
the cervical area at level C3, C4, C5, and C6 with the details as
shown in Table I and Fig. 2.
A commercial 32-channel EEG system, from Compumedics
was used with the sampling rate of the system at 256 Hz. This
study used six channels with the electrodes positioned at locations C3, C4, P3, P4, O1, and O2. The left earlobe (A1) was
used as the reference and the GND electrode was attached to
the right earlobe (A2) as shown in Fig 2. This configuration
refers to the standard 10–20 electrode montage system [24].
During the experiment, the EEG gel was applied; the electrode
contact impedance was measured and maintained below 5 kΩ.
Participants were asked to keep eye blinks, and unnecessary
movements to a minimum during the experiment. Data with
strong presence of artifacts were discarded.
As an offline study, a proper standard protocol is needed to
ensure all participants perform tasks correctly. A total of three
nonmotor imagery mental tasks were used including mental letter composing, arithmetic, and a figure of Rubik’s cube rolling.
Prior to the beginning of the session, participants were shown
a video as a guidance to perform mental tasks for the standard
protocol of measurement. Participants were asked to mentally

1616

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

perform the following tasks: composing words in their mind,
solving multiplication problems, and imagining figure Rubik’s
cube rolling in a forward direction. Additional eyes closed and
open tasks were also recorded for testing. The experiment was
recorded at ten sessions for each mental task with each session
lasting 15 s of recording time. The first 3 s of data were discarded for preparation time, and the remaining 12 s of data were
recorded for further signal processing.
Fig. 3.

C. Preprocessing and Feature Extraction Algorithms
For digital signal preprocessing, different moving timewindow segmentations from 1 until 10 s, were applied with
a quarter second segment. As a result, for ten sessions in each
mental task, each participant provided data of 450 sets for a 1-s
time-window, 410 sets for a 2-s time-window, 370 sets for a
3-s time-window, 330 sets for a 4-s time-window, 290 sets for a
5-s time-window, 250 sets for 6-s time-window, 210 sets for 7-s
time-windows, 170 sets for 8-s time-window, 130 sets for 9-s
time-window, and 90 sets for 10-s time window. This was further processed by applying digital signal processing filters using
a Butterworth bandpass filter (0.1–100 Hz) and a Butterworth
notch filter at 50 Hz for a signal-to-noise ratio improvement.
The HHT based on the time–frequency analysis was used for
the features extraction method [25]. In this study, HHT provided
good results for nonlinear and nonstationary EEG signals [19],
[26], [27]. There are two basic processes in HHT: empirical
mode decomposition (EMD) to decompose the time series of
data into sets of intrinsic mode function (IMF), and applying
the Hilbert Transform (HT) to obtain a spectrum of HHT [25]
as follows:
x(t) =

n


ANN structure for mental task-based BCI.

quencies and the last IMF representing the residue. For the EEG
data, the spectrum of the HHT for the features covers the following EEG band: δ (1–3 Hz), θ (4–7 Hz), α (8–13 Hz), and
β (14–30 Hz) in the frequency range from 1 to 30 Hz. Consequently, the input feature on each channel has 30 units and with
the six EEG channels resulting in 180 units of input features and
with two EEG channel, resulting in 60 units. Comparisons with
other features including FFT, wavelet, and an improved EMD
feature extractor are given in Section III.
D. Classification Algorithm
To do classification of the mental tasks, an ANN was used.
The ANN as a nonlinear classification method has been widely
explored for biomedical application [28], [29] including the
EEG-based BCI [6], [18], [19]. This study used a three-layer
feedforward neural network as shown in Fig. 3. The ANN model
and normalization are as follows:
⎛
	

⎞
m
n


wk j f2 bj +
wj i x∗n ⎠ (7)
zk (x, w) = fi ⎝bk +
j =1

ci (t) + rn (t)

(1)

i=1

where x(t) denotes the segment of EEG data, ci (t) is the ith
extracted IMF, rn (t) is the residual, and n denotes the number
of data points. The HT provides the instantaneous amplitude and
frequency as a function of time as represented in the spectrum
of HHT. The HT of IMF yi (t), the amplitude ai (t), the phase
ϕI (t), and the frequency ωi (t) are
 ∞
yi (t) = 1/π
(ci (τ )/(t − τ ))dt
(2)
−∞


ai (t) = yi (t)2 + ci (t)2

(3)

ϕi (t) = arctan(yi (t)/ci (t))

(4)

ωi (t) = dϕi (t)/dt.

(5)

For the initial testing of the HHT, a known combination of
four sinusoidal signals was used with the equation as follows:
π 
t + sin(πt) + 0.5 sin(10πt)
x(t) = 0.5 sin
10
+ 0.5 sin(40πt).
(6)
If the HHT method correctly handles the signal, the EMD
process of the first HHT step should comprise five IMFs with
four IMFs representing four signals of sinusoids at certain fre-

∗

x = (x − xm in )/(xm ax − xm in )

i=1

(8)

where f1 and f2 are the activation functions and log-sigmoid
function is used in this paper, n refers to the number of input
nodes, m refers to the number of hidden nodes, k refers to the
number of output nodes, bj and bk are the biases, wj i refers to
the weight to the hidden unit yj from input unit xi , wk j refers
to the weights to output unit zk from hidden unit yj , x∗ is the
input features after normalization, x is the input features before
normalization, xm in represents the minimum, and xm ax refers to
the maximum value of the input. As the activation function uses
the log-sigmoid function, prior to ANN training; the features
need to be normalized into the range of zero to one using (8).
For the ANN training, FPSOCM [23] was used with the algorithm pseudocode shown in Fig. 4.
A fuzzy inertia weight ω̃(t) and a CM operation were introduced for performance searching improvement and to tackle
the issue of trapping in local optima. The FPSOCM process
was started by the initialization of the particle swarm X(t)
with generation number t = 0. The X(t) was constructed with
wj i , wk j , bj , and bk of ANN. Each particle was evaluated by the
cost-objective (fitness) function, f (X(t)). The probability of
the CM operation for each particle (pcm ) was defined before the
iteration sequences had begun. The value of the inertia weight
(ω̃(t)) was selected to improve the searching performance and

CHAI et al.: BRAIN–COMPUTER INTERFACE CLASSIFIER FOR WHEELCHAIR COMMANDS

Fig. 4.

1617

Fig. 5.

EMD process for four known combined sinusoidal signals.

Fig. 6.

EMD process of eyes closed signal at 1-s time-window.

Fig. 7.

HHT spectrum of eyes-closed signal at a 1-s time-window.

FPSOCM procedure.

controlled by two inputs of the fuzzy inference system (FIS),
the normalized standard deviation of the cost value among all
the particles, ||ς(t)|| and the iteration stage, t/T . After the ω̃(t)
was found, the particle velocity/v(t) was updated. This was
continued by finding the control parameter, β(t) of the CM by
using the FIS. The velocity of each element swarm particle was
evaluated by the CM operation. A random particle (Rcm ) in the
range of 0 and 1 was generated. If the value of Rcm is more than
the value of pcm , the CM operation will be undertaken on that
particular element. Next, a new particle swarm was generated.
The process was continued and repeated until iteration number
(T ) as defined in the beginning was met.
The objective of the FPSOCM-ANN training is to minimize
the fitness (cost) values interactively with the fitness function
ﬁtness = 1/(1 + err)

(9)

where fitness denotes the fitness value and err is the mean square
error (MSE). It can be seen from the defined formula that a larger
fitness value implies a smaller MSE.
For the performance measurement, classification accuracy
was used in this paper as evaluation criteria. This is a widely
used evaluation criteria in BCI. Comparisons of classifier are
given including GA-ANN, support vector machine (SVM), linear discriminate analysis (LDA), and linear perceptron are given
in the next section.
III. RESULTS AND DISCUSSIONS
A. Testing the HHT as the Features Extractor
Initial testing was conducted for the HHT with a known signal of four combination sinusoid signals as defined in (6). The
result is shown in Fig. 5, EMD as the first step of HHT for
this signal was composed correctly of five IMFs with the first
four IMFs representing the four defined sinusoidal signals at
different frequencies and the fifth IMF representing the residue.
It has been known that during the eyes closed task, there is a
dominant feature in the alpha band of EEG (8–13 Hz) [30]. This

unique feature can be used for further testing to ensure that the
HHT method is correctly converting the raw EEG signal into
correct features.
The segmented EEG feature data (eyes closed task) was processed and converted into a series of IMFs and residue in the
EMD process as shown in Fig. 6. This was followed by applying
the HT method to the IMFs resulting in the amplitude and instantaneous frequency as functions of time. The plotting of the
HHT spectrum in Fig. 7 for the eyes closed task shows a clear
dominant feature of the instantaneous frequency of the alpha
EEG band (8–13 Hz). This proves that the features extraction
method has correctly converted EEG data for the eyes closed
task into the proper feature.

1618

Fig. 8.

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

Accuracy of eyes closed-opened action at 1-s time-window.

B. Classification Using FPSOCM-ANN at Different
Time-Windows and Comparison With GA-ANN
The training of the neural network was repeated ten times
for each different hidden neuron; thus, the reported accuracies
were the mean value of ten results of accuracies. The number
of hidden neurons was varied from 4 to 30 units to obtain the
best number with the lowest MSE and highest classification
accuracy. The parameters for FPSOCM were as follows: The
swarm size is 50, number iteration is 2000, both acceleration
constants are 2.05, maximum velocity is 0.2, and probability of
each CM is 0.0005.
The accuracy of the FPSOCM-ANN classifications in Fig. 8
shows the eyes closed and open experiments resulted in average
accuracy above 90% for able-bodied participants and patients
with tetraplegia. The high accuracy for eyes closed-open classification proves that the HHT algorithm was able to generate
distinct features for FPSOCM-ANN classification. The eyes
closed task can also be used for the additional on–off command
in the application of the BCI-based wheelchair control.
The GA-ANN from the previously applied mental-based
BCI method [18] was also used for initial comparison with
FPSOCM-ANN. This includes the following characteristics:
real-code genetic algorithm, selection operation using normalized geometric ranking, crossover operation based on Blend-α
crossover, and nonuniform operation for the mutation operation.
For comparison purposes, the classifier in this study used a globally trained classifier and subject’s specifically trained classifier.
This is due to the large differences in EEG-based BCI known
as intersubject variability [31], [32] which could affect different
performances. The features from different time-windows were
divided into training and testing sets. A k-fold cross validation
is one of the most popular methods for BCI machine learning
evaluation [33], [34]. As a result, this paper also used k-fold
cross-validation (k = 3) with the mean value of ten results of
accuracies on each fold. The mean value accuracy of three folds
was used for each participant.
Next, Table II shows the accuracies between GA-ANN and
FPSOCM-ANN to classify three mental tasks (letter composing, arithmetic, and figure of Rubik’s cube rolling forward) in
different time-windows (1 to 10 s) with five able-bodied subjects
(S1–S5) and five patients with tetraplegia (T1–T5).
Between 1- to 6-s time-windows, the average accuracies for
able-bodied subjects were increased in each higher time-window

between 67.3 ± 5.7% and 76.5 ± 7.9% using GA-ANN. These
were improved using FPSOCM-ANN compared to GA-ANN
with improved accuracies between 72.0 ± 3.9% and 83.9 ±
6.7%. Patients with tetraplegia resulted in accuracies of between
59.7 ± 1.5% and 74.4 ± 4.2% using GA-ANN and improved
accuracies based on FPSOCM-ANN with an average accuracy
of between 63.0 ± 1.0% and 81.8 ± 3.8%. The overall mean
accuracy of three mental tasks classification between 1- to 6-s
time-windows for both groups were between 63.5 ± 5.6% and
75.5 ± 6.1% with GA-ANN and improved accuracies between
67.5 ± 5.5% and 82.9 ± 5.2% were found with FPSOCM-ANN.
The highest overall accuracy was reached at 7-s timewindow with improved accuracies for both groups compared
to previous time-windows. In detail, the average accuracy of
five able-bodied subjects was 79.0 ± 8.6% using the GAANN method and improved accuracy at 85.5 ± 5.5% using
FPSOCM-ANN. On five patients with tetraplegia, the average accuracy resulted at 75.9 ± 5.3% using GA-ANN and
this accuracy was increased using FPSOCM-ANN with an
average accuracy at 83.3 ± 6.0%. The overall average accuracy of three mental tasks classification for two groups
combined at a 7-s time-window was 77.4 ± 6.9% using
GA-ANN and improved accuracy at 84.4 ± 5.5% using
FPSOCM-ANN.
Compared to the previous time-window, the overall accuracies between 8- and 10-s time windows were much more in
a steady value. The average accuracies for able-bodied subjects were between 77.2 ± 7.6% and 78.0 ± 6.9% with GAANN. These were improved using FPSOCM-ANN compared
to GA-ANN with accuracies of around 84.6 ± 5.3%. For patients with tetraplegia, accuracies using GA-ANN were between
75.4 ± 4.8% and 76.9 ± 6.4 and improved accuracies based on
FPSOCM-ANN with an average accuracy of around 83.4 ±
5.4%. The overall accuracies of three mental tasks classification
between 8- to 10-s time-windows for both groups were between
76.5 ± 6.7% and 77.1 ± 6.6% with GA-ANN and improved
accuracies of around 84.0 ± 5.1% using FPSOCM-ANN.
In general, for three mental task classifications, the results
show an overall improved accuracy for the classification algorithm using FPSOCM-ANN compared to GA-ANN across
both groups and in different time-windows. For comparison between able-bodied subjects and patients with tetraplegia, the
patients’ group provided lower classification accuracy. However, the accuracy was improved by increasing the duration of
the time-window with at best achieved accuracy for a 7-s timewindow of 77.4% based on GA-ANN and improved accuracy
of 84.4% using FPSOCM-ANN. From this experiment, patients
with tetraplegia tend to have better classification accuracy when
increasing the time-window which means they need more time to
perform the mental tasks due with their disability issue. This can
be found using FPSOCM-ANN, where for a 1-s time-window,
patients with tetraplegia achieve an accuracy of 63% compared
with 72% for able-bodied subjects. The patients group had accuracy around 9% lower than the able-bodied group. At 7-s timewindow, the accuracy difference between both groups was much
smaller at only 2.2% with accuracy for patients with tetraplegia
of 83.3% and able-bodied subject of 85.5%.

CHAI et al.: BRAIN–COMPUTER INTERFACE CLASSIFIER FOR WHEELCHAIR COMMANDS

1619

TABLE II
COMPARISON ACCURACIES BETWEEN GA-ANN AND FPSOCM-ANN OF SIX CHANNELS FOR THREE MENTAL TASK CLASSIFICATIONS (ARITHMETIC, LETTER
COMPOSING, AND CUBE ROLLING FORWARD) IN DIFFERENT TIME-WINDOWS WITH FIVE ABLE-BODIED SUBJECTS AND FIVE PATIENTS WITH TETRAPLEGIA

C. Further Comparison Classifiers and Features Extractors
Further comparisons are carried out between different classifiers and feature extractors as shown in Table III using the
7-s time-window of data as the best time window. Due to the
output classifier using three mental tasks, instead of using a
binary classifier, the comparison classifiers need a multiclass
model. These classifiers are: multiclass linear perceptron classifier with the Kesler’s construction [35], multiclass LDA with
the Fisher kernel [36], [37], and multiclass SVM using BSVM
(B refers to the added bias) [35], [38]. For the feature extraction methods comparison, FFT [18] and wavelet [39] methods
are presented. The discrete wavelet transform with Daubechies
type as the mother wavelet in a five-level decomposition was
used in accordance with previous BCI–EEG analyses [40], [41].
There are improvements on the original HHT especially with
the EMD analysis available [42], [43]. The HHT using the ensemble empirical mode decomposition (EEMD) [43] was also
included.
The result shows that the multiclass linear perceptron classifier provided an overall mean accuracy of: 63.7 ± 2.5% using
the FFT, 67.1 ± 2.8% using the wavelet, 71 ± 4.5% using the
HHT-EMD, and 71.7 ± 3.8% using the HHT-EEMD. The accuracies are slightly improved across different feature extractors

when using the multiclass LDA classifier with the overall mean
accuracy of: 64.8 ± 3.3% using the FFT, 68.1 ± 2.7% using the
wavelet, 72.1 ± 4.5% using the HHT-EMD, and 72.5 ± 4.4%
using the HHT-EEMD. The multiclass SVM classifier provided
improved results across different features extractors to the previous two methods with overall mean accuracy of: 66.9 ± 2.7%
using FFT, 70.6 ± 3.2% using wavelet, 77.0 ± 6.6% using
HHT-EMD, 63.7 ± 2.5% and 76.8 ± 5.6% using HHT-EEMD.
For the GA-ANN classifier, the accuracy is further improved
compare to previous classifiers with the overall accuracy of:
67.8 ± 3.4% using FFT, 71.8 ± 3.3% using wavelet, 77.4 ± 6.9%
using HHT-EMD, and 77.9 ± 6.7% using the HHT-EEMD. The
FPSOCM-ANN classifier provided the most improvement with
the overall mean accuracy of: 70.7 ± 2.9% using FFT, 75.7 ±
4.1% using wavelet, 84.4 ± 5.5% using HHT-EMD, and 84.5 ±
4.9% using HHT-EEMD.
The neural networks classifiers (GA-ANN and FPSOCMANN) with the optimization methods in this study provide better
results compared to the linear perceptron, LDA and SVM methods. The FPSOCM-ANN provided the best classifier among
other classifiers. The HHT as the feature extractor has higher accuracy compared to FFT and wavelet methods. In the FPSOCMANN, it can also be seen that there is a comparable accuracy

1620

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

TABLE III
COMPARISONS BETWEEN DIFFERENT CLASSIFIERS AND FEATURE EXTRACTORS USING 7-S TIME WINDOW OF DATA

between HHT-EMD and HHT-EEMD in this study; thus, both
methods can be used.
A statistical significance test using p-value is presented in
Table IV to evaluate the significant difference of classifiers.
The result shows the FPSOCM-ANN classifier compared to
GA-ANN, SVM, LDA, and linear perceptron with all of the p
values less than 0.05. A p-value less than 0.05 is considered
statistically significant with a 95% confidence level.
D. Comparison Between the Globally Trained Classifier and
the Subject’s Specifically Trained Classifier
For the intersubject variability in BCI using the EEG issue,
the comparison between the globally trained classifier and the

subject’s specifically trained classifier is presented. This can be
seen in Fig. 9 using the 7 s as the best time-window with the
total dataset for each mental task of 210 sets per participant. A
threefold cross validation was used to evaluate the performance
of the BCI classification accuracy. For the globally trained classifier, the datasets from six participants were used for classifier
training including portions of data from three able-bodied subjects (S1, S2, and S3) and portions of data from three patients
with tetraplegia (T1, T2, and T3) at the best time-window. The
same six participants (S1, S2, S3, T1, T2, and T3) provided
portions of data for the testing dataset. Also, the remaining participants (S4, S5, T4, and T5) were then treated as new users
with all of their data used for the testing set only. For subject’s
specifically trained classifiers, there were ten participants: five

CHAI et al.: BRAIN–COMPUTER INTERFACE CLASSIFIER FOR WHEELCHAIR COMMANDS

1621

TABLE IV
STATISTICAL SIGNIFICANT USING OVERALL MEANS CLASSIFICATION ACCURACIES AT 7 S OF TIME WINDOW

TABLE V
COMPARISON OF TRAINING TIMES AND CLASSIFICATION TIMES

Fig. 9. Comparison of accuracy between the globally trained classifier and
subject’s specifically trained classifier.

able-bodied subjects (S1, S2, S3, S4, and S5) and five patients
with tetraplegia (T1, T2, T3, T4, and T5), who provided their
portions of data for training and testing at the best time-window.
The results show comparable accuracies only for able-bodied
subjects and patients with tetraplegia (S1, S2, S3, T1, T2, and
T3) who have been provided with their portions of dataset for
the training of the classifier, while for the S4, S5, T4, and T5
subjects who are treated as new users of the system, a large drop
of accuracies resulted. The drop in these accuracies was large
for the globally trained classifier: S4 at 75.11%, S5 at 67.17%,
T4 at 63.08%, and T5 at 78.5%. Compare this to the subject’s
specifically trained classifier: S4 at 89.5%, S5 at 76.4%, T4 at
91%, and T5 at 84.4%. As a result, the overall accuracy for the
globally trained classifier has also dropped with mean accuracy
at 78.5%, compared to each subject specifically trained classifier
with mean accuracy at 84.4%. This proves the intersubject variability issue for the EEG-based BCI system. It shows that the
subject’s specifically trained classifier is preferable. The other
option is the globally trained classifier with adaptive retraining
to enable the classifier to adapt to the data generalization from
the new subject who was previously unseen by it.
E. Computational Time of Classifiers
Using the HHT as the chosen feature extraction, the comparison of training times and classification times for the different classifiers (linear perceptron, LDA, SVM, GA-ANN, and
FPSOCM-ANN) are given in Table V. The training time of
globally and subject’s specifically trained classifiers are presented with the same value classification (execution) time. This
computational time is estimated by MATLAB’s built-in tic/toc
functions, whereas the tic function was called before the program and the toc afterward on the computer (Intel Core i5–2400
processor 3.10 GHz, 4-GB RAM). The results show the train-

ing times of linear perceptron, LDA, and SVM classifiers were
faster than ANN-based classifiers being less than 10 s for the
subject’s specifically trained classifier and less than 2 min for the
globally trained classifier. For the ANN classifiers, the training
time for FPSOCM-ANN was faster compared to the GA-ANN
at around 3 min for the subject’s specifically trained classifier
and at around 15 min for the globally trained classifier. The
GA-ANN required the longest duration of time for the training compared to other classifiers at 11 min for the subject’s
specifically trained classifier and 45 min for the globally trained
classifier. In terms of the classification/execution time, all classifiers were able to complete the task in less than a second. The
program developed in MATLAB takes more computational time
compared to C language with significantly faster training time.
Note that for the classification, the reason that ANN-based
classifiers (GA-ANN and FPSOCM-ANN) were able to perform
as fast as other classifiers was because, after the ANN training,
final weights were treated as constants in the ANN feedforward
classification routine based on (7). This was the same for the
real-time BCI environment. There was no need to perform the
training classifier again during the real-time classification. Furthermore, the time-window was needed for the BCI real-time
operation as discussed in the previous section with the best at
7 s. As a result, there is sufficient time available even using a
1-s time-window for FPSOCM-ANN as the best classifier with
highest accuracy to perform continuous real-time classification
until the next time-window elapses.
F. Reduced EEG Channels for Practical Application
For more practical application purposes, the number of EEG
channels was reduced from six channels to two channels. From
the asymmetry of the channels location point of view, the locations can be divided into left and right groups: C3, P3, and O1
for the left channels’ group; C4, P4, and O2 for the right channels group. As a result, there are nine two-channel combinations
found from the two groups which are: C3&C4, C3&P4, C3&O2,
P3&C4, P3&P4, P3&O2, O1&C4, O1&P4, and O1&O2. Ta-

1622

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

TABLE VI
MEANS OF ACCURACIES OF TWO CHANNELS COMBINATIONS OF THREE
MENTAL TASKS CLASSIFICATION IN 7-S TIME-WINDOW WITH FIVE
ABLE-BODIED SUBJECTS (S1–S5) AND FIVE PATIENTS WITH TETRAPLEGIA
(T1–T5) USING FPSOCM-ANN

ble VI shows the accuracy for nine combinations of two EEG
channels of the three mental task classifications at 7-s-time window using FPSOCM-ANN. The results show that there was a
variety of chosen channels for each participant that provided
the best accuracy. The first able-bodied subject (S1) had the
best mean accuracy of 81.6% using the O1&O2 channels. The
fifth able-bodied subject (S5) had the best mean accuracy of
75.7% using the O1&P4 channels. The second patient with
tetraplegia (T2) had the best mean accuracy of 82.4% using the
P3&C4 channels. Five participants had the best accuracy using
the O1&C4 channels including the second able-bodied subject
(S2) with accuracy of 76.2%, third able-bodied subject (S3) with
accuracy of 87.1%, the first patient with tetraplegia (T1) with
accuracy of 83.6%, the fourth patient with tetraplegia (T4) with
an accuracy of 76.5%, and the fifth patient with tetraplegia (T5)
with accuracy of 88.1%. Two participants had the best accuracy
using the P3-O2 channels including the fourth able-bodied subject (S4) with an accuracy of 85.7%, the second patient with
tetraplegia, and the third patient with tetraplegia (T3) with an
accuracy of 79.4%.
For the overall mean of accuracy as a generalization, O1&C4
are the best two channels with accuracy at 80.5 ± 4.8%. This is
followed by the second option for two-channel EEG at P3&O2
with an overall mean of accuracy of 76.4 ± 5.6%. The third
option of two channels EEG was C3&O2 with an accuracy of
75.4 ± 5%. Between six channels (C3, C4, P3, P4, O1, and
O2) and the best two channels (O1&C4) at 7-s time-window,
the accuracy of six channels was 84.4 ± 5.5% and the best two
channels (O1&C4) was almost comparable accuracy at 80.5 ±
4.8%. The two channels option with less EEG electrodes is
preferable for a practical system as it still provides an accuracy
of above 80%.
Table VII shows the accuracy with correctly classified rates
for each mental task as the three-class classification using
FPSOCM-ANN at 7-s time windows of six EEG channels and
the best two EEG channels (O1&C4). Overall, mental arithmetic
has the best classification accuracy compared to other tasks with

TABLE VII
ACCURACIES AND CORRECTLY CLASSIFIED RATES OF EACH MENTAL TASK IN
7-S TIME-WINDOW WITH FIVE ABLE-BODIED SUBJECTS (S1–S5) AND FIVE
PATIENTS WITH TETRAPLEGIA (T1–T5) USING FPSOCM-ANN FOR SIX
CHANNELS (C3, C4, P3, P4, O1, AND O2) AND THE BEST TWO CHANNELS
(O1&C4) EEG

an average of the correctly classified rate of 89.3 ± 5.5% for six
EEG channels and 85.2 ± 5.4% for the best two EEG channels.
This is followed by mental Rubik’s cube rolling forward with
average correctly classified rate of 84.6 ± 6.8% for six EEG
channels and 78.5 ± 9.1% for the best two EEG channels. The
mental letter composing has a lower correctly classified rate
compared to the previous two tasks of 79.3 ± 8.7% for six EEG
channels and 77.8 ± 5.5% for two EEG channels.
The classifier training is done automatically by using the
FPSOCM-ANN classifier as a machine learning procedure. The
weights for the best accuracy are saved as constants to provide
a feedforward ANN classification. For the classification, it is a
straightforward calculation and does not require training at all.
Therefore, the classification function is final detection of the
mental task and the calculation is less than a second.
IV. CONCLUSION
The classifications of three nonmotor imagery mental tasks
have been applied in this paper with ten participants (five ablebodied subjects and five patients with tetraplegia). The HHT
was used for the features extraction method and the FPSOCMANN for the classification algorithm compared to GA-ANN.
The number of EEG channels used at first is six channels
(C3, C4, P3, P4, O1, and O2). Initial testing of the feature
extractor shows that the HHT composed correctly for the EMD
process with the known combinations of sinusoid signal. Furthermore, HHT testing for the eyes closed EEG signal shows a
correct dominant alpha (8–13 Hz) wave with high classification
accuracy for both groups of participants. Results for three mental tasks classification show improved accuracy of FPSOCMANN compared to GA-ANN and other classifiers in multiclass
mode (SVM, LDA, and linear perceptron) across both groups
and different time-windows. Although the patients group has
lower classification accuracy, this is improved by increasing the

CHAI et al.: BRAIN–COMPUTER INTERFACE CLASSIFIER FOR WHEELCHAIR COMMANDS

time windows with the best classification accuracy achieved at
a 7-s time-window. For practical use of a BCI, combinations of
two-channel EEG have also been presented with the variation
result of the best two channels in each subject. For overall generalization of both groups, O1 and C4 are the best two channels,
followed by the second best at P3 and O2, and the third best at
C3 and O2 channels. For each correctly classified mental task,
the arithmetic task has the highest rate of classification, followed
by the rolling cube task and letter composing task. In the online
application as future work, these three nonmotor imagery mental
tasks can be directly mapped into three wheelchair commands.
For example, the mental letter composing task is used for left
command, arithmetic mental task for right command, and imagining a rolling cube for forward command. An additional eyes
closed task can be used for on–off command. The users perform
the imagery mental task at will which are initiated by users’
themselves (self-paced) for the wheelchair control application.

REFERENCES
[1] J. R. Wolpaw, N. Birbaumer, D. J. McFarland, G. Pfurtscheller, and
T. M. Vaughan, “Brain–computer interfaces for communication and control,” Clin. Neurophysiol., vol. 113, pp. 767–791, Jun. 2002.
[2] G. Schalk, “Brain–computer symbiosis,” J. Neural Eng., vol. 5, pp. 1–14,
Mar. 2008.
[3] P. C. Petrantonakis and L. J. Hadjileontiadis, “A novel emotion elicitation
index using frontal brain asymmetry for enhanced EEG-based emotion
recognition,” IEEE Trans. Inf. Technol. Biomed., vol. 15, no. 5, pp. 737–
746, Sep. 2011.
[4] R. Vinjamuri, D. J. Weber, M. Zhi-Hong, J. L. Collinger, A. D. Degenhart,
J. W. Kelly, M. L. Boninger, E. C. Tyler-Kabara, and W. Wei, “Toward synergy-based brain-machine interfaces,” IEEE Trans. Inf. Technol.
Biomed., vol. 15, no. 5, pp. 726–736, Sep. 2011.
[5] A. Kubler, V. K. Mushahwar, L. R. Hochberg, and J. P. Donoghue, “BCI
meeting 2005-workshop on clinical issues and applications,” IEEE Trans.
Neural Syst. Rehabil. Eng., vol. 14, no. 2, pp. 131–134, Jun. 2006.
[6] D. A. Craig and H. T. Nguyen, “Adaptive EEG thought pattern classifier
for advanced wheelchair control,” in Proc. IEEE 29th Annu. Int. Conf.
Eng. Med. Biol. Soc., 2007, pp. 2544–2547.
[7] F. Galan, M. Nuttin, E. Lew, P. W. Ferrez, G. Vanacker, J. Philips, and
R. Jdel Millan, “A brain-actuated wheelchair: Asynchronous and noninvasive brain-computer interfaces for continuous control of robots,” Clin.
Neurophysiol., vol. 119, pp. 2159–2169, Sep. 2008.
[8] J. d. R. Millan, F. Galan, D. Vanhooydonck, E. Lew, J. Philips, and
M. Nuttin, “Asynchronous non-invasive brain-actuated control of an intelligent wheelchair,” in Proc. IEEE 31st Annu. Int. Conf. Eng. Med. Biol.
Soc., 2009, pp. 3361–3364.
[9] A. Kubler, F. Nijboer, J. Mellinger, T. M. Vaughan, H. Pawelzik,
G. Schalk, D. J. McFarland, N. Birbaumer, and J. R. Wolpaw, “Patients
with ALS can use sensorimotor rhythms to operate a brain-computer interface,” Neurology, vol. 64, pp. 1775–1777, May 2005.
[10] G. Pfurtscheller, C. Brunner, A. Schlogl, and F. Lopes da Silva, “Mu
rhythm (de) synchronization and EEG single-trial classification of different motor imagery tasks,” NeuroImage, vol. 31, pp. 153–159, May 2006.
[11] R. Leeb, D. Friedman, G. R. Müller-Putz, R. Scherer, M. Slater, and
G. Pfurtscheller, “Self-paced (asynchronous) BCI control of a wheelchair
in virtual environments: A case study with a tetraplegic,” Comput. Intell.
Neurosci., vol. 2007, pp. 1–8, 2007.
[12] B. Allison and C. Neuper, “Could anyone use a BCI?,” in Brain-Computer
Interfaces, Applying our Minds to Human-Computer Interaction, D. S. Tan
and A. Nijholt, Eds. London, U.K.: Springer, 2010, pp. 35–54.
[13] M. Conson, S. Sacco, M. Sarà, F. Pistoia, D. Grossi, and L. Trojano,
“Selective motor imagery defect in patients with locked-in syndrome,”
Neuropsychologia, vol. 46, pp. 2622–2628, 2008.
[14] G. E. Birch, Z. Bozorgzadeh, and S. G. Mason, “Initial on-line evaluations
of the LF-ASD brain-computer interface with able-bodied and spinal-cord
subjects using imagined voluntary motor potentials,” IEEE Trans. Neural
Syst. Rehabil. Eng., vol. 10, no. 4, pp. 219–224, Dec. 2002.

1623

[15] E. Curran, P. Sykacek, M. Stokes, S. J. Roberts, W. Penny, I. Johnsrude,
and A. M. Owen, “Cognitive tasks for driving a brain-computer interfacing
system: A pilot study,” IEEE Trans. Neural Syst. Rehabil. Eng., vol. 12,
no. 1, pp. 48–54, Mar. 2004.
[16] R. Palaniappan, “Identifying individuality using mental task based brain
computer interface,” in Proc. 3rd Int. Conf. Intell. Sens. Inform. Process.,
2005, pp. 238–242.
[17] F. Faradji, R. K. Ward, and G. E. Birch, “Design of a mental task-based
brain-computer interface with a zero false activation rate using very few
EEG electrode channels,” in Proc. IEEE /EMBS 4th Int. Conf. Neural
Eng., 2009, pp. 403–406.
[18] R. Chai, S. H. Ling, G. P. Hunter, and H. T. Nguyen, “Mental non-motor
imagery tasks classifications of brain computer interface for wheelchair
commands using genetic algorithm-based neural network,” in Proc. Int.
Joint Conf. Neural Netw., 2012, pp. 978–984.
[19] R. Chai, S. H. Ling, G. P. Hunter, and H. T. Nguyen, “Toward fewer EEG
channels and better feature extractor of non-motor imagery mental tasks
classification for a wheelchair thought controller,” in Proc. IEEE 34th
Annu. Int. Conf. Eng. Med. Biol. Soc., 2012, pp. 5266–5269.
[20] F. Lotte, M. Congedo, A. Lécuyer, F. Lamarche, and B. Arnaldi, “A review
of classification algorithms for EEG-based brain–computer interfaces,” J.
Neural Eng., vol. 4, pp. R1–R13, Mar. 2007.
[21] D. J. Krusienski, M. Grosse-Wentrup, F. Galán, D. Coyle, K. J. Miller,
E. Forney, and C. W. Anderson, “Critical issues in state-of-the-art brain–
computer interface signal processing,” J. Neural Eng., vol. 8, 025002,
Mar. 2011.
[22] C. Deng, H. Xiaofei, H. Jiawei, and T. S. Huang, “Graph regularized
nonnegative matrix factorization for data representation,” IEEE Trans.
Pattern Anal. Mach. Intell., vol. 33, no. 8, pp. 1548–1560, Aug. 2011.
[23] S. H. Ling, H. T. Nguyen, F. H. F. Leung, K. Y. Chan, and F. Jiang, “Intelligent fuzzy particle swarm optimization with cross-mutated operation,”
in Proc. IEEE Congr. Evol. Comput., 2012, pp. 3009–3016.
[24] G. H. Klem, H. Lüders, H. Jasper, and C. Elger, “The ten-twenty electrode system of the international federation. the international federation
of clinical neurophysiology,” Electroenceph. Clin. Neurophysiol., vol. 52,
pp. 3–6, 1999.
[25] N. E. Huang, Z. Shen, S. R. Long, M. C. Wu, H. H. Shih, Q. Zheng,
N. C. Yen, C. C. Tung, and H. H. Liu, “The empirical mode decomposition
and the Hilbert spectrum for nonlinear and non-stationary time series
analysis,” Proc. Roy. Soc. London A, vol. 454, pp. 903–995, Mar. 1998.
[26] C. Dan, L. Duan, X. Muzhou, B. Hong, and L. Xiaoli, “GPGPU-aided
ensemble empirical-mode decomposition for EEG analysis during anesthesia,” IEEE Trans. Inf. Technol. Biomed., vol. 14, no. 6, pp. 1417–1427,
Nov. 2010.
[27] V. Bajaj and R. B. Pachori, “Classification of seizure and nonseizure EEG
signals using empirical mode decomposition,” IEEE Trans. Inf. Technol.
Biomed., vol. 16, no. 6, pp. 1135–1142, Nov. 2012.
[28] H. T. Nguyen, “Intelligent technologies for real-time biomedical engineering applications,” Int. J. Autom. Control, vol. 2, no. 2/3, pp. 274–285,
2008.
[29] A. T. Tzallas, M. G. Tsipouras, and D. I. Fotiadis, “Epileptic seizure detection in EEGs using time-frequency analysis,” IEEE Trans. Inf. Technol.
Biomed., vol. 13, no. 5, pp. 703–710, Sep. 2009.
[30] A. Craig, P. Moses, Y. Tran, P. McIsaac, and L. Kirkup, “The effectiveness
of a hands-free environmental control system for the profoundly disabled,”
Archives Phys. Med. Rehabil., vol. 83, pp. 1455–1458, 2002.
[31] B. Blankertz, G. Dornhege, S. Lemm, M. Krauledat, G. Curio, and
K.-R. Muller, “The berlin brain-computer interface: Machine learning
based detection of user specific brain states,” J. Universal Comput. Sci.,
vol. 12, pp. 581–607, 2006.
[32] M. Grosse-Wentrup and B. Schölkopf, “A review of performance
variations in SMR-based brain−computer interfaces (BCIs),” in BrainComputer Interface Research, C. Guger, B. Z. Allison, and G. Edlinger,
Eds. Berlin, Germany: Springer, 2013, pp. 39–51.
[33] D. J. McFarland and D. J. Krusienski, “BCI signal processing: Feature translation,” in Brain–Computer Interfaces: Principles and Practice,
J. Wolpaw and E. W. Wolpaw, Eds. New York, NY, USA: Oxford Univ.
Press, 2012, pp. 147–163.
[34] M. Billinger, I. Daly, V. Kaiser, J. Jin, B. Z. Allison, G. R. Müller-Putz, and
C. Brunner, “Is it significant? guidelines for reporting BCI performance,”
in Towards Practical Brain-Computer Interfaces. New York, NY, USA:
Springer, 2013, pp. 333–354.
[35] V. Franc and V. Hlavac. (2004). Statistical pattern recognition toolbox for MATLAB. [Online]. Available: http://cmp.felk.cvut.cz/cmp/
software/stprtool/

1624

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

[36] J. Lu, K. N. Plataniotis, and A. N. Venetsanopoulos, “Face recognition
using LDA-based algorithms,” IEEE Trans. Neural Netw., vol. 14, no. 1,
pp. 195–200, Jan. 2003.
[37] A. Delorme, C. Kothe, A. Vankov, N. Bigdely-Shamlo, R. Oostenveld,
T. O. Zander, and S. Makeig, “MATLAB-based tools for BCI research,”
in Brain-Computer Interfaces. New York, NY, USA: Springer, 2010,
pp. 241–259.
[38] N. Fatma Guler and E. D. Ubeyli, “Multiclass support vector machines for
EEG-signals classification,” IEEE Trans. Inf. Technol. Biomed., vol. 11,
no. 2, pp. 117–126, Mar. 2007.
[39] Z. Rui, G. McAllister, B. Scotney, S. McClean, and G. Houston, “Combining wavelet analysis and Bayesian networks for the classification of
auditory brainstem response,” IEEE Trans. Inf. Technol. Biomed., vol. 10,
no. 3, pp. 458–467, Jul. 2006.
[40] A. Subasi, “EEG signal classification using wavelet feature extraction and
a mixture of expert model,” Expert Syst. Appl., vol. 32, pp. 1084–1093,
2007.
[41] W. Ting, Y. Guo-zheng, Y. Bang-Hua, and S. Hong, “EEG feature extraction based on wavelet packet decomposition for brain computer interface,”
Measurement, vol. 41, pp. 618–625, 2008.
[42] Y. Chen and M. Q. Feng, “A technique to improve the empirical mode
decomposition in the Hilbert–Huang transform,” Earthquake Eng. Eng.
Vibration, vol. 2, pp. 75–85, 2003.
[43] Z. Wu and N. E. Huang, “Ensemble empirical mode decomposition:
A noise-assisted data analysis method,” in Advances in Adaptive Data
Analysis, vol. 1. Singapore: World Scientific, 2009, pp. 1–41.

Rifai Chai (S’11) received the B.Eng. degree
from Krida Wacana Christian University, Jakarta,
Indonesia, in 2000. He is currently working toward
the Ph.D. degree in biomedical engineering with the
Faculty of Engineering and Information Technology,
University of Technology, Sydney, N.S.W., Australia.
From 2000 to 2010, he was a Product Development Engineer, a Research and Development Engineer, and a Project Engineer with companies in
Indonesia and Australia. His research interests include brain–computer interfaces, biomedical instrumentation, embedded system, and computational intelligence using neural networks, fuzzy logic, and evolutionary computation.

Sai Ho Ling (M’06–SM’12) received the B.Eng. degree from the Department of Electrical Engineering,
the M.Phil. and Ph.D. degrees from the Department of
Electronic and Information Engineering, Hong Kong
Polytechnic University, Hong Kong, in 1999, 2002,
and 2007, respectively.
He is currently with the University of Technology, Sydney, N.S.W., Australia, as a Lecturer. He has
authored and coauthored more than 130 books, international journal, and conference papers on computational intelligence and its industrial applications. His
current research interests include evolution computations, fuzzy logics, neural
networks, hybrid systems, and biomedical applications.
Dr. Ling serves as a Co-Editor-in-Chief for the Journal of Intelligent Learning Systems and Applications.

Gregory P. Hunter (M’86) received the B.Eng.
(Hons.) degree from the University of Sydney,
N.S.W., Australia, in 1975, and the Ph.D. degree from
the University of Technology, Sydney, Australia, in
1998, both in electrical engineering.
He has worked in the power electronics industry for most of his career both as an employee and
a consultant, specializing in the design of switched
mode power supplies, uninterruptible power supplies,
grid-connect inverters, and motor drives using both
PWM inverters and cycloconverters. Since 1998, he
has been a Senior Research Fellow at the University of Technology, Sydney.
His current research interests include sensorless motor drives, wind turbines,
electric wheelchair controllers, and power electronics for implanted medical
devices.

Yvonne Tran received the B.Sc. (Hons.) degree in
biomedical science in 1997, and the Ph.D. degree in
psychophysiology, in 2001, both from the University
of Technology, Sydney, N.S.W., Australia.
In 2001, she joined the Centre of Health Technology, Faculty of Engineering and Information Technology, University of Technology, Sydney as a Postdoctoral Fellow and is currently working as a Research Associate. In 2007, she joined the Rehabilitation Studies Unit, University of Sydney, Australia as a
Senior Research Officer. Her area of research include
investigating neural signals for BCI use, neuropsychophysiology and cognitive
associations of differentiation in people with spinal cord injury, detection of
psychophysiological signals following a fatiguing task, and psychological injury following a motor vehicle accident.

Hung T. Nguyen (SM’99) received the Ph.D. degree from the University of Newcastle, Callaghan,
Australia, in 1980.
He is currently a Professor of Electrical Engineering at the University of Technology, Sydney, N.S.W.,
Australia. He is the Dean of the Faculty of Engineering and Information Technology and the Director
of the Centre for Health Technologies. His research
interests include biomedical engineering, advanced
control, and artificial intelligence. He has developed
biomedical devices for diabetes, disability, and cardiovascular diseases.
Dr. Nguyen is a fellow of the Institution of Engineers, Australia, the British
Computer Society, and the Australian Computer Society.

