928

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 17, NO. 5, SEPTEMBER 2013

Correlation Modeling for Compression of Computed
Tomography Images
Juan Muñoz-Gómez, Joan Bartrina-Rapesta, Member, IEEE, Michael W. Marcellin, Fellow, IEEE,
and Joan Serra-Sagristà, Senior Member, IEEE

Abstract—Computed tomography (CT) is a noninvasive medical test obtained via a series of X-ray exposures resulting in 3-D
images that aid medical diagnosis. Previous approaches for coding
such 3-D images propose to employ multicomponent transforms to
exploit correlation among CT slices, but these approaches do not
always improve coding performance with respect to a simpler sliceby-slice coding approach. In this paper, we propose a novel analysis
which accurately predicts when the use of a multicomponent transform is profitable. This analysis models the correlation coefficient
r based on image acquisition parameters readily available at acquisition time. Extensive experimental results from multiple image
sensors suggest that multicomponent transforms are appropriate
for images with correlation coefficient r in excess of 0.87.
Index Terms—Computed tomography (CT) image compression, correlation modeling, digital imaging and communications
in medicine (DICOM) protocol, JPEG2000 coding standard, multicomponent transforms.

I. INTRODUCTION
UMAN body medical imaging is often used for clinical diagnosis. One of the medical imaging modalities
that is more commonly used is computed tomography (CT),
which combines special X-ray equipment with sophisticated
software to produce 3-D images, each consisting of a set of
image slices. These images of the inside of the human body
show organs, bones, soft tissue, and blood vessels with greater
clarity than standard X-rays, allowing radiologists to more easily diagnose problems such as cancer, infectious diseases, appendicitis, cardiovascular diseases, trauma, and musculoskeletal
disorders [1].
The use of CT imagery has increased rapidly. In 2007, it was
estimated that more than 62 million CT scans were obtained per
year in the U.S. [2]. To manage these data, medical centers use

H

Manuscript received September 11, 2012; revised March 3, 2013; accepted
May 13, 2013. Date of publication May 21, 2013; date of current version
August 30, 2013. This work was supported in part by the European Union,
the Ministry of Economy and Competitiveness of the Government of Spain,
FEDER, Catalan Government, and the Universitat Autònoma de Barcelona,
under Grants FP7-PEOPLE-2009-IIF, FP7-250420, TIN2009-14426-C02-01,
TIN2012-38102-C03-03, 2009-SGR-1224, and UAB-BI3INT2006-08.
J. Muñoz-Gómez, J. Bartrina-Rapesta, and J. Serra-Sagristà are with
the Department of Information and Communications Engineering, Universitat Autònoma de Barcelona, E-08193 Barcelona, Spain (e-mail:
jmunoz@deic.uab.cat; joan.bartrina@uab.cat; joan.serra@uab.cat).
M. W. Marcellin is with the Department of Electrical and Computer Engineering, University of Arizona, Tucson, AZ 85721 USA (e-mail: marcellin@
ece.arizona.edu).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2013.2264595

Fig. 1. Graphical representation of slice thickness and slice distance during a
CT scan.

picture archiving and communications systems (PACS) [3] to
store, retrieve, distribute, and display medical images. PACS are
commonly constituted of large computer networks, servers, and
workstations [4], [5]. The digital imaging and communications
in medicine (DICOM) standard [6] specifies the format used
to store and distribute images in PACS. Due to the number of
images managed, data compression plays a key role in DICOM.
During the CT scanning process, two main parameters can
be manipulated by the radiologist to capture the desired information: slice thickness and slice distance. Slice thickness is
defined as the width (in mm) of the region in the human body
represented by each slice. Its value can be selected according to
clinical requirements and commonly lies between 1 and 10 mm.
In general, a larger slice thickness results in poorer contrast resolution in the image. On the other hand, if the slice thickness is
small (e.g., 0.75–2 mm), higher radiation doses are required to
achieve a high-quality image [7]. Slice distance is defined as the
distance (in mm) between two adjacent slices. Similar to slice
thickness, common slice distances lie between 0 and 10 mm. It
is possible to choose the slice distance to be less than the slice
thickness. Fig. 1 provides a graphical representation of these
two concepts.
Regarding CT image acquisition parameters, Siegel et al. [8]
presented an empirical study of the effects of slice thickness
in CT coding, concluding that thinner CT slices are less compressible than thicker slices when 2-D coding is employed, and
recommended the use of a 3-D coder to obtain higher compression ratios. Such 3-D coding exploits the fact that CT images can
have a significant amount of redundancy among slices, which
can be exploited through multicomponent transforms to improve
coding performance. Under certain assumptions, the potential
for such improvement can be characterized via the correlation
coefficient r [9].
Compression of medical imagery is an active topic of research [10]. Recently published work on this topic includes
Schelkens et al. [11], which presented an extensive review of

2168-2194 © 2013 IEEE

MUÑOZ-GÓMEZ et al.: CORRELATION MODELING FOR COMPRESSION OF COMPUTED TOMOGRAPHY IMAGES

929

TABLE I
IMAGE CORPUS CHARACTERISTICS

3-D wavelet coders, and proposed three different coding methods which attempted to exploit correlation among components.
Xiong et al. [12] proposed a 3-D modification of set partitioning
in hierarchical trees (SPIHT) [13] and of embedded subband
coding with optimal truncation [14]. Agarwal et al. [15] presented a fast JPEG2000 decoder and discussed its usefulness in
medical image coding. In 2009, Miaou et al. [16] developed a
lossless coding scheme, using JPEG-LS and an interframe coding stage, which outperforms JPEG2000 and JPEG-LS for lossless coding. Sanchez et al. [17] have exploited image symmetries
to predict the value of wavelet coefficients on a block-by-block
basis. On the other hand, methods based on region-of-interest
(ROI) techniques, aimed to encode only the biological area of
the image—or the relevant area detected by computer-aided diagnosis procedures—have been proposed. Penedo et al. [18]
presented object-based extensions for the set partitioning in hierarchical trees and the set partitioning embedded block coder
algorithms for digital mammography, and explored the effects
of lossy compression for detecting microcalcifications in digital
mammography [19]. Sanchez et al. [20] proposed a 3-D scalable
compression method for medical images with optimized volume
of interest coding. More recently, Bartrina-Rapesta et al. [21]
introduced an ROI coding method for digital mammography
based on component priority. Kim et al. [22] presented a preprocessing method for CT images that replaces the pixels of the
nonbody region by a constant value, maximizing the data redundancy. A similar approach had previously been employed in the
framework of remote sensing scenarios [23]. Kassim et al. [24]
proposed a 4-D image coding scheme combining a 3-D wavelet
transform, 3-D motion compensation, and a 3-D extension of
SPIHT. Sanchez et al. [25] presented a 4-D image coding method
based on H.264/AVC and a modification of context-adaptive binary arithmetic coding that takes into account the probability
distribution of the residual and motion vector data.
In the next sections, we show that multicomponent transforms
improve compression performance significantly when the correlation among slices is sufficiently high. However, precomputing
image correlation is a computationally demanding task. In this
paper, we propose a new correlation model specifically designed
for CT images. Our novel contribution employs CT image acquisition parameters to model the correlation among slices. Results indicate that the proposed method accurately models the
correlation among slices.

This paper is structured as follows: Section II introduces the
employed image corpus, the metrics used to evaluate our proposal, and a short review of the JPEG2000 standard. Section III
describes our correlation model. Section IV provides experimental results. Section V closes the paper with discussion and
conclusions.
II. MATERIALS AND METHODS
A. Image Corpus
The images employed in this study were acquired with four
different CT scanners: Siemens Sensation 16, Siemens Somatom Plus 4, General Electric LightSpeed 16, and Philips
Brilliance 40. Images from the first sensor were provided by
Parc Taulı́ Health Corporation [26], while images from the second, third, and fourth sensors were obtained from The Cancer
Imaging Archive [27]. All images have a bit depth of 12 bppps
with sign, but are stored using 16 bppps. The corpus contains
100 3-D images. Different acquisition parameters—selected by
the radiologist for the purpose of specific examinations—are
considered.
Table I summarizes the corpus characteristics. The first column indicates the sensor used to acquire the imagery. The second
column provides image names, which end with an integer suffix
to differentiate between multiple 3-D images having the same
acquisition characteristics. The third column gives the number
of 3-D images with the same image characteristics. The fourth
and fifth columns give, respectively, slice thickness and slice
distance, while pixel spacing within a slice is provided in column six. The last column reports the number of slices Nz in
each 3-D image, which is given as a range, since images with
the same characteristics may have a different numbers of slices.
In every case, the slice size is 512 × 512 pixels.
B. Coding Performance Metrics
The performance of a coding system is established as a tradeoff between the rate achieved by the coding process, and the
quality of the recovered image after decoding. To evaluate performance, two quality metrics are used in this study: signalto-noise ratio (SNR) and high dynamic range-visual difference
predictor (HDR-VDP).

930

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 17, NO. 5, SEPTEMBER 2013

1) One of the most common metrics to evaluate reconstruction quality is SNR, defined as
SNR = 10 log10

σ2
(dB)
MSE

where
MSE =

Ny
Nz 
Nx 
1 1 1 
(Iij k − Iˆij k )2 .
Nz Nx Ny
i=1 j =1
k =1

Iij k and Iˆij k denote, respectively, the values of the original samples and decompressed samples at position ijk
corresponding to the horizontal, vertical, and slice axes.
σ 2 denotes the variance of the original image. Nx and
Ny are the number of pixels in a row and in a column,
respectively. Higher SNR represents better quality of the
decompressed image.
2) HDR-VDP is a perceptual metric, suitable for medical
applications [28]. This metric returns a probability-ofdetection map where each value in the map indicates
the probability that a human observer would detect a difference in the pixel at the corresponding location in the
compressed image. This probability-of-detection map is
summarized by a single value as
⎞ β1
⎛

HDR-VDP = ⎝
p(i, j)β ⎠
i

j

where p(i, j) is the probability of detection for pixel (i, j),
and β = 2.4 [28]. On a dB scale
HDR-VDPm ax
(dB)
HDR-VDP
where HDR-VDPm ax is the maximum value that
HDR-VDP can have, which would occur if all values in
the probability-of-detection map were 1. In their paper,
the authors conclude that an image recovered at 25.8 dB
or above is visually lossless.
HDR-VDP = 20log10

C. JPEG2000
JPEG2000 is a powerful image compression standard [29]
that provides advanced features for imaging applications and
has been included in DICOM since November 2001 [30]. Based
on a wavelet coding scheme, it is composed of a two-tiered
coding system: tier-1 carries out bitplane-by-bitplane arithmetic entropy encoding, while tier-2 organizes the code stream.
JPEG2000 achieves high compression ratios in lossy, lossless,
and progressive lossy-to-lossless regimes, supports more than
16 bits of signed or unsigned data, includes tools for interactive
transmission [31], and provides some interesting capabilities
for 3-D image coding, such as support for multicomponent
transforms [32], aimed to exploit redundancy among image
components, commonly increasing compression performance
when applied. It is worth noting that we use the JPEG2000
standard language that refers to “components” and “multicomponent transforms.” In the context of CT imagery, these can be
understood as “slices” and “multislice transforms.” In particular,
if z refers to the slice dimension, with x and y being the spatial

dimensions within a slice, then a multicomponent transform is
applied in the z-dimension.
An important feature provided by JPEG2000 is scalability in
terms of spatial location, resolution, component, and quality.
Spatial scalability provides access to different spatial regions
of an image. Resolution scalability allows one to obtain images in different resolutions or sizes. Quality scalability permits
access to image data corresponding to different compression
ratios or bit-rates. Finally, component scalability is the ability
to retrieve a set of selected components (or slices) of the image.
All JPEG2000 scalabilities can be exercised without needing to
decode the full code stream. Spatial location scalability, quality scalability, and resolution scalability are not affected by
multicomponent transforms. However, component scalability is
affected.
All experiments presented in this paper were performed with
Kakadu v6.4.1 [33]. In the (x, y) dimensions, the reversible 5/3
wavelet transform (RWT) was used with five decomposition
levels. In the third (z) dimension, either the RWT or the reversible HAAR transform (RHAAR) was used with a number
of transform levels that depends on the total number of slices
of each image. Specifically, the number of wavelet transform
levels chosen for the z dimension was min{5, log2 Nz }. Five
levels of wavelet transform are typical in the literature. More
than five levels does not generally provide additional increases
in compression performance. Additionally, each level of wavelet
transform reduces the number of “low band slices” by a factor
of 2. Thus, log2 Nz is a practical upper bound on the number of
wavelet transform levels in the z-dimension. A code-block size
of 64 × 64 was used throughout. With respect to rate allocation,
multicomponent post compression rate distortion optimization
was employed because it yields the best progressive lossy-tolossless coding performance [34].
III. CORRELATION MODELING FOR MULTICOMPONENT
TRANSFORM SELECTION
The study proposed in this section is based on the fact that
CT images can have a significant amount of redundancy among
slices, which may be exploited via multicomponent transforms
to improve coding performance. This performance improvement can be characterized by the correlation coefficient [9]. The
correlation among slices varies significantly, depending on the
two scanning parameters used to acquire an image: the slice
thickness and slice distance.
Given two random variables A and B, their correlation coefficient is given by
rA ,B =

E[(A − Ā)(B − B̄)]
σA σB

(1)

where E[•] indicates the expectation or probabilistic average,
Ā = E[A] is the mean of A, and σA2 = E[(A − Ā)2 ] is the
variance of A. Similarity, B̄ and σB2 are the mean and variance
of B. The correlation coefficient between two consecutive CT
slices k and k + 1 can be estimated by
rk ,k +1

Ny
Nx 
(xij k − x̄k )(xij k +1 − x̄k +1 )
1 
=
Nx Ny i=1 j =1
σk σk +1

(2)

MUÑOZ-GÓMEZ et al.: CORRELATION MODELING FOR COMPRESSION OF COMPUTED TOMOGRAPHY IMAGES

931

(a)
Fig. 2.

(b)

Coding rate gain versus estimated r  . (a) and (b) Coding rate gain for RWT and RHAAR. (a) RWT+JPEG2000. (b) RHAAR+JPEG2000.

where xij k denotes the pixel at column i and row j of slice k,
and x̄k and σk , respectively, denote the sample pixel mean and
standard deviation of slice k. The average correlation coefficient
between consecutive slices of an image is estimated as
r =

N
z −1
1
rk ,k +1 .
Nz − 1

(3)

k =1

Usually, “nonbiological areas” in a 3-D image do not change
from slice to slice; however, these areas substantially influence
the computation of r , bringing it artificially close to 1. To avoid
this effect, r is estimated using only a 170 × 170 pixel square
window centered in the slices, which corresponds roughly to the
biological area in the slices.
To evaluate the relationship between r and the benefit of
multicomponent transforms in terms of lossless coding performance, Fig. 2 depicts the difference in lossless coding rate
between JPEG2000 with and without a multicomponent transform as a function of r . Two multicomponent transforms are
explored: the 5/3 RWT and the RHAAR transform. In particular, the figure depicts the bit-rate obtained by JPEG2000 (without multicomponent transform) minus the bit-rate obtained by
JPEG2000 with a multicomponent transform (RWT+JPEG2000
or RHAAR+JPEG2000). We refer to this quantity as the coding rate gain, where positive values indicate improvement for
multicomponent transforms. For the images used in this paper,
the results of Fig. 2 suggest that r is a good indicator of when
a multicomponent transform can improve coding performance.
Roughly, a multicomponent transform should be applied among
slices when r is greater than or equal to 0.87. Unfortunately,
the computation of r is quite computationally and memory intensive. This issue is addressed below.
A. Correlation Modeling Based on CT Image Acquisition
Parameters
As mentioned in Section I, Siegel et al. investigated the performance of JPEG2000 as a function of slice thickness. That work
was empirical in nature and did not explore the role of slice
distance. In this section, we propose a theoretical model for the
correlation among components, denoted by r, as a function of
slice thickness T and slice distance D. This model provides a
basis for explaining compression performance in terms of these

two parameters and is used to determine when a multicomponent
transform will be profitable.
In the previous section, the pixel at spatial location ij of slice
k was denoted by xij k . In what follows, we consider a sequence
of pixels, indexed by k, obtained by fixing a spatial location ij.
To reduce notational clutter, we drop the explicit dependence
on ij and write x(k). We assume that the pixel x(k) can be
modeled as arising from the integration of some underlying
continuous signal y(z) over the extent corresponding to a slice
thickness. For computational purposes, we discretize y with a
sample distance significantly smaller than both T and D, and
replace the integration of y by a sum. Hereafter, this sample
distance is fixed at 0.0625 mm. The number of samples of y
that correspond to one slice thickness is then L = T /0.0625.
Similarly, the number of samples corresponding to the slice
distance is M = D/0.0625. For example, when T = 1 mm,
each x(k) is modeled as a sum of L = 16 consecutive samples
of y. Fig. 3 depicts this example for D = 0.75, 1, and 1.5 mm,
resulting in M = 12, 16 and 24, respectively.
The kth pixel value x(k) can then be written as
x(k) =

L


a(l)y(kM − l).

(4)

l=1

The constants a(l) are included in (4) for two reasons. First,
they allow for the possibility of generalizing the expression to
a weighted sum. Second, they facilitate the observation that (4)
corresponds to a filtering (or convolution) operation. Specifically, x(k) is a subsampled version of
w(n) = a(n) ∗ y(n).

(5)

x(k) = w(kM )

(6)

That is

where
w(n) =

L


a(l)y(n − l).

(7)

l=1

We now assume that the samples y(n) arise from a simple
autoregressive random process
Y (n) = bY (n − 1) + Θ(n)

(8)

932

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 17, NO. 5, SEPTEMBER 2013

Fig. 3.

Samples of y used to compute x(k) for three choices of D. In each case, T = 1 mm, (a) D = 1 mm, (b) D = 0.75 mm, and (c) D = 1.5 mm.

where b ∈ (0,1) is a constant and Θ(n) is a stationary white
Gaussian random process. The corresponding random processes
for w(n) and x(k) are denoted by W (n) and X(k). The autocovariance function of Y (n) is
CY (j) = E[(Y (n) − Ȳ )(Y (n + j) − Ȳ )]

TABLE II
MODELED r AND ESTIMATED r̄  , TOGETHER WITH MEAN ERROR AND
STANDARD DEVIATION OF THE DIFFERENCE BETWEEN r AND r  FOR IMAGES
WITH THE SAME ACQUISITION PARAMETERS T AND D

(9)

where Ȳ = E[Y (n)] = E[Y (n + j)], regardless of n. It is then
easily shown that for the specific choice of (8)
CY (j) = σY2 b|j | .

(10)

From (5), it follows that the autocovariance function of W (n)
is
CW (j) = CY (j) ∗ a(j) ∗ a(−j).

(11)

From (6), we then have
CX (k) = CW (kM ).

(12)

Thus, for given values of T, D, b, and a(j), j = 1, 2, 3, . . . , L, it
is straightforward to compute CX (k) via (10)–(12). Consistent
with our simple integration model, a(j) = 1 in all discussions
that follow, but other choices pose no complications. Finally,
it follows that, given values for T, D, and b, the correlation
coefficient between two pixels X(k) and X(k + 1) at the same
location (i, j) in two consecutive slices is modeled by
r=

E[(X(k) − X̄)(X(k + 1) − X̄)]
CX (1)
=
.
2
2
σX
σX

(13)

We have used 24 images from the corpus of Table I to find a
suitable value of b by minimizing the least squared error between
r as computed by (13) and r as computed via (3). Images with
a variety of values of D and T were used in this process to
obtain a single value of b = 0.9962. The results of Table II are
provided to assess the performance of our model. In particular,
each row of Table II corresponds to data from a collection of
images having the same acquisition parameters T and D. For
each row, one fixed value of r is reported. This value is computed
via (13) using b = 0.9962 together with the values of T and D
indicated by the image name. Additionally, a separate value of
r is computed for each image via (3). The average of these
values is reported as r̄ in Table II. Finally, the mean error and
variance of the error between r and r is reported for each image
set. We note that the 76 images used to obtain Table II are from
the corpus of Table I but are different from the 24 images used
to calculate b. As can be seen in Table II, the modeled values for
r agree closely with the estimated values r . Fig. 4 depicts the
modeled value of r as a function of T and D, where the color

Fig. 4.

Modeled r.

scale represents the different correlation values, as indicated
on the right side of the figure. We can see that the correlation
decreases when the slice distance D is increased. On the other
hand, correlation increases as a function of slice thickness T .
It is worth noting the significant difference in complexity between estimating the correlation coefficient directly as r versus
computing the modeled value r. It is evident that the computation of r via (3) requires several calculations per pixel multiplied
by Nx × Ny × Nz pixels per 3-D image. On the other hand, the
complexity of the proposed method is constant, independent of
the dimensions of the image.
IV. EXPERIMENTAL RESULTS
Extensive experiments have been carried out to evaluate
our correlation model. In particular, we have carried out 1) a

MUÑOZ-GÓMEZ et al.: CORRELATION MODELING FOR COMPRESSION OF COMPUTED TOMOGRAPHY IMAGES

(a)

933

(b)

Fig. 5. Coding rate gain versus modeled r. (a) and (b) Coding gain between RWT+JPEG2000 and RHAAR+JPEG2000, with respect to JPEG2000.
(a) RWT+JPEG2000. (b) RHAAR+JPEG2000.

(a)

(b)

(c)

Fig. 6. Rate-distortion performance for RWT+JPEG2000, RHAAR+JPEG2000, and JPEG2000 for different images. (a) LS16-T125-D125_2 (r = 0.961).
(b) LS16-T25-D25_2 (r = 0.909). (c) SS16-T1-D10_5 (r = 0.554).

lossless coding performance evaluation; 2) a rate-distortion evaluation; and 3) a component scalability evaluation. 1) and 2)
aim to analyze the compression performance of multicomponent transforms (RWT and RHAAR) on images with different
acquisition parameters, and 3) assesses the rate-distortion performance when a subset of components is decoded from a code
stream.

A. Lossless Coding Performance
In these experiments, we compare the lossless coding performance of JPEG2000 with two different multicomponent transforms (RWT+JPEG2000 and RHAAR+JPEG2000) with that of
JPEG2000 (without any multicomponent transform) as a function of the modeled correlation coefficient r. Fig. 5 is equivalent
to Fig. 2 but depicts r rather than r . The same conclusion is
apparent: performing a multicomponent transform is profitable
when r exceeds 0.87.

B. Rate-Distortion Evaluation
In this section, the rate-distortion performance of JPEG2000
with and without the two multicomponent transforms is evaluated in terms of SNR and HDR-VDP. Fig. 6 shows the ratedistortion performance in terms of SNR for three images from
two different sensors with various acquisition parameters. As
was the case for lossless compression, results suggest that for
images with r > 0.87, the multicomponent transforms improve
the rate-distortion coding performance, while for images with

low r, the rate-distortion performance of JPEG2000 without a
multicomponent transform is superior.
Fig. 7 depicts the rate-distortion performance in terms
of HDR-VDP. The horizontal black-dashed line identifies
the visually lossless threshold determined by the authors of
HDR-VDP. Results indicate that for images with r > 0.87,
RWT+JPEG2000 reaches visually lossless performance at a
lower rate than JPEG2000. However, for images with low r,
JPEG2000 (without multicomponent transform) provides visually lossless performance at a lower rate. Results are similar for
other images in the corpus.
C. Component Scalability
As mentioned in Section I, component scalability is
negatively impacted when multicomponent transforms are
employed. To explore this effect, we consider decoding a subset of N slices of interest. Due to the nonzero length impulse
response of the filters employed in the inverse transform, K
(multicomponent) transformed slices are involved in the reconstruction of the N slices of interest, where K > N . The number
of transformed slices K needed varies depending on the slice
axis transform (RHAAR or RWT) and the number of transform
levels used. Thus, even though a multicomponent transform
may improve the compression performance for an entire image,
it may cause more data to be read and decompressed when only
a subset of slices is desired. Accordingly, the aim of the following experiment is to evaluate the component scalability of the
proposed coding scheme. To assess this, we have analyzed the
number of bytes needed to decode a set of consecutive slices

934

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 17, NO. 5, SEPTEMBER 2013

(a)

(b)

(c)

Fig. 7. HDR-VDP performance for RWT+JPEG2000, RHAAR+JPEG2000, and JPEG2000 for different images. (a) LS16-T125-D125_1 (r = 0.954).
(b) SP4-T5-D5_1 (r = 0.828). (c) SS16-T1-D10_5 (r = 0.554).

(a)

(b)

Fig. 8. Data decoded (in MB) for JPEG2000, RWT+JPEG2000, and RHAAR+JPEG2000 as a function of N , where N is the number of slices decoded from the
center of the image (a) SS16-T1-D075 2 (r = 0.979) (b) SS16-T2-D2 2 (r = 0.926).

from the center of an image. Since the multicomponent transform only provides a gain for images with r > 0.87, only such
images are considered below.
Fig. 8 shows the amount of data decoded (in MB) for the
three tested coding approaches as a function of the number of
slices decoded N . Note that, for small N , RWT+JPEG2000
and RHAAR+JPEG2000 result in more data being decoded,
corresponding to a deterioration in performance with respect to JPEG2000. However, as N grows, the trend reverses, corresponding to an improved compression performance. The number of slices needed to achieve a positive
gain for RWT+JPEG2000 and RHAAR+JPEG2000 is larger
for images with lower correlation among slices, owing to the
lower performance improvement achieved by the multicomponent transforms. For small N , RHAAR outperforms RWT
due to the fact that the RHAAR filters have shorter lengths
than those of the RWT. However, as the number of retrieved
slices is increased, RWT eventually produces better coding
performance.
V. CONCLUSION
Given the extensive use of CT and the huge volume of data,
CT image coding is a relevant topic for practical medical scenarios and research. This paper proposes a new correlation modeling specifically designed for CT images. Our model is aimed to
determine whether a multicomponent transform helps improve
the coding performance, both for lossless and for progressive
lossy-to-lossless cases. This model employs CT image acquisition parameters to model the correlation among slices, without

the computationally demanding step of precomputing image
correlation. A study of the influence of correlation in 3-D coding performance is carried out, which shows, for the evaluated
corpus, that for images with r > 0.87, the RWT and RHAAR
along the z-dimension can provide significant coding gain.
Experimental results indicate that when the multicomponent
transform is profitable, RWT+JPEG2000 yields the best coding
performance in terms of SNR, HDR-VDP, and lossless bitrate,
always outperforming RHAAR. On the other hand, when a specific subset of components needs to be retrieved, JPEG2000 or
RHAAR+JPEG2000 can sometimes yield better rate-distortion
performance, depending on the value of r and on the number of
slices decoded.

REFERENCES
[1] American Cancer Society. (2013, Feb.). [Online]. Available:http://www.
cancer.org
[2] D. J. Brenner and E. J. Hall, “Computed tomography—an increasing
source of radiation exposure,” New Engl. J. Med., vol. 357, no. 22,
pp. 2277–2284, 2007.
[3] R. Choplin, “Picture archiving and communication systems: An
overview,” Radiographics, vol. 12, pp. 127–129, Jan. 1992.
[4] X. Cao and H. Huang, “Current status and future advances of digital
radiography and PACS,” IEEE Eng. Med. Biol. Mag., vol. 19, no. 5,
pp. 80–88, Sep. 2000.
[5] D. J. Foran, P. P. Meer, T. Papathomas, and I. Marsic, “Compression guidelines for diagnostic telepathology,” IEEE Trans. Inf. Technol. Biomed.,
vol. 1, no. 1, pp. 55–59, Mar. 1997.
[6] Digital Image and Communication in Medicine. (2013, Jul.). [Online].
Available:http://medical.nema.org/
[7] International Atomic Energy Agency. (2013, Feb.). Radiation protection
of patients [Online]. Available:https://rpop.iaea.org

MUÑOZ-GÓMEZ et al.: CORRELATION MODELING FOR COMPRESSION OF COMPUTED TOMOGRAPHY IMAGES

[8] E. Siegel, K. Siddiqui, J. Johnson, O. Crave, Z. Wu, J. Dagher, A. Bilgin,
M. Marcellin, M. Nadar, and B. Reiner, “Compression of multi-slice CT:
2D vs. 3D JPEG2000 and effects of slice thickness,” in Proc. SPIE Med.
Imag.: PACS Imag. Inf., 2005, vol. 5748, pp. 162–170.
[9] D. Taubman and M. W. Marcellin,
“Rate-distortion theory,” in
JPEG2000: Image Compression Fundamentals, Standards and Practice.
Norwell, MA, USA: Kluwer, 2002, ch. 3.
[10] J. Serra-Sagristà and A. Bilgin, “Special issue on image compression
technologies for medical applications,” IEEE COMSOC MMTC E-Lett.,
vol. 6, no. 7, pp. 5–37, Jul. 2011.
[11] P. Schelkens, A. Munteanu, J. Barbarien, M. Galca, X. Giro-Nieto, and
J. Cornelis, “Wavelet coding of volumetric medical datasets,” IEEE Trans.
Med. Imag., vol. 22, no. 3, pp. 441–458, Mar. 2003.
[12] Z. Xiong, X. Wu, S. Cheng, and J. Hua, “Lossy-to-lossless compression
of medical volumetric data using three-dimensional integer wavelet transforms,” IEEE Trans. Med. Imag., vol. 22, no. 3, pp. 459–470, Mar. 2003.
[13] B.-J. Kim, Z. Xiong, and W. A. Pearlman, “Low bit-rate scalable video
coding with 3-D set partitioning in hierarchical trees (3-D SPIHT),” IEEE
Trans. Circuits Syst. Video Technol., vol. 10, no. 8, pp. 1365–1374, Dec.
2000.
[14] J. Xu, Z. Xiong, S. Li, and Y. Zhang, “3-D embedded subband coding
with optimal truncation (3-D ESCOT),” J. Appl. Comput. Harmon. Anal.,
vol. 10, pp. 290–315, May 2001.
[15] A. Agarwal, A. H. Rowberg, and Y. Kim, “Fast JPEG 2000 decoder and
its use in medical imaging,” IEEE Trans. Inf. Technol. Biomed., vol. 7,
no. 3, pp. 184–190, Sep. 2003.
[16] S.-G. Miaou, F.-S. Ke, and S.-C. Chen, “A lossless compression method
for medical image sequences using JPEG-LS and interframe coding,”
IEEE Trans. Inf. Technol. Biomed., vol. 13, no. 5, pp. 818–821, Sep. 2009.
[17] V. Sanchez, R. Abugharbieh, and P. Nasiopoulos, “Symmetry-based scalable lossless compression of 3D medical image data,” IEEE Trans. Med.
Imag., vol. 28, no. 7, pp. 1062–1072, Jul. 2009.
[18] M. Penedo, W. Pearlman, P. Tahoces, M. Souto, and J. Vidal, “Regionbased wavelet coding methods for digital mammography,” IEEE Trans.
Med. Imag., vol. 22, no. 10, pp. 1288–1296, Oct. 2003.
[19] M. Penedo, M. Lado, P. Tahoces, M. Souto, and J. Vidal, “Effects of
JPEG2000 data compression on an automated system for detecting clustered microcalcifications in digital mammograms,” IEEE Trans. Inf. Technol. Biomed., vol. 10, no. 2, pp. 354–361, Apr. 2006.
[20] V. Sanchez, R. Abugharbieh, and P. Nasiopoulos, “3-D scalable medical
image compression with optimized volume of interest coding,” IEEE
Trans. Med. Imag., vol. 29, no. 10, pp. 1808–1820, Oct. 2010.
[21] J. Bartrina-Rapesta, J. Serra-Sagristà, and F. Aulı́-Llinàs, “JPEG2000 ROI
coding through component priority for digital mammography,” Elsevier
Comput. Vis. Imag. Understand., vol. 115, no. 1, pp. 59–68, Jan. 2011.
[22] K. J. Kim, K. H. Lee, B. Kim, T. Richter, I. D. Yun, S. U. Lee, K. T. Bae,
and H. Shim, “JPEG2000 2D and 3D reversible compressions of thinsection chest CT images,” Radiology, vol. 259, no. 1, pp. 271–277, 2011.
[23] J. Gonzalez-Conejero, J. Bartrina-Rapesta, and J. Serra-Sagristà,
“JPEG2000 encoding of remote sensing multispectral images with
no-data regions,” IEEE Signal Process. Lett., vol. 7, no. 2, pp. 251–255,
Apr. 2010.
[24] A. A. Kassim, P. Yan, W. S. Lee, and K. Sengupta, “Motion compensated
lossy-to-lossless compression of 4-D medical images using integer wavelet
transforms,” IEEE Trans. Inf. Technol. Biomed., vol. 9, no. 1, pp. 132–138,
Mar. 2005.
[25] V. Sanchez, P. Nasiopoulos, and R. Abugharbieh, “Novel lossless fMRI image compression based on motion compensation and customized entropy
coding,” IEEE Trans. Inf. Technol. Biomed., vol. 13, no. 4, pp. 645–655,
Jul. 2009.
[26] Corporacio Sanitaria Parc Tauli, Sabadell, Spain. (2013, Feb.). [Online].
Available:http://www.cspt.es
[27] National Cancer Institute. (2013, Feb.). The cancer imaging archive
[Online]. Available:http://http://www.cancerimagingarchive.net/
[28] K. J. Kim, B. Kim, R. Mantiuk, T. Richter, H. Lee, H. S. Kang, J. Seo,
and K. H. Lee, “A comparison of three image fidelity metrics of different computational principles for JPEG2000 compressed abdomen CT
images,” IEEE Trans. Med. Imag., vol. 29, no. 8, pp. 1496–1503, Aug.
2010.
[29] “Information technology—JPEG2000 image coding system—Part 1: Core
coding system,” ISO/IEC, Dec. 2000.
[30] D. Clunie. (2001, Nov.). DICOM supplement 61: JPEG2000 transfer
syntaxes [Online]. Available:ftp://medical.nema.org/medical/dicom/final/
sup61 ft.pdf
[31] “Information technology—JPEG 2000 image coding system—Part 9:
Interactivity tools, APIs and protocols,” ISO/IEC, Dec. 2005.

935

[32] “Information technology—JPEG 2000 image coding system—Part 2:
Extensions,” ISO/IEC, May 2004.
[33] D. Taubman. (2013). Kakadu software [Online]. Available:http://www.
kakadusoftware.com/
[34] J. E. Fowler and J. T. Rucker, “3D wavelet-based compression of hyperspectral imagery,” in Hyperspectral Data Exploitation: Theory and
Applications. Hoboken, NJ, USA: Wiley, 2007, pp. 379–407, ch. 14.

Juan Muñoz-Gómez received the B.E. and M.S.
degrees in computer science from the Universitat
Autònoma de Barcelona, Barcelona, Spain, in 2008
and 2009, respectively, where he is currently working
toward the Ph.D. degree in the Interactive Coding of
Images Group.
In July 2008, he joined the Interactive Coding of
Images Group, Universitat Autònoma de Barcelona.
His research interests include a wide range of image
coding and signal processing topics, including highly
scalable image and video coding systems, interactive
image and video transmission, statistical modeling, and medical image coding.

Joan Bartrina-Rapesta (S’06–M’10) received the
B.Sc., B.E., M.S., and Ph.D. degrees in computer science from the Universitat Autònoma de Barcelona,
Barcelona, Spain, in 2002, 2004, 2006, and 2009, respectively.
He received a doctoral fellowship from the Universitat Autònoma de Barcelona. He has collaborated
in the development of BOI, a JPEG2000 Part 1 implementation. His research interests include a wide range
of image coding topics, including highly scalable image and video coding systems, region-of-interest coding, rate-distortion optimization techniques, distortion estimation, interactive
image and video transmission, and medical image coding.

Michael W. Marcellin (S’81–M’87–SM’93–F’02)
received the B.S. degree in electrical engineering
from San Diego State University, San Diego, CA,
USA, in 1983, and the M.S. and Ph.D. degrees
in electrical engineering from Texas A&M University, College Station, TX, USA, in 1985 and 1987,
respectively.
Since 1988, he has been with the University of
Arizona, Tucson, AZ, USA, where he is currently
a Regents’ Professor, and is the International Foundation for Telemetering Chaired Professor. He has
authored or coauthored more than 200 publications in these areas. His research
interests include digital communication and data storage systems, data compression, and signal processing.
Dr. Marcellin has received numerous honors, including six teaching awards.

Joan Serra-Sagristà (S’97–M’05–SM’11) received
the Ph.D. degree in computer science from the Universitat Autònoma de Barcelona (UAB), Barcelona,
Spain, in 1999.
He is currently an Associate Professor in the Department of Information and Communications Engineering, UAB. From September 1997 to December
1998, he was at the University of Bonn, Bonn, Germany, funded by German Academic Exchange Service. He has coauthored more than 100 publications.
His current research interests focus on data compression, with special attention to image coding for remote sensing and telemedicine
applications.
Dr. Serra-Sagristà serves as an Associate Editor of the IEEE TRANSACTIONS
ON IMAGE PROCESSING. He was the recipient of the Spanish Intensification
Young Investigator Award in 2006.

