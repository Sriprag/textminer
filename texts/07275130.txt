1002

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 5, MAY 2016

Causality Analysis of fMRI Data Based on the
Directed Information Theory Framework
Zhe Wang, Ahmed Alahmadi, David C. Zhu, and Tongtong Li∗

Abstract—This paper aims to conduct fMRI-based causality
analysis in brain connectivity by exploiting the directed information (DI) theory framework. Unlike the well-known Granger
causality (GC) analysis, which relies on the linear prediction technique, the DI theory framework does not have any modeling constraints on the sequences to be evaluated and ensures estimation
convergence. Moreover, it can be used to generate the GC graphs.
In this paper, first, we introduce the core concepts in the DI framework. Second, we present how to conduct causality analysis using
DI measures between two time series. We provide the detailed procedure on how to calculate the DI for two finite-time series. The
two major steps involved here are optimal bin size selection for
data digitization and probability estimation. Finally, we demonstrate the applicability of DI-based causality analysis using both
the simulated data and experimental fMRI data, and compare the
results with that of the GC analysis. Our analysis indicates that
GC analysis is effective in detecting linear or nearly linear causal
relationship, but may have difficulty in capturing nonlinear causal
relationships. On the other hand, DI-based causality analysis is
more effective in capturing both linear and nonlinear causal relationships. Moreover, it is observed that brain connectivity among
different regions generally involves dynamic two-way information
transmissions between them. Our results show that when bidirectional information flow is present, DI is more effective than GC to
quantify the overall causal relationship.
Index Terms—Causal analysis, directed information (DI), fMRI,
Granger causality (GC).

I. INTRODUCTION
AUSALITY analysis provides important information on
how brain regions interact with each other to accomplish
a cognitive task [1]. In general, causality analysis tries to determine whether the values of one time series X is useful in
predicting the future values of another time series Y . Here, we
will first briefly revisit the work on causality analysis in literatures, including Granger causality (GC), Bayesian network,
dynamic causal modeling (DCM), and transfer entropy (TE).
Then, we will introduce the directed information (DI) frame-

C

Manuscript received January 29, 2015; revised June 18, 2015 and May 7,
2015; accepted September 15, 2015. Date of publication September 24, 2015;
date of current version May 19, 2016. Asterisk indicates the corresponding
author.
Z. Wang and A. Alahmadi are with the Department of Electrical & Computer
Engineering, Michigan State University.
D. C. Zhu is with the Department of Radiology, Michigan State University.
∗ T. Li is with the Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI 48824 USA (e-mail:
tongli@egr.msu.edu).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2015.2481723

work, explain why we adopt it, and how to apply it for causality
analysis.
A. Some Representative Techniques on Causality Analysis
1) GC: The first practical causal analysis framework was
proposed by Granger in 1969 [2]. The fundamental idea is, if
two signals X and Y form a causal relationship, then instead of
using the past value of Y alone, the information contained in the
past values (or lagged values) of X will help to predict Y . More
specifically, the calculation of GC is based on the autoregressive
or linear prediction models. Suppose Xn = [X1 , X2 , . . . , Xn ]
and Yn = [Y1 , Y2 , . . . , Yn ] are two time series. The most commonly used method in GC analysis is to compare the following
two prediction errors ei and e˜i :
Yi =

L


aj Yi−j + ei

(1)

[bj Yi−j + cj Xi−j ] + e˜i .

(2)

j =1

Yi =

L

j =1

Here, ei is the error of prediction Yi based only on the previous
value of Y , (Yi−1 , . . . Yi−L ), and e˜i is the error of predicting
Yi based on both the previous values of Y , (Yi−1 , . . . Yi−L ),
and the previous values of X, (Xi−1 , . . . Xi−L ). In practical
analysis, GC can be tested using a nested model comparison
based on the F statistics [3]. If e˜i is much smaller than ei , that
is, the introduction of the previous value of X can improve
the prediction accuracy, then we say there is a Granger causal
relationship between X and Y .
Since 1990s, there have been growing interests in the use of
GC analysis to identify causal interactions in neuroscience [4].
An early exploitation of GC in neuroscience was carried out by
Bernasconi et al. in electrophysiological data [5]. Their paper
verified the applicability of GC for electrophysiological data,
particularly EEG measurements. Goebel et al. presented an application of GC on the fMRI data [6], [7]. They applied the
GC approach to a dynamic sensorimotor mapping paradigm.
Bressler et al. applied GC analysis to examine the blood oxygen
level-dependent (BOLD) time series corresponding to the top–
down control signals from the frontal and parietal cortex [8]. Hu
et al. applied GC analyses on fMRI data to evaluate the causal
relationship among specific brain regions, so as to understand
the impact of amnesic mild cognitive impairment (aMCI) on
brain connectivity [9]. Wen et al. carried out simulations on
neural signals to examine GC in both neural level (neural GC)
and fMRI level (fMRI GC) [10], [11].

0018-9294 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

WANG et al.: CAUSALITY ANALYSIS OF FMRI DATA BASED ON THE DI THEORY FRAMEWORK

David et al. applied GC (together with DCM) in a combination of fMRI and EEG data [12]. Their experiments showed
that as the hemodynamics (i.e., the blood flow or the circulation) vary from region to region, GC may not be applied directly
on the fMRI signals. However, when the hemodynamic effects
were explicitly removed, GC test can perform effective causality
analysis in linear relationships.
As a well-known technique, the validity and computational
simplicity of GC have been widely recognized. However, it has
also been noticed that GC relies heavily on the linear prediction
method. When there exist instantaneous and/or strong nonlinear
interactions between two regions, GC analysis may lead to invalid results [12]. To address this problem, several approaches
on nonlinear GC have been proposed in the literature. For example, in [13], Bezruchko et al. proposed an autoregression
model constructed in the form of a polynomial. More recently,
Marinazzo et al. proposed a method to generalize GC to include
the nonlinear case using the kernel technique [14]. The copula
approach has been applied for GC assessment in [15] and [16].
A comprehensive discussion on nonlinear GC could be found
in [17].
2) Bayesian Network: In [18], J. Pearl summarized the
framework of Bayesian network for causal inference. The argument behind it is that: if a causal relationship exists between
two factors X and Y , the introduction of factor X may change
the distribution of another factor Y . That is, P (Y |X) = P (Y ).
Since 2000, the analyses based on Bayesian networks
have demonstrated successful applications [19], [20]. Luessi
et al. [20] modified the Bayesian network and applied it to
fMRI data by incorporating the vector autoregressive model
used in GC. Their result was in consistent with that of the GC
analysis. From a general perspective, the vector-autoregressivemodel-based Bayesian Network framework can be regarded as
a variation of the GC analysis.
3) DCM: In 2003, Friston proposed the framework of DCM
to describe the general interactions among a group of brain regions [21]. DCM assumes that the invisible neurostate x, the
(external) input u, the parameter θ that characterizes the connection between two brain regions, and the independent noise
ω form a complex dynamic system that could be described by
the following equations:
ẋ = f (x, u, θ) and y = L(θ, h(x)) + ω

(3)

where h(x) represents a cascade of differential equations that
connect the neurostate to changes in blood volume and deoxyhemoglobin content, and L represents a nonlinear output function
that relates θ and h(x) to the observed BOLD signal y [22].
With the help of EM algorithm, DCM has been attempted on
both fMRI and EEG data [22]. Some concerns with this framework are [23]: 1) as the observation model in DCM is nonlinear,
estimating the latent variable that describes the neuronal activity
could be quite difficult and 2) DCM is a confirmatory approach,
for which the users have to start with different connectivity describing models, then rank them based on an approximation of
the model evidences.
4) TE: Another widely applied causal measurement in neuroscience is TE. TE was introduced in 2000 by Schreiber [24]. It
measures the decrease of entropy in one signal Y after another

1003

signal X has been observed.


TX →Y = H (Yt | Yt−1:t−L ) − H (Yt | Yt−1:t−L , Xt−1:t−L )
(4)
in which H denotes the entropy operator, Yt−1:t−L =
[Yt−L , . . . , Yt−1 ] , and Xt−1:t−L = [Xt−L , . . . , Xt−1 ].
Similar to GC, TE measures how much additional information
the past values of process X contains about the future observations of Y , given that we already knew the past values of Y .
The quantity measured by TE is the amount of predictive information rather than the size of causal effect or coupling strength.
In [25], it was pointed out that TE can differentiate between
interactions in the process of information storage and those in
the process of information transfer.
The first exploration of applying TE in causality description
was conducted by Sporns et al. on the sensorimotor network
in 2006 [26]. Vicente et al. [27] applied TE in the magnetoencephalography (MEG) data and showed that TE was an effective metric for nonlinear connectivity, especially for sensorlevel MEG signals. Lizier et al. [28] developed a framework
that combined multivariate mutual information (MI) and TE together. They used TE to analyze fMRI time series to detect the
directed flow of information between brain regions involved in
a visuomotor tracking task.
As an information theoretic framework, a major advantage of
TE is that it does not does not rely on any model assumptions of
the signals. However, current algorithms on TE estimation have
not been proved to be convergent [29]. Also, in [24] and[25],
it was shown that the amplitude of TE could not accurately
quantify the strength of influence between brain regions.
B. Proposed Approach: DI-Based Causality Analysis
In the aforementioned discussions, we revisited some representative methods on causality analysis. These methods are
either limited to an existing model on the time series under
investigation, or cannot guarantee convergence or validity in
practical estimation. In an effort to overcome these weaknesses,
we propose to adopt the DI theory framework.
1) DI: Given two random sequences Xn and Yn , the DI
from Xn to Yn is defined as a sum of some conditional MI


I(Xn → Yn ) =

n


I(Xi ; Yi |Yi−1 )

(5)

i=1

where Xi = [X1 , X2 , . . . , Xi ], Yi = [Y1 , Y2 , . . . , Yi ]. First introduced by Massey to study communication channel with feedback [30], DI has been proved to be an effective tool for network
analysis in communications [31] and neuroscience [32], [33]. As
an information theoretical metric, DI shares some similarities
with TE. Both of them do not rely on any model assumptions of
the signals. Moreover, it was pointed in [25] and [34] that: As
time goes to infinity, DI may approximate the rate of TE.
The DI framework is adopted here for the following reasons.
1) It is a universal method. Unlike GC, which mainly relies on
the linear prediction theory, or linear modeling for the involved
parameters, the DI-based causality analysis does not have any
modeling constraint on the sequences to be evaluated, hence,

1004

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 5, MAY 2016

can be used to characterize more general relationships. 2) It is
well defined with specific physical meaning. Recall that the amplitude of TE cannot reflect the strength of dependence between
brain regions, the amplitude of DI reflects the information flow
from Xn → Yn , hence has a clear physical meaning. 3) It has
been shown in [34] that the GC graphs could be obtained using
the DI framework. As can be seen, the DI theory provides an
adequate framework for the connectivity inference problems in
neuroscience applications.
In the literature, there has been a limited number of references
on applications of DI in neuroscience [29], [35]. Quinn et al.
applied DI in studying neuron spike recording by introducing a
Markov Process model for the signal. Liu et al. applied DI to the
EEG data and compared the result with that of GC. Their conclusion was that the DI-based approach could be superior to GC
in capturing the instantaneous and nonlinear causal relationship
from EEG data.
2) Paper Overview: In this paper, first, we introduce the
core concepts in the DI framework. Second, we present how
to conduct causality analysis using direct information measures
between two time series. We provided the detailed procedure
on how to calculate the DI for two finite time series. The two
major steps involved here are optimal bin size selection for
data digitization, and probability estimation. Finally, we demonstrate the effectiveness of DI-based causality analysis using both
the simulated data and experimental fMRI data, and compare the
results with that of the GC analysis. For practical evaluation, we
collected both stimulation fMRI data with a well-defined blockdesign scene-object fMRI paradigm [36], [37] and resting-state
fMRI (rs-fMRI) data. Our analysis indicates that GC analysis is
effective in detecting linear or nearly linear causal relationship,
but has difficulty in capturing nonlinear causal relationships. On
the other hand, DI-based causality analysis can be used to capture both linear and nonlinear causal relationships. Moreover,
it is observed that brain connectivity among different regions
generally involves dynamic two-way information transmissions
between them. Our results show that when bidirectional information flow is involved, DI is a more effective than GC to
quantify the overall causal relationship.

variable X, the entropy of X is defined as

P (xi )logP (xi ).
H(X) = −

(6)

x i ∈Ω

The entropy of a random variable X represents the minimum
average number of bits needed for loseless encoding of each
symbol of X.
For a random sequence Xn , the entropy could be calculated
according to the chain rule
H(Xn ) = H(X1 ) + H(X2 |X1 ) + · · · + H(Xn |Xn −1 )
(7)
=

n


H(Xi |Xi−1 ).

(8)

i=1

2) MI: MI measures the decrease of uncertainty of one random variable after observing another one. The definition of MI
between two random variables X and Y is
I(X; Y ) = H(Y ) − H(Y |X)

P (x, y)
P (x, y)log
=
P
(x)P (y)
x,y

(9)
(10)

where H(Y ) is the total uncertainty (or information) in Y , and
H(Y |X) is the uncertainty (or information) left in Y after X is
observed. It is clear that MI is a symmetric measurement: for two
random variables X and Y , I(X; Y ) = I(Y ; X). MI measures
the dependence between two random variables. If X = Y , then
H(Y |X) = 0, and I(X; Y ) = H(X) = H(Y ). If X and Y are
independent, then I(X; Y ) = 0. Unlike the Pearson correlation
coefficient that only measures the linear dependence between
two random variables, MI includes both linear and nonlinear
dependence. For this reason, in recent years, there has been a
growing interest in applying MI to neuroscience to measure the
coupling strength among different brain regions or groups of
neurons [38], [39].
For two random sequences Xn and Yn , the MI could also be
calculated using a chain rule

II. METHODS
Let uppercase letters (X,Y ,...) denote random variables, and
lowercase letters (x,y,...) the possible values they can acquire.
For n ∈ N , define Xn = [X1 , X2 , . . . Xn ], where Xi is the
ith sample. Each Xi is a random variable taken from the
same finite alphabet Ω, with cardinality |Ω|. For any xi ∈ Ω,
P (xi ) = Prob{Xi = xi } denotes the probability for Xi to take
the value xi ; and PX i |X i −1 (xi |xi−1 ) = Prob{Xi = xi |xi−1 =
[x1 , x2 , . . . Xi−1 ]} the conditional probability that the current
sample Xi is xi , given that the previously observed sequence
is xi−1 = [x1 , x2 , . . . , xi−1 ]. Without extra explanation, the log
function log(∗) denotes the base 2 logarithm.
A. Core Concepts in the DI Framework
1) Entropy: A fundamental concept in information theory
is entropy, which is a measure of uncertainty. For a random

I(Xn ; Yn ) = H(Yn ) − H(Yn |Xn )
=

n


(11)

H(Yi |Yi−1 ) − H(Yi |Yi−1 , Xn ) (12)

i=1

=

n


I(Xn ; Yi |Yi−1 ).

(13)

i=1

3) DI: Since both correlation and MI are nondirectional, in
1990, Massey refined Markov’s work and proposed the concept
of DI [30] aiming to measure the DI flow from one random
sequence to another. Given Xn and Yn , the DI from Xn to Yn
is defined as
I(Xn → Yn ) =

n

i=1

I(Xi ; Yi |Yi−1 ).

(14)

WANG et al.: CAUSALITY ANALYSIS OF FMRI DATA BASED ON THE DI THEORY FRAMEWORK

Recall that the causally conditional entropy is defined as
H(Yn ||Xn ) =

n


H(Yi |Yi−1 , Xi )

(15)

i=1

then it follows from (14) and (15) that
I(Xn → Yn ) = H(Yn ) − H(Yn ||Xn ).

(16)

On the other hand
I(Xn ; Yn ) = H(Yn ) − H(Yn |Xn )
= I(X → Y ) + I(Y
n

n

n −1

(17)
→X )
n

(18)

= I(Xn −1 → Yn ) + I(Yn −1 → Xn )
+

n


I(Xi ; Yi |Xi−1 , Yi−1 ).

1005

neighbor (KNN)-based estimator for Kullback–Leibler distance [40]. This idea has been adopted in the work by Chai
et al. to estimate entropy and MI [41]. Theoretically, DI could
be estimated after obtaining other information theoretical measures like entropy and MI. However, the KNN estimator is based
on the assumption that samples in the random sequences are independent and identically distributed (i.i.d). Also, this approach
requires a large number of data points.
In this paper, we calculate the DI I(Xn → Yn ) by exploiting
the method initiated by Weissman et al. [42]. This approach is
universal, and not limited to any modeling assumptions on the
random sequences. There are two parts in the estimation.
Part I: This part has three steps.
1) Estimate H(Yn )

(19)

i=1

In (19), the first term I(Xn −1 → Yn ) specifies the DI flow
from Xn to Yn , the second term I(Yn −1 → Xn ) specifies the
reverse DI from Yn to Xn , and the third one represents the
conditional MI shared by both Xn and Yn . DI reflects directional and interactive influence between two random sequences,
and has recently been applied to characterize the connectivity
between different brain regions [29], [35].
4) DI and GC: GC [2], [29] has long been used in identifying causal relations between two random series. The main
idea behind the GC analysis is that, if one random process X
causally influences another random variable Y , then the knowledge of previous values of X will help to decrease errors in
predicting future values of Y . The calculation of GC is based
on the autoregressive or linear prediction models.
As can be seen from (1), the traditional GC analysis relies
on the linear prediction models. Its nonlinear extensions generally still rely on the “linear-in-the-parameter” modeling [34].
The DI, on the other hand, contains no requirement on models,
and hence, provides the freedom to characterize more generalized relationships. In [34], Amblard and Olivier investigated the
relationship between DI and GC, and showed that GC graphs
could be obtained using DI. They further pointed out that, the
DI theory provided an adequate information theoretical framework for the connectivity inference problems in neuroscience
applications.
B. DI Calculation and Causality Analysis
Developing practical estimators for DI measures is always a
challenging problem. Over the last two decades, a limited number of DI estimators have been purposed. In [29], Quinn et al.
utilized DI to infer causality based on neural spike recordings.
Their estimator is built upon the assumption that the random
sequences corresponding to spike recordings form stationary
ergodic Markov processes and adopts the simple general linear model. As a result, the causally conditional entropy can be
l
, Xl−(K −1) l )], in which g is a logsimplified as E[gJ K (Yl−J
probability function, and J and K denote the orders of the
Markov Processes. Although this method is not model free,
its validity has been verified in discovering causal relations
among groups of neurons. Verdu et al. purposed a K-nearest

1 
1
P (yi+1 |yi )log
n i=1 y
P (yi+1 |yi )
n

H(Yn ) =

i+ 1

(20)
n
1 
n i=1 x ,y

≈

i+ 1

×log

P (xi+1 , yi+1 |xi , yi )

i+ 1

1
.
P (yi+1 |yi )

(21)

2) Estimate the H(Yn ||Xn )
1
1
log
n i=1
P (yi |yi−1 , xi )
n

H(Yn ||Xn ) =

≈ −

n
1 
n i=1 x ,y
i+ 1

×log

(22)

P (xi+1 , yi+1 |xi , yi )

i+ 1

P (xi+1 , yi+1 |xi , yi )
.
Px i + 1 |X i Y i (xi+1 |xi , yi )

(23)

3) It then follows that I(Xn → Yn ) can be estimated as
H(Yn ) − H(Yn ||Xn ).
Part II: For validity of this estimation, it has been shown
ˆ n →
in the work by Weissman et al. [42] that as n → ∞, I(X
n
n
Y ) converges to the expected real value of I(X → Yn ). To
measure the causal influence of one region on another, we resort
to Dn = I(Xn → Yn ) − I(Yn → Xn ). Using (19), we have
Dn = I(Xn → Yn ) − I(Yn → Xn )

(24)

= [I(X ; Y ) − I(Y → X )]
n

n

n

n

−[I(Xn ; Yn ) − I(Xn → Yn )]
n −1

= I(X

→ Y ) − I(Y
n

n −1

(25)

→ X ).
n

(26)

As shown in (24), Dn is the difference of two DI between Xn and
Yn . If Dn is positive, that is, I(Xn −1 → Yn ) > I(Yn −1 →
Xn ), then we say that Xn shows more influence on Yn , and
can be interpreted as the causal driver during the connectivity;
otherwise we say Yn shows more influence on Xn .
To make the result more comparable, we will use γ =
Dn /I(Xn ; Yn ) instead of Dn . Clearly, γ ∈ [−1, 1]. When |γ|
approaches 1, it can be said with high confidence that there does

1006

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 5, MAY 2016

exist a causal influence between two stochastic processes; while
if |γ| is adjacent to 0, it is more likely that no clear causal relationship exists, or the samples in random sequences are subject
to strong noises. Therefore, in the simulations, a threshold-based
method is developed in interpreting the γ metric.
The causality analysis of two brain regions helps us to understand which region is more likely to be the causal driver during
a particular connectivity. However, we would like to point out
that brain connectivity between two different regions generally
involves dynamic two-way information transmission between
them, rather than a fixed one-way source to destination relationship.

Here, μ is the mean and σ the standard deviation of the signal. Then, the optimal bin size for digitization can be obtained

h∗n =

=

⎧
⎨ n ∞
⎩6

[−(x − μ)e

−∞

⎧ ∞
⎨n 
⎩6

( x −μ ) 2
− 2σ 2

u2 e−u du/πσ 3
2

0

n 1
√
6 4 πσ 3

Based on our discussions in Section II-B, for practical evaluation of the DI, the main point is how to estimate the probabilities
involved in (20) accurately from discrete time data or observations.
There are two major issues in probability estimation. First,
how to choose the optimal bin size for digitization. Second, how
to estimate the probability of a particular sequence after the
random sequence has been mapped into a series of symbols.
1) Optimal Bin Size for Time-Series Digitization: The first
problem in DI estimation of fMRI signals is digitization. If the
bin size is too large, then it results in considerable approximation
error, and cannot reflect the true data distribution accurately. If
the bin size is too small, then the number of samples falling into
each bin tends to be 0 or 1 due to the very limited data length.
As a result, the probability estimation become inaccurate. In
fact, when the bin size is too large or too small, the estimated
DI will approach zeros, due to the limited data length. Here, we
choose to use the bin size that minimizes the integrated mean
square error (IMSE) between the estimated probability and its
true value [43].
The random sequences in those fMRI signals acquire values
in the real number field, while the DI probability estimation can
be carried out only for discrete, finite-size alphabets. Hence,
mapping real-valued numbers into the symbols within a finite
alphabet is the first step for further procedures. In the digitization
process, we adopt the traditional histogram methods to estimate
the probability of the data points falling into each of the bins
representing symbols in the alphabet.
Suppose the true probability distribution function (pdf) of a
random variable X is f (x),and the estimated pdf is fˆ(x), the
IMSE is defined as

(27)
IMSE = E{fˆ(x) − f (x)}2 dx.

≈ 3.49 σn−1/3 .

stochastic process with distribution: f (x) =

√ 1 e−
2π σ

( x −μ ) 2
2σ 2

.

⎭

(Letu =

x−μ
)
σ

−1/3

=

Assume the random sequence xn was sampled from a white

⎫−1/3
⎬

(30)


C. Practical Evaluation

For a random sequence of length n, the optimal bin size that
minimizes the IMSE is given by
  ∞
−1/3
n
f 	 (x)2 dx
.
(28)
h∗n =
6 −∞

⎫−1/3
⎬
√
/ 2πσ 3 ]2 dx
(29)
⎭

(31)
(32)

∞
√
2
The results in (31) relies on the fact that 0 e−x dx = π/2.
In this paper, the fMRI data sequence is regarded as a Gaussian random process. For digitization, the bin size is chosen
according to (32).
2) Probability Estimation: After digitization, real-valued
fMRI time courses become a sequence of symbols {xn }
within an alphabet Ω. Denote the alphabet as Ω = {x|x ∈
{0, 1, . . . M − 1}}, where M = |Ω|; N0 , N1 , . . . NM −1 represent the counts for each symbol in the alphabet, respectively.
The next step is to estimate the sequence probabilities P (xi ) and
P (xi |xi−1 ), i ∈ [1, N ]. Here, we will resort to the Krichevsky–
Trofimov (KT) estimator [44] for the probability estimation. The
primary reason of using the KT estimator is that this estimator
is universal and does not put any specific modeling constraints
on the random sequence. It has been shown in [42] and [44] that
although the KT estimator is not optimal, the bias it introduces
will be upper bounded.
The KT estimator first assigns 0 to the initial value for the sequence probability, and updates this value as the sequence goes
on. In each step, the algorithm analyzes the current sequence
and generates a list of count numbers for each symbol in the alphabet. Denote this list as {N0 , N1 , . . . NM −1 }. The algorithm
goes as follows.

Initialize:
X = {∅}, {N0 , N1 , . . . NM −1 } = {0, 0, . . . , 0}, P (∅) = 0
Loop:
While i ≤ n do
xi ← {xi−1 , Xi = j}, j ∈ [0, M − 1];
{N0 , N1 , . . . NM −1 }
← {N0 , N1 , . . . , Nj + 1, . . . NM −1 };
N j +0.5
P (xi ) ← P (xi−1 ) × N 0 +N 1 +...N
M −1 +M /2
end While.

After estimating the probability P (xn ), the conditional probability PX i + 1 |X i (xi+1 |xi ) can be obtained as P (xi+1 )/P (xi ).

WANG et al.: CAUSALITY ANALYSIS OF FMRI DATA BASED ON THE DI THEORY FRAMEWORK

III. MATERIALS
A. Data Acquisition
Fourteen right-handed healthy college students (seven males,
23.4 ± 4.2 years of age) from Michigan State University volunteered to participate in this study and signed consent forms
approved by the Michigan State University Institutional Review
Board. The experiment was conducted on a 3-T GE Signa HDx
MR scanner (GE Healthcare, Waukesha, WI, USA) with an
eight-channel head coil.
For each subject, fMRI datasets were collected on a visual
stimulation condition with a scene-object fMRI paradigm, and
then, on a resting-state condition. The parameters for the fMRI
scan were: gradient-echo EPI, 36 contiguous 3-mm axial slices
in an interleaved order, time of echo = 27.7 ms, time of repetition
= 2500 ms, flip angle = 80◦ , field of view = 22 cm, matrix size
= 64 × 64, ramp sampling, and with the first four data points
discarded.
On the visual stimulation fMRI condition, each volume of
images were acquired 192 times (8 min) while a subject was
presented with 12 blocks of visual stimulation after an initial
10-s resting period. In a predefined randomized order, the
scenery pictures were presented in six blocks and the object
pictures were presented in other six blocks. All pictures were
unique. In each block, ten pictures were presented continuously
for 25 s (2.5 s for each picture), followed with a 15-s baseline condition (a white screen with a black fixation cross at the
center). The subject needed to press his/her right index finger
once when the screen was switched from the baseline to picture condition. Stimuli were displayed in color in full screen on
a 1024 × 768 32-in LCD monitor (Salvagione Design, Sausalito, CA, USA) placed at the back of the magnet room. The
LCD subtended 10.2◦ × 13.1◦ of visual angle. On the rs-fMRI
condition, each volume of images were acquired 164 times
(6 min and 50 s) after a subject was informed to relax, keep
his/her eyes closed and stay awake throughout the scan. After
the aforementioned functional data acquisition, high-resolution
volumetric T1-weighted spoiled gradient-recalled images with
cerebrospinal fluid suppressed were obtained to cover the whole
brain with 120 1.5-mm sagittal slices, 8◦ flip angle, and 24 cm
FOV. These images were used to identify anatomical locations.
B. fMRI Data Preprocessing and Analysis
All stimulus fMRI data preprocessing and analysis for each
subject were conducted with AFNI software (Cox, 1996) as
described in Henderson et al. [36]. Essentially, slice-timing correction and rigid-body motion correction were carried. Spatial
blurring with a full width half maximum of 4 mm was applied
to reduce random noise. Multiple linear regressions (using the
“3dDeconvolve” routine in AFNI) were applied on a voxel-wise
basis to find the magnitude change when each picture condition
was presented, followed with general linear tests to find the
statistical significances between stimulus conditions.
The regions of interest (ROI) in this study were defined in the
Talairach coordinate space [45]. Regions showing preferential
activation to scenes over objects (voxel-based p-value < 10−4 )
in the right and left parahippocampal gyri were defined as the

1007

right and left parahippocampal place area (PPA) [36]. The right
and left V1 ROIs were defined as the regions activated by pictures (voxel-based p-value < 10−10 ) within Brodmann area 17.
Because there was a high level of activation at and around V1,
a highly conservative p-value threshold was chosen to define
relatively focal ROIs. The right and left sensorimotor cortex
(SMC) spherical ROIs with 6-mm radius were defined with the
centers at (R36, P22, S54) and (L38, P26, S50) correspondingly in the Talairach coordinate space (R = Right, L = Left,
P = Posterior, S = Superior). The SMC coordinate locations
were defined by Witt et al. [46] and the ROIs were created
as in Zhu et al. [47]. The time courses from the stimulation
fMRI dataset that were already preprocessed as previously were
detrended and had their baselines removed also. The spatially
averaged time course at each of the aforementioned ROIs was
generated for the causality analyses discussed later.
The rs-fMRI preprocessing was also processed in AFNI [48]
as commonly applied in the field and as described in details
in Zhu et al. [47]. Essentially, slice-timing correction and rigidbody motion correction were carried. Spatial blurring with a full
width half maximum of 4 mm was applied to reduce random
noise. The time courses were detrended and the baselines were
removed. Brain global, cerebrospinal fluid, and white-matter
mean signals were modeled as nuisance variables and removed
from the time courses. Finally, the time courses were band-pass
filtered to the range of 0.009 Hz–0.08 Hz. The spatially averaged
time course at each of the forementioned ROIs was generated
for the causality analyses discussed later.
C. Simulated Data
The simulated data were synthesized from the fMRI data corresponding to the primary visual cortex (V1). Recall that the
total number of samples in the time series at V1 is 192, as described earlier. Denote this sequence as xn = [x1 , x2 , . . . , xn ],
where n = 192. Here, we will use two sets of simulated data.
Set I: For i ∈ [1, 2, . . . , 192], the first group of simulated data
y1n = [y1,1 , y1,2 , . . . , y1,n ] were obtained as
y1,i = 0.3 ∗ xi + 0.2 ∗ xi−1 .

(33)

It is clear that Xn has a causal influence on Yn . The true fMRI
data and the simulated dataset I form a linear causal relationship.
Set II: For further comparison, we introduced another group
that had a nonlinear relationship with the true fMRI data.
For i ∈ [1, 2, . . . , 192], the second set of simulated data y2n =
[y2,1 , y2,2 , . . . , y2,n ] were obtained as

1 if xi ≥ 0
y2,i =
(34)
0 if xi < 0.
Clearly, the nonlinear relationship in the second group is difficult
to be captured by a linear autoregression model. It has also
introduced a significant change in the power level in comparison
with true fMRI data.
To make the data more realistic, we added white Gaussian
noise to y1n and y2n , where the noise is of zero mean and variance
σ02 . In the simulation, the signal-to-noise ratio (SNR), which was
calculated as 20log(σx /σ0 ), was set in a range between 4 and

1008

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 5, MAY 2016

20 dB. Before performing fMRI causality analysis, we carry out
both DI-based causality analysis and the GC analysis over xn
and yn for method validation. The analysis based on simulated
data helps to set up a threshold for the metric γ = [I(Xn −1 →
Yn ) − I(Yn −1 → Xn )]/I(Xn ; Yn ). Note that the subtraction
operation in γ may help to reduce the noise effect in fMRI data.
In the GC analysis, the parameter F-test was adopted to generate
the p-value. The max lag in the test was set to be 2.
IV. RESULTS
In this section, we demonstrate the effectiveness of DI-based
causality analysis using both stimulated and acquired fMRI data,
and compare the results with that of the GC analysis.
A. Causality Between the fMRI Data and its Descending
Simulated Data
In this section, we validate the DI-based causality analysis
approach using fMRI data and the simulated data generated
from it.
1) DI-Based Causality Analysis: Fig. 1(a) and (b) presents
the DI-based causality analysis results corresponding to the
fMRI data and the simulated dataset I. Fig. 1(a) shows the
comparison of MI I(xn ; y1n ), DI I(xn → y1n ), and the reversed DI I(y1n → xn ). In this example, SNR = 8 dB. Clearly,
I(xn → y1n ) > I(y1n → xn ). As can be seen, the estimated DI
shows a clear surplus from xn → y1n , which implies that there
is a causal relationship between xn and y1n , and xn is more
likely to be the cause as expected.
Fig. 1(b) shows the values of γ versus different SNR levels. As
can be seen, when the SNR is above 6 dB (i.e., the noise level
is relatively low), we can observe a clear causal relationship
from xn → y1n . As the noise level gets higher, i.e., when SNR
< 5 dB, the causal relationship becomes ambiguous.
The results corresponding to the fMRI data xn and the simulated dataset II, y2n , are shown in Fig. 1(c) and 1(d). As can be
seen, the results are similar with that corresponding to xn and
y1n . Again, the DI-based causality analysis indicates that there is
a causal relationship between xn and y2n , and xn is more likely
to be the causal part as expected.
It should be noted that the relationship between y1n and xn is
linear, but the relationship between y2n and xn is nonlinear. It
can be seen that the DI-based causality analysis is effective in the
nonlinear case as well. The analysis results are consistent with
our prior knowledge that there is a causal relationship between
xn and y1n , and xn and y2n , with xn as the causal side in both
cases.
Based on our simulation results on xn and y1n , which is more
similar with true fMRI data than y2n , we found that
1) γ ∈ [0.1, 1] implies that X has more causal influence on
Y; accordingly, γ ∈ [−1, −0.1] implies that Y has more
causal influence on X;
2) γ ∈ [−0.1, 0.1] implies that there is no clear dominant
influence between X and Y.
2) GC Analysis: We then apply GC analysis to xn and y1n
and xn and y2n , the results are shown in Fig. 2. Fig. 2(a) and (b)
shows the p-value of the GC analysis corresponding to xn → y1n

Fig. 1. DI-based test results: MI, DI, and the γ metric. Here, x n denotes the
fMRI data, y 1n the simulation dataset I, and y 2n the simulation dataset II. (a) MI
and DI between x n and y 1n ; (b) γ versus SNR corresponding to x n and y 1n ;
(c) MI and DI between x n and y 2n ; (d) γ versus SNR corresponding to x n
and y 2n .

WANG et al.: CAUSALITY ANALYSIS OF FMRI DATA BASED ON THE DI THEORY FRAMEWORK

1009

and y1n → xn , respectively. As can be seen, there is a clear
causal relationship from xn → y1n ; most medians in the boxes
indicate a highly significant casual relationship (p < 0.0002,
which is much smaller than the commonly accepted p-value
0.01) [49]. These results lead to the expected conclusion that
two random sequences xn and y1n are Granger causally related.
However, for the test on xn and y2n , in which the causal relationship is completely nonlinear, the GC test was not able to
capture the causal relationship xn → y2n . In both Fig. 2(c) and
2(d), most medians in the boxes indicate that there is no significant causal relationship between these two time sequences
(0.2 < p < 0.6), leading to an unexpected conclusion that xn
and y2n are not causally related.
B. Causality Analysis Based Only on the Experimental
fMRI Data

Fig. 2. Interregion GC test results based on fMRI data and two sets of simulation data generated from it. (a) Test results for the direction x n → y 1n ; (b) test
results for the direction y 1n → x n ; (c) test results for the direction x n → y 2n ;
(d) test results for the direction y 2n → x n .

In this section, we apply both DI-based causality analysis and
GC analysis to the experimental fMRI data. We collected both
stimulation-based fMRI data with a well-defined block-design
scene-object fMRI paradigm as discussed earlier [36], [37], and
rs-fMRI data. Recall that in the scene-object paradigm, subjects
viewed blocks of scenery and object pictures. They were asked to
press a button once under the right index finger when they saw a
block of pictures. We test the robustness of our causality analysis
techniques against some expected outcomes: under the stimulation fMRI paradigm, the primary visual cortex (V1) and nearby
regions are activated first, followed with activation in the PPA for
higher level scene processing. Some but relatively small activations in the left SMC is also expected following V1 activations.
Overall sequential neuronal activity is not expected between
the aforementioned right and left homologous regions. Under
the resting-state condition, neuronal activity is not expected to
occur in a sequential manner among aforementioned regions.
1) DI-Based Causaity Analysis: Here, we examine the potential causal relationship between left V1 and left PPA, left
V1 and left SMC under both resting-state and visual stimulation conditions. The DI-based γ values are shown in Fig. 3. In
resting-state condition, the medians of the γ values are within
the [−0.1,0.1] region. The left V1 does not exhibit a dominating
causal influence over other regions, including left PPA and left
SMC. However, under the simulation paradigm, the γ values
for left V1 → left PPA and left V1 → left SMC increase significantly. In other words, under the stimulation, left V1 shows
stronger influences over left PPA, as well as left SMC, as expected.
Fig. 4 shows the γ values between the right and left homologous brain regions in both resting state and stimulus-based state.
As can be seen, the median values are well below 0.1. That is,
the DI-based causality analysis indicates that there is no dominating influence between the left and right homologous brain
regions.
2) GC Analysis: As in the DI-based analysis, we carry parallel GC analyses between brain regions (see Fig. 5). For the left
V1–left PPA pair [see Fig. 5(a) and (c)], GC analyses indicate
that there is a dominating influence of left V1 over left PPA
under both resting-state (median p = 0.004) and stimulation

1010

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 5, MAY 2016

Fig. 3. Interregion γ values of DI-based causality analysis (a) V1 and PPA
(b) V1 and SMC.

(median p = 0.0005) conditions. However, causal relationship
between left V1 and left PPA is not expected in the resting state
condition. With the GC analysis, it is difficult to distinguish between the resting state and stimulus-based state, as the p-values
in both states are small enough to indicate a causal relationship.
For the left V1–left SMC pair [see Fig. 5(b) and (d)], the GC
analysis seems to have reversed the expected causal relationship,
and indicates that SMC is more likely to be the cause.
Fig. 6 shows the results of the GC analysis for the right and
left homologous brain regions, including V1, PPA, and SMC.
The results indicated that the information flow between each
pair of homologous regions was very unbalanced, and varied
significantly in most cases. This is contradicting to the expected
nonsequential activation between them, as it is believed that the
right and left homologous regions should not have significant
sequential activation.
C. Impact of Hemodynamics on DI-Based Causality Analysis
In this section, we evaluate the impact of hemodynamics
(i.e., the blood flow or the circulation) on the performance of

Fig. 4. Inner-region (left–right) γ values of the DI-based causality analysis
(a) V1 (b) PPA (c) SMC.

DI-based causality analysis. We take a representative model
for the hemodynamic response function h(t) = t8.6 e−t/0.547
[50]. Let x(t) be the sawtooth waveform (to mimic the situation
under periodic stimulation), and y(t) = 0.3x(t) + 0.2x(t − 1).
Clearly, x(t) is the causal side. Define
x̂(t) = hx (t) ∗ x(t)

(35)

WANG et al.: CAUSALITY ANALYSIS OF FMRI DATA BASED ON THE DI THEORY FRAMEWORK

Fig. 6.
Fig. 5. Interregion GC test result (a) V1 to PPA (b) V1 to SMC (c) PPA to V1
(d) SMC to V1.

Inner-region (left–right) GC test results (a) V1 (b) PPA (c) SMC.

1011

1012

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 5, MAY 2016

ŷ(t) = hy (t) ∗ y(t).

(36)

Recall that the Dirac delta function, defined as
 ∞
δ(t) = 0∀t = 0,
δ(t)dt = 1
−∞

is generally used to model the impulse response of an ideal
communication channel. We conduct DI-based causal analysis
for x̂ and ŷ under the following scenarios.
1) Group 1
a) case 1.1: hx (t) = δ(t), hy (t) = δ(t);
b) case 1.2: hx (t) = h(t), hy (t) = h(t);
c) case 1.3: hx (t) = δ(t), hy (t) = 3δ(t).
2) Group 2
a) case 2.1: hx (t) = δ(t), hy (t) = δ(t);
b) case 2.2: hx (t) = 0.3h(t) + 0.2h(t − 1), hy (t) =
0.3h(t) + 0.2h(t − 1);
c) case
2.3:
hx (t) = h(t), hy (t) = 0.3h(t) +
0.2h(t − 1);
d) case
2.4:
hx (t) = h(t), hy (t) = 0.7h(t) +
0.4h(t − 1).
3) Group 3
a) case 3.1: hx (t) = δ(t), hy (t) = δ(t);
b) case 3.2: hx (t) = h(t), hy (t) = h(2t).
The results are shown in Fig. 7. We look at Group 1 first. It
can be observed that, when the hemodynamic response functions
hx (t) and hy (t) are identical, the causal relationship between
x̂(t) and ŷ(t) would be the same with that of x(t) and y(t).
That is, x̂(t) is the causal part. However, in case 1.3, when the
power level of ŷ(t) is much higher than that of x̂(t), the causal
relationship is either reversed or becomes ambiguous.
In Group 2, we consider the multipath channel model. For
cases 2.1 and 2.2, we can see clearly that x̂(t) is the causal
side, but in case 2.3, the power level of ŷ(t) is higher than that
of x̂(t), again, the causal relationship is reversed or becomes
ambiguous.
In Group 3, we consider the case when the hemodynamic
response hy (t) changes much faster than hx (t). From Fig. 7(c),
it can be seen that this did not bother the DI-based method. We
can see clearly that x̂(t) is the causal side.
For comparison purpose, we examine the impact of hemodynamics on GC analysis as well. In most cases, GC cannot
distinguish which one is the casual side. Due to space limits,
only the results for case 2.4 are shown here. Please refer to
Fig. 8. As can be seen, based on the p-values, both x(t) and y(t)
are identified as the causal side by GC. Our analysis indicates
that GC is more sensitive to hemodynamic effects.
D. Summary of Results
In the simulations, we first performed DI-based causality
analysis between the fMRI data and the simulated data, and
compared the results with that of the GC analysis. Two sets
of simulated data were generated from the fMRI data. Set I
is obtained by convolving the fMRI data with a simple causal
model; Set II is obtained by mapping the positive points in the
fMRI data to 1, and the negative points to zeros. The simulation
results showed that the GC analysis could identify the cause

Fig. 7. DI under different hemodyamic response functions (a) Group 1 (b)
Group 2 (c) Group 3.

clearly between the fMRI data and dataset I, but failed for the
test corresponding to dataset II, due to the severe nonlinearity of
the data. The DI-based approach, on the other hand, can identify
the cause accurately in both cases as long as the SNR is above
5 dB.

WANG et al.: CAUSALITY ANALYSIS OF FMRI DATA BASED ON THE DI THEORY FRAMEWORK

1013

state and the stimulus-based state, there is no dominant cause
observed in the right and left homologous brain regions. For the
GC analysis, it can be seen that: 1) the results for the V1–PPA
are consistent with that of the DI analysis; 2) for the V1–SMC
pair, the results corresponding to resting state are also consistent
with the DI analysis; however, in the stimulation-based state, it
shows that SMC is more likely to be the cause, which is contradicting with the expected sequential brain activation (V1 to
SMC). In this paradigm, the activity in SMC is weak, which
could be a reason that the GC analysis could not detect the
sequential activity; and 3) the information flows between each
pair of homologous regions were not balanced in most cases,
which is contradicting to the expected nonsequential activation
between them.
Finally, we evaluate the impact of hemodynamic effects on
DI-based causality analysis method using simulated data. we
observed that: 1) even if the hemodynamic response function of
the driving side changes slower than that of the other side, the
proposed DI method can still identify the causal side accurately;
2) however, when the power level of the driving side is much
lower than that of the other side, then the causal relationship may
be reversed or become ambiguous. This is because that: in the
digitization process, higher power level maps to higher entropy;
as in BOLD, higher fMRI amplitude implies more significant
activity levels. We will investigate more on this in the future.
Our results indicate that DI is an effective technique to quantify the overall causal relationship. It is also observed that brain
connectivity between two different regions generally involves
dynamic two-way information transmission between them,
rather than a fixed one-way source to destination relationship.
V. CONCLUSION

Fig. 8.

GC test results of case 2.4.

As can be seen, GC analysis is effective in detecting linear
or nearly linear causal relationship, but has difficulty in capturing nonlinear causal relationships. The underlying argument is
that GC analysis relies heavily on the linear prediction theory,
or linear modeling of the involved parameters. The DI-based
causality analysis, on the other hand, does not have any modeling constraints on the sequences to be evaluated, hence can be
used to capture both linear and nonlinear causal relationships.
We then applied both the DI-based analysis and the GC analysis to examine the causal relationship in V1–PPA, V1–SMC,
as well as the right and left homologous brain regions, including
V1, PPA and SMC. From the DI-based analysis, we observed
that: 1) in the resting state, there is no dominant cause for both
the V1–PPA and V1–SMC pairs; 2) in the stimulation-based
state, V1 turns out to be the cause in the V1-SMC pair. For the
V1–PPA pair, although not as strong as in the V1–SMC pair, V1
is more likely to be the cause part; and 3) for both the resting

In this paper, we presented the DI framework and showed
how to apply it for fMRI causality analysis. We provided the
detailed procedure on how to calculate the DI for two finite
time series. The two major steps involved here are optimal bin
size selection for data digitization, and probability estimation.
We applied the DI-based causality analysis to both the simulated
data and experimental fMRI data, and compared the results with
that of the GC analysis. Our results indicated that GC analysis is
effective in detecting linear or nearly linear causal relationship,
but has difficulty in capturing nonlinear causal relationships. On
the other hand, DI-based causality analysis is effective in capturing both linear and nonlinear causal relationships. Moreover,
it was observed that brain connectivity among different regions
generally involves dynamic two-way information transmissions
between them. Our results showed that when bidirectional information flow is present, DI is more effective than GC to quantify
the overall causal relationship.
We would also like to point out that with DI-based approach,
the performance improves as the data size increases. This is
because the probability estimation gets more accurate as we have
more samples. For future work, we would continue our research
on functional and effective brain connectivity by combining the
conventional information theory, the DI framework as well as
the network-level information theory.

1014

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 5, MAY 2016

REFERENCES
[1] A. Roebroeck et al., “Causal time series analysis of functional magnetic
resonance imaging data,” in Proc. JMLR: Workshop Conf., 2011, vol. 12,
pp. 65–94.
[2] C. Granger, “Investigating causal relations by econometric models and
cross-spectral methods,” Econometrica, vol. 37, no. 3, pp. 424–438, 1969.
[3] J. Geweke, “Measurement of linear dependence and feedback between
multiple time series,” J. Amer. Statist. Assoc., vol. 77, no. 378, pp. 304–
313, 1982.
[4] K. J. Friston, “Functional and effective connectivity: A review,” Brain
Connectivity, vol. 1, no. 1, pp. 13–36, 2011.
[5] C. Bernasconi and P. Konig, “On the directionality of cortical interactions
studied by structural analysis of electrophysiological recordings,” Biol.
Cybern., vol. 81, pp. 199–210, 1999.
[6] R. Goebela et al., “Investigating directed cortical interactions in timeresolved fMRI data using vector autoregressive modeling and Granger
Causality mapping,” Magn. Reson. Imag., vol. 21, pp. 1251–1261, 2003.
[7] A. Roebroeck et al., “Mapping directed influence over the brain using
Granger causality and fMRI,” NeuroImage, vol. 258, pp. 230–2421, 2005.
[8] S. L. Bressler et al., “Top-down control of human visual cortex by frontal
and parietal cortex in anticipatory visual spatial attention,” J. Neurosci.,
vol. 28, pp. 10 056–10 061, 2008.
[9] P. Liang et al., “Altered causal connectivity of resting state brain networks
in amnesic MCI,” PLoS ONE, vol. 9, p. e88476, Mar. 2014.
[10] X. Wen et al., “Is Granger Causality a viable technique for analyzing fMRI
data?” PLOS ONE, vol. 8, pp. 1–11, Jul. 2013.
[11] X. Wen et al., “Causal interactions in attention networks predict behavioral
performance,” J. Neurosci., vol. 32, pp. 1284–1292, Jan. 2012.
[12] O. David et al., “Identifying neural drivers with functional MRI: An
electrophysiological validation,” PLOS Biol., vol. 6, pp. 2683–2697, Dec.
2008.
[13] B. P. Bezruchko et al., “Modeling nonlinear oscillatory systems and diagnostics of coupling between them using chaotic time series analysis:
Applications in neurophysiology,” Phys.-Uspekhi, vol. 51, no. 3, pp. 304–
310, 2008.
[14] D. Marinazzo et al., “Kernel method for nonlinear Granger Causality,”
Phys. Rev. Lett., vol. 100, no. 14, p. 144103, 2008.
[15] M. Hu and H. Liang, “A copula approach to assessing Granger causality,”
NeuroImage, vol. 100, pp. 125–134, 2014.
[16] S. Iyengar et al., “Quantifying eeg synchrony using copulas,” in Proc.
IEEE Int. Conf. Acoustics Speech Signal Process., Mar. 2010, pp. 505–
508.
[17] D. Marinazzo et al., “Nonlinear connectivity by Granger causality,” Neuroimage, vol. 58, no. 2, pp. 330–338, 2011.
[18] J. Pearl, Causality: Models, Reasoning, and Inference, 2nd ed. New York,
NY, USA: Cambridge Univ. Press, Sep. 2009.
[19] E. E. Schadt et al., “An integrative genomics approach to infer causal
associations between gene expression and disease,” Nature Genetics,
vol. 37, pp. 710–717, Jul. 2005.
[20] M. Luessi et al., “Variational Bayesian causal connectivity analysis for
fMRI,” Frontiers Neuroinformat., vol. 8, pp. 1–16, May 2014.
[21] K. Friston et al., “Dynamic causal modeling,” NeuroImage, vol. 19,
pp. 1273–1302, 2003.
[22] K. Stephan et al., “Dynamic causal models of neural system dynamics:
Current state and future extensions,” J. Biosci., vol. 32, pp. 129–144, Jan.
2007.
[23] S. Ryali et al., “Multivariate dynamical systems models for estimating
causal interactionsin fMRI,” Neuroimage, vol. 54, pp. 807–823, 2011.
[24] R. Vicente et al., “Transfer entropy—A model-free measure of effective connectivity for the neurosciences,” J. Comput. Neurosci., vol. 30,
pp. 45–67, 2011.
[25] M. Wibral et al., Directed Information Measures in Neuroscience. New
York, NY, USA: Springer, 2014.
[26] M. Lungarella and O. Sporns, “Mapping information flow in sensorimotor
networks,” PLOS Comput. Biol., vol. 2, pp. 1301–1312, Oct. 2006.
[27] R. Vicente et al., “Transfer entropy—A model-free measure of effective connectivity for the neurosciences,” J. Comput. Neurosci., vol. 30,
pp. 45–67, Aug. 2010.
[28] J. T. Lizier et al., “Multivariate information-theoretic measures reveal
directed information structure and task relevant changes in fMRI connectivity,” J. Comput. Neurosci., vol. 30, pp. 85–107, Aug. 2010.
[29] C. Quinn et al., “Estimating the directed information to infer causal relationships in ensemble neural spike train recordings,” J. Comput. Neurosci.,
vol. 30, pp. 17–44, Feb. 2011.

[30] J. Massey, “Causality, feedback, and directed information,” in Proc. Int.
Symp. Inf. Theory Appl., Honolulu, HI, USA, Nov. 1990, pp. 303–305.
[31] G. Kramer, “Capacity results for the discrete memoryless network,” IEEE
Trans. Inf. Theory, vol. 49, no. 1, pp. 4–21, 2003.
[32] H. H. Permuter et al., “Interpretations of directed information in portfolio
theory, data compression, and hypothesis testing,” IEEE Trans. Inf. Theory,
vol. 57, no. 3, pp. 3248–3259, Jun. 2009.
[33] N. Soltani and A. Goldsmith, “Inferring neural connectivity via measured
delay in directed information estimates,” in Proc. IEEE Int. Symp. Inf.
Theory, Jul. 2013, pp. 2503–2507.
[34] P.-O. Amblard and O. J. Michel, “On directed information theory and
Granger causality graphs,” J. Comput. Neurosci., vol. 30, pp. 7–16, Feb.
2010.
[35] Y. Liu and S. Aviyente, “Quantification of effective connectivity in the
brain using a measure of directed information,” Comput. Math. Methods
Med., vol. 2012, 2012.
[36] J. Henderson et al., “Functions of parahippocampal place area and retrosplenial cortex in real-world scene analysis: An fMRI study,” Visual
Cognition, vol. 19, no. 7, pp. 910–927, 2011.
[37] R. Epstein and N. Kanwisher, “A cortical representation of the local visual
environment,” Nature, vol. 392, no. 6676, pp. 598–601, 1998.
[38] J. Jeong et al., “Mutual information analysis of the eeg in patients
with Alzheimer’s disease,” Clin. Neurophysiol., vol. 112, pp. 827–835,
2001.
[39] L. Bettencourt et al., “Functional structure of cortical neuronal networks
grown in vitro,” Phys. Rev., vol. 75, no. 2, pp. 021 915–1–021 915–10,
2007.
[40] Q. Wang et al., “Divergence estimation for multidimensional densities
via k-nearest-neighbor distances,” IEEE Trans. Inf. Theory, vol. 55, no. 5,
pp. 2392–2405, May 2009.
[41] B. Chai et al., “Exploring functional connectivities of the human
brain using multivariate information analysis,” in Advances in Neural Information Processing Systems, Y. Bengio, D. Schuurmans, J.
Lafferty, C. Williams, and A. Culotta, Eds. Red Hook, NY, USA:
Curran Associates, Inc., 2009, pp. 270–278. [Online]. Available:
http://papers.nips.cc/paper/3797-exploring-functional-connectivities-of the-human-brain-using-multivariate-information-analysis.pdf
[42] J. Jiao et al., “Universal estimation of directed information,” IEEE Trans.
Inf. Theory, vol. 59, no. 10, pp. 6220–6242, Oct. 2013.
[43] D. Scott, “On optimal and data-based histograms,” Biometrika, vol. 66,
no. 3, pp. 605–610, 1979.
[44] F. Willemx et al., “The context-tree weighting method: Basic properties,”
IEEE Trans. Inf. Theory, vol. 41, no. 3, pp. 653–664, May 1995.
[45] J. Talairach and P. Tournoux, Co-Planar Stereotaxic Atlas of the Human
Brain: 3-Dimensional Proportional System: An Approach to Cerebral
Imaging. New York, NY, USA: Georg Thieme Verlag., 1988.
[46] S. T. Witt et al., “Functional neuroimaging correlates of finger-tapping
task variations: an ale meta-analysis,” Neuroimage, vol. 42, no. 1,
pp. 343–356, 2008.
[47] D. C. Zhu and S. Majumdar, “Integration of resting-state fMRI and
diffusion-weighted MRI connectivity analyses of the human brain: limitations and improvement,” J. Neuroimag., vol. 24, no. 2, pp. 1763–186,
2014.
[48] R. W. Cox, “AFNI: Software for analysis and visualization of functional
magnetic resonance neuroimages,” Comput. Biomed. Res., vol. 29, no. 3,
pp. 162–173, 1996.
[49] S. Smith, “Overview of fMRI analysis,” Brit. J. Radiol., vol. 77, pp. S167–
S175, 2004.
[50] K. Schreiber and B. Krekelberg, “The statistical analysis of multi-voxel
patterns in functional imaging,” PLoS ONE, vol. 8, no. 7, p. e69328, Jul.
2013.

Zhe Wang received the B.Sc. degree from the Shandong Normal University, Shandong, China, in 2010
and the M.Sc. degree from the Southeast University,
Dhaka, Bangladesh, in 2013.
He is currently a Graduate Research Assistant in
the Electrical and Computer Engineering Department
at Michigan State University, East Lansing, MI, USA.
His current research focuses on computational analysis of functional magnetic resonance imaging data.

WANG et al.: CAUSALITY ANALYSIS OF FMRI DATA BASED ON THE DI THEORY FRAMEWORK

Ahmed Alahmadi received the B.S. degree in electrical engineering from Taibah University, Madina,
Saudi Arabia, in 2010, and the M.S. degree in electrical and computer engineering from Michigan State
University, East Lansing, MI, USA, in 2014. He
is currently working toward the Ph.D. degree in
electrical and computer engineering at Michigan
State University. His research interests include
wireless communications and networking, wireless
security and computational neuroscience.

David C. Zhu received the Ph.D. degree in biomedical engineering from the University of California,
Davis, CA, USA, in 1999.
He is an Associate Professor of Radiology,
Psychology and (adjunct) Electrical and Computer
Engineering at Michigan State University, (MSU)
East Lansing, MI, USA . He is also a faculty member in both the Cognitive Science Program and the
Neuroscience Program at MSU. His research interests are in the areas of magnetic resonance imaging,
and the technical development and applications of
neuroimaging.

1015

Tongtong Li received the Ph.D. degree in electrical
engineering from Auburn University, Auburn, AL,
USA, in 2000.
She is currently an Associate Professor in the Department of Electrical and Computer Engineering at
Michigan State University, East Lansing, MI, USA.
Her research interests fall into the areas of communication system design and networking, and statistical
signal processing, with applications in computational
neuroscience.
Dr. Li is currently an Associate Editor for IEEE
Transactions on Signal Processing. She is a recipient of the National Science
Foundation (NSF) CAREER Award and a senior member of the IEEE.

