IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 5, MAY 2015

1395

Sparse Dissimilarity-Constrained Coding
for Glaucoma Screening
Jun Cheng∗ , Fengshou Yin, Damon Wing Kee Wong, Member, IEEE, Dacheng Tao, Fellow, IEEE,
and Jiang Liu, Member, IEEE

Abstract—Objective: Glaucoma is an irreversible chronic eye
disease that leads to vision loss. As it can be slowed down through
treatment, detecting the disease in time is important. However,
many patients are unaware of the disease because it progresses
slowly without easily noticeable symptoms. Currently, there is no
effective method for low-cost population-based glaucoma detection
or screening. Recent studies have shown that automated optic nerve
head assessment from 2-D retinal fundus images is promising for
low-cost glaucoma screening. In this paper, we propose a method
for cup to disc ratio (CDR) assessment using 2-D retinal fundus
images. Methods: In the proposed method, the optic disc is first
segmented and reconstructed using a novel sparse dissimilarityconstrained coding (SDC) approach which considers both the dissimilarity constraint and the sparsity constraint from a set of reference discs with known CDRs. Subsequently, the reconstruction
coefficients from the SDC are used to compute the CDR for the
testing disc. Results: The proposed method has been tested for
CDR assessment in a database of 650 images with CDRs manually measured by trained professionals previously. Experimental
results show an average CDR error of 0.064 and correlation coefficient of 0.67 compared with the manual CDRs, better than
the state-of-the-art methods. Our proposed method has also been
tested for glaucoma screening. The method achieves areas under
curve of 0.83 and 0.88 on datasets of 650 and 1676 images, respectively, outperforming other methods. Conclusion: The proposed
method achieves good accuracy for glaucoma detection. Significance: The method has a great potential to be used for large-scale
population-based glaucoma screening.
Index Terms—Cup to disc ratio (CDR), glaucoma screening,
sparse dissimilarity-constrained coding (SDC).

I. INTRODUCTION
LAUCOMA is a chronic eye disease. It is the leading
cause of irreversible blindness, and is predicted to affect
around 80 million people by 2020 [1]. As the disease progresses
silently without easily noticeable visual symptoms especially in
the early stages, 50–90% of patients are unaware of the disease

G

Manuscript received August 31, 2014; revised October 19, 2014; accepted
December 9, 2014. Date of publication December 9, 2014; date of current
version April 17, 2015. This work was supported in part by the Agency for
Science, Technology and Research, Singapore, under SERC Grant 121-1480007. Asterisk indicates corresponding author.
∗ J. Cheng is with the Ocular Imaging (iMED) Department, Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore
138632 (e-mail: jcheng@i2r.a-star.edu.sg).
F. Yin, D. W. K. Wong, and J. Liu are with the Ocular Imaging (iMED)
Department, Institute for Infocomm Research, Agency for Science, Technology
and Research.
D. Tao is with the Centre for Quantum Computation & Intelligent Systems
and the Faculty of Engineering and Information Technology, University of
Technology, Sydney.
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2015.2389234

until it has reached its advanced stages [2]–[4]. Thus, glaucoma is also called the silent theft of sight. Although glaucoma cannot be cured currently, it can be slowed down through
treatment. This makes the screening of people at high risk of
glaucoma for timely detection very meaningful. Currently, the
air-puff intraocular pressure (IOP) measurement, visual field
test, and optic nerve head (ONH) assessment are often used in
glaucoma assessment. However, the IOP measurement provides
low accuracy in glaucoma detection and a visual field examination requires special equipment only present in specialized
hospitals. Therefore, they are unsuitable for screening in the
population. ONH assessment is more promising for glaucoma
screening. It can be done by a trained professional. However,
manual assessment is subjective, time consuming, and expensive. In recent years, automated algorithms for ONH assessment
have received much attention. There is some research into automated cup to disc ratio (CDR) assessment from 3-D images such
as stereo images [5] and optical coherence tomography images
[6]–[8]. However, the cost of obtaining 3-D images is still high,
which makes it inappropriate for low-cost large-scale screening
[9]. The 2-D retinal fundus images can be acquired at much
lower cost because such fundus cameras are widely available
in hospitals, polyclinics, eye centers, and especially in optical
shops. Therefore, there is little additional hardware cost to build
a glaucoma screening program using existing fundus cameras.
This paper is for automated CDR assessment from 2-D fundus
images.
One strategy for automatic ONH assessment is to use imagelevel features for a binary classification between glaucomatous
and healthy subjects [10]–[12]. In these methods, selection of
features and classification strategy is difficult and challenging
[9]. The other strategy is to follow clinical indicators. Many
glaucoma risk factors can be considered, such as the vertical
CDR [13], disc diameter [14], ISNT [15] rule, etc. Although
different ophthalmologists have different opinions on the usefulness of these factors, CDR is well accepted and commonly
used. A larger CDR generally indicates a higher risk of glaucoma and vice versa.
In 2-D retinal fundus images, the ONH or the optic disc can
be divided into a central bright zone called the optic cup and a
peripheral region called the neuroretinal rim, as shown in Fig. 1.
The CDR is computed as the ratio of the vertical cup diameter to
the vertical disc diameter clinically. Many methods have been
proposed for CDR assessment/computation from 2-D images. In
[16], thresholding based on intensity is used. However, in many
subjects from screening, the cup boundaries are not clear from
intensity. Later, relevant vessel bending is used to aid in cup
detection [9]. The challenge is to correctly identify the vessel

0018-9294 © 2015 EU

1396

Fig. 1. Structure of an optic disc: optic disc boundary (blue), optic cup (white),
neuroretinal rim (cyan), CDR is computed as VCD/VDD.

bends. Yin et al. developed an active shape model (ASM)-based
approach by combining prior knowledge with contour deformation [17]. However, the contour deformation does not work
well when the contrast between the cup and rim is weak. Cheng
et al. proposed superpixel classification-based approach [18]
by including features from superpixel level, which significantly
improves the disc and cup detection. However, it has a bias
of underestimating large cups and overestimating small cups
due to the dominance of medium sized cups used to train the
model. Very often, these methods rely on the contrast between
the cup and the neuroretinal rim to find the cup boundary for
CDR computation and can be challenging to use effectively
when the contrast is weak. Recently, Xu et al. proposed a reconstruction or atlas-based method for cup estimation from the
discs [19]. The method applies locality-constrained linear coding (LLC) [20] with 2 -norm Gaussian distance regularization to
reconstruct the disc from a set of reference images with known
CDRs. Then, it infers the CDR based on the reconstruction coefficients. It significantly reduces the CDR errors. However, the
2 -norm Gaussian distance suffers from the blood vessels (BV)
occlusion and other noise, which lead to a bias similar to the
superpixel-based method [18].
This paper focuses on computing the CDR from the disc.
Motivated from the observation that similar discs often have
very similar CDRs and the fact that many discs do not have
obvious boundary between neuroretinal rim and the optic cup,
we propose a sparse dissimilarity-constrained coding (SDC) to
estimate the CDR for a new disc image. In comparison with the
LLC method [19] which uses the Gaussian distance, the proposed method computes the dissimilarities between the testing
disc images and the reference disc images from their overall
intensity changes and use them as the dissimilarity constraint in
the SDC-based disc reconstruction. Several major factors that
often affect the disc dissimilarity computation and the disc reconstruction have been considered, including BVs, uneven illumination within each disc image, and the illumination changes
between different images. In addition, a sparsity constraint is
also included in SDC inspired from the observation that a few
reference disc images closest to the testing disc image are usually sufficient to estimate its CDR. The main contributions of
this paper include
1) a novel SDC method for CDR assessment which considers
both dissimilarity constraint and sparse constraint;
2) a new method to compute the dissimilarity between two
disc images;

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 5, MAY 2015

3) the results show that the proposed method achieves much
more accurate CDR assessment and better glaucoma
screening performance than the state-of-the-art methods.
Different from most of previous methods which are based on
low-level image segmentation, this method computes an optimal
sparse linear reconstruction of the input disc from the most
similar reference discs to estimate the CDR. This makes the
algorithms more robust to the cases where the contrast between
optic cup and rim is low.
The rest of the paper is organized as follows. In Section II,
we give a brief review of the disc localization and disc segmentation followed by the disc normalization used in this paper.
Section III introduces the proposed SDC method for CDR assessment including the computation of disc dissimilarity, the
formulation of SDC, the solution of SDC, and the CDR assessment using SDC. Section IV shows the experimental results
followed by the discussions and conclusions in the last section.
II. DISC LOCALIZATION, SEGMENTATION,
AND NORMALIZATION
In order to compute the CDR using the proposed SDC, it is
important to locate and segment the disc. The disc localization
focuses on finding an approximate location of the disc, very
often the disc center. It has been extensively studied for applications in diabetic screening [21]. The disc localization is often
achieved based on brightness [22], [23], anatomical structures
among the disc, macula, and retinal BVs [24], [25] or the relative
locations of these anatomical structures [26], [27]. In this paper,
the disc is located using our earlier brightness-based method in
[23], which works well in our datasets for glaucoma screening
as there are few white lesions to confuse disc localization as
compared to diabetic screening. The segmentation estimates the
disc boundary, which is a challenging task due to BV occlusions,
pathological changes around disc, and variable imaging conditions. Many algorithms have been proposed for disc segmentation, such as template-based approaches [28], [29], deformable
model-based approaches [6], [30] and classification-based approaches [5], [31].
In this paper, we segment the disc using the state-of-theart self-assessed disc segmentation method [32], which is a
combination of three approaches. It has been shown that the selfassessed approach achieves more accurate disc segmentation
than the individual methods in [32]. Here, we give a brief review
of the method while more details can be found in [32].
A. Self-Assessed Disc Segmentation
Optic disc segmentation from retinal fundus image is a fundamental but important step in many applications such as automated glaucoma detection. Very often, one method might work
well on many images but fail on some other images and it is
difficult to have a single method or model to cover all scenarios. Therefore, it is important to combine results from several methods to minimize the risk of failure. The self-assessed
disc segmentation proposed in [32] selects one result based on
the outputs from three individual disc segmentation methods.
Each individual method obtains a disc boundary and computes a

CHENG et al.: SPARSE DISSIMILARITY-CONSTRAINED CODING FOR GLAUCOMA SCREENING

self-assessment score that reflects a confidence or reliability of
its automated result. The self-assessed method determines the
disc by applying the three disc detection methods one by one
until a confident output is obtained. If none of the three methods
gives a confident result, the result from the most reliable method
is used.
The first individual method is the ASM-based method [30].
An initial boundary is obtained by circular Hough transform of
the edge points in the region containing the disc. Then, ASM
is used to deform the contour to the disc boundary. The selfassessment confidence score for the ASM method is computed
using the distance between the final boundary and the edge
points in the image. The second method detects the disc by
superpixel classification [31]. In this method, superpixels are
first generated from the region containing the disc. Then, histograms and center surround statistics are extracted to classify
each superpixel as disc or nondisc. The self-assessment confidence score for this method is computed by evaluating the difference between the raw boundary from superpixel classification
and its best-fitted ellipse [31]. The third method detects the disc
using elliptical Hough transform (EHT) [29]. In this method,
edges of the images are first detected and an EHT is applied to
find the disc boundary. The self-assessment confidence score for
the EHT method is computed using the number of edge points
lying on the final disc boundary. Based on the performance by
the individual methods, superpixel classification-based method
[31] is used as the most reliable method [32].
B. Disc Normalization
There are many choices for the disc representation. Earlier
experience [5], [9], [17] shows that the green channel of the
retinal color image is the most suitable one for CDR computation. Therefore, we use this channel in the paper. All disc images
from right eyes are flipped horizontally to avoid the difference
between the left and right eyes. The mean intensity is also removed to avoid the difference due to different illuminations in
different disc images. Besides that, we also conduct BV removal
and within disc uneven illumination correction.
1) BV Removal: The BVs within the disc vary largely among
different individuals. The disc reconstruction and the dissimilarity computation between two disc images are greatly affected
by them. Therefore, it is important to remove the BVs. Many
automated vessel detection methods [33], [34] reported in the literature can be used. In this application, we found it unnecessary
to use very complex and time-consuming vessel segmentation
to get precise BVs for the disc dissimilarity computation and
later the disc reconstruction. Instead, an approximate segmentation of BV is sufficient for the objective of computing the
disc dissimilarity. In this paper, we use a morphological closing
process with an empirically selected structure element size of 5
to estimate the BV

1, If |x(j, k) − x̃(j, k)| > T
BV(j, k) =
(1)
0, otherwise
where x̃ = morph(x) denotes the image after applying a morphological closing process on x. Then, the vessel removed image

1397

Fig. 2. Illustration of unbalance correction: A linear mapping based on the
average intensities on the left and right side.

x̂ is obtained by replacing the vessel pixels in x with the pixels
in x̃, i.e.,

x̃(j, k), If BV(j, k) = 1
x̂(j, k) =
(2)
x(j, k), Otherwise.
2) Within Disc Uneven Illumination Correction: Uneven illumination across the optic disc is another factor that affects
the dissimilarity computation and the disc reconstruction. Very
often, the temporal side of the disc is brighter than the nasal side
while the unbalance varies from one disc image to another. In
our method, we apply a linear mapping to correct the unbalance.
As shown in Fig. 2, we first compute the average intensity x̄l
and x̄r from the first and last p columns of the disc x̂. Then, the
balance corrected disc xb is computed as
xb (j, k) =

(k − kc )
(x̄l − x̄r ) + x̂(j, k)
km ax − p

(3)

where kc is the center column of the disc, and km ax is the
maximum number of columns. In this paper, we set p as 10%
of km ax , i.e., p = 5 for our disc resized to be 50 × 50. The
performance of the method is not sensitive to the value of p.
III. SPARSE DISSIMILARITY-CONSTRAINED CODING
In this section, we introduce the proposed spare dissimilarityconstrained coding algorithm. Denote a set of n reference disc
images X = [x1 , . . . , xn ] and the corresponding CDRs as r =
[r1 , r2 , . . . , rn ]T , i = 1, 2, . . . , n, xi denotes the ith balance corrected disc computed above. Inspired from the reconstructionbased method [19], we want to compute a linear reconstruction
coefficient w = [w1 , . . . , wn ]T for a new testing disc image y
while minimizing the reconstruction error y − Xw2 . From
our experience, a few reference disc images that are closest to y
are sufficient to estimate the CDR for y while too many reference images often lead to a bias especially when the reference
images do not have uniform CDR distribution. Therefore, we
want to limit the number of reference images used, i.e., we want
to minimize the nonzeros elements in w, or w0 . Because 0 norm is a NP-hard problem, the 1 -norm w1 is used instead.
In addition, as the reconstruction is more accurate from images
more similar to the test disc, we add the difference between the
reference and test disc images as a regularization term in the objective function to penalize the use of references. Denoting the
difference between y and the reference discs in X as the vector
d = [d1 , . . . , dn ]T , we want to minimize the overall difference
term expressed as d  w, where di represents the difference

1398

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 5, MAY 2015

As the BVs are not relevant to the overall intensity changes of the
discs, we exclude pixels belonging to BVs extracted previously,
i.e., pixels (j, k) with BV (j, k) = 1. It can be seen that
v = (QT Q)−1 QT x.

Fig. 3. Illustration of surface fitting on a disc image. (a) A disc in 3-D plot.
(b) Best-fitted disc surface.

between y and xi ,  denotes the elementwise
 product. Previ
−x i 2
between the test
ously, Gaussian distance di = exp y 2σ
2
disc y and the ith reference disc xi is used in LLC [19]. However, the pixelwise distance between two disc images suffers
from various noise including BVs, disc alignment error, etc. In
this paper, we propose to compute the dissimilarity between two
disc images.

(7)

The difference between two surfaces Sx i and Sy is computed
from their coefficients vx i and vy . As the overall intensity
change of the disc is only related to the a and c components
ax i , cx i , ay , cy , the difference di between the two surfaces can
be computed by a function f (ax i , cx i , ay , cy ). Here, the subscript denotes the disc used to compute the surface parameters.
In this paper, we use

di = f (ax i , cx i , ay , cy ) = (ax i − ay )2 + (cx i − cy )2 . (8)
B. Formulation of SDC
Combining the dissimilarity term d  w2 and the sparsity
term w1 with the data term y − Xw2 , the objective function
of the proposed SDC method is then given by
argmin y − Xw2 + λ1 · d  w2 + λ2 · w1

(9)

w

A. Dissimilarity
It is important to compute a dissimilarity score between two
discs which reflects their CDR difference. As mentioned, the
previously used Gaussian distance [19] often suffers from noise,
imperfect vessel removal, etc. Therefore, it faces some challenges to represent the actual CDR difference between two discs.
Very often, we found two discs with similar CDRs have a Gaussian distance even larger than two discs with significant different CDRs. Therefore, Gaussian distance is not a good choice.
In fact, this is also the reason that a k-nearest neighbor (kNN)
approach works poorly for this task. In this paper, we observe
that the overall intensity change within the disc is highly related
with the CDR value. Motivated from this, we propose to apply
surface fitting within the disc image to compute the dissimilarity. Fig. 3 shows an example of a disc image plotted in 3-D and
its best-fitted surface. Although higher order polynomials can
be computed, a second-order 2-D polynomial surface S(j, k) is
sufficient to capture the overall intensity change. It is defined by
v = [a, b, c, e, g]T ∈ R5
S(j, k) = aj 2 + bj + ck 2 + ek + g = (q)T · v

(4)

where q = [j 2 , j, k 2 , k, 1]T and T denotes the transpose.
This can be expressed in matrix form as
s = Qv

(5)

where s contains the coefficients S(j, k) strung out into a column vector, and the matrix Q contains the coefficients of q as
specified in (4). The coefficient v is then determined by minimizing the following quadratic error between s and x, where x
contains the intensities of the disc image xi or y strung out into
a column vector
E(v ) = (x − s)2
= (x − Qv )2 .

(6)

where λ1 and λ2 are parameters controlling the weights of the
two regularization items.
Rewriting the second item and merging it with the first item
in (9), we get


argmin y − Xw2 + λ1 · d  w2 + λ2 · w1
w



= argmin y − Xw2 + λ1 · Dw2 + λ2 · w1
w

⎛
  
⎞
 
2

 y


X




− √
= argmin ⎝

w
 + λ2 · w1 ⎠

 0


w
λ1 D


(10)
= argmin ŷ − X̂w2 + λ2 · w1
w

where D = diag(d) denotes a diagonal matrix with main diagonal element D(i,
 i)= di , i = 1,
 . . . , n, 0 is a vector of 0s
y
X
with length n, ŷ =
and X̂ = √
.
0
λ1 D
C. Solution
The problem in (10) is a standard 1 norm regularized leastsquare minimization problem. It has been shown that this unconstrained convex optimization problem can be represented as
the following constrained optimization problem [35]


(11)
argmin ŷ − X̂w2 , s.t., w1 < t
w

where t is inversely related to λ2 . It can be solved by least angle
regression (LARS) [36].
In LARS [36], ỹ = X̂w is initialized with all zeros and iteratively updated. In each iteration, the feature most correlated
with the objective function in (10) without 1 -norm penalty is
selected and added into an active set Ω. ỹ is updated in the
direction of most correlated feature until another feature with

CHENG et al.: SPARSE DISSIMILARITY-CONSTRAINED CODING FOR GLAUCOMA SCREENING

1399

equivalent correlation is added. When there is more than one
feature in Ω, LARS updates ỹ in a direction equiangular among
all features. More details of the algorithms can be found in [36].
D. CDR Assessment
After solving (10), we obtain w. Then, the ratio r̂ is computed
as
r̂ =

1
1Tw w

rT w

(12)

where 1w is a vector of 1s with length equals to the size of w.
In this paper, manual CDRs from the reference images are used
to form r.
IV. EXPERIMENTAL RESULTS
A. Dataset and Evaluation Criteria
We use 2326 images from 2326 different subject eyes including 650 from the Singapore Malay Eye Study (SiMES) and
1676 from the Singapore Chinese Eye Study (SCES), acquired
using Canon CR-DGi and Canon CR-1 Mark -II digital retinal cameras, respectively. For convenience, we name the two
datasets as SiMES set and SCES set, respectively. The IOPs of
these subject eyes have been measured. The CDRs of SiMES
images with image dimension 3072 × 2048 have been manually
measured by trained professionals in previous studies [37]. In
this paper, we use these manual CDRs as “ground truth” unless specified. The SCES images are collected in a screening
study. There are two sizes: 3504 × 2336 and 3888 × 2592. All
the SCES images are resized to be the same size as the SiMES
set for convenience. Among the 2326 eyes, 168 SiMES, and
46 SCES eyes are diagnosed as glaucomatous by ophthalmologists. These diagnostic outcomes are used as the gold ground
truth. The disc localization method in [23] is used to locate the
disc and determine an 800 × 800 region of interest for disc segmentation. It locates the disc correctly in all 650 SiMES images.
In SCES, it fails in four of 1676 images. We use what the method
obtained for all the SCES images even if the localization fails.
Then, we segment and normalize the disc using the methods in
Section II. After that, the minimum bounding box of the disc
is downsampled from a rectangular region of 200–450 pixels in
height or width to be 50 × 50 pixels for reconstruction. In our
test, the SiMES images are randomly divided into 325 reference
or training images and 325 testing disc images unless specified.
In each partition, the 325 reference images are used to reconstruct the testing images using the proposed SDC method. The
reconstruction coefficients are obtained and used to compute the
CDRs for the testing images.
The CDR assessment accuracy is evaluated using the following criteria: 1) CDR error, computed as δ = |CDRm − CDR|,
where CDRm denotes the manual CDR. 2) The correlation with
manual CDR. In this paper, we compute the Pearson’s correlation coefficient which measures the linear correlation between
the automated CDRs and the manual CDRs. 3) The glaucoma
detection accuracy. Sensitivity and specificity are often used as
measures of accuracy in diagnosis tests. There is a tradeoff between the specificity and sensitivity of a test. This is usually

Fig. 4.

Accuracies after each LARS iteration.

expressed on a receiver operating characteristic (ROC) curve,
which plots sensitivity against 1-specificity for all possible values. Often, the area under the curve (AUC) is calculated as the
overall measure of diagnostic strength of a test. In our analysis,
we evaluate the method through the AUC.
B. Performance Evaluation Under Different Settings
To evaluate the robustness of the proposed method, it is important to conduct the tests under different settings.
1) Parameters: There are two main parameters λ1 and λ2 in
the SDC. The first parameter λ1 determines the weight of the
dissimilarity regularization. In this paper, we conduct a crossvalidation search in 10−10 , 10−9 , . . . , 1010 in a reference set
and we found that 104 gives best result. This value also makes
the first two items in the SDC objective function close so that
neither of the first two items would dominate the result. Slight
variation of λ1 from 8000 to 12 000 does not have a large effect
on the performance.
The weight λ2 for 1 -norm penalty is inversely related to t
in (11), which is automatically determined and updated through
the LARS iterations [35], [36]. Since t and w are updated in
each LARS iteration, we evaluate the performance after each
iteration. Fig. 4 shows the performance. As we can see, given an
iteration of 100 or above, the performance is stable. In this paper,
we fix the number of iterations as 100 instead of specifying the
weight λ2 .
2) Reference Images: The reference images used to reconstruct the discs are important. Since there are many possibilities
to divide the SiMES images for reference and testing, it is important to know how different partitions affect the performance.
In addition, the number of reference images n is also important.
In our tests, we conduct the tests with n from 25 to 325 with a
step of 50. In the experiments, we obtain ten different random
partitions and conduct twofold cross validation in each partition.
Each partition divides the images to set Ai and Bi with 325 images in each set, i = 1, 2, . . . , 10. We randomly select n images
from Ai as reference to test in Bi and vice versa. Therefore,
we get 20 results for each n. In Fig. 5, we utilize the box plot
to show the performance variations as the number of reference
images n changes. Each box plot produces a box and whisker
plot for each setting. The boxes have lines at the lower quartile, median, and upper quartile values. The whiskers are lines

1400

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 5, MAY 2015

TABLE I
PERFORMANCE BY VARIOUS METHODS
CDR Error

Airpuff IOP
Superpixel [18]
LLE [39]
SC [38]
LLC [19]
Proposed
Expert B
Expert A

0.078
0.080
0.071
0.072
0.064
0.078
-

Pearson

AUC

Correlation

SiMES

SCES

0.59
0.47
0.59
0.60
0.67
0.63
-

0.59
0.80
0.75
0.80
0.81
0.83
0.82
0.84

0.66
0.82
0.74
0.85
0.86
0.88
-

Fig. 5. Box plot of performance for different number of reference images. (a)
CDR Error. (b) Pearson’s Correlation. (c) AUC.

extending from each end of the boxes to show the extent of
the rest of the data. Maximum whisker length is 1.5 times the
interquartile range. The results show slight performance improvement as n increases.
The computational cost is also evaluated. The major factor
that affects the speed of the proposed method is the number of
LARS iterations. It takes 0.17 to 4.0 s for a new disc image
tested with 325 reference images when the number of iterations
is changed from 100 to 300 using a dual core 3.0-GHz PC with
3.25-GB RAM. Since Fig. 4 shows that an iteration of 100
times is sufficient to obtain a stable result, we fix a maximum of
100 iterations for the rest of the tests. The number of reference
images n affects the computational cost linearly. Our tests show
an approximately linear increase of time from 0.12 to 0.17 s
per image for n from 100 to 325. This is much faster than
our previous superpixel classification [18] method which takes
around 2.6 s. Compared with LLC [19], the major difference in
computation is that LLC has a closed form solution while the
proposed method requires LARS iteration. However, the closed
form solution in [19] requires an inverse of matrix with size
n × n. Our tests show a time cost from 0.13 to 0.31 s as n
increases from 100 to 325 by LLC.
C. Comparison With Other Methods
To compare the proposed SDC method with other methods,
we tested the two most competitive state-of-the-art methods
using superpixel [18] and LLC [19]. Besides LLC, we have
also implemented two other possible reconstruction-based approaches based on sparse coding (SC) [38] and locally linear
embedding (LLE) [39] to justify the effectiveness of the regularization used in the proposed method. The SC is solved by the
same LARS solver as used in this paper and the LLE is solved
directly as it has closed-form solution. In addition, we have also
invited another expert ophthalmologist to measure the CDRs
for the 650 SiMES images manually. To be differentiated, we
denote the previous set of manual CDRs as “Expert A” and this
new set of CDRs as “Expert B.”
The experiments are conducted on both the SiMES and SCES
datasets. For the SiMES images, we use 325 reference images
to reconstruct the remaining 325 testing images and compute
their CDRs based on the ten random partitions as described in

Fig. 6. Box plot of performance by different methods. (a) CDR error. (b)
Pearson’s Correlation. (c) AUC.

Section IV-B. The obtained CDRs are compared with the “Expert A” CDRs and the diagnostic outcomes to compute the CDR
error, correlation coefficient, and AUC. For the SCES images,
all the SiMES images are used as reference images and only
one AUC is computed. The average CDR error, correlation, and
AUCs are given in Table I. The results show that the proposed
method achieves more accurate CDR values with lower CDR
error and higher correlation coefficient than the other methods.
Compared with the superpixel method and LLC method, the
proposed method reduces the CDR error by 18.0% and 11.1%,
respectively. In terms of the Pearson’s correlation, the relative
improvement is 13.6% and 11.7%, respectively. In terms of diagnosis, the improvement in AUC is relatively smaller. This is
likely because the diagnosis is more related with the CDR comparison between glaucomatous subjects and the healthy subjects.
Compared with other reconstruction-based methods such as SC
[38] and LLE [39], the proposed method also achieves better
results, which justifies the benefits of using the dissimilarity
constraint and the sparsity constraint in SDC. The proposed
method achieves an accuracy even better than the “Expert B.”
This implies that the method can be used for automated CDR
computation without decreasing the accuracy compared with
a manual one. Fig. 6 uses box plots to show the performance
variations by different methods in the SiMES images. We have
also conducted the t-test to evaluate the significance level of the
difference between the proposed method and other methods including superpixel, LLE, SC, and LLC as well as manual CDRs
by “Expert B.” We get p < 0.01 for all measurements in all the
tests. Therefore, the improvements are significant. Fig. 7 shows

CHENG et al.: SPARSE DISSIMILARITY-CONSTRAINED CODING FOR GLAUCOMA SCREENING

1401

TABLE II
CDR ERRORS BY THE PROPOSED METHOD USING DIFFERENT r AND
DIFFERENT EVALUATION GROUND TRUTH CDRS IN SIMES DATASET
Evaluation Ground Truth

r

Expert A
Expert B
Average

Expert A

Expert B

Average

0.064
0.068
0.065

0.069
0.066
0.068

0.055
0.057
0.055

TABLE III
PEARSON’S CORRELATION COEFFICIENTS BY THE PROPOSED METHOD USING
DIFFERENT r AND DIFFERENT EVALUATION GROUND TRUTH CDRS
IN SIMES DATASET
Evaluation Ground Truth

r

Fig. 7. CDR plots by various methods using manual CDRs by “Expert A” as
ground truth. (a) Superpixel [18]. (b) LCC [19]. (c) Expert B. (d) Proposed.

Fig. 8. ROC curves by various methods (best viewed in color). (a) SiMES.
(b) SCES.

scatter plots of the correspondence between manual CDRs and
automated CDRs by the superpixel method, the LLC method, the
“Expert B,” and the proposed method for one set of 325 testing
images in SiMES. As can be seen, the proposed method reduces
the bias in the superpixel and LLC methods. Even though a linear
mapping can be applied on the two methods to correct the bias,
it does not improve the correlation and the AUCs. Compared
with “Expert B,” the proposed method has smaller variation.
Fig. 8 compares the ROC curves by the proposed method with
those by the superpixel method, the LLC method, and the airpuff IOP in one set of 325 SiMES and the 1676 SCES images.
In addition, the ROC curves by the “Expert A” and the “Expert
B” are also given for the 325 SiMES images.
D. Effect of Reference Manual CDRs r
In the above, we have shown the results when we use the first
set of manual CDRs from “Expert A” to form r in (12). Since
manual assessment of CDRs is very subjective, it is reasonable
that different people give different manual CDRs especially for
challenging cases without obvious contrast between cup and

Expert A
Expert B
Average

Expert A

Expert B

Average

0.67
0.66
0.67

0.67
0.66
0.67

0.73
0.72
0.74

rim. Therefore, it is important to evaluate how different r would
affect the results. In this paper, we also use manual CDRs from
“Expert B,” as well as the average CDRs between “Expert A”
and “Expert B” to form r in (12) and compute CDRs. Therefore, we obtain three sets of automated CDRs. Since the results
from the manual CDRs from one expert are likely to be biased
to this person, we use all the three sets of manual CDRs as
evaluation ground truth CDRs to compute the CDR errors and
correlation coefficients in the subsequent tests. Again, the experiments are repeated for all the 20 sets of 325 reference and
325 testing images as in Section IV-B. Table II show the average CDR errors. In the table, each row shows how the average
CDR error changes when we fix r in CDR computation while
using different evaluation ground truths to compute the CDR
error. Each column shows how the average CDR error changes
when we fix the evaluation ground truth CDRs to compute CDR
error while using different r in CDR computation. It is shown
that the automated CDRs are slightly biased toward the manual
CDRs used in r. It is also observed that when the average CDRs
are used as evaluation ground truth, the CDR errors are much
smaller. This is intuitively sound as individual experts mark the
CDR subjectively with different errors compared with underlying actual CDRs while the averaged CDRs tend to neutralize the
errors. Table III shows the corresponding average correlation coefficients. The correlation coefficients between automated and
manual CDRs based on “Expert A” and “Expert B” are comparable with slight bias toward the manual CDRs used in r. Similar
to the observation on the CDR errors, the correlation coefficients are higher when the average CDRs are used as evaluation
ground truth. Table IV shows the AUCs for both SiMES and
SCES datasets when different r are used. The AUCs obtained
using different r are comparable as well.
V. DISCUSSIONS AND CONCLUSION
In this paper, we propose the SDC for CDR assessment. The proposed SDC formulation combines the pixelwise

1402

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 5, MAY 2015

TABLE IV
AUCS BY THE PROPOSED METHOD USING DIFFERENT r IN SIMES
AND SCES DATASETS
r
SiMES
SCES

Expert A

Expert B

Average

0.83
0.88

0.82
0.87

0.83
0.88

difference in data term y − Xw2 with the dissimilarity term
λ1 · d  w2 . It is shown that by including the disc dissimilarity constraint and the 1 -norm regularization into the SDC objective function, the proposed method significantly improves the
CDR computation compared with other reconstruction-based
methods such as LLE, SC and LLC. Compared with previous methods using superpixel or LLC, it improves the CDR
computation accuracy by more than 10%. The previous bias
of underestimating the large CDRs is reduced. Although the
improvement in AUC is relatively smaller, it is still significant
and an automated CDR with higher correlation and less bias is
still appreciated. It is important to highlight that the proposed
method achieves CDR correlation with the “Expert A” even
higher than that between the two experts. Even though this is
likely because the CDRs are computed based on the “Expert
A” CDRs measured by the same person, it shows that the proposed method achieves an error smaller than the interobserver
error. Therefore, the proposed method can be potentially used
to replace manual CDR assessment to save time and reduce
cost. The limitation is that the method may not capture local
cup deformation. It is also interesting to note that by using average CDRs from the two sets of manual CDRs as reference and
ground truth, the proposed method achieves smaller CDR error
and higher correlation.
The proposed SDC method achieves CDR computation and
glaucoma detection accuracy comparable with manual CDR assessment by experts. It suggests that the proposed method can be
used to replace the time-consuming and expensive manual CDR
assessment. Therefore, the proposed method has great potential
for low-cost glaucoma screening in polyclinics, eye centers, and
especially in optical shops, according to discussions with clinicians and ophthalmologists. This paper discussed the proposed
SDC for CDR computation. Within this paper, the general formulation in (9) can be extended for other applications, though
the computation of the d might need to be specially defined
based on actual data. The CDR-based screening from 2-D images has its limitations. For example, 2-D images do not have
depth information, which is the primary indicator of cup. Compared with 3-D images which capture true 3-D morphological
structures of disc and cup, 2-D images capture the color information of disc and rely on intensities to estimate the CDR.
Future work will explore the integration of other factors to improve diagnostic outcomes toward a more reliable and efficient
glaucoma screening system.
ACKNOWLEDGMENT
The authors would like to thank those who provided materials
that were used in this study.

REFERENCES
[1] H. A. Quigley and A. T. Broman, “The number of people with glaucoma worldwide in 2010 and 2020,” Brit. J. Ophthalmol., vol. 90, no. 3,
pp. 262–267, 2006.
[2] S. Y. Shen, “The prevalence and types of glaucoma in Malay people: The
Singapore Malay eye study,” Investigative Ophthalmol. Vis. Sci., vol. 49,
no. 9, pp. 3846–3851, 2008.
[3] P. J. Foster et al., “The prevalence of glaucoma in Chinese residents of Singapore: A cross-sectional population survey of the Tanjong Pagar district,” Arch. Ophthalmol., vol. 118, no. 8, pp. 1105–1111,
2000.
[4] Centre for Eye Research Australia. (2008). Tunnel vision: The economic impact of primary open angle glaucoma. [Online]. Available:
http://nla.gov.au/nla.arc-86954
[5] M. D. Abràmoff et al., “Automated segmentation of the optic disc from
stereo color photographs using physiologically plausible features,” Investigative Ophthalmol. Vis. Sci., vol. 48, pp. 1665–1673, 2007.
[6] J. Xu et al., “Optic disk feature extraction via modified deformable model
technique for glaucoma analysis,” Pattern Recognit., vol. 40, pp. 2063–
2076, 2007.
[7] Z. Hu et al., “Automated segmentation of neural canal opening and optic
cup in 3-D spectral optical coherence tomography volumes of the optic
nerve head,” Investigative Ophthalmol. Vis. Sci., vol. 51, pp. 5708–5717,
2010.
[8] M. D. Abràmoff et al., “Automated segmentation of the cup and rim from
spectral domain OCT of the optic nerve head,” Investigative Ophthalmol.
Vis. Sci., vol. 50, pp. 5778–5784, 2009.
[9] G. D. Joshi et al., “Optic disk and cup segmentation from monocular
color retinal images for glaucoma assessment,” IEEE Trans. Med. Imag.,
vol. 30, no. 6, pp. 1192–1205, Jun. 2011.
[10] J. Meier et al., “Effects of preprocessing eye fundus images on appearance
based glaucoma classification,” in Proc. 12th Int. Conf. Comput. Anal.
Images Patterns, 2007, pp. 165–172.
[11] R. Bock et al., “Classifying glaucoma with image-based features from
fundus photographs,” in Proc. Annu. Pattern Recog. Symp. German Assoc.
Pattern Recog., 2007, pp. 355–364.
[12] R. Bock et al., “Glaucoma risk index: Automated glaucoma detection
from color fundus images,” Med. Image Anal., vol. 14, pp. 471–481,
2010.
[13] T. Damms and F. Dannheim, “Sensitivity and specificity of optic disc
parameters in chronic glaucoma,” Investigative Ophthalmol. Vis. Sci.,
vol. 34, pp. 2246–2250, 1993.
[14] D. Michael and O. D. Hancox, “Optic disc size, an important consideration
in the glaucoma evaluation,” Clin. Eye Vis. Care, vol. 11, pp. 59–62, 1999.
[15] N. Harizman et al., “The ISNT rule and differentiation of normal from
glaucomatous eyes,” Arch. Ophthalmol., vol. 124, pp. 1579–1583, 2006.
[16] G. D. Joshi et al., “Optic disk and cup boundary detection using regional
information,” in Proc. IEEE Int. Symp. Biomed. Imag., 2010, pp. 948–951.
[17] F. Yin et al., “Automated segmentation of optic disc and optic cup in fundus
images for glaucoma diagnosis,” in Proc. IEEE Int. Symp. Comput.-Based
Med. Syst., 2012, pp. 1–6.
[18] J. Cheng et al., “Superpixel classification based optic disc and optic cup
segmentation for glaucoma screening,” IEEE Trans. Med. Imag., vol. 32,
no. 6, pp. 1019–1032, Jun. 2013.
[19] Y. Xu et al., “Efficient reconstruction-based optic cup localization for
glaucoma screening,” Proc. Med. Image Comput. Comput.-Assisted Intervention, 2013, vol. 8151, pp. 445–452.
[20] J. Wang et al., “Locality-constrained linear coding for image classification,” in Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog., 2010,
pp. 3360–3367.
[21] M. D. Abràmoff et al., “Retinal imaging and image analysis,” IEEE Trans.
Med. Imag., vol. 3, no. 9, pp. 169–208, Jan. 2010.
[22] H. Li and O. Chutatape, “Automatic location of optic disc in retinal images,” in Proc. Int. Conf. Image Process., 2001, vol. 2, pp. 837–840.
[23] Z. Zhang et al., “Optic disc region of interest localization in fundus image
for glaucoma detection in ARGALI,” in Proc. Int. Conf. Ind. Electron.
Appl., pp. 1686–1689. 2010
[24] A. Hoover and M. Goldbaum, “Locating the optic nerve in a retinal image
using the fuzzy convergence of the blood vessels,” IEEE Trans. Med.
Imag., vol. 22, no. 8, pp. 951–958, Aug. 2003.
[25] M. Foracchia et al., “Detection of optic disc in retinal images by means
of a geometrical model of vessel structure,” IEEE Trans. Med. Imag.,
vol. 23, no. 10, pp. 1189–1195, Oct. 2004.
[26] H. Li and O. Chutatape, “Automated feature extraction in color retinal
images by a model based approach,” IEEE Trans. Biomed. Eng., vol. 51,
no. 2, pp. 246–254, Feb. 2004.

CHENG et al.: SPARSE DISSIMILARITY-CONSTRAINED CODING FOR GLAUCOMA SCREENING

[27] A. P. Rovira and E. Trucco, “Robust optic disc location via combination
of weak detectors,” in Proc. Int. Conf. IEEE Eng. Med. Biol. Soc., 2008,
pp. 3542–3545.
[28] A. Aquino et al., “Detecting the optic disc boundary in digital fundus
images using morphological, edge detection, and feature extraction techniques,” IEEE Trans. Med. Imag., vol. 29, no. 11, pp. 1860–1869, Nov.
2010.
[29] J. Cheng et al., “Automatic optic disc segmentation with peripapillary
atrophy elimination,” in Proc. IEEE Int. Conf. Eng. Med. Biol. Soc., 2011,
pp. 6624–6627.
[30] F. Yin et al., “Model-based optic nerve head segmentation on retinal
fundus images,” in Proc. IEEE Int. Conf. Eng. Med. Biol. Soc., 2011,
pp. 2626–2629.
[31] J. Cheng et al., “Superpixel classification based optic disc segmentation,”
in Proc. 11th Asian Conf. Comput. Vis., 2013, vol. 7725, pp. 293–304.
[32] J. Cheng et al., “Self-assessment for optic disc segmentation,” in Proc.
IEEE Int. Conf. Eng. Med. Biol. Soc., 2013, pp. 5861–5864.
[33] T. Chanwimaluang and G. Fan, “An efficient blood vessel detection algorithm for retinal images using local entropy thresholding,” in Proc. Int.
Symp. Circuits Syst., 2003, vol. 5, pp. 21–24.
[34] C. A. Lupascu et al., “FABC: Retinal vessel segmentation using adaboost,”
IEEE Trans. Inf. Technol. Biomed., vol. 14, no. 5, pp. 1267–1274, Sep.
2010.
[35] M. Schmidt, “Lease squares optimization with l1-norm regularization,”
Dept. Comput. Sci., Univ. British Columbia, Vancouver, BC, Canada,
Tech. Rep. CS542B, 2005.
[36] B. Efron et al., “Least angle regression,” Ann. Statist., vol. 32, pp. 68–73,
2004.
[37] Z. Zhang et al., “Origa-light: An online retinal fundus image database for
glaucoma analysis and research,” in Proc. IEEE Int. Conf. Eng. Med. Biol.
Soc., 2010, pp. 3065–3068.
[38] B. A. Olshausen and D. J. Field, “Emergence of simple-cell receptive field
properties by learning a sparse code for natural images,” Nature, vol. 381,
no. 6583, pp. 607–609, 1996.
[39] S. Roweis and L. Saul, “Nonlinear dimensionality reduction by locally
linear embedding,” Science, vol. 290, no. 5500, pp. 2323–2326, 2000.
Jun Cheng received the B.E. degree in electronic
engineering and information science from the University of Science and Technology of China, Hefei,
China, and the Ph.D. degree in electrical and electronic engineering from Nanyang Technological University, Singapore.
In 2009, he joined the Institute for Infocomm Research, Agency of Science, Technology and
Research, Singapore. Earlier, he was with Panasonic
Singapore Laboratories for more than two years. He
is currently leading the research of fundus and optical
coherence tomography image processing and understanding in Ocular Imaging
(iMED) Department in the Institute for Infocomm Research. He has developed
many algorithms for automated ocular disease detection including glaucoma,
age-related macular degeneration, pathological myopia. He has authored many
publications at prestigious journals/conferences, such as IEEE TRANSACTIONS
ON MEDICAL IMAGING, IEEE TRANSACTIONS ON IMAGE PROCESSING, Investigative Ophthalmology and Visual Science, Journal of the American Medical
Informatics Association, Medical Image Computing and Computer Assisted Intervention and invented more than ten patents. His research interests include
computer vision, image processing, medical imaging, and machine learning.
Dr. Cheng received the IES Prestigious Engineering Achievement Award in
2013.
Fengshou Yin received the Bachelor’s degree in electrical engineering and the Master’s degree in computer engineering from the National University of
Singapore, Singapore, in 2008 and 2011, respectively.
He has also worked on the design and development
of several intelligent medical software systems for the
automated analysis and diagnosis of ocular diseases.
His research interests include medical image processing, machine learning, and cloud computing.
Mr. Yin has published more than 30 papers in ocular image processing for the disease of glaucoma,
age-related macular degeneration, cataract, and myopia. He is currently a Senior Research Engineer with the Institute for Infocomm Research, Agency for
Science, Technology and Research, Singapore.

1403

Damon Wing Kee Wong (M’09) received the Bachelor’s and Doctorate degrees in electrical engineering from the School of Electrical and Electronic
Engineering, College of Engineering, Nanyang Technological University, Singapore, in 2003 and 2007,
respectively.
He joined the Institute for Infocomm Research,
Agency for Science, Technology and Research in
2007 and is currently the Head of the Ocular Imaging (iMED) Department in I2R. He is also an adjunct
Research Fellow in the Singapore Eye Research Institute. He has contributed to more than 50 peer reviewed publications and
conference proceedings, and holds more than ten patents. His research interests
include medical image processing, ocular image analysis and computer assisted
detection, and he hold a number of grants focusing on intelligent ocular and
vision analysis.

Dacheng Tao (F’15) received the B.Eng. degree
from University of Science and Technology, China,
M.Phil. degree from the Chinese University, Hong
Kong, and Ph.D degree from the University of London.
He is a Professor of computer science with the
Centre for Quantum Computation and Intelligent
Systems, and the Faculty of Engineering and Information Technology, University of Technology, Sydney, NSW, Australia. He mainly applies statistics and
mathematics to data analytics and his research interests spread across computer vision, data science, geoinformatics, image processing, machine learning, multimedia, neural networks, and video surveillance.
His research results have expounded in one monograph and 100+ publications
at prestigious journals and prominent conferences, such as IEEE TRANSACTIONS
ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, IEEE TRANSACTIONS ON
NEURAL NETWORKS AND LEARNING SYSTEMS, IEEE TRANSACTIONS ON IMAGE PROCESSING, Journal of Machine Learning Research, International Journal of Computer Vision, Neural Information Processing Systems, International
Conference on Machine Learning, Computer Vision and Pattern Recognition,
International Conference on Computer Vision, European Conference on Computer Vision, International Conference on Data Mining, ACM Special Interest
Group on Knowledge Discovery and Data Mining and Multimedia, with several
best paper awards, such as the best theory/algorithm paper runner up award in
IEEE International Conference on Data Mining in 2007, the Best Student Paper
Award in IEEE International Conference on Data Mining in 2013, and the 2014
International Conference on Data Mining 10 Year Highest Paper Award.

Jiang Liu (M’09) received the B.Eng. degree from
University of Science and Technology, China, Master’s and Ph.D degree from National University of
Singapore.
He is the Advisor of Ocular Imaging (iMED) Department, Institute for Infocomm, Agency for Science, Technology and Research, Singapore. He is
the Director of the ATLANTIA Joint Lab with Topcon Corporation, Tokyo, Japan, and the AVATA Joint
Lab with National Healthcare Group, Singapore. He
is also an Adjunct Associate Professor with the
Nanyang Technological University, Singapore, and an Adjunct Scientist with
Singapore Eye Research Institute, Singapore General Hospital, Singapore. He
had more than 20 years of working experiences with both industries and
academia. He has authored/coauthored more than 100 international refereed
journal and conference papers as well as invented/coinvented more than ten
patents. His major research interests include medical image processing, imageguided robot assisted surgical training, glaucoma, and ocular disease diagnosis.
He has been awarded with many competitive research grants. He is leading
many multidisciplinary research projects now as Principle Investigators.

