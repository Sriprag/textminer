IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

1379

Part-Based Multiderivative Edge Cross-Sectional
Profiles for Polyp Detection in Colonoscopy
Yi Wang, Student Member, IEEE, Wallapak Tavanapong, Member, IEEE, Johnny Wong, Member, IEEE,
JungHwan Oh, Member, IEEE, and Piet C. de Groen

Abstract—This paper presents a novel technique for automated
detection of protruding polyps in colonoscopy images using edge
cross-section profiles (ECSP). We propose a part-based multiderivative ECSP that computes derivative functions of an edge
cross-section profile and segments each of these profiles into parts.
Therefore, we can model or extract features suitable for each part.
Our features obtained from the parts can effectively describe complex properties of protruding polyps including the shape of the
parts, texture, and protrusion and smoothness of the polyp surface. We evaluated our method against two existing polyp image
detection techniques on 42 different polyps, including those with
little protrusion. Each polyp has a large variation of appearance
in viewing angles, light conditions, and scales in different images.
The evaluation showed that our technique outperformed the existing techniques in both accuracy and analysis time. Our method
has a higher area under the free-response receiver operating characteristic curve. For instance, when both techniques have a true
positive rate for polyp image detection of 81.4%, the average number of false regions per image of our technique is 0.32 compared
to 1.8 of the best existing technique under study. Additionally, our
technique can precisely mark edges of candidate polyp regions as
visual feedback. These results altogether indicate that our technique is promising to provide visual feedback of polyp regions in
clinical practice.
Index Terms—Colonoscopy, edge cross-section profile (ECSP),
medical imaging analysis, polyp detection.

I. INTRODUCTION
OLORECTAL cancer is the second leading cause of
cancer-related deaths, claiming close to fifty thousand
lives annually in the United States [1]. Colonoscopy has contributed to a significant decline in colorectal cancers [2]. Most
colorectal cancers develop from adenomatous polyps that can
appear anywhere in the colon. Early detection and removal of

C

Manuscript received January 20, 2013; revised May 29, 2013 and August
19, 2013; accepted September 30, 2013. Date of publication October 9, 2013;
date of current version June 30, 2014. This work was supported in part by the
National Science Foundation STTR Grant No. IIP-0956847, Mayo Clinic in
Rochester, MN, and EndoMetric Corporation. Opinions and findings in this paper are those of the authors and do not represent those of the funding agencies.
W. Tavanapong, J. Wong, and J. Oh have management roles in EndoMetric
Corp. De Groen is a medical advisor of EndoMetric.
Y. Wang, W. Tavanapong, and J. S. Wong are with the Department of
Computer Science, Iowa State University, Ames, IA 50014, USA (e-mail:
ywang110@gmail.com; tavanapo@cs.iastate.edu; wong@cs.iastate.edu).
J. Oh is with the Department of Computer Science and Engineering, University of North Texas, Denton, TX 76203, USA (e-mail: jhoh@cse.unt.edu).
P. C. de Groen is with the Mayo Clinic College of Medicine, Mayo Clinic,
Rochester, MN 55905, USA.
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2013.2285230

polyps is the main goal when performing the colonoscopy for
prevention of colorectal cancer. Colonoscopy, however, is not
perfect. The average cancer and polyp miss rate is estimated
around 4–12% [3]–[6]. Our ultimate goal is to develop new technology that assists the endoscopist by providing visual feedback
of a potential polyp during routine screening colonoscopy using
a standard endoscope commonly used in practice. The endoscopist may use the feedback to improve the polyp detection
rate during the procedure.
The research problem of automated polyp detection in
colonoscopy is challenging: 1) endoscopic images can be blurry
due to motion of the capturing camera or water injection, maybe
under or over illuminated, or contain strong light reflection
spots. 2) Polyps vary in their appearance, shape, size, amount
of protrusion, and location in the colon. The same polyp may
appear very differently in different images due to amount of
colon insufflation, degree of colon muscular contraction, viewing angle, and distance from the capturing camera. For instance,
a close inspection of a polyp results in a large polyp region,
whereas a distant inspection of the same polyp results in a small
polyp region. Furthermore, polyps may be occluded by stools
or therapeutic instruments. The existing computer-aided techniques utilize features such as texture, pixel color, geometric
shape of edges, or combinations of these features together with
machine learning classifiers for polyp detection. These techniques are summarized in Section II.
Different from the existing work, we investigated edge crosssection profile (ECSP) for polyp detection because the ECSP has
the potential to overcome some of the aforementioned challenging issues due to its pattern discrimination and model robustness
as follows:
1) Pattern discrimination: Fig. 1(a–b) shows a polyp example
with marked edge cross-section and associated region of interest
(ROI). Fig. 1(c) shows the corresponding ECSP. Due to the polyp
protrusion, we observe that the intensity values on the ECSP of
protruding polyps increase abruptly near the edge [around pixel
positions 40–60 on the Pixel#-axis in Fig. 1(c)] and increase at a
much slower pace afterward. This is also true for sessile polyps
with very little protrusion. However, most nonpolyp objects
do not have this pattern. More discriminative patterns between
polyps and most types of commonly seen nonpolyp objects in
colonoscopy are obvious on our multiderivative functions of
ECSP (see Section IV).
2) Model robustness: As a local appearance model, the ECSP
and its derivative profiles are robust to variations in object appearances, such as variations caused by the rotation and translation of the capturing camera. Additionally, our ECSP functions

2168-2194 © 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

1380

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

Fig. 1. (a) A polyp with an edge normal vector labeled as a white bar.
(b) The corresponding ROI extracted from (a). (c) ECSP obtained from (b).
The intensity values are rescaled from [0,255] to [0,1].

utilize a scaling factor, which makes our method robust to variations in polyp region sizes.
In the medical imaging field, the ECSP was used for blood
vessel extraction in retinal images [7]–[9], skin cancer detection [10], and colonoscopic appendiceal orifice detection [11].
These techniques are not suitable for polyp detection in the
colonoscopy images as discussed in Section II.B.
In this paper, we propose a new technique using the ECSP
for polyp detection called the part-based multiderivative ECSP.
First, we compute several derivative functions of an ECSP (multiderivative ECSP) and segment each of these profiles into parts.
Next, we model or extract features from different parts separately using methods suitable for individual parts. Finally, we
combine the scores from modeling and feature scores as feature
vectors for classification. As a result, we have features on parts
which effectively describe some complex properties of polyp
ECSP including the shape of the profile parts, texture of the
polyp region, estimated polyp protrusion, and the smoothness
of a polyp surface. To our knowledge, no prior research has investigated segmented multiderivative ECSP for polyp detection
in colonoscopic images.
Our contributions are: 1) part-based multiderivative ECSPs
using segmentation; 2) features derived from segmented parts
for polyp detection. Our method outperforms opponent-color
LBP (OCLBP), the best texture-based method, in terms of
performance of free-response receiver operating characteristic
curves (FROC) and processing time based on analysis of a thousand images of combined nonpolyp images and polyp images
of 42 different polyps.
The remainder of this paper is organized as follows. Section II discusses related work. We introduce multiderivative
ECSP functions and their segmentation in Section III. We introduce features obtained from the segmented parts in Section IV.
The experimental results are reported in Section V. We conclude
the paper and give a description of future work in Section VI.
II. RELATED WORK
We summarize recent polyp detection methods for endoscopic
images and methods for object detection using the ECSP, re-

spectively. We group the polyp detection methods based on
acquisition modality of endoscopic images.
1) Wireless capsule endoscopes; [12]–[14].
2) Magnifying endoscopes; [15]–[17].
3) Narrow-Band Imaging (NBI); [18].
4) Standard endoscopes used in routine screening. [19]–[28].
The NBI images have different color ranges than those from
standard endoscopes. The pit patterns of polyps clearly seen
in magnifying endoscopes [15]–[17] are not typically seen using standard scopes. The NBI or magnifying endoscopes are
not typically used for the entire procedure. They are used in
the regions where the endoscopist is suspicious of abnormality.
Lastly, many endoscopes currently in use do not have features
such as NBI or magnification.
We focus on analyzing polyp appearance on images from
standard endoscopes since our aim is to assist the endoscopist
to find more polyps during routine screening.
A. Colorectal Polyp Detection
We classify the recent techniques into two categories.
Category I (Spatial domain features): Four major feature categories are: 1) geometric shape of edges [19], 2) region color [20],
3) region texture [21], and 4) the combinations of color, texture,
and edges, such as the combination of region color and geometric shape of edges [22] or the combination of region color
and local binary pattern (LBP) texture [23], [24]. Other polyp
detection techniques using the features in the aforementioned
four categories are summarized in [25].
Our technique [19] relying on shape approximation of polyp
edges to the ideal shape template misses polyps that do not
approximate well with the ideal shape template. The OCLBP
was found to be the most effective feature in an extensive
performance comparison against LBP, wavelet energy, color
wavelet energy, and wavelet correlation signature features [24].
The OCLBP was confirmed to be the best texture-based feature for polyp detection [26]. Most recent techniques (except
[19], [27], [28]) published following the performance comparison [24] were evaluated on a too small dataset (fewer than
100 combined normal and abnormal images) to validate the
effectiveness [25]. A 2012 study [27] used watershed image
segmentation and region merging to obtain candidate regions.
The region features are based on strong valleys around the pixels
in the regions. The tests were conducted on 300 images.
Category II (Spatial and temporal features): Park et al. uses
the conditional random field to model variations of the features
of corresponding fixed size subimages across frames [28]. The
features are derived from Eigen images of the subimages and
the number of detected qualified edges, sizes of these edges, and
distances of the edges from specular reflection spots, etc.
B. Object Detection Using ECSP
We group existing ESCP-based object detection techniques
as follows:
1) Modeling ECSP with Multivariate Distributions: Each
point on an ECSP is treated as a random variable. The mean
and variance–covariance matrices of all random variables are

WANG et al.: PART-BASED MULTIDERIVATIVE EDGE CROSS-SECTIONAL PROFILES FOR POLYP DETECTION IN COLONOSCOPY

Fig. 2. ECSP extraction of an edge in (a) to the corresponding ROI in (b).
→i indicates the position of an edge pixel with its tangent vector
The vector −
u
→i . The edge has its surrounding ROIs ROIc o n c ave and
→
−
n
v i and normal vector −
ROIc o nve x with the dashed lines indicating the edge pixels as region boundaries.

calculated and potential correlations among these variables are
exploited. The active shape model [29]–[31] models the gradient profile of the ECSP using multivariate Gaussian distribution.
This underlying multivariate probability model or other ‘modelfree’ ones such as principal component analysis cannot be directly applied for detecting objects with large-scale variations
like polyps because they are not scale-invariant. Furthermore,
they do not effectively capture the detailed features of the ECSP.
2) Modeling ECSP with Predefined Functions: Multiscale
convolution functions or regression functions are used as shape
models. In [7], multiscale 2-D Gaussian-like matched filters
are used as convolution functions for extracting blood vessels
in retinal images. In [8], [9], a regression function defined as
a linear combination of several inverse Gaussian functions is
used. However, the global shapes of the ECSP of polyps do not
strictly follow the shapes of these predefined functions.
3) ECSP Feature Extraction and Classification: We extracted
the features of the ECSP and its gradient profile and used J48
decision tree [32] for classification of appendiceal orifice images
in the colonoscopy videos [11]. These features are obtained at
some key positions (e.g., zero-crossing positions) on the ECSP
functions. They only represent some local appearance of the
ECSP, which is insufficient to represent more complex characteristics of polyp ECSP.
III. PROPOSED PART-BASED MULTIDERIVATIVE ECSP
In this section, we first present the multiderivative ECSP
functions. We then describe our algorithm that segments the
multiderivative ECSP into parts.
A. ECSP Descriptor
→
ECSP function for an edge pixel: Let I(−
ui ) be the intensity
→
−
value of an edge pixel ui for i ∈ 1, . . . , M , where M is the total
→
number of edge pixels on this edge. The vector −
ui denotes the
pixel at the coordinate (xi , yi ) on a 2-D image. We define an
→
edge tangent vector −
vi as a unit vector passing the edge pixel at
→
−
→
→
ui and an edge normal −
ni as a unit vector perpendicular to −
vi
pointing to the concave side of the edge. (see Fig. 2). The ECSP
→
function for the edge pixel −
ui is defined as


λ λ
→
−
→
−
fi (r) = I ( ui + r · ni ) , r ∈ − ,
,r ∈ Z
(1)
κ κ

1381

where r is the pixel distance (called radius) in an integer set Z
→
→
ni . The maximum
from the edge pixel −
ui along its edge normal −
value of r is inversely proportional to the edge curvature κ and
scaled by a positive constant λ. This maximum radius r value
depends on the edge curvature. Therefore, polyp region sizes
are taken into account via the values of radius r on the ECSP
functions. That is, a large radius value reflects a large polyp in the
image (e.g., polyp seen closely) and a small radius value reflects
a small polyp in the image (e.g., polyp seen at a distance).
→
−
ECSP ROI: Let a row vector fi represent all the points on
function fi (r) starting from r = −λ/κ to r = λ/κ. We define a
⎡−
→⎤
f1
matrix ROI = ⎣ . . . ⎦. Fig. 1(b) shows the plot of the intensity
−→
fM
values in the matrix ROI obtained from the corresponding edge
in Fig. 1(a). The matrix ROI is divided into two equal size
submatrices: the left-half submatrix ROIconvex and the righthalf submatrix ROIconcave . ROIconvex consists of pixels taken
from the outer side of the edge/contour and ROIconcave consists
of pixels taken from the inner side of the edge. Fig. 2(b) is the
corresponding ROI of Fig. 2(a).
ECSP function for an entire edge: We define the ECSP function for an entire edge j as


λ λ
Fj (r) = median (f1 (r) , . . . , fM (r)) , r ∈ − ,
, r ∈ Z.
κ κ
(2)
We denote Fj (r) by F (r) hereafter for ease of exposition.
We use a median value of these function values for the same r
values to increase the robustness of the ECSP against speckle
and specular noises caused by light reflection. Next, we obtain
the first-order and second-order derivatives of the function F(r)
2
respectively.
We call a set
denoted as ∇F
	
 (r) and ∇ F (r),
of functions F (r) , ∇F (r) , ∇2 F (r) multiderivative ECSP
functions. Each of these functions shows both patterns and noise.
We did not use higher order derivative functions because the
calculation of a function’s derivative amplifies noise, and we
empirically found that it is difficult to discern noise from real
patterns on a higher order of derivative functions. To reduce the
effect of noise, an ECSP function is smoothed using the moving
average smoothing method [33] before the calculation of its
derivative. To extract the ECSP, we use our algorithm in [11].

B. Multiderivative ECSP and ROI Segmentation
We segment the ECSP, its first-order profile, and its secondorder profile into a total of ten nonoverlapping parts. We also
segment ROI into four nonoverlapping parts in order to extract
texture features. Because the detected edge point r = 0 may not
be the local minimum intensity point on F (r) due to the image
smoothing, we search for the local minimum intensity point in
a small 1-D window centered at r = 0. We denote this local
minimum intensity point as r0 .
Segmentation of multiderivative ECSP: The segmentation algorithm consists of two steps. See Fig. 3 for an example and
notations.

1382

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

(2)

e). Next, we segment ∇2 F (r) at r = r− as shown at point c7
in Fig. 3(f).
After the above steps, multiderivative ECSP functions of an
edge are segmented into ten nonoverlapping parts: four parts
0
from F (r), denoted as {St∇ }4t=1 , four parts from ∇F (r), de1
noted as {St∇ }4t=1 , and two parts from ∇2 F (r), denoted as
2
{St∇ }2t=1 .
Segmentation of ROI: We also segment the ROI corresponding to the edge into four nonoverlapping submatrices, each corresponding to each segmented part of F (r)
0
({St∇ }4t=1 ). (see Fig. 3(d)). We represent the segmented ROIs
by {ROI1convex , ROI2convex , ROI3concave , ROI4concave } and extract texture features from some of these segmented ROIs.

IV. PROPOSED FEATURES ON PARTS

Fig. 3. Example of segmentation steps on polyp ECSP functions. (a)–(c): The
backward segmentation steps. The red rhombuses show the points between
segmented parts. The dash-dotted lines link the red rhombuses on the ECSP
functions and their corresponding segmentation points at zero-crossing value
positions on their derivative functions. (d)–(f): The segmentation at key points.
The green rhombuses show the segmentation points in this step. The dash-dotted
lines link the green rhombuses on the ECSP functions and their corresponding
segmentation points. The labels h 1 , h2 , h3 , and h 4 correspond to the amount
of intensity drop before crossing the edge, the amount of intensity return after
crossing the edge, edge sharpness before crossing the edge and edge sharpness
after crossing the edge, respectively. These features were introduced in [11].

Backward segmentation from zero-crossing points: Let points
(1)
(1)
r = r− and r = r+ be two zero-crossing value points closest
(2)
(2)
to r = r0 on ∇F (r). Let points r = r− and r = r+ be two
2
zero-crossing value points closest to r = r0 on ∇ F (r). These
points must satisfy both conditions below.
(1)
(1)
(2)
(2)
1) r− < r0 < r+ and r− < r0 < r+ .
(1)
(1)
(2)
(2)
2) ∇F (r− ) = ∇F (r+ ) = ∇2 F (r− ) = ∇2 F (r+ ) = 0.
We segment F (r) at positions c1 and c2 which correspond
(1)
(1)
to the points at r− and r+ on ∇F (r). Similarly, we segment
∇F (r) at positions c3 and c4 which correspond to the points
(2)
(2)
at r− and r+ on ∇2 F (r). As a result, F (r) and ∇F (r) are
each divided into three parts in this step. Because the segmentation points on F (r) and ∇F (r) are referred back from their
corresponding derivative function, we call this backward segmentation. We do not segment the profile if its corresponding
zero-crossing positions do not exist. Fig. 3(a–c) demonstrates
the backward segmentation step.
Segmentation at key points: We further segment the parts
obtained from the previous step. First, we segment F (r) and
∇F (r) at r = r0 as the illustrated points c5 and c6 in Fig. 3(d–

Using part-based multiderivative ECSP and ROI, we have
flexibility to model or calculate features from a segmented part
using the method suitable for that part. In this section, we introduce some features on parts which effectively describe some
complex properties of the polyp ECSP including texture of
the region, shape of the parts, estimated polyp protrusion, the
smoothness of a polyp surface, and intensity values on key positions on parts. We developed these features based on the observations of characteristics of protruding polyps in colonoscopy
and consultation with the domain experts.

A. Texture Features on ROI3concave and ROI4concave
The protrusion of protruding polyps causes the intensity values on F (r) to abruptly increase from r0 (the edge pixel posi0
tion) to the right most point on S3∇ and then gradually increase
∇0
afterward on S3 as shown in Fig. 3(d). We estimate the protrusion of polyps by capturing this tendency of intensity increase
using texture features on ROI3concave and ROI4concave . First,
we reduce the effect of small impulsive and speckle noises by
smoothing the intensity values on each row and then on each
column of ROI3concave and ROI4concave using locally weighted
scatterplot smoothing (LOWESS) with a tri-cube weight function [40]. We empirically found that LOWESS performs best
among several smoothing methods such as average, median,
and moving average filters.
Next, we slide a 1 × 2 pixel window over ROI3concave and
ROI4concave separately, one pixel at a time, to obtain texture
features. We assign a binary score of 1 to that pixel if the pixel
intensity value in the right window is greater (brighter) than
that in the left window, or a binary score of 0 otherwise. We
experimented with different window sizes and chose a 1 ×
2 pixel window due to its simplicity and effectiveness. Next, we
obtain two binary matrices: one for ROI3concave and the other
for ROI4concave . Finally, we compute Vtexture1 as the average of
the binary values of the binary matrix of ROI3concave . Similarly,
we compute Vtexture2 from the binary matrix of ROI4concave . As
a result, we have two texture features, each in the domain of
[0, 1].

WANG et al.: PART-BASED MULTIDERIVATIVE EDGE CROSS-SECTIONAL PROFILES FOR POLYP DETECTION IN COLONOSCOPY

1

Fig. 4. Left: The part S ∇
of an example polyp. The dots are points on
3
1
function ∇F s 3 (r) of S ∇
3 , the dashed line is fitted Gamma PDF functions
2
∇F̂ s 3 (r; a, b). Right: Six labeled PNP patterns on an example S ∇
2 used for
calculating surface smoothness feature.

B. Shape Modeling of S3∇

1

The global shapes of polyp ECSP functions do not match
existing functions studied in [7]–[9] (e.g., a linear combination
of several inverse Gaussian functions). However, the shape of
1
on ∇F (r) after profile segmentation skews to
the part S∇
3
the left and looks similar to the shape of a Gamma probability
1
distribution function (PDF). Fig. 4 (left) shows the shape of S3∇
of an example polyp. The segmentation of the multiderivative
ECSP allows modeling of each part separately without affecting
1
the others. We model the shape of part S3∇ as follows.
1
Let a function ∇F s 3 (r) denote the part S3∇ on
∇F (r). We define a Gamma PDF ∇F̂ s 3 (r; a, b) =
a −1 − ar
e
, (a > 1, b > 0) as the estimation of F s 3 (r). The
ra−1 bra (a−1)!
shape of the function ∇F s 3 (r) mainly depends on some
particular points on the function. These points are close
to the function peak, or have large function value differences from their neighbor points. [see Fig. 4 (left)]. Therefore, we apply the weighted Levenberg–Marquardt algorithm
[34] to optimize the goodness of model fitting by setting
higher weights for important pixels. The diagonal element
Wr r in a diagonal weight matrix W presents the weight
of pixel r defined as Wr r = |∇F s 3 (r + 1) + ∇F s 3 (r)| ·
|∇F s 3 (r + 1) − ∇F s 3 (r)| . The first term of Wr r gives a large
value for the pixels r and r + 1 that are close to the function peak
position. The second term measures the difference of function
values between the pixel r and its right
r+1. We com
 neighbor
Diﬀ
pute a similarity score Vshap e = 1/ 1 + Com
m between the
s3
underlying model ∇F (r) and its estimated ∇F̂ s 3 (r; a, b) as
1
the shape feature on part S3∇ , where Diff is the difference between the areas under the curve of the two functions and Comm
is the amount of the overlapping area between them.
C. Surface Smoothness Feature on S2∇

2

Due to polyp protrusion, the intensity values on the ECSP of
polyps increase abruptly near their edge pixel positions. This
property results in large amplitude values near the approximate
edge pixel position r = r0 on the derivative functions of the
polyp ECSP [see Fig. 3(b–c)]. The surface of most polyps,
in particular polyps less than 1–2 cm, is smooth. As a result,
when comparing with the large amplitude values near r = r0

1383

for polyp edges, only very small oscillating amplitude values
appear on nonedge positions of ∇2 F (r) when r > r0 . However,
for a noisy surface, the calculation of a function’s derivative
amplifies the noise; the amplified noises are obvious on the
profile functions of the second-order derivative. Therefore, some
protruding nonpolyp objects like stool show large amplitude
values near both edge pixel position and nonedge pixel positions
2
of ∇2 F (r). S∇
2 is the part which reflects the information of both
edge pixel position and nonedge pixel positions on ∇2 F (r) at
the concave side of a polyp. We design a feature to capture the
2
differences of amplitude values on S∇
2 as follows.
2
We define consecutive pixels as a PNP pattern on S2∇ if they
contain three zero-crossing pixels in order: one P-pixel, one
N-pixel, and another P-pixel. Specifically, the P-pixel is a
pixel at r whose function value satisfies ∇2 F (r) < 0 and
∇2 F (r + 1) > 0. In other words, P-pixel is a zero-crossing
pixel from negative to positive. N-pixel is a pixel at r whose
function value satisfies ∇2 F (r) > 0 and ∇2 F (r + 1) < 0. In
other words, N-pixel is a zero-crossing pixel from positive to
2
negative. First, we segment S2∇ into nonoverlapping PNP patterns at all P-pixel positions. Fig. 4 (right) shows six such PNP
2
patterns on S2∇ , labeled from 1 to 6. Next, we calculate the
maximum and minimum function values of a PNP pattern as its
amplitude, represented by a pair-value (e.g., function values at
1
labeled in Fig. 4 (right)). Finally, we apply k-means
rP1 and rN
clustering algorithm [32] on all pair-values of amplitude using
the Euclidean distance among the pair-values to cluster these
PNP patterns into two groups: g1 and g2 , where g1 is the group
with more patterns than those in g2 .
An object with smooth surface has only one large amplitude
2
pair-value near edge pixel position on S2∇ . That is, the group g1
should contain only one PNP pattern—the pattern that is closest
to r = r0 . Otherwise, g1 should contain other PNP patterns
caused by noise. We use a binary score to represent a smoothness
feature denoted as Vsm o othness . We assign 1 to Vsm o othness when
the surface of the corresponding object is considered smooth.
That is, if 1) the PNP pattern closest to r = r0 belongs to g1 , and
2) g1 contains at most q pair-values of amplitude. Otherwise,
we assign 0 to Vsm o othness . We set q as 2 to allow the maximum
of one noisy PNP pattern in g1 .
D. Features on Key Positions of Parts
We extracted six features on key positions; three of them
(h2 , h3 , and h4 ) were introduced in [11]. Table I shows the
description of these features.
Final Feature Vector: Our final feature vector V has ten
features (Vtexture1 , Vtexture2 , Vshap e , Vsm o othness , h1 -h2 , h2 , h3 ,
h4 , h2 /h1 , h4 /h3 ). While additional features may be useful
for detecting protruding polyps, we focus on these ten features
in this study. These features were selected using the forward
feature selection method [35] and shown effective for polyp
detection based on our experiments in Section V.
Fig. 5 shows multiderivative ECSP functions of some types
of commonly seen objects in colonoscopy. The shapes of the
ECSP functions of polyps appear different from those of other
often seen objects. For the objects like smooth stool (omitted in

1384

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

Fig. 5. Multiderivative ECSP of the different types of colonoscopic images. First row: Original gray scale image marked with a white bar as an edge normal;
Second row: the intensity edge profile; Third row: the gradient profile; Fourth row: the second-order derivative edge profile. (a) Polyp image. (b) Appendiceal
orifice image. (c) Colon lumen with the lumen in the middle of the image and with multiple nested folds. (d) Colon fold. (e) Endoscope seen during retroflexion.
TABLE I
FEATURES ON KEY POSITIONS OF PARTS USED FOR POLYP DETECTION

Fig. 5) whose ECSP functions appear similar to those of polyps,
their function values are generally in different ranges.
V. PERFORMANCE EVALUATION
A. Experimental Setup
We implemented the analysis software in MATLAB. We ran
all experiments on an Intel Xeon 3.80-GHz CPU, 4-GB RAM
workstation running Microsoft Windows Server 2003.

Dataset: We randomly selected 46 de-identified video files
captured during routine screening colonoscopy at the image
resolution of 720×480 pixels at 29.97 frames per second (fps).
Each file contains only one colonoscopy procedure in its entirety.
Twenty-eight of these videos were captured using FUJINON endoscopes, and the remaining eighteen video files were captured
using OLYMPUS endoscopes. The colons seen in these videos
had little stool inside them. We extracted from these video files
69 smaller clips: 50 clips with polyps and 19 clips without any
polyps. The 50 clips represent 50 different polyps (one polyp
per clip). Each polyp clip has consecutive frames showing the
same polyp appearing at various viewing angles, light conditions, and scales. The polyp pit patterns were not clearly seen
since magnifying endoscopes were not used.
Our nonpolyp clips contain images with most types of objects often seen in colonscopy, including blood vessels, colon
wall, colon folds, stool, retroflexion, appendiceal orifices, and
diverticula [1]. For each clip, we extracted the images in JPEG
format with a resolution of 720×480 pixels at the frame rate
of 1 fps. We removed blurry images using our blurry frame
removal software [36], leaving the remaining clear (in-focus)
images for the experiments. The software considers a frame as
blurry if it does not have sufficient number of connected edge
pixels detected using the Canny edge detector. In total, we obtained 1025 images, each with a polyp in it and 488 images
without any polyps in them. Two domain experts marked and

WANG et al.: PART-BASED MULTIDERIVATIVE EDGE CROSS-SECTIONAL PROFILES FOR POLYP DETECTION IN COLONOSCOPY

1385

Fig. 6. Examples of detected polyps: 1st and 3rd rows: ground truth is the area of the union of all marked ellipses; 2nd and 4th rows: detected results marked
with the minimum bounded rectangle of the detected edges. (a) Polyp on colon wall. (b) Polyp on side of colon fold, with blood. (c) Small polyp on colon wall,
near flat, facing the camera. (d) Polyp on colon fold, with stool, facing the camera. (e) Polyp on colon wall, facing the camera. (f) Polyp on colon fold. (g) Polyp on
colon fold, with stool. (h) Small polyp on colon wall, near flat, with stool, facing camera. (i) Polyp on colon wall. (j) Small polyp on side of colon fold. (k) Polyp
on colon fold, with stool. (l) Polyp on colon wall. (m) Polyp on colon fold, with water and stool. (n) Polyp on side of colon wall.

agreed on the ground truth of all polyp regions in the images.
See Fig. 6 for the examples.
Image preprocessing and ECSP calculation: We applied the
preprocessing step [11] with parameter values suitable for this
dataset. Because our dataset has clear images obtained based
on the quality of their Canny edges, we successfully extracted
real polyp edges for the vast majority of polyp images (1018 of
1025) with these parameters. We set λ to 0.5 and the maximum
value of λ/κ to 80. The 1-D window size centering at r = 0 for
finding the minimum intensity point r0 in the window was 1 ×
21.
Feature normalization: The values of most of our features,
Vtexture1 , Vtexture2 , Vshap e , Vsm o othness , h1 − h2 , h2 , h3 , h4 are
in the range of [–1, 1]. As the values of features h2 /h1 and h4 /h3
are in large-scale ranges, we transformed the data of these two
features using log functions: log (h2 /h1 ) and log (h4 /h3 ). We
then normalized each individual feature h3 , h4 , log (h2 /h1 ) and
log (h4 /h3 ) by dividing it by its corresponding C (d) , where C (d)
is the absolute difference of the maximum and minimum values
for the feature d in the training data.
Performance metrics: We consider the minimum bounding
rectangle of each edge obtained from Canny edge detector as one
region. Let DET_RLPLP_IMG, RLPLP_IMG, FL_REGION,
and IMG be the number of correctly detected polyp images, the
number of real polyp images, the number of falsely detected
regions (FLRs) (regions not overlapping with any real polyps),
and the number of tested images, respectively. A polyp image
is considered correctly detected if it has at least one correctly
detected polyp region. A detected region is counted as a true
positive if it overlaps with a ground truth polyp region. The
number of wrongly detected polyp regions is counted as FLR.
The FLR also counts FLRs in true polyp images. We used the
following performance metrics as in [21].
True position rate (TPR) =

DET RLPLP IMG
RLPLP IMG

Number of false regions per image (FLR) =

FL REGION
.
IMG

In an ideal case, TPR is 1 and FLR is 0. However, achieving
the ideal performance is unlikely. Generally, the number of true
positives varies inversely with the number of false positives.
For clinical use, a polyp detection algorithm should have high
TPR and low FLR as well as limit the number of false regions
within a few percentages of total frames. If detected regions
are marked as feedback, FLRs across many frames can distract
the endoscopist, which is not desirable. For feedback on the
correctly detected region, the endoscopist has another chance
to reexamine the entire image and may identify other polyps in
the same image that an algorithm may miss. This is the reason
we define the TPR based on images not regions. We present
the FROC of these metrics. FROC is similar to the receiver
operating characteristic curves, except that the false positive
rate on the x-axis is replaced by the FLR and there is no widely
accepted single index that summarizes the FROC curve like
ROC despite some proposals [37]. All parameter values were
determined based on experiments with the training set. The
parameter values may vary for different image resolutions in
other datasets.
B. Evaluation Using Ten-Fold Cross Validiation
We evaluated our technique using a ten-fold cross validation with several classifiers: two-class support vector machine
(SVM) with radial basis function (RBF) kernel using Torch
SVM library [38] and generalized linear models (GLM) [39]
with binomial, Gaussian, and Poisson distributions as kernels.
We used all images to extract feature vectors to obtain performance of these classifiers. We varied the standard deviation of
the Gaussian kernel for the SVM classifier, and the threshold values of probability for the GLM classifiers to obtain the FROCs.
There are two more parameters for the SVM classifier [39], but

1386

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

Fig. 7. FROC curves of all images tested on all features with different classifiers using ten-fold cross-validation.
TABLE II
DESCRIPTION OF DATASETS

TABLE III
POLYP CATEGORIES IN THE TESTING SET

they had little effect on the FROCs. Among these classifiers,
SVM with RBF kernel and GLM with Gaussian kernel showed
a slightly better performance with the largest area under the
FROC comparing to the other three classifiers. However, all of
these different classifiers showed similar FROCs. (see Fig. 7).
C. Evaluation Using Separate Polyp Clips
The experiments using ten-fold cross validation may result in
the selection of features from different images, but of the same
polyp, for training and testing. However, in clinical use, it is
not possible that the training and the testing data come from
the same polyp. Therefore, we mainly evaluated our technique
by splitting our polyp clips into nonoverlapping training and
testing clips. The polyps in the training set are different from
those in the testing set. Table II describes the data sets including
the number of clips, images, and extracted edges after the image
preprocessing step. We included eight polyp clips in the training
set, which covered all categories of polyp appearance in Table III
(discussed in more details in a later paragraph).
As the evaluated classifiers have the similar performance, we
used the two-class SVM classifier with RBF kernel, which has
the best performance in Section V-B as the classifier in the rest
of our experiments.

Fig. 8. FROC curves of different features tested on all testing data. Shape
feature is V sh a p e ; texture features are V te x tu re 1 , V te x tu re 2 ; smoothness feature
is V sm o o th n e ss , three key points features are h 2 , h 3 , h 4 used in [11], and six
key points features are the features presented in Table I.

The two classes were the polyp images and nonpolyp images. In our experiments, we varied the standard deviation of
the Gaussian kernel for the SVM classifier to train the classifier using all images in the training set and applied the trained
classifier on the entire testing set to get the TPR and FLR for
each point on the FROC. We evaluated our technique in the
following three aspects: 1) Performance of different features.
2) Performance on different appearance types of polyps. 3) Comparison of our technique with existing leading techniques using
LBP and OCLBP features [23], [24], [26]. We tried ten-fold
crossing validation on these leading techniques using the LBP
and OCLBP features. However, we found that not every fold of
the split training data can be used to derivate a model using the
features of the LBP and OCLBP.
Performance of different features: Fig. 8 shows the FROC of
individual features and the combination of all the features. The
individual shape features, texture features, or three key features
used in [11] showed similar performance. That is about 2/3 TPR
comparing with the performance using all proposed features.
The six key features presented in Table I or combination of
smoothness, shape, and texture features improved about 10%
TPR on average. The combination of all features (ten features
per edge) further improved about 10% TPR on average and
showed the best performance.
Performance on different appearance types of polyps:
Table III shows polyp types based on their appearance: polyps
on colon wall, polyps on colon folds, polyps with stool, and
near flat polyps (polyps with little protrusion). A polyp image
can belong to more than one category. For example, a near flat
polyp image may also have stool. To the best of our knowledge, no other existing work investigated their performance on
these different types of polyp appearance, which demonstrate
complexities of polyps in our data set.
The training and testing procedures were the same as in the
previous experiment to evaluate the effectiveness of different
features. However, the TPR and FLR for each polyp category
was calculated using detection results on polyp images in that

WANG et al.: PART-BASED MULTIDERIVATIVE EDGE CROSS-SECTIONAL PROFILES FOR POLYP DETECTION IN COLONOSCOPY

Fig. 9.

FROC curves for different types of polyps using the proposed features.

category only. These polyp images have other edges besides
polyp edges. Fig. 9 shows the FROC of these types of polyps.
The results of nonpolyp images were excluded from Fig. 9. The
number of false regions per image is highest for the polyps
on colon folds because some protruding colon folds look very
similar to real protruding polyps. We obtained the highest TPR
of around 90% for detecting polyps on colon wall. The best
TPR of near flat polyps is about 76%. Most of the stool was
correctly rejected. Some polyps contain reflected smooth stool
(e.g., water injected via the instrument) as FLRs. Other false
regions are caused by noises like light reflected spots and water.
Our technique is robust to different viewing angles and polyp region sizes. Fig. 6 shows some detection results under the TPR of
86.3%. The detected edges are labeled by the minimum bounded
rectangles of the edges. The examples show the complexities of
the polyps in our dataset. Under the TPR of 86.3%, most misdetected polyps are either poorly illuminated or far away from
the camera.
Performance comparision with existing techniques: Our emphasis is on effective features for polyp image detection. We
compared our technique with two existing leading techniques
using the LBP and OCLBP features in [23], [24], [26]. The
OCLBP was shown to perform best in a 2006 study [24] and a
more recent study in 2009 [26].
The LBP and OCLBP use region texture in a sliding window
while our technique uses features from edges. For comparison,
in our technique, we consider the minimum bounding rectangle
of a detected edge as a detected region representing that edge.
The LBP and OCLBP algorithms slide a square window over
an entire image. At each sliding step, the square region covered by the window is classified as a polyp candidate region
or a nonpolyp candidate region by a SVM classifier using the
features obtained from that square region. The detected polyp
candidate regions are connected in eight directions. The union of
these connected regions is considered as a single detected polyp
region if it consists of least Thldregion number of connected
candidate polyp regions. Besides the parameters of the SVM,
we also varied Thldregion for the LBP and OCLBP. Since our
technique does not use sliding windows, Thldregion was not rel-

1387

Fig. 10. FROC curves of features obtained from part-based multiderivative
ECSP, LBP, and OCLBP with different sizes of sliding windows; features were
tested on a SVM classifier with RBF kernel.

evant. We used the RBF kernel for SVM and 64 histogram bins
for both the LBP and intra and interchannel OCLBP patterns as
in [23] and [24]. The size of the sliding window influences the
performance of the LBP and OCLBP features. Setting a window
size too large will include many nonpolyp pixels, resulting in
ineffective classification. We investigated the performance under three window sizes: 32 × 32, 48 × 48, and 64 × 64 pixels,
respectively. The sliding window step was set to half the window
size.
Fig. 10 shows the comparison of these techniques. The
OCLBP outperforms the LBP with the same window size. The
OCLBP with 48 × 48 pixels window size (denoted as OCLBP48 × 48) shows the best performance comparing with the LBP
and OCLBP using the other window sizes for this dataset. Our
proposed technique outperforms these two methods in the following aspects. 1) Under the same TPR, the average FLR of
our technique is under 0.5 (see Figs. 8 and 10), which is significantly lower than those of the LBP and OCLBP. Most of the
false regions occur within images with a) strong light reflected
spots, b) smooth stool, c) water, or d) protruding colon folds.
Furthermore, the false regions generated by our technique are
not equally distributed within nonpolyp images. For example,
for an 81.4% TPR, our technique has 0.32 FLR. These false
regions occur within only 20.5% of nonpolyp images. However,
OCLBP-48 × 48 generates around 1.8 FLR under the same
81.4% TPR. These false regions are close to equally distributed
on different types of nonpolyp images. As a result, nearly every
nonpolyp image (99.8%) has at least one false region. 2) We
observed that detected regions using the OCLBP and LBP generally contained a large area of nonpolyp pixels surrounding
real polyp pixels: the FLRs were connected with real polyp
regions and counted as a single correctly detected region. Compared with these sliding-window based methods, our method
detects polyp edges, which reflects more accurate locations of
the polyps. Thus, our results should be more meaningful in clinical practice. 3) Analysis time: Table IV shows that the average
time for our technique was 7.1 s per image. The bottlenecks

1388

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

TABLE IV
AVERAGE ANALYSIS TIME IN SECONDS PER IMAGE

are the ECSP and ROI extraction. For the LBP and OCLPB,
the analysis time decreases as the window size increases. In
contrast, our technique took around 1/3 of the time taken by the
OCLBP-48 × 48 (the most effective OCLBP) and a few seconds
less than that of the LBP-48 × 48 (the most effective LBP).
The additional polyp detection algorithms surveyed in [25],
[21], [27], and [28] were proposed after [24]. However, these
recent techniques except [27] and [28] and our technique [19]
were evaluated on datasets that were too small to convincingly
validate them. For instance, the algorithm in [21] provided an
86.2% TPR and 1.26 FLR tested on only 37 images and took
about 13 s per image on a similar workstation. The size of
the processed image is only around 1/4 of our image size. The
number of distinct polyps studied was not given. We did not
directly compare with this technique as it used sliding-window
based texture features, which have similar drawbacks as using
the LBP and OCLBP. That is the slow processing time and
the dependence on the window size. We did not compare with
the technique in [27] or our previous algorithm [19]. They ran
significantly slower than our proposed method. For instance, it
was reported in [27] that the technique took about 19 s per image
on average on an Intel i7–930 quad core processor. The design of
the region segmentation and merging step is difficult to optimize
without better hardware to achieve real-time feedback of the
polyp candidates. We cannot set up a fair comparison between
our work and a technique that uses both spatial and temporal
domain information such as [28] since our technique uses only
features in spatial domain for the detection of polyp images
where the referenced technique uses temporal information to
detect a group of polyp images.
VI. CONCLUSION AND DISCUSSION
We introduce a part-based multiderivative ECSP method for
polyp detection in colonoscopy images. Segmenting the ECSP
into parts gives flexibility to model or extract features from
each part using the method component which is suitable for
that part. Our technique is robust to some challenging issues of
polyp detection and outperforms existing leading methods. Our
technique can effectively detect different types of protruding
polyp appearance including polyps with little protrusion. It can
mark detected polyp edges as visual feedback which is more
precise and less intrusive than marking a large region as in
a sliding-window based method such as the OCLBP, the best

performing technique compared with several previous works
on a large dataset. Our technique is better than the OCLBP in
terms of processing time and effectiveness. It also has fewer
FLRs and these regions appear in much fewer images compared
to the OCLBP.
There are no concensus regarding techniques newer than [24]
as they were not compared with prior work to confirm their
effectiveness. We agree with the statement in [27] that performance comparison is difficult due to the absence of standard
benchmark datasets and implementation of techniques that are
very different. Some of them do not specify important implementation details. At best, we can qualitatively imply that our
technique may be better than the new techniques using a slidingwindow approach like the OCLBP in terms of significantly less
processing time and more compactness of the detected regions.
The larger window means less processing time, but is less precise because the marked regions include nonpolyp pixels for
polyps smaller than the window size.
Our proposed technique is fully automatic. It is potentially
useful for clinical use for automated documentation after the
procedure for patients and for insurance claim purpose to reduce
the manual process by physicians. By converting the code to
C/C++ and optimization on the ECSP and feature extraction,
we can already reduce the average analysis time down to less
than 1 s per image. After further optimization, our software
should be able to mark the edges of potential polyps as feedback
in real time to help the endoscopist who may overlook some
polyps due to fatigue or inexperience. The system is promising
for assisting the endoscopist toward reducing the polyp miss
rate and improving quality of care.
As our future work, we will further reduce false positive
edges of strong light reflected spots, smooth stool, and water. We
will investigate the use of temporal information in consecutive
frames (e.g., tracking of detected edges across frames; modeling
temporal information, and spatial features together) to recall as
many real polyps and reduce the FLRs.

REFERENCES
[1] Colorectal cancer facts & figures, Amer. Cancer Soc., Atlanta, GA, USA,
2013.
[2] D. Lieberman, “Quality and colonoscopy: A new imperative,” Gastrointestinal Endoscopy, vol. 61, no. 2, pp. 392–4, 2005.
[3] D. K. Rex, C. S. Cutler, G. T. Lemmel, E. Y. Rahmani, D. W. Clark, D.
J. Helper, G. A. Lehman, and D. G. Mark, “Colonoscopic miss rates of
adenomas determined by back-to-back colonoscopies,” Gastroenterology,
vol. 112, no. 1, pp. 24–28, 1997.
[4] P. J. Pickhardt, P. A. Nugent; P. A. Mysliwiec; J. R. Choi, and W. R.
Schindler, “Location of adenomas missed by optical colonoscopy,” Ann.
Internal Med., vol. 141, no. 5, pp. 352–9, 2004.
[5] A. Pabby, R. E. Schoen, J. L. Weissfeld, R. Burt, J. W. Kikendall, P. Lance,
M. Shike, E. Lanza, and A. Schatzkin, “Analysis of colorectal cancer occurrence during surveillance colonoscopy in the dietary prevention trial,”
Gastrointestinal Endoscopy, vol. 61, no. 3, pp. 385–91, 2005.
[6] D. H. Kim, P. J. Pickhardt, A. J. Taylor, W. K. Leung, T. C. Winter, J. L.
Hinshaw, D. V. Gopal, M. Reichelderfer, R. H. Hsu, and P. R. Pfau, “CT
colonography versus colonoscopy for the detection of advanced neoplasia,” New Engl. J. Med., vol. 357, pp. 1403–12, 2007.
[7] S. Chaudhuri, S. Chatterjee, N. Katz, M. Nelson, and M. Goldbaum, “Detection of blood vessels in retinal images using two-dimensional matched
filters,” IEEE Trans. Med. Imag., vol. 8, no. 3, pp. 263–269, Sep. 1989.

WANG et al.: PART-BASED MULTIDERIVATIVE EDGE CROSS-SECTIONAL PROFILES FOR POLYP DETECTION IN COLONOSCOPY

[8] V. Mahadevan, H. Narasimha-Iyer, B. Roysam, and H. L. Tanenbaum,
“Robust model-based vasculature detection in noisy biomedical images,”
IEEE Trans. Inf. Technol. Biomed., vol. 8, no. 3, pp. 360–376, Sep. 2004.
[9] H. Azegrouz and E. Trucco, “Max-min central vein detection in retinal
fundus images,” in Proc. IEEE Int. Conf. Image Process., 2006, pp. 1925–
1928.
[10] E. Claridge and A. Orun, “Modeling of edge profiles in pigmented skin
lesions,” in Proc. Med. Image Understanding Anal., 2002, pp. 53–56.
[11] Y. Wang, W. Tavanapong, J. Wong, J. Oh, and P. C. de Groen, “Detection
of quality visualization of appendiceal orifices using local edge crosssection profile features and near pause detection,” IEEE Trans. Biomed.
Eng., vol. 57, no. 3, pp. 689–695, Mar. 2010.
[12] S. Hwang and M. E. Celebi, “Polyp detection in wireless capsule endoscopy videos based on image segmentation and geometric feature,” in
Proc. IEEE Conf. Acous. Spe. Sig. Process., 2010, pp. 678–681.
[13] S. Gross, M. Kennel, T. Stehl, J. Wulff, J. Tischendorf, C. Trautwein, and
T. Aach, “Polyp segmentation in NBI colonoscopy,” in Algorithmen —
Systeme — Anwendungen Proc. des Workshops, Bildverarbeitung für die
Medizin. Berlin, Heidelberg, Germany: Springer, vol. 22, no. 25, 2009,
pp. 252–56.
[14] Q. Zhao, T. Dassopoulos, G. E. Mullin, M. Q. Meng, and R. Kumar,
“A decision fusion strategy for polyp detection in capsule endoscopy,”
Stud. Health Technol. Inf. Med. Meets Virtual Reality, vol. 173, no. 19,
pp. 559–65, 2012.
[15] S. Tanaka, S. Oka, M. Hirata, Y. Shigeto, K. Iwao, and C. Kazuaki, “Pit
pattern diagnosis for colorectal neoplasia using narrow band imaging
magnification,” Digestive Endoscopy, vol. 18, no. S1, pp. S52–6, 2006.
[16] M. Häfner, A. Gangl, R. Kwitt, A. Uhl, A. Vécsei, and F. Wrba, “Improving pit-pattern classification of endoscopy images by a combination of
experts,” in Proc. Med. Imag.Comput. Comput. Assist. Intervent., 2009,
pp. 247–254.
[17] M. Häfner, M. Liedlgruber, A. Uhl, A. Vécsei and F. Wrba, “Color treatment in endoscopic image classification using multi-scale local color vector patterns,” Med. Image Anal., vol. 16, no. 1, pp. 75–86, 2012.
[18] M. Ganz, X. Yang, and G. Slabaugh, “Automatic segmentation of polyps
in colonoscopic narrow-band imaging data,” IEEE Trans. Biomed. Eng.,
vol. 59, no. 8, pp. 2144–2151, Aug. 2012.
[19] S. Hwang, J. Oh, W. Tavanapong, J. Wong, and P. C. de Groen, “Polyp
detection in colonoscopy video using elliptical shape feature,” in Proc.
IEEE Int. Conf. Image Process., 2007, pp. 465–468.
[20] S. A. Karkanis, D. K. Iakovidis, D. E. Maroulis, D. A. Karras, and M.
Tzivras, “Computer-aided tumor detection in endoscopic video using
color wavelet features,” IEEE Trans. Inf. Technol.. Biomed., vol. 7, no. 3,
pp. 141–52, Sep. 2003.
[21] D. C. Cheng, W. C. Ting, Y. F. Chen, Q. Pu, and X. Jiang, “Colorectal
polyps detection using texture features and support vector machine,” in
Proc. Int. Conf. Adv. Mass Data Anal. Images Signals Med., Biotech.,
Chem. Food Ind., 2008, pp. 62–72.
[22] B. V. Dhandra, R. Hegadi, M. Hangarge, and V. S. Malemath, “Analysis
of abnormality in endoscopic images using combined HSI color space
and watershed segmentation,” in Proc. Int. Conf. Pattern Recog., 2006,
pp. 695–98.
[23] L. Alexandre, N. N. Nobre, and J. C. Casteleiro, “Color and position versus texture features for endoscopic polyp detection,” in Proc. Int. Conf.
Biomed. Eng. Inf., 2008, vol. 1, pp. 38–42.

1389

[24] D. K. Iakovidis, D. E. Maroulis, and S. A. Karkanis, “An intelligent system
for automatic detection of gastrointestinal adenomas in video endoscopy,”
Comput. Biol. Med., vol. 30, no. 10, pp. 1084–103, 2006.
[25] S. Ameling, S. Wirth, and D. Paulus, “Methods for polyp detection in
colonoscopy video: A review,” Technical Report, University of KoblenzLandau, Landau, Germany, Tech. Rep. Nr. 14/2008, 2008.
[26] A. Stefan, W. Stephan, P. Dietrich, L. Gerard, and F. Vilarino, “Texturebased polyp detection in colonoscopy,” in Bildverarbeitung für die Medizi.
Berlin, Heidelberg, Germany: Springer, 2009, pp. 346–50.
[27] J. Bernal, J. Sánchez, and F. Vilarino, “Towards automatic polyp detection
with a polyp appearance model,” Pattern Recog., vol. 45, no. 9, pp. 3166–
82, 2012.
[28] S. Park, D. Sargent, I. Spofford, K. G. Vosburgh, and Y. A-Rahim, “A colon
video analysis framework for polyp detection,” IEEE Trans. Biomed. Eng.,
vol. 59, no. 5, pp. 1408–1418, May 2012.
[29] T. F. Cootes, C. J. Taylor, D. H. Cooper, and J. Graham, “Active shape
models—their training and application,” Comput. Vis. Image Understanding, vol. 61, no. 1, pp. 38–59, 1995.
[30] F. Jiao, S. Li, H.-Y. Shum, and D. Schuurmans, “Face alignment using
statistical models and wavelet features,” in Proc. IEEE Int. Conf. Comput.
Vis. Pattern Recog., 2003, pp. 321–327.
[31] Z. Wang, X. Xu, and B. Li, “Bayesian tactile face,” in Proc. IEEE Int.
Conf. Comput. Vis. Pattern Recog., 2008, pp. 1–8.
[32] I. H. Witten and E. Frank, Data Mining: Practical Machine Learning Tools
and Techniques, 2nd ed. San Francisco, CA, USA: Morgan Kaufmann,
2005.
[33] W. S. Cleveland, E. Grosse, and W. M. Shyu, “Local Regression Models,”
in Statistical Models, J. M. Chambers and T. J. Hastie, Eds. New York,
NY, USA: Chapman and Hall, 1992.
[34] D. W. Marquardt, “An algorithm for least-squares estimation of nonlinear
parameters,” J. Soc. Ind. Appl. Math., vol. 11, no. 2, pp. 431–41, 1963.
[35] G. Isabelle and E. André, “An introduction to variable and feature selection,” J. Mach. Learning Res., vol. 3, pp. 1157–1182, 2003.
[36] J. Oh, S. Hwang, W. Tavanapong, P. C. de Groen, and J. Wong, “Blurry
frame detection and shot segmentation in colonoscopy videos,” in Proc.
IS&T/SPIE Symp. Electron. Imag., 2004, pp. 531–42.
[37] A. I. Bandos, H. E. Rockette, T. Song, and D. Gur, “Area under the free
response ROC curve (FROC) and a related summary index,” Biometrics,
vol. 65, no. 1, pp. 247–56, 2009.
[38] R. Collobert, S. Bengio, and J. Marithoz, “Torch: A modular machine
learning software library,” IDIAP , Martigny, Switzerland, Technical Tech.
Report Rep. IDIAP-RR 02–46, IDIAP, 2002.
[39] H. Trevor, T. Robert, and F. Jerome, The Elements of Statistical Learning:
Data Mining, Inference, and Prediction, 2nd ed. New York, NY, USA:
Springer, 2009.
[40] “Polynomial curve fitting,” MathWorks, [Online]. Available: http://www.
mathworks.com/help/techdoc/ref/polyfit.html

Authors’ photographs and biographies not available at the time of publication.

