IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 8, AUGUST 2015

2001

Acoustic Gaits: Gait Analysis With Footstep Sounds
M. Umair Bin Altaf∗ , Taras Butko, and Biing-Hwang (Fred) Juang, Fellow, IEEE

Abstract—We describe the acoustic gaits—the natural human
gait quantitative characteristics derived from the sound of footsteps as the person walks normally. We introduce the acoustic
gait profile, which is obtained from temporal signal analysis of
sound of footsteps collected by microphones and illustrate some
of the spatio-temporal gait parameters that can be extracted from
the acoustic gait profile by using three temporal signal analysis
methods—the squared energy estimate, Hilbert transform and
Teager–Kaiser energy operator. Based on the statistical analysis
of the parameter estimates, we show that the spatio-temporal parameters and gait characteristics obtained using the acoustic gait
profile can consistently and reliably estimate a subset of clinical and
biometric gait parameters currently in use for standardized gait
assessments. We conclude that the Teager–Kaiser energy operator
provides the most consistent gait parameter estimates showing the
least variation across different sessions and zones. Acoustic gaits
use an inexpensive set of microphones with a computing device as
an accurate and unintrusive gait analysis system. This is in contrast
to the expensive and intrusive systems currently used in laboratory
gait analysis such as the force plates, pressure mats and wearable
sensors, some of which may change the gait parameters that are
being measured.
Index Terms—Acoustic gait analysis, gait analysis, temporal
signal analysis.

I. INTRODUCTION
HE walking pattern of a person, the manner in which
the body and the legs move and the way the feet make
steps, comprises the human gait. It signifies the mobile state
of a person through the various characteristics it embodies. These characteristics—acquired through various sensing
mechanisms—can be used to identify a walking person [1],
detect the person’s state of mobility (running, walking, and beyond) [2], and diagnose gait and posture related pathologies of
the person of interest [3].
Gait analysis (GA) is a broad term which encompasses many
facets of the human walking behavior ranging from motion and
posture analysis to stride and energy expenditure analysis. For
example, in sports medicine, GA performed with biomechanical
and foot-pressure sensors is used to assess, and if necessary,
correct the gait and posture of an athlete or an injured person
alike [4]–[6]. Geriatrics makes extensive use of GA to assess
and predict the risks associated with mobility in the elderly
[7]–[10]. It is also used to assess the stage of certain diseases

T

Manuscript received October 11, 2014; revised January 22, 2015; accepted
February 18, 2015. Date of publication March 5, 2015; date of current version
July 15, 2015. Asterisk indicates corresponding author.
∗ M. U. B. Altaf and B.-H. (Fred) Juang are with the Center for Signal and Information Processing, School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332 USA (e-mail:
umair.altaf@gatech.edu; juang@ece.gatech.edu).
T. Butko is a CEO at Elian LLC, Dnipropetrovsk, Ukraine (e-mail:
tarasbarc@gmail.com).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2015.2410142

like Parkinson’s and Alzheimer’s diseases and to determine the
degree of recovery from stroke [10]. As a large portion of the
body is involved in executing the walking movement, it can
provide a biomarker for the identification of a healthy person
[11], [12].
Several standardized assessments and physical performance
tests based on GA can reliably predict function and healthrelated events, such as walking speed test, timed “up and go”
test (TUG), the Berg balance scale (BBS), the performanceoriented mobility assessment, and many others [9], [13], [14].
Various modalities have been used to collect gait information.
Electromyography was initially used [15] to analyze gait within
medical research. More recently, gait is analyzed with video and
wearable kinematic and pressure sensors [16]. Video recordings
are mostly used for later observational assessment of the gait
and for archival purposes. Automated video analysis, while not
generally used for augmenting the clinical assessment process,
has been proposed for use in identification of persons using
their gaits [1], [12], [17], [18]. Signals acquired from kinematic
sensors [19]–[21] and pressure sensors [11] have been analyzed
to model and identify a person’s gait, although not necessarily
from a medical perspective either.
Audio has also been used to study footstep sounds in the
laboratory [22]. Barring very few exceptions [23], the general emphasis has been on using spectral features derived from
short-time Fourier transform (STFT) to characterize the footstep
sound [24], [25]. However, these conventional STFT features are
designed to characterize human speech or music and are inadequate in characterizing footstep sounds [26]. Therefore, the
tasks that have been investigated with footstep sounds, such as
their detection among other sounds and biometrics extraction,
have had limited success [26], [27]. The results in the current
study will also highlight this gap in the STFT audio analysis
framework.
We note that the standardized gait assessments stated above
do not use these modalities to automate the tests. Furthermore,
these gait assessments have not been in consistent use in physical therapy and other clinical settings [28]–[30]. This infrequent
use can be partly explained by the qualitative nature of the tests;
apart from TUG and walking speed tests, both of which provide
rather limited gait dimensions, they rely on the subjective assessment of a trained observer. Other factors contributing to this
sparse use of standardized gait assessments may include tedious
and cumbersome procedural designs, expensive equipment, or
lack of knowledge in interpreting the assessment data.
To address these concerns, we believe that the sound which the
feet of the person make when walking encapsulates information
about the normal gait of the person without any alteration of the
behavioral environment. This sound can be collected cheaply,
nonintrusively, accurately and consistently with simple microphones, placing little burden on the patient and the doctor, a

0018-9294 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

2002

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 8, AUGUST 2015

Fig. 1. Schematic of a foot identifying the parts of the acoustically relevant
foot structure (top) and their interaction with the surface as the stance phase proceeds (bottom). The downwards arrows highlight the parts of the foot structure
that are most acoustically relevant at various instances of the stance phase.

combination of factors which is difficult to replicate with other
sensors such as video, pressure or kinematic wearable sensors.
The sounds can be further analyzed to obtain spatio-temporal
gait parameters. The challenge is to find a proper sound analysis
technique that is capable of reliably and accurately producing
gait-related measurements.
The paper is organized as follows. We introduce the main
concepts that underlie acoustic gaits (AG) in Section II and
explain the database and the signal analysis methods in Section
III. In Section IV, we specify the gait parameters that can be
obtained with AG and discuss their significance in the context
of the standardized gait assessments. We statistically analyze
the data obtained for two parameters from AG with ANOVA
and test for internal consistency and reliability in Section V. We
discuss the results and the issues raised by AG in Section VI
and conclude with a few observations and suggestions for future
improvements in Section VII.
II. MAIN CONCEPTS
We address GA from an acoustic perspective and describe the
concept of AG and acoustic gait profile (AGP), which provides
a substantial subset of markers required for GA.

Fig. 2. (b) SEE, (c) HT and (d) TKEO processed energy profiles of the raw
recorded footstep shown in (a).

clothing or others is insignificantly low relative to footsteps.
This is normally true unless in inordinary situations which are
beyond the present scope of investigation. Fig. 2(a) displays the
sound waveform recorded from a series of footsteps. As the
foot makes initial contact with the ground, in Fig. 1 made with
the heel, the audio waveform in Fig. 2(a) shows a significant
increase in amplitude. We notice another increase, though not
as prominent, when the hump at MTP joint makes contact with
the floor. There may also be a third notable burst of acoustic
activity, depending on the walking style and the footwear of the
person, when the MTP joint structure lifts off from the surface.
The rest of the cycle ensues when the next foot makes contact.
In general, each footstep creates a burst of acoustic activity,
which consists of multiple subbursts followed by a gradual decay. In this interaction, the anatomical structure of the foot as
well as the person’s walking behavior (habitual under normal
conditions or adaptive when the person’s body conditions are
temporarily different from normal) affects the characteristics of
these bursts. External factors such as footwear, noise level, and
floor type may also effect the burst characteristics but their effect can be controlled for in a practical situation. This series of
seemingly rough bursts, irregularly separated and interspersed
with background sounds, needs to be processed for GA as the
key characteristics of the gait may not be readily observed in
the raw waveform.

A. Human Gait
We show the major anatomical components of a human foot—
the heel, the metatarsals-phalanges (MTP), and the toes—and
part of a typical human gait cycle in Fig. 1. A normal gait cycle
begins when the heel of one foot makes contact with the ground
and ends when that same foot touches the ground again. Each
cycle consists of two phases: a stance phase (60% of a gait cycle)
in which a foot is in contact with the ground as shown in the
lower part of Fig. 1, and a swing phase (40% of a gait cycle)
in which the same foot swings forward until the next contact
with the ground. We only show the stance phase and omit the
swing phase in Fig. 1 as the foot generates no sound during the
swing phase, though the interaction of clothes with the moving
body parts may produce sounds which we ignore as noise, as in
our current recording setup the noise level due to frictions from

B. AGP
The AGP of a person is a time-domain representation of a
waveform obtained after applying a transformation, which can
be linear or nonlinear, on successive footstep sound bursts. The
bursts in the raw waveform become identifiable pulses within
an AGP and the gait specific characteristics naturally embedded
in the waveform bursts—the relative energy, shape, timings,
and duration—become available. The AGP is similar to other
clinical diagnostic tools such as the electrocardiogram, where
the plot can be further processed by a skilled clinician or a
computer to extract relevant information.
In Fig. 2(d), we show the AGP which is produced after processing the raw audio waveform of Fig. 2(a) with Teager–Kaiser
energy operator (TKEO). When compared with the profiles from

ALTAF et al.: ACOUSTIC GAITS: GAIT ANALYSIS WITH FOOTSTEP SOUNDS

Fig. 3.

Recording room schematic.

Hilbert transform (HT) [see Fig. 2(c)] and square energy estimate (SEE) [see Fig. 2(b)], the TKEO profile clearly shows three
subbursts in the footstep sound around the 1.5-s mark, while HT
and SEE profiles miss the last subburst. TKEO preserves the
three subbursts as three pulses. These signal analysis methods
are elaborated in Section III-B.
III. METHODS AND MATERIALS
A. Database
In general, sound databases treat footstep sounds as a homogeneous category and do not differentiate between the sound
of footsteps generated by different people. An existing publicly
available database of footstep sounds from different people is
noisy and lacks the necessary annotations [31].
We recorded a new database with person-specific footstep
sounds suitable for AG. The sounds were recorded in a lowreverberant room schematically shown in Fig. 3 with dimensions
noted as 5.10 m × 6.57 m. The room has a nominal reverberation
time RT60 of 200 ms from the room center to a transducer on
the wall (as estimated by the maximum-length sequence method
[32]). In total, sixteen microphones were employed for recordings: eight cardioid and eight omni-directional attached in pairs
to the walls of the room. Additionally, one video camera with
fish-eye lens was used to facilitate the annotation process. While
these multichannel signals have been recorded simultaneously,
for future investigations, we only use those channels that are
in the zoned proximity of the walking subject in the current
study. Thus, the direct signal dominates in the signal that was
analyzed and the effective reverberation time significantly deviates from the aforementioned nominal RT60 . The audio signals
are recorded in pcm format at 48-kHz sampling rate, Fs , with
24 bits per sample. The ratio between the peaks of footsteps and
the ambient noise in the recordings is around 20 dB.
We recorded the database in two scenarios. In Scenario-I, ten
sessions corresponding to ten participating volunteers (one female and nine males) were recorded. Each session consisted of
the subjects walking around the recording laboratory at his/her
natural speed, making 15 rounds clockwise and 15 rounds anticlockwise. In Scenario II, each participant recorded at least three
sessions, each with different footwear, and walked ten rounds

2003

clockwise and ten anticlockwise in each session. A total of 22
sessions were recorded for Scenario-II with seven subjects (all
male). When a subject walks in the clockwise direction, the left
foot will always be closer to the microphones mounted on the
walls than the right foot, and vice versa for the anticlockwise
direction. Making the subjects walk both directions and using
balanced averaging allow us to eliminate this asymmetry in distance and helps with detection and statistical analysis of the
asymmetry of the footstep energy E in Section V.
For convenience, as shown in Fig. 3, the room was divided
into 12 zones so each individual footstep of the subject may
take place in a particular zone. However, to verify the internal
statistical consistency of the parameters in a recording session,
we further group the 12 zones into four zone groups to get a
statistically significant balanced sample of the parameters (see
Section V).
The database was annotated by two annotators using the
ELAN annotation tool [33] that allows creating, editing, visualizing and searching annotations for video and audio data.
The annotation file includes the starting time of each footstep
sound together with one of 24 possible text labels: L01, L02,
..., L12, R01, R02, ..., R12. Each label corresponds to the zone
in which the footstep occurred and the foot (left or right) which
produced the sound. The text labels were manually assigned
based on information from the video camera. Ten sessions from
Scenario-I and 13 sessions from Scenario-II were annotated.
B. Audio Analysis Methods
A suitable signal processing technique—a transformation
which preserves and accentuates the gait specific features while
suppressing the spurious distortions—is the challenge. The conventional choice in audio signal processing is to decompose
the footsteps sound into its frequency components using STFT.
However, footsteps sounds are impact sounds with very little
harmonic structure making them unsuited for STFT analysis.
We introduce two improved transformations as alternatives to
STFT: the HT—a linear integral transformation that preserves
the outer contour of the sound under certain general conditions and the TKEO—a nonlinear differential transformation
that calculates the instantaneous energy based on amplitude
and frequency of the sound. The nonlinearity of TKEO can
be shown to sharpen the bursts within a footstep sound. Compared to STFT, both of these transforms report results in the
time-domain which is desirable for GA. The transformed signal
further undergoes a proper lowpass filtering, resulting in crisp
pulses and accurate timing information.
The sound of footsteps depends on the type of floor (e.g.,
carpets, hardwood, concrete, etc.) and the footwear the walking
subject has on. Different combinations of floor and footwear
result in different footstep sounds, which at times can be perceptually discerned. The method of STFT may well be relevant in
reflecting some of the spectral aspects these sounds may encapsulate. However, short-time spectral features derived from STFT
have deficiency in at least two ways. The rapid temporal changes
cannot be represented accurately due to the time-frequency
uncertainty principle [34]. Second, the typical short-time

2004

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 8, AUGUST 2015

interval of 20–40 ms is not long enough to encompass the
long-term (greater than 100 ms) repeatability of the series of
footsteps. Increasing the short-time interval in STFT to account
for this leads to unreliable estimates due to the nonstationarity
of the signal at such time-scales.
We wish to find a possible feature representation from the
acoustic signal of the footsteps of a person, which preserves the
prominent characteristics, as outlined before. Since these characteristics require fine temporal precision and measurements of
energy over the long run, we propose to extract the “temporal profile” or “temporal envelope” of the waveform. This is
achieved by a suitable signal processing technique. A temporal
profile is an instantaneous energy representation of the signal.
The smoothed temporal profile is a lowpassed version of the
temporal profile. We termed the smoothed temporal profile extracted from transformed footstep sounds as the AGP in Section
II-B. In the following we will discuss in more details the three
methods which can be used to obtain AGP.
Let us denote the lowpass filter operator with cut-off frequency set at c Hz as Lc (). It is a fourth-order digital Butterworth filter. We can obtain the simplest profile by the
SEE. That is, for a time-domain discrete signal x[n], n ∈ Z,
AGPSEE [n] = Lc (x2 [n]) is the SEE AGP. The HT is the method
that provides another way to extract the profile. The discrete HT
of x[n] is
H{x[n]} = x[n] ∗ h[n]
where ∗ is the convolution operator and

0,
n ∈ even,
h[n]  2
n ∈ odd.
nπ ,

(1)

(2)

(3)

where xa [n] is the analytic signal obtained from x[n]. The absolute value, |xa [n]|, is the discrete Hilbert envelope of x[n].
AGPH T [n] = Lc (|xa [n]|) is the Hilbert AGP.
The TKEO [35] provides an unconventional perspective on
the instantaneous energy of a signal. It relates energy to square
of the signal amplitude and the square of its frequency. The
discrete instantaneous energy, ψd (x[n]) of a signal x[n] given
by TKEO is
ψd (x[n]) = x2 [n] − x[n + 1]x[n − 1].

Acoustic GA is the processing of the AGP to automatically
extract the gait characteristics. The following general observations guide the acoustic GA framework.
Consistency of Successive Footsteps: In a normal sequence of
steps a walking subject’s gait demonstrates a certain degree of
statistical consistency, natural fluctuations notwithstanding. An
effective analysis method will reflect this statistical consistency
in its results. This can be manifest in the continuity of the walk,
the dynamic balance, or the variability in cadence and speed.
Presence of Multiple Pulses in a Step Burst: Each sound burst
due to a footstep is found to consist of one, two or more subbursts. They arise as different parts of the foot make contact with
the walking surface. The energy distribution, temporal duration,
and the number of subbursts are correlated with a particular
walking style of an individual. The proper analysis of these
subbursts yields the pulses.
Asymmetry Between Left and Right Foot: The acoustic characteristics produced by the two feet may be asymmetric. These
asymmetries may be modulated by footwear, floor surface,
carry-on objects or a pathological condition.
The nature of the sensing mechanism in acoustic GA limits
it to the stride and ground reaction forces level. As we will
discuss in the next section, we can infer certain facts about
the posture and kinematic parameters but we cannot directly
perform posture and kinematic analyses, which are beyond the
scope of acoustic GA and this paper.
A. AGP Measurements

After obtaining H{x[n]}, we construct a complex signal xa [n]
as follows:
xa [n]  x[n] + iH{x[n]}

IV. ACOUSTIC GA

(4)

AGPT K [n] = Lc (ψd (x[n])) is the TKEO AGP. In Fig. 2(b)–
(d), we show the SEE, HT, and TKEO AGPs, respectively, of the
footsteps sound shown in Fig. 2(a), with c = 20 Hz. TKEO AGP
provides the most crisp representation of the sound, as the pulses
are clearly delineated. This is because the decay of the sound
burst is similar to an exponential decay and ψd (e−bn ) = 0, ∀b ≥
0. Moreover, TKEO combines the instantaneous frequency, in
addition to signal amplitude, in the energy estimate—combining
the local and long-term measurement in a single estimate.

We now detail the procedure used for obtaining the raw measurements from the AGP. Let ni be the starting time epoch of
a footstep sound in samples, where i ∈ {1, . . . , N } and N is
the total number of footsteps. ni is determined from the annotations, as described in Section III-A, though it can also be
estimated automatically [26]. Let δ1 be the maximum duration,
in samples, of the first pulse for any footstep AGP. From our
observations, we set δ1 /Fs = 200 ms, where Fs is defined in
Section III-A. The highest magnitude of the first pulse of the
ith footstep sound, Ei1 , is determined from the AGP with the
following:
Ei1 =

max

n ∈[n i ,n i +δ 1 ]

{AGP{.} [n]}.

(5)

The time sample epoch of Ei1 , nEi 1 , is straightforward to obtain
with nEi 1 = arg maxn ∈[n i ,n i +δ 1 ] {AGP{.} [n]}. To determine the
magnitude and time sample epoch of the second pulse of the ith
footstep sound, Ei2 , we calculate an adaptive threshold, for a
particular session m and channel p with a global mean μm ,p .
The mean is estimated by iterated expectations over the interval [ni + δ1 , ni+1 ] ∀ i, i.e., μim ,p = E[x[ni + δ1 : ni+1 ]] and
μm ,p = E[μim ,p ], where E[.] is the expectation operator and : is
the range operator. Thus
Ei2 =

max

n ∈[n i +δ 1 ,n i + 1 ]

{AGP{.} [n]|AGP{.} [n] > βμm ,p }

(6)

ALTAF et al.: ACOUSTIC GAITS: GAIT ANALYSIS WITH FOOTSTEP SOUNDS

2005

TABLE II
MAPPING BETWEEN THE AGP AND GRF TERMS
AG Term
E L /E R
D1
D2
T1
T2
AGP
Cadence/velocity
Cardinality

Fig. 4. Illustration of the measurements which can be extracted from the AGP
along the magnitude and time axes. The magnitude indicates energy of the
footstep. The term “energy” is applied to the conventional SEE as well as to the
quantity estimated by the TKEO.
TABLE I
SUMMARY OF THE AG PARAMETERS
Parameter
C
D1
D2
T1
T2
E L and E R
S1
S 2 L and S 2 R

Definition
The number of pulses in one footstep sound.
E
E
(n i 2 − n i 1 )/F s , needs C ≥ 2.
E
E
(n i 3 − n i 2 )/F s , needs C ≥ 3.
t
E
(n i1 − n i 1 )/F s .
t
E
(n i2 − n i 2 )/F s .
i+ 1
i
E 1 and E 1 , respectively, when i is the index of a left footstep.
E1
E1
(n i +
1 − n i )/F s .
E1
E1
(n i + 2 − n i )/F s , i is the index of a left footstep for S 2 L .

GA Term
Balance asymmetry
NA
NA
Mid stance interval
Terminal stance interval
Vertical GRF pattern
Cadence/velocity
Forward/backward lean

and, over a large number of footsteps, generate a statistical
distribution. The number of pulses per footstep sound, derived
from the subbursts, deserves special mention. We use the term
cardinality, C, of a footstep to indicate the number of these
pulses in a footstep sound. C = 1, 2, and 3 corresponds to
single, double, and triple footsteps, respectively.
Most of the parameters available from AG are spatio-temporal
gait parameters [36], such as stride-time or cadence. Others, such
as EL /ER and C, are not strictly time or distance parameters
but both of these parameter types are sourced from the same
time-varying sound pressure measurement. Therefore, the latter
category of parameters also inherits a spatio-temporal character.
C. Clinical Significance

where β = 1.20. Ei2 is undefined if there is no value above
this threshold. The time sample epoch of Ei2 , nEi 2 , is obtained
with nEi 2 = arg maxn ∈[n i +δ 1 ,n i + 1 ] {AGP{.} [n]|AGP{.} [n] >
βμm ,p }. Likewise, we can determine the third pulse magnitude,
Ei3 , and the time sample epoch, nEi 3 , if any.
The time epochs of the first trough, nti1 , and
second trough, nti2 , which occur after the first
and second pulses, respectively, are estimated with
nti1 = arg min[n E1 ,n E2 ] {AGP{.} [n]|AGP{.} [n] > 0} and nti2 =
i
i
arg min[n E2 ,n E3 ] {AGP{.} [n]|AGP{.} [n] > 0}, when the rei
i
spective intervals are defined. We are not interested in the
magnitude of the troughs. Fig. 4 illustrates the magnitude and
time epoch measurements that can be taken from an AGP.
The database includes the footstep sounds from multiple
channels and in this study we only use the sound from the
single channel closest to the source, due to the preliminary nature of this study. This channel was identified using video. The
multichannel capability, along with automatic detection of footsteps, can lead to a better collection of the initial sound and will
provide acoustic localization and tracking, which is currently
accomplished with video. Also, we did not perform any normalization over the room impulse response. These aspects of
the AG system will be studied in the future.
B. AG Parameters
Table I gives a subset of the AGP parameters that can be
obtained from the raw measurements in Section IV-A. They
are automatically collected for every subject with each footstep

The parameters identified in the last section are by no means
exhaustive but they do provide a reasonable subset that are used
for GA in clinical settings. We first notice that the AGP in
Fig. 2(d) resembles, though not identical to, the vertical ground
reaction forces (GRF) plots [6], [37] traditionally used for GA
in the stance phase of a gait cycle. GRF shows the magnitude
and direction of loading applied to the foot structures during
locomotion. The AGP provides the magnitude of such forces
and the information about the stance phase of the gait cycle.
Various epochs within the stance phase indicated by the AGP,
such as the initial contact, the loading response, the mid stance
valley and the terminal stance, can be easily mapped to the
GRF plot. For example, EL /ER is the “balance asymmetry”
in conventional GA, T1 is the midstance interval and T2 the
terminal stance interval, to name a few. The AGP provides this
information with off-the-shelf microphone sensors which are
cheaper and easier to set up than force plates or pressure mats,
which are normally used in gait laboratories. Table II shows
such a mapping.
Body-weight balancing is an important factor included in
gait assessment tests such as BBS and POMS. Interestingly,
most people with normal weight systematically distribute more
weight on one foot than the other as they walk [12]. This asymmetry appears as energy asymmetry between the AGP of the
right and the left footstep quantified by the ratio of sound energy, EL /ER .
In Fig. 5 we show the normalized statistical distribution of
EL /ER for different healthy people with a normal walking
style. This parameter was obtained from the database that we

2006

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 8, AUGUST 2015

Fig. 7. Left and right foot distribution of D 1 for subject 1. The distribution of
both feet is clustered around 50 ms. Note the lateral asymmetry due to a second
prominent distribution mode for the right foot.
Fig. 5. Normalized distribution of the ratio E L /E R for four subjects estimated with TKEO AGP. The number followed by p is the subject label, while
m and s are the parameters of the best-fit lognormal distribution.

10 does not have any. Most of the left-footsteps of subject 5
have C = 2.
In Fig. 7, we plot the distribution of D1 , for subject 1 from left
and right foot. D1 is a proxy for step height and foot clearance
parameters, which are used in POMS gait assessment tests.
Figs. 5 to 7 illustrate the statistical distribution of a subset of
AG parameters that can be extracted from the AGP and show the
symmetry, or otherwise, of these parameters from the left and
right foot. The clustering of the distributions around a central
point indicates a consistency in a given session for a given person
and we will quantify this consistency in the next section.
V. STATISTICAL ANALYSIS

Fig. 6. Percentage of cardinality of footsteps for 10 subjects produced by the
left foot.

collected from normal walking subjects (see Section III-A). A
value of EL /ER other than 1 corresponds to an asymmetry in
gait. We notice that the distribution of this ratio can be well approximated by a log-normal distribution with the parameters of
the log-normal distribution given in Fig. 5. Clearly, we are able
to identify subtle asymmetries in weight distribution for healthy
individuals—EL /ER is distributed more evenly for Subjects 7
and 9 when compared to EL /ER for Subjects 3 and 4, which is
skewed toward the left and right, respectively. These measurements can be extended to evaluation of foot and gait pathologies
[38].
Stride time, stride length, cadence (steps/min), walking speed
(m/s) and their stability are fundamental gait assessment parameters [28], [39]. It is straightforward to obtain the stride time,
cadence, and, given the total walking distance, the stride length
from S2R and S2L .
The elderly, unless they have diseases such as osteoporosis
with kyphosis, can walk upright with no forward lean [40],
although some healthy people walk normally with a forward
lean. In either case, forward lean would almost always lead to
increased proportion of C > 1 cardinality steps and may suggest
pathological issues for unhealthy subjects. In Fig. 6, we plot the
proportion of C of left-footsteps for several healthy subjects with
normal gait during the session. This plot shows that subject 1 has
the highest number of left-footsteps with C = 3, while subject

Within the AG framework, we generate the parameters by
analyzing the footstep sounds collected over a period of a few
minutes. These multiple realizations of the footstep sound generation process lends itself naturally to a statistical description.
We have already illustrated this when we showed the parameters in terms of their statistical distributions in Section IV-C.
The statistical analysis in this section:
1) verifies the internal consistency of the parameters;
2) helps us understand the parameter variation when the conditions change for a given healthy subject; and
3) compares the results in 1) and 2) across the aforementioned three signal analysis methods to assess the relative discerning power of parameters estimated from each
method.
We leverage our dual-scenario database recordings from
healthy individuals, described in Section III-A to achieve the
above. We achieve 1) by checking for intrasession consistency
of the parameters estimated with recordings from Scenario-I and
Scenario-II, and 2) by checking for intersession consistency of
the perimeters estimated from recordings in Scenario-II only.
The parameters are estimated from the estimation methods for
both cases and are compared to each other to achieve 3). In
the subsequent discussion, each session label has the format
“Sy − x,” where y = 1 for sessions from Scenario-I and y = 2
for sessions from Scenario-II. x ∈ N is an arbitrary index.
The ratio EL /ER and D1 , as defined in Table I, are chosen as
the study parameters in the following analyses. EL /ER is used
instead of EL or ER directly, as each analysis method’s energy
estimate is not directly comparable. This becomes important
when comparing the estimates of this parameter with different

ALTAF et al.: ACOUSTIC GAITS: GAIT ANALYSIS WITH FOOTSTEP SOUNDS

2007

methods, which is the goal 3) above. It also obviates the need for
applying arbitrary normalizations for each scenario. A one-way
balanced ANOVA design is used to achieve the objectives 1)–3).
One of the assumptions behind ANOVA is the normality of
the data but, as we show in Fig. 5, this is not true of EL /ER
derived from TKEO. To address this, we also checked the results with the Kruskal–Wallis (KW) test, which is similar to
the standard ANOVA test but does not require the normality
assumption. The results from both tests were similar, indicating
that ANOVA is sufficiently robust against the violation of the
normality assumption for this data. Thus, we used the standard
ANOVA for subsequent tests.

TABLE III
NUMBER OF SAMPLES OF THE PARAMETER E L /E R COLLECTED FROM
EACH ZG
Session Label
S1-3
S1-5
S1-6
S1-8
S2-1
S2-3
S2-4
S2-5
S2-7

i =ZG1

i =ZG2

i =ZG3

i =ZG4

35
80
83
76
58
58
57
54
55

35
70
78
76
56
49
50
49
54

34
77
72
71
57
54
53
54
55

39
72
88
73
59
59
58
56
57

A. Intrasession Consistency and Parameter Stability
Let us denote the parameter of interest as ρ. It is collected
from each of the 12 zones in the room during a given session. We
group the statistics from the 12 zones into four zone groups (ZG)
numbered 1 ...4. Zones 1, 2, and 3 are grouped as ZG1, zones
4, 5, and, 6 are grouped as ZG2 and, so on. This grouping into
ZGs ensures adequate samples for each grouping and makes
for a more balanced ANOVA design between the ZGs when
compared with just the zones.
We assume the following fixed-effects one-way ANOVA
model for parameter ρ estimated in ith ZG, with jth method
at time t, (ρ)ji (t):
(ρ)ji (t) = μj (t) + ZGji,ρ (t) + ji (t)

(7)

where i = 1, 2, 3, and 4 is the ZG index and j ∈
{SEE, HT, T KEO} is the label for the method used to estimate the parameter. SEE is the SEE profile, HT is the Hilbert
profile and T KEO is the TKEO profile. μj (t) is the grand mean
for the jth estimation method, and ZGji,ρ (t) is the effect on the
ρ parameter estimated in the ith ZG and jth method at time t.
ji (t) is the zero mean, unit variance Gaussian noise process for
the ith ZG and jth method at time t. We set the significance
level for ANOVA at α = 0.01.
We expect that a parameter collected within a session is statistically consistent across the four ZGs. This ensures that the
value of the parameter is internally stable. To test this, we set
up the following null hypothesis:
j
: ZGj1,ρ = ZGj2,ρ = ZGj3,ρ = ZGj4,ρ .
H0ρ

(8)

We begin with the perimeter ρ = EL /ER in (7). Table III
shows the number of estimated parameters for EL /ER in
each ZG for a given session. In Table IV we show the result of the ANOVA analysis on EL /ER for the sessions in
Table III. It shows that for a majority of sessions, the hypothesis
j
|ρ=E L /E R is not rejected. This suggests that the variation
H0ρ
across the ZGs is not statistically significant for those sessions.
For sessions S1-5 and S1-6, the parameter estimated from SEE
and HT shows significant variation at α = 0.01, while the TKEO
estimates are still insignificant. These results imply that the variation of the parameter as estimated from the audio analysis is
not significant during a session, and that TKEO estimate is the
most consistent among the three.

Table IV also gives the mean value of the parameter and
its standard error for each session and method. A value of
EL /ER < 1 indicates an asymmetry in favor of the left foot
and vice versa for EL /ER > 1. We can notice that the asymmetry indicated by the three methods is consistent in indicating
the dominance of one foot over the other within the error bounds.
For example, in session S1-3 EL /ER < 1 for all methods, while
for session S2-1 EL /ER > 1 for all methods, though the degree of this asymmetry is not consistent. We can also notice that
the standard error is consistently the least for TKEO among all
methods for a given session.
Next we test consistency for parameter ρ = D1 in (7). The
setup, including the one-way ANOVA model, is identical to the
case for parameter EL /ER , except that we do not use SEE to
estimate D1 , i.e., j ∈ {HT, T KEO} for ρ = D1 in (7) and
(8). Table V tabulates the number of parameter D1 estimated
in each ZG for a given session. All estimation methods will
have the same number of parameters in a given session. Unlike
EL /ER , the parameter D1 relies on the presence of a double
step—i.e., C ≥ 2—and is thus subject to the walking style of an
individual. Hence, we only show sessions here where we could
collect adequate number of double steps balanced across the
ZGs. In Table VI we give the results for the ANOVA analysis
j
|ρ=D 1 in (8). The p-values suggest that
with the hypothesis H0ρ
D1 estimated from TKEO profiles does not show significant
variation within a session, while D1 estimated from HT profile
does show significant variation for some sessions such as S1-4
and S2-5. Thus we conclude that the intrasession consistency
is much stronger for D1 estimated from the TKEO profile than
the HT profile.
The average values of the parameter and its standard error
also appear in Table VI. D1 estimated by the TKEO profile
is consistently higher than the HT profile estimate, while the
standard error is similar for both. We can also notice that the
estimates of D1 for session S2-4 and S2-5 are almost the same.
This is an example where the same subject participated in the
two sessions, but with different footwear. We will study this
intersession variation more throughly in the next section.
B. Intersession Consistency and Footwear Variation
We now discuss the statistical tests for the case when the same
subject is recorded in different sessions with different footwear.

2008

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 8, AUGUST 2015

TABLE IV
RESULTS OF ANOVA WITH THE E L /E R PARAMETER, COLLECTED FROM FOUR ZGS WITH THE SEE, HT AND TKEO PROFILES FOR THE SESSIONS IN TABLE III
j = SEE
Session Label

j = HT

j = T KEO

F-value

p

E L /E R

F-value

p

E L /E R

F-value

p

E L /E R

2.86
8.38
5.41
1.86
0.95
2.94
3.00
1.58
0.35

0.039
0.000
0.001
0.136
0.416
0.034
0.031
0.197
0.791

0.70 ± 0.04
1.33 ± 0.04
1.16 ± 0.06
1.22 ± 0.05
2.09 ± 0.09
0.96 ± 0.05
1.38 ± 0.08
1.23 ± 0.10
1.29 ± 0.09

2.41
9.66
9.96
0.90
1.34
3.08
2.58
0.88
1.00

0.070
0.000
0.000
0.441
0.263
0.028
0.055
0.452
0.396

0.81 ± 0.03
1.13 ± 0.05
1.04 ± 0.05
1.08 ± 0.05
1.36 ± 0.08
0.91 ± 0.04
1.09 ± 0.06
0.99 ± 0.07
1.05 ± 0.08

1.09
3.02
2.16
0.32
0.08
1.46
0.83
0.11
0.78

0.355
0.030
0.093
0.814
0.969
0.226
0.479
0.953
0.504

0.62 ± 0.02
1.22 ± 0.02
0.99 ± 0.02
1.15 ± 0.02
2.27 ± 0.03
1.01 ± 0.02
1.23 ± 0.03
1.02 ± 0.04
1.17 ± 0.03

S1-3
S1-5
S1-6
S1-8
S2-1
S2-3
S2-4
S2-5
S2-7

F-value column is the F-statistic for each one-way ANOVA, the p column gives the p-value and E L /E R gives the average
estimate of the parameter along with its std. error. The p-values in bold are statistically significant w.r.t. α = 0.01.

TABLE V
NUMBER OF SAMPLES OF THE PARAMETER D 1 COLLECTED FROM EACH ZG
Session Label
S1-4
S1-5
S1-8
S1-9
S2-4
S2-5
S2-13

i =ZG 1

i =ZG 2

i =ZG3

i =ZG4

58
148
118
153
78
79
93

64
138
131
159
87
79
92

63
134
123
146
84
70
83

71
147
128
163
94
85
95

j = SEE
Subject No. k
3
6
8

TABLE VI
RESULTS OF ANOVA WITH THE D 1 PARAMETER, COLLECTED FROM FOUR
ZGS WITH THE HT AND TKEO PROFILES FOR THE SESSIONS IN TABLE V
j = HT
Session Label
S1-4
S1-5
S1-8
S1-9
S2-4
S2-5
S2-13

j = T KEO

F-value

p

D 1 ms

F-value

p

D 1 ms

4.50
0.38
3.85
3.61
8.03
4.91
0.39

0.004
0.765
0.010
0.013
0.000
0.002
0.761

84.17 ± 1.05
62.10 ± 0.48
106.90 ± 1.38
68.76 ± 0.88
99.90 ± 1.33
100.01 ± 1.23
69.19 ± 1.27

3.72
1.43
3.39
0.47
2.12
0.14
1.33

0.013
0.235
0.018
0.700
0.098
0.934
0.265

86.31 ± 1.50
64.04 ± 0.54
108.63 ± 1.36
70.09 ± 1.09
104.28 ± 1.11
105.15 ± 0.86
69.64 ± 1.42

F-value column is the F-statistic for each one-way ANOVA, the p column gives the
p-value and D 1 gives the average estimate of the parameter along with its std. error.
The p-values in bold are statistically significant w.r.t. α = 0.01.

Let ρ denote the parameter of interest. We assume the following fixed-effects one-way ANOVA model for parameter
(ρ)jik , l (t), which is ρ estimated in ith
k ,l session, for kth subject,
with jth method at time t:
(ρ)jik , l (t) = μj,k (t) + Sijk , l ,ρ (t) + jik , l (t)

TABLE VII
RESULTS OF ANOVA WITH THE E L /E R PARAMETER, COLLECTED FROM
THREE SUBJECTS ESTIMATED FROM THE SEE, HT, AND TKEO PROFILES FOR
THE SESSIONS IN TABLE III

(9)

where ik ,l is the session label for the lth session of the kth subject
and j ∈ {SEE, HT, T KEO} is the label for the methods used
to estimate the parameter. μj,k (t) is the grand mean for the jth
estimation method and kth subject, and Sijk , l ,ρ (t) is the effect on
(ρ)jik , l (t). The footwear variation is achieved by keeping j and
k constant and varying l. jik , l (t) is the zero mean, unit variance

j = HT

j = T KEO

F-value

p

F-value

p

F-value

p

1.94
0.21
7.03

0.145
0.651
0.001

6.31
0.02
7.36

0.002
0.884
0.001

7.93
2.30
31.32

0.000
0.130
0.000

F-value column is the F-statistic for each one-way ANOVA and the p column
gives the p-value. The p-values in bold are statistically significant w.r.t. α =
0.01.

Gaussian noise process for the ith
k ,l session and jth method at
time t. As before, we set the significance level for ANOVA at
α = 0.01.
We first set ρ = EL /ER in (9). To check the consistency,
or otherwise, of the EL /ER estimate across the footwear variant sessions, we set up the following null hypothesis for three
subjects with k ∈ {3, 6, 8}:
j,k
: Sijk , 1 ,E L /E R = Sijk , 2 ,E L /E R = Sijk , 3 ,E L /E R . (10)
H0E
L /E R

i3,{1,2,3} = {S2-4, S2-5, S2-6}, i6,{1,2} = {S2-6, S2-8}, and
i8,{1,2,3} = {S2-9, S2-10, S2-11} are the session labels for the
three subjects. Note that there are only two sessions for subject
k = 6. In Table VII, we give the results of the ANOVA analysis
j,k
is
on EL /ER for these subjects. Table VII shows that H0E
L /E R
not rejected for subject 6 for all methods, while it is rejected for
the majority of the rest. To analyze this further, we performed
posthoc tests at the same, Bonferroni corrected, significance
levels. The results are given in Table VIII. It shows that sessions
S2-4 and S2-6, for subject 3, are not significantly different from
each other while session S2-5 is significantly different from
the other two for subject 3. Subject 8 not only shows variation
with footwear, but the differences among the sessions are also
significant for different methods.
Next, we fix ρ = D1 as the parameter of interest in (9). As
before, j ∈ {HT, T KEO} for ρ = D1 in (9) is the label for the
methods used to estimate D1 .

ALTAF et al.: ACOUSTIC GAITS: GAIT ANALYSIS WITH FOOTSTEP SOUNDS

TABLE VIII
TABLE PROVIDES THE AVERAGE E L /E R ESTIMATE AND ITS STANDARD
ERROR FROM THE SEE, HT, AND TKEO PROFILES FOR EACH SESSION WITH
THE GIVEN SUBJECT LABELS
Subject No. k

Session label i k , l

3

S2-4
S2-5
S2-6
S2-7
S2-8
S2-9
S2-10
S2-11

6
8

j = SEE

j = HT

j = T KEO

E L /E R

E L /E R

E L /E R

1.36 ± 0.07
1.17 ± 0.07
1.32 ± 0.08
1.29 ± 0.08
1.24 ± 0.08
1.02 ± 0.06
1.33 ± 0.06
1.15 ± 0.05

1.22 ± 0.06
0.97 ± 0.06
1.26 ± 0.06
1.17 ± 0.06
1.04 ± 0.06
0.88 ± 0.05
1.33 ± 0.05
0.85 ± 0.04

1.09 ± 0.03
0.96 ± 0.03
1.08 ± 0.03
1.05 ± 0.03
1.06 ± 0.03
0.97 ± 0.02
1.08 ± 0.02
1.08 ± 0.02

TABLE IX
RESULTS OF ANOVA WITH THE D 1 PARAMETER, COLLECTED FROM TWO
SUBJECTS WITH HT AND TKEO PROFILE
j = HT
Subject No.
2
3

j = T KEO

F-value

p

F-value

p

13.55
4.48

0.000
0.012

0.48
3.07

0.487
0.047

F-value
column
is
the
F-statistic
for
each
one-way
ANOVA
and
the
p column gives the p-value. The p-values in
bold are statistically significant w.r.t. α = 0.01.

We now determine the effect on the estimate of the footwear
across different sessions by setting up the following null hypothesis for two subjects with labels k ∈ {2, 3}:
j,k
H0D
: Sijk , 1 ,D 1 = Sijk , 2 ,D 1 = Sijk , 3 ,D 1 .
1

(11)

i2,{1,2} = {S2-1, S2-2} and i3,{1,2,3} = {S2-3, S2-4, S2-5} are
the session labels for the two subjects. Note that there are only
two sessions for subject k = 2. In Table IX, we give the results of
the ANOVA analysis on D1 for these subjects. As we explained
in the last section, the selection of these sessions was dictated by
the availability of sufficient number of estimates of D1 balanced
across the sessions.
j,k
is rejected for subject no. 2 for
Table IX shows that H0D
1
HT estimate, while it is on the margin for subject no. 3 for
both estimation methods. To analyze this further, we performed
posthoc tests at the same, Bonferroni corrected, significance
levels. The results are given in Table X. It shows that sessions
S2-4 and S2-5, for subject 3, are not significantly different from
each other while session S2-3 is significantly different from
the other two for subject 3. The differences are statistically
significant but, for a given method, the absolute difference in
values are less than 5% for this parameter.
VI. DISCUSSION
The data analysis of parameters EL /ER and D1 in Section V
shows that the values do not significantly vary within a walking
session (p > 0.01) for parameters obtained with TKEO pro-

2009

TABLE X
TABLE PROVIDES THE AVERAGE D 1 ESTIMATE AND ITS STANDARD ERROR
FROM THE TWO METHODS FOR EACH SESSION WITH THE GIVEN SUBJECT
LABELS
Subject No. k

2
3

Session Label i k , l

S2-1
S2-2
S2-3
S2-4
S2-5

j = HT

j = T KEO

D1

D1

74.58 ± 0.88
78.61 ± 0.64
96.29 ± 1.01
100.25 ± 1.10
100.04 ± 1.16

79.49 ± 1.04
80.42 ± 0.80
102.45 ± 0.77
104.98 ± 0.86
104.85 ± 0.94

file. When the footwear is changed, EL /ER shows statistically
significant (p < 0.01) variations, while D1 remains unchanged.
With these results, we can be reasonably confident that the
parameters provided by AG are internally consistent and reliable
enough over a session to be usable in GA. In Section V-A, where
we compare the parameters estimated within each zone group
of a given session, we validate a premise of AG that the sounds
are picking up the characteristics related to gaits of the person.
The TKEO profile provides better estimates when compared
with other methods as evidenced by its consistency within the
session and the low standard error of its estimates.
The results in Section V-B indicate that EL /ER , which is
energy based, is sensitive to footwear variation, more so when
estimated with TKEO and HT methods. On the one hand, this
shows that these methods are able to pick-up subtle variations in
gait. On the other hand, it shows that this statistic is not a good
biometric due to its dependence on footwear, when estimated
with TKEO. D1 , which is duration based, seems to be better
at footwear independence due to its low relative variation. In
case footwear dependency is to be avoided (as in some critical
situations), AG with bare foot (i.e, footwear free) would be
advisable.
We estimate D1 using the Hilbert and TKEO profiles for
both the right and left foot. The asymmetry in any parameter
extracted from the left and right foot may be a characteristic of
the walking style of a person which can be significant, e.g., for
a biometric application, or may be correlated with a pathology
for an unhealthy person. Since we do not know if asymmetry for
D1 is significant, unlike E parameter where the lateral asymmetry is manifest as dynamic weight imbalance, we do not explore
it in detail.
The variation in footwear is one of the few controllable
changes which can potentially affect a healthy individual’s
gait characteristics. Other changes may include walking while
holding or wearing a heavy object, and walking variations introduced across sessions separated by a time-period [31].
The difference between an energy based and duration based
statistic is understandable because the latter is tied to the length
of the footwear, while the former depends more strongly on the
construction—such as the presence or absence of heel and its
width and height—and material of the footwear. This implies
that a normalization over footwear is essential for making AGs
practically viable. However, at this point the data and analysis

2010

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 8, AUGUST 2015

that we present does not allow us to point out the exact origin
and extent of variations in the parameters due to footwear.
With the novelty of the study in mind, the particular recording setup was designed to provide maximum data for subsequent
analyses. Thus, the design of the experiment is overdetermined
in a few respects and the results can be replicated with a reduced
or simplified setup, e.g., the consistency of the parameters indicates that we can reduce the number of rounds in our recording
scenarios by 30–40%, the subject can also walk in a straight
line, and the number of microphones can be reduced as long
as the walking area is adequately covered and the sounds are
accurately localized.
In this study we do not compare to the standardized gait
assessments and this will be left as a future work.
VII. CONCLUSION
We introduce the novel approach of using audio to extract
quantitative characteristics of the human gait. It enables in situ
data acquisition and testing of the subject without wearing any
instruments—as such instruments may alter the gait characteristics to be measured. We show that the sound from footsteps does
encapsulate information useful for GA and that this information
can be consistently extracted.
We propose to augment the current mostly qualitative gait
assessment tests with objective and quantitative parameters,
identify and extract gait characteristics in a reliable and consistent manner, and ensure that they are physically correlated with
gait spatio-temporal characteristics. The proposed approach also
makes available some new parameters which are not available
with qualitative gait assessments.
The use of this technique in clinical conditions is predicated
on further studies, which are necessary to compare and correlate
the results with current assessment methods. The new parameters also need evaluation for their usefulness in improving the
current gait assessment criteria.
REFERENCES
[1] J. J. Little and J. E. Boyd, “Recognizing people by their gait: The shape
of motion,” Videre: J. Comput. Vision Res., vol. 1–2, pp. 2–32, 1998.
[2] J. Frank et al., “Activity and gait recognition with time-delay embeddings,” in Proc. Conf. Artif. Intell., 2010, pp. 1581–1586.
[3] J. Perry, Gait Analysis: Normal and Pathological Function. Thorofare,
NJ, USA: SLACK, 1992.
[4] S. Ounpuu, “The biomechanics of walking and running,” Clin. Sports
Med., vol. 13, no. 4, pp. 843–863, 1994.
[5] V. M. Zatsiorky et al., “Basic kinematics of walking. Step length and
step frequency. A review,” J. Sports Med. Phys. Fitness, vol. 34, no. 2,
pp. 109–134, 1994.
[6] M. M. Rodgers, “Dynamic foot biomechanics,” J. Orthop. Sports Phys.
Ther., vol. 21, no. 6, pp. 306–316, 1995.
[7] L. Wolfson et al., “Gait assessment in the elderly: A gait abnormality
rating,” J. Gerontol. A Med. Sci., vol. 45, no. 1, pp. M12–M19, 1990.
[8] K. O. Berg et al., “Clinical and laboratory measures of postural balance
in an elderly population,” Arch. Phys. Med. Rehabil., vol. 73, no. 11,
pp. 1073–1080, 1992.
[9] D. M. Wrisley and N. A. Kumar, “Functional gait assessment: Concurrent, discriminative, and predictive validity in community-dwelling older
adults,” Phys. Ther., vol. 90, no. 5, pp. 761–773, 2010.
[10] J. H. Patrick and M. A. E. Keenan, “Gait analysis to assist walking after
stroke,” Lancet, vol. 369, no. 9558, pp. 256–257, 2007.
[11] R. J. Orr and G. D. Abowd, “The smart floor: A mechanism for natural
user identification and tracking,” in Proc. Conf. Human Factors Comput.
Syst., 2000, pp. 275–276.

[12] M. S. Nixon et al., Human Identification Based on Gait. New York, NY,
USA: Springer, 2006.
[13] S. Studenski, “Bradypedia: Is gait speed ready for clinical use?,” J. Nutr.
Health Aging, vol. 13, no. 10, pp. 878–880, 2009.
[14] F. B. Horak et al., “The balance evaluation systems test (BESTest) to
differentiate balance deficits,” Phys. Ther., vol. 89, no. 5, pp. 484–498,
2009.
[15] D. H. Sutherland, “The evolution of clinical gait analysis part l: Kinesiological EMG,” Gait Posture, vol. 14, no. 1, pp. 61–70, 2001.
[16] W. Tao et al., “Gait analysis using wearable sensors,” Sensors, vol. 12,
no. 2, pp. 2255–2283, 2012.
[17] L. Lee and W. E. L. Grimson, “Gait analysis for recognition and classification,” in Proc. IEEE Int. Conf. Autom. Face Gesture Recog., 2002,
pp. 148–155.
[18] S. Sarkar et al., “The human ID gait challenge problem: Data sets, performance, and analysis,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 27,
no. 2, pp. 162–177, Feb. 2005.
[19] T. Teixeira et al., “PEM-ID: Identifying people by gait-matching using
cameras and wearable accelerometers,” in Proc. IEEE Int. Conf. Distributed Smart Cameras, 2009, pp. 1–8.
[20] J. Han and B. Bhanu, “Performance prediction for individual recognition by gait,” Pattern Recognition Letters, vol. 26, no. 5, pp. 615–624,
2005.
[21] H. Becker and W. Burgard, “Recognizing people based on their footsteps
using a wearable accelerometer,” in Proc. IEEE Int. Conf. Intell. Robot.
Syst., 2010, pp. 5404–5409.
[22] K. Mäkelä et al., “The use of walking sounds in supporting awareness,”
in Proc. Int. Conf. Auditory Display, 2003, pp. 144–147.
[23] D. Alpert and M. Allen, “Acoustic gait recognition on a staircase,” in
Proc. World Autom. Congr., 2010, pp. 1–6.
[24] M. Tanaka and H. Inoue, “A study on walk-recognition by frequency
analysis of footsteps,” Trans. IEE Japan, vol. 119-C, no. 6, pp. 762–763,
1999.
[25] J. T. Geiger et al., “Gait-based person identification by spectral, cepstral
and energy-related audio features,” in Proc. IEEE Int. Conf. Acoustics
Speech Signal Process., 2013, pp. 458–462.
[26] M. U. B. Altaf et al., “Perceptually motivated temporal modeling of
footsteps in a cross-environmental detection task,” in Proc. IEEE Int.
Conf. Acoustics Speech Signal Process., 2013, pp. 823–827.
[27] M. U. B. Altaf et al., “Person identification using biometric markers from
footsteps sound,” in Proc. INTERSPEECH, 2013, pp. 2934–2938.
[28] S. Fritz and M. Lusardi, “White paper: Walking speed: The sixth vital
sign,” J. Geriatr. Phys. Ther., vol. 32, pp. 2–5, 2009.
[29] P. W. Duncan et al., “Outcome measures in acute stroke trials a systematic
review and some recommendations to improve practice,” Stroke, vol. 31,
no. 6, pp. 1429–1438, 2000.
[30] M. K. Holden et al., “Clinical gait assessment in the neurologically
impaired reliability and meaningfulness,” Phys. Ther., vol. 64, pp. 35–40,
1984.
[31] M. Hofmann et al., “The TUM gait from audio, image and depth (GAID)
database: Multimodal recognition of subjects and traits,” J. Vis. Commun.
Image Represent., vol. 25, pp. 195–206, 2014.
[32] D. D. Rife and J. Vanderkooy, “Transfer-function measurement with
maximum-length sequences,” J. Audio Eng. Soc., vol. 37, pp. 419–444,
1989.
[33] P. Wittenburg et al., “ELAN: A professional framework for multimodality
research,” in Proc. Int. Conf. Language Resources Evaluation, 2006, pp.
1556–1559.
[34] L. Cohen, Time-Frequency Analysis. Englewood Cliffs, NJ, USA: Prentice
Hall, 1995.
[35] J. F. Kaiser, “On a simple algorithm to calculate the energy of a signal,” in Proc. IEEE Int. Conf. Acoustics Speech Signal Process., 1990,
pp. 381–384.
[36] J. H. Hollman et al., “Normative spatiotemporal gait parameters in older
adults,” Gait Posture, vol. 34, pp. 111–118, 2011.
[37] D. Sutherland, “The evolution of clinical gait analysis part III - Kinetics
and energy assessment,” Gait Posture, vol. 21, no. 4, pp. 447–461, 2005.
[38] M. J. Hessert et al., “Foot pressure distribution during walking in young
and old adults,” BMC Geriatrics, vol. 5, pp. 8-1–8-8, 2005.
[39] J. H. Hollman et al., “Does walking in a virtual environment induce
unstable gait?: An examination of vertical ground reaction forces,” Gait
Posture, vol. 26, pp. 289–294, 2007.
[40] J. O. Judge, “Gait disorders in the elderly,” in The Merck Manual of Diagnosis and Therapy. Boston, MA, USA: Merck Res. Lab.,
2011.

ALTAF et al.: ACOUSTIC GAITS: GAIT ANALYSIS WITH FOOTSTEP SOUNDS

M. Umair Bin Altaf received the M.S. degree in
electrical engineering from the Imperial College of
Science, Technology and Medicine, London, U.K.,
in 2006, and the M.S. degree in mathematics from
the Georgia Institute of Technology, Atlanta, GA,
USA, in 2010. He is currently working toward the
Ph.D. degree in electrical and computer engineering
at Georgia Tech, Atlanta.
He has been with Avaya Labs and Broadcom Inc.
as a Research Intern, working on robust speech recognition and speech coding. His research interests lie in
the general area of audio signal processing with special focus on speech recognition, machine learning, and environmental sound representation.

Taras Butko received the M.S. degree in computer
science from Dnipropetrovsk National University,
Dnipropetrovsk, Ukraine, in 2006, and the Ph.D. degree in signal theory and communications from the
Technical University of Catalonia, Barcelona, Spain,
in 2012.
He has been with the School of Electrical and
Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA, working on acoustic intelligence. He is currently working as CEO at Elian LLC
creating software for desktops and mobile devices.
His research interests lie in the general area of audio signal processing, acoustic
event detection and machine learning.

2011

Biing-Hwang (Fred) Juang (F’91) received the
Ph.D. degree from the University of California, Santa
Barbara, CA, USA.
He is the Motorola Foundation Chair Professor
and a Georgia Research Alliance Eminent Scholar at
Georgia Institute of Technology, Atlanta, GA, USA.
He is also enlisted as Honorary Chair Professor at
several renowned universities. He had conducted research work at Speech Communications Research
Laboratory and Signal Technology, Inc., in the late
1970s on a number of government-sponsored research projects and at Bell Labs during the 80s and 90s until he joined Georgia
Tech in 2002. His notable accomplishments include development of vector quantization for voice applications, voice coders at extremely low bit rates (800 and
300 b/s), robust vocoders for satellite communications, fundamental algorithms
in signal modeling for automatic speech recognition, mixture hidden Markov
models, discriminative methods in pattern recognition and machine learning,
stereo- and multiphonic teleconferencing, and a number of voice-enabled interactive communication services. He was Director of Acoustics and Speech
Research at Bell Labs (1996–2001), and Director of Multimedia Technologies
Research at Avaya Labs (a spin-off of Bell Labs) in 2001. He has published
extensively, and holds nearly two dozen patents.
Dr. Juang received the Technical Achievement Award from the IEEE Signal
Processing Society in 1998 for contributions to the field of speech processing
and communications and the Third Millennium Medal from the IEEE in 2000.
He also received two Best Senior Paper Awards, in 1993 and 1994, respectively,
and a Best Paper Award in 1994, from the IEEE Signal Processing Society. He
was elected a Bell Labs Fellow (1999), a Member of the US National Academy
of Engineering (2004), and an Academician of the Academia Sinica (2006). He
was named recipient of the IEEE Field Award in Audio, Speech and Acoustics,
the J. L. Flanagan Medal, and a Charter Fellow of the National Academy of
Inventors, in 2014.

