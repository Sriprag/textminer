IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 4, APRIL 2014

1027

Noninvasive Diabetes Mellitus Detection Using
Facial Block Color With a Sparse
Representation Classifier
Bob Zhang∗ , Member, IEEE, B. V. K. Vijaya kumar, Fellow, IEEE, and David Zhang, Fellow, IEEE

Abstract—Diabetes mellitus (DM) is gradually becoming an epidemic, affecting almost every single country. This has placed a
tremendous amount of burden on governments and healthcare officials. In this paper, we propose a new noninvasive method to detect
DM based on facial block color features with a sparse representation classifier (SRC). A noninvasive capture device with image
correction is initially used to capture a facial image consisting of
four facial blocks strategically placed around the face. Six centroids from a facial color gamut are applied to calculate the facial
color features of each block. This means that a given facial block
can be represented by its facial color features. For SRC, two subdictionaries, a Healthy facial color features subdictionary and DM
facial color features subdictionary, are employed in the SRC process. Experimental results are shown for a dataset consisting of 142
Healthy and 284 DM samples. Using a combination of the facial
blocks, the SRC can distinguish Healthy and DM classes with an
average accuracy of 97.54%.
Index Terms—Color feature, diabetes mellitus (DM), facial
block, facial color gamut, sparse representation classifier (SRC).

I. INTRODUCTION
N the year 2000, World Health Organization estimated that
there were 171 million people worldwide with diabetes mellitus (DM). This number is set to increase to 366 million by
2030 [1] making the disease among the leading causes of disabilities, death, and economic hardship in the world. There are
two main types of DM: Type 1 DM and Type 2 DM. People
with Type 1 DM fail to produce insulin, and therefore require
injections of it. Type 2 DM can be categorized by insulin resistance and is the most common type. Currently, there is no cure
for Type 1 DM or Type 2 DM.

I

Manuscript received October 27, 2012; revised November 12, 2013; accepted
November 14, 2013. Date of current version March 17, 2014. The work was
supported in part by the GRF fund from the HKSAR Government, the central
fund from Hong Kong Polytechnic University, and the NSFC Oversea fund
(61020106004), China. Asterisk indicates corresponding author.
∗ B. Zhang is with the Department of Computer and Information Science,
University of Macau, Taipa, Macau (e-mail: bobzhang@umac.mo).
B. V. K. Vijaya Kumar is with the Department of Electrical and Computer
Engineering, Carnegie Mellon University, Pittsburgh, PA 15213 USA (e-mail:
kumar@ece.cmu.edu).
D. Zhang is with the Department of Computing, Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong (e-mail: csdzhang@
comp.polyu.edu.hk).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2013.2292936

A fasting plasma glucose (FPG) test is the standard method
practiced by many medical professionals to diagnose DM. The
FPG test is performed after the patient has gone at least 12 h
without food, and requires taking a sample of the patient’s blood
(by piercing their finger) in order to analyze its blood glucose
levels. Even though this method is accurate, it can be considered
invasive, and slightly painful (piercing process). Therefore, there
is a need to develop a noninvasive yet accurate detection method.
To this end, this paper addresses the aforementioned problems and proposes a noninvasive method to detect DM by distinguishing Healthy and DM samples (using facial block color
features) via a sparse representation classifier (SRC) [2]. Traditional medicines use facial diagnosis [3]–[6]. In Traditional
Chinese Medicine (TCM) [3]–[6], for example, the belief is
that the cause, symptoms, and the origin of the disease can be
reflected on the face through color changes. However, the diagnostic result given by the practitioner based on years of experience can be thought of as subjective or qualitative. To eliminate
this bias, computerized facial diagnosis based on quantitative
feature extraction and analysis can be established.
Facial images are first captured using a especially designed
noninvasive device, and calibrated to ensure consistency in feature extraction and analysis. Four facial blocks, one on the forehead and nose, and two below the left and right eyes are extracted
automatically and used to represent a face. A facial color gamut
is constructed with six color centroids (representing the most
common facial colors, more detail can be found in Section III)
in order to compute a facial color feature vector, characterizing
each facial block. Experimental results are obtained for a dataset
consisting of 142 Healthy samples taken from the Guangdong
Provincial Hospital of TCM, Guangdong, China, and 284 DM
samples processed from the Hong Kong Foundation for Research and Development in Diabetes, Prince of Wales Hospital,
Hong Kong SAR. A comparison was made between the color
features of the two classes, and classification was performed
between Healthy and DM using a combination of facial blocks
and SRC. The principle of SRC is to represent a test sample as
a linear combination of the training samples, or a dictionary of
atoms from the training samples. By requiring that the representation coefficients are as sparse as possible, only the coefficients
associated with the samples from the same class as the testing
sample will be large, and hence, the class label of the testing
sample can be identified.
The rest of this paper is organized as follows. Section II discusses the facial image acquisition device, facial block definition, and dataset used. In Section III, facial block color feature

0018-9294 © 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

1028

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 4, APRIL 2014

Fig. 2.

Fig. 1. Facial image acquisition device. (a) Viewing geometry and imaging
path of the facial imaging device. (b) Appearance of the device and the system
interface.

extraction is described in detail, with SRC presented in the
subsequent section by first explaining its theory, followed by
its application to Healthy versus DM classification. Section IV
presents the experimental results, after which concluding remarks are made in Section V.
II. FACIAL IMAGES AND DATASET
In the following, a facial image acquisition device is described
in Section II-A, along with image calibration to ensure consistency. Afterward, facial image block definition is discussed in
Section II-B, succeeded by an introduction of the facial image
dataset (Section II-C).
A. Facial Image Acquisition Device
The primary issue with automatic facial diagnosis is image
capturing and its representation. Facial images from various
health statuses must be captured and depicted in an accurate
way under a standardized setting in order to ensure unbiased
feature extraction and analysis. To resolve this issue, a especially designed facial image capture device with calibration is
developed. The main component of this device is a SONY 3CCD video camera, which is a high-end industrial camera able
to acquire 25 images/s. The size of each image is 640 × 480
pixels. Fig. 1(a) illustrates the schematic diagram of the viewing
angle and imaging path. With the camera placed in the center
of the device, two fluorescent lamps are situated on either sides

Location of Blocks A, B, C, and D on a facial image.

of the camera. The angle between the incident light and emergent light is 45◦ , recommended by Commission Internationale
de l’Eclairage (CIE) [7]. Fig. 1(b) shows this capture device,
which also provides a chin rest for the patient to position their
face (with the 3-CCD video camera calibrated to record this).
In order to portray the color images in a precise way so as
to facilitate quantitative analysis, a color correction procedure
is performed before feature extraction and classification. This
eliminates any variability in color images caused by variations of
illumination and device dependence, allowing images taken in a
variety of environments to be compared to each other. To correct
the facial images, an algorithm developed by Wang and Zhang
[8] was applied and adapted from its original use in tongue
images. A polynomial-based regression method was utilized to
train the correction model based on the corresponding values
of a reference training set, obtained using the Munsell Color
Checker in the device. Using this correction model, uncorrected
facial images can be corrected, and rendered to be in standard
RGB (sRGB) color space.
B. Facial Block Definition
According to TCM theory, the human face can be partitioned
into several regions [3], [4], where different regions can reflect
the health status of internal organs. From each captured image,
four blocks (A, B, C, and D) of size 64 × 64 strategically
located around the face are extracted (automatically) to better
characterize a facial image (see Fig. 2). As long as the blocks
are located in the regions, analysis can be performed [3], [4]. If a
patient is positioned further away from the capture device, both
the camera and block size will require recalibration. Binarization
is first applied to each image, where morphological operations
are used to locate the pupils. From there, the distance between
the pupils is used to map out the blocks. Block A is located
on the forehead. Blocks B and D are symmetrical and found
below the left and right eyes, respectively. Finally, Block C is
situated on the nose, B and D’s midpoint. For completeness, a
block was not extracted under the lower lip on the chin due to
the fact that this area may be obscured by facial hair.

ZHANG et al.: NONINVASIVE DIABETES MELLITUS DETECTION USING FACIAL BLOCK COLOR WITH A SRC

1029

Fig. 4. Facial color gamut (located within the black boundary) with its six
centroids marked by red crosses.

Fig. 3.

Typical Healthy (top) and DM (bottom) facial block samples.

C. Facial Image Dataset
The facial image database comprises 426 images split into
142 Healthy images captured at the Guangdong Provincial TCM
Hospital, Guangdong, in late 2011, and 284 DM images taken
from the Hong Kong Foundation for Research and Development
in Diabetes, Prince of Wales Hospital, Hong Kong SAR, in mid2012. Healthy samples were verified through a blood test and
other examinations. If indicators from these tests fall within a
certain range, they were deemed healthy. In the DM class, the
FPG test was used to diagnose diabetes at the time of their visit.
For the 284 DM patients, the average was 7.3 mmol/L, while
having lived with the disease for an average of seven years.
Fig. 3 illustrates three typical Healthy and DM samples, where
each sample is represented by its A–D facial blocks.

III. FACIAL BLOCK COLOR FEATURE EXTRACTION
Facial block color feature extraction is described in this section. First, color feature extraction using the facial color gamut
is presented, and preceded by six centroids representing main
colors of the facial blocks. The six centroids are then used to
calculate a facial color feature vector for each block.

The distribution of facial block colors in the form of a facial
color gamut and typical color centroids is important in facial
block analysis. The facial color gamut shows the range of facial block colors. Each pixel in the facial block is extracted and
combined to form the facial block color distribution in the CIE
xy chromaticity diagram [9] (see Fig. 4). The black boundary in
Fig. 4 encloses all facial block pixel intensities from the established dataset as well as 1038 disease samples (from Guangdong
Provincial TCM Hospital). To better represent this distribution,
six color centroids are selected (red crosses marked in Fig. 4).
The six centroids characterize the most commonly found colors
in the facial block (since it is within the black boundary) and
are spread out to ensure that two or more colors do not overlap. This is more resourceful than using the entire distribution
which would make color feature extraction computationally inefficient. The idea of the six color centroids is derived from the
principle of facial diagnosis in TCM, in which main color types
are commonly extracted from a set of color categories, and utilized as an important feature for disease diagnosis. The bottom
of Fig. 4 depicts the six centroids from the facial color gamut
as a solid color square with its label on top and correspondingly
RGB value below. These six centroids are red, yellow, light
yellow, gloss, deep red, and black.
Given a facial block, its RGB pixels values are first extracted
and converted to CIELAB [10] by translating RBG to CIEXYZ
using
⎡ ⎤ ⎡
⎤⎡ ⎤
X
0.4124 0.3576 0.1805
R
⎢ ⎥ ⎢
⎥⎢ ⎥
Y
=
0.2126
0.7152
0.0722
G
(1)
⎣ ⎦ ⎣
⎦⎣ ⎦
Z

0.0193

0.1192

0.9505

B

1030

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 4, APRIL 2014

TABLE I
COMPARISON OF COLOR FEATURES BETWEEN EACH BLOCK

Fig. 5. Healthy facial block sample, its facial color feature vector, and corresponding six color makeup with most of the pixels classified as GL.

Fig. 6. DM facial block sample, its facial color feature vector, and corresponding six color makeup with most of the pixels classified as R.

followed by CIEXYZ to CIELAB by
⎧ ∗
⎪
⎨ L = 166f (Y /Y0 ) − 16
a∗ = 500 [f (X/X0 ) − f (Y /Y0 )]
⎪
⎩ ∗
b = 200 [f (Y /Y0 ) − f (Z/Z0 )]

(2)

where f (x) = x1/3 if x > 0.008856 or f (x) = 7.787x +
16/116 if x ≤ 0.008856.
In (2), X0 , Y0 , and Z0 are the CXYZ tristimulus values of
the reference white point. The CIELAB values are then compared to six centroids from the facial color gamut (see Fig. 4)
and assigned the color which is closest to it (measured using
Euclidean distance). After evaluating all the pixels of a facial
block, the total of each color (based on the six centroids) is
summed and divided by the total number of pixels (in a facial
block). This ratio forms the facial color feature vector v, where
v = [c1 , c2 , c3 , c4 , c5 , c6 ] and ci represents the sequence of the
six centroids in Fig. 4. As an example, the color features of
two facial blocks from A are shown in Figs. 5 and 6 along with
its extracted color feature vector, where the original block is
decomposed into one of six centroids. Fig. 5 shows a Healthy
sample while Fig. 6 shows DM. In the Healthy sample, the
majority of pixels are GL and for DM it is R.
By comparing the four facial color feature vectors (per facial
image) in groups of two (using all images in the dataset), and
calculating the mean absolute difference of each group, Blocks
B and D are shown to have the smallest difference. This can
be seen from Table I where the mean absolute difference of
B–D is smaller than others. The result makes sense given Blocks
B and D are symmetrical, located on either side of the face.
In the following experiments, Block D is removed due to its
resemblance to B.

TABLE II
BLOCKS A, B, AND C COLOR FEATURE MEAN FOR HEALTHY AND DM

The mean color feature vectors of three blocks (A, B, and C)
for Healthy and DM are shown in Table II (A/B/C). In Block A,
R, Y, DR, and BK are the highest in DM, while LY and GL are
greater in Healthy. As for Block B, Healthy samples have higher
values in R, LY, and GL, whereas Y, DR, and BK are bigger in
DM. In Block C, the first four colors have a greater percentage
in Healthy compared to DM, and the last two colors of DR and
BK have higher percentages in DM.
IV. HEALTHY VERSUS DM CLASSIFICATION WITH AN SRC
Once the facial color feature vectors are extracted from the
facial blocks, they are classified using the SRC. The theory of
SRC is first introduced in this section. Afterward, a discussion
is given on how the SRC can be applied to separate Healthy and
DM samples.
Given a test sample and a set of training samples, the idea
of SRC is to represent the test sample as a linear combination
of the training samples, while requiring that the representation
coefficients are as sparse as possible. If the test sample is from
class i, then among its representation coefficients over all the
training samples, only those from the samples in class i will
be significant while others will be insignificant, and hence, the
class label of the test sample can be determined. In practice,
the l1 -norm minimization is used to solve the sparsest linear
representation of the test sample over the training samples. More
information about the SRC can be found in [2].
Denote by Ai = [si,1 , si,2 , . . . , si,n i ] ∈ Rm ×n i the set of
training samples of the ith object class, where m is the dimensionality of the object and ni is the number of training
samples of the ith class. For a test sample y ∈ Rm from the
same class, y could be approximated 
by a linear combination
i
αi,j si,j = Ai αi ,
of the samples within Ai , i.e., y = nj =1
T
ni
where αi = [αi,1 , αi,2 , . . . , αi,n i ] ∈ R are the representation coefficients. Suppose that we have C object classes, and let
Ai = [A1 , A2 , . . . , AC ] be the concatenation of the n training
samples from all the C classes, where n = n1 + n2 + · · · + nC .
In the ideal case, the linear representation of y in terms of A

ZHANG et al.: NONINVASIVE DIABETES MELLITUS DETECTION USING FACIAL BLOCK COLOR WITH A SRC

1031

can be written as y = Aα, where α = [α1 , α2 , . . . , αC ] =
[0, . . . , 0, αi,1 , αi,2 , . . . αi,n i , 0, . . . , 0]T is a vector of coefficients whose entries are all zeros except those associated with
the ith class. To solve this, ideally, we want to use l0 -norm
minimization. However, in practice, l0 -norm nonconvex optimization is difficult. Therefore, we use l1 -norm minimization:


α̂ = arg min y − Aα22 + λα1
(3)
α

where λ is a positive scalar, and we can obtain the real sparse
coding vector α̂ of y over A.
Denote by δi (·) : Rn → Rn the characteristic function which
selects only the sparse coding coefficients associated with the
class i. By reconstructing the object as Aδi (α̂), we can compute
the reconstruction error associated with each class as
ri (y) = y − Aδi (α̂) 22 .

i

block, we can see that its rH > rD M , which means that y is a
DM sample.

(4)

If y belongs to the ith class, we can expect that ri (y) should
be minimum among all ri (y) , i = 1, 2, . . . , C. Therefore, the
classification is achieved by letting
identity (y) = arg min ri (y).

Fig. 7. Example of Healthy versus DM classification using the SRC. The left
Block A is classified as a Healthy sample due to the fact that rH ≤ rD M , while
the right Block A is designated a DM sample since rH > rD M .

(5)

Healthy versus DM classification is essentially a two-class
classification problem. Therefore, we can use two subfacial
color features dictionaries for SRC: the Healthy facial color
features subdictionary and the DM facial color features subdictionary. Let Γ = [γ 1 , γ 2 , . . . , γ h ] represent the Healthy facial color features subdictionary and Δ = [δ 1 , δ 2 , . . . , δ dm ]
be the DM facial color features subdictionary, where γ i , i =
1, 2, . . . , h, and δ j , j = 1, 2, . . . , dm, are single column vectors containing the facial color feature vector(s) of a Healthy or
DM sample. The columns of Γ and Δ are normalized to have
unit l2 -norm. The two subfacial color features dictionaries are
then combined to form color features dictionary D = [Γ, Δ].
For each facial block(s) color feature vector denoted by y, we
can use D to represent it by solving the l1 -norm minimization
problem using (3), by replacing A with D. Since D = [Γ, Δ],
we let α = [αΓ , αΔ ] (from the result of (3)), where αΓ is the
representation of y over Γ and αΔ is the representation of y
over Δ.
Using Γ and the associated coefficients αΓ to reconstruct y,
the reconstruction error will be rH (y) = y − ΓαΓ 22 , and if
we use Δ and αΔ to reconstruct y, the reconstruction error will
be rDM (y) = y − ΔαΔ 22 . Intuitively, if the candidate object
y is a Healthy sample, it could be well represented by Γ so that
the error rH will be small. If y is a DM sample, rH will be large,
while the reconstruction error rD M will be small. Therefore, the
magnitudes of rH and rD M can reflect the membership of y.
We use the following rule to classify y:

y is a Healthy sample if rH ≤ rDM
(6)
y is a DM sample
if rH > rDM .
Fig. 7 depicts an example of Healthy versus DM classification
using the SRC. Two unknown Block As are represented by
their corresponding y. rH (y) of the left block is calculated to
be 0.2191, while its rDM (y) is 2.4495. Since rH ≤ rD M , it
follows from (6) that y is a Healthy sample. Shifting to the right

V. EXPERIMENTAL RESULTS
The experimental results were obtained for the facial image
dataset described in Section II-C. Half the images were randomly assigned as training, and the other half used as testing.
This means that the number of dictionary atoms in Γ is 71 (h),
while in Δ it is 142 (dm). Average accuracy defined in (7) was
the performance metric used to evaluate the classification result
of Healthy versus DM
Average Accuracy
=

True Pos. + True Neg.
.
True Pos. + False Pos. + True Neg. + False Neg.

(7)

In order to achieve the optimal result using facial blocks A, B,
and C, all combinations of blocks were tested. Altogether there
were seven combinations (without repeating): A, B, C, AB, AC,
BC, and ABC. This means that the size of each single column
vector in D and y ranges from 6 × 1 for a single block, to 12 × 1
for two blocks, and 18 × 1 for all three blocks.
The sparse coding (3) contains a positive scalar parameter λ.
In the experimental results, various λ values were tested along
with the block combinations. Table III displays this result. The
highest average accuracy of 97.54% (highlighted) was achieved
using Block A with λ = 8, 9, and 10, and Blocks ABC with
λ = 7, 8, 9, 10, 11, 12, and 13. Since Block A and Blocks
ABC achieve the same average accuracy, Block A with λ = 8
is chosen as the final result due to the computational cost of
using Blocks ABC. Sensitivity and specificity values have been
calculated for the highest average accuracies of the seven block
combinations (see Table IV).
To be thorough, comparisons were made with traditional classifiers [11] using the same experimental setup described earlier,
where facial block color features are used. The results of k-NN
and support vector machine (SVM) using the kernel function
(dot product) to map the training data into kernel space are
shown in Table V. The best outcome of k-NN is 92.96% with
Blocks AB, while an average accuracy of 94.72% was attained
through Blocks AC by applying SVM. A bar chart showing the
highest average accuracy of all three methods is displayed in
Fig. 8, where the red bar of SRC is the highest.

1032

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 61, NO. 4, APRIL 2014

TABLE III
AVERAGE ACCURACY OF SEVEN FACIAL BLOCK COMBINATIONS WITH VARIOUS λ VALUES

TABLE IV
SENSITIVITY AND SPECIFICITY VALUES OF THE PROPOSED METHOD FOR THE HIGHEST AVERAGE ACCURACIES OF THE SEVEN BLOCK COMBINATIONS

TABLE V
AVERAGE ACCURACY OF TRADITIONAL CLASSIFIERS k-NN AND SVM

Fig. 9.

Fig. 8. Comparison of the best classification methods using average accuracy.
SRC shown as the red bar achieves the best result.

VI. DISCUSSION
Guangdong Provincial Hospital of TCM where Healthy samples were collected is located in Guangzhou, China, while DM
samples were taken at the Hong Kong Foundation for Research
and Development in Diabetes, Prince of Wales Hospital, Hong
Kong. Both locations adhering to the same international standards are situated approximately 115 km apart. A majority of the

Two facial blocks not easily distinguishable to the naked eye.

Hong Kong population are descendents of those from Guangdong. They share similar diets and a common language in Cantonese. We collected a high concentration of pure samples from
the Hong Kong Foundation for Research and Development in
Diabetes due to their expertise in DM research. The same can
be said for the Guangdong Provincial Hospital of TCM, where
a body checking station was installed. At the same time, both
locations used the same capture device taking into account color
correction. This justifies why Healthy and DM samples taken at
different locations can still be compared with one another.
In Fig. 3, typical Healthy and DM samples are illustrated.
Even though these facial blocks look distinguishable to the human eye, there exist samples in our database (refer to Fig. 9)
where the difference is not so obvious (to the naked eye), and
our proposed method still managed to separate each correctly.

ZHANG et al.: NONINVASIVE DIABETES MELLITUS DETECTION USING FACIAL BLOCK COLOR WITH A SRC

1033

With regard to the standardization of the proposed method,
we can report that all aspects are standardized. We start with
the capture device (designed in-house) which takes into consideration color correction. This means that images taken under
different environments can be compared equally as is the case
with our Healthy and DM samples. Development of the facial
color gamut is another example of standardization, allowing a
facial block to be represented by its color feature vector v. Using
recognized statistical pattern recognition techniques such as the
SRC, v for Healthy and DM can be separated with an average
accuracy of 97.54%.

Bob Zhang (M’12) received the B.A. degree in computer science from York University, Toronto, ON,
Canada, in 2006, the M.A.Sc. degree in information
systems security from Concordia University, Portland, OR, USA, in 2007, and the Ph.D. degree in
electrical and computer engineering from the University of Waterloo, Waterloo, ON, Canada, in 2011.
After graduating from Waterloo, he remained with
the Center for Pattern Recognition and Machine Intelligence, and later was a Postdoctoral Researcher
in the Department of Electrical and Computer Engineering, Carnegie Mellon University. He is currently an Assistant Professor in
the Department of Computer and Information Science, University of Macau,
Taipa, Macau, China. His research interests focus on medical biometrics, pattern recognition, and image processing.

VII. CONCLUSION

B. V. K. Vijaya Kumar (F’10) received the B.Tech.
and M.Tech. degrees in electrical engineer-ing from
the Indian Institute of Technology, Kanpur, India,
and the Ph.D. degree in electrical engineering from
Carnegie Mellon University (CMU), Pittsburgh, PA,
USA.
Since 1982, he has been a Faculty Member in the
Department of Electrical and Computer Engineering
(ECE), CMU, where he is currently a Professor and
the Associate Dean for Graduate and Faculty Affairs
for the College of Engineering. He served as the Associate Department Head of the ECE Department from 1994 to 1996 and as
the Acting Head of the Department during 2004–2005. His publications include
the book entitled Correlation Pattern Recognition (coauthored with Dr. Abhijit
Mahalanobis and Dr. Richard Juday, Cambridge, U.K.: Cambridge University
Press, November 2005), 20 book chapters, 370 conference papers, and 180
journal papers. He is also a Co-Inventor of eight patents. His research interests
include computer vision and pattern recognition algorithms and applications
and coding and signal processing for data storage systems.
Dr. Vijaya Kumar served as a Pattern Recognition Topical Editor for the
Information Processing division of Applied Optics and as an Associate Editor
for IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY. He has
served on many conference program committees and was a Co-General Chair
of the 2005 IEEE AutoID Workshop, a Co-Chair of the 2008–2010 SPIE conferences on Biometric Technology for Human Identification, and a Co-Program
Chair of the 2012 IEEE Biometrics: Theory, Applications and Systems (BTAS)
conference. He is a Fellow of SPIE, Optical Society of America, and International Association of Pattern Recognition. In 2003, he received the Eta Kappa
Nu Award for Excellence in Teaching in the ECE Department at CMU and the
Carnegie Institute of Technology’s Dowd Fellowship for educational contributions and he was a Co-Recipient of the 2008 Outstanding Faculty Research
Award in CMU’s College of Engineering.

This paper proposed a noninvasive approach to classify
Healthy and DM samples using facial color features extracted
from facial blocks via the SRC. A facial color gamut was first
applied such that each facial block is represented by six colors.
SRC with two subdictionaries, one characterizing Healthy facial
color features and the other DM facial color features, was applied along with various λ values for sparse coding. Given a test
sample, its smallest reconstruction error calculated either from
Healthy or DM determines its class membership. By evaluating
a combination of seven different facial block groupings (from
three blocks) and various λ values, the highest average accuracy
of 97.54% was attained from Block A with λ equal to 8. This
outperforms the traditional classifiers of k-NN and SVM, and
potentially provides a new way to detect DM, one which does not
inflict any harm or induce any pain. As part of our future work,
more Healthy and DM samples will be collected in order to
further validate the statistical accuracy of the proposed method.
ACKNOWLEDGMENT
The authors would like to thank Xingzheng Wang for his help
in the data collection.
REFERENCES
[1] Prevention of Blindness From Diabetes Mellitus, World Health Organization, Geneva, Switzerland, 2006.
[2] J. Wright, A. Yang, A. Ganesh, S. Sastry, and Y. Ma, “Robust face recognition via sparse representation,” IEEE Trans. Pattern Anal. Mach. Intell.,
vol. 31, no. 2, pp. 210–227, Feb. 2009.
[3] G. Maciocia, The Foundations of Chinese Medicine. London, U.K.:
Churchill Livingstone, 1989.
[4] M. Porkert, Theoretical Foundations of Chinese Medicine: Systems of
Correspondence. Cambridge, MA, USA: MIT Press, 1978.
[5] L. Bridges, Face Reading in Chinese Medicine. London, U.K.: Churchill
Livingstone, 2004.
[6] B. Liu and T. Wang, Inspection of Face and Body for Diagnosis of Diseases. Beijing, China: Foreign Languages Press, 2002.
[7] I. G. Wyszecki and W. S. Stiles, Color Science: Concepts and Methods,
Quantitative Data, and Formulae. New York, NY, USA: Wiley, 2000.
[8] X. Wang and D. Zhang, “An optimized tongue image color correction
scheme,” IEEE Trans. Inf. Technol. Biomed., vol. 14, no. 6, pp. 1355–
1364, Nov. 2010.
[9] M. D. Fairchild, Color Appearance Models. New York, NY, USA: Wiley, 2006.
[10] M. Strokes, M. Anderson, S. Chandrasekar, and R. Motta, “A standard default color space for the internet-sRGB,”. (1996). Microsoft and HewlettPackard Joint Report, 1996.
[11] R. O. Duda, P. E. Hart, and D. G. Stork, Pattern Classification, 2nd ed.
New York, NY, USA: Wiley-Interscience, 2000.

David Zhang (M’89–SM’95–F’08) received the
Graduation degree in computer science from Peking
University, Beijing, China, the M.Sc. degree in computer science in 1982, and the Ph.D. degree in
1985 from the Harbin Institute of Technology (HIT),
Harbin, China. In 1994, he received the second Ph.D.
degree in electrical and computer engineering from
the University of Waterloo, Waterloo, ON, Canada.
From 1986 to 1988, he was a Postdoctoral Fellow
at Tsinghua University and then an Associate Professor at the Academia Sinica, Beijing. He is currently
a Chair Professor at the Hong Kong Polytechnic University, Kowloon, Hong
Kong, where he is the Founding Director of the Biometrics Technology Centre
(UGC/CRC) supported by the Hong Kong SAR Government in 1998. He also
serves as a Visiting Chair Professor in Tsinghua University, and an Adjunct
Professor in Peking University, Shanghai Jiao Tong University, HIT, and the
University of Waterloo. He is the author of more than 10 books and 250 journal
papers.
Dr. Zhang is the Founder and Editor-in-Chief of International Journal of
Image and Graphics, a Book Editor of Springer International Series on Biometrics (KISB), an Organizer of the International Conference on Biometrics
Authentication, and an Associate Editor of more than ten international journals
including IEEE TRANSACTIONS AND PATTERN RECOGNITION. He is a Croucher
Senior Research Fellow, Distinguished Speaker of the IEEE Computer Society,
and a Fellow of International Association of Pattern Recognition.

