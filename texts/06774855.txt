IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

1525

Logic-Centered Architecture for Ubiquitous
Health Monitoring
Jacek Lewandowski, Member, IEEE, Hisbel E. Arochena, Member, IEEE,
Raouf N. G. Naguib, Senior Member, IEEE, Kuo-Ming Chao, Member, IEEE, and Alexeis Garcia-Perez

Abstract—One of the key points to maintain and boost research
and development in the area of smart wearable systems (SWS) is
the development of integrated architectures for intelligent services,
as well as wearable systems and devices for health and wellness
management. This paper presents such a generic architecture for
multiparametric, intelligent and ubiquitous wireless sensing platforms. It is a transparent, smartphone-based sensing framework
with customizable wireless interfaces and plug‘n’play capability to
easily interconnect third party sensor devices. It caters to wireless
body, personal, and near-me area networks. A pivotal part of the
platform is the integrated inference engine/runtime environment
that allows the mobile device to serve as a user-adaptable personal
health assistant. The novelty of this system lays in a rapid visual
development and remote deployment model. The complementary
visual Inference Engine Editor that comes with the package enables
artificial intelligence specialists, alongside with medical experts, to
build data processing models by assembling different components
and instantly deploying them (remotely) on patient mobile devices.
In this paper, the new logic-centered software architecture for ubiquitous health monitoring applications is described, followed by a
discussion as to how it helps to shift focus from software and hardware development, to medical and health process-centered design
of new SWS applications.
Index Terms—Artificial intelligence (AI), body sensor networks,
remote monitoring, telemedicine, ubiquitous computing.

I. INTRODUCTION
CCORDING to a recent report published by the World
Health Organization [1], well-developed countries are expected to face major challenges in the way current health care
services are deployed and delivered. This is due mainly to: 1) an
ageing population; 2) increased life expectancy; and 3) population growth. The United Nations report [2] states that this trend
is global and over 60 years old are expected to account for 32%
of the population by year 2050. These factors will have a significant impact on the high-rising costs of healthcare liabilities
which will eventually outpace the growth of the overall economy. In response to this, we need a more accurate, pre-hospital
and prevention-oriented health care system, which will take care
of a person’s health status at earliest stage, through his/her phys-

A

Manuscript received December 1, 2013; revised February 15, 2014; accepted
March 8, 2014. Date of publication March 18, 2014; date of current version
September 2, 2014.
The authors are with the Faculty of Engineering and Computing, Coventry
University, Coventry CV1 5FB, U.K. (e-mail: jacek.lewandowski@coventry.
ac.uk; h.arochena@ieee.org; r.naguib@ieee.org; k.chao@coventry.ac.uk;
alexeis.garcia-perez@coventry.ac.uk).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2312352

ical activity management, status monitoring and assessment, as
well as early notification in case of an emergency.
One of the possible contributing solutions to these problems
could be the implementation of an accurate and ubiquitous
health monitoring of individuals by means of smart wearable
systems (SWSs). SWSs are defined as end-to-end, sensor-based
integrated systems, capable of sensing, processing, and communicating medical data to interested parties, such as the medical
professionals and emergency services, or store it for further reference. It contends to be the next-generation e-health systems,
delivering patient-oriented services with the vision of empowered health care on the move [3].
In this paper, a new logic-centered software architecture for
ubiquitous health monitoring applications based on our previous research into service selection [4] and context-aware ubiquitous computing [5] is proposed. It consists of a transparent,
smartphone-based sensing framework with customizable wireless interfaces and plug‘n’play capability to easily interconnect
third party sensor devices in body area network (BAN), personal area network (PAN), and near-me area network (NAN).
A pivotal part of the platform is the integrated inference engine/runtime environment that allows the mobile device to serve
as a user-adaptable personal health assistant (PHA). The novelty
of this system lays on a rapid visual development and remote deployment model. The complementary visual Inference Engine
Editor enables machine learning experts along with medical experts to build data processing models by interlacing together
different components and controlling the application logic with
scripts. The editor allows the instant deployment of such models
remotely on patient mobile devices. This approach shifts focus
from complex software and hardware development, to simple
medical and health process design, what helps to speed up development and deployment of m-health applications.
In the following two sections, the challenges in SWS adoption
as well as state of the art in the field are discussed. Section IV
is dedicated to the formulation of use cases and system requirements, while Section V describes the system architecture. In
Section VI, the proposed software design is presented. The inference engine, the complementary editor as well as the development and deployment model that they promote are presented in
Section VII. Section VIII provides conclusions and future work.
II. CHALLENGES IN SWS ADOPTION
Wireless medical telemetry is not a new concept, yet its adoption is minimal in nearly every country. Chan et al. [6] summarized issues preventing the wider acceptance of current SWSs
as, amongst others:

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

1526

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

1) lack of systems’ efficiency, reliability, and unobtrusiveness [7], [8],
2) complexity of system development and validation [9],
3) lack of unified multiplatform telemedicine solution for the
mobile and desktop operating systems [10],
4) not clear requirements from health care professionals and
end-users [6],
5) cost [11],
6) services availability and interoperability issues [12].
As a means to maintain and boost SWS research and development, many researchers [9], [13], [14] identified a development
of integrated architectures for intelligent home services with
wearable systems and devices for home comfort, health and
wellness. They concluded that there was currently no SWS in
the market integrating several biosensors, intelligent processing
and alerts to support medical applications. Such a state of affairs is due to the lack of end-to-end interoperability standards
within the sensor networks and also between SWS and disparate healthcare systems. This prevents seamless medical data
collection, increases the cost of the systems and their upgrade
capabilities, and also limits the shift to systems that are semantically interoperable, process-related, decision-supportive,
context-sensitive, user oriented, and trustworthy [15].
III. RELATED WORKS
A variety of wireless personal vital signs monitors, both for
medical and fitness purposes, are either already in the market,
or under development at prototype stage. A full list of wearable
systems developed in recent years along with a brief description
of their applications can be found in [6]. A vast number of
those projects focused on on-body sensing technologies through
integration of micro–nanotechnologies and flexible systems in
textile material. They aimed at the implementation of the “etextile” paradigm, where sensing, actuating, communicating,
processing, and power sourcing are seamlessly integrated on a
textile.
Whereas sensors and actuators are essential to promote SWS
adoption amongst the population, they are only means of data
collection. The true benefits of health monitoring systems come
with data processing and integration. The early systems were
generally designed to “cut the cord” between the patient and
the medical professionals, providing mainly only instantaneous
single-parameter assessment and transmission. Hence, in order
to fully explore the benefits offered by SWS, current research efforts in this area focus on integration and interoperability aspects
as well as new classification algorithms [6] which will further
boost SWS’s adoption and release their commercial value.
In an attempt to design a general-purpose, flexible wireless
remote monitoring framework, the noteworthy example of a
fully integrated system architecture that took all relevant parties
and services on-board was outlined by Otto et al. [16]. Their
proposed model spanned a three-tier network made of: 1) tier
1—wireless BAN; 2) tier 2—individual health monitoring mobile phone system; and 3) tier 3—wide area network (WAN)
connection to medical servers. The first, fully commercialized
product implementing a similar model is MobiHealth [17]. This

system provides an integrated mobile remote monitoring and
feedback system that integrates with compact third-party sensor systems. Despite having intelligent capabilities to analyze
acquired data locally, the main aim of this system was to ensure that patients stayed securely connected to their remote care
professional. Moreover, the system introduced for the first time
the concept of the M-health service layer, which integrated the
intra-BAN and extra-BAN communication, making applications
independent from specific characteristics of the underlying communication protocols. This concept of sensor virtualization and
reusable mobile-centric, wireless sensing platform was further
developed by the Nokia Remote Sensing (NORS) project [18].
The NORS platform aimed at exploiting the artificial intelligence (AI) in several ubiquitous devices that connect locally to
sensors and remotely with servers. Depending on the network
availability and/or scenario of use, the system allowed users to
select where the data processing would take place locally on the
sensor/phone or remotely on the server.
These, as well as other cross platform developments and integration efforts, opened new paths in deploying intelligence on
distributed devices which informed our model design.
IV. SYSTEM REQUIREMENTS
Reviewing previous implementations and their outcomes,
several basic functional requirements common to almost every reported SWS system have been identified. These include:
1) sensing and filtering; 2) data aggregation; 3) wireless communication; 4) power management; 5) data presentation; and
6) storage. In most cases, all these elements are necessary just
to get simple sensor readings. To assemble a complete wireless
sensors network (WSN) monitoring system traditionally, one
requires skills in electronics, software engineering, signal processing, control theory, wireless networking, and AI, to name
a few. This, in turn, involves extensive and often platform targeted implementations when, in fact, all what differentiates one
application from the other are the sensors used and the data
processing algorithms implemented.
This observation suggests that a higher level application development paradigm could potenatially be applied to SWS systems development which could result in a shift from application
development to customization. This is possible with the use of
framework applications, middlewares, runtime environments,
scripts, and XML. Such platform should offer predefined methods and paradigms, where design efforts focuses on logic and
processes rather than on data aqusition or aggregation. In doing
so, it must futher enable the following.
1) Integration of vendor-specific sensor nodes under one
framework.
2) Integration of different wireless communication technologies under one framework.
3) Integration of a real-time inference engine, such as artificial neural networks.
4) Customizable context-aware data sampling and efficient
data sources utilization.
5) Remote control over sensor nodes through customizable
WSN commands.

LEWANDOWSKI et al.: LOGIC-CENTERED ARCHITECTURE FOR UBIQUITOUS HEALTH MONITORING

Fig. 1.

1527

High-level system architecture.

6) Customizable data aggregation from sensor nodes.
7) Service-oriented design enabling integration with third
party web services over WAN connection, where it can
be either a service subscriber or a publisher.
Finally, the user should be able to choose whether the system will work as a stand-alone PHA or as part of a broader
telemedicine application.
V. SYSTEM ARCHITECTURE
The proposed high-level system architecture (see Fig. 1) is
based on a well-established three-tier architecture of the WSN
as proposed in [16], spanning over a network of medical sensors
and remote web services. The WSN tier comprises a number of
sensor nodes, each capable of sampling, filtering, processing,
and communicating physiological signals. The WAN tier encompasses external web services that can either publish their
services or subscribe to the available sensor data sources. The
middleware, called personal server, links these tiers together
and it is deployed on a smartphone device that interfaces WSN
nodes locally and WAN services externally. Moreover, it provides integrated sensor nodes management, data aggregation,
real-time data processing and transmission, as well as inference
capabilities.
The main architectural difference of our proposed model,
compared to a typical health monitoring system, lays in the
workload distribution, which in terms of data processing, network management, and inference algorithms, is a responsibility
of a personal server and sensor nodes, rather than of a remote
centralized server. The proposed model allows to eliminate the
central medical server from this architecture and instead, dynamically allocates resources and external services [19]. An
important advantage of such a two-tier model is the improved
response time, which is achieved by locating the processing
power close to the user, improving therefore user’s mobility. Another important advantage achieved is the adaptability aspect,
enabling such system to become a user tailored device which
can be sensitive to individual’s special conditions or behaviors.

It also allows developing algorithms, which will determine the
user’s state and well-being status ubiquitously, taking into account contextual- and patient-specific information.
The pivotal element of this system, the AI runtime environment, allows the loading and running of new custom classification and decision algorithms developed in the corresponding Inference Engine Editor. The algorithm can be either downloaded
by the user from medical and health process repositories, or can
be directly uploaded on the personal server and executed there
by health professionals with access rights to it. Such repositories are designed based on the concept of digital distribution
platforms for mobile devices, commonly known as application
stores.
Reduction of service maintenance costs is one of the most
important benefits that come out of a ubiquities logic-centered
approach to development and more autonomous wellness monitoring systems, such as intelligent PHAs, that require no or
only little human intervention. Distributed processing, opposed
to only centralized server processing, not only decreases the
data transmission cost but can also improve the accuracy of
monitoring through patient adaptation, response time, and availability of the service to the user. With logic centered development methodology, we can “shorten the time-to-market” for new
solutions/applications, improve code reusability, reuse existing
infrastructure of third party measurement devices but foremost
focus on medical and health data processing models what is the
future of SWS.

VI. FRAMEWORK MIDDLEWARE
A. Personal Server Middleware
The personal server middleware consists of a number of specialized software packages which are grouped into two functional layers: data aggregation and data processing accompanied
by data presentation layer as illustrated in Fig. 2(a).
1) Data Aggregation Layer: The data aggregation layer consists of:

1528

Fig. 2.

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

(a) Block diagram of personal server middleware. (b) TinyOS sensor node middleware.

1) a node and network interface package,
2) the sensor networks abstraction model,
3) a WAN/external services package,
4) a data acquisition control package.
The data aggregation layer is mainly responsible for sensor’s
data fusion as well as WSN and WAN connections configuration and management. It provides an abstraction and virtualization of nodes, sensors and connections, through the network
manager, sensor manager, and WAN services coordinator modules. The abstraction uses node-specific protocol drivers what
makes applications independent from specific characteristics of
the underlying communication protocols. It enables customizable wireless interfaces and plug‘n’play capability to easily interconnect multiple third party sensor devices and services in
BAN, PAN, NAN, and WAN landscape.
The primary function of this layer is to keep a register of every single data source and manage them accordingly, including
discovery, registration, configuration, and initialization. Once
the network connections are set up, the data acquisition control package manages the network utilization, taking care of
channel sharing, time synchronization, data transmission, and
data encryption. As a result, the data aggregation layer provides
the complete collection of real-time, preprocessed, and cleaned
sensor’s data streams ready for processing.
2) Data Processing Layer: The data processing layer builds
upon the data aggregation layer. It focuses on real-time classification and implementation of decision algorithms, applied to
the data supplied by the sensor nodes. It consists of:
1) data representation package,
2) data sources control package,
3) data analyses package,
4) data storage and distribution packages.
The data processing is based on an inference engine deployed
as the data analyses package. It uses the data representation
package in order to obtain the higher level semantic data or
indexes used for analyses. The inference engine is built based
on the Java Object Oriented Neural Engine [20]. This model

features a modular architecture made of linkable components
that can be used to build not only neural network architectures,
but also other types of machine learning algorithms such as selforganizing maps (SOM), or support vector machine, amongst
others. Each machine learning model is composed of a number
of connected components. Depending on how these components
are connected, a variety of architectures can be created.
Data processing is capable of taking control over data acquisition through the data sources control package (a decision
making tool for data sources management). It introduces the dynamic sensors model which utilizes only those sensor channels
necessary for accurate system operation. A decision is made
based on the decision matrix and decision trees encoding the
expert knowledge for outcomes from the data analyses module.
Decisions take the form of actions such as: 1) to add/remove a
sensor channel for more accurate monitoring; 2) to use external
data services; or 3) to reconfigure the current data sources.
Other predefined blocks include the data distribution mechanism, which posts alarms and notification remotely to third
parties, and a file system to storage monitoring logs.
B. Sensor Node Middleware
The sensor node middleware consists of components that
sample, filter, and process physiological signals. Such data are
then stored locally or transmitted to the personal server middleware for integration, analysis, and decision making.
The prototype software runs on the TinyOS platform. The
applications are implemented as a set of components written
in nesC. A prototype sensor node middleware has been developed paying special attention to the reusability, flexibility, and
customization of its components [see Fig. 2(b)] following design patterns presented in [21]. With this in mind, our proposed
application architecture consists of the following components.
1) Sensor component (SensorC and interface Sense), responsible for data sampling on analog-to-digital converter’s
inputs, implemented using the Facade pattern which

LEWANDOWSKI et al.: LOGIC-CENTERED ARCHITECTURE FOR UBIQUITOUS HEALTH MONITORING

2)

3)

4)

5)

6)

defines a coherent abstraction boundary by exporting the
interfaces of several subcomponents;
Filter component (Filter#C and Filter interface), responsible for signal filtering, implemented using Service Instance pattern which provide multiple instances of a particular service sharing the same code;
Processor component (Processor#C and Data interface),
responsible for data preprocessing, implemented using the
Decorator pattern enhances the capabilities and functionality of the SensorsC and Filter#C components without
modifying their implementation;
Storage component (StorageC and interface Store), responsible for local data storage on flash memory, implemented using the Facade pattern which allows for a single
configuration that simplifies dependency;
Node Protocol component (NodeProtocolC that provides
Protocol interface as well as its subsequent Operation#C
components and interface Operation), responsible for performing an externally customizable set of operations in
response to the input from the network interface or call
from App module, implemented using the Dispatcher pattern.
Communication Stack component (BTCommStackC and
interface CommStack), which implements the network interface responsible for data transmission, in this case using Bluetooth radio. This functionality is encapsulated in
the Adapter pattern which converts the protocol-specific
interface into a single interface type CommStack, what
simplifies access to the network resources.
VII. AI RUNTIME AND INFERENCE ENGINE EDITOR

The biggest advantage of the proposed logic centered architecture lays on the embedded inference engine, which serves as
an artificial runtime environment for the algorithms and constitutes the central component of the system. It offers capabilities
to allow the development of new machine learning algorithms,
and instantly deploys them remotely on the user mobile device
without needing to modify or reimplement the whole application
again.
A complementary visual Inference Engine Editor, offered
with the package, enables AI experts and health professionals to build new inference models for their applications in a
very short time. This is done by linking together components
and, in cases where out-of-the-box implementations are needed,
the application logic can be controlled with scripts. Depending
on the nature of the problem, any type of algorithm(s) can be
used to solve it. Each model can be composed of one or many
components of different types. All components are pluggable,
reusable, parameterizable, and serializable code modules. These
features guarantee the scalability, reliability, and expansibility
of the model, enabling the feature selection, training, validation
and verification, data dimensionality reduction, and testing of
complex hybrid models in one editor. The resulting algorithm
converts to a self-contained object by serializing the network as
a byte stream to the file system or database. Such file can then
be sent to the remote mobile device using a WAN connection

1529

and resurrected there. Deployment of the algorithm on mobile
devices can be accomplished by embedding it into a custom
framework mobile application.
A framework application, such as our personal server, has
to then supply data to the algorithm inputs, interrogate these,
and read the results on its output. There are two ways to accomplish this, depending on how the embedding application
interrogates the algorithm it can choose between synchronous
or asynchronous mode. In synchronous mode, the algorithm is
interrogated by the application by setting its input patterns and
calling a run method. After processing, the results are stored
in memory and it waits to be collected by the application for
further processing or presentation. In asynchronous mode, the
algorithm runs as a background process, and an external asynchronous source of data interrogates the algorithm with an input
pattern as it arrives. Such source of data can be a sensor device or
an external data acquisition service. The example of such development and deployment process for the simple neural network
algorithm illustrated in Fig. 3.
VIII. EVALUATION
Based on the system architecture presented earlier, we have
rapidly developed a prototype vital signs monitoring system
to continuously monitor and analyze five vital signs and their
trends using two sensor nodes. The first sensor node is a chest
strap, capable of measuring ECG, temperature, and respiratory
rate, which uses off-the-shelf SHIMMER wireless sensor platform [22] with a number of sensors such as SHIMMER ECG
daughter card, NTC type thermistor, and piezoelectric sensor.
It has been programmed using our TinyOS sensor node middleware. The second sensor node used in our case study is
a commercially available wireless pulse oximeter, which was
rapidly integrated with the aid of the personal server framework.
The prototype of the personal server has been implemented for
CLDC 1.1 and MIDP 2.0 profiles in Java programming language. The prototype system was tested on phoneME Java Virtual Machine that can run on Windows, IOS, and Android.
Our objective is to assess the effectiveness of the proposed
architecture in enabling flexible design of algorithms versus
their performance. The design processes with their corresponding performances of applications using sensor node middleware were compared with their direct implementation on top of
TinyOS. For such purposes, 1) AccelECG application, available
from TinyOS contributed code repository and its two extensions, 2) AccelECG_TEMP, and 3) AccelECG_TEMP_RESP
were reimplemented using the proposed sensor node middleware. The main qualitative issues that manifest the proposed
sensor node middleware to be superior to the direct implementation are as follows:
1) Direct TinyOS implementation is much more complex
where developers must manually wire all subsequent
components, implement their interfaces, control message
transmission, parsing, buffering data, etc., while using the
middleware the focus is on the application-specific processing related to the actual data of interest with all configuration being done a prior by the model.

1530

Fig. 3.

Fig. 4.

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

AI algorithms development and deployment lifecycle.

Comparison of middleware against direct TinyOS implementation.

2) The middleware enables the network heterogeneity of the
application in terms of communication protocol and its
sensitivity to network conditions what in case of direct
implementation is equivalent to app redesign.
3) The middleware improves the scalability of the application in case when new sensors must be deployed on the
node, enabling to reuse existing code by adding new sensor component with its specific processing.
4) Data flow in the TinyOS application is not evident due to
split phase operation, what greatly complicate the maintenance and debugging. The proposed middleware alleviates
this problem with the processor component.
Quantitative measures used to compare the complexity of
those applications are presented in Fig. 4. The comparison includes the number of lines of code, which for this examples
decreased by almost 50% with use of the middleware. Also,
using the middleware, the number of explicit application events
that the developer must control to simply get sensor readings de-

creased to four events which are independent from the number
of sensors. These events include connection made, command
received, sensing done, and connection closed. Such simplification comes at the price of a slight increase in the size of the
binary code deployed on the mode (ROM) as well as heap size
(RAM). This, however, remains well within the limits of program flash memory size of the commercially available sensor
platforms.
A qualitative evaluation of the Personal Server and Inference Engine conducted during the application design process
revealed model inherent properties.
1) Heterogeneity of the middleware that manifest in its ability
to easily integrate multiple third party sensor devices and
communication protocols was obtained through the sensor abstraction model, which simplifies data acquisition
and network coordination by hiding the whole networkspecific functionality, what enables to perceived sensors
as a data publishing service within any type of network.
2) Scalability achieved with modified Flooding Time Synchronization Protocol with dynamic slot allocation for efficient use of the available bandwidth what increased the
node sleep time and helped to reduce the transmission and
energy cost.
3) Usability, enabled by the high-level abstraction of application design process using embedded inference engine
and its rapid deployment model facilitated by the visual
data flow composition using visual editor. With a corresponding visual editor and training environment, a subjectspecific user such as medical professional is able to develop the AI algorithm, and subsequently, in a very short
period of time, conduct initial field tests.
To verify that the advantages we identified above do not negatively affect the system performance, we extended our evaluation beyond the development model to look at how the network overheads and inference engine model affect the sample

LEWANDOWSKI et al.: LOGIC-CENTERED ARCHITECTURE FOR UBIQUITOUS HEALTH MONITORING

Fig. 5. Impact of number sensors and complexity of inference algorithms on
sample execution time.

execution time. As expected, Fig. 5 shows significant correlation between execution time and the complexity of the inference
algorithm (measured by the SOM dimension). However, it also
shows that the network overheads associated with the increase
of number of sensor data streams do not affect the execution
time what proves the quality of the presented model.
IX. CONCLUSION AND FUTURE WORK
The main innovations presented in this paper are as follows: 1)
the newly proposed concept of logic-centered design methodology for ubiquitous health monitoring enabled by the presented
integrative SWS architecture; and 2) the embedded inference
engine model that can be hosted locally on the personal server.
Both contributes to shift focus from software and hardware development to medical and health process-centered design when
developing new SWSs. Thanks to the presented capabilities, a
normally extensive implementation project can be achieved in
a limited time frame and reduced to components assembly and
configuration.
Future work will focus on porting and extending further the
platform to support any native smartphone operating system,
what will translate on an improvement on the adoption rate of
systems build using this framework. It is envisaged that this
can be achieved with a central metacode repository, which at
the time of deployment will port the application to the right
platform following methods presented by Miroslav et al. [10].
Other areas of future work are development of further test beds
with applications offering solutions to various health monitoring
problems. By enabling the acquisition of different body parameters from commercially available third party devices as well as
integration with wider telemedicine systems and external services, we aim to boost the adoption and integration of SWS in
everyday life.
REFERENCES
[1] The World Health Report 2010: Health Systems Financing: The Path to
Universal Coverage, World Health Organisation, Geneva, Switzerland,
2010.
[2] Population Ageing and Development 2012 (Wall Chart), United Nations,
Population Division, Department of Economic and Social Affairs, New
York, NY, USA, 2012.
[3] R. S. H. Istepanian, S. Laxminarayan, and C. S. Pattichis, M-Health:
Emerging Mobile Health Systems. New York, NY, USA: Springer, 2006.

1531

[4] P. Wang, K.-M. Chao, C.-C. Lo, and R. Farmer, “An evidence-based
scheme for web service selection,” Inf. Technol. Manage., vol. 12, pp. 161–
172, Jun. 1, 2011.
[5] J. Lewandowski, H. Arochena, R. Naguib, and K. Chao, “A portable
framework design to support user context aware augmented reality applications,” presented at the 3rd International Conference in Games and
Virtual Worlds for Serious Applications, Athens, Greece, 2011.
[6] M. Chan, D. Estève, J.-Y. Fourniols, C. Escriba, and E. Campo, “Smart
wearable systems: Current status and future challenges,” Artif. Intell. Med.,
vol. 56, pp. 137–156, 2012.
[7] B. K. Hensel, G. Demiris, and K. L. Courtney, “Defining obtrusiveness in
home telehealth technologies: A conceptual framework,” J. Amer. Med.
Informat. Assoc., vol. 13, pp. 428–431, Jul. 1, 2006.
[8] J. Ko, C. Lu, M. B. Srivastava, J. A. Stankovic, A. Terzis, and M. Welsh,
“Wireless sensor networks for healthcare,” Proc. IEEE, vol. 98, no. 11,
pp. 1947–1960, Nov. 2010.
[9] A. Lymberis and A. Dittmar, “Advanced wearable health systems and
applications—Research and development efforts in the European union,”
IEEE Eng. Med. Biol. Mag., vol. 26, no. 3, pp. 29–33, May/Jun. 2007.
[10] K. Miroslav, L. Fedor, and V. Gabriel, “Multi-platform telemedicine
system for patient health monitoring,” in Proc. IEEE-EMBS Int. Conf.
Biomed. Health Inf., 2012, pp. 127–130.
[11] T. S. Bergmo, “Economic evaluation in telemedicine—Still room for improvement,” J. Telemed. Telecare, vol. 16, pp. 229–231, Jul. 1, 2010.
[12] R. S. H. Istepanian, E. Jovanov, and Y. T. Zhang, “Guest editorial introduction to the special section on M-health: Beyond seamless mobility
and global wireless health-care connectivity,” IEEE Trans. Inf. Technol.
Biomed., vol. 8, no. 4, pp. 405–414, Dec. 2004.
[13] I. Korhonen, J. Parkka, and M. Van Gils, “Health monitoring in the home
of the future,” IEEE Eng. Med. Biol. Mag., vol. 22, no. 3, pp. 66–73,
May/Jun. 2003.
[14] P. Świátek, P. Stelmach, A. Prusiewicz, and K. Juszczyszyn, “Service
composition in knowledge-based SOA systems,” New Gener. Comput.,
vol. 30, pp. 165–188, Jun. 1, 2012.
[15] B. G. Blobel, “Educational challenge of health information systems’ interoperability,” Methods Inf. Med., vol. 46, pp. 52–56, 2007.
[16] C. Otto, A. Milenkovic, C. Sanders, and E Jovanov, “System architecture
of a wireless body area sensor network for ubiquitous health monitoring,”
Mobile Multimedia J., vol. 1, pp. 307–326, 2006.
[17] A. van Halteren, R. Bults, K. Wac, N. Dokovsky, G. Koprinkov, I. Widya,
D. Konstantas, V. Jones, and R. Herzog, “Wireless body area networks
for healthcare: The MobiHealth project,” Stud Health Technol. Inform.,
vol. 108, pp. 181–193, 2004.
[18] D. Trossen and D. Pavel, “Building a ubiquitous platform for remote sensing using smartphones,” in Proc. 2nd Annu. Int. Conf. Mobile Ubiquitous
Syst.: Netw. Serv., 2005, pp. 485–489.
[19] A. Grzech, P. Świátek, and P. Rygielski, “Dynamic resources allocation
for delivery of personalized services,” in Software Services for e-World,
vol. 341, W. Cellary and E. Estevez, Eds. Berlin, Germany: Springer,
2010, pp. 17–28.
[20] P. Marrone. (2007). JOONE: The Complete Guide [Online]. Available:
http://www.joone.org
[21] D. Gay, P. Levis, and D. Culler, “Software design patterns for TinyOS,”
Trans. Embedded Comput. Syst., vol. 6, no. 4, pp. 22:1–22:39, 2007.
[22] M. J. McGrath and T. J. Dishongh, “A common personal health research
platform—SHIMMER and BioMOBIUS,” Intel Technol. J., vol. 13,
pp. 122–147, 2009.

Jacek Lewandowski (M’09) received the B.Sc. degree from Coventry University, Coventry, U.K., in
2008, and the M.Sc. degree from the Wroclaw University of Technology, Wroclaw, Poland, in 2011,
both in software engineering. He is currently working toward the Ph.D. degree at Coventry University.
He is an Assistant Lecturer at Coventry University. His research focuses on mathematical modeling,
artificial intelligence and systems development for
industrial and medical applications.

1532

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

Hisbel E. Arochena (M’01) received the Ph.D. degree in computer science, (biomedical computing)
from Coventry University, Coventry, U.K., in 2003.
She is the Founder and Director of Pioneering
Technologies Solutions Ltd., formerly a Senior Lecturer in Computer Science within the Faculty of Engineering and Computing, Coventry University. Her
research interests fall within the areas of mathematical modelling, computer networks and artificial intelligence for medical and well-being applications.

Kuo-Ming Chao (M’10) received the Ph.D. degree in
computer science from Sunderland University, U.K.,
in 1997.
He is a Professor of computing at Coventry University, Coventry, U.K. His research interests include
the areas of intelligent agents, service-oriented computing, cloud computing, big data, etc., as well as
their applications, such as energy efficiency management and green manufacturing.

Raouf N. G. Naguib (SM’97) received the Ph.D. degree in electrical engineering from Imperial College
London, London, U.K., in 1986.
He was until recently a Professor of biomedical computing and Head of the Biomedical Computing and Engineering Technologies Research Group
at Coventry University, Coventry, U.K. His research
interests focus on the applications of artificial neural
networks in cancer diagnosis, prognosis and patient
management.

Alexeis Garcia-Perez received the Ph.D. degree in
information systems at Cranfield University, Bedford,
U.K.
He has been a Lecturer at Coventry University,
Coventry, U.K., since 2011. His teaching and research
interests include information systems development
and their applications in business, in particular for
the collection and analysis of data.

