1494

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

Accurate Segmentation of Partially Overlapping
Cervical Cells Based on Dynamic Sparse Contour
Searching and GVF Snake Model
Tao Guan, Dongxiang Zhou, and Yunhui Liu, Fellow, IEEE

Abstract—Overlapping cells segmentation is one of the challenging topics in medical image processing. In this paper, we propose
to approximately represent the cell contour as a set of sparse contour points, which can be further partitioned into two parts: the
strong contour points and the weak contour points. We consider
the cell contour extraction as a contour points locating problem
and propose an effective and robust framework for segmentation
of partially overlapping cells in cervical smear images. First, the
cell nucleus and the background are extracted by a morphological
filtering-based K-means clustering algorithm. Second, a gradient
decomposition-based edge enhancement method is developed for
enhancing the true edges belonging to the center cell. Then, a dynamic sparse contour searching algorithm is proposed to gradually locate the weak contour points in the cell overlapping regions
based on the strong contour points. This algorithm involves the
least squares estimation and a dynamic searching principle, and
is thus effective to cope with the cell overlapping problem. Using
the located contour points, the Gradient Vector Flow Snake model
is finally employed to extract the accurate cell contour. Experiments have been performed on two cervical smear image datasets
containing both single cells and partially overlapping cells. The
high accuracy of the cell contour extraction result validates the
effectiveness of the proposed method.
Index Terms—Cervical smear image, dynamic sparse contour
searching (DSCS), Gradient Vector Flow (GVF) Snake model, medical image processing, overlapping cells segmentation.

I. INTRODUCTION
ERVICAL cancer, as one of the world’s most common
cancers among females, is preventable and can be detected
in its premalignant stage. It has been shown from the clinical
results that the reduction in the risk of developing of cervical
cancer is approximately 30% for a cervical cancer screening
taken once every ten years, 80% for every five years, and 92%
for annual screening [1]. Among all the screening methods,
Pap smear test is considered as a quite effective one [2]–[6].
However, until now Pap smear screening work is mainly done
by cytotechnologists, who must be critically trained and well

C

Manuscript received February 24, 2014; revised June 19, 2014; accepted July
31, 2014. Date of publication August 8, 2014; date of current version July
23, 2015. This work was supported in part by the National Natural Science
Foundation of China under Grant 61375032.
T. Guan and D. Zhou are with the College of Electronic Science and Engineering, National University of Defense Technology, Changsha 410073, China
(e-mail: gt_mike2003@126.com; dxzhou@nudt.edu.cn).
Y. Liu is with the Department of Mechanical and Automation Engineering,
The Chinese University of Hong Kong, Shatin, Hong Kong (e-mail: yunhui.liu@
gmail.com).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2346239

experienced. Due to the large amounts of Pap smear samples,
cytotechnologists are susceptible to make erroneous decisions
caused by monotony, fatigue, inexperience, etc. Therefore, the
study of developing an automatic cervical precancerous diagnostic system has attracted extensive attention [2]–[5], [7]–[14].
It has been shown that the normal and abnormal cervical cells
are different from their morphologic and architectural properties
[2]–[6], such as the photometric properties of the cell nucleus,
the shape and size of the nucleus and cytoplasm, and the nuclearcytoplasmic ratio. Consequently, the accurate measurement of
these morphologic and architectural parameters is crucial for
the discrimination of the normal and abnormal cells. In order to
develop an automatic cervical cancer screening system, an accurate and robust segmentation algorithm, which can extract the
contours of the cell nucleus and cytoplasm, is needed urgently
[2], [5], [7].
From earlier thresholding and watershed-based techniques
[15], [16] till now, various methods have been proposed in the
study of cervical cell image segmentation. These studies can
be categorized into two aspects [2]: 1) locate the contours of
the nuclei in low-resolution cervical smear images containing
plenty of cervical cells [3], [5], [7], [9], [10], [17], [18]; and
2) accurate segmentation of the nuclei or cytoplasm in highresolution cervical smear images (e.g., the Herlev dataset [19])
containing single-nonoverlapping cells or partially overlapping
cells [2], [4], [11], [12], [14]. The studies of these two aspects
are briefly surveyed next.
The first topic has been extensively investigated. Mat-Isa
et al.[5] employed a seed-based region growing method to extract the nuclei from cervical smear images. Plissiti et al. [3]
detected the contours of cell nuclei based on morphological reconstruction. Bamford and Lovell [8] proposed a dual active
contour model to extract cell nuclei. This approach transforms
the cell image into the polar coordinates and adopts the Viterbi
searching algorithm in their model to detect the contours of cell
nuclei. Other methods have also been introduced into the nuclei
segmentation, such as the randomized Hough transform [9], the
concave point-based method [20], and the multiscale hierarchical watershed segmentation method [7]. However, most of these
methods focus on the accurate segmentation of cell nuclei and
seldom address the problem of overlapping cytoplasm segmentation, which is also important for the cervical cell segmentation.
Since the Herlev dataset [19] is publicly available, the second
topic has also attracted much attention. Mao-Yang et al. [4]
proposed an edge-based method to extract cell contours
in single-cell cervical smear images. They employed a

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

GUAN et al.: ACCURATE SEGMENTATION OF PARTIALLY OVERLAPPING CERVICAL CELLS BASED ON DYNAMIC SPARSE CONTOUR

trim-meaning filter and a bi-group enhancer to remove noise
and enhance the obscure edges in cell images, respectively.
Then, they proposed a mean vector difference enhancer using
the gradient vector flow (GVF) vectors [21] to further brighten
the obscure edges. The cell contours are finally obtained by
automatic thresholding [22] and morphological operations.
Li et al. [2] proposed to extract cell contours using the Radiating GVF (RGVF) Snake model. The edge and region information is combined to solve the cell segmentation problem.
A spatial K-means clustering algorithm is used for rough extraction of the cell nucleus and cytoplasm. Then, a stack-based
refinement method is proposed to compute the radiating edge
map. The GVF Snake model [21] is finally employed to extract the cell contour. High accuracy of the segmentation result
has been shown in their work. However, their approach may
be only suitable for the segmentation of single-nonoverlapping
cells. Due to the challenge of cell overlapping, most of the recent studies [2], [4], [11], [12] only dealt with images with
single-nonoverlapping cells. To the best of our knowledge, accurate segmentation of overlapping cervical cells has not been
sufficiently addressed.
The aim of this paper is to address the problem of partially
overlapping cells segmentation in high-resolution cervical
smear images (e.g., the Herlev dataset [19]). Since the cervical
cell generally has an irregular shape, the active contour
model (Snake model) is a suitable tool for cervical cell image
segmentation [2], [8], [23]. The dual active contour model
[8] and the RGVF Snake model [2] have been proposed for
segmentation of cervical cell images. The common idea of
these two models lies in the fact that the nucleus is in the center
of the whole cell and surrounded by the cytoplasm, and they
both analyze the cell structure from a center-radial direction,
which is an effective way to solve the problem of cell image
segmentation. The work presented in this paper is inspired by
these two models as well as the hysteresis thresholding method
in the Canny [24] edge detector.
Based on carefully investigating the cell contour structure
from a center-radial direction, we summarize the characteristics
of the cell contour points and propose a novel cell segmentation
method in this paper. We first approximately represent the cell
contour as a set of sparse contour points. Inspired by the hysteresis thresholding method [24], we further divide these contour
points into two categories: the strong contour points (between
the cytoplasm and the background) and the weak contour points
(in the cell overlapping regions). Then, we consider the cell segmentation as a contour points locating problem and propose a
dynamic sparse contour searching (DSCS) algorithm to search
for the weak contour points based on the strong contour points.
Finally, we combine the DSCS algorithm with the GVF Snake
model [21] to obtain accurate cell segmentation results. In the
rest of this paper, Section II summarizes the characteristics of
cell contours in detail and presents the main idea as well as
the framework of our method. Sections III and IV describe the
details of the individual steps of the proposed segmentation
method. Section V analyzes the performance of the proposed
method on two cervical smear image datasets. Conclusions and
future work of this paper are presented in Section VI.

Fig. 1.

1495

Cervical smear images containing overlapping cells.

II. OVERVIEW OF THE PROPOSED SEGMENTATION FRAMEWORK
In cervical smear images, there are a large number of overlapping cells that make the cervical cell segmentation a challenging
problem. Fig. 1 shows some cell images with overlapping cells
from the Herlev dataset [19]. The difficulties for segmentation
of such kind of images are mainly caused by three aspects:
1) there are plenty of small artifacts dispersedly distributed in
the whole image; 2) the color (or intensity) in the cell region
is not uniformly distributed due to cell overlapping and uneven
illumination; and 3) cell contours belonging to different cells in
the overlapping regions intersect with each other and it is even
a time-consuming task for human to distinguish the true cell
boundaries.
To address the aforementioned difficulties and extract accurate cell contours, we investigated the GVF Snake [21] model
for cervical cell segmentation. Because the Snake [25] is an
elastic shape model, which is suitable for the description of cell
contours, we use the GVF Snake as the final step of our segmentation method. However, there are two problems to be solved
when applying the GVF Snake to segmentation of overlapping
cells: one is how to automatically estimate the initial contour;
the other is how to enhance the true edges of the cell and suppress the false edges caused by other unconcerned overlapping
cells and artifacts. The aim of solving these two problems is to
make the Snake converge to the true cell boundary. In this paper,
we solve these two problems and propose an initial contour estimation method based on a DSCS algorithm. The main idea of
our segmentation framework is briefly summarized as follows.
After investigating the geometric structure of cell contours,
we summarize their characteristics and make three assumptions
to approximately describe a cell contour next.
A. Assumption 1
A cell contour is composed of a set of contour points, and the
nucleus is surrounded by these points. If we draw a radial line
starting from the nucleus center, there would be one contour
point on this line. We use the polar coordinates (ρ, θ) as the
representation of cell contour points and set the nucleus center
as the origin. For a contour point pi , θi represents the angle
between its corresponding radial line and a reference radial
axis, and ρi represents the Euclidean distance from the origin
to pi . In the rest of this paper, we define θi as the angle of the
radial line corresponding to pi . Then, the cell contour can be
represented by a set P :
P = {pi |(ρi , θi ) are the corodinates of pi }, i = 1, . . . , ∞.
(1)

1496

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

Fig. 2. (a) Original cell image and the sparse contour points of the center cell
(green points). (b) Cell model with two neighboring contour points.

B. Assumption 2
In order to simplify our model, we do not use all the contour
points of a cell. Instead, we just use a subset of these points
to approximately represent the cell contour. In this subset, if
(ρi , θi ) and (ρj , θj ) are the coordinates of two neighboring contour points pi and pj , respectively, Δθ = θi − θj is the angle
difference between these two points, as shown in Fig. 2(b).
Then, a cell contour can be approximately represented by a set
of sparse points, as shown in Fig. 2(a). Let N be the total number
of these points, then
P = {pi }, i = 1, . . . , N.

(2)

C. Assumption 3
We divide the contour points of a cell into two categories: the
strong contour points, denoted by a set P s, and the weak contour
points, denoted by a set P w. The strong contour points lie on
the cell contour between the cytoplasm and the background. The
weak contour points lie on the cell contour in the cell overlapping
regions. Then, the cell contour can be further described as
P = P s ∪ P w.

(3)

According to the previous assumptions, we consider the cell
segmentation as a contour points locating problem and present
a novel framework for segmentation of overlapping cells images. There are two major steps in this framework. The first step
is to locate the strong contour points of the cell and set these
points as basic contour points. The second step is to search for
the weak contour points along the basic contour points based
on a DSCS algorithm proposed in this paper. The flowchart of
the proposed method is shown in Fig. 3. First, we adopt a morphological filtering-based K-means (MF K-means) clustering
algorithm to obtain the nucleus and the background. Second,
we propose a gradient decomposition-based edge enhancement
method to enhance the true edges belonging to the center cell
and suppress the false edges belonging to other unconcerned
cells and artifacts. With the extracted background and the enhanced edge map, the basic contour points can be extracted.
Then, we propose the DSCS algorithm to locate the cell contour
points automatically. The located contour points are arranged to
construct the initial contour of the GVF Snake, which is finally
performed to make accurate segmentation of the cell images.
Due to the variety of the shapes of real cervical cells, the
aforementioned three assumptions may not be perfect to describe all the cell contours. Also, the DSCS algorithm does not

Fig. 3. (Left) Flowchart of the proposed segmentation framework. (Right)
Intermediate results for illustration of the processing steps in the left flowchart.

locate all the contour points of a cell but a set of sparse contour
points. Therefore, we combine the DSCS algorithm with the
GVF Snake model, which is able to cope with boundary concavities. The DSCS algorithm provides the GVF Snake with a
better initial contour that is very close to the true cell boundary.
The combination of them facilitates the accurate extraction of
cell contours.
III. PRESEGMENTATION AND EDGE ENHANCEMENT
A. Preprocessing
During the staining process, the specimen with cervical cells
is often colored with different dyes. Since different dyes make
the cervical cells have different colors, in order to make our
segmentation method more robust to cervical cell images with
different colors, we follow [2], [7] to convert the original RGB
color image into the CIELAB color space and use the L∗ channel
as the grayscale image in this paper. In addition, the nonlocal
means filter [26] has been considered to be an effective filter
for filtering the Gaussian noise and impulse noise in cervical
smear images [2]. Therefore, we adopt this filter for denoising
the cervical smear images.
B. MF K-means
In a real cervical smear image, small contaminations with
low intensities and small areas are widely distributed. In order to eliminate the influence of the contaminations on the

GUAN et al.: ACCURATE SEGMENTATION OF PARTIALLY OVERLAPPING CERVICAL CELLS BASED ON DYNAMIC SPARSE CONTOUR

Fig. 4.
results.

(Top row) Original images. (Bottom row) Morphological filtering

1497

Fig. 5. (Top left) Cell image after the morphological filtering method. (Right)
Corresponding histogram (a, b, c, and d represent the nuclei, the dark cytoplasm,
the light cytoplasm, and the background, respectively). (Bottom left) Cell image
colored with four grey levels (given by the mean of the a, b, c, and d regions of
the histogram).

presegmentation results, a morphological filtering method is
first adopted in the presegmentation.
The morphological filter is able to eliminate the dark points
in an image. If f is the grayscale cell image denoised by the
nonlocal means filter [26] in the previous section, fm is the filtered image by the morphological filter, then the morphological
filtering method can be described as follows:
fm = (f ⊕ SE1 )  SE1

(4)

where SE1 is a flat disk-shaped structuring element with
radius 7, its size is related to the size of the small dark contaminations, ⊕ is the morphological dilation operator, and  is
the morphological erosion operator. Fig. 4 shows some results
obtained by the morphological filtering method. It can be found
that the morphological filtering method eliminates most of the
small dark contaminations in the original images.
In a cell image, the pixels can be classified into three parts:
the nucleus, the cytoplasm, and the background, respectively,
according to their intensities. Therefore, an ideal cell image has
a three-model distributed histogram. Based on this property,
a spatial K-means method is proposed in [2] to make rough
segmentation of the cell image. However, if we investigate the
cell image (especially the image containing overlapping cells)
carefully, we can find that the cytoplasm does not have uniformly distributed intensities because of cell overlapping and
uneven illumination. Actually, a real cervical cell image generally has a four-model distributed histogram with four classes of
pixels: the nuclei, the dark cytoplasm, the light cytoplasm, and
the background. Fig. 5 shows a typical cell image filtered by
the morphological filtering method and its histogram. There are
approximately four classes of pixel intensities distributed in the
histogram, and each class approximately follows a Gaussian
distribution (as depicted by the red curves in Fig. 5).
We propose to adopt MF K-means clustering algorithm to
make presegmentation of the cell image. In this method, we
divide the image pixels into four parts (including the nuclei,
the dark cytoplasm, the light cytoplasm, and the background)
instead of three parts as the classical clustering method [2]
does. The K-means clustering algorithm first splits the image
pixels obtained by the morphological filtering method into four

Fig. 6. (a) Original cell images. (b) Segmentation results by spatial K-means.
(c) Segmentation results by MF K-means.

classes, and then merges the two classes of pixels that have
median grey levels into a single class as the cytoplasm. Fig. 6
shows some results of our method and the spatial K-means
method [2]. We can find that the MF K-means method corrects
and refines the rough divisions of the spatial K-means method
and thus obtains more reliable results, which are important for
the rest segmentation steps of this paper.
After presegmentation, we choose the darkest regions as the
candidate nucleus regions. Because the nucleus generally has a
circular shape and its area is within a fixed range, we follow [2]
and use the geometric features of the candidate nucleus regions
to screen out the nucleus of interest. The threshold for each
geometric feature is fixed based on statistical analysis.
C. Gradient Decomposition-Based Edge Enhancement
In the cell overlapping regions, different cell contours intersect with each other and their edges are also blurred. It is crucial
to enhance the true edges belonging to the center cell and suppress the false edges belonging to other unconcerned cells and

1498

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

Fig. 7. Illustration of the difference between the gradient vectors at different
cell contour points.

artifacts. Based on careful analysis of the geometric relationship between the nucleus center and the gradient direction of
the cell contour, we propose a gradient decomposition-based
edge enhancement method as follows.
In a typical cell image, the cytoplasm regions are generally
darker than the background, while the cell overlapping regions
are generally darker than the cytoplasm regions. Since the cell
generally has a convex shape, the gradient at a contour point
of the cell generally diverges from the nucleus center. Fig. 7
shows a simple model of overlapping cells, where Cell 1 is the
cell of interest, and Cell 2 is an unconcerned cell and partially
overlapped with Cell 1. p1 and p2 are two contour points belonging to Cells 1 and 2, respectively. α is the angle between the
gradient vector (arrow) at a contour point and the corresponding
radial line (dashed line). According to the previous analysis, we
may conclude that α1 is generally an acute angle, whereas α2
is generally an obtuse angle.
In our method, the Sobel operator [27] is first employed to
calculate the gradient edge map of the cell image denoised by
the nonlocal means filter in Section III-A. Let W (i, j) be the
corresponding window of pixel (i, j) with 3 × 3 pixels, then the
gradient g (i, j) at pixel (i, j) is
g (i, j) = (Mx ∗ W (i, j), My ∗ W (i, j) )

|g (i, j)| =
(Mx ∗ W (i, j))2 + (My ∗ W (i, j))2

(5)
(6)

where ∗ is the operator of convolution, and Mx and My are two
3 × 3 Sobel convolution masks.
Then, the enhanced edge map is defined as follows:
fg de (i, j) = |g (i, j)| ·

cos α + |cos α|
2

(7)

where α is the angle between the gradient g (i, j) and the corresponding radial line (as Fig. 7 shows). Fig. 8(c) shows some
edge enhancement results of our method. We can find that most
of the true edges belonging to the center cell are effectively enhanced, whereas the false edges belonging to other unconcerned
overlapping cells and artifacts are mostly suppressed. It should
be noted that there may be a few parts of the cell contour that are
not convex, and these parts are not enhanced. However, the main
aim of our edge enhancement method is to suppress the false
edges belonging to other unconcerned cells, and the loss of a
few true cell edges may not significantly influence our method,
because in the final step, we use the original edge map as well

Fig. 8. (a) Original cell images. (b) Sobel edge map. (c) Enhanced edge map
by our method. (d) Extracted basic contours.

as the enhanced edge map for the final contour extraction, as
described in (19).
In order to further suppress the false edges, we redefine fg de
as follows:

fg de (i, j), fg de (i, j) > μ max{fg de }
(8)
fg de (i, j) =
0,
others
where μ is a weight, and max{fg de } is the maximum of fg de . μ
is used to suppress the false weak edges and make the rest steps
more robust.
IV. ACCURATE CELL CONTOUR EXTRACTION
The major difficulty in overlapping cells segmentation is the
correct segmentation of the cell overlapping regions. Our edge
enhancement method described in the previous section can make
the true cell contour more distinct, but it is still a difficult problem to effectively extract the whole cell contour. Recent studies
[2], [10] have attempted to use the rough boundary of the whole
cell region (including all other overlapping cells) or a circle
that encloses the cell as the initial contour of the GVF Snake
model. However, such initial contours obtained by these methods are far away from the true cell boundaries. Therefore, the
GVF Snake is prone to be disturbed by the interferential edges
in the cell overlapping regions and can hardly converge to the
true cell boundary. In order to estimate the initial contour as
close as possible to the true cell boundary, we propose a DSCS
algorithm to achieve this objective in this section.
A. Basic Contour Extraction
According to Section II-C, the cell contour can be divided into
two parts: the strong contour and the weak contour. The strong
contour is more obvious than the weak contour. Although the
weak contour is unobvious, it is, to some extent, connected
with the strong contour in the enhanced edge map (see Fig. 8).
Based on this fact, the main idea of our contour extraction is

GUAN et al.: ACCURATE SEGMENTATION OF PARTIALLY OVERLAPPING CERVICAL CELLS BASED ON DYNAMIC SPARSE CONTOUR

that we first extract the strong contour and set it as the basic
contour, and then the proposed DSCS algorithm is performed to
gradually locate the weak contour points starting from the basic
contour points.
The basic contour belongs to the strong contour that lies
between the cell cytoplasm and the background. We first extract
the background in the presegmentation result and further extract
its rough boundary using morphological operators. Let fbk g be
the background and ∇fbk g be its rough boundary, then
∇fbk g = fbk g ⊕ SE2 − fbk g  SE2

(9)

where SE2 is a flat disk-shaped structuring element with
radius 3, its size is related to the width of the enhanced cell edge.
Due to the interference of some contaminations, there may be
a few small holes within the background regions. Therefore,
we first find out these small holes whose areas are less than a
threshold (statistically 1% of the whole image area), and then
fill in these holes to make our method more robust. The basic
contour fcb is defined by the following equation:
fcb (i, j) = fg de (i, j) × ∇fbk g (i, j).

(10)

Several basic contours extracted by our method are shown in
Fig. 8(d). We can see that these contours belong to the strong
contours that lie on the boundaries between the center cells and
the corresponding background regions, as defined in Section II.
B. DSCS
After extracting the basic contour, we set the nucleus center as the origin and then search for the weak contour points
around the origin. In the enhanced edge map, a contour point
lies on an intensity peak of the radial edge (the edge on the radial
line). Therefore, the proposed searching algorithm searches for a
proper intensity peak on each radial line and then set it as the contour point on this line. The enhanced edge map fg de obtained in
Section III-C serves as the search map. In this algorithm, we first
locate the contour points on the basic contour, with one point on
each radial line. Then, the searching algorithm is performed to
locate the rest contour points based on the located basic contour
points. More specifically, our aim is to fix ρi for each θi around
the origin. After the searching algorithm is finished, we can
obtain the contour points set P = {pi |(ρi , θi ), i = 1, . . . , N }.
The searching process of our algorithm can be briefly described as: 1) the algorithm starts from a located basic contour
point and scans every θi around the origin; 2) every time a new
θi is scanned, it first estimates the position of the contour point,
sets the searching zone centered at the estimated position along
the radial line (corresponding to θi ), and then searches for the
exact position of the contour point in the searching zone; and
3) update the new contour point, and then scan the next angle
θi+1 .
In the second step previous, how to estimate the position of
the contour point and set the searching zone are important for
the design of the proposed searching algorithm. In order to make
this algorithm more robust, we introduce the least squares estimation method into the searching algorithm, and furthermore,
we propose a dynamic searching principle as follows.

1499

C. Least Squares-Based Contour Point Estimation
Due to the variety of cell shapes, we can hardly find an accurate mathematical model to describe the shape of a whole cell
contour. However, a small segment of the cell contour can be
approximately regarded as an arc segment. Therefore, in this
paper, we use a quadratic function to approximately describe a
small segment of the cell contour. Then, the least squares estimation [28] is used to estimate the position of a contour point
according to its k neighboring contour points. Since k is related
to the length of the small arc segment and a large value may
result in high computational cost, k is supposed to be a small
integer. We fixed that k = 4 is able to make proper estimations
based on statistical analysis.
Assume that there are k neighboring contour points in a
small segment of the cell contour, and their coordinates are
(ρ1 , θ1 ), (ρ2 , θ2 ), . . . , (ρk , θk ), respectively. In this segment,
the cell contour can be modeled as the quadratic function:
ρ = aθ2 + bθ + c

(11)

where a, b, and c are three parameters to be estimated. Because
the previous function is an approximate model, we assume that
the value of θ is known, while ρ is disturbed by a Gaussian
noise w with a distribution N (0, σ 2 ). Thus, for each contour
point (ρi , θi ), the previous model can be rewritten as
ρi = aθi2 + bθi + c + w(i) = H(i)X + w(i) , i = 1, 2, · · · , k
(12)
where H(i) = [θi2 , θi , 1] and X = [a, b, c]T .
The least squares estimation is supposed to minimize:
J(X̂) = [ρ − HX̂]T [ρ − HX̂]

(13)

T

where ρ = [ρ1 , ρ2 , . . . , ρk ] , H = [H(1); H(2); . . . ; H(k)],
and X̂ is the estimation of X.
Taking the derivative of J(X̂) with respect to X̂ and setting
the result to zero
∂J(X̂)

(14)
= −2HT [ρ − HX̂] = 0.
∂ X̂
Through solving the previous equation, we obtain the final
least squares estimation
X̂ = (HT H)−1 HT ρ.

(15)

Using the previous equation, we can get X̂ = [â, b̂, ĉ]T , and
then the (k + 1)th contour point can be estimated by
ρk +1 = âθk2 +1 + b̂θk +1 + ĉ.

(16)

D. Dynamic Searching Principle
According to Section II-B, we just need to locate a set of
sparse contour points. Therefore, we do not search for the contour point of every angle. Instead, we search in a set of sparse
angles. The angle difference between two neighboring radial
lines is Δθ. We choose the value of Δθ as follows:
ε
π
(17)
Δθ =
m+n
where m and n are the width and height of the cell image,
respectively, and ε is dependent on the smoothness of the cell

1500

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

boundary. For a smooth cell boundary, ε can be set to a large
value, while for a rough boundary, ε must be a small value. Since
it is difficult to estimate the smoothness of a cell boundary beforehand, ε should be set to a small value to make the searching
algorithm favor both the smooth and the rough boundaries.
From Fig. 8(c), we can find that most of the true edges of
the cell contour are enhanced by our edge enhancement method
in Section III-C, but there are still a few edges left unobvious,
which make the cell contour discontinuous. When our searching algorithm is running, there may be some angles at which
the algorithm cannot find proper contour points. To solve this
problem, we introduce a parameter ϕ, which controls how many
steps the algorithm will continue to search for. In addition, we
use another parameter δ to control the searching zone along the
radial line at the corresponding angle. When the algorithm fails
to find the proper contour point at a certain angle, both ϕ and δ
control the region size where it continues the searching process.
The dynamic searching principle is described as follows. The
whole searching process can be divided into two stages. In
Stage 1, we set ϕ to a small value ϕsm all and set δ to a fixed value.
That is, we use a small fixed searching zone to search for the
contour points that are close to the basic contour points. The execution steps of Stage 1 are briefly summarized in Algorithm 1.
In Stage 2, the execution steps are similar to those steps in Stage
1 except that we set ϕ to a large value ϕlarge and set δ to a
dynamically varying value δd :
 
t
δd = δ × round
(18)
2
where round[ ] is an operator that rounds the element in [ ] to the
nearest integer. Then, the searching zone is [ρe − δd , ρe + δd ],
which is dynamically varying with respect to t. That is, we use
a large dynamic searching zone in Stage 2 to search for the
contour points that are a little far away from the basic contour
points (or the located points in Stage 1).
In each stage, the searching algorithm involves two circular
scanning processes: first, it scans around the nucleus counterclockwise; second, it scans clockwise. Afterward, if the located
contour points corresponding to the same radial line are different, we average their positions to obtain the final contour point
on this radial line. The whole searching process is briefly shown
in Fig. 9.
In our searching algorithm, the angle scanning is performed
step by step, which results in a set of sparse contour points.
Moreover, a dynamic searching principle is introduced into this
algorithm. Therefore, this algorithm is called a DSCS algorithm.
Fig. 10(c) shows some results of this algorithm. We can find that
the contour points located by this algorithm are a set of sparse
points as described by Section II-B, and they are fairly close
to the true cell boundary. However, if we only use a common
searching algorithm without the dynamic searching principle,
many desirable contour points will be lost, which will make
the final results poor, as shown in Fig. 10(a) and (b). On the
contrary, most of the proper contour points (including both the
strong and weak contour points) are detected by the DSCS
algorithm and the final contour successfully converges to the
true cell boundary, as shown in Fig. 10(c) and (d).

Algorithm 1
Initializing:
Set the initial angle θ0 , which is selected according to
the basic contour points;
Set a counter t = 0;
Angle scanning (contour searching):
The angle scanning process starts from θ0 , steps by
increments of Δθ each time, and ends until the whole
circle (2π) has been covered. The algorithm repeatedly
executes the following statements in each loop (each θi ):
if (the contour point at θi has been fixed)
clear the counter (t = 0);
continue to scan the next angle θi+1 ;
else
if (t < ϕsm all )
estimate the position ρe of the contour point at the
current angle θi by the least squares estimation;
set the searching zone to [ρe − δ, ρe + δ] along the
radial line;
if (there are no intensity peaks in the searching zone)
update t = t + 1 and continue to scan the next angle;
else
find the intensity peak (nearest to ρe ) of the radial
edge in the searching zone and set it as the exact
position of the current contour point;
clear the counter (t = 0);
end
else // t reaches its maximum, t = ϕsm all ;
continue to scan the next angle θi+1 ;
end
end
E. Deformation of GVF Snake
In order to further obtain more accurate cell contour extraction
result, we employ the GVF Snake model [21] to extract the final
contour (as Fig. 10(d) shows). We arrange the contour points
located by the DSCS algorithm to construct the initial contour
of the GVF Snake. Due to the complex intensity distributions of
cervical smear images, a few true edges of the cell contour may
be also suppressed by the proposed edge enhancement method
in Section III-C. Therefore, we combine the Sobel gradient edge
map |g | and the enhanced edge map fg de to calculate the final
edge map ffusion , which is used for the deforming of the GVF
Snake, as follows:
ffusion (i, j) = λ × |g (i, j)| + (1 − λ) × fg de (i, j)

(19)

where λ is a weighting parameter that governs the tradeoff between |g | and fg de (λ is set to 0.4 in this paper).
V. EXPERIMENTAL RESULTS AND DISCUSSIONS
A. Datasets
The main purpose of our experiments was to validate the effectiveness of the proposed method for segmentation of both
single cells and overlapping cells. For nuclei segmentation, due

GUAN et al.: ACCURATE SEGMENTATION OF PARTIALLY OVERLAPPING CERVICAL CELLS BASED ON DYNAMIC SPARSE CONTOUR

1501

TABLE I
PARAMETERS SETTING OF THE PROPOSED METHOD
Parameter
ε
μ
δ
ϕsm a ll
ϕla rg e

Value
3
0.1
5
5
8

images. These cervical smear images are from the Herlev dataset
[19]. Dataset 2 contains 182 single-cell images (Dataset 2-A)
and 168 partially overlapping cells images (Dataset 2-B), which
are from our laboratory. The cervical smear images of our laboratory were acquired by an automatic microscopic image acquisition system with a charge-coupled device camera (DAHENG), an optical microscope (Olympus CX31) and a 40×
magnification lens (numerical aperture = 0.65). The initial image size is 800 × 600 pixels (stored in JPEG format). In order to
construct Dataset 2, we manually cropped the initial image to a
small image that contains a well focused cell and a small portion
of the neighboring background (or the neighboring overlapped
cell). The small image size is approximately 270 × 270 pixels.
Fig. 9. Brief illustration of the contour searching process based on the dynamic
searching principle (the original cell image is in Fig. 8 and the dashed radial
line is to be scanned).

B. Cell Segmentation Results
In our experiments, the RGVF Snake [2] was employed for
comparisons. The RGVF Snake is a recently proposed cervical
cell segmentation method, and it is also applied on the Herlev
dataset [19]. The key parameters of the proposed method were
set according to Table I and the rest parameters have been described in the previous sections. The parameters of the GVF
Snake and the RGVF Snake were both set according to those
set in [2]. The proposed method was implemented in MATLAB
R2011b using a Pentium Dual-core 2.6 GHz with 2 GB RAM.
In order to explicitly evaluate the performance of the proposed
method, we employ the Zijdenbos similarity index (ZSI) [29]
and the modified Hausdorff distance (MHD) [30] to test the
accuracy of the segmentation results.
The ZSI is defined as
ZSI = 2

Fig. 10. (a) Contour points located by a common searching algorithm.
(b) Final contour extraction results using a common searching algorithm (inaccurate results are labeled by an arrow). (c) Contour points located by the DSCS
algorithm. (d) Final contour extraction results using the DSCS algorithm.

to the high accuracy of recent studies [2], [3], [7], our experiments did not focus on it, although the nuclei extraction is a
fundamental step described in Section III-B. Therefore, only the
segmentation results of the whole cells are shown for validation
in this section.
Two cervical smear image datasets have been tested in our
experiments. Dataset 1 is composed of 77 single-cell images
(Dataset 1-A) and 65 partially overlapping cells (Dataset 1-B)

#{A1 ∩ A2 }
#{A1 } + #{A2 }

(20)

where A1 is the set of ground-truth cell pixels, A2 is the set of
segmented cell pixels, and #{} is the number of pixels in the
set. This index is similar to the Dice [31] similarity coefficient in
the literature. The ground-truth cell contours of Dataset 1 were
from the Herlev dataset [19], and the ground-truth contours of
Dataset 2 were carefully delineated by an expert cytopathologist. The average ZSI μZSI and the standard deviation σZSI of
the proposed method and the RGVF Snake method on the tested
image datasets are provided in Table II. For single-cell images
(Datasets 1-A and 2-A), the average ZSI values of both methods are higher than 0.95, whereas for overlapping cells images
(Datasets 1-B and 2-B), the average ZSI value of the proposed
method is higher than that of the RGVF Snake, which indicates

1502

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

TABLE II
AVERAGE ZSI AND STANDARD DEVIATION OF EACH DATASET
μZ S I ± σZ S I

Dataset

Dataset 1-A
Dataset 1-B
Dataset 2-A
Dataset 2-B

RGVF Snake

The proposed method

0.9604 ± 0.0402
0.9322 ± 0.0560
0.9512 ± 0.0462
0.9273 ± 0.0595

0.9710 ± 0.0285
0.9595 ± 0.0426
0.9652 ± 0.0302
0.9506 ± 0.0506

TABLE III
AVERAGE MHD AND STANDARD DEVIATION OF EACH DATASET
μM H D ± σM H D

Dataset

Dataset 1-A
Dataset 1-B
Dataset 2-A
Dataset 2-B

RGVF Snake

The proposed method

0.3533 ± 0.6895
1.4910 ± 2.1719
0.3220 ± 0.6525
1.5010 ± 2.6257

0.1891 ± 0.2689
0.5622 ± 0.8675
0.1802 ± 0.2563
0.5795 ± 0.9619

that the contour extraction results of the proposed method are
more similar to the ground true contours.
The MHD is defined as
MHD = max{dM HD (A1 , A2 ), dM HD (A2 , A1 )}
where
dM HD (A1 , A2 ) =


1
min 
a1 − a2 

a 2 ∈A 2
#{A1 }

Fig. 11. (a) Original grayscale cell images from Dataset 1. (b) Ground-truth
cell contours. (c) Cell contours extracted by RGVF Snake. (d) Cell contours
extracted by the proposed method.

(21)

(22)

a 1 ∈A 1

and 
a1 − a2 
 is the Euclidean distance of two pixels in A1
and A2 , respectively. The MHD measures the shape distortion
of the tested contour to the ground-truth contour. Table III lists
the average MHD values of different methods. Although the
average MHD values of both methods are low for single-cell
images (lower than 0.4), the values of the proposed method for
overlapping cells images are significantly lower than that of the
RGVF Snake, indicating that the contours extracted by the proposed method are more close to the ground-truth contours. It
can been seen from Tables II and III that for single-cell images,
both the proposed method and the RGVF Snake perform well,
whereas for overlapping cells images, the proposed method performs better. It should be noted that the standard deviation in
Table III is a little high for overlapping cells images. This is
mainly caused by a few cell images in our tested datasets. These
images contain either too obscure boundaries or high degrees
of cell overlapping. We will discuss about the limitations of the
proposed method in Section V-C.
Figs. 11 and 12 show some contour extraction results of the
proposed method, the RGVF Snake and the ground-truth cell
contours as well. In Fig. 11, the first three cell images contain
cells partially overlapped by neighboring cells, which make
the RGVF Snake converge to the wrong boundaries in the cell
overlapping regions. On the contrary, the cell contours extracted
by the proposed method are more accurate and reliable. For
the single-cell image shown in the last row of Fig. 11, both

Fig. 12. (a) Original grayscale cell images from Dataset 2. (b) Ground-truth
cell contours. (c) Cell contours extracted by RGVF Snake. (d) Cell contours
extracted by the proposed method.

GUAN et al.: ACCURATE SEGMENTATION OF PARTIALLY OVERLAPPING CERVICAL CELLS BASED ON DYNAMIC SPARSE CONTOUR

TABLE IV
AVERAGE EXECUTION TIME (IN SECONDS) OF THE PROPOSED METHOD
FOR DATASET 1
Step
Preprocessing + MF K-means
Edge enhancement + DSCS
Evolution of GVF Snake

Dataset 1-A

Dataset 1-B

21.06
130.76
5.94

21.35
143.16
6.23

the RGVF and the proposed method obtain acceptable contour
extraction results, although the proposed method is slightly more
reliable. In addition, our method is also able to cope with the
cell containing folds, as can be illustrated by Fig. 10(d). The two
cells both contain folds, and the final results extract the whole
regions belonging to the center cells.
The RGVF Snake sets the initial contour of the Snake based
on the rough segmentation result of the spatial K-means [2]
method. This initial contour is actually the rough boundary of the
whole cell region containing both the center cell and parts of its
neighboring cells. Consequently, the Snake can hardly converge
to the true cell boundary because of the interferential edges
in the cell overlapping regions. On the contrary, the proposed
DSCS algorithm provides the GVF Snake with a better initial
contour that is very close to the true cell boundary [see Fig. 10
(c)], and with this initial contour, the GVF Snake is prone to
converge to the true cell boundary. More cell contour extraction
results obtained by our method are provided in Fig. 12. We can
see that the proposed method still works well and successfully
extracts the cell contours, while the RGVF Snake is not able
to extract the cell contours in overlapping cells images. The
experimental results shown in Tables II, III, Figs. 11 and 12
indicate that the proposed method is effective for segmentation
of both single cell and partially overlapping cells in cervical
smear images.
C. Discussions
The five key parameters of the proposed method are ε, μ,
δ, ϕsm all , and ϕlarge as described in Table I. These parameters
were obtained after experiments in 50 randomly selected images
from Datasets 1 and 2, and the numerical evaluation of our
method was based on these parameters setting (in Table I).
Actually, we randomly selected 25 cell images (including 5
single cells and 20 overlapping cells) from each dataset, and
then we took these images as a training set to obtain a proper
value for each parameter. We found that based on the parameters
setting in Table I, 48 images of the training set can be well
segmented, while the results of the rest two images are not so
good. These two images contain either too obscure boundaries
or high degrees of cell overlapping (more than a half of the cell
contour is overlapped).
In order to evaluate the computational efficiency of the proposed method, we used Dataset 1 to test the processing time of
the individual steps (in Table IV) of our method. The average
image size of Dataset 1-A is 270 × 296 pixels, and the average
size of Dataset 1-B is 280 × 302 pixels. From Table IV, we

1503

can see that the edge enhancement and the DSCS steps cost
the majority of the processing time. These steps are especially
designed to cope with the segmentation of overlapping cells.
If the proposed method is optimized in C code, the processing
time would be significantly reduced.
The proposed method is able to cope with the case that half
(or less than a half) of the cell contour is overlapped by other
cells. For the case that more than a half of the cell contour
is overlapped, our method might still work well to obtain a
reasonable cell contour. However, our method is not suitable
for the case that the whole cell is entirely embedded in the cell
clusters, e.g., the last cell in Fig. 1, where no strong contour
points can be found. In addition, our method bears little relation
to how many cells that the center cell is overlapped by. This can
be illustrated by the second row of Fig. 11. The main concern is
that the cell should contain a few strong contour parts.
Also, the proposed method is extendable to cope with two or
more overlapping cells segmentation. To address this topic, we
should first extract each cell nucleus in the image; second, set
each nucleus as a center and adaptively crop the original image
to a small image that just contains the whole cell belonging to
this nucleus; then, the proposed method can be applied to this
small image containing one whole cell; finally, all the extracted
cell contours are combined to obtain the final results. In our
future work, we will investigate this topic to make our method
more reliable for multicell segmentation.
VI. CONCLUSION AND FUTURE WORK
This paper proposes an effective framework for segmentation
of overlapping cells in cervical smear images. After carefully
investigating the geometric structure of a cell contour, we propose to use a set of sparse contour points to approximately
represent the cell contour and consider the cell contour extraction as a contour points locating problem. We first adopt a
MF K-means method to eliminate the small contaminations and
extract the cell nucleus and the background. Then, we propose a
gradient decomposition-based edge enhancement method to enhance the edges of the center cell. Based on the cell nucleus, the
background and the enhanced edge map, we propose a DSCS
algorithm to locate the sparse contour points of the cell. Finally,
we combine the DSCS algorithm with the GVF Snake model to
extract the accurate cell contour. In the experiments, we use the
ZSI and the MHD criteria to evaluate the performance of the
proposed method. Experimental results show that the proposed
method is more accurate and robust than the recently proposed
RGVF Snake [2] for segmentation of partially overlapping cells
in cervical smear images.
The whole process of the proposed method is fully automatic.
The proposed techniques may be also applicable to object contour extraction in other kinds of images. Our future work will
focus on integrating the proposed segmentation method with the
cell region of interest locating method, which aims at extracting
the cell nuclei and the whole cell regions in low-resolution cervical smear images, to make complete segmentation of cervical
cells in practical cervical smear images. Our ultimate goal is to
develop a computer-assisted cervical cancer diagnostic system.

1504

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

ACKNOWLEDGMENT
The authors would like to thank K. Li and W. Liu for their
open RGVF Snake demo.
REFERENCES
[1] T. Kuie, Cervical Cancer: Its Causes and Prevention. Singapore, Singapore: Times Book Int., 1996.
[2] K. Li, Z. Lu, W. Liu, and J. Yin, “Cytoplasm and nucleus segmentation
in cervical smear images using radiating GVF snake,” Pattern Recog.,
vol. 45, no. 4, pp. 1255–1264, 2012.
[3] M. E. Plissiti, C. Nikou, and A. Charchanti, “Automated detection of
cell nuclei in pap smear images using morphological reconstruction and
clustering,” IEEE Trans. Inf. Technol. Biomed., vol. 15, no. 2, pp. 233–241,
Mar. 2011.
[4] S.-F. Yang-Mao, Y.-K. Chan, and Y.-P. Chu, “Edge enhancement nucleus
and cytoplast contour detector of cervical smear images,” IEEE Trans.
Syst., Man, Cybern. B, Cybern., vol. 38, no. 2, pp. 353–366, Apr. 2008.
[5] N. A. Mat-Isa, M. Y. Mashor, and N. H. Othman, “An automated cervical pre-cancerous diagnostic system,” Artif. Intell. Med., vol. 42, no. 1,
pp. 1–11, 2008.
[6] WHO, Comprehensive Cervical Cancer Control: A Guide to Essential
Practice. Geneva, Switzerland: WHO Press, 2006.
[7] A. Genctav, S. Aksoy, and S. Onder, “Unsupervised segmentation and
classification of cervical cell images,” Pattern Recog., vol. 45, no. 12,
pp. 4151–4168, 2012.
[8] P. Bamford and B. Lovell, “Unsupervised cell nucleus segmentation with
active contours,” Signal Process., vol. 71, no. 2, pp. 203–213, 1998.
[9] C. Bergmeir, M. G. Silvente, and J. M. Benitez, “Segmentation of cervical
cell nuclei in high-resolution microscopic images: A new algorithm and
a web-based software framework,” Comput. Methods Programs Biomed.,
vol. 107, no. 3, pp. 497–512, 2012.
[10] N. M. Harandi, S. Sadri, N. A. Moghaddam, and R. Amirfattahi, “An
automated method for segmentation of epithelial cervical cells in images
of ThinPrep,” J. Med. Syst., vol. 34, no. 6, pp. 1043–1058, 2010.
[11] C.-H. Lin, Y.-K. Chan, and C.-C. Chen, “Detection and segmentation of
cervical cell cytoplast and nucleus,” Int. J. Imag. Syst. Technol., vol. 19,
no. 3, pp. 260–270, 2009.
[12] P.-Y. Pai, C.-C. Chang, and Y.-K. Chan, “Nucleus and cytoplast contour
detector from a cervical smear image,” Expert Syst. Appl., vol. 39, no. 1,
pp. 154–161, 2012.
[13] M. E. Plissiti, C. Nikou, and A. Charchanti, “Combining shape, texture
and intensity features for cell nuclei extraction in pap smear images,”
Pattern Recog. Lett., vol. 32, no. 6, pp. 838–853, 2011.
[14] M.-H. Tsai, Y.-K. Chan, Z.-Z. Lin, S.-F. Yang-Mao, and P.-C. Huang,
“Nucleus and cytoplast contour detector of cervical smear image,” Pattern
Recog. Lett., vol. 29, no. 9, pp. 1441–1453, 2008.
[15] H. S. Wu, J. Gil, and J. Barba, “Optimal segmentation of cell images,” in
Proc. IEEE Vis. Image Signal Process., 1998, pp. 50–56.
[16] P. Bamford and B. C. Lovell, “A water immersion algorithm for cytological image segmentation,” in Proc. APRS Image Segmentation Workshop,
Sydney, Australia, 1996, pp. 75–79.
[17] C. Park, J. Z. Huang, J. X. Ji, and Y. Ding, “Segmentation, inference, and
classification of partially overlapping nanoparticles,” IEEE Trans. Pattern
Anal. Mach. Intell., vol. 35, no. 3, pp. 669–681, Mar. 2013.
[18] K. Peng, X. Chen, D. Zhou, Y. Liu, and Y. Zhai, “3-D reconstruction using
image sequences based on projective depth and simplified iterative closest
point,” Opt. Eng., vol. 51, no. 2, pp. 020010-1–021110-10, 2012.
[19] E. Martin, Pap-smear classification, Master’s thesis, Technical University
of Denmark, Oersted-DTU, Automation, Lyngby, Denmark, 2003.
[20] L. Zhang, S. Chen, T. Wang, Y. Chen, S. Liu, and M. Li, “A practical
segmentation method for automated screening of cervical cytology,” in
Proc. Int. Conf. Intell. Comput. Bio-Med. Instrum., 2011, pp. 140–143.
[21] C. Xu and J. L. Prince, “Snakes, shapes, and gradient vector flow,” IEEE
Trans. Image Process., vol. 7, no. 3, pp. 359–369, Mar. 1998.

[22] N. Otsu, “A threshold selection method from gray-level histograms,” IEEE
Trans. Syst., Man, Cybern., vol. SMC-9, no. 1, pp. 62–66, Jan. 1979.
[23] M. E. Plissiti, C. Nikou, and A. Charchanti, “Accurate localization of cell
nuclei in pap smear images using gradient vector flow deformable models,”
in Proc. 3rd Int. Conf. Bio-Inspired Signals Syst., Valencia, Spain, 2010,
pp. 284–289.
[24] J. Canny, “A computational approach to edge detection,” IEEE Trans.
Pattern Anal. Mach. Intell., vol. PAMI-8, no. 6, pp. 679–698, Nov. 1986.
[25] M. Kass, A. Witkin, and D. Terzopoulos, “Snakes: Active contour models,”
Int. J. Comput. Vis., vol. 1, no. 4, pp. 321–331, 1988.
[26] A. Buades, B. Coll, and J. M. Morel, “Self-similarity-based image denoising,” Commun. ACM, vol. 54, no. 5, pp. 109–117, 2011.
[27] R. C. Gonzalez and R. E. Woods, Digital Image Processing, 2nd ed. New
York, NY, USA: Prentice-Hall, 2002.
[28] S. M. Kay, Fundamentals of Statistical Signal Processing: Estimation
Theory. Englewood Cliffs, NJ, USA: Prentice-Hall, 1993.
[29] A. Zijdenbos, B. Dawant, R. Margolin, and A. Palmer, “Morphometric
analysis of white matter lesions in MR images: Method and validation,”
IEEE Trans. Med. Imag., vol. 13, no. 4, pp. 716–724, Dec. 1994.
[30] M. Sezgin and B. Sankur, “Survey over image thresholding techniques
and quantitative performance evaluation,” J. Electron. Imag., vol. 13,
no. 1, pp. 146–165, 2004.
[31] L. R. Dice, “Measures of the amount of ecologic association between
species,” Ecology, vol. 26, no. 3, pp. 297–302, 1945.

Tao Guan received the Master’s degree in information and communication engineering from the National University of Defense Technology, Changsha,
China, in 2009, where he is currently working toward
the Ph.D. degree.
His research interests include medical image processing and computer vision.

Dongxiang Zhou received the Ph.D. degree in information and communication engineering from the
National University of Defense Technology, Changsha, China, in 2000.
He is currently a Professor at the National
University of Defense Technology. His major research interests concern computer vision and image
processing.

Yunhui Liu (F’08) received the Ph.D. degree in mathematical engineering and information physics from
the University of Tokyo, Tokyo, Japan, in 1992.
He is currently a Professor at The Chinese
University of Hong Kong, Shatin, Hong Kong. His
research interests include visual servoing, robotics
and automatic control.

