IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 10, OCTOBER 2015

2421

Accurate Segmentation of Cervical Cytoplasm and
Nuclei Based on Multiscale Convolutional
Network and Graph Partitioning
Youyi Song, Ling Zhang, Siping Chen, Dong Ni, Baiying Lei∗ , and Tianfu Wang∗

Abstract—In this paper, a multiscale convolutional network
(MSCN) and graph-partitioning-based method is proposed for accurate segmentation of cervical cytoplasm and nuclei. Specifically,
deep learning via the MSCN is explored to extract scale invariant
features, and then, segment regions centered at each pixel. The
coarse segmentation is refined by an automated graph partitioning method based on the pretrained feature. The texture, shape,
and contextual information of the target objects are learned to
localize the appearance of distinctive boundary, which is also explored to generate markers to split the touching nuclei. For further
refinement of the segmentation, a coarse-to-fine nucleus segmentation framework is developed. The computational complexity of the
segmentation is reduced by using superpixel instead of raw pixels. Extensive experimental results demonstrate that the proposed
cervical nucleus cell segmentation delivers promising results and
outperforms existing methods.
Index Terms—Cervical segmentation, coarse to fine, graph
partitioning, multiscale convolutional network (MSCN), touchingcell splitting.

I. INTRODUCTION
ERVICAL cancer is one of the common cancers leading to woman’s morbidity and mortality [1]. More than
0.2 million people lose their life due to cervical cancer every
year [2]. In 2008, 85% among 0.53 million new incidents of the
cervical cancer has been found in the developing countries [3].
Pap smear is one of the easiest and most important examination
[4] to significantly reduce the death rate of cervical cancer. The
recently developed H&E stain is more stable and accurate compared with pap smear. Hence, cytology screening via H&E stain
has been widely applied to detect early stages of cervical cancer

C

Manuscript received January 28, 2015; revised April 8, 2015; accepted May
3, 2015. Date of publication May 7, 2015; date of current version September
16, 2015. This work was supported in parts by the National Natural Science
Foundation of China under Grants 61402296, 61101026, 61372006, 81270707,
and 61427806), the 48th Scientific Research Foundation for the Returned Overseas Chinese Scholars, National Natural Science Foundation of Guangdong
Province under Grant S2013040014448, Shenzhen Key Basic Research Project
JCYJ20130329105033277 and JCYJ20140509172609164, and ShenzhenHong Kong Innovation Circle Funding Program JSE201109150013A. Asterisk
indicates corresponding author.
Y. Song, L. Zhang, S. Chen,and D. Ni are with Shenzhen University.
∗ B. Lei and ∗ T. Wang are with the National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for
Biomedical Measurements and Ultrasound Imaging, Department of Biomedical Engineering, School of Medicine, Shenzhen University, Shenzhen 518060,
China (e-mail: leiby@szu.edu.cn; tfwang@szu.edu.cn).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2015.2430895

in the recent decade. However, such diagnosis is heavily dependent on the clinician’s experience, which is extremely time
consuming and is subjected to human error even for experienced
doctors [5].
To address these issues, low-cost and efficient methods using
computer technology have developed to assist doctor’s analysis.
This is particularly useful for underprivileged countries, which
may not have access to highly experienced doctors. Therefore,
development of new automated diagnosis techniques has been
attracting numerous interest lately, which not only alleviates
psychological fatigue of manual inspection, but also reduces
the misdiagnosis and missed diagnosis [6]–[8].
Automatic-assisting methods have played an important role
in nucleus detection of abnormal cervical cells [9], and great
success has been witnessed for cervical cell segmentation [9]–
[14]. Traditional methods assume the input image contains only
a single cell so one boundary or at most two boundaries are
considered. This assumption is not realistic as one cannot make
any assumption about the number of cells. Besides, multiple
touching cervical cell splitting is quite challenging. Complicated cases such as the irregular cross-lined leukocytes, dust,
impurities, and uneven illumination make nucleus segmentation even more difficult. The existing touching nuclei splitting
algorithms are not feasible, and cervical cell segmentation used
in clinical application is still immature. In view of these challenges and limitations of the existing methods, it is essential to
develop a new automatic tool for cervical nucleus and cytoplasm
segmentation.
To obtain this goal, a multiscale convolutional network
(MSCN) is investigated to densely extract a myriad of multiscale feature vectors for nucleus region detection [15]. To reduce segmentation complexity, superpixels are utilized instead
of the raw pixels. In superpixels, similar pixels are clustered
into regularly spacing. Hence, the texture, shape, and contextual information are also captured to evaluate the likelihood of
a superpixel belonging to a certain part of the target structure.
In addition, graph partitioning is also integrated with superpixels to refine the coarse segmentation [16]. Differing from the
previous graph-partitioning method using only local statistical
information, the global information is also integrated for improved segmentation.
To improve segmentation performance, touching cervical nuclei splitting plays a more significant role as compared to single cell segmentation. To achieve this goal, a marker via distance transform and adaptive threshold is constructed using an
unsupervised clustering method instead of using concave points

0018-9294 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

2422

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 10, OCTOBER 2015

applied by existing methods. This method is fast and has the
capability to segment cells with or without unclear concave
point. In addition, shape, color, and geometrical information are
effectively incorporated to measure the evidence from different markers. According to some concave point, the toughing
nucleus is split based on the marker via shape and color information clustering. As a result, the limitations of the previous
works such as poor stain, low contrast, and low illuminations
are also resolved.
In this study, a deep-learning based method via the MSCN
is developed for segmentation using a powerful feature representation. The main contributions of the proposed method are
mainly fourfolds: 1) MSCN for the feature extraction; 2) graph
partitioning for nucleus segmentation; 3) postprocessing via the
prior knowledge; and 4) the touching nucleus splitting based on
the marker.
II. RELATED WORK
A. Cervical Cell Segmentation
There is a myriad of the literature available for the cervical cytoplasm and nucleus splitting, which includes the widely
used morphology operation [15], edge detection [14], k-means
[11], [16], thresholding [12], [17], difference maximization [11],
Hough transform [17], watershed [12], [18], [19], parameter fitting [20], and active contour model (ACM) [16], [21]. However,
most of these approaches were developed for isolated cell only,
hence such approaches are inapplicable for multiple nuclei splitting in the field-of-view images.
For segmenting cytoplasm and nuclei with multiple cells,
Genctav et al. [12] proposed an unsupervised method for cervical cell segmentation using multiscale watershed. Bergmeir
et al. [17] utilized the Canny edge operator to detect edges between the nucleus and cytoplasm first. Then, shape and prior
knowledge were explored for cytoplasm boundary separation.
Finally, the Hough transform was developed to localize the
boundary for nucleus segmentation. Zhang et al. [13] proposed
to segment the cytoplasm region with a multithresholding Otsu
method. The nuclei were segmented using a local adaptive graph
cut approach.
Although these methods can obtain good cytoplasm and nuclei segmentation performance, these methods were developed
on healthy rather than a mix of pathological and healthy cells.
Due to the difference in shape, size, chromatin among differentpathological cells, these methods cannot be applied to nucleus segmentation when both healthy and cancerous cells are
coexisting.

retrieval, and object classification fields [23], [24]. For example, the CNN was applied for segmentation used in binary image restoration [25]. In [26], CNN segmented the H&E stained
breast cancer using multichannel input. In [27], the deep CNN
was implemented for neuronal membrane segmentation. In [22],
feature extraction by the CNN was applied for scene labeling.
In [28], an affinity graph for image segmentation was achieved
by the deep learning method.
C. Segmentation by Graph Partitioning
The ACM and level set methods have been widely applied
for image segmentation [29], [30], but these methods require
individual initialization, shape prior, and contour knowledge,
hence, the performance of these methods degrades when applied to intersecting objects without distinctive contours. Moreover, occlusion in objects degrades performance as well. As the
pathological and healthy nuclei simultaneously exist with various shapes and sizes in full resolution H&E stained image, a
large number of overlapping nuclei render proper initialization
and shape definition to be quite challenging and impractical.
Graph partitioning is gaining popularity in the recent decade,
and state-of-the-art performance [31], [32] is achieved with
graph partitioning in the natural image field. Differing from the
level set and ACM, the complexity of graph partitioning is not
affected by the number of target objects. In the graph partitioning modeling, every node in the graph corresponds to the pixel,
voxel, superpixel, or supervoxel [22], [33]. The nodes and edges
of each graph [34], [35] are defined as the global objective function in graph partitioning approaches. By the max-flow\min-cut
algorithm [36], the energy function is minimized to separate the
foreground and background. The shape prior [37] learned from
shape information [33] and manual annotation [38] can integrate the local image into the graph partitioning framework, and
hence, more robust results are achieved.
D. Touching Nuclei Splitting
The splitting of touching nuclei is important for quantitative
analysis of histopathological images because feature quantification is carried out on single cells before these cells are categorized using classification algorithms. The popular widely used
touching nucleus splitting include the watershed [39], [40], gradient and edge detection [41], ACM [30], [42], morphological
erosion [43], sliding band filter [44], and concave point [8],
[45]–[47].
III. METHODOLOGY
A. MSCN Feature Representation and Coarse Segmentation

B. Convolutional Networks in Image Segmentation
The hierarchical representation based on the pixels, edgelets,
motifs, parts, and objects has been extensively applied in the
computer vision field. The convolutional neural network (CNN)
is able to learn the hierarchical feature and provide a simple
architecture [22], and hence, notable success has been achieved
recently using the convolutional networks in the advanced computer vision, pattern recognition, image segmentation, object

The traditional single scale convolutional network (SSCN)
for segmentation suffers from two main problems: 1) different gray intensity information has a small distance in a small
window, which cannot provide enough information for cell detection and 2) large window can achieve this goal but it is highly
computational intensive. To tradeoff this, an MSCN method is
investigated. The MSCN integrates large contexts into local
decisions, but the parameter or dimensionality still remains

SONG et al.: ACCURATE SEGMENTATION OF CERVICAL CYTOPLASM AND NUCLEI BASED ON MULTISCALE CONVOLUTIONAL NETWORK

Fig. 1.

2423

Illustration of the MSCN structure.

Fig. 2. Framework of the proposed segmentation system. Raw input image is transformed through a dyadic Gaussian pyramid. Each scale is fed to a one-stage
convolutional network to generate a set of feature maps. The feature maps of all scales with a large contextual window around each pixel are concatenated together.
The superpixel method is also explored based on the color and shape information. Final segmentation is produced by graph partitioning, and touching nucleus is
separated by the marker.

2424

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 10, OCTOBER 2015

Fig. 3. (a) Color image with original resolution; (b) graph partitioning; (c) postprocessing. Boundaries of cytoplasm and nuclei delineated are marked as pink
and blue, respectively.

manageable. The MSCN is composed of multistage trainable
architecture and each stage includes a filter bank layer, nonlinearity layer, and feature pooling layer; the MSCN structure is
illustrated in Fig. 1. Fig. 2 shows the detailed framework of our
proposed method.
Specifically, for each input image I, a multiscale pyramid
of images Is ∀s ∈ {1, . . . , N }, is constructed using the dyadic
Gaussian pyramids, where I1 and I have the same size. For
each scales, the image’s raw pixels are used to train the MSCN.
Given a classical convolutional network Ns with parameters ωs ,
a network Ns with L layers, we have
Ns (Is ; ωs ) = WL HL −1

(1)

where the vector of hidden units at layer lis
Hl = pool(tanh(Wl Hl−1 + bl )).

(2)

For all l ∈ {1, . . . , L − 1},with bl , a vector of bias parameters
and H0 = Is , Wl are Toeplitz matrices. Each hidden unit vector
Hl can be expressed as a regular convolution between kernels
from Wl and the previous hidden unit vector Hl−1 , squashed
through a tanh function, and pooled spatially

Hlp = pool(tanh(blp +
Wlpq ∗ Hl−1,q )). (3)
q ∈parents(p)

The filters Wl and biases bl are trainable, in our experiments,
the function tanh is a pointwise nonlinearity, pool is a function that we use max-pooling operator to take the maximum
activation within the neighborhood.
The final feature extraction is based on N network output and
upsampled to be the same size of f1 .
F = [f1 , u(f2 ), . . . , u(fN )]

(4)

where u is the upsample function.
After feature extraction, a two-layer neural network is used to
produce the correct categorization for all pixel locations i from

the feature vectors Fi .
yi = W2 tanh(W1 Fi + b1 )

(5)

where W1 and W2 are the trainable parameters of the classifier,
b1 is a vector of bias parameters. We compute the normalized
predicted probability distributions over classes Ĉi,a by
Ĉi,a =

ey i , a


ey i , b

.

(6)

b∈classes

By minimizing the cross-entropy between predicted class distribution Ĉi,a and the target class distribution, Loss function
penalizes their deviation and denoted as


Ci,a ln(Ĉi,a ).
(7)
Loss = −
i∈pixels a∈classes

The true target probability Ci,a of class a being present at
location i is a hard target vector.

1,
i ∈ a,
Ci,a =
(8)
0, otherwise.
Finally, a coarse segmentation is acquired to assign each pixel
by maximizing the prediction at its location in pixel i.
Pi = argmaxĈi,a .

(9)

a∈classes

B. Fine Segmentation by Graph Partitioning
The resulting segmentation P , although fairly accurate, is not
visually satisfying as it lacks spatial consistency, precise delineation of objects, and does not involve a global understanding of
full image. In this section, we implemented a graph partitioning
model to address this problem. Moreover, superpixels instead
of pixels are implemented to reduce the computational cost and
memory requirement.

SONG et al.: ACCURATE SEGMENTATION OF CERVICAL CYTOPLASM AND NUCLEI BASED ON MULTISCALE CONVOLUTIONAL NETWORK

2425

1) Superpixels: To efficiently compute superpixel, the simple
linear iterative clustering (SLIC) [48] method is selected due to
the smoothed boundaries of the regular shape of images. SLIC
takes advantage of the color similarity and the spatial information in the pixel to cluster the image. In SLIC, initial cluster
centers are sampled on a regular grid. The center is first moved
toward the lowest gradient position in a 3 × 3 neighborhood,
iterative K-means clustering is then applied on the feature space
that combines pixel locations and color information, the iteration continues until the distance between the new centers and
previous ones is small enough.
2) Graph Partitioning: This method minimizes a global objective function defined on an undirected graph G = (V, E),
with vertices v ∈ V and edge e ∈ E ⊆ V × V . Each superpixel in the image is associated with a vertex, and each edge is
added between every neighboring node. In our study, the energy
function is defined as


ψ(yk |xk ) + λ
φ(yk , yl |xk , xl ) (10)
E(y|x, λ) =
k ∈V

(k ,l)∈E

where yk ∈ {0, 1, 2} is a class label assigned to superpixel k
corresponding to the background, cytoplasm, and nucleus. The
unary term ψ enforces the agreement between the node’s label
yk and the prediction xk , the pairwise term φ enforces regularity
or local consistency between labels of neighboring node k and
l, and the weight λ controls the relative importance of the two
terms. The unary term is denoted as
ψ(yk |xk ) = exp(−αD̂k )

(11)

where D̂k is the pixelwise distributions at superpixel k that are
predicted from (9)
D̂k ,a =

1 
Pi,a
s(k)

(12)

i∈k

where s(k) denoting the area of superpixel k. The pairwise term
is represented by

yk = yl
exp(−β |meank −meanl | ,
φ(yk , yl |xk , xl ) =
0,
otherwise
(13)
where meank is the mean intensity value within the superpixel
k, details on the parameters λ, α, β shall be given in the experimental section of this paper. The energy is minimized using a
fast min-cut/max- flow algorithm [36], [49].
3) Postprocessing: To reduce the errors due to the similarity
about the blood, mucus, inflammatory cells, dust, powder, and
nuclei, the following prior knowledge is introduced. First, the
nucleus should be surrounding by cytoplasm. Second, if there is
only background area around the candidate nuclei, the candidate
nuclei is noise. Third, the area of cell (including cytoplasm and
nuclei) should be higher than a prespecified value (i.e., 1000).
Namely, if the area of a whole cell is lower than the specified
value, this region is regarded as noise. The effect of this approach
is illustrated in Fig. 3.

Fig. 4. (a) Original image; (b) inner-distance map; (c) markers obtained from
adaptive threshold of inner-distance map; (d) zoomed green box region from
(c), noted different markers with different colors; (e) markers after clustering
of the (c), same cluster of markers have the same color; (f) results of splitting,
nuclei boundaries and splitting lines are marked as pink and white, respectively.

C. Touching Nucleus Splitting by Markers
The MSCN and graph partitioning algorithm given in the
previous section can accurately separate cytoplasm, nuclei, and
background regions. However, we frequently observe wide ranging degrees of nuclei overlaps in result images. For the quantitative analysis of cervical cell’s abnormal degree, a novel robust
nuclei clump splitting algorithm is proposed in this section.
Our touching nucleus approach is splitting based on markers,
and the number of markers decides if there is any overlapping
of nuclei. From Fig. 4, it can be seen that there is no need to
determine if there is any overlapping of the nuclei. The nuclei
at different stages have different shapes, and hence, avoid the
splitting error by the prior judgment error.
1) Marker Finding: Since the shape of a cervical nucleus
is convex, each center of object’s nucleus should have local
maximal distances to the boundaries in the overlapping clump.
Therefore, the distance transform or inner-distance map is utilized to compute markers corresponding to the center of the
nuclei. The inner-distance transform of a nucleus pixel p is defined as
D(p) = min p −q
q ∈E

(14)

where • is the Euclidean distance and pixel q is an element
of the set of nucleus’ edge pixels.
To find markers of the image in the inner-distance map, we
check the criteria: whether the current pixel value is greater than
or equal to any of its neighbors in the 3 × 3 region. However,
the noise point may become a local maximum. To overcome
this, a global threshold T is designed to eliminate the impact of

2426

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 10, OCTOBER 2015

noisy pixels and is given as
T = μM (p) − (maxD(i) + minD(i) −2M (p)) (15)
i∈M

i∈M

1 
D(i)
M (p) =
N

(16)

i∈M

where μ is the adjusting parameters, M is the set of markers, and
N is the number of pixel i belong to the markers M. As a result,
if the marker’s distance is smaller than T, it will be removed.
2) Marker Clustering: From Fig. 4(c) and (d), we observed
that each target can have several markers, and hence, different
markers from the same target should be fused into one marker.
Differing from the seed filtering, the main difficulty is that the
final numbers of the markers are unknown beforehand. In view
of this, an unsupervised clustering method is implemented, and
the shape and geometrical information are combined together
to improve the clustering accuracy on the markers.
In the clustering process, the measure evidence distance between marker mi and mj to decide the final clustering effect is
defined as
g(mi , mj ) =

min

p∈m i ,q ∈m j

p −q .

(17)

Instead of using hard threshold or grid search, an adaptive
threshold is adopted to find conditions in our experiment, which
is defined as
g(mi , mj ) ≤

min

p∈m i ,q ∈m j

(D(p), D(q)).

(18)

The overlapping nuclei might lose the original distance information with the conventional unsupervised clustering method
since the cluster centroids are used as the new clusters. For the
proposed method, the original significant marker is kept, and
the pixels from the two classes mi and mj are clustered as a
new cluster, which is shown in Fig. 4(e).
3) Splitting Based on Shape and Color Information: After
obtaining the correct markers, the simplest way to find the split
line between touching objects is to use the nearest-neighbor
assignment, which assigns each pixel to its nearest marker.
However, this method causes unnatural object boundary and
is inaccurate when there are too many variations on the object
sizes. Therefore, the gradient-barrier watershed algorithm [40],
which incorporates geometric and intensity information to effectively determine the natural boundary is adopted in our method.
However, oversegmentation errors occur when the nuclei are
poorly stained and internal structure of the nucleus has been
modified. To solve this limitation, the effective evidence from
pixel to marker association is proposed. The effective evidence
L(p, mi ) between pixel p and marker mi is defined as
L(p, mi ) = η D(p) − min D(q) + υ Ip −mi 
q ∈m i

(19)

where Ip is the mean intensity value of the 5 × 5 patch centered at pixel p, mi is the mean intensity value of marker mi
in the inner-distance map, and η and υ are adjusting weight
parameters. Finally, the pixel p is assigned by
S(p, mi ) = argmin L(p, mi ).
m i ∈m arkers

(20)

Fig. 5.

Illustration of sample train set in image boundaries by mirroring.

IV. EXPERIMENTAL RESULTS
A. Clinical Data Collection
The materials used in our experiments are collected from
the Sixth People’s Hospital of Shenzhen based on 200 female
subjects aged from 22 to 64. All the materials used in this experiment have been approved by the Ethics Committee of the
Sixth People’s Hospital of Shenzhen, and informed written permission is obtained from each participant. A total of 53 slides
are collected using the Olympus BX43 microscope at a magnification rate of 40. 21 images (15 images contain abnormal and
6 images contain normal nuclei only) are chosen for our evaluation. The ground truth of cytoplasm and nucleus segmentation
was obtained by manual delineation by a pathologist with more
than 15 years of residency. All slides were prepared using a
manual liquid-based cytology technique stained with H&E, and
confirmed by biopsy.
B. Parameters and Implementation Details
1) MSCN Feature Extraction: The MSCN includes three layers. The first two layers are composed of a bank of filter size
11 × 11 followed by tanh units and 2 × 2 max-pooling operations, the third layer is the full connection layer. The input image
is transformed into the YUV color space, the pyramid includes
three different scales: 1024 × 1360, 512 × 680, and 256 × 340.
Each pixel is centered in the 32 × 32 region as the network input. When a pixel is close to the image border, its window will
include pixels outside the image boundaries, such pixels are
synthesized by mirroring the pixels in the actual image across
the boundary (see Fig. 5).
Three different scales, Y, U, V spaces, all nine convolutional
network are trained parallel, dimension of the filtering is obtained via grid search. The final Y channel is eight dimensions,
U is six dimensions, and V is two dimensions. There are a total
of 5 650 background, 8 590 cytoplasm, and 8 560 nucleus pixels
as the training sample.
2) Graph Partitioning: The SLIC method has two main parameters involved: the area of the superpixels and the balance
parameters to control compactness of the superpixel. If the area
value is too big, the small nucleus will become invisible. On
the other hand, when the value is too small, it will increase the

SONG et al.: ACCURATE SEGMENTATION OF CERVICAL CYTOPLASM AND NUCLEI BASED ON MULTISCALE CONVOLUTIONAL NETWORK

2427

TABLE I
MEAN AND STANDARD DEVIATION OF DSC OF CYTOPLASM SEGMENTATION
PERFORMANCE COMPARISON BETWEEN PROPOSED METHOD AND OTHER
METHODS

Mean
Std.

Fig. 6.

Method

computation burden and lose the function of voting. Finally, the
area value is empirically set as 10.
As for balance parameters, small superpixel regions usually
have irregular shapes, whereas big superpixel cannot capture the
boundary very well. Thus, this value is set as 0.1 empirically.
The neighborhood superpixel is defined as a common edge of
these areas (see Fig. 6). Since the superpixel area is set as 10,
the perimeter is approximately 12 pixels, the value of common
edge is set as 2. To construct the pairwise term, the input image
is converted to grayscale image for evaluating the superpixel
region’s similarity. In our graph, λ = 120, α = 0.1, and β = 20
obtains the best performance with grid search.
3) Postprocessing: For each candidate nucleus clump, the
area of each class in the ring region obtained by morphological
dilation with the structure element is selected as a disk. A radius
of 5 pixels is empirically selected in this paper. If the area ratio
of background and cytoplasm is higher than 3, we filter the
nucleus clump, and we filter the cell if the whole cell region’s
area is lower than 1000 pixels.
4) Touching Nucleus Splitting: There are three parameters
involved to avoid the noise interference. The global threshold T
is added if the value is lower than 0, which indicate that most
candidate markers have large distance values, and large weight
for M (p) should be added for a global threshold T. Based on
empirical value and the experiments, μ is set as 0.8.
In the process of splitting, η controls the shape information
for the weight in the distance measure L(p, mi ),υ is the weight
for the color information. The color information is calculated
based on the R, G, and B channels and get the sum values. η
and υ is set as 0.8 and 0.2 by cross validation, respectively.
C. Evaluation of Cytoplasm Segmentation
1) Evaluation Metric: Full resolution images consist of multiple cells, hence, a matching step is required to find the correspondences between the resulting segments and the ground
truth. However, reliable delineation of the cytoplasm boundary
for each cell is unrealistic even for human experts in the presence of heavily overlapping cells. Therefore, the dice similarity
coefficient (DSC) [50] is used to evaluate the performance as
follows:
|AGT ∩ Aseg |
|AGT | + |Aseg |

[8]

Ours

0.64
0.26

0.93
0.3

0.95
0.18

TABLE II
COMPARISON OF AVERAGE NUCLEUS BINARIZATION PERFORMANCE USING
PIXEL-BASED CRITERION

Illustration of neighboring superpixels.

DSC = 2

[12]

(21)

[16]
[51]
[8]
Ours

All Nuclei

Abnormal Nuclei

PPV

NPV

F1

Ovel

PPV

NPV

F1

Ovel

0.52
0.79
0.85
0.94

0.77
0.67
0.90
0.92

0.598
0.710
0.873
0.912

0.45
0.57
0.78
0.87

0.62
0.77
0.88
0.90

0.86
0.61
0.91
0.91

0.688
0.627
0.884
0.897

0.56
0.52
0.81
0.83

TABLE III
COMPARISON OF AVERAGE NUCLEUS BINARIZATION PERFORMANCE USING
OBJECT-BASED CRITERION

Mean
Std.

[16]

[51]

[8]

Ours

0.80
0.35

0.78
0.14

0.99
0.01

0.99
0.01

where AGT and Aseg denote the manual “ground truth” and the
segmented cytoplasm, respectively, |•| is the number of pixels
in a certain region DSC ∈ [0, 1]. A higher DSC value indicates
better segmentation performance.
2) Comparison With Other Methods: The performance of the
proposed method is further compared with methods in [8] and
[12]. Since both algorithms segment the cytoplasm first, and
then, the nucleus, to objectively evaluate the performance, the
cytoplasm performance evaluation is based on the common area
between nuclei and cytoplasm.
Table I summarizes the mean and standard deviation of the
DSC for the selected three methods. Compared with [12], the
DSC mean and standard deviation are improved by 48.44% and
reduced by 30.77%, respectively, using the proposed method.
The reason of degradation with [12] is that the images used in
their experiments did not have the abnormal and normal nuclei, and the difference between nuclei and background is quite
obscure. The images in [12] have low contrast, poor illumination, and only the color space transform and morphological
operation are utilized. These reasons led to poor segmentation
performance. The images used in our method are collected automatically without manual intervention. Both normal and abnormal cells exist in our dataset, which enhances the algorithm’s
generalizability.
Compared with [8], the DSC mean is improved by 2.15%,
but the standard deviation is decreased by 40.00%. Although
the mean DSC value is not improved significantly, the low
standard deviation means that the segmentation performance is

2428

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 10, OCTOBER 2015

TABLE IV
COMPARISON OF ABNORMAL NUCLEUS BINARIZATION PERFORMANCE
BY GRADING F1-MEASURE
Method
[16]
[51]
[8]
Ours

% Poor

% Acceptable

% Very accurate

45.3
48.4
6.2
9.6

54.7
51.6
93.8
90.4

17.2
20.3
51.6
60.2

Fig. 7. Comparison of the nuclei segmentation under different algorithms.
From left to right: (a) original images, (b) ground truth, (c)–(f) segmentation
results by [16], [51], [8], and the proposed method.

relatively stable as compared to the method in [8]. Also, there is
no color selection and noise filtering, which is more generalized
compared with that with it.
D. Evaluation of Nuclei Segmentation
1) Evaluation Metric: To evaluate nucleus segmentation, a
pixel-based and object-based criterion is used. In the pixel-based
criterion, the positive predictive value (PPV), negative predictive
value (NPV), F1 measurement (F1), and overlapping ratio (Ovel)
are adopted for the objective evaluation of the segmentation
ratio. These metrics can be used to evaluate all the nuclei in
the image and each abnormal nucleus individually. Moreover,
the pixel-based criterion serves as a basis for designing the
object-based criterion. Nucleus detection was considered as a
true positive if its NPV was higher than 60%.
To better evaluate the segmentation performance of the abnormal nucleus, we graded the F1 values, F1 value below 0.75

TABLE V
EVALUATION OF SPLITTING PERFORMANCE
Image
ID

No.
cells

1
104
2
68
3
72
4
107
5
75
6
62
7
198
8
144
9
86
10
61
11
384
12
85
13
296
14
236
15
287
16
261
17
391
18
346
19
171
20
157
21
75
Total
3666
Percentage

Correct
split

Under
Split

Over
Split

Error

PPV

NPV

97
62
67
105
73
50
184
133
81
58
353
81
274
227
265
237
366
307
158
145
65
3388
92.42

4
2
3
1
1
5
6
5
3
1
20
1
10
7
15
20
21
26
10
8
4
173
4.72

0
1
0
0
0
1
1
0
0
0
1
2
2
0
1
2
0
1
0
0
1
13
0.36

2
1
1
0
0
3
3
3
1
1
6
0
8
2
6
2
4
8
2
1
1
55
1.50

1.000
0.984
1.000
1.000
1.000
0.980
0.995
1.000
1.000
1.000
0.997
0.976
0.993
1.000
0.996
0.992
1.000
0.997
1.000
1.000
0.985
0.996

0.960
0.969
0.957
0.991
0.986
0.909
0.968
0.964
0.964
0.983
0.946
0.988
0.965
0.970
0.946
0.922
0.946
0.950
0.940
0.948
0.942
0.951

is unacceptable, above 0.75 is acceptable, and between 0.9 and
1 is very accurate, and then, calculated the percentage of the
number of abnormal nuclei in each range. The percentage is
summarized in Table IV.
2) Comparison With Other Methods: The performance is also
compared with the related works [8], [16], [51]. Table II shows
the average nucleus binarization performance using pixel based
criterion. Compared with [16], F1 and Ovel exhibit improvement of 52.51% and 93.33%, respectively, which shows the
superiority of the proposed method over the existing methods
for pathological and normal nucleus segmentation.
Table III compares average nucleus binarization performance
using object-based criterion. Compared with [16], it can be
observed that the mean value is improved by 23.75% among
all the evaluation, and the mean value is improved by 250.00%.
The accepted ratio is improved by 65.27%, and the unaccepted
ratio is decreased by 78.81% as shown in Table IV.
The improvement of the proposed method is attributed to its
high suitability for single nucleus segmentation, and hence, the
contrast between cytoplasm and nucleus is very obvious. In the
full resolution image, the uneven stain, various life span of the
nucleus, the decreasing ratio of different nucleus increases the
challenges of segmentation even for an expert based on contextual information of a small region. Meanwhile, the multiscale
technique increases the number of large contextual window and
segmentation accuracy.
Similar to our method, Zhang et al. [8] and Al-Kofahi et al.
[51] employed the graph partitioning method based on the Poisson distribution assumption. It can be seen that F1 and Ovel
are improved by 4.47% and 11.54% compared with [8], respectively. Besides, the proposed method is superior over the abnormal nuclei segmentation, and is slightly better than method in

SONG et al.: ACCURATE SEGMENTATION OF CERVICAL CYTOPLASM AND NUCLEI BASED ON MULTISCALE CONVOLUTIONAL NETWORK

2429

Fig. 8. Examples of spliting touching cell clumps: for each triplet, right image corresponds to the split result for each candidate nuclei, middle image corresponds
to the final markers, left image is the original image. Note that some images have been rescaled for better viewing.

Fig. 9. Automatic segmentation results for full cervical cell images. Upper two images contain abnormal cells, while lower two are normal cases. Boundaries of
the cytoplasm and nuclei and the split lines are marked as pink, blue, and white, respectively.

2430

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 10, OCTOBER 2015

TABLE VI
PERFORMANCE OF OUR SEGMENTATION ALGORITHM USING PIXEL-BASED
CRITERION
Method

Cytoplasm

SSCN
MSCN
MSCN + superpixels
MSCN + graph partitioning

Nuclei

Mean

Std.

Mean

Std.

0.62
0.79
0.83
0.90

0.34
0.18
0.17
0.21

0.57
0.77
0.79
0.85

0.32
0.22
0.24
0.18

TABLE VII
RESULT OF SPLITTING ALGORITHM
Algorithm
Classical clustering + effective distance
Our clustering + shape information
Our clustering + effective distance

Correct split Under Split Over Split
61.6%
79.4%
90.2%

8.1%
4.4%
4.4%

3.2%
1.2%
1.2%

Error
27.1%
15.0%
4.2%

[16]. The accurate ratio is improved by 16.67%, the acceptable
ratio is improved by 3.62%, and the unacceptable ratio is improved by 54.84%. The main reason for the good performance
in [8] confirms the effectiveness of the coarse to fine segmentation algorithm. The performance improvement in [8] is due to
the introduction of the graph partitioning, which improves both
the local and global learning ability.
Compared to [51], F1 and Ovel are improved by 28.45%
and 52.63%, respectively. This method is also superior over the
abnormal nuclei segmentation, and slightly better than method
in [16]. The high accurate ratio is improved by 196.55%, the
acceptable ratio is improved by 75.19%, and the unacceptable
ratio is improved by 80.17%.
Fig. 7 shows six sample results by [8], [16], and [51] and the
proposed method. The proposed method achieves good segmentation performance even under low contrast, highly overlapping,
and poor stained cases. The comparisons under different cases
demonstrate the superiority of our proposed method over existing methods. The preliminary explanation is that the hierarchical
architectures enhance internal representation with the learned
robust feature. The MSCN not only increases large contextual
window, but also integrates numerous contextual information
to globalize the graph partitioning. These techniques increase
consistency of superpixel regions for segmentation, and hence,
the proposed algorithm obtains better performance.
E. Evaluation of Splitting
Under-splitting, over-splitting, and encroachment errors are
selected to evaluate the performance of the splitting of touching
nucleus. Under splitting refers to no splitting for the overlapping
nucleus, over splitting refers to placement of a boundary within
a single nontouching cell, and the encroachment error refers to
incorrect nucleus splitting. Table V illustrates the segmentation
results based on a total of 21 images. The experimental results
based on the average results of three pathological doctors are
also presented here.

In a total of 21 images, the image IDs: 1, 2, 3, 4, 5, 6, 9, 10,
12, and 21 are slightly overlapped images with a few nuclei.
The total nucleus numbers are less than 107, and the touching
nuclei is less than 20. In the touching nuclei, most of them have
less than five nuclei, and only a few of them have 7–10 nuclei.
The worst segmentation result is image ID 6, 52 out of 62 nuclei
are split correctly, whereas others achieved more than 91.18%
splitting rate.
Image IDs: 7, 8, 14, 16, 19, and 20 have slightly overlapping nuclei, and the true nuclei is within 144 ∼ 261. With the
increase of the touching nuclei, the overlapping becomes more
complicated. Image ID 14 produces the best results, and the true
nuclei is within 144 ∼ 261. The correct splitting ratio is 96.19%,
the worst ratio of 90.80% is obtained with image ID 16, and the
average splitting ratio is 92.84%.
The rest of the images (IDs: 11, 13, 15, 17, and 18) have heavily overlapped nuclei, the true numbers of nuclei is between 287
and 391, the overlapping nuclei is more than 35, and the overlapping cases are quite complicated. For this image, the best
performance is 93.61%, the worst is 88.73%, and the average
is 91.83%. Fig. 8 shows numerous examples of split touching
clumps, and it is clear that the proposed method satisfies the cervical overlapping nuclei’s splitting requirement for quantitative
analysis of cervical cell’s abnormal degree.
Fig. 9 shows four full-segmented images where the upper
two images are abnormal images and the bottom images are
normal images. Regarding the overlapping of nuclei, the upper
two images contain intermediate touching, whereas the bottom
two images contain just slightly overlapping. It can be seen that
the proposed method addresses the segmentation problem even
in the poor-illuminated case. For the low contrast, the proposed
method achieves great segmentation performance under inappropriate staining. In the nuclei detection, most of the nuclei are
detected correctly. For the touching nuclei splitting, less than
four nuclei touching cases can be split effectively. From the
aforementioned statistics, the proposed method not only accurately segments the cytoplasm and nucleus, but also accurately
separates the touching nuclei, which will be quite beneficial for
the cervical cancer screening.
V. DISCUSSIONS
A. Effect of MSCN
Although the CNN can complete the image segmentation
task, the traditional CNN has large window size, which leads
to high computational cost. A small window can only provide
poor observation basis and lead to low classification accuracy.
In view of these observations, the spatial pyramid is adopted
in our method to preserve more textual, shape, and contextual
information without changing window size parameter than a
single window. Table VI shows the segmentation accuracy of
SSCN alone, MSCN, and MSCN with superpixels and graphpartitioning method. In terms of DSC, the MSCN statistical results shows segmentation performance is improved by 27.42%,
and the nucleus segmentation accuracy is improved by 35.09%
compared with SSCN, and hence, the MSCN is able to improve
the segmentation performance.

SONG et al.: ACCURATE SEGMENTATION OF CERVICAL CYTOPLASM AND NUCLEI BASED ON MULTISCALE CONVOLUTIONAL NETWORK

2431

Fig. 10. Examples of failure by our method: (a) erroneous segmentation of some cytoplasm due to poor staining and contrast (green box), (b) erroneous
segmentation of some nuclei (red arrow), (c) erroneous split line (green box).

B. Effect of Superpixel
The MSCN is capable of increasing the field-of-view to obtain texture, shape, and context information. The superpixel
method is an effective way and standard approach. By using the
superpixel, the cytoplasm segmentation accuracy is improved
by 5.06%, the nucleus segmentation accuracy is improved by
2.60%. Therefore, the superpixel has a positive effect on the
segmentation performance.
C. Effect of Graph Partitioning
To further improve the segmentation performance, the graphpartitioning method is integrated. Superpixel replaces the pixel
to reduce the computation time, and the limited local learning
ability is improved by integrating global learning ability. After
graph partitioning, the performance is further improved, the
consistency of the neighboring superpixel is further improved
as well.
As shown in Table VI, the cytoplasm performance is improved
by 13.92%, and the nucleus segmentation accuracy is enhanced
by 10.39%, respectively, using graph partitioning.
D. Effect of Marker and Clustering
A new marker usually poses a representation problem in unsupervised clustering, and the fused clustering distance is used
as the new clustering center. But this method ignores the original
distance information, which leads to the new clustering center
unable to satisfy the marker generation since the location of
the new distance is not the local maximum. Consequently, the
new generated maker cannot effectively reflect the single target
object information, and hence, the spitting error occurs and the
object boundary becomes unnatural.
This problem is improved by keeping the distance information of the original maker. Because there is no hard threshold for
the fusion condition between different markers, this enhanced
clustering algorithm is generalized. To validate the effectiveness
of the splitting algorithm, 2000 nucleus clumps are selected to
compare the splitting performance, and the results are summarized in Table VII. Table VII confirms that splitting performance

is improved by 46.43% and the splitting line error is decrease
by 84.50%.
E. Effect of Effective Distance by Color Information
After obtaining the correct markers, the direct way is to use the
nearest-neighbor assignment, but the detected nucleus boundary
is unnatural and the splitting performance is very bad. To address
this, both shape and color information is included, and weights
for shape and color are cross validated.
Table VII gives the results of the effective distance and the
traditional geometrical distance result. By using the measure
distance, the performance is boosted by 13.60%, and the splitting error is reduced by 72.0%.
F. Failure Cases
One of the limitations of our method is the ignorance of the
overlapping cytoplasm splitting. As shown in Fig. 10, the cytoplasm overlapping is highly complicated, and even the clinicians
have difficulty to split them correctly. The cytoplasm is beneficial for the cervical diagnosis, but the nucleus information is
even more important. For the cytoplasm segmentation, the first
limitation is that it is ineffective for the poorly stained cytoplasm. Due to the relatively low ratio of the cytoplasm around
the nucleus, the nucleus will be regarded as the impurities, and
hence, the nucleus in the green box in Fig. 10 is regarded as
background.
The second limitation is the inaccurate segmentation of the
atrophic cell since this cell has large overlapping area with other
cells, which can be seen in Fig. 10(b). This error is mainly caused
by insufficient training samples, and the selected nucleus will be
overlapped with other nucleus, as illustrated in Fig. 10(b). The
cytoplasm and nucleus are very near; hence the local boundary of the nucleus may be unclear, which leads to the incorrect
nucleus segmentation. To resolve this issue, more training samples can be used to further enhance the nucleus segmentation
performance.
The third limitation is the overlapping nucleus with complicated shapes, which degrades the splitting performance. As

2432

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 10, OCTOBER 2015

shown in Fig. 10(c), the left bottom box represents the inaccurate segmentation of nucleus causes incorrect splitting error.
The right upper box denotes the inaccurate marker leads to inaccurate segmentation.
VI. CONCLUSION
In this paper, graph partitioning via superpixel and MSCN
techniques was investigated for accurate cytoplasm and nucleus
segmentation in the cervical image. Our experimental results
indicated that superpixel, graph partitioning, and MSCN are
highly effective for cervical cell segmentation. The achieved
remarkable segmentation results demonstrate that the proposed
method can be used for automatic cervical cancer detection and
diagnosis. Compared with previous algorithms, state-of-the-art
performance is achieved. Moreover, the proposed method is
a promising way for cervical cancer screening and provides
powerful support for automatic assisting.
REFERENCES
[1] A. Jemal et al., “Global cancer statistics,” CA-Cancer J. Clin., vol. 61,
pp. 69–90, 2011.
[2] W. H. O. R. Health, W. H. O. C. Diseases, and H. Promotion, Comprehensive Cervical Cancer Control: A Guide to Essential Practice, World
Health Organization, Geneva, Switzerland, 2006.
[3] J. Ferlay et al., “Estimates of worldwide burden of cancer in 2008:
GLOBOCAN 2008,” Int. J. Cancer,vol. 127, pp. 2893–2917, 2010.
[4] D. Saslow et al., “American cancer society, American society for colposcopy and cervical pathology, and American society for clinical pathology screening guidelines for the prevention and early detection of cervical
cancer,” CA-Cancer J. Clin., vol. 62, pp. 147–172, 2012.
[5] G. G. Birdsong, “Automated screening of cervical cytology specimens,”
Hum. Pathol., vol. 27, pp. 468–481, 1996.
[6] E. Bengtsson, “Computerized cell image analysis: Past, present, and
future,” in Image Analysis. New York, NY, USA: Springer, 2003,
pp. 395–407.
[7] E. Bengtsson, “Recognizing signs of malignancy—The quest for computer assisted cancer screening and diagnosis systems,” in Proc Int. Conf.
Comput. Intell., 2010, pp. 1–6.
[8] L. Zhang et al., “Segmentation of cytoplasm and nuclei of abnormal cells
in cervical cytology using global and local graph cuts,” Comput. Med.
Imag. Graph., vol. 38, pp. 369–380, 2014.
[9] Y. Marinakis et al., “Pap smear diagnosis using a hybrid intelligent scheme
focusing on genetic algorithm based feature selection and nearest neighbor
classification,” Comput. Biol. Med., vol. 39, pp. 69–78, 2009.
[10] O. Lezoray and H. Cardot, “Cooperation of color pixel classification
schemes and color watershed: A study for microscopic images,” IEEE
Trans. Image Process., vol. 11, no. 7, pp. 783–789, Jul. 2002.
[11] M.-H. Tsai et al., “Nucleus and cytoplast contour detector of cervical
smear image,” Pattern Recogn. Lett., vol. 29, pp. 1441–1453, 2008.
[12] A. Gençtav, S. Aksoy, and S. Önder, “Unsupervised segmentation
and classification of cervical cell images,” Pattern Recog., vol. 45,
pp. 4151–4168, 2012.
[13] L. Zhang et al., “Automation-assisted cervical cancer screening in manual
liquid-based cytology with hematoxylin and eosin staining,” Cytometry A,
vol. 85, no. 3, pp. 214–230, 2014.
[14] S.-F. Yang-Mao et al., “Edge enhancement nucleus and cytoplast contour
detector of cervical smear images,” IEEE Trans. Syst., Man, Cybern. B,
Cybern., vol. 38, no. 2, pp. 353–366, Apr. 2008.
[15] P. Bamford and B. C. Lovell, “A water immersion algorithm for cytological
image segmentation,” in Proc. APRS Image Segmentation Workshop, 1996,
pp. 75–79.
[16] K. Li et al., “Cytoplasm and nucleus segmentation in cervical
smear images using radiating GVF snake,” Pattern Recog., vol. 45,
pp. 1255–1264, 2012.
[17] C. Bergmeir et al., “Segmentation of cervical cell nuclei in high-resolution
microscopic images: A new algorithm and a web-based software framework,” Comput. Method. Program. Biomed., vol. 107, pp. 497–512, 2012.

[18] M. E. Plissiti et al., “Automated detection of cell nuclei in pap
smear images using morphological reconstruction and clustering,” IEEE
Trans. Inf. Technol. Biomed., vol. 15, no. 2, pp. 233–241, Mar.
2011.
[19] M. E. Plissiti et al., “Combining shape, texture and intensity features
for cell nuclei extraction in Pap smear images,” Pattern Recog. Lett.,
vol. 32, pp. 838–853, 2011.
[20] H.-S. Wu et al., “A parametric fitting algorithm for segmentation of cell
images,” IEEE Trans. Biomed. Eng., vol. 45, no. 3, pp. 400–407, Mar.
1998.
[21] P. Bamford and B. Lovell, “Unsupervised cell nucleus segmentation with
active contours,” Signal Process., vol. 71, pp. 203–213, 1998.
[22] C. Farabet et al., “Learning hierarchical features for scene labeling,” IEEE
Trans. Pattern Anal. Mach. Intell., vol. 35, no. 8, pp. 1915–1929, Aug.
2013.
[23] B. B. Le Cun et al., “Handwritten digit recognition with a backpropagation network,” in Proc. Neural Inf. Process. Syst., 1990,
pp. 396–404.
[24] Y. LeCun et al., “Gradient-based learning applied to document recognition,” Proc. IEEE, vol. 86, no. 11, pp. 2278–2324, Nov. 1998.
[25] V. Jain et al., “Supervised learning of image restoration with convolutional
networks,” in Proc. Conf. Comput. Vis., 2007, pp. 1–8.
[26] B. Pang et al., “Cell nucleus segmentation in color histopathological imagery using convolutional networks,” in Proc. Chin. Conf. Pattern Recog.,
2010, pp. 1–5.
[27] D. Ciresan et al., “Deep neural networks segment neuronal membranes
in electron microscopy images,” in Proc. Neural Inf. Process. Syst., 2012,
pp. 2843–2851.
[28] S. C. Turaga et al., “Convolutional networks can learn to generate affinity graphs for image segmentation,” Neural Comput., vol. 22,
pp. 511–538, 2010.
[29] D. Padfield et al., “Spatio-temporal cell cycle phase analysis using
level sets and fast marching methods,” Med. Imag. Anal., vol. 13,
pp. 143–155, 2009.
[30] S. Ali and A. Madabhushi, “An integrated region-, boundary-, shapebased active contour for multiple object overlap resolution in histological imagery,” IEEE Trans. Med. Imag., vol. 31, no. 7, pp. 1448–1460,
Jul. 2012.
[31] P. F. Felzenszwalb and D. P. Huttenlocher, “Efficient graph-based image
segmentation,” Int. J. Comput. Vis., vol. 59, pp. 167–181, 2004.
[32] J. Shi and J. Malik, “Normalized cuts and image segmentation,” IEEE
Trans. Pattern Anal. Mach. Intell., vol. 22, no. 8, pp. 888–905, Aug. 2000.
[33] A. Lucchi et al., “Supervoxel-based segmentation of mitochondria in em
image stacks with learned shape features,” IEEE Trans. Med. Imag., vol.
31, no. 2, pp. 474–486, Feb. 2012.
[34] A. Delong and Y. Boykov, “Globally optimal segmentation of multi-region
objects,” in Proc. Int. Conf. Comput. Vis., 2009, pp. 285–292.
[35] Y. Y. Boykov and M.-P. Jolly, “Interactive graph cuts for optimal boundary
& region segmentation of objects in ND images,” in Proc. Int. Conf.
Comput. Vis., 2001, pp. 105–112.
[36] Y. Boykov and V. Kolmogorov, “An experimental comparison of mincut/max-flow algorithms for energy minimization in vision,” IEEE
Trans. Pattern Anal. Mach. Intell., vol. 26, no. 9, pp. 1124–1137,
Sep. 2004.
[37] X. Lou et al., “Learning to segment dense cell nuclei with shape
prior,” in Proc. Int. Conf. Comput. Vis. Pattern Recogn., 2012,
pp. 1012–1018.
[38] H. Chang et al., “Invariant delineation of nuclear architecture in Glioblastoma multiforme for clinical and molecular association,” IEEE Trans. Med.
Imag., vol. 32, no. 4, pp. 670–682, Apr. 2013.
[39] J. Cheng and J. C. Rajapakse, “Segmentation of clustered nuclei with
shape markers and marking function,” IEEE Trans. Biomed. Eng., vol. 56,
no. 3, pp. 741–748, Mar. 2009.
[40] H. Yang and N. Ahuja, “Automatic segmentation of granular objects in images: Combining local density clustering and gradient-barrier watershed,”
Pattern Recog., vol. 47, pp. 2266–2279, 2014.
[41] N. Jamil et al., “A modified edge-based region growing segmentation
of geometric objects,” in Visual Informatics: Sustaining Research and
Innovations. New York, NY, USA: Springer, 2011, pp. 99–112.
[42] M. E. Plissiti and C. Nikou, “Overlapping cell nuclei segmentation using
a spatially adaptive active physical model,” IEEE Trans. Image Process.,
vol. 21, no. 11, pp. 4568–4580, Nov. 2012.
[43] C. Park et al., “Segmentation, inference and classification of partially
overlapping nanoparticles,” IEEE Trans. Pattern Anal. Mach. Intell.,
vol. 35, no. 3, pp. 669–681, Mar. 2013.

SONG et al.: ACCURATE SEGMENTATION OF CERVICAL CYTOPLASM AND NUCLEI BASED ON MULTISCALE CONVOLUTIONAL NETWORK

[44] P. Quelhas et al., “Cell nuclei and cytoplasm joint segmentation using the sliding band filter,” IEEE Trans. Med. Imag., vol. 29, no. 8,
pp. 1463–1473, Aug. 2010.
[45] H. Kong et al., “Partitioning histopathological images: An integrated
framework for supervised color-texture segmentation and cell splitting,”
IEEE Trans. Med. Imag., vol. 30, no. 9, pp. 1661–1677, Sep. 2011.
[46] H. Fatakdawala et al., “Expectation maximization driven geodesic active
contour with overlap resolution (emagacor): Application to lymphocyte
segmentation on breast cancer histopathology,” IEEE Trans. Biomed. Eng.,
vol. 57, no. 7, pp. 1676–1689, Jul. 2010.
[47] L. Zhang et al., “Automation-assisted cervical cancer screening in manual
liquid-based cytology with hematoxylin and eosin staining,” Cytometry A,
vol. 85, pp. 214–230, 2014.

2433

[48] R. Achanta et al., “SLIC superpixels compared to state-of-the-art superpixel methods,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 34,
no. 11, pp. 2274–2282, Nov. 2012.
[49] Y. Boykov et al., “Fast approximate energy minimization via graph
cuts,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 23, no. 11,
pp. 1222–1239, Nov. 2001.
[50] L. R. Dice, “Measures of the amount of ecologic association between
species,” Ecology, vol. 26, pp. 297–302, 1945.
[51] Y. Al-Kofahi et al., “Improved automatic detection and segmentation
of cell nuclei in histopathology images,” IEEE Trans. Biomed. Eng.,
vol. 57, no. 4, pp. 841–852, Apr. 2010.
Authors’ Photographs and biographies not available at the time of publication.

