Journal of Informetrics 1 (2007) 59–67

The source-item coverage of the exponential function
Thierry Lafouge
Laboratoire Ursidoc Université Claude Bernard Lyon 1, 43 Boulevard du 11 novembre 1918, 69622 Villeurbanne Cedex, France
Received 17 July 2006; received in revised form 18 September 2006; accepted 19 September 2006
I dedicate this work to the memory of B. Delattre, brilliant mathematician.

Abstract
Statistical distributions in the production of information are most often studied in the framework of Lotkaian informetrics. In this
paper, we recall some results of basic theory of Lotkaian informetrics, then we transpose methods (Theorem 1) applied to Lotkaian
distributions by Leo Egghe (Theorem 2) to the exponential distributions (Theorem 3, Theorem 4). We give examples and compare
the results (Theorem 5). Finally, we propose to widen the problem using the concept of exponential informetric process (Theorem 6).
© 2006 Elsevier Ltd. All rights reserved.
Keywords: Exponential function; Mathematical-fitting; Lotkaian informetrics

1. Introduction
Many phenomena studied in informetrics, concerning the production or use of information, can be represented by
a triple (source, production function, items) called information production process (IPP) (Egghe, 1990). This consists
of a set of sources S, a set of items I, T (respectively, A) denotes the total number of sources, the total number of items,
respectively and finally a function of production or use that quantifies the production of the items by the sources. There
are several methods for representing these phenomena. In this article, the theory is developed with a size-frequency
function f, the most usual form for quantifying this production.
f: [1, Imax ] → + , f(j) describes the density of sources with item density j (in the discrete setting f(j) indicates the
number of sources that have produced j items). We assume f is continuous.
Imax indicates the maximal item per source density.
The following two equalities allow us to calculate T and A.
 Imax
f (j) dj
(1.1)
T =
1


A=

Imax

jf (j) dj

(1.2)

1

Of course it may happen that T and A are infinite if Imax is infinite. If T is finite we have the following inequality:
0 < T < A. We denote μ = A/T, the average number of items by source. We have, μ > 1.

E-mail address: Lafouge@univ-lyon1.fr.
1751-1577/$ – see front matter © 2006 Elsevier Ltd. All rights reserved.
doi:10.1016/j.joi.2006.09.004

60

T. Lafouge / Journal of Informetrics 1 (2007) 59–67

In practice, the production function of an IPP has similar characteristics in very diverse situations of production or
use of information:
-

authors (sources) write articles (items),
words in a text (sources) produce occurrences of words in the text (items),
web pages (sources) contain links (items),
web sites (sources) are visited (items),
requests (sources) through a search engine are sent by users (items).

In all quoted examples, if we quantify the production of the items by the sources with a size-frequency function, this
one is decreasing with a long tail and a gap between a high number of sources producing few items and a small number
of sources producing a lot. In practice, when one determines a best-fitting curve, we must truncate the distribution
because, for high frequencies the number of items produced is very low. This characteristic results in the standard
deviation often being extremely high compared with the average and is a poor indicator. The statistical distribution
mostly used in informetrics is the inverse power function, also called Lotkaian informetric distribution. This distribution
is unimodal; it models the information production processes in many of the quoted examples. At present, with Internet,
there are many examples for which the data resulting from the Web has been adjusted by such models (Bilke & Peterson,
2001). The zero-truncated generalized inverse Gaussian–Poisson (GIGP) model known and tested over a long time
(Burrel & Fenton, 1993) is also used to day to adjust some of this data (Ajiferuke & Wolfram, 2004).
2. Lotkaian informetric distribution
With the preceding notations, a Lotkaian informetric distribution is given:
f: [1, Imax ] → + ,where
f (j) =

C
,
jα

C>0

and α > 1

(2.1)

We will limit ourselves to the case where α > 1, meaning where T (number of sources) is finite and where the
corresponding probability density function is: f(j) = (α − 1) × j−α α > 1, if Imax = ∞. Moreover, we know that A is finite
if α > 2. More generally, f has moments of order n if α > n.
The mathematical properties of these functions (Haitun, 1982) have been studied to a great extent. They have
often been opposed to the functions modeling Gaussian processes. They have been the subject of a recent work of
informetrics (Egghe, 2005), which contains many results. This work has the merit among others of unifying all the
work done concerning empirical applications, Lotka, Bradford, Zipf, Mandelbrot, with the mathematical theory of IPP,
choosing, as central distribution, the Lotkaian distributions. The coefficient α characterizes the gap between strongly
productive sources and those that produce little. Many works (Bookstein, 1990a, b) have shown the strength of the
law of Lotka (Lotka, 1926). In addition, the value α = 2 plays a key role since we know, according to whether α is
smaller or greater than 2, that the representation of Leimkuhler (Rousseau, 1988) has or does not have a turning point;
in informetrics the term “Groos droop” (Groos, 1967) is often used.
Finally, these distributions are scale free. A function f is called scale-free if, for every positive constant C, there is a
positive constant D such that f(Cx) = Df(x) for all x in the domain of f (Egghe, 2005, p. 27). This property is important
when frequencies are observed. It allows us to change scale without changing model. In the main, it justifies the choice
of Leo Egghe in his work that we have just quoted. If we impose the scale free property, it implies that some decreasing
functions, such as the decreasing exponential function one, are not allowed.
However, the phenomena of obsolescence and growth of quotations on a subject of search in scientific literature
(Egghe, 1993) are modeled by exponential processes.
In addition, the often ignored result of Naranan (Naranan, 1971), shows that distributions of Lotkaian type can be
deduced under certain conditions from an exponential growth of sources and the number of items produced by these
sources. It gives the exponential functions an importance that we cannot neglect. In the previously quoted examples,
the temporal parameter plays the role of variable.
Finally, the law of geometrical probability, which is the discrete version of the exponential law, is often used as a
rough approximation for modeling the processes of commands or library circulation data (Bagust, 1983).

T. Lafouge / Journal of Informetrics 1 (2007) 59–67

61

Thus, all these reasons lead us to adopt a procedure similar to that of Leo Egghe (Egghe, 2005) and to find a
mathematical result for the exponential distributions, which is a necessary condition of the same type as Lotkaian
distributions.
3. Reminder of some results of basic theory of Lotkaian informetrics
There is a lot of statistical work that consists of verifying the statistical regularities in the variety of examples
mentioned in the introduction, and making fittings. Lotkaian distributions play an important role here. However, to
my knowledge, few bibliometric researchers use the mathematical theorem, certainly recent, which we remind is a
necessary condition for the production of sources covering the items produced. This theorem plays a key role in this
article.
Theorem 1. (Egghe, 2005, p. 111)
The following assertions are equivalent, given A > T > 0
(i) There exists a function f: [1,+∞[→+ and a finite number Imax > 1 such that:


Imax

T =

f (j) dj

1


A=

Imax

jf (j) dj

1

(ii) There exists a function f* : [1,+∞[→+ such that
∞ ∗
jf (j) dj
μ < 1∞ ∗
1 f (j) dj

Moreover if (i) or (ii) holds we have, necessarily that f* = D × f with D > 0, a constant.
We refer readers interested in the demonstration to the reference quoted. What is interesting for us here in the
theorem is the implication (ii) ⇒ (i).
Leo Egghe applies this theorem to Lotkaian informetric distributions.
Theorem 2. (Egghe, 2004)
Let 0 < T < A < ∞ be given. Let α > 1 and a number Imax > 1.
If Imax is infinite
(i) If the inverse power function as in (2.1) satisfies (1.1) and (1.2) if we have
α=

2μ − 1
μ−1

(3.1)

C=

A
μ−1

(3.2)

and

which implies α > 2 if A < ∞.
If Imax is finite (the general case)

62

T. Lafouge / Journal of Informetrics 1 (2007) 59–67

(ii) If α ≤ 2 then there always exists a numberImax > 1such that (2.1) satisfies (1.1) and (1.2).
(iii) If α > 2 the conclusion (i) is valid if and only if
α−1
(3.3)
α−2
We will follow exactly the same procedure for the exponential functions (Theorem 3 and Theorem 4), then compare
the results (Theorem 5).
μ<

4. Exponential distribution
4.1. Theoretical results
With the preceding notations, an exponential function: g: [1, Imax ]→+ is given where
g(j) = C e−α(j−1)

with C > 0

and

α>0

(4.1)

We can also write it in an equivalent form:
g(j) = Ca−j

with C > 0

and a > 1

We will use the first form here. The corresponding probability density function is:
g(j) = α e−α(j−1)

with α > 0

and

Imax = ∞

As for the power function, g has as a maximum value for 1.
Unlike the inverse power function, a decreasing exponential function has moments of order n whatever the n positive.
∞
Lemma. If we call A(n) = 1 j n e−α(j−1) dj the moment of order n divided by α of an exponential function, we
have


p=n−1

n!
1
1
, n ≥ 0;
+
n!
A(n) =
(n − p)! αp+1
αn+1
p=0

Proof. An integration by part gives:
1
n
+ A(n − 1)
α α
with A(0) = 1/α. We show by recurrence:
A(n) =

⎞
⎛
p=n−1
n!
1 ⎠
(n + 1)
1 (n + 1) ⎝ 
1
1
+ n! n+1
A(n) = +
A(n + 1) = +
α
α
α
α
(n − p)! αp+1
α
p=0

⎞
p=n−1
p=n
1 ⎝  (n + 1)! 1
1
1 ⎠  (n + 1)!
1
= +
=
+
(n
+
1)!
+ (n + 1)! n+2
p+2
n+1
p+1
α
(n − p)! α
α
(n + 1 − p)! α
α
⎛

p=0

p=0

More particularly we obtain:
1
1
(4.2)
+ 2 
α α
Problem. What are the conditions, given A and T (0 < T < A), for the existence of an exponential function g as in (4.1)
which verifies:
 Imax
 Imax
g(j) dj = T and
jg(j) dj = A?
A(1) =

1

1

We separate the study into two cases.

T. Lafouge / Journal of Informetrics 1 (2007) 59–67

63

(1) Imax is infinite
Theorem 3. Let 0 < T < A be given. The exponential function defined in (4.1) satisfies the following conditions:


∞



∞

g(j) dj = T ;

1

jg(j) dj = A

1

if
α=

T
1
=
A−T
μ−1

(4.3)

C=

T2
A−T

(4.4)

Proof. By solving the integrals above (see (4.2)), we obtain:


∞

C e−α(j−1) dj =

1

C
α

and


∞

−α(j−1)

Cj e


dj = C

1

1
1
+
2
α
α



We then deduce the desired results ((4.3), (4.4)) by solving the two equations:
T =

C
α

A=

Cα + C
.
α2

and

As for a Lotkaian distribution, α only depends on μ. When fitting, the formulas (4.3), (4.4) give a rough estimate
of the parameters of the exponential function (4.1). 
(2) Imax is finite
Theorem 4. Let A > T > 0 be given. Thus, α > 0, there is still Imax > 1 finite and an exponential function defined by
(4.1) verifying the two conditions:
 Imax
 Imax
g(j) dj = T and
jg(j) dj = A
1

1

if the inequality
μ<1+
holds.

1
α

(4.5)

64

T. Lafouge / Journal of Informetrics 1 (2007) 59–67

Proof. According to the preceding lemma, we have:
∞
jC e−α(j−1) dj
(1/α2 ) + (1/α)
1∞
= 1 + (1/α)
=
−α(j−1) dj
(1/α)
1 Ce
The assertion (ii) of Theorem 1 allows us to conclude. It will be noticed that the result is valid for any value α > 0.
In particular, the value α = 2, unlike the Lotkaian distribution, is not a key value.
Construction of g
Now its existence is proven, we must show how to build it. To simplify the notations we put x = Imax .
 x
T
1 − e−α(x−1)
C e−α(j−1) dj = T ⇒
=
C
α
1


x

jC e−α(j−1) = A ⇒

1

A
1 − x e−α(x−1)
1 − e−α(x−1)
=
+
C
α
α2

We suppose x 	= 1. By eliminating C we deduce the following equation:
Aα
e−α(x−1) (−1 − xα) + α + 1
=
T
1 − e−α(x−1)
thus,
μα −

e−α(x−1) (−1 − xα) + α + 1
=0
1 − e−α(x−1)

(4.6)

Unlike the case where x is infinite there are many values α > 0 where the preceding equation has solutions. We
consider α as a parameter of the Eq. (4.6), α > 0. We solve this equation in x, by the iterative method, using the
MAPPLE 4.0 software for example. Then we calculate C,
C=

αT
1 − e−α(x−1)



(4.7)

We have just seen a necessary condition for an exponential function to produce a given number of items with a given
number of sources. We shall see that if this necessary condition holds, then it also holds for a Lotkaian distribution.
More precisely, we have the following result:
Theorem 5. Let A > T > 0 be given. Let α > 1. If there is a number Imax > 1 such that (4.1) satisfies (1.1) and (1.2),
then it is also valid for (2.1).
Proof. If Imax = ∞ it is still true according to the results (i) of Theorem 2.
If Imax is finite we have two cases.
(i) α ≤ 2, we know according to the result (ii) of Theorem 2 that it is also true.
(ii) α > 2, we know according to Theorem 4 that (4.5) is true, thus, α < [1/(μ − 1)], then 1/(μ − 1) < [2(μ − 1)/μ − 1]
thus, the inequality α < [(2μ − 1)/(μ − 1)] is true, thus, the inequality (3.3) is true, the assertion (iii) of Theorem
2 then allows us to conclude. 
4.2. Examples
(1) A=10,000, T=5000 thus, μ = 2 and α = 0.5. The inequality (4.5) is demonstrated. We must then solve the Eq. (4.6):
1−

e−0.5(x−1) (−1 − 0.5x) + 1.5
= 0.
1 − e−0.5(x−1)

We obtain the solution x = 3.512, then according to (4.7) we have C ≈ 8778.

T. Lafouge / Journal of Informetrics 1 (2007) 59–67

65

The desired exponential function is: g(j) = 8778 e−0.5(j − 1).
(2) A=10,000, T=7000 thus, μ = 1.43 and α = 2. The inequality (4.5) is demonstrated. We must then solve the Eq. (4.6):

2.86 −

e−2(x−1) (−1 − 2x) + 3
= 0.
1 − e−2(x−1)

We obtain the solution x = 2.58 then according to (4.7) we have C ≈ 1462
The desired exponential function is: g(j) = 1462 e−2(j − 1) .
Note
The results in Section 4 could be considered as a “mathematical fitting” method for exponential function, as opposed
to statistical fitting.
5. Perspectives: exponential informetric process
In the article (Lafouge & Prime Claverie, 2005) we define an exponential informetric process in terms of an
exponential function and an effort function where the average quantity supplied by the sources, to produce all the items
is finite. More precisely, a set of functions, denoted EF.
EF = {h: [1, ∞[→+ : increasing, continuous, and not majorized}
h ∈ EF an effort function is then any element of EF.
We call exponential informetric process the size-frequency function v(h):
ν(h)(j) = C e−h(j)

C>0

(5.1)

where the following quantity
∞
ν(h)(j)h(j) dj

F=

(5.2)

1

is finite, F corresponds to the quantity of effort produced by v(h).
Note
∞
The total number of sources T, T = 1 ν(h)(j) dj is finite and we have the inequality ∞ > F > T > 0.
Examples
The respective functions of effort, h(j) = α × ln(j), α > 1 and h(j) = α(j − 1), α > 0 correspond to the inverse power
function f(j) = C/jα and to the exponential function g(j) = C × e−α(j − 1) , studied previously.
Problem. What are the conditions, given the quantity of effort F, the number of sources T, forthe existence of an
i
exponential
informetric process v(h) as in (5.1), where Imax is a number > 1, which verifies F = 1 max ν(h)(j)h(j) dj
 imax
and T = 1 ν(h)(j) dj?
We will limit ourselves to the case where the respective functions of effort correspond to the inverse power function
(2.1) and to the exponential function (4.1), and where Imax = ∞.
Theorem 6. Let F > T > 0 be given:
(i) the exponential informetric process as in (5.1) where h(j) = α(j − 1),α > 0 satisfies the following conditions:

66

T. Lafouge / Journal of Informetrics 1 (2007) 59–67



∞

T =

C e−α(j−1) dj

1


F=

∞

C e−α(j−1) α(j − 1) dj

1

if
T = F = C/α

(5.3)

(ii) the exponential informetric process as in (5.1) where h(j) = α × ln(j), α > 1 satisfies the following
conditions:
 ∞
1
T =
C α dj
j
1

F=

∞

C

1

1
α ln(j) dj
jα

if
α=

F
F −T

(5.4)

C=

T2
F −T

(5.5)

Proof.
(1) By (4.1) T = C/α. An integration by part give: F = C/α
C
(2) By (2.1) T = α−1


∞
∞
1
1
, an integration by part give: 1 j1α ln(j) dj =
ln(j)
dj
=
−
ln(j)
d
α−1
1
α−1 1
j
We then deduce the desired results (5.4) and (5.5) by solving the two equations:

∞

1
jα

T =

C
α−1

F=

Cα
(α − 1)2

1
x thus, F
(α−1)2

=

Cα
.
(α−1)2

and


The case where Imax is finite is an open problem.
References
Ajiferuke, I., & Wolfram, D. (2004). Informetric modelling of Internet search and browsing characteristics. The Canadian Journal of Information
and Library Science, 28(1), 1–16.
Bagust, A. (1983). A circulation model for busy public libraries. Journal of Documentation, 39(1), 24–37.
Bilke, S., & Peterson, C. (2001). Topological properties and metabolic networks. Physical Reviews E, 6403(3), 76–80.
Bookstein, A. (1990a). Informetric distribution, Part 1: unified overview. Journal of the American Society for Information Science, 41(5), 368–375.
Bookstein, A. (1990b). Informetric distribution, Part 2: resilience to ambiguity. Journal of the American Society for Information Science, 41(5),
376–385.
Burrel, Q. L., & Fenton, M. R. (1993). Yes, the GIGP really does work and is workable. Journal of the American Society for Information Science,
44(2), 61–69.
Egghe, L. (1990). On the duality of informetric systems with applications to the empirical law. Journal of Information Science, 16, 17–27.
Egghe, L. (1993). On the influence of growth on obsolescence. Scientometrics, 27(1), 195–214.

T. Lafouge / Journal of Informetrics 1 (2007) 59–67

67

Egghe, L. (2004). The source-item coverage of the Lotka function. Scientometrics, 61(1), 103–115.
Egghe, L. (2005). Power laws in the information production process: Lotkaian informetrics. Elsevier.
Groos, A. V. (1967). Bradford’s law and the Keenan–Atherton data. American Documentation, 18, 46.
Haitun, S. D. (1982). Stationary scientometric distributions. Scientometrics no. 4, Part I, 5–25, Part II, 89–104, Part III, 181–194.
Lafouge, T., & Prime Claverie, C. (2005). Production and use of information. Characterization of informetric distributions using effort function and
density function exponential informetric process. Information Processing and Management, 41, 1387–1394.
Lotka, A. J. (1926). The frequency distribution of scientific productivity. Journal of the Washington Academy of Science, 292–306.
Naranan, S. (1971). Bradford Law of bibliography of science an interpretation. Nature, 227(5258), 631–632.
Rousseau, R. (1988). Lotka’s law and its Leimkuhler representation. Library Science with a Slant to Documentation and Information Studies, 25(3),
150–178.

