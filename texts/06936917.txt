IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 3, MARCH 2015

807

A Lumen Detection-Based Intestinal Direction Vector
Acquisition Method for Wireless Endoscopy Systems
Dan Wang∗ , Xiang Xie, Guolin Li, Zheng Yin, and Zhihua Wang, Senior Member, IEEE

Abstract—This paper proposes a novel method for acquiring an
intestinal direction vector (IDV) based on a single static wireless
endoscopic image. The IDV can be used for navigation of wireless capsule endoscopy, and for multicamera microball system, this
information can help to select cameras to capture images of the region of interest. Our proposal is based on lumen detection, which
involves Bayer-format downsample, adaptive threshold segmentation, and radial texture detection. Then, an IDV calculation method
with only one single static image by modeling the small intestine
and image capture process is put forward. The performance of
the proposed method is verified with experiments based on real
digestive tract images and the microball demo system. The lumen
detection method achieves 95.5% precision and 98.1% sensitivity.
The experimental results in pig intestine show that the error of IDV
is limited by a sphere with center (−0.00629, 0.00097, 0.00061) and
radius 0.085.
Index Terms—Intestinal direction vector (IDV) acquisition, lumen detection.

I. INTRODUCTION
HE wireless capsule endoscopy technology [1], [2] is a
revolutionary breakthrough that allows physicians to examine the digestive tract of the human body in a minimally
invasive way. With the development of information and microelectronic technologies, the wireless endoscopy system (WES)
becomes more and more intelligent [3]. One development
tendency is the microcapsule robot [4], which can know the
walking direction and adjust its attitude relative to the intestine
to move directly to the target site for specific treatments, such as
drug delivery, biopsy, etc. [see Fig. 1(a)]. On the other hand, to
reduce the high missing rate which is average 20–30% in small
intestine [5], multiple cameras are adopted in WES, such as
the two-camera PillCam [6] and six-camera microball [7]. The
multicamera WES needs to know which camera should work
in order to capture images of region of interest (ROI) depending on some particular demands, e.g., intestinal lumen images
for gastrointestinal (GI) motility assessment or intestinal wall

T

Manuscript received April 9, 2014; revised August 8, 2014; accepted October
15, 2014. Date of publication October 27, 2014; date of current version February
16, 2015. Asterisk indicates corresponding author.
∗ D. Wang is with the Institute of Microelectronics, Tsinghua University,
Beijing 100084, China (e-mail: wangdan06@gmail.com).
X. Xie and Z. Wang are with the Institute of Microelectronics, Tsinghua University, Beijing 100084, China (e-mail: xiexiang@tsinghua.edu.cn; zhihua@
tsinghua.edu.cn).
G. Li and Z. Yin are with the Electronic Engineering Department,
Tsinghua University, Beijing 100084, China (e-mail: guolinli@tsinghua.edu.cn;
popmailyz@yahoo.com.cn).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2014.2365016

Fig. 1. IDV acquisition can be used in WESs and conventional endoscopy
systems.

images for lesion diagnosis [see Fig. 1(b)]. The key issue to be
solved in previous applications is that how to know the attitude
of the WES relative to the intestinal tract. Although the inertial
measurement unit or some other inertial sensors can give the
attitude information when the WES travels in the human body,
the attitude is relative to human body instead of the intestine
due to the fact that the human intestine twists and turns around.
In this paper, we address the issue by acquiring the intestinal
direction vector (IDV) information based on lumen detection.
IDV is defined as a unit vector which exactly represents the axis
direction of the human intestine relative to the camera of WES.
To our best knowledge, there is no related work before for WES.
It is noted that even for traditional endoscopy examination, IDV
can provide the accurate inserting direction information, which
may make automatic propulsion of the endoscopy possible, and
can help the operator to make the examination smoothly as well
as relieve the patients’ discomfort [see Fig. 1(c)].
As the intestinal lumen contains some useful information such
as the direction and the motility of the intestinal tract, a few
of related works about lumen detection have been researched
for intestinal motility assessment and endoscopy navigation.
In the field of WES, one category of the state-of-art lumen
detection technologies is sequence-based method, such as [8]
and [9]. For IDV acquisition, image sequence information is
not suitable to be used with the consideration of response time
and computational complexity. Another category of detection
methods works on one image. To recognize the lumen with a
single image, a Haar-like features-based AdaBoost classifier

0018-9294 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

808

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 3, MARCH 2015

A. Adaptive Threshold Segmentation for Noncompletely
Contractive Lumen Detection

Fig. 2.

Bayer-format R-channel 1/2∗ 1/2 downsample.

and global threshold-based segmentation method are presented
in [10] and [11], respectively. The lumen detection results of the
two methods are sensitive to the light conditions and folds of
the intestinal wall. The proposal in [12] utilizes the mean-shift
algorithm and region exaction technique to detect and track the
lumen for wireless endoscopy navigation. The method needs to
set six parameters and the complexity is relatively high. The
case of completely contractive lumen is also not investigated. In
the area of conventional endoscopy, spatial-domain [13]–[16]
and frequency-domain [17] methods are presented for colon
lumen detection. However, those methods are not suitable for
the images of WES because the random motion of the WES
as well as the poorer imaging conditions bring more complex
situations compared with that of conventional endoscopy.
For intestinal direction detection, as far as we know, only a
couple of works are reported for giving the direction adjustment
information in conventional endoscopy examination. The detection of halation or brightness gradient calculation is used [18],
[19], to acquire the route when the lumen disappears. It can give
the direction indication on the image to tell the operator how to
adjust the endoscopy to keep it along the intestinal axis to make
the examination smoothly and relieve the patients’ discomfort.
However, the direction adjustment information is not the IDV
which is relative to a defined coordinate system and it cannot be
used in WES directly for acquiring the attitude of the endoscopy
relative to the intestinal tract.
The major contributions of this work can be summarized as
follows: 1) A novel adaptive threshold segmentation method is
put forward to effectively and accurately detect the noncompletely contractive lumen. While a specific radial texture detection method is presented for completely contractive lumen
detection; 2) an explicit and feasible IDV calculation method
is designed by modeling the small intestine and image capture
process. All the works are verified by experiments. This paper
is organized according to the previous sequence.

By analyzing the histogram feature of the images, as discussed in Section II-B, it can be found that most of GI tract
images with noncompletely lumen have distinct region feature.
Their corresponding histograms have obvious valley points, especially based on the R-channel, so the threshold-based image
segmentation method can be adopted. Some reported methods
are not suitable for being implemented inside the microball or in
the portable receiver outside body, e.g., global threshold methods [20], [21] cannot adapt to various intestinal images and
adaptive threshold methods [22]–[24] have high complexity.
With consideration of the compromise between usability and
complexity, an adaptive threshold method with relatively low
complexity is designed as follows.
Let the pixels of a given image be represented in L gray levels
[1, 2, . . . , L]. Then, the gray-level histogram is given by
h(i) = ni , h(i) ≥ 0,

L


(1)

where ni represents the number of pixels at level i and N is the
total number of pixels.
Based on the histogram function h(i), suppose that we dichotomize the image pixels into two classes C0 and C1 (corresponding to lumen region and nonlumen region, or vice versa) by
a threshold at gray level t ∈ [1, . . . , L]; C0 denotes pixels with
levels [1, . . . , t] and C1 denotes pixels with levels [t + 1, . . . , L].
In order to evaluate the “goodness” of the threshold (at level
t) for segmenting the lumen, a specific discriminant criterion
measure is designed as follows:
κ(t) = λ(t) · η(t).

(2)

And the optimal threshold t∗ is obtained by
κ(t∗ ) = max κ(t)

(3)

1≤t≤L

where λ(t) is a function specifically designed in this paper and
it will be discussed in the following part. The function η(t) in
(2) is one kind of measure of class separability used in the
discriminant analysis [25], which is defined by
η(t) =

σB2 (t)
σT2

(4)

where σB2 and σT2 are, respectively, the between-class variance
and the total variance of levels, which are defined as follows:

II. LUMEN DETECTION
Based on the analysis of the intestinal images, the intestinal
lumen detection method needs to be designed for two kinds of
lumen, noncompletely contractive lumen and completely contractive lumen, and the corresponding methods are discussed as
follows.
In order to reduce computation complexity, 1/2∗ 1/2 downsample is implemented after R-channel of the original Bayerformat image is extracted, as shown in Fig. 2. Then, the data
amount can be reduced to 6.25% of the whole image, while the
image information is effectively reserved.

h(i) = N

i=1

σB2

= ω0 ω1 (μ1 − μ0 ) ,
2

σT2

=

L

i=1

(i − μT )2

h(i)
N

(5)

Variables ω0 and ω1 are the probabilities of occurrence of
classes C0 and C1 , while μ0 and μ1 represent the mean levels
of the two classes, respectively. Moreover, μT is the total mean
level of the image.
As σT2 is independent of t and σB2 is based on the first-order
statistics which is easier to be calculated than high-order statistics, criterion measure η(t) is preferred by some methods [26].
However, the optimal threshold only based on η(t) is relatively

WANG et al.: LUMEN DETECTION-BASED IDV ACQUISITION METHOD FOR WIRELESS ENDOSCOPY SYSTEMS

809

Fig. 3. Analysis and results concerning the proposed adaptive threshold segmentation method. (a) Situation in which the lumen is small. (b) Situation in which
the lumen is not distinct on its edge. (c) Situation in which there is no lumen.

larger than expected for intestinal images, especially when the
lumen is small [see Fig. 3(a)-(B.2)], not distinct on its edge [see
Fig. 3(b)-(B.2)] or even disappears [see Fig. 3(c)-(B.2)], i.e.,
the segmented lumen is larger than real situation or the intestinal wall is incorrectly segmented. Considering that the lumen
is generally corresponding to the darkest region of the image,
the function λ(t) in (2), which is decreasing with gray level t, is
designed to shift the t∗ to the darker region (6), as depicted in
Fig. 3(a)-(A.2), (b)-(A.2), and (c)-(A.2):

Based on criterion measure К(t) (2), the segmented lumen
is more accurately than that which is obtained by η(t) and can
serve as the result at coarse level, as shown in Fig. 3(a)-(B.3)
and (b)-(B.3). However, the intestinal wall is still be segmented
mistakenly [see Fig. 3(c)-(B.3)]. In order to refine the extracted
region and prevent the wall image from being segmented, another function, ω(i), for acting on histogram h(i) (1) is designed
as
ω(i) =

λ(t) = (−t + L) ·

1
gm ean

(6)

where gm ean is the mean gradient magnitude of the image. As
for the calculation of discontinuity
of intensities, we employ the

Sobel edge detector, g = G2h + G2v , where Gh and Gv are, respectively, the response of horizontality and verticality of edges
of Sobel operator within a 3∗ 3 window. The reciprocal factor
gm ean of the image with large and prominent lumen is generally larger than that of the image with small and inconspicuous
lumen. The factor is introduced to enhance the effect on the images with small or nondistinct lumen and weaken the impact on
images with large and distinct lumen to avoid oversegmentation
(the segmented lumen is smaller than real situation).

1
L
·
.
i gm ean

(7)

Then, the lumen segmentation is based on histogram, h (i),
defined by
h (i) = ω(i) · h1 (i).

(8)

As illustrated in (8), ω(i) is an inverse function of the gray
level and drops relatively fast. When multiplying on the histogram, it can make the low brightness area become the dominant area relative to the wall area, i.e., make the discrimination
between lumen and wall more distinct. The functions h (i) of
the images containing the lumen are depicted in Fig. 3(a)-(A.3)
and (b)-(A.3), while the corresponding criterion measure К(t) is
shown in Fig. 3(a)-(A.4) and (b)-(A.4). The global mean gradient factor (gm ean ) aims to enhance the impact when the lumen

810

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 3, MARCH 2015

Fig. 4. Examples for lumen candidate selection and further refining. (The
mean gray value of regions A and B in (a-1) are, respectively, 70 and 72; the
area value of regions A and B in (b-1) are, respectively, 131 and 187(64∗ 64
image resolution).)

is not distinct on its edge. It is noted that the histogram h(i) is
preprocessed by

h(i) h(i) = 0
h1 (i) =
(9)
1
h(i) = 0
before being multiplied by ω(i). The operation by (9) aims to
make the function ω(i) work on low gray part of the histogram
of the intestinal wall image [see Fig. 3(c)-(A.3)] and prevent the
image being segmented.
The detected results based on h (i) and К(t) are shown in
Fig. 3; we can see that the lumen can be segmented accurately
[see Fig. 3(a)-(B.4) and (b)-(B.4)] while the image without lumen appearance is kept not being segmented [see Fig. 3(c)(B.4)].
Moreover, another issue to be solved is that the region
segmented will contain many isolated islands (segmentation
patches) [see Fig. 4(a-1) and (b-1)], {D1 , D2 , . . . , Dn } (n represents the number of the patches), with the influence of slight
clutter or light condition. A dominant region, LR C, which
is probably the lumen region should be extracted by a certain
criterion. An effective metric is designed as
√
A
(10)
S=
pm ean · p2m in
and the LR C is obtained by
LR C = D∗ =

max

D ∈{D 1 ,D 2 ,...,D n }

S(D)

(11)

where pm in , pm ean , and A are, respectively, the minimum gray
value, mean gray value, and area of the region D. As the lumen
is usually the darkest region inside the image, the parameter
pm ean is adopted for the metric S (11). However, it is errorprone just based on pm ean , as the case shown in Fig. 4(a). For
this situation, another parameter A is introduced to select the
darkest region with a relatively dominant area. To differentiate
the small lumen from the relatively larger folds or shade of the
wall, as illustrated in Fig. 4(b), the area parameter A is weaken
by square root operation and the parameter pm in is added. It is
set to be the most influential factor by square operation because
the minimum gray pixel usually appears in the lumen region. As
depicted in Fig. 4, the lumen region, whether is larger or smaller
than other isolated islands, can be extracted. In order to keep the

Fig. 5. Sketch of texture feature detection method. (a) Pixel sequence is
extracted with center (xl , y l ). (b) Gray level of the pixel sequence.

stability of the detection method, parameter A is limited by A >
10 pixels, which is set based on the image size accordingly (here
is for 64∗ 64 size of image). By this step, if possible, only one
lumen region LR C, which is defined as the lumen candidate,
will be remained and the close operation (dilation and erosion)
is implemented subsequently to refine the region further [see
Fig. 4(a-2) and (b-2)]. Meanwhile, the minimum gray pixel (xl ,
yl ) can also be extracted in the adaptive threshold segmenting
process and it will be used in the radial texture detection.
After extracting the lumen candidate, the images from which
there is no lumen extracted need to be judged whether the images
have a completely contractive lumen or is corresponding to the
intestinal wall by the radial texture detection method as follows.
B. Radial Texture Detection for Completely
Contractive Lumen
To detect the completely contractive lumen, image texture
feature should be extracted and used. Contractions usually appear with a prolonged, strong occlusion of the lumen. The omnipresent characteristic in this kind of images are the strong
edges (wrinkles) of the folded intestinal wall, distributed in a
radial way around the closed intestinal lumen. In order to extract the wrinkle-star pattern, a special texture detection method
with low complexity is proposed in this paper. First, a pixel sequence G{pi |i ∈ [1, 4R − 4}, located on the square with side
length R centering at (xl , yl ) (the location of the minimum
gray pixel in the image, which can be obtained in the adaptive
threshold segmenting process), will be extracted, as shown by
the white square in Fig. 5(a). Parameter R can be defined based
on image size and shape of the contractive lumen to make the
extracted square contain the wrinkles of the lumen. It can be
set to 20 empirically when the image resolution is 64∗ 64. With
the extracted pixel sequence [see Fig. 5(b)], the extreme points
{e1 , e2 , . . . , en } can be detected.
Considering that the gray level change across the wrinkles of
the contractive lumen is larger than that of other parts, the gray
level change among the extracted extreme points can be utilized
to detect effective peak-to-valley change which is corresponding
to a specific wrinkle of the completely contractive lumen. The
criterion can be set as
|ei − ei+1 | > Pth OR |ei − ei−1 | > Pth , i = 2, 4, 6, . . . , i < n
(12)

WANG et al.: LUMEN DETECTION-BASED IDV ACQUISITION METHOD FOR WIRELESS ENDOSCOPY SYSTEMS

Fig. 7.
Fig. 6.

811

Sketch of IDV representation.

Situation, which needs an additional filter of extreme points.

where n is the number of the extreme points and Pth is the gray
threshold, which can be defined based on the analysis of gray
level change across the wrinkles and other parts (Pth = 20 is
used here).
As the minimum number of wrinkles formed by intestinal
contraction is 3, the image may contain a completely contractive lumen if the number of effective peak-to-valley (wrinkles)
N um p satisfies N um p ≥ 3. Then, an additional constraint is
designed according to the star characteristics of the completely
contractive lumen, for the wall image may have the similar
number of wrinkles on the extracted square. The criterion is
designed as follows: the square region is divided averagely into
three parts centering at (xl , yl ) and each region needs to contain
one detected peak-to-valley change at least. The image satisfying the constraint will be determined as containing a completely
contractive lumen; otherwise, it will be judged as the intestinal
wall image.
For a given function f(x), the extreme points can be obtained
by df /dx = 0. However, there still exist some negative extreme
points, as the point pw shown in Fig. 6. Therefore, an additional
filter of extreme points is needed to extract the positive extreme
points, and the simple filtering operation is based on
(ei > ei−1 AND ei ≥ ei+1 ) OR (ei < ei−1 AND ei ≤ ei+1 )
(i = 1, 2, 3, . . . , i < n)

(13)

where ei (i = 1, 2, 3, . . . , n) represent the extreme points extracted from the pixel sequence and the points satisfying (13)
will be remained in the filtering operation.
III. IDV ACQUISITION
IDV acquisition is to acquire IDV’s representation in a particular coordinate system. When the microball or the capsule walks
inside the small intestine, a coordinate system O-Xc Yc Zc can
be defined by the image sensor as shown in Fig. 7 and if the
IDV can be represented in this coordinate, the attitude of the
endoscopy relative to the intestine can be known.
Then, the IDV is defined as a unit vector (14), in the coordinate
system O-Xc Yc Zc as shown in Fig. 7, which exactly represents
the axis direction of the human intestine relative to the camera
of WES
IDV = (sinϕ0 cosα, sinϕ0 sinα, cosϕ0 ).

(14)

As illustrated in Fig. 7, ϕ0 and α, respectively, represent the
angle between IDV and the shooting direction of the camera
−
→
((Zc )) and the angle between the projection of IDV on plane
Xc -O-Yc and axis Xc . Here, we use two angles (ϕ0 , α) in
the vector representation instead of pitch, yaw and roll because
the angle, ϕ0 , between IDV and the shooting direction of the
−
→
camera ((Zc )) is a key parameter in this paper which reflects the
deviation of the camera from the intestinal lumen.
To get the angles ϕ0 and α, the lumen information in the
captured image is utilized in this paper. In order to analyze the
IDV calculation method based on lumen detection for WES,
the mathematical models should be first built and then we can
calculate, simplify, and analyze the precision of IDV based on
the models.
A. Modeling and Notation
Here, the microball with six cameras is used as an example
because the situation of the capsule with one or two cameras
is simpler than that of the microball. We address the problem
with emphasis on the situation of the small intestine. Considering that the small intestinal wall is generally collapsed on the
microball, the relative relationship between the intestine and the
microball are modeled, respectively, when the intestinal lumen
is open—Model A [see Fig. 8(a)] and when the intestinal lumen is contractive—Model B [see Fig. 8(b)]. We can see that
the small intestine is idealized as a cylinder. And the related
parameters are defined as follows.
Point O 1 and O: The center of the microball and the center
of the image sensor.
Point O2 : The optic center of the lens.
Coordinate system O-Xc Yc Zc : Defined by the image sensor
−
→
and s (Zc ) is the shooting direction, i.e., the center axis direction
of the image sensor.
θ: The image sensor’s angle of field of view which is con→
−
→
−
structed by vectors I1 and I2 .
Rc : The radius of the cylinder is set to the radius of the
microball.
R1 : The distance between the center of the microball and the
optic center of the lens.
R2 : The illumination range.
The previous parameters are the physical parameters of the
→
−
→
−
microball. The zone defined by vectors k1 and k2 represents the
lumen region captured under the illumination condition.
In the next section, IDV (y ) represented in coordinate system O-Xc Yc Zc will be calculated, respectively, based on the

812

Fig. 8.

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 3, MARCH 2015

Modeling the small intestine and image capture process of the microball.

two models. For Model B, parameter d defines the diameter of
the contractive part and then d = 2Rc when the lumen is open.
B. IDV Acquisition Method
Based on the discussion earlier, the calculation of IDV (vector
y ) is equivalent to the calculation of ϕ0 and α. In order to acquire
these two angles, the utilization of the border of the lumen region
is intuitive and relatively simple. For instance, in Model A, the
→
−
→
−
angle between vector k1 and k2 can be known if the border
points A and B of the lumen region can be found in the image,
and angle α can also be obtained simultaneously, as illustrated
in Fig. 8(c). Then, angle ϕ0 can be calculated directly based on
→
−
→
−
the geometrical relationships and the angle between k1 and k2 ,
as shown in Fig. 8(a). However, in the real intestinal situation,
the border of the lumen region is not stable and sensitive to the
small intestinal motility and illumination, so it is difficult to find
the corresponding points like A and B in Fig. 8(c) to calculate
ϕ0 and α.
In order to solve the problem discussed earlier, another structure information—geometric center, centroid, is selected to be
involved in the calculation, with consideration of its merits—it
is relatively stable and easy to be extracted with lumen detection.
Fig. 9 shows the explanatory diagram concerning captured image and IDV calculation method based on a single static wireless
endoscopic image.
If the image contains the lumen, the angle pair (ϕ, α) can be
calculated with the geometric center of the lumen region in the
image and the geometrical relationships illustrated in Fig. 8(a)
−−→
and (b), where ϕ is the angle between vector GO2 (point G
in plane Xc -O-Yc represents the geometric center of the lumen
region in the image as shown in Figs. 8 and 9) and the shooting

Fig. 9. Explanatory diagram concerning angles α and ϕ based on a single
static wireless endoscopic image.

−
→
direction of the camera ((Zc )s). The computational formulas
are as follows:

ϕ = tan

−1

(x0l − x0i )2 + (y0l − y0i )2 · psize
f


(15)

WANG et al.: LUMEN DETECTION-BASED IDV ACQUISITION METHOD FOR WIRELESS ENDOSCOPY SYSTEMS

⎧
 
ya
⎪
−1
⎪
tan
⎪
⎪
⎪
x
a
⎪
⎪
 
⎪
⎪
ya
⎪
⎪
⎪
2π + tan−1
⎪
⎪
x
a
⎪
⎪
 
⎪
⎪
⎪
y
a
⎪
⎪
π + tan−1
⎪
⎪
xa
⎨
α=

⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩

xa > 0, ya > 0
xa > 0, ya > 0
(xa > 0, ya > 0)
OR (xa < 0, ya < 0)

0
π
2
3π
2
π

(16)

ϕ0 =
⎧ 
⎪
⎪
R22 − (d/2)2
⎪
⎪
⎪

ϕ, ϕ ≤ ϕ4
⎪
⎪
⎪
⎨ R22 − (d/2)2 + R1


⎪
2 − (d/2)2
⎪
⎪
2
R
R22 − (d/2)2
d
−
θ
2
⎪
⎪
⎪


ϕ
+
, ϕ > ϕ4
⎪
⎪
2 − (d/2)2 + R
⎩ R2 − (d/2)2 + R1
2
R
1
2
2

xa ≥ 0, ya = 0
xa = 0, ya > 0
xa = 0, ya < 0
xa < 0, ya = 0

where point G(x0l , y0l ) is the geometric center of the detected
lumen; point O(x0i , y0i ) is the center of the image sensor, psize
is the pixel size, and f is the focal length. And xa and ya in (16)
are calculated by xa = x0i − x0l , ya = y0i − y0l .
−−→
With (ϕ, α), we can calculate the vector k(GO2 ) represented
in the coordinate system O-Xc Yc Zc by (14). However, there
will be an error existing in the result if we use k instead of y .
Fortunately, the accurate representation of y defined by ϕ0 can
be estimated with k defined by ϕ. Specially, ϕ0 represents the
angle between the shooting direction s and the cylinder axis
which is defined by vector y .
Based on Model B which includes the situation defined by
Model A, the relationship between ϕ which is the angle calculated based on the centroid of the lumen, and the accurate
angle ϕ0 can be formulated. However, the derived formula is
so complicated that the explicit formulation of ϕ0 along with ϕ
is difficult to be obtained because the calculation includes arc
tangent, sine, and square root. With consideration of method
feasibility, appropriate simplification is considered. According
to the actual situation, some expected parameters are defined
by R1 = 4.6 mm, R2 = 20 mm, Rc = 7.5 mm, θ = π2 , and the
corresponding simplified formulas are shown as follows.
(a) 0 < d < d0 , as shown at the bottom of the page.
(b) d0 ≤ d ≤ 2Rc

813

(17)
where d0 ≈ 4.8 mm and the critical angles are defined by

2
2
d R2 − (d/2) + R1

ϕ1 =
, ϕ2
2
R1 R22 − (d/2)2
=

d
θ
− 
, ϕ3
2
2
2 R2 − (d/2)2

=

d
θ
θ
, ϕ4 = −  2
.
2
2 2 R2 − (d/2)2

(18)

When the lumen is open (Model A), i.e., d = 2Rc , the formulas are relatively simple, which are illustrated as
⎧ 
⎪
R22 − Rc2
⎪
⎪

ϕ ≤ ϕ
⎪
⎨ R2 − R2 + R ϕ,
1
c
2
ϕ0 =


⎪
2 R22 − Rc2
2Rc − θ R22 − Rc2
⎪
⎪
⎪


ϕ+
, ϕ > ϕ
⎩
R22 − Rc2 + R1
2 R22 − Rc2 + R1
(19)
where
Rc
θ
ϕ = −  2
.
(20)
2
R2 − Rc2
As the parameter d, i.e., the diameter of the contractive intestine, is not a prior quantity, we need one more equation simultaneous with (17) to calculate ϕ0 . Since the area of the lumen
extracted from the image can be known easily, the other equation can be deduced based on the ratio between the area of the
lumen and the area of the image (denoted as ratio_a) and it can
be represented by f (ratio a, ϕ0 , d, R1 , R2 , θ) = 0. However,

ϕ0 =
⎧ √
2
2
⎪
⎪
√ 2R 2 −(d/2)
ϕ
ϕ ≤ ϕ1
⎪
2
⎪
R
−(d/2)
+R
⎪
1
2
⎪
 
⎪

⎪
⎪
⎪
1
⎪
2 − (d/2)2 − R
⎪

R22 − (d/2)2 ϕ
R



⎪
1
c
⎪
2
⎪
R
2
2
2
2
⎪
⎨ Rc2 − (d/2) R22 − (d/2) + R21 Rc2 − (d/2) − R21 R22 − (d/2) − 21



⎪
⎪
2
2
d
2
2
⎪
−4
Rc − (d/2) − R2 − (d/2) − R1
ϕ1 ≤ ϕ ≤ min(ϕ2 , ϕ3 )
⎪
⎪
⎪
⎪
⎪
⎪

 

 
⎪
⎪
1
1
⎪
2
2
⎪
2
2

⎪
Rc − (d/2) − R1 ϕ −
ϕ2 < ϕ ≤ ϕ3 (if ϕ2 < ϕ3 )
2
θ Rc − (d/2) − θR1 − d
⎪
⎪
2
⎩ R2 − (d/2)2
c

814

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 3, MARCH 2015

TABLE I
ERROR CHARACTERISTICS OF IDV WITH DIFFERENT NONIDEAL FACTORS
Error
R n i d (%)
10
20
30

Mean value

Standard deviation

(−0.00000, −0.00000, −0.00130)
(0.00000, −0.00000, −0.00350)
(0.00000, 0.00000, −0.00577)

0.012
0.031
0.051

For the convenience of discussion, a nonideal factor Rnid is
defined to represent the nonideal degree
Rnid =

Fig. 10.

Nonideal model.

f (ratio a, ϕ0 , d, R1 , R2 , θ) = 0 is also a transcendental equation with complex calculations and it is difficult to solve the
angle ϕ0 independent with d. Here, we address the issue by estimating d with equation f (ratio a, ϕ0 = 0, d, R1 , R2 , θ) = 0
and the formula is shown by

ratio a
.
(21)
d = 2R2 tan (θ/2)
1 + ratio a · tan2 (θ/2)
In order to evaluate the simplification results (17) and (18)
and the formula for estimating d (21), the angle error of IDV
caused by the
 two
 items is analyzed by all possible combinations
of ϕ (ϕ ∈ 0, π4 with θ = π2 ) and d (d ∈ (0, 2Rc ]). The mean
value and standard deviation of the error are, respectively, 0.46°
and 0.03°. The maximum value is about 3.66°. We can see
that the error caused by simplification and contractive diameter
estimation is small and it will be verified in the experiment
section that the results can be accepted for practical demands.
IV. DISCUSSION OF IDV ACQUISITION
A. Analysis of Nonideal Model
For further consideration, the practical small intestine is not
an ideal cylinder with some wrinkles and one side of the intestinal wall may collapse to some extent due to gravity. Generally,
the collapse becomes larger and larger with the decrease of the
contractive degree because the intestinal wall is more relaxant
when the lumen is open than that when the lumen is contractive.
Therefore, the worst case, i.e., the nonideal factor ΔR is introduced into Model A (see Fig. 10), is analyzed here. Comparing
Fig. 10 with Fig. 8(a), we can see that the vector k, which is
related to geometric center, will vary (from dashed line to solid
line as shown in Fig. 10), so the geometric center extracted
from the image will be deviated from the accurate location corresponding to Model A. Then, the calculation result based on
(15) will be affected due to the error of the geometric center
caused by nonideal factor. And the final calculation result of
IDV will also be affected.

ΔR
.
2Rc

(22)

In order to fully analyze the effect of nonideal factor Rnid ,
all of the possible locations of the collapse on the intestinal
wall relative to the camera in a particular shooting direction
have to be considered. As there are too many cases and it is
difficult to discuss them analytically, we make simulation to
obtain the mean value and standard deviation of the error of the
calculated IDV based on equal probability distribution of every
possible shooting direction. Considering that the WES has a
certain volume and the illumination is limited, we make analysis
of nonideal Rnid in the range of 0–30% and the results are shown
in Table I. Since the acquired IDV is represented by a unit vector
and it is dimensionless, the error is evaluated based on vector
calculation instead of scalar angle value in this paper. The error
center is the mean value of the error of the calculated IDV, and
error radius is indicated by the standard deviation of the error.
The error radius is the maximum value of the difference between
the calculated IDV and the accurate direction vector, which
represents the deviation degree of the estimated vector. The
relationship between the error radius and angle deviation value
is: angle deviation value = 2arcsin error 2radius . As illustrated in
Table I, the error radius indicated by the standard deviation
increases with the increase of Rnid . In order to intuitively see
the effect of nonideal factor in a specific shooting direction, the
relationship between the mean value or deviation of the angle
error caused by collapse of the intestinal wall, and the shooting
direction defined by (ϕ0 , α) are also analyzed, respectively. The
angle error as well as its mean value and standard deviation
are calculated only based on the magnitude of the error of IDV
in nonideal situations. Results show that the maximum value
of mean error induced by nonideal factor Rnid = 30% is about
3.5° when ϕ0 ≈ 21◦ and the corresponding standard deviation
is about 1.8°. The verification and evaluation of this result will
be given in the section of experiments (Section V-B and C).
B. Effect of Image Downsample
In order to reduce the computation complexity, Bayer-format
based R-channel 1/2∗ 1/2 downsample which is equivalent to
1/4∗ 1/4 downsample images is used as discussed in Section II.
And we will verify that the IDV calculation based on downsample images is accurate enough in the following discussion.
Assume that the region to be recognized is a M∗ M square,
its origin is (r1 , c1 ) and the image center is (rc , cc ), then

WANG et al.: LUMEN DETECTION-BASED IDV ACQUISITION METHOD FOR WIRELESS ENDOSCOPY SYSTEMS

815

TABLE II
the geometrical center of the M∗ M square before downsample
PERFORMANCE EVALUATION PARAMETER DEFINITIONS
(gr1 , gc1 ) and the geometrical center with restoring from the
downsample image (gr2 , gc2 ) can be calculated, respectively,
Precision (Pre.)
Sensitivity (Sen.)
Specificity (Spe.)
Accuracy (Acc.)
by (here the original point of the image is (1,1)):


TP
TP
TN
TN + TP
M −1
M −1
TP + FP
TP + FN
TN + FP
Total
, c1 +
(gr1 , gc1 ) = r1 +
(23)
2
2
TP: True positives. TN: True negatives.
 
 


FP: False positives. FN: False negatives.
r1 − 1
r1 + M − 1
(gr2 , gc2 ) = 2
+
−1
4
4
 pig intestine in vitro using the microball demo system. Finally,

 


c1 − 1
c1 + M − 1
we also make some experiments for accuracy and effectiveness
+ 1, 2
+
−1 +1 .
verification of the IDV acquisition method on the microball for
4
4
capturing images of ROI.
(24)

Then, the IDV without and with image downsample can be
calculated based on (15), (16), (19), and (23) or (24). And the
error of the IDV after image downsample compared with the
result calculated before downsample can be obtained by analyzing all kinds of the combination of M, r1 , and c1 . The mean
value and standard deviation of the error are, respectively, μ =
(−0.00587, −0.00702, 0.00049) and σ = 0.004, with practical
parameters adopted in this paper. We can see that image downsample has little effect on the IDV calculation and the verification and evaluation of this result will be given in the section of
experiments.
C. Summary of IDV Acquisition
According to the discussions earlier, by modeling the small
intestine and image capture process as well as a specific calculation method design based on lumen detection and structure
information (centroid of the lumen region) selection, the 3-D
physical direction of the intestine can be known using only one
2-D image. Once the lumen is detected in the image, the process
of calculating IDV is shown as follows.
1) First, the captured image should be corrected [27] because
the barrel distortion caused by the large field of view will
have a negative effect on the accuracy of the IDV.
2) Calculate the geometric center of the detected lumen by


i xi
i yi
, y0l =
(xi , yi ) ∈ LR C
x0l =
Area(LR C)
Area(LR C)
(25)
and the area ratio ratio_a = Area(LR_C)/Area(Image),
where Area(LR_C) and Area(Image), respectively, represent the area of the lumen and the captured image.
3) Calculate ϕ, α, and d [see (15), (16), and (21)].
4) Calculate ϕ0 [see (17)].
5) Calculate IDV [see (14)].
V. EXPERIMENTS AND RESULTS
In this section, the performance of the proposed methods will
be verified by experiments. For the lumen detection method,
the performance will be tested on nine patients’ video streams.
Some comparisons are made with other typical lumen detection
technologies. Meanwhile, the experiments for precision evaluation of the IDV given by the proposed method are made on the

A. Performance of Lumen Detection
The performance test of the proposed lumen detection method
is made on nine patients’ video streams which include different positions of the small intestine, i.e., duodenum, jejunum,
and ileum. It is noted that only the gray information not the
tissue structure information is the main feature adopted in the
lumen detection for IDV calculation. So, the method is not sensitive to the different positions of small intestine, since the gray
feature difference is very small among images of duodenum,
jejunum, and ileum. The image data’s resolution is 256∗ 256.
As the proposed approach is based on R-channel values with
1/2∗ 1/2 downsample, the effective resolution of images used
here is 64∗ 64.
Only the images of small intestine are considered here as the
proposed IDV acquisition method including lumen detection
and IDV calculation is just for small intestine. The original
images are manually labeled to provide the ground truth. To
test the lumen detection method, the images with lumen are
labeled as positive samples, while the images without lumen
appearance are labeled as negative samples. The performance of
the proposed lumen detection method is measured by precision,
sensitivity, specificity, and accuracy, respectively (see Table II).
1) Performance Evaluation: First, the proposed adaptive
threshold method and radial texture detection method are, respectively, tested on the nine patients’ datasets. The adaptive
threshold method for noncompletely contractive lumen detection can reach 95.2% precision and 92.0% sensitivity for distinguishing noncompletely contractive lumen images, and wall
images or completely contractive lumen images, while the radial texture detection method for completely contractive lumen
detection can reach 97.3% precision and 91.2% sensitivity.
The proposed lumen detection method is the combination of
the two methods discussed earlier, and the exhaustive test results on the nine patients’ datasets of small intestinal images are
illustrated in Table III. We can see that the proposed lumen detection method can achieve 95.5% precision, 98.1% sensitivity,
and 92.6% specificity averagely.
2) Comparison: The performance of the proposed intestinal
lumen detection method is compared with other two methods
[10], [12], because they are also based on a single image. First,
for comparison of the method capability, neither of the two
methods can deal with the case of completely contractive lumen.

816

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 3, MARCH 2015

TABLE III
PERFORMANCE OF THE LUMEN DETECTION METHOD
Study
1
2
3
4
5
6
7
8
9

Fig. 11.

Total

Number of I l u m e n

Number of I w a l l

Pre. (%)

Sen. (%)

Spe. (%)

Acc. (%)

14 420
20 024
25 643
19 674
22 780
17 845
23 675
24 756
22 542

12 508
16 903
21 505
16 482
19 237
14 777
19 695
20 448
18 872

1912
3121
4138
3192
3543
3068
3980
4308
3670

98.7
97.6
95.4
91.7
95.2
94.7
93.3
99.7
93.6

99.1
97.5
98.8
98.3
97.0
96.3
98.9
97.8
98.9

91.2
95.7
92.8
89.9
91.6
94.6
85.6
99.6
92.4

98.0
97.3
96.4
94.4
95.0
95.4
94.5
98.6
95.9

Experimental platforms based on the FPGA microball system and the SoC microball system.

Second, the performance parameters are compared as follows.
The method in [10] can detect the lumen image but not extract
the lumen region, and its detection performances are 70.5% precision, 89.5% sensitivity, and 90.9% accuracy averagely, while
the proposed method can extract the lumen region accurately,
and achieves 95.5% precision, 98.1% sensitivity, and 96.2% accuracy averagely. Since there is no lumen region extraction in
[10], the method has lower complexity (0.002 s/frame [Intel (R)
Core (TM) 2 Duo CPU and 4 GB RAM]) than that of the proposed method (0.02 s [Intel (R) Core (TM) 2 Duo CPU E8300
at 2.83 GHz, 1.96 GB RAM]). The method in [12] can extract
the lumen region, but it needs 3 s to process a single image
([Conventional Pentium PC]). The complexity of our method
is much lower. As the other performance parameters are not
reported in [12], we cannot compare the method with the proposed method further. As discussed earlier, the proposed lumen
detection method is superior with the compromise among capability, performance, and complexity.

B. IDV Acquisition Experiments
In the previous section, the real intestinal images are used
to test the lumen detection method and the plastic colon and
in vitro pig intestine are adopted to evaluate the IDV calculation method in this section. As shown in Fig. 11, two kinds of

experimental platforms are designed to test the proposed IDV
acquisition method: a) Soft plastic tube platform, which includes
a microball demo system based on field-programmable gate array (FPGA) (diameter ϕ ≈ 17 cm) and a cylindrical soft plastic
tube to simulate the small intestine [see Fig. 11(a)]; b) in vitro
pig intestine platform, which includes a microball demo system based on system on chip (SoC) [28] (diameter ϕ < 4 cm)
and in vitro pig intestine [see Fig. 11(b)]. It is noted that there
is an attitude sensing unit embedded in the microball systems.
Platform (a), which is convenient for improving the method, is
used to verify the effectiveness and accuracy of the proposed
method preliminarily. With consideration of method feasibility
in practice, the platform (b) is designed for testing the method
in real pig intestine.
1) Precision Evaluation of the IDV: In order to evaluate the
precision of IDV calculated by the proposed method, a high
precision attitude sensing system (about 0.5° for angle measure
in ideal situations) is used as the reference in this experiment.
As the location of the lumen relative to the image sensor
 is
symmetric, we rotate the microball in an angel range 0, π2 , and
calculate the vector change, respectively, based on the proposed
method and attitude information given by the attitude sensing
system.
By comparing with the results of attitude sensing system,
the precision of the IDV can be evaluated, respectively, on the

WANG et al.: LUMEN DETECTION-BASED IDV ACQUISITION METHOD FOR WIRELESS ENDOSCOPY SYSTEMS

817

TABLE IV
PRECISION EVALUATION OF THE IDV

(a) Soft
plastic tube
platform

(b) In vitro
pig intestine
(0–30%
collapse)

Amount of
measurements

Mean value

Standard
deviation

A

140

(−0.00164, −0.00103,
−0.00008)

0.038

B

140

(−0.00027, 0.00302,
0.00030)
(−0.00629, 0.00097,
0.00061)

0.075

140

0.085

A: no collapse; B: 30% collapse.

two experimental platforms and the results are illustrated in
Table IV. On platform (a), we made two kinds of experiments: A) ideal cylinder without collapse [see Fig. 11(a)-A]; B)
nonideal cylinder with consideration of 30% collapse (Rnid ≈
30%, where Rnid is defined by (22) of Section IV-A) of the
intestinal wall in order to verify the results of theoretical prediction discussed in Section IV-B and evaluate the precision of
the IDV in nonideal situations [see Fig. 11(a)-B]. We made experiments on the plastic colon with white color and pink color
and the results are similar. On pig intestine in vitro, the intestinal
contraction motility is realized by air inflation and suction while
the collapse of the intestinal wall happens simultaneously due
to gravity, as illustrated in Fig. 11(b). The picture is got in the
light, but we made experiments in darkness and the microball
is illuminated by four LED lights. The results show that the
mean value and standard deviation of the error, respectively, are
μ
 ≈ (−0.00629, 0.00097, 0.00061), and σ ≈ 0.085 by making
about 140 times of measurements on the in vitro pig intestine.
It means that the error of the calculated IDV is limited by a
sphere with center (−0.00629, 0.00097, 0.00061) and radius
0.085. From Table IV, we can see that the error on pig intestine
platform is a little larger than that on soft plastic tube platform.
There are two main reasons: one is that the precision of the
data obtained by the attitude sensor in the microball based on
SoC (platform (b)) is lower than that in the microball based on
FPGA (platform (a)), because the attitude sensor in the SoC
system is more sensitive to intrinsic noise; the other one is that
the situation is more complicated in real intestine.
It is noted that image downsample is adopted for this result. And it shows that the proposed method can provide IDV
estimation with very high precision.
2) Effect of Image Downsample: As the Bayer-format
R-channel 1/2∗ 1/2 downsample images are used in the method,
we also calculate the error caused by downsample compared
with the results of full resolution images in the experiment in
order to verify the theoretical analysis discussed in Section IV-B.
Based on the experimental data of platform (a), the mean value
and standard deviation of the error of IDV caused by downsample are, respectively, (−0.00019, −0.00058, −0.00005) and
0.004. And it is matched with theoretical results illustrated in
Section IV-B. In order to intuitively see the effect of downsample, the angle error based on the magnitude of the error for all

Fig. 12. Error angle caused by 1/4∗ 1/4 downsample compared with full resolution results.

TABLE V
EXPERIMENTAL DATA FOR CALCULATING POCSC

(a) Soft plastic
tube platform

Number of the
images of ROI

Total number of
the captured
images

POCSC (%)

A

2376

2386

99.6

B

1605
3925

1635
4089

98.2
96.0

(b) In vitro pig
intestine (0–30%
collapse)
A: no collapse; B: 30% collapse.

measurements is given in Fig. 12. We can see that the maximum angle error caused by downsample in the experiment is
about 0.4°. So, image downsample has little effect on the IDV
calculation.
C. Experiments of Capturing Images of ROI Based on IDV
The experiment of capturing images of ROI is made to verify
the accuracy and effectiveness of the IDV acquisition method
based on the microball demo system to select cameras. Here,
ROI is defined as the region of the intestinal wall.
The experimental process is shown as follows. The microball
will capture a few images when it travels along the soft plastic
tube or pig intestine. The images will be processed in turn until
one image contains the lumen and the lumen is detected and
then the IDV will be given out. Combining the attitude relative
to the human body (ARHB) given by the attitude sensing unit at
this moment, the initial attitude of the microball relative to the
small intestine (IAMRSI) can be obtained. Then, in the next period of time, the corresponding AMRSI can be calculated based
on IAMRSI and current ARHB. And the camera for capturing
images of ROI next time can be selected based on this information. Since we define ROI as the intestinal wall, the probability
of correctly selecting cameras (POCSC) can be obtained by calculating the ratio between the number of images of ROI and
the total number of the captured images. For situation (a)-A,
(a)-B and (b), the POCSC are, respectively, 99.6%, 98.2%, and
96.0%, as illustrated in Table V. We can see that the proposed

818

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 3, MARCH 2015

Fig. 15. Extracted lumen is not accurate when there is a lot of turbid liquid in
the lumen.

Fig. 13. Angle error curve of the proposed method for calculating the IDV
(ideal situation).

POCSC is about 94.9% averagely, while the value is about
94.6% on pig intestine in vitro. From the results of theoretical
analysis, we can see that the accuracy and effectiveness of the
proposed method for selecting cameras are very high. Since it
is difficult to cover all possible attitudes of the microball in the
experiments, almost all the selections of cameras are correct in
our experiments.
For the proposed IDV calculation method, the algorithm may
falter when there is a lot of turbid liquid in the lumen as illustrated in Fig. 15. For this case, the proposed adaptive threshold
method may fail to acquire a proper threshold to exactly extract
the lumen. Then, the calculated IDV may be also not accurate
as it is based on the lumen detection result. Considering that the
patient should be fasting and get gut purge before endoscopy
examination, the number of images which have a lot of turbid
liquid and bubbles is small and this kind of images is not considered here.
VI. CONCLUSION

Fig. 14.

Probability distribution of the error in ideal situation.

method has a high effectiveness in selecting cameras to capture
images of ROI for the microball.
Then, we will make a theoretical analysis on why the POCSC
is high in the experiments discussed earlier.
For image capture controlling of the microball, only the angle
error of the IDV will be considered due to the symmetry of the
spatial relationship between the cubic structure constructed by
the six cameras and the small intestine. So, we make error
analysis of IDV only based on the magnitude of the error and
calculate the angle error corresponding to the error magnitude of
IDV. Then, the angle error curve of the proposed method and the
probability distribution of the angle error can be, respectively,
obtained. Figs. 13 and 14 show the results in ideal situation
(platform (a)-A). The mean value and standard deviation of the
error are, respectively, 1.97° and 0.87°. For nonideal situation
with 30% collapse of the intestinal wall (platform (a)-B) and in
vitro pig intestine (platform (b)), we can analyze the angle error
similarly. The mean value and standard deviation of the angle
error are, respectively, 3.30° and 2.70° for platform (a)-B and
3.66° and 3.23° for platform (b).
Based on the precision analysis of the IDV given earlier, a
simulation is made to get the theoretical value of POCSC. In
ideal cylinder, the POCSC can achieve about 95.9% averagely.
With consideration of 30% collapse of the intestinal wall, the

The work in this paper mainly discusses the issues of detection
of the intestinal lumen and IDV acquisition based on Bayerformat images captured by WESs. The IDV information can
provide attitude information of the wireless endoscopic capsule
or microball relative to the intestinal wall. This information can
help to control capturing images of ROI in the wireless microball
and can also be used for navigation of the WES and automatic
propulsion of conventional endoscope.
For lumen detection, a method involving Bayer-format downsample, adaptive threshold segmentation and radial texture detection is proposed. An explicit and feasible IDV calculation
method with only one single static image by modeling the small
intestine and image capture process is also given. The performance of the proposed methods is verified based on a large
number of real wireless capsule endoscopic images and the microball demo system, respectively. Experimental results indicate
that the lumen detection method can reach 95.5% precision and
98.1% sensitivity. Moreover, the error of the calculated IDV
on the in vitro pig intestine is limited by a sphere with center
(−0.00629, 0.00097, −0.00061) and radius 0.085. Finally, the
accuracy and effectiveness of this IDV acquisition method is
verified by the microball system to capture images of ROI as
expected. On the in vitro pig intestine, the POCSC can achieve
about 94.6% theoretically and 96.0% in the experiments, as it
is difficult to cover all possible attitudes of the microball in the
experiments.

WANG et al.: LUMEN DETECTION-BASED IDV ACQUISITION METHOD FOR WIRELESS ENDOSCOPY SYSTEMS

REFERENCES
[1] G. Iddan, G. Meron, and A. Glukhovsky, “Wireless capsule endoscopy,”
Nature, vol. 405, p. 417, 2000.
[2] X. Xie, G. L. Li, and X. K. Chen, “A low-power digital IC design inside
the wireless endoscopic capsule,” IEEE J. Solid-State Circuits, vol. 41,
no. 11, pp. 2390–2400, Nov. 2006.
[3] T. Nakamura and A. Terano, “Capsule endoscopy: Past, present, and
future,” J. Gastroenterol., vol. 43, pp. 93–99, 2008.
[4] B. Kim, Y. Jeong, and T. Kim, “Micro capsule type robot,” U.S. Patent
6 719 684, 2004.
[5] M. Q.-H. Meng, T. Mei, and J. X. Pu, “Wireless robotic capsule endoscopy:
State-of-the-art and challenges,” in Proc. World Congr. Intell. Control
Autom., vol. 6, 2004, pp. 5561–5564.
[6] S. Bar-Meir and M. B. Wallace, “Diagnostic colonoscopy: The end is
coming,” Gastroenterology, vol. 131, pp. 992–994, 2006.
[7] Y. K. Gu, X. Xie, and G. L. Li, “Design of micro-ball endoscopy system,”
in Proc. IEEE Biomed. Circuits Syst. Conf., 2012, pp. 208–211.
[8] F. Vilarino, P. Spyridonos, and F. DeIorio, “Intestinal motility assessment
with video capsule endoscopy: Automatic annotation of phasic intestinal contractions,” IEEE Trans. Med. Imag., vol. 29, no. 2, pp. 246–259,
Feb. 2010.
[9] F. Vilarino, P. Spyridonos, and F. Azpiroz, “Cascade analysis for intestinal contraction detection,” Int. J. Comput. Assist. Radiol. Surg., vol. 1,
pp. 9–10, 2006.
[10] G. Gallo and A. Torrisi, “Lumen detection in endoscopic images: A boosting classification approach,” Int. J. Adv. Intell. Syst., vol. 5, nos. 1/2, pp.
127–134, 2012.
[11] M. Yagihashi, Y. Niwa, and M. Nakamura, “Analysis of large bowel
peristalsis with video capsule endoscopy,” in Proc. Int. Conf. Complex
Med. Eng., 2007, pp. 766–769.
[12] X. Zabulis, A. A. Argyros, and D. P. Tsakiris, “Lumen detection for
capsule endoscopy,” in Proc. IEEE Int. Conf. Intell. Robots Syst., 2008,
pp. 3921–3926.
[13] S. Xia, S. M. Krishnan, and M. P. Tjoa, “A novel methodology for extracting colon’s lumen from colonoscopic images,” J. Systemics Cybern.
Informat., vol. 1, pp. 7–12, 2003.
[14] S. J. Phee, W. S. Ng, and I. M. Chen, “Automation of colonoscopy—Part ii:
visual-control aspects,” in Proc. Int. Conf. IEEE Eng. Med. Biol. Soc., vol.
17, 1998, pp. 81–88.
[15] S. M. Krishnan, C. S. Tan, and K. L. Chan, “Closed-boundary extraction
of large intestinal lumen,” in Proc. Int. Conf. IEEE Eng. Med. Biol. Soc.,
vol. 1, 1994, pp. 610–611.
[16] K. V. Asari, “A fast and accurate segmentation technique for the extraction
of gastrointestinal lumen from endoscopic images,” Med. Eng. Phys.,
vol. 22, pp. 89–96, 2000.
[17] C. Kwoh and D. Gillies, “Using Fourier information for the detection
of the lumen in endoscope images,” in Proc. TENCON Conf., 1995,
pp. 981–985.
[18] H. N. a. T. Nonami, “Endoscope inserting direction detecting method and
endoscope inserting direction detecting system,” US Patent 7 905 829 B2,
Mar. 15, 2011.
[19] J. Hasegawa and T. Nonami, “Endoscope insertion direction detecting device, endoscope insertion direction detecting system, and endoscope insertion direction detecting method,” US Patent 2006/0015011 A1,
Jan. 19 2006.
[20] M. L. Dertouzos and Z. Fluhr, “Minimization and convexity in threshold
logic,” IEEE Trans. Electron. Comput., vol. EC-16, no. 2, pp. 212–215,
Apr. 1967.
[21] E. T. Bullmore, J. Suckling, and S. Overmeyer, “Global, voxel, and cluster
tests, by theory and permutation for a difference between two groups of
structural MR images of the brain,” IEEE Trans. Med. Imag., vol. 18,
no. 1, pp. 32–42, Jan. 1999.
[22] C. P. Y. Beevi and S. Natarajan, “An efficient video segmentation algorithm
with real time adaptive threshold technique,” Int. J. Signal Process. Image
Process. Pattern Recog., vol. 2, pp. 154–168, Dec. 2009.
[23] A. N. M. R. Karim and M. G. Alam, “Dynamic threshold for morphological change detection algorithm,” J. Convergence Inf. Technol., vol. 4,
pp. 53–58, 2009.
[24] S. Y. Chien, Y. W. Huang, and B. Y. Hsieh, “Fast video segmentation
algorithm with shadow cancellation, global motion compensation, and
adaptive threshold techniques,” IEEE Trans. Multimedia, vol. 6, no. 5,
pp. 732–748, Oct. 2004.
[25] K. Fukunage, Introduction to Statistical Pattern Recognition. New York,
NY, USA: Academic, 1972, pp. 260–267.

819

[26] N. Ostu, “A threshold selection method from gray-level histogram,” IEEE
Trans. Syst., Man, Cybern., vol. SMC-9, no. 1, pp. 62–66, Jan. 1979.
[27] Z. Y. Zhang, “A flexible new technique for camera calibration,” IEEE
Trans. Pattern Anal. Mach. Intell., vol. 22, no. 11, pp. 1330–1334,
Nov. 2000.
[28] Y. K. Gu, G. L. Li, and X. Xie, “The design and implementation of a
chipset for the endoscopic micro-ball,” in Proc. IEEE Int. Symp. Circuits
Syst., 2012, pp. 2633–2636.

Dan Wang received the B.S. and M.S. degrees from
the Institute of Microelectronics, Tsinghua University, Beijing, China, in 2010 and 2013, respectively.
Her researches focus on the image processing
and pattern recognition, especially for biomedical
images.

Xiang Xie received the Ph.D. degree from the Institute of Microelectronics, Tsinghua University, Beijing, China, in 2005.
He is now an Associated Professor with the Institute of Microelectronics, Tsinghua University. His
research fields cover SoC design, image processing,
biomedical electronics, and pervasive HCI. He is the
author or co-author of more than 80 papers, two
books, and one book chapter in the related research
fields. He has filed over ten patents and applied for
over ten patents in this research field.

Guolin Li received the B.S., M.S., and Ph.D. degrees
from the Department of Electronics Engineering,
Tsinghua University, Beijing, China, in 1993, 1998,
and 2002, respectively.
He is currently an Associate Professor at Tsinghua
University. His current research interests include the
circuit design of RFIC, WPT, etc.

Zheng Yin’s, photograph and biography not available at the time of publication.

Zhihua Wang (M’99–SM’04) received the B.S.,
M.S., and Ph.D. degrees in electronic engineering
from Tsinghua University, Beijing, China, in 1983,
1985, and 1990, respectively.
In 1983, he joined the faculty at Tsinghua University, where he has been a Full Professor since 1997
and Deputy Director of the Institute of Microelectronics since 2000. He is coauthor of ten books and
book chapters, more than 90 papers in international
journals and more than 300 papers in international
conferences. He is holding 58 Chinese patents and
four US patent. His current research mainly focuses on CMOS RF IC and
biomedical applications.
Dr. Wang was the Chairman of IEEE Solid-State Circuit Society Beijing
Chapter during 1999–2009. He served as a technologies program committee
member of the IEEE International Solid-State Circuit Conference from 2005
to 2011. He has been a steering committee member of the IEEE Asian SolidState Circuit Conference (A-SSCC) since 2005 and has served as the technical
program chair for the 2013 A-SSCC. He is an Associate Editor for IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS and IEEE TRANSACTIONS
ON CIRCUITS AND SYSTEMS—PART II: EXPRESS BRIEFS.

