1370

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

MRI-Based Segmentation of Pubic Bone
for Evaluation of Pelvic Organ Prolapse
Sinan Onal, Susana K. Lai-Yuen, Paul Bao, Alfredo Weitzenfeld, and Stuart Hart

Abstract—Pelvic organ prolapse (POP) is a major women’s
health problem. Its diagnosis through magnetic resonance imaging
(MRI) has become popular due to current inaccuracies of clinical
examination. The diagnosis of POP on MRI consists of identifying
reference points on pelvic bone structures for measurement and
evaluation. However, it is currently performed manually, making it
a time-consuming and subjective procedure. We present a new segmentation approach for automating pelvic bone point identification
on MRI. It consists of a multistage mechanism based on texturebased block classification, leak detection, and prior shape information. Texture-based block classification and clustering analysis using K-means algorithm are integrated to generate the initial bone
segmentation and to identify leak areas. Prior shape information
is incorporated to obtain the final bone segmentation. Then, the
reference points are identified using morphological skeleton operation. Results demonstrate that the proposed method achieves
higher bone segmentation accuracy compared to other segmentation methods. The proposed method can also automatically identify
reference points faster and with more consistency compared with
the manually identified point process by experts. This research
aims to enable faster and consistent pelvic measurements on MRI
to facilitate and improve the diagnosis of female POP.
Index Terms—Bone segmentation, classification, magnetic resonance imaging (MRI), pelvic floor measurements, support vector
machines (SVMs).

I. INTRODUCTION
ELVIC organ prolapse (POP) is a serious health condition
that affects about 30–50% of women [1]. It occurs when
a pelvic organ such as bladder, uterus, small bowel and rectum
drops from its normal position and pushes against the vaginal
walls. POP is currently diagnosed through clinical examination
using the POP quantification (POP-Q) system [2]. However,
studies have shown that clinical examination is inadequate and
in disagreement with surgical findings [3], [4]. Groenendijk et al.

P

Manuscript received April 22, 2013; revised October 9, 2013, December 4,
2013, and January 15, 2014; accepted January 17, 2014. Date of publication
March 6, 2014; date of current version June 30, 2014. This work was supported
in part by the University of South Florida Interdisciplinary Research Development Grant. The work of A. Weitzenfeld was supported by NSF.
S. Onal and S. K. Lai-Yuen are with the Department of Industrial and Management Systems Engineering, University of South Florida, Tampa, FL 33620
USA (e-mail: sonal@mail.usf.com; laiyuen@usf.edu).
P. Bao and A. Weitzenfeld are with the Division of Information Technology,
University of South Florida, Tampa, FL 33620 USA (e-mail: pbao@usf.edu;
aweitzenfeld@usf.edu).
S. Hart is with the Department of Obstetrics and Gynecology, Division
of Female Pelvic Medicine and Reconstructive Surgery, University of South
Florida and USF Health Center for Advanced Medical Learning and Simulation
(CAMLS), Tampa, FL 33612 USA (e-mail: shart1@health.usf.edu).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2302437

Fig. 1. (a) Regions of interest with their reference points; (b) current and
proposed reference features [7].

[5] found that the diagnostic accuracy of clinical examination
for POP was 0.42.
Dynamic magnetic resonance imaging (MRI) is currently being used for assessing POP as it provides global assessment
of the movements and interactions of pelvic floor organs while
avoiding the use of ionizing radiation [6]. The current practice consists of identifying specific reference points on pelvic
bone structures manually on the midsagittal plane as shown in
Fig. 1(a) [7]. Based on these points, reference lines are drawn to
measure and define the severity of POP as shown in Fig. 1(b) [7].
Unfortunately, the manual identification of these points and
measurements is a time-consuming and subjective procedure.
Current studies have only analyzed small sample sizes resulting
in limited and noncomparable data [8], [9]. This has restricted
the correlation analysis of MRI measurements with clinical and
surgical outcomes as well as the validation of newly proposed
reference lines.
Dynamic MRI is a promising complementary diagnostic tool
for POP but appropriate validation has been limited. Automating
the identification of reference points, lines, and measurements
is expected to facilitate the high throughput analysis of images
and improve the evaluation of POP. To this aim, pelvic bone
structures need to be segmented and their corresponding reference points identified automatically. However, segmentation
of bone structures on MRI is a challenging task since the pixel
intensities of bones can be very similar to the pixel intensities of
other structures such as soft tissue, fat and air. For this reason,
challenges remain for bone segmentation on MRI.
Previous methods for segmentation on MRI include region
growing approaches [10], [11], active shape models [12], general deformable models [13]–[15], clustering methods [16],
and graph-based approaches [17]. Lorigo [18] segmented the
knee bone using texture-based geodesic active contours. Fripp
et al. [12] segmented the knee bone using three-dimensional
(3-D) active shape models initialized by affine registration to an

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

ONAL et al.: MRI-BASED SEGMENTATION OF PUBIC BONE FOR EVALUATION OF PELVIC ORGAN PROLAPSE

atlas. Shape models [19], normalized cuts [20], and graph cut
[21]–[23] have been used to segment the femur and hip bones,
spinal, and femoral head, respectively. Schmid and MagnenatThalmann [19] presented a technique based on physically based
deformable models and prior shape knowledge to segment the
femur and hip bones on MRI. Yin et al. [24] used graph cuts for
knee-joint bone and cartilage segmentation.
Recently, segmentation techniques based on statistical classification have been used for bone segmentation on MRI [25],
[26]. These techniques group pixels or voxels based on distinguished features such as intensities, gradients and texture. Simple intensity-based features do not provide successful segmentation results because different tissues have overlapping image
intensity values. Bourgeat et al. [25] used Gabor filter features
extracted from the phase of MR signal to improve texture discrimination in bone segmentation. van Ginneken et al. [26] combined texture-based classification with the anatomically valid
shape information of the chest structure to constrain the segmentation. Although these methods present promising results,
the main drawbacks are high computation time, initialization
sensitivity, definition of many parameters, and lack of leak detection processes.
In our previous work [7], we presented the framework for
semi-automated pubic bone segmentation on MRI. The current
paper builds upon our previously developed segmentation technique by addressing the leak detection problem to overcome
previously identified issues during the segmentation of structures on images with low contrast and image inhomogeneity.
In this paper, we present a multistage method that combines
texture-based block classification and clustering analysis using
K-means algorithm to identify leak areas. This is performed by
subtracting binary images obtained by classification from clustered binary images to effectively segment the bone structure.
In addition, a comprehensive analysis of the proposed segmentation framework compared to other segmentation algorithms is
presented in this paper.
The remaining of the paper is organized as follows. Section II
introduces the proposed segmentation and leak detection framework. The performance evaluation is presented in Section III
followed by the discussion and conclusions in Sections IV and
V, respectively.
II. SEGMENTATION FRAMEWORK
The pelvic floor measurements process on MRI starts with
the identification of reference points, which are located on three
different regions: pubic bone, sacral promontory, and coccyx
[see Fig. 1(a)]. Given that each region has unique characteristics,
different approaches have to be considered to identify these
points. For instance, points located on the pubic bone can be
identified by segmenting the pubic bone and its cartilage. On
the other hand, points on the vertebra can be considered as
corner points and can be extracted using a corner point detector.
Then, the points are connected through lines for pelvic floor
measurements.
Fig. 2 shows the overview of the proposed method. It consists
of three main stages: presegmentation, segmentation, and point

Fig. 2.

1371

Overview of the proposed multistage method.

identification. The model begins with noise reduction and contrast adjustment of the images followed by manual segmentation
of the pelvic floor structure for data training, and generation of
the statistical mean shape. In our approach, each region of interest (ROI) is subdivided into small blocks of 3 × 3 pixels to
classify them as bone or background blocks and to reduce computational cost. In the segmentation step, feature extraction of
the blocks based on intensity and texture features is performed
using independent significance feature selection method and sequential forward selection method. Then, blocks are grouped
as bone or background blocks using support vector machines
(SVMs) and K-means clustering to generate the initial segmentation. First phase morphological operation is used to eliminate
small regions that do not belong to the bone regions. The segmentation is finalized by incorporating the mean shape into the
initial segmentation. In the point identification step, points are
identified using skeleton operation and corner point detectors.
The detailed description of the proposed method is presented in
the following sections.
A. Presegmentation Stage
1) Dataset Description: MR images were obtained from a
3-T GE system (General Electric Company, GE Healthcare,
Buckinghamshire, UK) using an eight-channel torso phasedarray coil with the patient in a modified dorsal lithotomy position
(patient laying in the supine position with their knees slightly
elevated and abducted under a support). Dynamic MRI of the
pelvic floor structure was obtained using a T2-weighted singleshot turbo spin-echo (SSH-TSE) sequence in the midsagittal
plane for 23–27 s with a temporal resolution of 2 s (FOV 300 ×
300 mm2 , slice thickness 3 mm, TR/TE 2,000/75 ms, 20 image
sequences, in-plane resolution of 1.6 × 1.6 mm2 ). Subjects
were coached, prior to imaging, on performance of an adequate valsalva maneuver (straining maneuver) to observe the
movement of the pelvic organs from rest to maximum strain.
The image data has been preprocessed and de-identified.

1372

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

TABLE I
INTENSITY AND GLCM FEATURES

Fig. 3. K × L size cropped image (window) and m × n size blocks (blocks
are shown larger than 3 × 3 pixels for demonstration purposes).

Two-dimensional (2-D) dynamic MRI images of 25 patients
were analyzed in this study and each patient has 20 image sequences showing the pelvic floor structures from rest to maximum strain. Even though the bone structures are static during
the image sequences, the pelvic organs and other soft tissue
surrounding the bones are not static and move at each image
sequence. For this reason, we used the 20 images of each patient to train our model and improve the bone segmentation.
Then, after identifying the reference points on the 20 images of
each patient, the average of the reference points over the image
sequence was calculated.
2) Image Preprocessing: The first step of the proposed
method is to perform noise reduction by applying the convolution operation onto the raw image with the smoothing kernel.
In this study, we use a Gaussian kernel due to its computational
efficiency and ability to control the degree of smoothing. The
Gaussian kernel is expressed in the discrete form with a size
of 3 × 3 pixels. After noise reduction, image normalization is
performed to improve the contrast in the images by stretching
the range of intensity values. Minimum and maximum values
used for normalization are 0 and 255, respectively.
Prior shape information is acquired by generating the mean
shape of the pubic bone (bone and cartilage) from a set of
training images. To generate the mean shape, the pubic bone was
manually segmented by a radiologist on all the images and the
results were stored as a binary mask. Then, the ROI for the pubic
bone was cropped through a K × L sized window. The extracted
structures were aligned with respect to a set of reference axes
to remove the differences in shapes due to translation, scaling,
and rotation. An image was selected arbitrarily as the reference
shape. Then, the mean shape is created as a binary image as
described in our previous work [7], [27].
Finally, the ROI for the pubic bone is subdivided into small
blocks of m × n size as shown in Fig. 3. These small blocks
of pixels will be used for the classification process instead of
using individual pixels to increase computational efficiency and
to enable the use of texture features for classification.
B. Segmentation Stage
1) Feature Extraction: Feature selection is a challenging
task in the classification process to differentiate patterns accurately. Due to the low level contrast intensity of MRIs, intensity
based features alone do not provide enough information for the
classification. For this reason, texture features have been used

to improve the classification accuracy on MRI by providing information on the relative position between any two pixels [28].
Medical images possess different textures depending upon the
area of the body considered for imaging.
Gray level features are extracted from each block. In addition,
gray level co-occurrence matrix (GLCM) is utilized to extract
the texture features as in [28]. GLCM provides information on
the relative position between two pixels using horizontal left to
right direction. Table I shows the intensity and GLCM features
used in this study.
After feature extraction, a two-step feature subset selection is
performed. In the first step, irrelevant or redundant features are
removed using the independent significance feature selection
method as described in [29]. This is used to eliminate features
with a significance level lower than 2 as calculated from the
following equation:
|mean (Bonei ) − mean (Backgroundi )|
(1)
significancei = 
var (Bonei ) + var (Backgroundi )
n1 + n2
where Bonei represents the ith feature being measured from
bone blocks, Backgroundi indicates the ith feature being measured from background blocks, n1 and n2 are the corresponding
number of blocks for bone and background, respectively. Based
on the significance level, 12 independent significant features
were identified in this study.
In the second step of the feature subset selection process, the
final set of significant features for training the classifier is selected using the sequential forward selection method measured
by tenfold cross validation. In tenfold cross validation, we first
divide the feature set into k subsets of equal size. Each subset
is tested on the remaining k − 1 subsets using mean squared
error that minimizes the mean criterion value. This process continues until the addition of more features does not decrease the
criterion any further.
2) Block Classification: The classification of the image
blocks involves two steps: construction of the classifier and
prediction. In the first step, a classifier structure is constructed
based on the training data set using SVMs. Our implementation
of SVMs is designed to increase the speed of the classification
process by classifying blocks of pixels instead of classifying
each pixel. We trained SVMs using the “kernel trick,” which
allows the algorithm to fit the maximum-margin hyperplane in a
transformed feature space to provide for nonlinear decision
surface. The training vectors xi , i = 1, 2, ..., L are nonlinearly
mapped onto a high-dimensional feature space by Φ: IRM → F

ONAL et al.: MRI-BASED SEGMENTATION OF PUBIC BONE FOR EVALUATION OF PELVIC ORGAN PROLAPSE

Fig. 4. Proposed segmentation process: (a) Ground truth image, (b) block
classification (R c la ss ) with bone (white) and background (black), (c) first phase
classified image with morphological operations (R c la ss+ m o rp h ), (d) clustering (R c lu ste r ) with cartilage (white) and background (black), (e) leakage region detected (black area), (f) R c o m p le m e nt , (g) mean shape (R m e a n sh a p e ),
(h) first registration between (f) and (g) (R in itia l ), (i) union of (d) and
(h) (R in itia l+ c lu ste r ), (j) final registration between (g) and (i) (R ﬁ n a l ),
(k) final segmentation of pubic bone, and (l) morphological skeleton of final
segmentation.

and then a linear separation is attempted in F. If F is a Hilbert
space, K is a kernel function in the original space IRM that
describes the inner product in F
Φ (u) · Φ (v) = K (u, v) = (u · v + 1)2

(2)

where K (u, v) should satisfy Mercer’s condition that ensures
that the kernel function can always be expressed as the dot product between two input vectors in high dimensional space. This
transformed space of the SVM kernels is called a reproducing
kernel Hilbert space. The radial basis function kernel (RBF) was
employed in our training process to construct nonlinear SVMs
and is described as follows:
K (u, v) = exp(−γ ||u − v||2 ).

(3)

There are two parameters for an RBF kernel that need to
be determined: C representing the penalty parameter and γ
representing the RBF sigma parameter. tenfold cross validation
is used to in this study to identify the best (C, γ) so that the
classifier can accurately predict unknown data. After the blocks
are trained according to the selected features, the second step of
the segmentation process is to apply the model to test example
images using the built SVM classifier. The anticipated outcome,
Rclass , at the end of this process is a set of two groups of blocks
that are automatically classified as bone (white) and background
(black) as shown in Fig. 4(b).
Our classification method evaluates each block independently
based on the selected features. Since the classifier may produce
errors, a relaxation stage is needed to smooth the classifier’s
output. Therefore, first phase morphological operations are applied to the classifier’s output to remove the misclassified back-

1373

ground blocks. To fill the small gaps on the objects, the filling
operation is incorporated and then small regions that are fewer
than 100 pixels are removed using “thinning” followed by the
area opening operation. Image opening is done by using “diamond” structuring element that has a radius of 4. The result
Rclass+m orph is shown in Fig. 4(c).
Given the similar intensity characteristics of bone and soft
tissue, soft tissue regions may be occasionally included into
the bone region. This problem, which we consider as “leaks,”
occurs when the pubic bone and background regions (soft tissue,
cartilage, and fat regions) become joined together due to the lack
of strong edges between them. The following sections describe
our approach to address the leak problem and separate these two
regions.
3) Block Clustering: We propose a leak detection approach
based on integrating SVM classification and K-means clustering. K-means clustering is used since it is convenient for
medical images as the number of clusters (K) is usually known
for particular regions of human anatomy [30]. The region of the
pubic bone can be divided into four subregions representing the
bone, cartilage, fat, and background. Therefore, K is selected to
be 4 in this study. Since the basic K-means clustering is susceptible to initialization, we used a “bisecting K-means” algorithm
presented in [31]. The idea is to obtain K clusters by first splitting the set of all points into two clusters. Then, one of these
clusters is selected for splitting and the process continues until
K clusters are generated. The bisecting K-means algorithm is
less dependent on initialization because it performs several trial
bisections and takes the one with the lowest sum of the squared
error (SSE). The outcome of this process is the region called
Rcluster .
4) Leak Detection and Registration: After clustering the
blocks, the cluster that represents the cartilage is selected to
identify the leak as shown in Fig. 4(d). The clustered cartilage
region Rcluster is subtracted from the classified region after first
morphological operation Rclass+m orph to find the leakage area
Rleakage as seen in Fig. 4(e) (black region). Their complement
Rcom plem ent is shown in Fig. 4(f) (white region), and is calculated as follows:
Rcom plem ent = (Rclass+m orph − Rcluster ) (i, j) ≥ 1

(4)

where,
Rleakage = (Rclass+m orph − Rcluster ) (i, j) < 0.

(5)

As shown in Fig. 4(f), the region Rcom plem ent provides separated regions that include the desired bone region (largest
region in the figure), and the soft tissue and fat regions.
Rcom plem ent is edited by incorporating the statistical mean shape
Rm eanshap e , as shown in Fig. 4(g). Rm eanshap e is registered
with the Rcom plem ent by using similarity type image registration that considers rotation, translation and scaling as shown in
Fig. 4(h). The initialization problem was eliminated by using
the largest component in Rcom plem ent that corresponds to the
bone structure. Any small regions surrounding the bone structure were removed by morphological opening operations in the
previous steps. The mean square error metric was used as a similarity metric and step gradient descent approach was used for

1374

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

TABLE II
PERFORMANCE COMPARISON OF THE PROPOSED METHOD WITH
CLASSIFICATION METHOD ONLY

Fig. 5. (a) Reference bony joints for sacral promontory and coccyx. (b) Pelvic
floor reference points and lines generated by our method [7].

minimization. This results in the initial segmentation region
Rinitial


Transform
(6)
Rinitial = Rm eanshap e ⇐=====⇒ Rcom plem ent .
Then, as shown in Fig. 4(i), the correction step involves
adding the cartilage region Rcluster to Rinitial to obtain the preliminary region of the pubic bone Rinitial+cluster . The current
procedure for identifying the pelvic floor reference points on
MRI is based on the pubic bone and its cartilage (bone + cartilage). For this reason, our goal is to identify both the pubic bone
and its cartilage to determine the corresponding reference points
automatically. In our work, K-mean clustering is employed to
find the cartilage region and the texture-based classification provides the bone structure region. Therefore, we combine the two
regions to obtain the full bone + cartilage region to find the reference points for assessing POP. Finally, a second registration is
performed between the corrected image Rinitial+cluster and the
mean shape Rm eanshap e , with the same similarity type image
registration. At the end of this process, the final segmentation of
the pubic bone is obtained Rﬁnal , as shown in Fig. 4(j). Then,
the boundary of the pubic bone is extracted as shown Fig. 4(k).
This will be used to identify the reference points using the morphological skeleton operation as indicated in Fig. 4(l)


Transform
(7)
Rﬁnal = Rm eanshap e ⇐=====⇒ Rinitial+cluster .
C. Point Identification Stage
After segmentation, the reference points located on the pubic
bone can be found using the morphological skeleton operation,
which removes pixels on the boundaries of the pubic bone and
provides at least three branches of the skeleton without allowing
the object to break apart. The remaining pixels constitute the
image skeleton, whose extreme points indicate the reference
points 1, 2, and 3. For reference points 4 and 5, these can be
defined as corner points for which there are two dominant and
different edge directions on the local neighborhood of the point.
Consequently, these points can be detected using a corner point
detector such as the Harris corner detection algorithm [32] as
presented in our previous work [7] and shown in Fig. 5(a).
After identifying all the reference points, they are moved onto
the original MR image and used to generate the reference lines
as shown in Fig. 5(b) [7]. These points can also be used to
build other reference lines such as diagonal, obstetric, and true

conjugate lines, which could possibly be used for radiological
assessment of POP.
III. RESULTS
The validation of the proposed method was performed on a
representative clinical data set of 25 dynamic MRI. The database
was divided into a training set of 10 randomly selected images
and a testing set composed of the remaining 15 images. The
dynamic MRI of each patient consists of 20 image sequences.
The presented method was implemented using MATLAB 2012b
on a workstation with 3.00 GHz dual processors and 2 GB RAM.
A. Bone Segmentation
The performance of the proposed segmentation method was
measured by quantifying the region overlap between the manual and automated segmentations using the dice similarity index
(DSI) [25]. In addition to DSI, we used two additional measures: correct rate and area error measure (AEM) [33]. First, we
compared the segmentation results from our proposed method
vs. results from the texture-based classification method only as
shown in Table II. The texture-based classification method is
about 6 s faster than the proposed method. However, the segmentation accuracy of the texture-based classification is very
low with DSI and correct rate of 52% and 79%, respectively. It
was also observed that the segmented regions obtained with the
classification only method resulted in oversegmentation in most
of the cases. The AEM should be 0 for a perfect segmentation.
The classification only method also resulted in more negative
values indicating that the segmented regions are larger than
the manually segmented regions. On the other hand, our proposed method with the leak detection algorithm provides higher
accuracy for all cases with a DSI above 92% for 13 cases and a
correct rate above 95% for all cases.
In order to verify the quality of our proposed segmentation
technique, we compared our method with four commonly used
segmentation methods in medical image segmentation: region
growing [11], region-based active contour [14], graph-cut [23],

ONAL et al.: MRI-BASED SEGMENTATION OF PUBIC BONE FOR EVALUATION OF PELVIC ORGAN PROLAPSE

1375

and distance regularized level set [15]. In our study, the Taguchi
method [34] was used to analyze the significance of each variable in the performance of the segmentation processes. The
parameters used are given as follows:
1) Region growing: Absolute threshold level to be included:
10; maximum distance to the initial position: 20.
2) Region-based active contour: Alpha: 0.2; Max iteration:
250.
3) Graph-cut: 10 seeds for background and 10 seeds for
foreground; large constant K = 10; similarity variance
sigma = 1; terminal constant lambda = 1012 ; similarity
constant c = 108 .
4) Distance regularized level set: Time step = 1; coefficient
of the distance regularization, mu = 0.2/time step; inner
iteration = 10; outer iteration = 30; coefficient of the
weighted length, lambda = 5; coefficient of the weighted
area, alpha = –3; parameter that specifies the width
epsilon = 1.5.
As shown in Fig. 6, the region growing method is the fastest
segmentation method; however, its segmentation accuracy is the
lowest among the methods, with approximately 30% in DSI and
80% in correct rate. It can also be observed that the segmented
regions from the region growing method are smaller than the
manually segmented regions for all cases. The graph-cut and
distance regularized level set methods provide better results
than the region growing and region-based active contour for all
cases in terms of DSI and correct rate. However, both methods
have drawbacks such as longer computational time, initialization
sensitivity, and the need to select the best parameters. The AEM
rates for these methods are also very low compared to the region
growing and active contour methods.
Our proposed method provides the highest accuracy with
above 92% in DSI for 13 cases and above 95% in correct
rate metric for all cases. In terms of computational time, our
method is the second fastest method. Results also show that our
method only has one case with oversegmentation but with very
low error rate. Only two cases provided a smaller region when
compared with the manually segmented region. These results
demonstrate that our segmentation technique achieves higher
segmentation accuracy and performance compared to other segmentation methods.
B. Reference Points Identification
Our proposed method was used to identify the pelvic bone
and its reference points (p1, p2, and p3) and the reference points
on the vertebra (p4 and p5) on the testing images. We compared
the point locations identified by our method with the points
identified manually by three experts over three iterations. The
average of the three iterations is calculated to find the experts’
average point location. Table III shows the standard deviation
of each point identified by the experts over all the fifteen images. It can be observed that the manual identification of p4
vastly differs among the experts due to difficulties in identifying
the coccyx on the images. Interobserver reliability was also assessed by calculating the intraclass correlation coefficient (ICC)
for all five reference points. An ICC > 0.9 indicates excellent

Fig. 6. Performance comparison of the proposed method with other commonly
used segmentation methods: (a) dice similarity index, (b) correct rate, (c) AEM,
and (d) computation time.

agreement; between 0.9 and 0.6—good agreement; between 0.6
and 0.4—moderate agreement; and <0.4—poor agreement. Table IV provides the Hausdorff distance and the mean distance
between the point locations identified by our method and by
experts.

1376

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

TABLE III
MIN AND MAX STANDARD DEVIATION OF REFERENCE POINTS ON ALL TRIALS
ON 15 PATIENTS PERFORMED BY 3 EXPERTS

TABLE IV
HAUSDORFF DISTANCE AND MEAN DISTANCE BETWEEN POINT LOCATIONS BY
EXPERTS AND BY THE PROPOSED METHOD

As seen in Table V, the lowest accuracy obtained by the
proposed method was related to p4 and p5. This was due to
the anatomical location of these points, which are not easily
identifiable on the images in most cases. These differences can
be related to the results in Table III, where p4 and p5 had
the highest standard deviation among experts. It can also be
observed that the proposed method provided better results for
some patients (e.g., P15), while lower results on others (e.g., P1).
This is due to the disagreement on the location of the reference
points for some cases by the experts.
Our model currently requires user interaction to select the
regions of interest shown in Fig. 1(a). Our future work aims
to fully automate the process. In addition, we used the 2-D
dynamic MRI images of 25 patients that were approved by IRB
(IRB Study #Pro00007792). We are currently in the process of
obtaining IRB approval (IRB Study #Pro00002408) to acquire
more images to further test our model as our future work.
V. CONCLUSION

The accuracy of the automatically identified points by our
method was compared to the average location of the manually identified points, where the Euclidian distance is calculated
between the manually and automatically identified points as
shown in Table V. It can be observed that our method is able to
accurately identify all the reference points. In terms of computation time, the manual point identification process for each
patient that has 20 image sequences was about 10 min, while
our method took 4.5 min.

In this paper, we presented a scheme to semi-automatically
identify the reference points for evaluation of POP using MRI.
The points located on the pubic bone were identified by segmenting the pubic bone and then identifying its reference points.
The segmentation of bones on MRI is a challenging task due to
weak boundaries and image inhomogeneity. To overcome this
problem, a multistage segmentation mechanism using texturebased classification, leak detection, and prior shape information
is presented. The reference points of the pubic bone were identified using morphological skeleton operation whereas the points
located on the vertebra were identified by intersecting point detection methods. Experiments demonstrate that the presented
method provides more accurate and faster segmented regions
compared to other commonly used segmentation methods. The
point identification process is also accurate, faster, and consistent compared with the process of manual point identification
by experts. The presented method aims to overcome the current
limitations of manually identifying points and measurements on
MRI and to enable high throughput image analysis. In the future,
we will extend the method by fully automating the measurement
process for POP diagnosis.

IV. DISCUSSION

ACKNOWLEDGMENT

In this study, we present a new segmentation approach that
provides leak detection for automating pelvic bone point identification on MRI. Results demonstrate that the proposed method
achieves higher bone segmentation accuracy compared to other
segmentation methods. The proposed method can also automatically identify reference points faster and with more consistency
compared with the manually identified point process by experts.
When analyzing the intraobserver reliability for reference
point identification amongst the three experts, we found no significant difference between measurements taken by the three
experts for p1, p2, and p3. We also found good agreement but
high standard deviation for p4 and p5. On the other hand, the
proposed method is fully deterministic, i.e., it can identify the
exact same location for each reference point for all the cases.

The authors would like to thank Dr. R. Kedar and Dr. K.
Greene for performing the manual segmentation and point identification process.

TABLE V
EUCLIDIAN DISTANCE (IN MILLIMETERS) BETWEEN POINTS IDENTIFIED
MANUALLY AND USING OUR MODEL FOR 15 PATIENTS

REFERENCES
[1] P. Dallenbach, I. Kaelin-Gambirasio, S. Jacob, J. B. Dubuisson, and
M. Boulvain, “Incidence rate and risk factors for vaginal vault prolapse
repair after hysterectomy,” Int. Urogynecol. J., vol. 19, pp. 1623–1629,
2008.
[2] R. C. Bump, A. Mattiasson, K. Bo, L. P. Brubaker, J. O. L. DeLancey,
P. Klarskov, B. L. Shull, and A. R. B. Smith, “The standardization of
terminology of female pelvic organ prolapse and pelvic floor dysfunction,”
Amer. J. Obstet. Gynecol., vol. 175, pp. 10–17, 1996.
[3] A. Fayyad, S. Hill, V. Gurung, S. Prashar, and A. Smith, “How accurate is
symptomatic and clinical evaluation of prolapse prior to surgical repair?”
Int. Urogynecol. J., vol. 18, pp. 1179–1183, 2007.

ONAL et al.: MRI-BASED SEGMENTATION OF PUBIC BONE FOR EVALUATION OF PELVIC ORGAN PROLAPSE

[4] D. Altman, A. Lopez, J. Kierkegaard, J. Zetterstrom, C. Falconer,
J. Pollack, and A. Mellgren, “Assessment of posterior vaginal wall prolapse: Comparison of physical findings to cystodefecoperitoneography,”
Int. Urogynecol. J. Pelvic Floor Dysfunct., vol. 16, pp. 96–103, 2005.
[5] A. G. Groenendijk, V. P. vander-Hulst, E. Birnie, and G. J. Bonsel, “Correlation between posterior vaginal wall defects assessed by clinical examination and by defecography,” Int. Urogynecol. J., vol. 19, pp. 1291–1297,
2008.
[6] M. C. Colaiacomo, G. Masselli, E. Polettini, S. Lanciotti, E. Casciani,
L. Bertini, and G. Gualdi, “Dynamic MR imaging of the pelvic floor: A
pictorial review,” Radiographics, vol. 29, no. 3, p. e35, 2009.
[7] S. Onal, S. Lai-Yuen, P. Bao, A. Weitzenfeld, and S. Hart, “Image based
measurements for evaluation of pelvic organ prolapse,” J. Biomed. Sci.
Eng., vol. 6, pp. 45–55, 2013.
[8] S. R. Broekhuis, J. J. Futterer, J. O. Barentsz, and M. E. Vierhout, “A systematic review of clinical studies on dynamic magnetic resonance imaging
of pelvic organ prolapse: The use of reference lines and anatomical landmarks,” Int. Urogynecol. J. Pelvic Floor Dysfunct., vol. 20, pp. 721–729,
2009.
[9] M. M. Lakeman, F. M. Zijta, J. Peringa, A. J. Nederveen, J. Stoker, and
J. P. Roovers, “Dynamic magnetic resonance imaging to quantify pelvic
organ prolapse: Reliability of assessment and correlation with clinical
findings and pelvic floor symptoms,” Int. Urogynecol. J., vol. 23, pp. 1547–
1554, 2012.
[10] J. G. Tamez-Pena, S. Totterman, and K. J. Parker, “Unsupervised statistical
segmentation of multispectral volumetric MR images,” J. Med. Imaging,
Int. Soc. Optics Photon., pp. 300–311, 1999.
[11] R. Adams and L. Bischof, “Seeded region growing,” IEEE Trans. Pattern
Anal. Machine Intell., vol. 16, no. 6, pp. 641–647, Jun. 1994.
[12] J. Fripp, S. Crozier, S. K. Warfield, and S. Ourselin, “Automatic segmentation of the bone and extraction of the bone–cartilage interface from magnetic resonance images of the knee,” Phys. Med. Biol., vol. 52, pp. 1617–
1631, 2007.
[13] M. H. Brem, M. H. Brem, P. K. Lang, G. Neumann, P. M. Schlechtweg,
E. Schneider, R. Jackson, J. Yu, C. B. Eaton, F. F. Hennig, H. Yoshioka,
G. Pappas, and J. Duryea, “Magnetic resonance image segmentation using
semi-automated software for quantification of knee articular cartilage—
Initial evaluation of a technique for paired scans,” Skeletal Radiol., vol. 28,
pp. 505–511, 2008.
[14] T. F. Chan and L. A. Vese, “Active contours without edges,” IEEE Trans.
Image Process., vol. 10, no. 2, pp. 266–277, Feb. 2001.
[15] C. Li, “Distance regularized level set evolution and its application to image
segmentation,” IEEE Trans. Image Process., vol. 19, no. 12, pp. 3243–
3254, 2010.
[16] J. Folkesson, E. B. Dam, O. F. Olsen, P. C. Pettersen, and C. Christiansen,
“Segmenting articular cartilage automatically using a voxel classification approach,” IEEE Trans. Med. Imag., vol. 26, no. 1, pp. 106–115,
2007.
[17] H. Shim, S. Chang, C. Tao, J. H. Wang, C. K. Kwoh, and
K. T. Bae, “Knee cartilage: Efficient and reproducible segmentation on
high-spatial-resolution MR images with the semiautomated graph-cut
method,” Radiology, vol. 251, pp. 548–556, 2009.
[18] L. Lorigo, “Segmentation of bone in clinical knee MRI using based
geodesic active contours,” presented at the MICCAI, Cambridge, MA,
USA, 1998.
[19] J. Schmid and N. Magnenat-Thalmann, “MRI bone segmentation using
deformable models and shape priors,” Med. Image Comput.-Assisted Interv. - MICCAI, pp. 119–126, 2008.
[20] J. Carballido-Gamio, S. Belongie, and S. Majumdar, “Normalized cuts
in 3-D for spinal MRI segmentation,” IEEE Trans. Med. Imag., vol. 23,
no. 1, pp. 36–44, 2004.
[21] L. Liu, D. Raber, D. Nopachai, P. Commean, P. Sinacore, F. Prior, R. Pless,
and T. Ju, “Interactive separation of segmented bones in ct volumes using graph cut,” presented at MICCAI (LNCS), New York, NY, USA,
2008.
[22] Y. Boykov and V. Kolmogorov, “An experiemental comparison of mincut/maxflow algorithms for energy minimization in vision,” IEEE Trans.
Pattern Anal. Mach. Intell, vol. 26, no. 9, pp. 1124–1137, 2004.
[23] Y. Y. Boykov, “Interactive graph cuts for optimal boundary and region
segmentation of objects in N-D images,” in Proc. 8th IEEE Int. Conf.
Comput, Vis., 2001, pp. 105–112.
[24] Y. Yin, X. Zhang, and M. Sonka, “Optimal multi-object multi-surface
graph search segmentation: Full-joint cartilage delineation in 3 d,” in
Medical Image Understanding and Analysis, S. McKenna and J. Hoey,
Eds. U.K.: Dundee, 2008 pp. 104–108.

1377

[25] P. Bourgeat, J. Fripp, P. Stanwell, S. Ramadan, and S. Ourselin, “MR
image segmentation of the knee bone using phase information,” Med.
Image Anal., vol. 11, pp. 325–335, 2007.
[26] B. van Ginneken, M. Stegmann, and M. Loog, “Segmentation of anatomical structures in chest radiographs using supervised methods: A comparative study on a public database,” Med. Image Anal., vol. 10, pp. 19–40,
2006.
[27] S. Onal, S. Lai-Yuen, S. Hart, P. Bao, and A. Weitzenfeld, “MRI-based
semi-automatic pelvimetry measurement for pelvic organ prolapse diagnosis,” presented at ISSPA, Montreal, QC, Canada, 2012.
[28] R. M. Haralick and L. G. Shapiro, “Survey of image segmentation techniques,” Comput. Vis. Graph. Image Process, vol. 29, pp. 100–132, 1985.
[29] S. M. Weiss, Predictive Data Mining: A Practical Guide. San Francisco,
CA, USA: Morgan Kaufmann, 1998.
[30] C. W. Chen, J. Luo, and K. J. Parker, “Image segmentation via adaptive
K-mean clustering and knowledge based morphological operations with
biomedical applications,” IEEE Trans. Image Process., vol. 7, no. 12,
pp. 1673–1683, 1998.
[31] M. Steinbach, G. Karypis, and V. Kumar. (2000). “A comparison of
document clustering techniques,” M. Grobelnik, D. Mladenic, N. MilicFrayling, Eds., IEEE KDD Workshop on Text Mining, vol. 400, no. 10,
pp. 1–2, Available: http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?
arnumber = 4721382
[32] C. Schmid, R. Mohr, and C. Bauckhage, “Evaluation of interest point
detectors,” Int. J. Comput. Vis., vol. 37, pp. 151–172, 2000.
[33] J. Cui, B. Sahiner, and H. P. Chan, “A new automated method for the
segmentation and characterization of breast masses on ultrasound images,”
Med. Phys., vol. 36, pp. 1553–1565, 2009.
[34] S. Maghsoodloo, “Strengths and limitations of Taguchi’s contributions to
quality, manufacturing, and process engineering,” Manuf. Syst., vol. 23,
pp. 73–126, 2004.

Sinan Onal received the B.S. degree in industrial engineering from Hacettepe University, Ankara,
Turkey, in 1996 and the M.S. degree in 2010 in engineering management program from the University
of South Florida, Tampa, USA, where he is currently
working toward the Ph.D. degree in the Department
of Industrial and Management Systems Engineering.
He was with different companies at different positions for 12 years. He is currently under supervision
of Dr. Susana Lai-Yuen in the Department of Industrial and Management Systems Engineering, where
he is involved in a new image-based diagnosis tool for assessment of pelvic
organ prolapse (POP). His current research interests include medical image processing and medical device design.

Susana K. Lai-Yuen received the Ph.D., M.S.,
and B.S. (summa cum laude) degrees in industrial
engineering from North Carolina State University,
Raleigh, USA.
She is currently an Associate Professor of Industrial and Management Systems Engineering at the
University of South Florida, Tampa, USA, where
she has been the Director of the Virtual Manufacturing and Design Laboratory for Medical Devices
(VirtualMD Lab) since 2007. Her current research
interests include computational geometry, machine
learning, and human–computer haptic interfaces with applications in medical
image analysis, computer-aided decision support systems, clinical diagnosis,
and pharmaceutical drug discovery.

1378

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

Paul Bao received the Ph.D. degree in computer science from the University of Calgary, Calgary, AB,
Canada, in 1988.
He is currently with the Division of Information Technology, University of South Florida, Tampa,
USA. He was with the Faculty of Computer Science,
University of Calgary during 1988–1989. During
1990–1995, he was with IBM Canada Laboratory as
a Senior Staff Analyst, where he was involved in design and implementation of networked client/server
system and multimedia projects such as VisualAge
C++ as a Project Lead. During 1995–2005, he was with the Computing Department, The Hong Kong Polytechnic University as an Associate Professor; in
the Department of Information Engineering, Chinese University of Hong Kong
as a Visiting Professor; and in the School of Computer Engineering, Nanyang
Technological University as an Associate Professor. He is currently a Tenured
Associate Professor in the Division of Information Technology, University of
South Florida, and a 985 Plan Visiting Professor, School of Computer Sciences,
Chongqing University. His current research interests include computer graphics
and virtual reality, image-based rendering, image/video processing, multimedia
systems and wireless multimedia technologies. In these areas, he has authored or
coauthored over 180 research papers, 70 of which are in international journals,
such as the IEEE TRANSACTIONS PATTERN ANALYSIS AND MACHINE INTELLIGENCE, IEEE TRANSACTIONS ON IMAGE PROCESSING, IEEE TRANSACTIONS
IN MEDICAL IMAGING, IEEE TRANSACTIONS ON AUTOMATIC CONTROL, IEEE
TRANSACTIONS ON CIRCUIT AND SYSTEMS FOR VIDEO TECHNOLOGY, IEEE
TRANSACTIONS ON CIRCUIT AND SYSTEMS II, IEEE TRANSACTIONS ON INFORMATION THEORY, IEEE TRANSACTIONS ON MULTIMEDIA, PATTERN RECOGNITION, etc.

Alfredo Weitzenfeld received the B.S. in electrical
engineering from the Technion, Israel, the M.S. degree in computer engineering and the Ph.D. degree
in computer science from the University of Southern
California, Los Angeles, USA.
He is currently a Professor of Information Technology and a Courtesy Professor of Computer Science and Engineering in the College of Engineering,
University of South Florida. Dr. Weitzenfeld is the
Director of the USF Biorobotics Laboratory and the
USF RoboBulls teams. His current research interests
include biologically inspired robotics, cognitive robotic, humanoid robots, multirobot systems, and medical engineering. He has authored or coauthored more
than 120 refereed journal articles, conference papers, book chapters, and two
books.

Stuart Hart received the M.Sc. degree in entrepreneurship in applied technologies from the University of South Florida College of Business, Tampa,
USA.
He is currently an Associate Professor of Obstetrics and Gynecology in the Division of Female Pelvic
Medicine and Reconstructive Surgery, University of
South Florida Morsani College of Medicine. He completed medical school at the University of Maryland,
completed residency in Obstetrics and Gynecology
at Emory University, and completed a Pelvic Surgery
Fellowship at Northside Hospital in Atlanta, GA. He also holds a courtesy
faculty appointment in the Department of Industrial and Management Systems
within the University of South Florida College of Engineering. He completed
the 18-month Leadership Institute Program from the Center for Transformation
and Innovation (CTI), University of South Florida College of Medicine.
Dr. Hart is Board Certified in Obstetrics and Gynecology, and Subspeciality
Board Certified in Female Pelvic Medicine and Reconstructive Surgery. He is a
Fellow of the American College of Obstetrics and Gynecology and the American College of Surgeons. He also completed the Regulatory Affairs in Medical
Devices Certificate Program through the Department of Industrial and Management Systems Engineering within the USF College of Engineering, and started
the Executive MBA Program at the Massachusetts Institute of Technology in
the Fall of 2013.

