1178

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

The Effect of Sample Age and Prediction Resolution
on Myocardial Infarction Risk Prediction
Darwin Tay, Chueh Loo Poh, Eric Van Reeth, and Richard I. Kitney

Abstract—Myocardial infarction (MI) is one of the leading
causes of death in many developed countries. Hence, early detection of MI events is critical for effective preventative therapies,
potentially reducing avoidable mortality. One approach for early
disease prediction is the use of risk prediction models developed
using machine learning techniques. One important component of
these models is to provide clinicians with the flexibility to customize
(e.g., the prediction range) and use the risk prediction model that
they deemed most beneficial for their patients. Therefore, in this
paper, we develop MI prediction models and investigate the effect
of sample age and prediction resolution on the performance of MI
risk prediction models. The cardiovascular health study dataset
was used in this study. Results indicate that the prediction model
developed using SVM algorithm is capable of achieving high sensitivity, specificity, and balanced accuracy of 95.3%, 84.8%, and
90.1%, respectively, over a time span of 6 years. Both sample age
and prediction resolution were found not to have a significant impact on the performance of MI risk prediction models developed
using subjects aged 65 and above. This implies that risk prediction models developed using different sample age and prediction
resolution is a feasible approach. These models can be integrated
into a computer aided screening tool which clinicians can use to
interpret and predict the MI risk status of the individual patients
after performing the necessary clinical assessments (e.g., cognitive
function, physical function, electrocardiography, general changes
to health/lifestyle, and medications) required by the models. This
could offer a means for clinicians to screen the patients at risk of
having MI in the near future and prescribe early medical intervention to reduce the risk.
Index Terms—Classification, clinical decision support system,
clinical risk prediction, medical screening, myocardial infarction.

I. INTRODUCTION
HE best practice to avoid human mortality caused by
life threatening diseases like myocardial infarction (MI)
is to detect them early and prevent their onset. One approach

T

Manuscript received April 8, 2014; revised June 7, 2014; accepted June
8, 2014. Date of publication June 13, 2014; date of current version May 7,
2015. This work was partially supported by The Engineering and Physical
Science Research Council (EPSRC), Ministry of Education (Singapore) and
the National Heart, Lung and Blood Institute (NHLBI) for providing the CHS
dataset. The work of D. Tay was supported by the scholarship funding provided
by the Nanyang Technological University-Imperial College London Joint Ph.D.
program.
D. Tay is with the Department of Bioengineering, Imperial College London, London, SW7 2AZ, U.K. and also with the Division of Bioengineering, Nanyang Technological University, Singapore 639798 (e-mail: darwintay@
imperial.ac.uk).
C. L. Poh and E. Van Reeth are with the Division of Bioengineering, Nanyang
Technological University, Singapore 639798 (e-mail: clpoh@ntu.edu.sg;
eric.vanreeth@ntu.edu.sg).
R. I. Kitney is with the Department of Bioengineering, Imperial College
London, London, SW7 2AZ, U.K. (e-mail: r.kitney@imperial.ac.uk).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2330898

is to devise computational methods that capitalize on clinical
biomarkers to better screen the patients for their potential risk
of experiencing (future) MI. Broadly, clinical screening/risk
prediction tools are very important as it could potentially
lead to the following benefits at the individual patient-level:
for example, 1) when patients become knowledgeable of
their health risk and with good physician-patient therapeutic
relationship, they would be more willing to make changes
to their lifestyle and adhere to treatment regimens [1], 2)
allows clinicians to promptly recommend effective therapeutic
or preventive measures (e.g., lifestyle changes, treatment of
subclinical manifestation, etc.) to their patients [2], and 3)
if such screening tools were to be integrated into electronic
health record system and executed automatically to analyze
individuals’ health risk, the number of unscreened patients who
are at risk of a disease could be reduced dramatically [3]. The
key ramification of wide adoption of clinical screening tools is
the possibility of significantly reducing the number of avoidable
mortality. However, the development of versatile, reliable,
and accurate computer aided MI screening tools which the
clinicians can use in the clinics/hospitals to instantly predict
patients’ risk remains a challenge.
The conventional approaches for assessing the risk of
individuals experiencing MI include risk scoring system and
survival curves [4]–[6]. These, however, have limitations like
the inability to substantially identify minority of individuals
with subsequent risk of experiencing MI [7]. Moreover, clinical
biomarkers and symptoms seldom follow a linear relationship
and the expected outcome at the individual patient-level does
not always abide by the rules of epidemiology [8]. As a result,
conventional risk scoring systems—which model relationships
in a linear manner—often flounder in view of these challenges
[9], [10].
In recent years, there is an exponential increase in the amount
of clinical and molecular data collected from routine medical examination. To overcome the challenges associated with human
scale of thinking and analysis, data mining techniques—which
have been postulated as a “central feature” for future healthcare system [11]—became a popular method for extracting insights from this data deluge. Advantages of using data mining
techniques include the capability of dealing with plethora of information, solving nontrivial problems, producing data-driven
prediction models, and handling nonlinear relationships among
biomarkers. Examples of data mining techniques used to estimate disease risk include work from: 1) Wiens et al. [12] who
employed support vector machine (SVM) to identify patients
who are at high risk of experiencing hospital acquired Clostridium difficile (C. diff); and 2) Khan et al. [13] who used artificial

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

TAY et al.: EFFECT OF SAMPLE AGE AND PREDICTION RESOLUTION ON MYOCARDIAL INFARCTION RISK PREDICTION

neural network (ANN) for discriminating small, round blue-cell
tumors (SRBCTs).
One important component of risk prediction tools is to provide clinicians with the flexible to customize (e.g., change the
range and how far into the future the prediction would be) and
use a risk prediction model that they deemed most beneficial
for their patients. To this end, we explore the possibility of
customizing MI risk prediction models to better meet the patients’ needs and clinicians’ expectation. Particularly, the effect
of sample age and prediction resolution—two aspects that are
not commonly examined in the literature—on the performance
of MI risk prediction models constructed using SVM [14]–[16]
and evolutionary data-conscious artificial immune recognition
system (EDC-AIRS) [17] algorithms were investigated. Here,
sample age refers to the average age of individuals found in
the baseline (i.e., input) dataset used to construct the clinical
risk prediction model while prediction resolution refers to the
prediction scale (i.e., number of years into the future where
prediction of MI occurrence begins) and interval (i.e., time duration, in years, that marks the start and end of MI outcomes to
be considered) employed by the clinical risk prediction model.
In the view of the rapid aging population worldwide and the
relatively high prevalence of MI among the elderly, participants
amassed from the Cardiovascular Health Study (CHS) [18]—
consisting of subjects aged 65 and above—were analyzed. Further, with the wide range of clinical measurements and risk
factors accrued during the CHS observational study, it makes
the CHS dataset a valuable source of information for this paper.
The rest of the paper is organized as follows. Section II provides details of CHS dataset, and delineates the methodology
involved in developing the predictive models. Section III provides the experimental results achieved by the risk prediction
models developed using different combinations of sample age
and prediction resolution. Key results are discussed in Section
IV and conclusions are drawn in Section V.
II. MATERIALS AND METHODS
In Section II-A, details of CHS dataset are provided. This
dataset, however, consists of a significant percentage of missing
data and a highly skewed data distribution (commonly known as
the class imbalanced data problem). Hence, for effective analysis, data imputation and class data balancing are performed and
described in Sections II-B and II-C, respectively. Section II-D
explains how the various MI risk prediction models based on
different combinations of baseline data and prediction resolution
were developed and validated.
A. CHS Dataset
The CHS dataset, as described in [18], is an epidemiology
study of risk factors for cardiovascular diseases in elderly aged
65 and above. It contains two cohorts recruited at different
phases. The first cohort consists of 5201 subjects from four U.S.
communities, namely Forsyth County, North Carolina; Sacramento County, California; Washington County, Maryland; and
Pittsburgh, Pennsylvania. An additional 687 African Americans
were subsequently recruited forming the second cohort. Eligible individuals were sampled from Medicare eligibility lists

1179

in each area. Eligible participants include all individuals sampled from the Health Care Financing Administration (HCFA)
sampling frame—they were 65 years or older at the time of examination, noninstitutionalized, expected to remain in the area
for the next 3 years, and able to give informed consent and
did not require a proxy respondent at baseline. Individuals who
were wheelchair bound at home at baseline or receiving hospice treatment, radiation therapy or chemotherapy for cancer
were excluded. Eligible individuals were examined yearly from
1989 to 1999. Extensive physical and laboratory evaluations
were carried out to identify the presence and severity of CVD
risk factors—such as hypertension, hypercholesterolemia, and
glucose intolerance; subclinical disease, such as carotid artery
atherosclerosis, left ventricular enlargement, and transient ischemia. Criteria for identification of MI events include: observation of evolving Q-wave, cardiac pain, and abnormal enzymes
together with an evolving ST-T pattern or new left bundle branch
block. The reason for choosing the CHS dataset was because
of 1) the relatively high prevalence of CHD among the elderly,
2) worldwide demographic aging, 3) paucity of information regarding risk factors for CHD among elderly, and 4) the changing
clinical characteristics of CHD with advancing age [18]–[21].
B. Data Imputation
Data imputation is the process of substituting missing entries
in a dataset with plausible values and aims to improve the quality
of the data. It was performed using weighted K-nearest neighbor
(KNN) because of its excellent performance in estimating missing values [22], [23]. Moreover, it has the capability to estimate
both qualitative and quantitative attributes. Hence, it is highly
suitable for interpolating the missing values in the CHS dataset.
Individuals with unknown MI status and clinical features that
were uninformative (i.e., features with consistent value throughout) were first removed from the analysis. Individuals and clinical features with high percentage of missing entries were also
removed. This is to ensure that there is an adequate supply of
complete entries for weighted KNN to reference when estimating the missing values, which in turn promotes a more accurate
data imputation process [22]–[24]. The resulting dataset was
next normalized to unit variance to ensure that the attributes
with large scale do not dominate the (Euclidean) distance measure [25]. Subsequently, the optimal value of K for each clinical
feature was determined by 10-fold cross validation and used for
the data imputation process. The type of replacement method
used by weighted KNN depends on the data type. For instance, if
categorical (continuous) data were encountered, the weightedmode (weighted-mean) of the KNN was used to assign the value
for the missing entries. The use of weighted KNN estimation
has been demonstrated in [22], [26] to be robust and accurate.
C. Class Imbalance Data Problem
In order to create an unbiased dataset for SVM and EDCAIRS algorithms to learn from, undersampling of the majority class is necessary. The Kennard–Stone (KS) algorithm [27]
was employed to perform this task because of its excellent
performance—as demonstrated in a comparative study [28].
This algorithm sequentially selects representative data that are

1180

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

uniformly scattered across the data domain space. This is carried out by first selecting the data object that is closest to the
mean of the dataset and is included as the first data candidate.
Subsequently, the data object that is most distant from the first
one (based on Euclidean distance) is included as the second data
candidate. The next data object is chosen by identifying the one
farthest away from the previously selected data candidates. This
process repeats until the desired number of candidates has been
identified [28], [29].
In this study, the KS algorithm was used to undersample the
majority class found in the imputed CHS dataset. The number
of candidates to select is equivalent to the number of samples in
the minority class. In other words, after this process, the number
of controls and cases would be identical.
D. MI Risk Prediction Models
Two algorithms (SVM and EDC-AIRS) were employed to
develop MI risk prediction models. SVM algorithm is a robust supervised learning algorithm that is capable of yielding
excellent generalization performance on an extensive area of
problems [30]–[32]. It is derived from statistical learning theory and is capable of solving linearly and nonlinearly separable
problems. Fundamentally, SVM performs classification through
the construction of an N-dimensional hyperplane that optimally
separates the data into two or more categories whereby the margin of separation between the different categories is maximized.
EDC-AIRS algorithm [17] is a supervised classification algorithm inspired by the principles and processes associated with
the human immune system. It performs classification by first
constructing a pool of memory cells (i.e., candidate solutions
in the form of data vectors) that are representative of the training data through repetitive optimization of the (values of the)
memory cells. Optimization was carried out by robustly adapting the memory cells to the different density, distribution, and
characteristics exhibited by each data class in the training data.
Finally, with the utilization of the generated memory cells pool,
KNN is used to classify unseen data observations. This algorithm, when tested on several widely benchmarked datasets,
has demonstrated highly competitive classification performance
[17]. To adopt a ceteris paribus experimental design, the parameters for both algorithms were first tuned using genetic algorithm
(GA) and subsequently, feature selection was conducted (using GA) to identify predictive biomarkers. The GA parameters
were determined experimentally to work well with this clinical prediction problem and kept constant for all experiments.
The setup details of GA are as follows: population size: 100;
maximum generation: 100; natural selection: stochastic universal sampling; crossover type: discrete recombination; crossover
probability: 0.8; mutation rate: 1/P, where P is the number of
parameters/features. The parameter details for SVM are kernel
function: radial basis function (RBF); cost: [2−5 , 213 ]; gamma:
[2−15 , 23 ]; and for EDC-AIRS are seed: 1; clonal rate: 10;
hyper-mutation rate: 2; stimulation threshold: 0.9; initial memory pool size: [0, 200]; KNN value: [1, 15]; affinity threshold
scalar: [0, 1]; total resource: [150, 300]; Radiusdensity = [0, 3];
Radiusm ax = [0, 3].

Clinical data—recorded during the 5th to 11th year in which
the CHS clinical study was undertaken—were utilized. The reason for using clinical data recorded from year 5 onward was
because clinical examinations taken by the two different cohorts recruited at different phases synchronized from that year
onward. The reason for ending the prediction at year 11 is because from year 12 onward, participants were only monitored
annually via phone calls and no clinical examinations were
conducted.
To test the hypothesis, prediction models—using different
baseline datasets (with different sample age)—capable of predicting the risk of experiencing MI at various prediction scales
and intervals were developed. As illustrated in Fig. 1, eight different prediction models were designed to investigate how time
factor in relation to the onset of MI would affect the performance of the prediction model. Three different baseline datasets
were used. These datasets contain clinical examination results
recorded in year 5, year 7, and year 9 of the CHS study. Each
of these datasets was used to predict future. Three different
prediction scales (1, 3, and 5 years) and three different prediction intervals (2, 4, and 6 years) were investigated. Specifically,
healthy individuals present in year 5 of the CHS dataset were
used as the baseline data to predict whether one would experience MI from year 6 to 11 (prediction scale: 1 year; prediction
interval: 6 years), year 6 to 7 (prediction scale: 1 year; prediction interval: 2 years), year 8 to 9 (prediction scale: 3 years;
prediction interval: 2 years) and year 10 to 11 (prediction scale:
5 years; prediction interval: 2 years). Similarly, clinical examination results of healthy participants in year 7 was initialized as
the baseline data, where prediction of whether one would suffer
from MI whether an individual would experience MI in the near
from year 8 to 11, year 8 to 9, and year 10 to 11 were conducted. Likewise, clinical data recorded in year 9 were utilized
to perform prediction of MI occurrence from year 10 to 11.
Each baseline dataset was randomly split into two subsets
having balanced class distribution. The first subset contains 70%
of the initial data. Using this subset, the prediction model was
trained and tuned based on 10-fold cross validation. The second
subset, which contains the remaining 30% of the data, was used
to validate the developed model. This splitting process was repeated three times and independently used to develop and test
the respective prediction model. It is highly encouraged to do
so to avoid the developed model from capturing not only the
true associations, but, also, idiosyncratic features of the training data, which often produces an overly optimistic model [33].
Three commonly used performance measurements were employed to evaluate the prediction models developed—namely
sensitivity, specificity, and balanced accuracy (i.e., average between sensitivity and specificity).
Finally, to determine whether the prediction models developed using SVM and EDC-AIRS algorithms are statistically
different from each other, McNemar’s test was conducted. This
statistical test was chosen as it has been demonstrated to have
low type-1 error [34]. For each prediction model, this test was
carried out by first recording the prediction outcomes obtained
(by each algorithm) when tested using each validation dataset.
The results obtained from each algorithm were then used to

TAY et al.: EFFECT OF SAMPLE AGE AND PREDICTION RESOLUTION ON MYOCARDIAL INFARCTION RISK PREDICTION

1181

Fig. 1. MI risk prediction models of various prediction scales and intervals. MI risk prediction at various time scales and intervals using the CHS dataset was
performed. Prediction scale refers to the number of years into the future where prediction of MI occurrence begins while prediction interval refers to the time
duration (in years) that marks the start and end of MI outcomes to be considered.

TABLE I
DETAILS OF THE IMPUTED CHS DATASET
Prediction
Model

Fig. 2. Contingency table for McNemar’s test. “a” indicates the number of data
items misclassified by both SVM and EDC-AIRS algorithms; “b” represents the
number of data items misclassified by SVM algorithm but correctly classified
by EDC-AIRS algorithm; “c” denotes the number of data items misclassified by
EDC-AIRS algorithm but correctly classified by SVM algorithm; “d” dictates
the number of data items correctly classified by both SVM and EDC-AIRS
algorithms.

construct the contingency table shown in Fig. 2. Referring to
the figure, if the sum of “b” and “c” is greater than 25, chisquare test with 1 degree of freedom is used for performing
McNemar’s test. Otherwise, to provide a better estimation of
small sample (i.e., b + c ≥ 25), binomial distribution is used
for (exact) McNemar’s test. The prediction model is considered
to be statistically different from the ground truth if the p-value
computed using McNemar’s test is smaller than 0.05.
III. EXPERIMENTAL RESULTS
A. Data Preprocessing
Table I provides the details of the resulting CHS datasets
after the removal of records and clinical features with significant
missing entries.
Table II offers the details of the datasets used to develop and
test the MI prediction models after data imputation and class
data balancing were performed.

yr50611
yr50607
yr50809
yr51011
yr70811
yr70809
yr71011
yr91011

Sample Size∗
(Cases/Controls)

#Features

Age
(Mean±SD)

3102 (6.2%/93.8%)
3102 (2.4%/97.6%)
3034 (2.1%/97.9%)
2978 (2.1%/97.9%)
2407 (2.1%/97.9%)
2407 (2.1%/97.9%)
2362 (2.0%/98.0%)
1909 (1.9%/98.1%)

237
237
237
237
233
233
233
242

75.7 ± 5.34
75.7 ± 5.34
75.7 ± 5.34
75.7 ± 5.36
77.2 ± 5.40
77.2 ± 5.40
77.2 ± 5.40
78.8 ± 5.09

∗
This sample size refers to the number of individuals that remain in the CHS dataset
after removal of records with significant missing entries.
“yrXYYZZ” denotes that the prediction model uses clinical measurements observed in
year X to make prediction of whether one would experience MI from year YY to ZZ.

TABLE II
DETAILS OF DATASETS USED TO BUILD THE PREDICTION MODELS

Prediction

#Training

#Validation

McNemar’s Test#
(p-value)

Model

Instances

Instances

SVM versus EDC-AIRS

270
104
92
88
136
70
66
52

114
42
38
36
58
30
28
20

< 0.01
< 0.01
< 0.01
< 0.01
0.31
0.04
< 0.01
0.07

yr50611
yr50607
yr50809
yr51011
yr70811
yr70809
yr71011
yr91011

All training and validation datasets contain equal number of cases and controls.
#
The p-value of McNemar’s test is presented examining whether the performance of
the SVM algorithm is statistically different from EDC-AIRS algorithm.

1182

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

Fig. 3. Classification performance of SVM and EDC-AIRS algorithms (cross
validated). (a) Sensitivity performance metric. (b) Specificity performance metric. (c) Balanced accuracy performance metric. These performance measurements were obtained by performing 10-fold cross validation for each prediction
model.

Fig. 4. Classification performance of SVM and EDC-AIRS algorithms (tested
with validation dataset). (a) Sensitivity performance metric. (b) Specificity performance metric. (c) Balanced accuracy performance metric. These performance
measurements were obtained by evaluating each developed prediction model
with their respective validation dataset.

B. MI Risk Prediction Models

models “yr70811” and “yr91011”), the performance of SVM
and EDC-AIRS algorithms are statistically different.

Prediction models—using baseline dataset with different
sample age—at various time scales and intervals were developed using the training datasets. Cross validation was carried
out to evaluate the performance of each prediction model. For
all prediction models developed, results (as shown in Fig. 3)
indicate consistently high predictive performance was achieved
by both SVM and EDC-AIRS algorithms. For example, a balanced accuracy of at least 0.95 and 0.81 was achieved by SVM
and EDC-AIRS algorithms, respectively.
To assess whether the prediction models developed generalize
well, validation was performed using the validation datasets.
Results, as presented in Fig. 4, demonstrate that a balanced
accuracy of at least 0.81 and 0.71 was achieved by SVM and
EDC-AIRS algorithms, respectively.
McNemar’s test was conducted to determine whether the performance of SVM and EDC-AIRS algorithms is statistically
different from each other. Results (as shown in Table II) indicate that for most of the prediction models (except prediction

IV. DISCUSSION
MI risk prediction models developed using baseline datasets
with different sample age, and based on different prediction
resolution combinations were analyzed. Cross validation was
utilized during the training phase as an approach to evaluate and
develop potent MI risk prediction models. The resultant prediction models developed by both algorithms achieved a relatively
high sensitivity, specificity, and balanced accuracy (for SVM
algorithm, the respective performance achieved is at least 0.94,
0.96, and 0.95; while for EDC-AIRS algorithm, the respective
performance achieved is at least 0.89, 0.62, and 0.81). An investigation of whether the prediction models developed were
overtrained was conducted by validating each developed model
with an unseen dataset (i.e., not used to develop the prediction
model). The aim of this step was to assess the generalizability of
the developed models. Results indicate that SVM algorithm (and

TAY et al.: EFFECT OF SAMPLE AGE AND PREDICTION RESOLUTION ON MYOCARDIAL INFARCTION RISK PREDICTION

EDC-AIRS algorithm)—across all prediction models tested—
achieved a sensitivity, specificity, and balanced accuracy of at
least 0.84, 0.70, and 0.82 (and 0.84, 0.40, and 0.67), respectively.
Furthermore, it can be observed that in general there is a drop
in the validation sensitivity (SVM: 0.060 ± 0.054; EDC-AIRS:
0.073 ± 0.052), specificity (SVM: 0.154 ± 0.058; EDC-AIRS:
0.219 ± 0.124), and balanced accuracy (SVM: 0.107 ± 0.036;
EDC-AIRS: 0.146 ± 0.070) among all the prediction models
developed. It is noteworthy that the drop in performance is less
severe for SVM algorithm (when compared to EDC-AIRS algorithm). This shows that SVM algorithm tends to perform better
on noisy data even after data imputation was conducted. This
observation is supported by the results obtained from the performance of McNemar’s test. From this statistical evaluation, it
was demonstrated that SVM algorithm outperforms EDC-AIRS
algorithm for six out of eight prediction models tested.
Prediction models developed (with SVM algorithm) using
baseline dataset from year 5 (and year 7), and tested using their
respective validation datasets have shown comparable sensitivity, specificity, and balanced accuracy. Analysis of variance
(ANOVA) test was conducted on the respective group of prediction models (i.e., developed using either year 5 or 7 as baseline
dataset) that has a prediction interval of 2 years. Results demonstrate that they are statistically comparable—with p-value of
0.47 for prediction models using baseline dataset from year 5
(and 0.25 for prediction models using baseline dataset from
year 7). This signifies that predication scale does not have a significant impact on the performance of (SVM-based) prediction
models developed and tested using subjects aged 65 and above.
Similar analysis was performed on prediction models developed based on different prediction interval. Results indicate that
these models are statistically comparable—with p-value of 0.92
and 0.88 for prediction models developed using baseline dataset
from year 5 and 7, respectively. This means that prediction interval does not have a significant impact on the performance of
prediction models developed using SVM algorithm.
As for prediction models developed using EDC-AIRS algorithm, similar analysis was conducted. For prediction models
developed using baseline dataset from year 5 (and year 7) that
are based on 2-year prediction interval, and tested using their
respective validation datasets, ANOVA test was conducted. Results indicate that the prediction models in their respective group
are statistically comparable—having a p-value of 0.71 (for prediction model using year 5 baseline dataset) and 0.93 (for prediction model using year 7 baseline dataset). This indicates that
predication scale does not have a significant impact on prediction models developed using EDC-AIRS algorithm as well.
Likewise, prediction models developed based on different prediction interval were analyzed. Results show that these models
are statistically comparable—having a p-value of 0.12 and 0.14
for prediction models developed using baseline dataset from
year 5 and 7, respectively. This suggests that prediction interval
does not have a significant impact on the performance of prediction models developed using EDC-AIRS algorithm as well.
A summary of the p-values discussed is provided in Table III.
Analysis of prediction models that aim to predict the likelihood of MI occurrence in individuals’ subsequent 2 years
(i.e., “yr50607,” “yr70809,” and “yr91011”) indicate compa-

1183

TABLE III
STATISTICAL EVALUATION OF PREDICTION RESOLUTION
ANOVA Test# (p-value)
Prediction Models Compared
Prediction Scale
yr50607; yr50809; yr51011
yr70809; yr71011
Prediction Interval
yr50611; yr50607
yr70811; yr70809

SVM

EDC-AIRS

0.47
0.25

0.71
0.93

0.92
0.88

0.12
0.14

#
The p-value of ANOVA test is presented examining the significance of prediction
scale and interval for both SVM and EDC-AIRS algorithms.

rable performance—with p-value of 0.50 and 1.00 for SVM and
EDC-AIRS algorithms, respectively. Comparison of age among
individuals belonging to different baseline datasets indicates
that they are statistically different (p-value < 0.01). This portends that sample age does not have a significant impact on the
performance of prediction models.
Among all the prediction models developed, key biomarkers
identified to be statistically significant by both SVM and EDCAIRS algorithms are related to cognitive function, physical
function, depression/life events, electrocardiography, general
changes to health/lifestyle, and medications. These biomarkers, in general, are also identified as clinically significant in
the literature [35]–[38]. This suggests that statistically significant biomarkers can also be clinically significant—providing
a promising avenue for identifying the potential cardiovascular
risk factors to be evaluated in clinical trials.
One benefit of performing risk prediction using different prediction resolution and sample age is that it allows more refined
and progressive risk prediction to be conducted (without compromising accuracy). This provides the advantage of estimating
the seriousness of a disease one is experiencing; enabling clinicians to offer a more personalized management and/or therapeutic strategy to the patient.
The limitation of this investigation includes the use of a single dataset to evaluate the effect of sample age and prediction
resolution in relation to the performance of MI risk prediction.
This limits the power to conclusively state how each factor influences the performance of the prediction model. Nevertheless,
it does provide some insights on whether sample age and prediction resolution have an impact on the performance of clinical
risk prediction model. In view of the observations from this
study and the importance of screening since young, we aim to
investigate the effect of prediction resolution and sample age on
younger subjects as part of our future work.
V. CONCLUSION
Early detection of individuals with high risk of experiencing
MI is very important clinically, but has proved to be elusive. To
this end, we investigated the effect of sample age and prediction
resolution in relation to the development of accurate clinical risk
prediction model. Our experiments indicate that both sample
age and prediction resolution do not have a significant impact
on prediction models developed using subjects aged 65 and
above.

1184

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

Overall, high validation sensitivity, specificity, and balanced
accuracy were achieved by SVM algorithm. This opens the opportunity for constructing predictive models capable of detecting MI early, allowing clinicians to take preventative measures
promptly, improving the quality of individuals’ life, and reducing avoidable mortality.
In view of these results, we suggest the use of different prediction resolution to provide a more detailed health screening of elderly subjects so that more appropriate preventative
measurements—in relation to the individual’s risk level—can
be taken.

[19]
[20]

[21]

REFERENCES
[1] L. R. Martin, S. L. Williams, K. B. Haskard, and M. R. DiMatteo, “The
challenge of patient adherence,” Therapeutics Clin. Risk Manage., vol. 1,
no. 3, pp. 189–199, 2005.
[2] M. A. Whooley, “To screen or not to screen?: Depression in patients
with cardiovascular disease,” J. Amer. Coll. Cardiol, vol. 54, no. 10,
pp. 891–893, 2009.
[3] R. J. Hye, A. E. Smith, G. H. Wong, S. S. Vansomphone, R. D. Scott, and
M. H. Kanter, “Leveraging the electronic medical record to implement
an abdominal aortic aneurysm screening program,” J. Vascular Surg., vol.
59, no. 6, pp. 1535–1543, 2014.
[4] T. Clayton, J. Lubsen, S. Pocock, Z. Vokó B. Kirwan, K. Fox, and
P. Poole-Wilson, “Risk score for predicting death, myocardial infarction,
and stroke in patients with stable angina, based on a large randomised trial
cohort of patients,” Biomed. J., vol. 331, pp. 869–873, 2005.
[5] D. M. Lloyd-Jones, P. W. Wilson, M. G. Larson, A. Beiser, E. P. Leip,
R. B. D’Agostino, and D. Levy, “Framingham risk score and prediction
of lifetime risk for coronary heart disease,” Amer. J. Cardiol., vol. 94, no.
1, pp. 20–24, 2004.
[6] W. Levy, D. Mozaffarian, D. Linker, S. Sutradhar, S. Anker, A. Cropp,
I. Anand, A. Maggioni, P. Burton, M. Sullivan, B. Pitt, P. Poole-Wilson,
D. Mann, and M. Packer, “The seattle heart failure model: Prediction of
survival in heart failure,” Circulation, vol. 113, pp. 1424–1433, 2006.
[7] S. Alty, N. Angarita-Jaimes, S. Millasseau, and P. Chowienczyk, “Predicting arterial stiffness from the digital volume pulse waveform,” IEEE
Trans. Biomed. Eng., vol. 54, no. 12, pp. 2268–2275, Dec. 2007.
[8] S. Chattopadhyay, “Mining the risk of heart attack: A comprehensive
study,” Int. J. Biomed. Eng. Technol., vol. 11, no. 4, pp. 394–410,
2013.
[9] X. Song, A. Mitnitski, J. Cox, and K. Rockwood, “Comparison of machine
learning techniques with classical statistical models in predicting health
outcomes,” Medinfo, vol. 107, no. Pt 1, pp. 736–740, 2004.
[10] J. Kim, B. Cho, S. Im, M. Jeon, I. Kim, and S. Kim, “Comparative study
on artificial neural network with multiple regressions for continuous estimation of blood pressure,” in Proc. IEEE 27th Annu. Conf. Eng. Med.
Biol., 2005, pp. 6942–6945.
[11] R. Snyderman and J. Langheier, “Prospective health care: The second
transformation of medicine,” Genome Biol., vol. 7, pp. 104.1–8, 2006.
[12] J. Wiens, J. Guttag, and E. J. Horvitz, “Patient risk stratification for
hospital-associated C. diff as a time-series classification task,” in Proc.
Neural Inf. Process. Syst., 2012, pp. 476–484.
[13] J. Khan, J. S. Wei, M. Ringnér, L. H. Saal, M. Ladanyi, F. Westermann,
F. Berthold, M. Schwab, C. R. Antonescu, C. Peterson, and P. S. Meltzer,
“Classification and diagnostic prediction of cancers using gene expression profiling and artificial neural networks,” Nature Med., vol. 7, no. 6,
pp. 673–679, 2001.
[14] B. E. Boser, I. M. Guyon, and V. N. Vapnik, “A training algorithm for optimal margin classifiers,” in Proc. 5th Annu. Workshop Comput. Learning
Theory, 1992, pp. 144–152.
[15] C. Cortes and V. Vapnik, “Support-vector networks,” Mach. Learning, vol.
20, no. 3, pp. 273–297, 1995.
[16] V. Vapnik, “An overview of statistical learning theory,” IEEE Trans. Neural Netw., vol. 10, no. 5, pp. 988–999, Sep. 1999.
[17] D. Tay, C. Poh, and R. Kitney, “An evolutionary data-conscious artificial
immune recognition system,” in Proc. 15th Annu. Conf. Genetic Evol.
Comput. Conf., 2013, pp. 1101–1108.
[18] L. Fried, N. Borhani, P. Enright, C. Furberg, J. Gardin, R. Kronmal, L.
Kuller, T. Manolio, M. Mittelmark, A. Newman, D. O’Leary, B. Psaty,

[22]
[23]

[24]

[25]

[26]
[27]
[28]

[29]

[30]
[31]
[32]

[33]
[34]
[35]
[36]
[37]
[38]

P. Rautaharju, R. Tracy, and P. Weiler, “The cardiovascular health study:
Design and rationale,” Ann. Epidemiol., vol. 1, no. 3, pp. 263–276, 1991.
J. Wiener and J. Tilly, “Population ageing in the United States of America:
Implications for public programmes,” Int. J. Epidemiol., vol. 31, no. 4,
pp. 776–781, 2002.
A. S. Go, D. Mozaffarian, V. L. Roger, E. J. Benjamin, J. D. Berry,
W. B. Borden, D. M. Bravata, S. Dai, E. S. Ford, C. S. Fox, S. Franco,
H. J. Fullerton, C. Gillespie, S. M. Hailpern, J. A. Heit, V. J. Howard, M.
D. Huffman, B. M. Kissela, S. J. Kittner, D. T. Lackland, J. H. Lichtman,
L. D. Lisabeth, D. Magid, G. M. Marcus, A. Marelli, D. Matchar, D.
McGuire, E. Mohler, C. Moy, M. Mussolino, G. Nichol, N. Paynter, P.
Schreiner, P. Sorlie, J. Stein, T. Turan, S. Virani, N. Wong, D. Woo, and
M. Turner, “Heart disease and stroke statistics–2013 update: A report from
the American heart association,” Circulation, vol. 127, pp. e6–e245, 2013.
R. Abbott, J. Curb, B. Rodriguez, K. Masaki, K. Yano, I. Schatz,
G. Ross, and H. Petrovitch, “Age-related changes in risk factor effects on
the incidence of coronary heart disease,” Ann. Epidemiol., vol. 12, no. 3,
pp. 173–181, 2002.
O. Troyanskaya, M. Cantor, G. Sherlock, P. Brown, T. Hastie, R. Tibshirani, D. Botstein, and R. Altman, “Missing value estimation methods for
DNA microarrays,” Bioinformatics., vol. 17, no. 6, pp. 520–525, 2001.
J. Jerez, I. Molina, P. Garcı́a-Laencina, E. Alba, N. Ribelles, M. Martn,
and L. Franco, “Missing data imputation using statistical and machine
learning methods in a real breast cancer problem,” Artif. Intell. Med., vol.
50, no. 2, pp. 105–115, 2010.
P. Garcia-Laencina, A. Vidal, and J. L. Sancho-Gomez, “A robust
approach for classifying unknown data in medical diagnosis problems,” presented at the IEEE World Autom. Congr., Hawaii, HI, USA,
2008.
B. Minaei-Bidgoli, D. Kashy, G. Kortmeyer, and W. Punch, “Predicting
student performance: An application of data mining methods with an
educational web-based system,” in Proc. 33rd ASEE/IIEEE Frontiers Edu.
Conf., 2003, pp. T2A–T13.
S. Dudani, “The distance-weighted k-nearest-neighbor rule,” IEEE Trans.
Syst., Man Cyber., vol. SMC-6, no. 4, pp. 325–327, Apr. 1976.
R. Kennard and L. Stone, “Computer aided design of experiments,” Technometrics, vol. 11, no. 1, pp. 137–148, 1969.
W. Wu, B. Walczak, D. Massart, S. Heuerding, F. Erni, I. Last, and
K. Prebble, “Artificial neural networks in classification of NIR spectral
data: Design of the training set,” Chemometrics Intell. Lab. Syst., vol. 33,
no. 1, pp. 35–46, 1996.
M. Shahlaeiab, A. Madadkar-Sobhanic, L. Saghaiebd, and A. Fassihibd, “Application of an expert system based on genetic algorithm—
Adaptive neuro-fuzzy inference system (GA–ANFIS) in QSAR of cathepsin K Inhibitors,” Expert Syst. Appl., vol. 39, no. 6, pp. 6182–6191,
2012.
W. H. Chen, S. H. Hsu, and H. P. Shen, “Application of SVM and
ANN for intrusion detection,” Comput.Operations Res., vol. 32, no. 10,
pp. 2617–2634, 2005.
E. Osuna, R. Freund, and F. Girosit, “Training support vector machines:
An application to face detection,” in Proc. Comput. Vis. Pattern Recog.,
1997, pp. 130–136.
J. Listgarten, S. Damaraju, B. Poulin, L. Cook, J. Dufour, A. Driga,
J. Mackey, D. Wishart, R. Greiner, and B. Zanke, “Predictive models
for breast cancer susceptibility from multiple single nucleotide polymorphisms,” Clin. Cancer Res., vol. 10, pp. 2725–2737, 2004.
J. Taylor, D. Ankerst, and R. Andridge, “Validation of biomarker-based
risk prediction models,” Clin. Cancer Res., vol. 14, no. 19, pp. 5977–5983,
2008.
T. G. Dietterich, “Approximate statistical tests for comparing supervised classification learning algorithms,” Neural Comput., vol. 10, no. 7,
pp. 1895–1924, 1998.
M. Breteler, J. Claus, D. Grobbee, and A. Hofman, “Cardiovascular disease and distribution of cognitive function in elderly people: The Rotterdam study,” Brit. Med. J., vol. 308, no. 6944, pp. 1604–1608, 1994.
G. Erikssen, K. Liestøl, J. Bjørnholt, E. Thaulow, L. Sandvik, and
J. Erikssen, “Changes in physical fitness and changes in mortality,” Lancet,
vol. 352, no. 9130, pp. 759–762, 1998.
D. L. Musselman, D. L. Evans, and C. B. Nemeroff, “The relationship
of depression to cardiovascular disease: Epidemiology, biology, and treatment,” Arch. Gen. Psychiatry, vol. 55, pp. 580–592, 1998.
B. Kannel William, T. Gordon, P. Castelli William, and R. Margolis James,
“electrocardiographic left ventricular hypertrophy and risk of coronary
heart disease: The Framingham study,” Ann. Intern. Med., vol. 72, no. 6,
pp. 813–822, 1970.

TAY et al.: EFFECT OF SAMPLE AGE AND PREDICTION RESOLUTION ON MYOCARDIAL INFARCTION RISK PREDICTION

Darwin Tay received the B.Eng. (Hons.) degree in
computer science from Nanyang Technological University, Singapore. He is currently working toward the
doctoral degree in the Department of Bioengineering,
under the Imperial College London, Nanyang Technological University Joint Ph.D. program.
His research interests include medical computing, nature-inspired algorithms, and machine learning among others.

Chueh Loo Poh received the B.Eng. degree in electrical and electronic engineering from Nanyang Technological University, Singapore, and the Ph.D. degree
in bioengineering from Imperial College London,
London, U.K.
His research interests include image processing
techniques, bioinspired machine learning methods,
security methods related to biomedical imaging in a
web-based environment, and synthetic biology. He
is currently an Assistant Professor in the School of
Chemical and Biomedical Engineering, NTU.

1185

Eric Van Reeth was born in 1985. He received the
Engineer’s degree in electrical and electronic engineering with a major in image processing in 2007,
and the Ph.D. degree in collaboration with STMicroelectronics from Grenoble INP, Grenoble, France, in
2011.
In 2011, he joined Nanyang Technological University, Singapore, as a Postdoctoral Fellow. His current
research interests include resolution enhancement of
MRI data.

Richard I. Kitney was born in the U.K. in 1948. He
received the Ph.D. degree in biomedical engineering
from Imperial College, London, U.K.
He was the Founding Head of the Department of
Bioengineering; is the Chairman of the Institute of
Systems and Synthetic Biology, and the Codirector
of the new EPSRC Centre for Synthetic Biology and
Innovation. He is currently the Chair of Biomedical
Systems Engineering, Imperial College. His research
interests over the last 25 years have focused on modeling biological systems, biomedical information systems and, more recently, synthetic biology.
Dr. Kitney is a Fellow of The Royal Academy of Engineering; an Academician of the International Academy of Biomedical Engineering; a Fellow of the
American Academy of Biomedical Engineering and an Honorary Fellow of both
The Royal College of Physicians and The Royal College of Surgeons (U.K.).

