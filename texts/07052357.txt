IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 7, JULY 2015

1805

Domain Transfer Learning for MCI
Conversion Prediction
Bo Cheng, Mingxia Liu, Daoqiang Zhang∗ , Member, IEEE, Brent C. Munsell,
and Dinggang Shen∗ , Senior Member, IEEE

Abstract—Machine learning methods have successfully been
used to predict the conversion of mild cognitive impairment (MCI)
to Alzheimer’s disease (AD), by classifying MCI converters (MCIC) from MCI nonconverters (MCI-NC). However, most existing
methods construct classifiers using data from one particular target domain (e.g., MCI), and ignore data in other related domains
(e.g., AD and normal control (NC)) that may provide valuable information to improve MCI conversion prediction performance. To
address is limitation, we develop a novel domain transfer learning
method for MCI conversion prediction, which can use data from
both the target domain (i.e., MCI) and auxiliary domains (i.e., AD
and NC). Specifically, the proposed method consists of three key
components: 1) a domain transfer feature selection component that
selects the most informative feature-subset from both target domain and auxiliary domains from different imaging modalities; 2)
a domain transfer sample selection component that selects the most
informative sample-subset from the same target and auxiliary do-

Manuscript received April 16, 2014; revised December 10, 2014 and January 31, 2015; accepted February 4, 2015. Date of publication March 2,
2015; date of current version June 16, 2015. Data used in this article
were obtained from the Alzheimer’s Disease Neuroimaging Initiative database
(http://adni.loni.usc.edu/). This work was supported in part by NIH under
Grant EB006733, Grant EB008374, Grant EB009634, Grant MH100217, Grant
AG041721, and Grant AG042599, by the National Natural Science Foundation of China under Grant 61422204, Grant 61473149, and Grant 61473190,
the Jiangsu Natural Science Foundation for Distinguished Young Scholar under Grant BK20130034, the Specialized Research Fund for the Doctoral Program of Higher Education under Grant 20123218110009, the NUAA Fundamental Research Funds under Grant NE2013105, the Scientific and Technological Research Program of Chongqing Municipal Education Commission
under Grant KJ131108, and by the Alzheimer’s Disease Neuroimaging Initiative (ADNI), for data collection and sharing, National Institutes of Health
under Grant U01 AG024904. ADNI was supported by the National Institute
on Aging, the National Institute of Biomedical Imaging and Bioengineering,
and through generous contributions from the following: Abbott, AstraZeneca
AB, Bayer Schering Pharma AG, Bristol-Myers Squibb, Eisai Global Clinical
Development, Elan Corporation, Genentech, GE Healthcare, GlaxoSmithKline, Innogenetics, Johnson and Johnson, Eli Lilly and Co., Medpace, Inc.,
Merck and Co., Inc., Novartis AG, Pfizer Inc, F. Hoffman-La Roche, ScheringPlough, Synarc, Inc., as well as nonprofit partners: the Alzheimer’s Association
and Alzheimer’s Drug Discovery Foundation, with participation from the U.S.
Food and Drug Administration. B. Cheng and M. Liu contribute equally to this
paper. Asterisk indicates corresponding author.
B. Cheng is with the Nanjing University of Aeronautics and Astronautics and
also with Chongqing Three Gorges University.
M. Liu is with the Nanjing University of Aeronautics and Astronautics and
also with Taishan University.
∗ D. Zhang is with the College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing 210016, China.(email:dqzhang@nuaa.edu.cn)
B. C. Munsell is with the College of Charleston.
∗ D. Shen is with the Department of Radiology and BRIC, University of North
Carolina, Chapel Hill, NC 27599 USA and also with the Department of Brain
and Cognitive Engineering, Korea University, Seoul 136-701, Korea.
This paper has supplementary downloadable material available at
http://ieeexplore.ieee.org (File size: 1 MB).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2015.2404809

mains from different data modalities; and 3) a domain transfer support vector machine classification component that fuses the selected
features and samples to separate MCI-C and MCI-NC patients. We
evaluate our method on 202 subjects from the Alzheimer’s Disease
Neuroimaging Initiative (ADNI) that have MRI, FDG-PET, and
CSF data. The experimental results show the proposed method
can classify MCI-C patients from MCI-NC patients with an accuracy of 79.4%, with the aid of additional domain knowledge
learned from AD and NC.
Index Terms—Alzheimer’s disease (AD), domain transfer learning, feature selection, mild cognitive impairment converters (MCIC), sample selection.

I. INTRODUCTION
LZHEIMER’S disease (AD) is characterized by the progressive impairment of neurons and their connections,
which results in loss of cognitive functions. In 2007, a report
published by Ron et al. indicated that there were 26.6 million
AD sufferers worldwide, and forecasted that 1 in 85 people
will be affected by 2050 [1]. As the prodromal stage of AD,
mild cognitive impairment (MCI) can be further categorized
into MCI converters (MCI-C) and MCI nonconverters (MCINC). Specifically, MCI-C patients will likely progress to AD,
while MCI-NC patients will not convert to AD. Existing research has suggested that the individuals with amnestic MCI
tend to progress to the probable AD at a rate of approximately
10% to 15% per year [1]. Thus, the accurate diagnosis of AD,
especially in the early stage (i.e., MCI), is very important for
timely therapy, disease modifying drug development, and possible delay of the disease. Nowadays, many machine learning
methods have been proposed to recognize AD patients [2]–[10].
Recently, an increasing number of studies on AD research begin
to address classification of MCI conversion (MCI-C) and MCI
nonconversion (MCI-NC) patients based on the high-resolution
brain imaging data [4], [7], [11]–[24].
One challenge for MCI-C prediction is that the number of
MCI-C and MCI-NC subjects available for training is generally very small, while the dimensionality of data is often very
high, which makes it very challenging to train an accurate classifier. Thus, many advanced machine learning methods have
been proposed to address this issue [2], [3], [7], [11], [22],
[23], [49]–[51], [57]. For instance, in [3], a multitask learning
method achieved an accuracy of 73.9% on 43 MCI-C and 48
MCI-NC patients using multimodality data such as MRI, fluorodeoxyglucose positron emission tomography (FDG-PET),
and cerebrospinal fluid (CSF). In [7], a manifold harmonic
transform method using cortical thickness data achieved a sensitivity of 63% and specificity of 76% on 72 MCI-C and 131
MCI-NC patients, and in [11], a morphological factor method

A

0018-9294 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

1806

using MRI data achieved an accuracy of 72.3% on 20 MCI-C
and 29 MCI-NC patients. In [22], an orthogonal partial least
square to latent structures was used to diagnosis of MCI-C and
achieved prediction accuracy of 75.4% and 68% for those MCI
subjects converting to AD by 24 and 36 months, respectively.
This performance was reported on 162 MCI Alzheimer’s disease neuroimaging initiative (ADNI) patients. In [23], a Gaussian process approach that combined several multimodality data
sources (i.e., MRI, PET, CSF, and APOE genotype) was used
for classification and achieved an accuracy of 74.1% on classification between 47 MCI-C and 96 MCI-NC patients. In all
these referenced studies, the size of dataset is small and also
only one domain (i.e., MCI-C and MCI-NC) of subjects is used
for training the classification models.
It is worth noting that MCI cohorts are heterogeneous, consisting of MCI-C (that will convert to AD) and MCI-NC (that
will remain stable). Because of the characteristic of MCI cohorts, several studies proposed a hypothesis that the MCI-NC
subjects are more healthy-like, while the MCI-C subjects are
more AD-like, which is consistent with the contention that discrete disease states are an approximation to a continuous disease
spectrum [23], [40], [56]. In the literature, several studies have
treated AD as MCI-C, and NC as MCI-NC, and then used AD
and NC subjects to train a support vector machine (SVM) for
MCI-C prediction [23]–[25]. It demonstrates that the task of
classifying MCI-C and MCI-NC subjects is related to the task
of classifying AD and NC subjects. On the other hand, in machine learning community, transfer learning has been developed
to better deal with the problem involving multiple domains (including target domain and auxiliary domain) of data [26]–[28],
where it does not assume that the auxiliary data have exactly
the same distribution as the target data. Recently, in our preliminary work [29], transfer learning has been introduced into
medical imaging analysis. Specifically, in [29] a domain transfer
support vector machine (DTSVM) was used to classify MCI-C
and MCI-NC patients (i.e., target data) with the help of AD and
NC patients as the auxiliary data, showing a great performance
improvement. However, in [29], it did not use a feature selection
step to identify the most discriminative features from imaging
data. Also, in [29], all the patients in the auxiliary domain were
used for training, without a step to select the most informative
samples in the auxiliary domain (i.e., AD/NC subjects) for further improving the classification performance between MCI-C
and MCI-NC patients.
To address the aforementioned limitations, we propose a
novel domain transfer learning framework for MCI-C prediction. Specifically, we first develop a domain transfer feature
selection (DTFS) method by using both the auxiliary (AD/NC)
and target (MCI-C/MCI-NC) domains to select a subset of discriminative features, common to both domains. Then, using the
instance-transfer approach, a cross-domain kernel is constructed
for transferring the auxiliary domain knowledge. To improve the
quality of the source data in the cross-domain kernels, a domain
transfer sample selection (DTSS) method is further developed
using the multitask least absolute shrinkage selection operator (Lasso) kernel-based method to select the most informative
sample subset. Finally, all selected samples are classified by a
DTSVM using adaptive SVMs and multikernel learning. The

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 7, JULY 2015

TABLE I
SUBJECT INFORMATION
Characteristics
Age (mean ± SD)
Education (mean ± SD)
MMSE (mean ± SD)
CDR (mean ± SD)

AD
(n = 51)

NC
(n = 52)

MCI-C
(n = 43)

MCI-NC
(n = 56)

75.2 ± 7.4
14.7 ± 3.6
23.8 ± 2.0
0.7 ± 0.3

75.3 ± 5.2
15.8 ± 3.2
29.0 ± 1.2
0.0 ± 0.0

75.8 ± 6.8
16.1 ± 2.6
26.6 ± 1.7
0.5 ± 0.0

74.7 ± 7.7
16.1 ± 3.0
27.5 ± 1.5
0.5 ± 0.0

AD = Alzheimer’s Disease, NC = Normal Control, MCI = Mild Cognitive Impairment,
MCI-C = MCI Converter, MCI-NC = MCI Nonconverter, MMSE = Mini-mental State
Examination, CDR = Clinical Dementia Rating.

proposed method is evaluated using MRI, FDG-PET, and CSF
data of 202 subjects from the ADNI, and experimental results
show that the proposed method can recognize MCI-C patients
from MCI-NC ones with 79.4% accuracy by using the aid of
additional domain knowledge learned from AD and NC.
II. MATERIALS AND METHODS
The data used in our experiments came from the ADNI
database. The ADNI was launched in 2003 by the National Institute on Aging, the National Institute of Biomedical Imaging
and Bioengineering, the Food and Drug Administration, private
pharmaceutical companies, and nonprofit organizations, as a
U.S. $60 million, five-year public–private partnership. The primary goal of ADNI has been to test whether the serial MRI, PET,
other biological markers, and clinical and neuropsychological
assessments can be combined to measure the progression of MCI
and early AD. Determination of sensitive and specific markers
of very early AD progression is intended to aid researchers and
clinicians to develop new treatments and monitor their effectiveness, as well as lessen the time and cost of clinical trials.
ADNI is the result of efforts of many coinvestigators from a
broad range of academic institutions and private corporations,
and subjects have been recruited from over 50 sites across the
U.S. and Canada. The initial goal of ADNI was to recruit 800
adults, aged 55 to 90, to participate in the research (approximately 200 cognitively normal older individuals to be followed
for three years, 400 people with MCI to be followed for three
years, and 200 people with early AD to be followed for two
years). The research protocol was approved by each local institutional review board and the written informed consent is
obtained from each participant.
A. Subjects
In the ADNI database, there are totally 202 subjects with
three modality data (i.e., MRI, PET, and CSF), including 51 AD
patients, 99 MCI patients (including 43 MCI-C and 56 MCINC), and 52 normal controls. During the 24-month follow-up
period, 43 MCI subjects converted to AD and 56 remained
stable. It is worth noting the subject size used in our experiments
is very similar to that used in many previous studies [2], [3], [29],
and thus is sufficient to compare our proposed method with other
methods. In general, the inclusion/exclusion criteria are listed
below, and Table I provides a summary.
1) MCI subjects: MMSE scores between 24–30, a memory complaint, having objective memory loss measured

CHENG et al.: DOMAIN TRANSFER LEARNING FOR MCI CONVERSION PREDICTION

by education adjusted scores on Wechsler Memory Scale
Logical Memory II, a Clinical Dementia Rating (CDR)
of 0.5, and absence of significant levels of impairment in
other cognitive domains, essentially preserved activities
of daily living, and an absence of dementia.
2) Mild AD: MMSE scores between 20–26, CDR of 0.5 or
1.0, and meeting the National Institute of Neurological and
Communicative Disorders and Stroke and the Alzheimer’s
Disease and Related Disorders Association criteria for
probable AD.
3) Healthy subjects: MMSE scores between 24–30, a CDR
of 0, nondepressed, non-MCI, and nondemented.
B. MRI, CSF, and PET Biomarkers
A detailed description on how the MRI, CSF, and PET
datasets were acquired can be found in the public ADNI website.
In general, structural MR scans were acquired from 1.5 or 3.0-T
scanners. Raw DICOM MRI scans were downloaded from the
public ADNI website reviewed for quality, and automatically
corrected for spatial distortion caused by gradient nonlinearity
and B1 field inhomogeneity. PET images were acquired 30–
60 min postinjection, averaged, spatially aligned, interpolated
to a standard voxel size, intensity normalized, and smoothed
to a common resolution of 8 mm full width at half maximum.
CSF data were collected in the morning after an overnight fast
using a 20- or 24-gauge spinal needle, frozen within 1 h of
collection, and transported on dry ice to the ADNI Biomarker
Core laboratory at the University of Pennsylvania Medical Center. In this study, amyloid β (Aβ42 ), CSF total tau (t-tau) and
tau hyperphosphorylated at threonine 181 (p-tau) are used as
features.
C. Image Analysis
The MRI and PET images are preprocessed to extract ROIbased features, by following the pipeline in [2]. Specifically, we
first perform an anterior commissure (AC)–posterior commissure (PC) correction on all MRI and PET images using MIPAV
software [30]. The AC-PC corrected images are resampled to
256 × 256 × 256, and the N3 algorithm [31] is then used to
correct the intensity inhomogeneity. For the MR images, the
skull is stripped using the method described in [32], followed
by manual editing and cerebellum removal. Next, we use FAST
in the FSL package [33] to segment the human brain into three
different types of tissues: gray matter (GM), white matter (WM),
and CSF. For a given brain image with three segmented tissues
(i.e., GM, WM, and CSF), we then nonlinearly register it to a
template with 93 manually labeled regions-of-interests (ROIs)
[35], by using a widely used high-dimensional elastic warping
tool (i.e., HAMMER [34]). Finally, we use the volumes of GM
tissue of the 93 ROIs, which were normalized by the total intracranial volume (which is estimated by the summation of GM,
WM, and CSF volumes from all ROIs), as features for a given
subject. For PET image, we first align it to its corresponding
MRI image of the same subject through affine transformation,
and then compute the average intensity of each ROI in the PET
image as features. In addition, three CSF biomarkers are also

1807

used in this study, namely CSF Aβ42 , CSF t-tau, and CSF p-tau.
As a result, for each subject, we have 93 features derived from
the MRI image, 93 features generated from the PET image, and
three features obtained from the CSF biomarkers.
D. Domain Transfer Learning for MCI-C Prediction
The system diagram illustrated in Fig. 1 outlines the steps and
components used in our proposed classification framework. In
general, it contains four components, i.e., image preprocessing,
DTFS, DTSS, and DTSVM. At first, all MRI and PET images
are preprocessed to get the extracted features as described in
Section II-C. Then, for both MRI and PET features, the DTFS
component identifies a subset of features (corresponding to brain
regions) that are relevant to the disease under study. Next, the
DTSS component uses the multimodality features found by
the DTFS component, as well as the CSF features, to compute
cross-domain kernels that simultaneously select the most informative cross-domain sample subset. Finally, in the DTSVM
component, the auxiliary domain and cross-domain kernels are
combined to train the ultimate classifier for classifying MCIC and MCI-NC patients. In what follows, we will provide the
technical details of these three components (i.e., DTFS, DTSS,
and DTSVM).
1) Domain Transfer Feature Selection: In traditional singledomain learning, we can employ sparse logistic regression
(SLR) [43] for learning weight vectors wA and wT from the
auxiliary and target domains, respectively. Then, we can use
weight vectors wA and wT for feature selection. Although using
single-domain sparse learning can achieve better performance
for MCI-C prediction [44], it cannot acquire knowledge from
cross domain. Since the task of classifying MCI-C and MCI-NC
patients is related to the task of classifying NC and AD patients,
we combine these two learning domains for learning a common weight matrix W that can select a common feature subset,
as done in our proposed DTFS model which will be explained
below.
Specifically, the proposed DTFS model jointly considers two
learning domains: 1) AD and NC classification as the auxiliary
NA
A
d
domain, denoted as A = {xA
i }i=1 , where xi ∈ R is a sample
with d features, NA is the number of samples in the auxiliary
A
A
domain, and yA = {yiA }N
i=1 , yi ∈ {+1, −1} is the corresponding class label (with the AD labeled as +1 and the NC labeled
as –1); 2) MCI-C/MCI-NC classifications as the target domain,
T
d
T
denoted as T = {xTi }N
i=1 , where xi ∈ R is a sample with d
features, NT is the number of samples in the target domain,
T
yiT ∈ {+1, −1} is the class label (with
and yT = {yiT }N
i=1 ,
the MCI-C labeled as +1 and the MCI-NC labeled as –1). The
DTFS model combines auxiliary domain A and target domain T
for learning a common weight matrix W = [wA , wT ]. Fig. 2(a)
gives the illustration of DTFS, which optimizes the following
objective function with the “group sparsity” (i.e., L2 /L1 -norm)
regularization:
min
W



nt
 
1
log
n
i=1 t

t∈{A,T }




1 + exp −yit (wt ) xti + bt
+ β W2,1

(1)

1808

Fig. 1.

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 7, JULY 2015

System diagram of our proposed classification framework.

where W2,1 =

d


wi 2 , W ∈ Rd×t is the weight matrix

i=1

whose row vector wi is the coefficient vector associated with
i-th feature across two different learning domains, and b =
[bA , bT ] ∈ R1×t is the intercept for the classification task both in
the auxiliary (t = A) and target (t = T ) domains. Also, β > 0
is a regularization parameter that controls the relative contributions of the two terms, and the symbol  denotes the transpose
of a matrix. According to the optimization algorithm of the literature [36] for solving the optimization problem of (1), we can
get the sparse matrix W, where all nonzero row vectors wi correspond to features that will be selected, indicating that they are
essential for classification both on auxiliary and target domains.
2) Domain Transfer Sample Selection: After performing
DTFS, we have obtained the most informative features in both
auxiliary and target domains. In what follows, we will compute the cross-domain kernel matrix K for implementing the
knowledge fusion both on auxiliary and target domains. Here,
the instance-transfer approach [37], [38] is used to join the auxiliary domain data (i.e., AD and NC subjects, which are more

separable than MCI-C and MCI-NC subjects in the reduced feature space via DTFS) to the target domain data (i.e., MCI-C and
MCI-NC subjects).
To be specific, we first define the kernel matrices from the aux
iliary domain and the target domain as: KA ,A = k(ziA , zjA ) ∈


RN A ×N A and KT ,T = k(ziT , zjT ) ∈ RN T ×N T , respectively.
Here, ziA (zjA ) and ziT (zjT ) are samples in the auxiliary and target
domains, respectively, in the reduced feature space via DTFS.
Also, as defined before, NA and NT are the numbers of samples in the auxiliary and target domains, respectively. Then, we
define the cross-domain kernel matrices from the auxiliary domain to the target domain and also
 from thetarget domain to
the auxiliary domain as KA ,T = k(ziA , zjT ) ∈ RN A ×N T and


KT ,A = k(ziT , zjA ) ∈ RN T ×N A , respectively. Then the crossdomain kernel matrix K can be computed as
 A ,A A ,T 	
K K
∈ RN ×N
(2)
K=
T ,A T ,T
K K
where N = NA + NT .

CHENG et al.: DOMAIN TRANSFER LEARNING FOR MCI CONVERSION PREDICTION

1809

Fig. 2. Illustration on the proposed DTFS and DTSS models. (a) Using DTFS to select discriminative brain regions. (b) Using DTSS to select informative
subjects.

In our study, from (2), three cross-domain kernel matrices
are obtained, which correspond to three modalities (i.e., MRI,
PET, and CSF), denoted as K(M RI) , K(PET) , and K(CSF) , respectively. Moreover, to remove the noisy samples and seek
out the most informative samples from multimodal cross domain, we present a sample selection framework via a multitask
Lasso-based kernel learning, namely DTSS. Specifically, in our
proposed DTSS model, we first employ the kernel learning technique to map sample set from the original space to the kernel
space, where multitask Lasso is then performed for sample selection. Fig. 2(b) gives the illustration of the proposed DTSS
method. From Fig. 2(b), DTSS learns a common weight matrix V = [v(M RI) , v(PET) , v(CSF) ], where v(M RI) , v(PET) ,
and v(CSF) are the learning weight vectors corresponding to
MRI, PET, and CSF modalities, respectively, and is to solve the
following objective function:
M

2
1 


 (m ) (m )


− y(m ) 
 + λ V2,1
min

K v
V 2
2
m =1

where V2,1 =

N

i=1

(3)

vi 2 , V ∈ RN ×M is the weight matrix

whose row vector vi is the vector of coefficients associated with
the i-th training sample across three different modalities, and M
is the number of modalities (M = 3 in this study); λ > 0 is a
regularization parameter that controls the relative contributions
of the two terms; and y(m ) ∈ RN ×1 is the corresponding class
label of cross domain for the m-th modality. In addition, K(m )
is the cross-domain kernel matrix for the m-th modality, i.e.,
K(M RI) , K(PET) , and K(CSF) , respectively, which can be seen
as the similarity between pairwise samples in the cross domain
for the m-th modality. In our study, the widely used Gaussian
kernel function is used, which is defined as follows:


(4)
k (x, y) = exp −||x − y||2 /σ 2
where σ is the bandwidth. Due to the use of “group sparsity”
(i.e., L2 /L1 -norm) regularization, many of the rows of V will
be zeros, and thus, all samples corresponding to nonzero row
vectors will be selected. In this paper, the SLEP package [39] is
used for solving the optimization problems in DTFS and DTSS.
3) Domain Transfer Support Vector Machines: After performing DTFS and DTSS, we can obtain the most discrimina-

tive features and informative samples, upon which we will build
a DTSVMs classifier for final classification.
NA
T
T NT
Denote SA = {sA
p }p=1 and S = {sq }q =1 as the new auxiliary and target domains, with the corresponding labels denoted

N A
T
T NT
A
as zA = {zA
p }p=1 and z = {zq }q =1 , respectively. Here, sp
T
and sq , respectively, denote the new auxiliary and target data
after feature selection (via DTFS) and sample selection (via
DTSS), and NA and NT are the numbers of selected samples.
Then, we employ multikernel learning for multimodal kernel
combination [2], [3], [6], which can be used to compute the
ultimate auxiliary domain kernel matrix KA ,A and the crossdomain kernel matrix K. Here, kernel combination is used to
define a new integrated kernel function for the m-th modality
(m )
(m )
data si and sj as follows:

k (si , sj ) =

M




(m ) (m )
cm k (m ) si , sj

(5)

m =1

where k (m ) denotes the kernel function over the m-th modality, and Cm denotes the weight on the m-th modality. From
(5), we can achieve the ultimate auxiliary domain kernel matrix KA ,A and cross-domain kernel matrix K, i.e., KA ,A =
M
M


cm (KA ,A )(m ) , K =
cm K(m ) . To find the optimal
m =1
m =1

cm =
values for weights cm , we constrain them so that
m

1, 0 ≤ cm ≤ 1, and then adopt a coarse-grid search through
cross validation on the training samples, which has been shown
effective in our previous work [2], [3], [6].
Then, we adopt the adaptive SVMs method in [26] to learn
the ultimate classifier f (s). This ultimate classifier f (s) is first
learned from the auxiliary domain classifier f A (s), which is
implemented by adding a delta function for cross domain in the
form of Δf (s) = h Φ (s) on the basis of f A (s)
f (s) = f A (s) + Δf (s) = f A (s) + h Φ (s)

(6)

where Φ (s) is a kernel-based nonlinear mapping function, and h
is the weight vector of cross-domain classifier. Also, h denotes
the transpose of h.

1810

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 7, JULY 2015

To learn the weight vector h in (6), we use the following
objective function, similar to the SVM:

TABLE II
COMPARISON OF PERFORMANCE MEASURES OF FIVE DIFFERENT METHODS
FOR MCI-C/MCI-NC CLASSIFICATION

N


1
ζl
min h2 + C
h 2

Modality

Method

ACC
%

SEN
%

SPE
%

AUC

p-value

SVM

63.8

58.8

67.7

0.683

< 0.0001

SVM + SLR
DTSVM
LapSVM
Proposed
SVM
SVM + SLR
DTSVM
LapSVM
Proposed
SVM
DTSVM
LapSVM
Proposed
SVM
SVM + SLR
DTSVM
LapSVM
Proposed

67.3
69.4
64.6
79.4
53.9
63.6
63.3
58.3
73.4
60.8
66.2
61.1
67.6
58.0
60.9
67.0
59.1
71.6

73.9
64.3
55.9
84.5
47.6
67.5
59.8
52.4
74.3
55.2
60.3
55.6
74.6
52.1
65.1
59.6
53.3
76.4

58.8
73.5
71.1
72.7
57.7
58.3
66.0
62.9
72.1
65.0
70.8
65.3
61.5
62.5
55.4
72.7
63.5
67.9

0.728
0.736
0.689
0.848
0.554
0.696
0.700
0.593
0.764
0.647
0.701
0.651
0.715
0.612
0.662
0.732
0.607
0.741

< 0.0001
< 0.0001
< 0.0001
< 0.0001
< 0.0001
< 0.0001
< 0.0001
< 0.0010
< 0.0500
< 0.0010
< 0.0001
< 0.0001
< 0.0100
< 0.0001
-

l=1

s.t. ζl ≥ 0,
zl h Φ (sl ) + zl f A (sl ) ≥ 1 − ζl

(7)

where l is the l-th sample in the cross-domain training
A
T
T

N  ×1
subset, z = [zA
, N  = NA +
1 , . . . , zN A , z1 , . . . , zN T ] ∈ R
NT represents the total number of samples in z, and ζl is the
slack variable that represents the prediction error of objective
function of (7), thus it can be used for nonlinear classification.
The parameter C balances contributions between auxiliary classifier and cross-domain training examples. According to [26],
we can solve this objective function (i.e., (7)) to obtain the solution for the weight vector h. Then, we can obtain the final
solution for f (s). In this study, f A (s) is trained by SVM using
the auxiliary domain kernel matrix KA ,A , and Δf (s) is solved
by (6) using the cross-domain kernel matrix K = [k (s, s )], and
k (s, s ) = Φ (s) , Φ (s )	.

Multimodality
(MRI + CSF
+ PET)

MRI

CSF

PET

ACC = Accuracy, SEN = Sensitivity, SPE = Specificity.

III. RESULTS
A. Experimental Settings
In this study, we use a 10-fold cross-validation strategy to
evaluate the performances of different methods. Specifically,
the set of subjects in the target domain (i.e., 99 MCI subjects)
are partitioned into ten subsets (each subset with a roughly
equal size), and then one subset is successively selected as the
test dataset and the remaining subsets are used to train the classifiers. This process is repeated ten times, and the classification
performance is evaluated by the average sensitivity, specificity,
accuracy, and area under curve (AUC) measures.
In our experiments, traditional SVM (denoted as SVM) and
other methods with the SVM algorithm for classification (i.e.,
DTSVM and our proposed methods) are implemented using
the LIBSVM toolbox [41] with a linear kernel. For DTFS and
DTSS components, sparse learning is performed using the SLEP
package [39], and regularization parameters β and λ are learned
using another 10-fold cross-validation strategy on the training
data. In DTSS component, the similarity function bandwidth
parameter σ is also learned using the 10-fold cross-validation
strategy on the training subsets. Specifically, a hierarchical optimization based grid search is employed for searching the optimal parameters. In our experiments, we first optimize the regularization parameters β and λ simultaneously through grid
search with the range of {0.00001, 0.0001, 0.0005, 0.001, 0.004,
0.007, 0.01, 0.02, 0.03, 0.05, 0.06, 0.08, 0.1, 0.2, 0.4, 0.6, 0.8},
with the fixed default values for other parameters (i.e., σ = 2,
weights cm : cM RI = 0.4, cCSF = 0.3, cPET = 0.3). Then, we
adopt a grid search with the range of {2, 4, 8, 16, 32, 64, 128}
to optimize the bandwidth parameter σ of similarity function.
Finally, we use the grid search to find the optimal weights cm in
multikernel learning. The performance of the proposed method
was compared with the Laplacian SVM (LapSVM) [42]. The

LapSVM classifier uses a linear kernel function and its graph
Laplacian is constructed by using the k-nearest neighbor algorithm, where k (1 ≤ k ≤ 10) is learned through 10-fold cross
validation on training data.
In addition, we use another similar hierarchical optimizationbased grid search to search the optimal parameters (including k and cm ). Specifically, we first find the optimal value for
the nearest neighbor k with fixed values for weights cm (i.e.,
cM RI = 0.4, cCSF = 0.3, cPET = 0.3), and then determine the
optimal weights cm in multikernel learning through cross validation. Multimodality and single-modality biomarkers are used for
testing the classification performance of the proposed method,
and a multikernel learning method is used to combine multimodality biomarkers (i.e., MRI, CSF, and PET) for all classification methods. In particular, multikernel learning implement
a grid search with range from 0 to 1 and step size 0.1 on the
training subsets. It is worth noting that for optimization of all
parameters, it is performed on the training subset by an inner
10-fold cross validation. In addition, the same feature normalization scheme as in [2] is used in our experiments.
B. Classification Results for Recognizing MCI-C and MCI-NC
Patients
To investigate the effectiveness of the proposed method, we
first evaluate the classification performance of our method for
recognizing MCI-C and MCI-NC patients using both multimodality and single-modality biomarkers. Table II shows the
classification performance of five different methods, including
SVM (traditional SVM), SVM + SLR, DTSVM [29], LapSVM
[42], and the proposed method (i.e., DTFS + DTSS + DTSVM).
We also perform DeLong’s method [53] on the AUC between the proposed method and each of other four comparison

CHENG et al.: DOMAIN TRANSFER LEARNING FOR MCI CONVERSION PREDICTION

1811

TABLE III
COMPARISON OF PERFORMANCES OF DIFFERENT VARIANTS OF OUR PROPOSED
METHOD
Modality

Method

ACC
%

SEN
%

SPE
%

AUC

p-value

Multimodality
(MRI + CSF
+ PET)

DTSVM

69.4

64.3

73.5

0.736

< 0.0001

DTSS + DTSVM
DTFS + DTSVM
Proposed
DTSVM
DTSS + DTSVM
DTFS + DTSVM
Proposed
DTSVM
Proposed
(DTSS + DTSVM)
DTSVM
DTSS + DTSVM
DTFS + DTSVM
Proposed

71.3
76.5
79.4
63.3
65.6
69.4
73.4
66.2
67.6

84.0
81.2
84.5
59.8
66.2
72.0
74.3
60.3
74.6

61.4
71.9
72.7
66.0
65.3
67.3
72.1
70.8
61.5

0.755
0.836
0.848
0.700
0.686
0.743
0.764
0.701
0.715

< 0.0001
< 0.0010
< 0.0001
< 0.0001
< 0.0010
< 0.0500
-

67.0
68.1
68.7
71.6

59.6
72.9
81.0
76.4

72.7
60.8
59.0
67.9

0.732
0.726
0.733
0.741

< 0.0100
< 0.0010
< 0.0500
-

MRI

CSF

PET

Fig. 3. ROC curves of different methods for MCI-C/MCI-NC classification
with multimodality and single-modality data, respectively.

methods, with the corresponding p-values shown in Table II.
Note that DeLong’s test is a nonparametric statistical test for
comparing AUC between two ROC curves, which can be employed to assess statistical significance via computing z-scores
for the AUC estimate [54], [55]. Here, SLR denotes a sparse
feature selection method with logistic regression loss function
[43], and “SVM + SLR” represents the method that first applies
SLR for feature selection and then adopts SVM for classification. Note that each value in Table II is the averaged result of
the 10-fold cross validation, which was performed ten different
times. In addition, we plot the ROC curves achieved by different
methods in Fig. 3.
As can be seen in Table II and Fig. 3, the proposed method
consistently outperforms SVM, SVM + SLR, DTSVM, and
LapSVM in terms of the classification accuracy, sensitivity,
and AUC measures. Also, Table II indicates that both the proposed method and DTSVM significantly outperform SVM and
SVM + SLR methods, while LapSVM is only slightly better
than SVM. Moreover, statistical test measures via DeLong’s
method [53] (i.e., p-value) demonstrate the superiority of the
proposed method over other comparison methods. These results
imply that using knowledge learned from auxiliary domain (i.e.,
AD/NC classification) can effectively improve the performance
of MCI-C/MCI-NC classification. These results also suggest
that transfer learning is more suitable than semisupervised learning for the case of data coming from different domains.
On the other hand, to investigate the relative contributions of
the three components (i.e., DTFS, DTSS, and DTSVM) in our
proposed method, we compare our method with its three variants, i.e., DTSVM, DTSS + DTSVM, and DTFS + DTSVM,
with experimental results shown in Table III. It is worth noting
that DTSS + DTSVM is based on DTSVM classifier using only
the DTSS sample selection method, and DTFS + DTSVM is
also based on DTSVM classifier using only the DTFS feature selection method. For using CSF biomarkers, feature selection was
not performed because there are only three features in CSF. In

Fig. 4.

ROC curves of different variants of our proposed method.

Fig. 4, we also plot the ROC curves achieved by different methods using both multimodality and single-modality biomarkers,
respectively. In addition, we also report the p-values, which
are computed by DeLong’s method [53] on the AUC between
the proposed method and its other three variants methods in
Table III.
From Table III and Fig. 4, each component can boost the classification performance compared with SVM. It is worth noting
that, according to Fig. 4 and statistical significance assessment
in Table III, the MRI features (as opposed to PET and CSF
biomarkers) are most benefited from the proposed method as
compared with other individual components (DTSVM, DTSS,
and DTFS). This observation shows that using MRI features
in the auxiliary domain can more efficiently capture those discriminative features between MCI-C and MCI-NC patients, than
using PET or CSF features. Also, it indicates that the structural

1812

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 7, JULY 2015

TABLE IV
PERFORMANCE COMPARISON OF FOUR DIFFERENT FEATURE SELECTION
METHODS: BASELINE (NO FEATURE SELECTION), PAIRED T-TEST, SLR, AND
DTFS
Modality

Multimodality
(MRI + CSF
+ PET)

MRI

PET

Method

ACC
%

SEN
%

SPE
%

AUC

Baseline

69.4

64.3

73.5

0.736

< 0.0001

t-test
SLR
DTFS
Baseline
t-test
SLR
DTFS
Baseline
t-test
SLR
DTFS

72.3
73.1
76.5
63.3
65.3
67.2
69.4
67.0
66.6
67.7
68.7

73.1
79.3
81.2
59.8
63.1
63.4
72.0
59.6
69.2
67.9
76.4

71.7
68.3
71.9
66.0
66.9
70.2
67.3
72.7
64.5
67.6
59.1

0.760
0.824
0.836
0.700
0.699
0.741
0.743
0.732
0.718
0.714
0.733

< 0.0010
< 0.0010
< 0.0001
< 0.0010
> 0.0500
> 0.0500
< 0.0500
< 0.0500
-

TABLE V
SELECTED BRAIN REGIONS BY THE DTFS METHOD ON MRI AND PET
IMAGES, RESPECTIVELY
MRI (Brain regions)

PET (Brain regions)

amygdala right
anterior limb of internal capsule left
entorhinal cortex left
inferior frontal gyrus right
temporal lobe WM left
inferior temporal gyrus right
insula left
fornix left
hippocampal formation left
perirhinal cortex left
precuneus left
precentral gyrus left
superior parietal lobule right
supramarginal gyrus left

angular gyrus left
amygdala right
cuneus right
inferior occipital gyrus left
inferior temporal gyrus left
hippocampal formation right
lingual gyrus left
middle frontal gyrus left
medial frontal gyrus right
middle occipital gyrus left
middle temporal gyrus left
precuneus left
postcentral gyrus right
superior frontal gyrus right
superior parietal lobule left temporal pole right

p-value

changes in a brain from MRI scans are more distinctive than
the changes in a brain reflected by PET and CSF biomarkers.
In general, our proposed method that integrates all the three
components together achieves the best performance.
C. Discriminative Brain Regions Detection
To evaluate the efficacy of our proposed DTFS method for
detecting the discriminative brain regions, we compare our proposed DTFS method with the commonly used single-domainbased feature selection methods including paired t-test and SLR
[43]. It is worth noting that in the feature selection step, both
paired t-test and SLR methods only use data from target domain
(i.e., MCI-C/MCI-NC), while DTFS uses data from both target and auxiliary (i.e., AD/NC) domains. In addition, we also
compare our method with a baseline method where all features
are used (i.e., no feature selection). For evaluating the performances of different feature selection methods including DTFS,
paired t-test, SLR, and baseline, the classifier DTSVM is used
for subsequent classification after feature selection. Table IV
shows results achieved by different feature selection methods.
Here, each value in Table IV is the averaged result of 10-fold
cross-validation strategy in ten independent runs. In addition,
we also compute the p-value on the AUC between the DTFS
method and other three methods via DeLong’s method [53],
which is shown in Table IV. As can be seen from Table IV,
for MRI biomarker, there is no statistical significance between
the DTFS and SLR (P = 0.054), and also for PET biomarker,
there is no statistical significance between the DTFS and the
baseline method (P = 0.063). In general, in most cases, our
proposed DTFS method outperforms the other three methods,
which suggests that the combination of auxiliary and target domains may provide complementary information for seeking out
the most discriminative brain regions.
Furthermore, we list all selected brain regions with the highest
frequency of occurrence by DTFS on MRI and PET images in
Table V. Here, to get these features (i.e., brain regions), we count
the frequency of each feature and selected across all folds and

all runs (i.e., a total of 100 times for 10-fold cross validation
with ten independent runs), and then regarded those features
with frequency of 100 (i.e., always selected in all folds and
all runs) as selected stable features. On the other hand, in the
supplementary Tables S1 and S2, we also listed all selected
stable brain regions by paired t-test and SLR methods on MRI
and PET images, respectively.
Finally, Fig. 5 visually shows the selected brain regions with
the highest frequency of occurrence by DTFS, paired t-test,
and SLR on MRI and PET images, respectively. As can be
seen from Fig. 5, our proposed DTFS method successfully finds
out the most discriminative brain regions (e.g., hippocampal,
amygdala, temporal lobe, precuneus, and insula) that are known
to be related to AD [3], [4], [44], [45].
IV. DISCUSSION
In this paper, we propose a domain transfer learning framework to recognize MCI-C and MCI-NC patients by using
AD and NC subjects as auxiliary domain. We evaluated the
performance of our method on 202 baseline subjects from
ADNI database, and the experimental results show the proposed method can consistently and substantially improve the
classification performance, with an overall MCI-C and MCINC classification accuracy of 79.4%.
A. Domain Transfer Learning
Domain transfer learning is a recently developed machine
learning technique, which is able to learn a set of related models from the target domain and its related auxiliary domain for
improving the classification performance in target domain [26]–
[28], [38], [46]. Different from conventional machine learning
methods, domain transfer learning does not require target and
auxiliary domains having the same data distribution [38], [46],
and it can effectively use data from auxiliary domain for improving the performance in the target domain [26]–[28], [38],
[46]. However, to the best of our knowledge, there are few
studies using domain transfer learning for neuroimaging-based

CHENG et al.: DOMAIN TRANSFER LEARNING FOR MCI CONVERSION PREDICTION

Fig. 5.

1813

Selected stable brain regions by three different methods on (top) MRI and (bottom) PET images. Note that different colors indicate different brain regions.

diagnosis of brain diseases [29], [47]. It is worth noting that
in our preliminary study [29], domain transfer learning is performed only on the classification stage (i.e., DTSVM). To further improve the performance, we implement domain transfer learning throughout the whole process including DTFS,
DTSS, and domain transfer classification (i.e., DTSVM). Our
experimental results have validated the efficacy of the proposed
domain transfer learning method for recognizing MCI-C and
MCI-NC patients.
Recently, many studies in early diagnosis of AD focus on predicting the conversion of MCI to AD, i.e., identifying the MCIC from MCI-NC [3], [4], [7], [13], [15], [17], [20], [23]–[25],
[45], [48]–[51]. Several studies adopted the correlated domain
knowledge to design classifiers, or feature selection methods
for predicting the conversion from MCI to AD [3], [49], [50].
The regression-based biomarkers and multiple clinical variables
(MMSE and ADAS-Cog scores) were used as auxiliary domain knowledge for feature selection in the literatures [3], [49].
Liu et al. in [50] proposed an improved multitask feature selection method for finding discriminative brain regions using
multimodality data (MRI and PET). Different from the above
studies, our method adopts more informative auxiliary domain
knowledge (i.e., AD/NC learning task) for feature selection.
For the validity of using AD/NC learning task as auxiliary domain, we applied the method of [3], [49] on our used dataset
(i.e., 99 MCI, and their corresponding MMSE and ADAS-Cog
scores), and achieved an accuracy of 71.7% and an AUC of
0.766 using the three modalities data (i.e., MRI, PET, and CSF).
Also, we apply the method of [50] on the dataset used in this

study, and achieve an accuracy of 67.8% and an AUC of 0.696
with two modalities data (i.e., MRI and PET). Especially, our
method achieve an accuracy of 79.4% and an AUC of 0.848 with
three modalities data (i.e., MRI, PET, and CSF), and achieve an
accuracy of 77.3% and an AUC of 0.842 with two modalities data (i.e., MRI and PET). This result further validates our
assumption that using AD and NC subjects as auxiliary domain
can significantly improve the performance of MCI-C/MCI-NC
classification.
In addition, our current study uses only AD and NC subjects
as auxiliary domain. However, according to the principle of
domain transfer learning, multiple auxiliary domain knowledge
can also be utilized, as long as these multidomain learning tasks
are related to the target-domain learning task. Therefore, other
relevant learning tasks, e.g., data of other dementia type, could
be utilized to further promote the learning performances of our
proposed methods.
B. Validation and Optimizing
To evaluate the performance of our proposed domain transfer learning method, the 10-fold cross-validation strategy was
adopted. Besides the outer 10-fold cross validation, we further
perform an inner 10-fold cross validation on the training data to
find the optimal parameters. Our proposed method is evaluated
on 43 MCI-C and 56 MCI-NC subjects, which include 93 MRI
features and 93 PET features extracted from the original MR
and PET images, as well as three CSF features. To overcome
the potential overfitting problem caused by the issue of small
sample size (i.e., the sample size is considerably smaller than

1814

Fig. 6 Classification accuracy of our proposed method in multimodal case with
respect to different iterations, achieved by iterative optimization algorithm.

the feature dimensionality), we propose a DTFS method to select the most discriminative features. Similar to several studies
in early diagnosis of AD [3], [13], [44], [49]–[51], [58] where
many machine learning methods were developed for selecting
discriminative brain regions, our proposed method can also be
used for detecting discriminative brain regions from a larger
number of brain images on the clinical application. In addition,
according to our experimental results, we found that the overfitting issue rarely occurs because of the following two possible
reasons. First, the number of samples is comparable to the number of features after feature selection (DTFS). Second, instead
of simply concatenating multimodal features into a long vector,
the multikernel SVM [2] we adopted can compute kernel matrices using feature subsets from individual modalities, which
helps avoid the overfitting problem.
In this paper, a hierarchical optimization-based coarsegrid search is employed for searching optimal parameters
(i.e.,β, λ, σ, and cm ). Using this optimization strategy, it cannot
guarantee the joint optimality of parameter values. For addressing this problem, we further design an iterative optimization
algorithm to find the optimal parameters jointly. Specifically,
we first perform a grid search to find the optimal parameters β
and λ. With determination of these parameters, we then optimize other parameters (i.e., σ and cm ). Afterwards, the above
procedures are reported iteratively. In Fig. 6, we plot the change
of the classification accuracy with respect to different iterations
using the iterative optimization algorithm.
As shown in Fig. 6, the accuracy first rises with the increase
of iteration number, and then keep stable when the iteration
number is larger than 3. However, it is very time consuming
to perform such iterative optimization algorithm. We plan to
adopt such iterative optimization strategy to find the optimal
parameters in the future for further boosting the classification
performance.
C. Predicting the Conversion of MCI to AD
As mentioned above, many studies in early diagnosis of AD
focus on predicting the conversion of MCI to AD using multi-

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 7, JULY 2015

modality data [3], [4], [10], [22], [23], [50], [52]. Accordingly,
we report some representative results as follows.
In [3], a multitask feature selection method achieved an accuracy of 73.9% and an AUC of 0.797 on 43 MCI-C and 48 MCINC ADNI subjects by using multimodality data (MRI, FDGPET, and CSF). The method proposed in [4], which combines
statistical analysis and pattern classification methods, achieved
an accuracy of 62% and an AUC of 0.734 on 69 MCI-C and 170
MCI-NC ADNI subjects by using multimodality data (MRI and
CSF). Also, Hinrichs et al. in [10] proposed a multikernel pattern classification method, achieving an AUC of 0.791 on 119
MCI ADNI subjects with multimodality data (including MRI,
FDG-PET, CSF, and APOE). Westman et al. in [22] proposed
a multivariate data analysis method and achieved an accuracy
of 68.5% and an AUC of 0.76 on 81 MCI-C and 81 MCI-NC
ADNI subjects with multimodality data (i.e., MRI and CSF).
In [23], a Gaussian process classification method was proposed
and achieved an accuracy of 74.1% and an AUC of 0.795 on
47 MCI-C and 96 MCI-NC ADNI subjects with multimodality
data (i.e., MRI, FDG-PET, CSF, and APOE). By using the data
employed in this study, we apply the Gaussian process classification method proposed in [23], and achieve an accuracy
of 72.1% and an AUC of 0.797. In [50], an intermodality relationship constrained multitask feature selection method was
proposed, which achieved an accuracy of 67.8% and an AUC
of 0.696 on 43 MCI-C and 56 MCI-NC ADNI subjects with
MRI and FDG-PET data. Trzepacz et al. [52] used a statistical
analyses method and achieved an accuracy of 76% on 20 MCI-C
and 30 MCI-NC ADNI subjects by using MRI, FDG-PET, and
PIB-PET data. As shown in Section IV, our proposed domain
transfer learning classification method achieves an accuracy of
79.4% and an AUC of 0.848 with three modalities (i.e., MRI,
FDG-PET, and CSF).
D. Extension for Recognizing MCI and AD/NC
To further investigate the efficacy of our proposed domain transfer learning method, besides recognizing MCI-C and
MCI-NC, we also apply our method for recognizing MCI and
AD/NC. Specifically, we have two new classification tasks, i.e.,
MCI versus NC classification and MCI versus AD classification.
It is worth noting that AD subjects are regarded as the auxiliary
data for MCI versus NC classification, and NC subjects are regarded as the auxiliary data for MCI versus AD classification. In
the appendix, we show the experimental results by comparing
different methods with both multimodality and single-modality
biomarkers for MCI versus NC classification and MCI versus
AD classification in Tables S3 and S4, respectively.
As we can see from Tables S3 and S4, our proposed method
achieves consistently better performance than other methods in
terms of four performance evaluation measures. Specifically,
for multimodality case, our proposed method achieves the classification accuracy of 86.4%, sensitivity of 92.8%, specificity
of 73.8%, and AUC of 0.924 in MCI versus NC classification;
and the classification accuracy of 82.7%, sensitivity of 89.2%,
specificity of 69.6%, and AUC of 0.906 in MCI versus AD
classification.

CHENG et al.: DOMAIN TRANSFER LEARNING FOR MCI CONVERSION PREDICTION

In addition, we also list the results achieved by different variants of our proposed method in Tables S5 and S6 in the appendix.
Tables S5 and S6 indicate that our method that integrates all
the three components together achieves the best performance.
These results further validate the efficacy of our proposed domain transfer learning method that uses data from auxiliary
domain for aiding the classification in the target domain.
E. Limitations
The current study is limited by several factors. First, our proposed method is based on the single auxiliary domain data (i.e.,
AD and NC) from the ADNI database. In the future work, we
will investigate whether using data from more auxiliary domains
(e.g., fMRI or PIB-PET data, or even the related disease data,
e.g., vascular dementia) can further improve the performance.
Second, our current method cannot deal with subjects with incomplete multimodality of data (i.e., missing of some modalities
of data) and, thus, used only 202 subjects with all three modalities of data in ADNI. It is interesting to extend our current
method for dealing with subjects with missing modalities of
data for further improvement of performance, which is also one
of our future works. Finally, in the current study, we computed
the total PET signal from each ROI, but did not perform any
partial volume correction based on the segmented tissues from
MR image. For further performance improvement in our future
work, we will address the issues of partial volume effect and
different point spread functions between modalities.
V. CONCLUSION
In this paper, we propose a general domain transfer learningbased framework that consists of DTFS, DTSS, and DTSVM,
for MCI conversion prediction. Here, the main idea of our domain transfer learning-based method is to exploit the auxiliary
domain data (AD/NC subjects) to improve the classification between MCI-C and MCI-NC in the target domain. To the best
of our knowledge, our study is among the first in neuroimaging
to use and transfer the knowledge learned from the auxiliary
task with multimodal data (i.e., AD versus NC classification)
for guiding the target task (i.e., MCI-C versus MCI-NC classification). We have validated the efficacy of our proposed method
using 202 subjects from the ADNI database with multimodality
data (including MRI, FDG-PET, and CSF). The experimental results show that our proposed method achieves significantly better performance than the traditional methods for MCI conversion
prediction by effectively adopting the extra domain knowledge
learned from AD and NC.
ACKNOWLEDGMENT
Private sector contributions to ADNI are facilitated by the
Foundation for the National Institutes of Health. The grantee
organization is the Northern California Institute for Research
and Education, and the study is coordinated by the Alzheimer’s
Disease Cooperative Study at the University of California, San
Diego. ADNI data are disseminated by the Laboratory for Neuron Imaging at the University of California, Los Angeles.

1815

REFERENCES
[1] B. Ron et al., “Forecasting the global burden of Alzheimer’s disease,”
Alzheimer’s Dementia, J. Alzheimer’s Assoc., vol. 3, pp. 186–191, 2007.
[2] D. Zhang et al., “Multimodal classification of Alzheimer’s disease and
mild cognitive impairment,” NeuroImage, vol. 55, pp. 856–867, Apr. 1,
2011.
[3] D. Zhang et al., Multi-modal multi-task learning for joint prediction of
multiple regression and classification variables in Alzheimer’s disease,”
NeuroImage, vol. 59, pp. 895–907, Jan. 16, 2012.
[4] C. Davatzikos et al., “Prediction of MCI to AD conversion, via MRI,
CSF biomarkers, and pattern classification,” Neurobiol. Aging, vol. 32,
pp. 2322-e19–2322-e27, Dec. 2011.
[5] R. Filipovych et al., “Semi-supervised pattern classification of medical
images: application to mild cognitive impairment (MCI),” NeuroImage,
vol. 55, pp. 1109–1119, Apr. 1, 2011.
[6] D. Zhang and D. Shen, “Semi-supervised multimodal classification of
Alzheimer’s disease,” in Proc. IEEE Int. Symp. Biomed. Imag., 2011,
pp. 1628–1631.
[7] Y. Cho et al., “Individual subject classification for Alzheimer’s disease
based on incremental learning using a spatial frequency representation
of cortical thickness data,” NeuroImage, vol. 59, pp. 2217–2230, Feb. 1,
2012.
[8] R. Filipovych et al., “Semi-supervised cluster analysis of imaging data,”
NeuroImage, vol. 54, pp. 2185–2197, Feb. 1, 2011.
[9] L. J. Ritchie and H. Tuokko, “Patterns of cognitive decline, conversion
rates, and predictive validity for 3 models of MCI,” J. Alzheimer’s Dis.
Other Dementias, vol. 25, pp. 592–603, Nov. 2010.
[10] C. Hinrichs et al., “Predictive markers for AD in a multi-modality framework: an analysis of MCI progression in the ADNI population,” Neuroimage, vol. 55, pp. 574–589, Mar. 15, 2011.
[11] Y. Aksu et al., “An MRI-derived definition of MCI-to-AD conversion
for long-term, automatic prognosis of MCI patients,” PloS One, vol. 6,
pp. e25074, Oct. 12, 2011.
[12] B. Borroni et al., “Combined 99mTc-ECD SPECT and neuropsychological studies in MCI for the assessment of conversion to AD,” Neurobiol.
Aging, vol. 27, pp. 24–31, Jan. 2006.
[13] S. Duchesne and A. Mouiha, “Morphological factor estimation via highdimensional reduction: Prediction of MCI conversion to probable AD,”
Int. J. Alzheimers Dis., Jun. 2011, doi:10.4061/2011/914085
[14] G. Chetelat et al., “Using voxel-based morphometry to map the structural
changes associated with rapid conversion in MCI: A longitudinal MRI
study,” NeuroImage, vol. 27, pp. 934–946, Oct. 1, 2005.
[15] K. K. Leung et al., “Increasing power to predict mild cognitive impairment conversion to Alzheimer’s disease using hippocampal atrophy rate
and statistical shape models,” in Proc. Int. Conf. Med. Image Comput.
Comput.-Assisted Intervention, 2010, vol. 13, pp. 125–132.
[16] S. L. Risacher et al., “Baseline MRI predictors of conversion from MCI
to probable AD in the ADNI cohort,” Current Alzheimer Res., vol. 6,
pp. 347–361, Aug. 2009.
[17] C. Misra et al., “Baseline and longitudinal patterns of brain atrophy in
MCI patients, and their use in prediction of short-term conversion to
AD: Results from ADNI,” NeuroImage, vol. 44, pp. 1415–1422, Feb. 15,
2009.
[18] L. Mosconi et al., “MCI conversion to dementia and the APOE genotype:
A prediction study with FDG-PET,” Neurology, vol. 63, pp. 2332–2340,
Dec. 28, 2004.
[19] S. Morbelli et al., “Mapping brain morphological and functional conversion patterns in amnestic MCI: A voxel-based MRI and FDG-PET study,”
Eur. J. Nuclear Med. Mol. Imag., vol. 37, pp. 36–45, Jan. 2010.
[20] R. Cuingnet et al., “Automatic classification of patients with Alzheimer’s
disease from structural MRI: a comparison of ten methods using the ADNI
database,” NeuroImage, vol. 56, pp. 766–781, May 15, 2011.
[21] R. Wolz et al., “Multi-method analysis of MRI images in early diagnostics
of Alzheimer’s Disease,” PLoS ONE, vol. 6, pp. e25446, 2011.
[22] E. Westman et al., “Combining MRI and CSF measures for classification of Alzheimer’s disease and prediction of mild cognitive impairment
conversion,” NeuroImage, vol. 62, pp. 229–238, Aug. 1, 2012.
[23] J. Young et al., “Accurate multimodal probabilistic prediction of conversion to Alzheimer’s disease in patients with mild cognitive impairment,”
NeuroImage, Clin., vol. 2, pp. 735–745, 2013.
[24] X. Da et al., “Integration and relative value of biomarkers for prediction
of MCI to AD progression: Spatial patterns of brain atrophy, cognitive
scores, APOE genotype and CSF biomarkers,” NeuroImage, Clin., vol. 4,
pp. 164–173, 2014.

1816

[25] P. Coupé et al., “Scoring by nonlocal image patch estimator for
early detection of Alzheimer’s disease,” NeuroImage, Clin., vol. 1,
pp. 141–152, 2012.
[26] J. Yang et al., “Cross-domain video concept detection using adaptive
SVMs,” in Proc. 15th Int. Conf. Multimedia, 2007, pp. 188–197.
[27] L. Duan et al., “Domain adaptation from multiple sources via auxiliary
classifiers,” in Proc. Int. Conf. Mach. Learn., 2009, pp. 289–296.
[28] W. Jiang et al., “Cross-domain learning methods for high-level visual
concept classification,” in Proc. 15th IEEE Int. Conf. Image Process.,
2008, pp. 161–164.
[29] B. Cheng et al., “Domain transfer learning for MCI conversion prediction,”
in Proc. Int. Conf. Med. Image Comput. Computer-Assisted Intervention,
2012, vol. 7510, pp. 82–90.
[30] CIT. (2012). Medical Image Processing, Analysis and Visualization (MIPAV) [Online]. Available: http://mipav.cit.nih.gov/clickwrap.php
[31] J. G. Sled et al., “A nonparametric method for automatic correction of
intensity nonuniformity in MRI data,” IEEE Trans. Med. Imag., vol. 17,
no. 1, pp. 87–97, Feb. 1998.
[32] Y. Wang et al., “Robust deformable-surface-based skull-stripping for
large-scale studies,” in Proc. Med. Image Comput. Comput.-Assisted Intervention, Toronto, Canada, 2011, pp. 635–642.
[33] Y. Zhang et al., “Segmentation of brain MR images through a hidden
Markov random field model and the expectation maximization algorithm,”
IEEE Trans. Med. Imag., vol. 20, no. 1, pp. 45–57, 2001.
[34] D. Shen and C. Davatzikos, “HAMMER: Hierarchical attribute matching
mechanism for elastic registration,” IEEE Trans. Med. Imag., vol. 21, no.
11, pp. 1421–1439, Nov. 2002.
[35] N. Kabani et al., “A 3D atlas of the human brain,” Neuroimage, vol. 7,
pp. 7–17, 1998.
[36] A. Argyriou et al., “Convex multi-task feature learning,” Mach. Learn.,
vol. 73, pp. 243–272, 2008.
[37] W. Dai et al., “Boosting for transfer learning,” in Proc. 24th Int. Conf.
Mach. Learn., 2007, pp. 193–200.
[38] S. J. Pan and Q. Yang, “A survey on transfer learning,” IEEE Trans. Knowl.
Data Eng., vol. 22, pp. 1345–1359, Oct. 2010.
[39] J. Liu et al. (2009). SLEP: Sparse Learning With Efficient Projections [Online]. Arizona State University, Tucson, AZ, USA. Available:
http://www.public.asu.edu/ ∼jye02/Software/SLEP
[40] L. Ferrarini et al., “Morphological hippocampal markers for automated
detection of Alzheimer’s disease and mild cognitive impairment converters in magnetic resonance images,” J. Alzheimer’s Disease, vol. 17,
pp. 643–659, 2009.
[41] C. C. Chang and C. J. Lin. (2000, Apr.) LIBSVM: A library for support vector machines. Taipei, Taiwan [Online]. Available: http://www.
csie.ntu.edu.tw/∼cjlin/libsvm/
[42] M. Belkin et al., “Manifold regularization: A geometric framework for
learning from labeled and unlabeled examples,” J. Mach. Learn. Res.,
vol. 7, pp. 2399–2434, Nov. 2006.
[43] J. Liu et al., “Large-scale sparse logistic regression,” in Proc. 15th ACM
SIGKDD Conf. Knowl. Discovery Data Mining, 2009, pp. 547–556.
[44] J. Ye et al., “Sparse learning and stability selection for predicting MCI to
AD conversion using baseline ADNI data,” BMC Neurology, vol. 12, pp
46–58, Jun. 25, 2012.
[45] S. F. Eskildsen et al., “Prediction of Alzheimer’s disease in subjects with
mild cognitive impairment from the ADNI cohort using patterns of cortical
thinning,” NeuroImage, vol. 65, pp. 511–521, 2013.
[46] L. X. Duan et al., “Domain transfer multiple kernel learning,” IEEE Trans.
Pattern Anal. Mach. Intell., vol. 34, no. 3, pp. 465–479, Mar. 2012.
[47] Y. Schwartz et al., “Improving accuracy and power with transfer learning
using a meta-analytic database,” in Proc. Int. Conf. Med. Image Comput.
Comput.-Assisted Intervention, 2012, vol. 7512, pp. 248–255.
[48] M. Lehmann et al., “Visual ratings of atrophy in MCI: Prediction of
conversion and relationship with CSF biomarkers,” Neurobiol. Aging,
vol. 34, no. 1, pp. 73–82, Apr. 17, 2012.
[49] D. Zhang et al., “Predicting future clinical changes of MCI patients using
longitudinal and multimodal biomarkers,” PLoS One, vol. 3, pp. e33182,
2012.
[50] F. Liu et al., “Inter-modality relationship constrained multi-modality
multi-task feature selection for Alzheimer’s Disease and mild cognitive
impairment identification,” NeuroImage, vol. 84, pp. 466–475, Jan. 1,
2014.
[51] H. Li et al., “Hierarchical interactions model for predicting mild cognitive
impairment (MCI) to Alzheimer’s Disease (AD) conversion,” PloS One,
vol. 9, pp. e82450, 2014.

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 7, JULY 2015

[52] P. T. Trzepacz et al., “Comparison of neuroimaging modalities for the
prediction of conversion from mild cognitive impairment to Alzheimer’s
dementia,” Neurobiol. Aging, vol. 35, pp. 143–151, Jan. 2014.
[53] E. R. DeLong et al., “Comparing the areas under two or more correlated receiver operating characteristic curves: a nonparametric approach,”
Biometrics, vol. 44, pp. 837–845, 1988.
[54] M. R. Sabuncu et al., “Clinical prediction from structural brain
MRI scans: A large-scale empirical study,” Neuroinformatics, vol. 13,
pp. 31–46, 2015.
[55] X. Robin et al., “pROC: An open-source package for R and S+ to analyze
and compare ROC curves,” BMC Neurology, vol. 12, pp 77–85, 2011.
[56] N. Singh et al., “Genetic, structural and functional imaging biomarkers
for early detection of conversion from MCI to AD,” in Proc. Int. Conf.
Med. Image Comput. Comput.-Assisted Intervention, 2012, vol. 7510,
pp. 132–140.
[57] Y. Fan et al., “Unaffected family members and schizophrenia patients
share brain structure patterns: a high-dimensional pattern classification
study,” Biol. Psychiatry, vol. 63, pp. 118–124, 2008.
[58] Y. Li et al., “Discriminant analysis of longitudinal cortical thickness
changes in Alzheimer’s disease using dynamic and network features,”
Neurobiol. Aging, vol. 33, pp. 427-e15–427-e30, 2012.

Bo Cheng received the B.Eng. and M.Eng. degree
from Southwest University, Chongqing, China, in
2005 and 2008, respectively. He is currently working
toward the Ph.D. degree in computer science from the
Nanjing University of Aeronautics and Astronautics,
Nanjing, China.
In 2008, he joined the School of Computer Science
and Engineering, Chongqing Three Gorges University, Chongqing, as a Lecturer. His research interests
include machine learning, pattern recognition, and
neuroimaging analysis.

Mingxia Liu received the B.S. and M.S. degrees from
Shandong Normal University, Shandong, China, in
2003 and 2006, respectively. She is currently working toward the Ph.D. degree in computer science from
the Nanjing University of Aeronautics and Astronautics, Nanjing, China.
In 2006, she joined the School of Information Science and Technology, Taishan University, as a Lecturer. Her research interests include machine learning, pattern recognition, computer vision, and neuroimaging analysis.

Daoqiang Zhang (M’14) received the B.Sc. and
Ph.D. degrees in computer science from the Nanjing
University of Aeronautics and Astronautics, Nanjing,
China, in 1999 and 2004, respectively.
He joined the Department of Computer Science
and Engineering, Nanjing University of Aeronautics
and Astronautics in 2004, where he is currently a
Professor. He has published more than 100 technical
papers in referred journals or conference proceedings, including reputable international journals, such
as the Neuroimage, the Human Brain Mapping, etc.,
and top-tier international conferences, such as MICCAI, IJCAI, AAAI, etc.,
with more than 4500 citations by Google Scholar. His research interests include
machine learning, pattern recognition, data mining, and medical image analysis.
Prof. Zhang was also nominated for the National Excellent Doctoral Dissertation Award of China in 2006, and received the Best Paper Award at the 9th
Pacific Rim International Conference on Artificial Intelligence. He served as a
Program Committee Member for several international and native conferences.
He is a Member of the Chinese Association of Artificial Intelligence Machine
Learning Society.

CHENG et al.: DOMAIN TRANSFER LEARNING FOR MCI CONVERSION PREDICTION

Brent C. Munsell received the B.S. degree in electrical engineering from Michigan State University, East
Lansing, MI, USA, the Master’s degree in electrical
engineering from Clemson University, Clemson, SC,
USA, and the Ph.D. degree in computer science and
engineering from the University of South Carolina,
Columbia, SC.
He is currently an Assistant Professor at the Computer Science Department, College of Charleston,
Charleston, SC. His research interests include medical image analysis, machine learning, and computer
vision.
Dr. Munsell has published papers in several top journals and conferences,
such as the IEEE Transactions on Pattern Analysis and Machine Intelligence,
the International Journal of Computer Vision, the NeuroImage, the Medical Image Computing and Computer Assisted Intervention, and the IEEE Computer
Vision and Pattern Recognition. He has also served as an Organizer or Committee Member or for several workshops, including MICCAI Machine Learning in
Medical Imaging, Patch-Based Techniques and Medical Imaging, and Analysis
and Retrieval of Tracked Events and Motion in Imagery Streams.

1817

Dinggang Shen (A’00–M’00–SM’07) was a TenureTrack Assistant Professor with the University of
Pennsylvanian, and a Faculty Member with the Johns
Hopkins University. He is currently a Professor of
radiology at the Biomedical Research Imaging Center (BRIC), Computer Science and Biomedical Engineering Department, University of North Carolina
at Chapel Hill, Chapel Hill, NC, USA. He is also
the Director with the Center for Image Informatics,
Image Display, Enhancement, and Analysis Lab, Department of Radiology, and also the Medical Image
Analysis Core, BRIC. His research interests include medical image analysis,
computer vision, and pattern recognition. He has published more than 500 papers in the international journals and conference proceedings.
Dr. Shen serves as an Editorial Board Member for six international journals.
He also serves in the Board of Directors, The Medical Image Computing and
Computer Assisted Intervention Society.

