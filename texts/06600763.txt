492

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 2, MARCH 2014

Knowledge-Assisted Sequential Pattern Analysis
With Heuristic Parameter Tuning for Labor
Contraction Prediction
Zifang Huang, Mei-Ling Shyu, Senior Member, IEEE, James M. Tien, Michael M. Vigoda, and David J. Birnbach

Abstract—The optimal dosing regimen of remifentanil for relieving labor pain should achieve maximal efficacy during contractions and little effect between contractions. Toward such a need,
we propose a knowledge-assisted sequential pattern analysis with
heuristic parameter tuning to predict the changes in intrauterine
pressure, which indicates the occurrence of labor contractions. This
enables giving the drug shortly before each contraction starts. A sequential association rule mining based patient selection strategy is
designed to dynamically select data for training regression models.
A novel heuristic parameter tuning method is proposed to decide
the appropriate value ranges and searching strategies for both the
regularization factor and the Gaussian kernel parameter of leastsquares support vector machine with radial basis function (RBF)
kernel, which is used as the regression model for time series prediction. The parameter tuning method utilizes information extracted
from the training dataset, and it is adaptive to the characteristics
of time series. The promising experimental results show that the
proposed framework is able to achieve the lowest prediction errors
as compared to some existing methods.
Index Terms—Association rule mining, labor contraction prediction, least-squares support vector machine (LS-SVM), parameter
tuning, time series prediction.
Fig. 1.

I. INTRODUCTION
EMIFENTANIL is a relatively new, very potent, and shortacting opioid, which has shown to be effective in the relief
of labor pain. It is an alternative analgesia for those parturients
who cannot receive neuraxial analgesia because of preexisting
conditions, or those who request analgesia other than epidural
block. A challenge to a systemic opioid is that the infusion
must match the unique time course of labor pain, so that it
will have maximal efficacy during contractions and little effect
between contractions. A continuous infusion during times in
which the patient does not experience pain may increase the

R

Manuscript received March 1, 2013; revised August 10, 2013; accepted
September 5, 2013. Date of publication September 16, 2013; date of current
version March 3, 2014.
Z. Huang is with Western Union Digital, San Francisco, CA 94107 USA
(e-mail: z.huang3@umiami.edu).
M.-L. Shyu and J. M. Tien are with the Department of Electrical and Computer Engineering, University of Miami, Coral Gables, FL 33124 USA (e-mail:
shyu@miami.edu; jmtien@miami.edu).
M. M. Vigoda and D. J. Birnbach are with the Department of Anesthesiology, University of Miami Miller School of Medicine, Miami, FL 33136 USA
(e-mail: MVigoda@med.miami.edu; dbirnbach@miami.edu).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2013.2281974

Flowchart of the proposed framework.

risks of respiratory depression, sedation and nausea, and also
the amount of the drug to which the fetus is exposed. Therefore,
it is necessary to optimize the dosing regimen in order to employ
remifentanil in labor pain relieving effectively [1], [2].
The onset of the opioid’s effect is approximately 30s [3],
so the prediction should be made approximately 30s ahead of
the next contraction to accurately match the effect of analgesia.
After a review of the physiology of labor contractions, we appreciate that a pacemaker for contractions has not been found [4],
and there is no such factor from the physiological point of view
that is able to predict the uterine activities ahead of time. Therefore, an appropriate way for us to approach this problem is to
analyze the intrauterine pressure time series, and undertake the
prediction of contractions based on the learned patterns. The
contraction pattern differs from woman to woman, from pregnancy to pregnancy, and also changes in different stages of a
woman’s labor, which makes it very challenging to accurately
perform a prediction. It would be preferred if the prediction
model is personalized, which is adaptive to each patient’s age,
weight, gestational age, and oxytocin usage, etc.
To address the aforementioned challenges, a novel
knowledge-assisted sequential pattern analysis with heuristic
parameter tuning, as shown in Fig. 1, is developed for predicting the intrauterine pressure multiple seconds ahead in real time.
A group of historical patient tracings (HTs) are dynamically se-

2168-2194 © 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

HUANG et al.: KNOWLEDGE-ASSISTED SEQUENTIAL PATTERN ANALYSIS WITH HEURISTIC PARAMETER TUNING

lected from the stored records of patient information (HI) based
on the current patient’s demographic and obstetrical information. A sequential association rule based collaborative training
dataset selection method is designed to dynamically select a
training dataset from HT and the current patient’s own most
recent training time series for training the prediction models. A
k-nearest neighbors (k-NN) based least-squares support vector
machine (LS-SVM) approach with heuristic parameter tuning is
proposed to conduct long-term time series prediction. The bottleneck of the LS-SVM with the RBF model lies in the fact that
there are two parameters to be tuned, i.e., the regularization parameter γ and the bandwidth for the RBF kernel σ. It is crucial to
select appropriate values for these two parameters to ensure the
accurate prediction results. Finally, a postprediction process is
applied to further enhance the prediction results. Please note that
the focus of this paper is on sequential association rule based patient selection and heuristic parameter tuning, while the k-NN
based LS-SVM approach, the postprediction process, and the
sequential association rule based collaborative training dataset
selection were presented in our previous publications [5]–[7].
The remainder of this paper is organized as follows. Section II
presents the proposed sequential association rule based patient
selection method. Section III details the heuristic parameter
tuning strategy. In Section IV, comparisons and experimental
results are shown to evaluate the performance of the proposed
framework. The conclusion is given in Section V.

II. SEQUENTIAL ASSOCIATION RULE BASED
PATIENT SELECTION
Although obstetricians have some empirical observation on
how the demographic and obstetrical features impact the uterine contraction pattern, systemic and theoretical study is challenging due to the difficulties in formulizing the problem. We
propose a sequential association rule mining based approach to
discover the interesting sequential patterns from the intrauterine
pressure time series, and then identify the demographic and obstetrical features that have an impact on the uterine contraction
pattern. Patient selection can then be conducted using the identified features. The selection process makes the HT personalized
to each patient.
A contraction can be described by the peak height and period
in the intrauterine pressure tracing. The contraction pattern is
determined by the combination of both the height and the period
of a contraction. The features extracted for contractions are numerical. In order to discover the sequential association relationships among contractions, it is necessary to discretize the features. There are many association rules generated from the discretized time series. From our empirical study, the equal-width
discretization method generates a better and more meaningful
set of association rules for our dataset in comparison to those
rules generated by the equal-frequency discretization method.
Thus, the equal-width discretization method is adopted. Sequential pattern analysis on intrauterine pressure tracings provides a
way to characterize the pattern of contractions. This enables the
analysis on whether and how the demographic and obstetrical

493

features impact the sequential uterine contraction pattern. The
sequential association rule mining method is detailed in [8].
Based on the domain knowledge, we summarize some demographic and obstetrical features that might have some impacts
on the uterine contraction pattern in labor. The features include
maternal age, body mass index (BMI), gestational age, number
of pregnancies, living children pregnancy history, labor anesthesia, and indication of oxytocin. The meaning of each variable is
given as follows.
1) The maternal age is a numerical value. The maternal age
determines the contractility of the muscles, so it might
influence the uterine contraction pattern as well.
2) The BMI is a heuristic proxy for human body fat based on
an individual’s weight and height. The BMI is a numerical
value.
3) The gestational age is defined as the time elapsed since
14 days prior to fertilization, and it is recorded in terms of
the number of weeks.
4) The number of pregnancies means the number of babies
that the parturient is carrying.
5) The living children pregnancy history indicates if the
woman has ever given birth before.
6) For labor anesthesia, most of the women in the study have
chosen epidural, and some other chose anesthesia other
than epidural, for example, intravenous sedation or no
anesthesia.
7) Oxytocin can be used for induction or labor augmentation.
The amount of oxytocin for induction is much larger than
it is for augmentation. Oxytocin promotes and accelerates
uterine contraction.
We analyze these features one by one using the sequential
association rule mining method. Patients are divided into several
groups with different ranges of value for one feature, and then
analyze the sequential uterine contraction pattern of each group.
If the sequential uterine contraction patterns of these groups
are different, it means that this feature has a strong impact
or determines the sequential uterine contraction pattern. Thus,
the feature is kept for grouping the patients for later analysis;
otherwise, the feature is discarded.
Based on our analysis, we observe that maternal age, gestational age, labor anesthesia, and indication of oxytocin, have an
impact on the sequential uterine contraction pattern. Therefore,
these four features are employed to select the patients. Based on
the generated sequential uterine contraction pattern and domain
knowledge, we use three of the chosen features and design a
tree, as shown in Fig. 2, to classify the patients in HI into seven
groups. The three features are gestational age, labor anesthesia,
and indication of oxytocin.
Induced labor significantly differs from spontaneous labor.
A large amount of oxytocin alters how frequently the uterus
contracts. The retrieved sequential uterine contraction patterns
are also different. Therefore, we choose indication for oxytocin
as the root node to separate the patients who had induction from
the patients who gave natural birth. For patients who did not
experience induction, labor anesthesia is used to differentiate the
patients who had epidural from the patients who had analgesic
other than epidural. For induced labor, the labor process usually

494

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 2, MARCH 2014

It is an optimization problem to calculate w and b based on
the given training instances. Let ej be an error variable, which
is the approximate error for the jth training instance. Let γ
be a regularization parameter; the optimization problem can be
formulated in the primal weight space as follows:
1 T
1 2
w w+γ
e
2
2 j =1 j
N

min JP (w, e) =

w ,b,e

subject to yj = wT ϕ(xj ) + b + ej , j = 1, . . . , N.

(1)

The estimated function can be derived as in (2) using kernel
trick:

Fig. 2.

Tree for patient selection.

takes a longer time. All the patients who had induced labor chose
to have epidural. Therefore, we omit the labor anesthesia node
in the left branch. We further divide the groups by gestational
age to differentiate preterm labor (gestational age < 38) from
term and postterm labor (gestational age ≥ 38). For patients who
gave natural birth and had epidural (majority of patients are in
this case), we also separate term labor (38 ≤ gestational age
≤ 40) from postterm labor (gestational age > 40). Accordingly,
we can divide the patients into seven groups based on this built
tree.
The inputs of the patient selection component are HI and the
current patient’s demographic and obstetrical information. HI
includes multiple past patients’ preprocessed intrauterine pressure time series and their demographic and obstetrical information. The patients in HI are divided into seven groups according
to the tree shown in Fig. 2. The output is selected HT. The purpose of patient selection is to select some patients who share
similar demographic and obstetrical features with the current patient of interest. The selection process contains two steps. First,
we determine which group the current patient should belong to
according to her gestational age, labor anesthesia, and indication of oxytocin using the tree in Fig. 2. Let the current patient
belong to group i, where 1 ≤ i ≤ 7. Second, select nP atient
patients from group i whose ages are closest to the current patient’s age. The selected patients’ intrauterine tracings are the
output of this component, and are passed to collaborative training dataset selection component as one of its inputs to form a
training dataset for building the prediction models.
III. HEURISTIC PARAMETER TUNING
The LS-SVM method is widely used in nonlinear regression
and classification [9]. Here, we provide an overview of its application in the nonlinear regression problem. Given a set of
training instances {(x1 , y1 ), (x2 , y2 ), . . . , (xN , yN )}, where N
is the number of training instances. Let x ∈ Rp , y ∈ R, and
ϕ(x) : Rp → Rp h be a mapping function which maps the input
vector x, of which the dimensionality is p, to a high-dimensional
feature space at dimension ph . The LS-SVM model can be described as y(x) = wT ϕ(x) + b, where w ∈ Rp h is a weight
vector and b is a bias.

y(x) =

N


αj K(x, xj ) + b.

(2)

j =1

The kernel trick enables us to map the input vector into
a huge-dimensional feature space without explicitly computing in that space. The kernel function should satisfy Mercer’s
condition [9]. In our study, the RBF kernel (K(xi , xj ) =
exp(−xi − xj 22 /σ 2 ), where σ is the variance) is used because of its suitability in nonlinear modeling and the time series
prediction application.
There are two tuning parameters, γ and σ, which need to
be decided. γ is the regularization factor, which determines the
tradeoff between the training error minimization and smoothness of the estimated function. σ is the bandwidth of the Gaussian kernel. In Section III-A and Section III-B, we propose
strategies for tuning these two parameters utilizing the information extracted from the training dataset. More details about the
LS-SVM method can be found in [9].
A. Selection of the Kernel Parameter σ
The kernel trick enables us to work in large-dimensional feature spaces without doing explicit computation in the largedimensional spaces. In the case of the RBF kernel, the underlying mapping function actually maps the input vectors into
an infinite-dimensional space. Even though LS-SVM with RBF
kernel has been commonly used for regression, there is no sufficient study on how to find a reasonable range for tuning the
kernel parameter σ. Given two input vectors in the training
dataset, x and z, the RBF kernel function can be expressed as
shown in (3):
K(x, z) = exp(−x − z22 /σ 2 ).

(3)

Let s = x − z2 , and hence K(x, z) = exp(−s2 /σ 2 ). For a
given training dataset, the values of s are bounded in a specific
range for any possible combination of x and z values. Assume
that the minimum distance between the two training instances
is sm in , and the maximum distance between the two training
instances is sm ax . Fig. 3 is a plot of the kernel function which
shows how K(x, z) decreases when s increases.
In order to obtain a good regression model for the training
dataset as described in (2), we propose that the range of s, which
is [sm in , sm ax ], should be located at a position where the slope
of the kernel function is large. The reason of this assumption is

HUANG et al.: KNOWLEDGE-ASSISTED SEQUENTIAL PATTERN ANALYSIS WITH HEURISTIC PARAMETER TUNING

We do not expect the training error to be zero or very close to
zero, because that probably means the model is overfitting to
the training dataset. Here, we utilize Gamma test to estimate
the variance of the noise. Gamma test is introduced for model
selection and also for input selection [10], [11], while it is employed here for the purpose of parameters tuning. Gamma test is
based on the assumption that if two points are very close in the
input space, the corresponding output should be close enough.
Otherwise, the deviation is caused by noise. Given M instances:
{(x1 , y1 ), (x2 , y2 ), . . . , (xM , yM )}, where x ∈ Rp and y ∈ R.
The relationship between the input and the output can be formulated as in (5):

1

K(x,z)

0.8

0.6

0.4

0.2

0
0 smin
Fig. 3.

495

σ

smax

2σ

s

3σ

4σ

RBF kernel function.

that we want to differentiate the instances as much as possible
through the use of the kernel trick. By differentiating the training instances through the kernel trick, the nonlinear regression
approach is able to capture more information from the training dataset for modeling. On the other hand, if many training
instances are mapped to the flat part of the kernel function,
K(x, xj ) will be a constant, which will not be able to construct
a reasonable regression model. Based on the observation that
the K(x, z) curve becomes flat when s is larger than 2σ, it is
recommended to bound s within 2σ. Thus, we have sm ax ≤ 2σ.
It can be deduced that the slope of the point at s = 0.0367σ
is the same as the slope of the point at s = 2σ. Following the
same reasoning, we have sm ax ≥ 0.0367σ. Therefore, a heuristic value range for the kernel parameter σ is shown in (4):
sm ax
sm ax
≤σ≤
.
(4)
2
0.0367
Meanwhile, through empirical studies, we observe that the
value of the optimal kernel parameter is usually closer to sm ax /2
than to its upper bound sm ax /0.0367. Therefore, in the experiments, we select sm ax /2 as the initial value of σ, and then search
for the optimal value within the suggested range.
B. Selection of the Regularization Factor γ
The regularization factor γ in (1) controls the tradeoff between the training error minimization and the smoothness of
the model. A larger regularization factor gives more weights
to the modeling error in solving the optimal problem. In this
case, the corresponding training error will be smaller, while the
smoothness of the model is lower. When the value of γ is too
large, it leads to the overfitting problem. On the other hand, if
the value of γ is too small, the model will be smoother but it
has not learned from the training dataset enough, which means
that the model cannot fully capture the relationship between the
inputs and outputs in the training dataset. Therefore, it is important to select an appropriate value for γ, so that the estimated
model will not overfit the training dataset but is able to model
the underlying function.
The problem is how we can know if the model is overfitting to
the training dataset, and when the training error is small enough.

yi = f (xi ) + ri , i ∈ [1, M ]

(5)

where f is the underlying function which captures the relationship between xi and yi . ri is the noise for the ith instance. We
can assume that the mean of the r is zero, because any bias can
be considered as a part of the underlying function f . Gamma
test is used to estimate the variance of r, denoted as σr2 , by
calculating the vertical intercept of the linear regression line:
η(k) = Aδ(k) + B, 1 ≤ k ≤ p, where A is the slope parameter
and B is the vertical intercept. p is usually set to 10. η(k) and
δ(k) are defined in (6) and (7), respectively:
η(k) =

M
1 
(y[i,k ] − yi )2
2M i=1

(6)

δ(k) =

M
2
1  
x[i,k ] − xi 
M i=1

(7)

where x[i,k ] is the kth nearest neighbor of xi , and y[i,k ] is the
output value corresponding to x[i,k ] . Compute the regression
line of the p points (δ(k), η(k)), 1 ≤ k ≤ p. σr2 is estimated by
the vertical intercept B of the regression line. When the number
of the instances is large enough, B is a reliable estimation of the
variance.
If the signal does not contain noise, the component estimated
by the Gamma test can also be considered as a part of the signal
that cannot be captured by regression modeling. We compute
leave-one-out (LOO) error to estimate the training error σt2 .
The LOO technique can evaluate the model more generally and
avoid overfitting. If the LOO error is larger than the variance of
the noise, we increase the value of γ. Otherwise, the value of γ
is decreased. γ is updated according to (8):
γ(i + 1) = γ(i) ×

σt2 (i)
σr2

(8)

where i is the index of the iterations. σt2 (i) is the LOO error at
the ith iteration. According to (1), γ is a weight coefficient of the
squared training error. Therefore, a variance ratio based updating
strategy is suitable to quickly locate the optimal value for γ. The
searching process stops when the training error changes within
5%. The selection of 5% is another attempt to avoid overfitting,
which can be adjusted if necessary. In this way, the trained model
is not overfitted to the training dataset, and is able to model the
underlying function between the inputs and outputs. The tuning
process converges quickly because of the utilization of the error

496

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 2, MARCH 2014

feedback to adjust the value of γ. As suggested in [10], the initial
value of γ, denoted as γ(1), is given by (9):
γ(1) =

σy2
σr2

(9)

where σy2 is the variance of the output in the training dataset.
The pseudocode of the algorithm is shown below. The inputs
are the training time series d and a set values for σ within the
range [sm ax /2, sm ax /0.0367], denoted as SIGM A. The outputs of the tuning process are the σ and γ values corresponding to
the minimum LOO error. The processes of tuning σ and γ are intertwined, and are based on the training dataset only. Line 1 calculates the variance of the training time series and estimates the
variance of the noise. Lines 2 and 3 initialize the variables cost
and gam. The f or loop from line 4 to line 18 is to select a γ value
for each value of σ in SIGM A, according to (8), and the initial
σ2
value of γ is set to σ y2 . In lines 8 and 14, leaveoneout(T raining
r
dataset, γ(i), σ 2 ) is a function which takes the training dataset
as the input, uses γ(i) and σ 2 as the hyperparameters of the
LS-SVM method with RBF kernel, and returns the LOO error.
As stated in lines 9 and 10, when the LOO error is 0, or the
LOO error decreases less than 5% compared to the error measure from the previous iteration, the value of γ to pair with the
given σ is returned. In lines 19 and 20, the combination of the
parameters which gives the lowest LOO error among the paired
parameters is returned as the output.

The training error could be less than the variance of the noise
of the outputs when the value of γ is large enough. However,
LS-SVMNNE does not provide the initial value for γ and the
range for σ 2 , while the prediction performance is closely related
to these preset values. Meanwhile, the strategy that increases the
value of γ by doubling its previous value might not be appropriate. Given an initial γ value, γ(1), let the number of iterations
be m, i.e., the searching is terminated after increasing the γ
value m times. The updating step size is increased after each
iteration, and the maximum deviation of the selected γ value
from the true optimal γ value is 2m −1 γ(1), which increases exponentially. Therefore, the deviation from the optimal value can
be very large when m is large. In the proposed framework, a
variance ratio based updating strategy, according to (8), is able
to locate the optimal value for γ quickly. The number of iterations is expected to be small, which will be validated through
the experiments. Also, the updating step size is decreased after
each iteration, and it does not suffer from the problem that the
returned value deviates from the optimal value significantly. The
limitation of the proposed method is that the estimated variance
of the noise cannot be zero. This criterion is satisfied by most
of the time series.
LS-SVMheu recommends the minimum and maximum values of both γ and σ 2 , while LS-SVMheu does not give a solution
of finding the optimal values of these parameters [10]. For the
regularization factor γ, both the initial and maximum values are
suggested to be the ratio of the variance of the output to the
estimated variance of the noise [10], and its minimum value is
set to 1. However, there is no sufficient reasoning on this selection of the range of γ. In addition, a fixed minimum γ value
for all time series is not preferable. The suggested range for σ
is [sm in , sm ax ], where sm in is the minimum distance between
the two training instances and sm ax is the maximum distance
between the two training instances. However, there is no theoretical basis for this selection. The recommended range for σ by
the proposed method is [sm ax /2, sm ax /0.0367], which is based
on the property of the RBF kernel function.

IV. EXPERIMENTAL RESULTS

C. Comparative Analysis
We theoretically compare the proposed parameter tuning
method with some existing approaches: LS-SVMNNE [12] and
LS-SVMheu [10]. LS-SVMNNE keeps increasing the value of
γ by doubling its previous value until the training error does not
exceed the noise variance estimated by the nonparametric noise
estimator [12]. A larger γ value leads to a smaller training error.

We compare the proposed framework with the four existing methods, namely: LL-MIMO [13], LS-SVM [9], autoregressive model (AR) [14], and autoregressive moving average
(ARMA) [15]. 611 women’s ‘IUP’ tracings, together with their
demographic and obstetrical information, are employed to form
the HI. We randomly select 11 patients’ records for testing.
The selected tracings, either for training or testing, contain a
sequence of recognizable peaks. The metrics used to evaluate
the performance of the algorithms are root-mean-squared error
(RMSE) and FIT (defined in Section IV-A). In addition, a criterion is proposed in Section IV-A to evaluate the prediction accuracy of the starting points. The experiments were conducted on
an Intel Core 2 machine with two 2.66 GHz CPUs and 3.25 GB
of RAM.

HUANG et al.: KNOWLEDGE-ASSISTED SEQUENTIAL PATTERN ANALYSIS WITH HEURISTIC PARAMETER TUNING

TABLE I
WEIGHT DISTANCE MAPPING TABLE

497

TABLE II
EXPERIMENTAL RESULTS IN TERMS OF THE RMSE

A. Framework Evaluation Criteria
We employ an error measurement, RMSE, to evaluate the
performance of the prediction models. Let X be the real time
series, and X be the predicted time series obtained at prediction
horizon n. The length of both X and X is m. RMSE is the
square root of the variance, which is defined in (10). RMSE is
closely related to the value range of the time series data:

m
2
t=1 (xt − xt )
.
(10)
RMSE =
m

TABLE III
EXPERIMENTAL RESULTS IN TERMS OF THE FIT MEASURE

A fit measure is used as one of the measurements as well to
evaluate how fit the prediction is to the real time series. Let the
mean value of X be mean(X). The fit measure is defined in
(11).


X − X2
FIT = 100 × 1 −
%
(11)
X − mean(X) · 1v 2
where 1v = 1; . . . ; 1, and the length of 1v is m. FIT reaches the
maximum value (100%) when the prediction X exactly matches
with the real time series X, i.e., the prediction error RMSE is 0.
Other then this ideal situation, FIT is always a number smaller
than 100%. A larger FIT value implies a better performance.
We also conducted comparison experiments to evaluate the
abilities of the prediction models in predicting the starting points
of the contractions. Each of the testing time series contains
more than one contraction. The prediction for each contraction
is assigned an accuracy weight based on the distance between
the predicted starting point and the true starting point of the
contraction, and then the average of the weights for all the
contractions in a testing time series is calculated as the accuracy
measure. Table I shows the weights for different distance ranges,
which are defined based on the domain knowledge and empirical
studies.
B. Experiment and Results
We subsample the intrauterine time series once every second
during the data preprocessing step. The onset of the remifentanil’s effect is approximately 30s, so the prediction should be
made approximately 30s ahead of the next contraction to accurately match the effect of analgesia. Accordingly, we set the prediction horizon to 30. In addition, we set minSupL, minSupG,
and minP S to 0.03, 0.1, and 0.01, respectively, for the sequential association rule mining process. These thresholds can be
adjusted if we get more or a different set of patient tracings in
the selected HT.

The comparison results are shown in Tables II and III in terms
of RMSE and FIT, respectively. As we can see from the results,
the proposed approach achieves the lowest prediction error in
terms of RMSE. It also achieves the highest FIT measure. The
experimental results show that the proposed framework is superior to the compared four methods; on average, 64.2%, 15.9%,
106.2%, and 51.3% better in terms of RMSE than LL-MIMO,
LS-SVM, AR, and ARMA, respectively. The intrauterine pressure time series are rather dynamic and complex, thus we do not
expect the prediction error to be zero. When the prediction significantly deviates from the true value, it is possible that the FIT
measure is a negative number according to its definition in (11).
As shown in Table III, the FIT measures of the prediction results
of AR and ARMA are negative numbers for some patients.
Not every model that works for short-term time series prediction would work well for long-term prediction. The long-term
time series prediction is a much more challenging task due
to the ever-changing labor contraction pattern. LL-MIMO is a
simple and low computational cost algorithm. It predicts the future values by calculating the average of the training instances.
LL-MIMO does not train a model to describe the inherent relationship between inputs and outputs, and its prediction ability
is very limited as analyzed previously.
The LS-SVM method gives fair prediction results, but it is
computationally expensive due to using a large training dataset
and complex computing. On average, it takes 20.4s to perform
a single 30s ahead prediction using LS-SVM, while it only
takes 1.0s for the proposed framework, which is about 19 times

498

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 2, MARCH 2014

We include some plots of the predicted intrauterine pressure
time series together with the original tracings in Fig. 4 and
Fig. 5 to demonstrate the prediction performance of the complete
proposed framework. The accuracy for each tracing is included
in the title of the plot. Due to the space limit, we are not able
to show the results for all the testing cases. It can be observed
that the prediction is able to anticipate and preserve the trend
of the intrauterine pressure. High accuracies demonstrate that
the proposed framework is capable of predicting the start of the
upcoming contractions consistently.

100
90

Intrauterine Pressure (mmHg)

80
70
60
50
40
30
20

0

V. CONCLUSION

predicted
real value

10
0

100

200

300

400
500
Time (s)

600

700

800

900

Prediction results for patient 1 (accuracy = 0.92).

Fig. 4.

100
predicted
real value

90

Intrauterine Pressure (mmHg)

80
70

Labor contraction prediction is a challenging task yet to
be further explored. In this paper, we introduce a knowledgeassisted sequential pattern analysis with a heuristic parameter
tuning framework to tackle this problem. The framework reveals interesting sequential patterns in the intrauterine pressure
sequences, which we employ to assist the contraction prediction by selecting the patients to train the prediction model via
demographic and obstetrical information analysis. The parameters tuning process guarantees that the proposed framework is
able to reach its best performance. The promising experimental
results validate the effectiveness and efficiency of the modeling
for labor contraction prediction.

60

REFERENCES

50
40
30
20
10
0

Fig. 5.

0

200

400

600
Time (s)

800

1000

1200

Prediction results for patient 2 (accuracy = 0.91).

faster than LS-SVM. Therefore, LS-SVM is not applicable for
real-time prediction, even though it gives better prediction than
LL-MIMO.
The autoregressive model is a linear prediction method that
attempts to predict the next value based on the previous observations. Because of its linear nature, it is not able to achieve
good prediction precision if the time series contains nonlinear
components. In the case of long-term time series prediction, the
mapping function is usually nonlinear. Therefore, the autoregressive model is not preferable. The prediction errors of AR
are usually the highest among the compared algorithms, and
the FIT measures are negative for most of patients. Compared
to AR, ARMA includes a moving average part, which incorporates the prediction error to build the prediction model. This
makes ARMA more capable and faster in following a time series
trend. It can be also observed from Tables II and III that ARMA
always outperforms AR.

[1] S. Evron, M. Glezerman, O. Sadan, M. Boaz, and T. Ezri, “Remifentanil:
A novel systemic analgesic for labor pain,” Anesth. Analg., vol. 100, no. 1,
pp. 233–238, Jan. 2005.
[2] P. Volmanen, E. I. Akural, T. Raudaskoski, and S. Alahuhta, “Remifentanil
in obstetric analgesia: A dose-finding study,” Anesth. Analg., vol. 94, no. 4,
pp. 913–917, Apr. 2002.
[3] D. Hill, “The use of remifentanil in obstetrics,” Anesthesiol. Clin., vol. 26,
no. 1, pp. 169–182, Mar. 2008.
[4] J. M. Marshall, “Regulation of activity in uterine smooth muscle,” Physiol.
Rev. Suppl., vol. 42, pp. 213–227, 1962.
[5] Z. Huang and M.-L. Shyu, “k-NN based LS-SVM framework for longterm time series prediction,” in Proc. IEEE Int. Conf. Inf. Reuse Integr.,
2010, pp. 69–74.
[6] Z. Huang and M.-L. Shyu, “Long-term time series prediction using kNN based LS-SVM framework with multi-value integration,” in Recent
Trends in Information Reuse and Integration, T. Ozyer, K. Kianmehr, and
M. Tan, Eds. Vienna, Austria: Springer-Verlag, 2012, pp. 191–209.
[7] Z. Huang, M.-L. Shyu, J. Tien, M. M. Vigoda, and D. Birnbach, “Prediction of uterine contractions using knowledge-assisted sequential pattern
analysis,” IEEE Trans. Biomed. Eng., vol. 60, no. 5, pp. 1290–1297, May
2013.
[8] Z. Huang, M.-L. Shyu, J. Tien, D. Birnbach, and M. Vigoda, “Labor contraction prediction via demographic and obstetrical information analysis,”
in Proc. IEEE Int. Conf. Bioinformat. Biomed., Oct. 2012, pp. 300–305.
[9] J. A. K. Suykens, T. V. Gestel, J. D. Brabanter, B. D. Moor, and
J. Vandewalle, Least Squares Support Vector Machines. Singapore:
World Scientific, 2002.
[10] G. Rubio, H. Pomares, I. Rojas, and L. J. Herrera, “A heuristic method for
parameter selection in LS-SVM: Application to time series prediction,”
Int. J. Forecast., vol. 27, no. 3, pp. 725–739, 2011.
[11] A. Sorjamaa, J. Hao, N. Reyhani, Y. Ji, and A. Lendasse, “Methodology for
long-term prediction of time series,” Neurocomputing, vol. 70, no. 16–18,
pp. 2861–2869, 2007.
[12] A. Lendasse, Y. Ji, N. Reyhani, and M. Verleysen, “LS-SVM hyperparameter selection with a nonparametric noise estimator,” in Proc. Int. Conf.
Artif. Neural Netw., 2005, pp. 625–630.
[13] G. Bontempi, “Long term time series prediction with multi-input multioutput local learning,” in Proc. 2nd Eur. Symp. Time Series Predict., 2008,
pp. 145–154.

HUANG et al.: KNOWLEDGE-ASSISTED SEQUENTIAL PATTERN ANALYSIS WITH HEURISTIC PARAMETER TUNING

[14] S. Soltani, D. Boichu, P. Simard, and S. Canu, “The long-term memory
prediction by multiscale decomposition,” Signal Process., vol. 80, no. 10,
pp. 2195–2205, 2000.
[15] G. Zhang, “Time series forecasting using a hybrid ARIMA and neural
network model,” Neurocomputing, vol. 50, pp. 159–175, 2003.

Zifang Huang received the Bachelor’s and Master’s
degrees from Beihang University, Beijing, China,
in 2008 and 2005, respectively. She received the
Ph.D. degree from the Department of Electrical and
Computer Engineering, University of Miami, Coral
Gables, FL, USA, in May 2012.
She is a Senior Risk Analyst at Western Union
Digital, San Francisco, CA, USA. Her research interests include data mining and multimedia databases.
Dr. Huang served as a program committee member for multiple IEEE International Conferences.

Mei-Ling Shyu (M’95–SM’03) received the Ph.D.
degree from the School of Electrical and Computer
Engineering and three Master degrees, all from Purdue University, West Lafayette, IN, USA.
She has been a Full Professor at the Department
of Electrical and Computer Engineering, University
of Miami (UM), Coral Gables, FL, USA, since June
2013. Prior to that, she was an Associate/Assistant
Professor in ECE at UM from January 2000. Her
research interests include multimedia data mining,
management and retrieval, and security.
Dr. Shyu received the 2012 IEEE Computer Society Technical Achievement
Award and the ACM 2012 Distinguished Scientists Award. She received the
Best Paper Award in 2012, the Best Published Journal Article in IJMDEM
for 2010 Award, the Best Student Paper Award with her student in 2009. She
serves/served as an Associate Editor for several journals including IEEE TRANSACTIONS ON HUMAN–MACHINE SYSTEMS, and on the editorial board of many
other journals. She is a Fellow of the SIRI.

James M. Tien received the S.M., E.E. and Ph.D.
degrees from the Massachusetts Institute of Technology (MIT), Massachusetts, MA, USA and the B.E.E.
degree from Rensselaer Polytechnic Institute (RPI),
Troy, NY, USA.
He joined the University of Miami as a Distinguished Professor and Dean of its College of Engineering in 2007. He formerly served as the Yamada
Corporation Professor at RPI. He joined the Department of Electrical, Computer and Systems Engineering at RPI in 1977, became Acting Chair of the department, joined a unique interdisciplinary Department of Decision Sciences
and Engineering Systems as its founding Chair, and twice served as the Acting
Dean of Engineering. He has also held leadership positions at Bell Telephone
Laboratories, at the Rand Corporation, and at Structured Decisions Corporation
(which he cofounded in 1974). His research interests include the development
and application of computer and systems analysis techniques to information and
decision systems.
Dr. Tien has published extensively, been invited to present dozens of plenary lectures, and been honored with both teaching and research awards, including being elected a member of the prestigious U.S. National Academy of
Engineering.

499

Michael M. Vigoda received the M.D. degree from
the School of Medicine and Public Health, University
of Wisconsin-Madison, USA, in 1985, and the M.B.A
degree from Kennesaw State University, USA, in
2002.
He is the Chief Medical Information Officer of
Bon Secours Health System. He is a Voluntary Professor in the Departments of Anesthesiology, Ophthalmology, and Health Informatics at the University
of Miami, Miami, FL, USA.

David J. Birnbach received the Master’s degree in
public health from Johns Hopkins Bloomberg School
of Public Health, Baltimore, MD, USA, and his medical training at the Royal College of Surgeons and
Harvard University.
He is currently a Miller Professor of Anesthesiology and Professor of Obstetrics and Gynecology
and Public Health Sciences at the University of Miami Miller School of Medicine, Miami, FL, USA
and the Director of the University of Miami–Jackson
Memorial Hospital Center for Patient Safety. He completed his anesthesiology residency and fellowship training at the Brigham and
Women’s Hospital of Harvard University. Prior to relocating to Miami in 2002,
he was a Professor at Columbia University, New York, NY, USA.
Prof. Birnbach is the editor of two textbooks and has published more than
250 articles, abstracts, and textbook chapters. He has lectured throughout the
world, has received several honorary fellowships, and has been a consultant to
the NIH and FDA. He currently sits on several editorial boards and is the past
President of the Society for Obstetric Anesthesia and Perinatology.

