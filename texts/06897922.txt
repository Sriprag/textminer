1036

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

Multiple-Time-Series Clinical Data Processing
for Classification With Merging Algorithm
and Statistical Measures
Yi-Ju Tseng, Xiao-Ou Ping, Ja-Der Liang, Pei-Ming Yang, Guan-Tarn Huang, and Feipei Lai, Senior Member, IEEE

Abstract—A description of patient conditions should consist of
the changes in and combination of clinical measures. Traditional
data-processing method and classification algorithms might cause
clinical information to disappear and reduce prediction performance. To improve the accuracy of clinical-outcome prediction
by using multiple measurements, a new multiple-time-series dataprocessing algorithm with period merging is proposed. Clinical
data from 83 hepatocellular carcinoma (HCC) patients were used
in this research. Their clinical reports from a defined period were
merged using the proposed merging algorithm, and statistical measures were also calculated. After data processing, multiple measurements support vector machine (MMSVM) with radial basis
function (RBF) kernels was used as a classification method to
predict HCC recurrence. A multiple measurements random forest regression (MMRF) was also used as an additional evaluation/classification method. To evaluate the data-merging algorithm,
the performance of prediction using processed multiple measurements was compared to prediction using single measurements. The
results of recurrence prediction by MMSVM with RBF using multiple measurements and a period of 120 days (accuracy 0.771, balanced accuracy 0.603) were optimal, and their superiority to the
results obtained using single measurements was statistically significant (accuracy 0.626, balanced accuracy 0.459, P < 0.01). In
the cases of MMRF, the prediction results obtained after applying the proposed merging algorithm were also better than singlemeasurement results (P < 0.05). The results show that the performance of HCC-recurrence prediction was significantly improved
when the proposed data-processing algorithm was used, and that
multiple measurements could be of greater value than single
Index Terms—Data mining, data processing, multiple measurements, support vector machine (SVM), time-series analysis.

Manuscript received December 30, 2013; revised September 2, 2014 and July
24, 2014; accepted September 5, 2014. Date of publication September 12, 2014;
date of current version May 7, 2015. The work of F. Lai was supported by the
Ministry of Science and Technology, Taiwan, under Grant 101-2221-E-002203-MY3. The work of Y. J. Tseng was supported by the Ministry of Science
and Technology, Taiwan, under Grant 103-2917-I-564-063.
Y.-J. Tseng is with the Children’s Hospital Informatics Program, HarvardMIT Division of Health Sciences and Technology, Children’s Hospital Boston,
Boston, MA 02115 USA (e-mail: YiJu.Tseng@childrens.harvard.edu).
X.-O. Ping is with the Department of Computer Science and Information
Engineering, National Taiwan University, Taipei 10617, Taiwan (e-mail: pingxiaoou@gmail.com).
J.-D. Liang, P.-M. Yang, and G.-T. Huang are with the Department of Internal Medicine, College of Medicine, National Taiwan University Hospital,
Taipei 10617, Taiwan (e-mail: jdliang@ntuh.gov.tw; pmyang@ntuh.gov.tw;
gthuang@ntu.edu.tw).
F. Lai is with the Department of Computer Science and Information Engineering, Department of Electrical Engineering, Graduate Institute of Biomedical Electronics and Bioinformatics, National Taiwan University, Taipei 10617,
Taiwan (e-mail: flai@ntu.edu.tw).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2357719

I. INTRODUCTION
HE varieties of data characteristics are one of the major
problems of data processing [1]. There are two types of
data: time-series data and cross-sectional data. Time-series data
are a sequence of observations of a particular feature, which
are ordered in time, while cross-section data are collected by
observing many features at the same time. In the first type, the
features change over time, and these changes contain important
information. For example, the time sequence of blood glucose
levels and blood pressure are considered as important health
indicators [2], [3]. In the second type, multiple clinical data that
are generated at the same time should be considered together to
obtain a complete picture of a patient’s condition in a specific
time period. For instance, in a routine health examination, the
health status of individuals is described by the results of a series
of laboratory tests and physical examinations, such as height,
weight, white blood cell count, and red blood cell count [4],
[5]. Designing a data-processing method that can handle crosssectional and time-series data at the same time would therefore
seem to be essential for clinical data analysis.
Using data-processing techniques before data analysis can
substantially improve the quality of the data, reduce the time
required for the analysis, and improve the quality of the analysis [6]. There are a number of data-preprocessing techniques,
including data cleaning, data integration, data transformation,
and data reduction. Data cleaning is the process of detecting
inaccurate records [7]–[9]. Data integration combines data from
multiple sources [10]. Data transformation refers to the application of a deterministic mathematical function to each point
in the data, which may improve the accuracy and efficiency of
data mining [11]. Data reduction aggregates or eliminates redundant features of the data, thus reducing it to a more manageable size [12]. Transforming data from a low-level quantitative
form to a high-level qualitative description is known as temporal abstraction (TA) [13]. The process of TA takes either raw
or preprocessed data as input and produces context-sensitive
and qualitative interval-based representations. In the case of
patients’ health data, qualitative description is closer to the language of clinicians [14]. Temporal classification of time-related
clinical data has certain properties that distinguish it from other
classification methods [15], [16], and using the characteristics
of temporal data could, in theory, improve the performance of
temporal classification. However, not all the relevant data or observations are recorded at the same time. For example, different
laboratory tests might have different observation frequencies,
because the orders for them might be originated by different

T

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

TSENG et al.: MULTIPLE-TIME-SERIES CLINICAL DATA PROCESSING FOR CLASSIFICATION WITH MERGING ALGORITHM

1037

departments or physicians, and might be further affected by
the patient’s status. Data with an unequal collecting frequency
should be processed before analysis.
For combining features of multiple types observed at different times, a merging algorithm for time-series and multiplevariables data is proposed. The basic idea is to merge all features
that occur within a defined time period; if a particular feature has
more than one value, only one of these values will be chosen
to represent it. This merging algorithm for multiple measurements is a method of data reduction; that is, information in the
original data could be removed by the merging algorithm. For
preserving the information, statistical measures of the original
data in a specific time period are taken, and these can stand in
for the tendency and the distribution of the original data. After
multiple-measurements data processing, the data that include
selected features are integrated from their various databases.
In this study, the research targets were patients who had hepatocellular carcinoma (HCC) and were being treated by radiofrequency ablation (RFA). Their clinical reports that were collected
before treatment were used for evaluating the data-processing
method. After data processing, the single measurement and
multiple measurements data were classified into two classes—
recurrence and nonrecurrence—to predict patients’ HCC outcome after RFA therapy. A comparison of the classification results obtained with single measurements against those obtained
with multiple measurements could represent the performance of
the data-processing method, and demonstrate that the method
could improve the effectiveness of prediction of RFA-treated
HCC recurrence.
II. LITERATURE REVIEW
Time-series data can be found everywhere; TA, temporal classification and sequential pattern mining methods are proposed
[17]–[29] and widely used in many fields, including medicine
[17]–[26], biology [27], agriculture [28], and environmental research [26], [29]. A number of studies have noted the importance
of time-series data in the medical domain, and proposed timeseries data-processing approaches and classification methods.
These studies can be grouped by data sources, including signal
data (such as electroencephalography) [17]–[19], [26], single
variable [22], and multiple variables [20]–[23], [25]. The bestknown type of time-series data is signal data. Sitaram et al. used
support vector machine (SVM) and hidden Markov model to recognize the patterns in multichannel near-infrared spectroscopy
signals [19]. Yin and Zhang identified temporal variations in
mental workload by using SVM-based clustering and classification algorithms [17]. For nonsignal clinical data, Schmidt
and Gierl proposed a predictive model combing TA and casebased reasoning [22], and they processed multiple variables by
abstracting them into states (i.e., high, normal, and low) [24].
Ghalwash and Obradovic proposed a method called multivariate shapelets detection, which extracts patterns from multiple
dimensions of the time series, and evaluated it using a geneexpression dataset. The results they achieved were superior to
those they had achieved using a traditional shapelets detection
method and a single dimension [20].

Fig. 1. Flowchart of multiple measurements classification and performance
evaluation of multiple-time-series data-processing algorithm.

In contrast to previous research, we propose a data-merging
algorithm for multiple variables with different sampling rates
and data types, to preserve both cross-sectional and time-series
clinical information for predictive model establishment.
III. METHODS
The multiple-time-series data from different databases were
extracted and cleaned. Then, the time-related data from a defined period were merged using the proposed data-merging
algorithm, and statistical measures were also calculated. Finally, the merged multiple-measurements data with or without
statistical measures were generalized for classification. After
data processing, multiple measurements SVM (MMSVM) and
multiple measurements random forest (MMRF) were used as
classification methods, and the model of classification was optimized through grid search and cross validation. The performance of classification using processed multiple measurements
was compared against single measurement to evaluate the dataprocessing method we propose. Fig. 1 presents a flowchart of
the evaluation method.

1038

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

TABLE I
PSEUDOCODE FOR MERGING MULTIPLE FEATURES ALGORITHM AND ADDING STATISTICAL MEASURES BASED ON TIME PERIODS
BEGIN
Read D m = m days period (m could be 7, 14, 21, 28, 60, 90, or 120)
T e v e n t = the time of specific event //therapy
R B = all records before T e v e n t , sorted by record date in descending order
F B = all features in R B
Initialize merged records array M m based on m days period and F B
FOR each record R B k in R B , k = 1, . . . , N
T k = the time of R B k recorded
i = (T e v e n t − T k )/D m //ith period in merged records
M m i = the ith merged record based on m days period
//Get the value of each feature F q which is closet to T e v e n t in period i
FOR each feature F q in R B k (q = 1, . . . , O )
Set the value W q of F q in M m i as the most recent value of F q from all the R B k in R B and ith period
ENDFOR
ENDFOR
If statistical measures mode
//statistical measures were defined in Supplementary Data 2
FOR each period i in M m
FOR each time-related feature F t in F B
//time-related laboratory data in Supplementary Data 1
F t M a x i = m aximum of all the F t in R B within period i
F t M i n i = m inimum of all the F t in R B within period i
F t A v g i = average of all the F t in R B within period i
F t S D i = standard deviation of all the F t in R B within period i
F t C o r i = Pearson’s correlation coefficient of all the F t in R B within period i
F t S l p i = slop e of trend line of all the F t in R B within period i
Add F t M a x i , F t M i n i , F t A v g i , F t S D i , F t C o r i , F t S l p i as addition features into the ith merged record M m i
ENDFOR
ENDFOR
OUTPUT M m
END

A. Data Sources
Our research targets were patients who received RFA as their
first therapy for HCC in a 2200-bed teaching hospital in Taiwan
from 2007 to 2009. The clinical data from 180 days before the
RFA therapy to the therapy date were collected as experiment
data. To ensure adequate follow-up, we included only individuals who had continuously returned for one year or more. A
total of 16 clinical features, taken from the laboratory information system (LIS) database, radiology information system (RIS)
database, and hospital information system (HIS) database, were
selected for model establishment by specialists. The data types
of features are shown in Supplementary Data 1. The ten laboratory tests selected were alanine aminotransferase (ALT), aspartate transaminase (AST), α-Fetoprotein, total bilirubin, platelet,
albumin, creatinine, prothrombin time international normalized
ratio, hepatitis C virus and hepatitis B virus (HBV). The six other
features were tumor size and tumor number, extracted from radiology reports or ultrasound reports in RIS; stage of BarcelonaClinic Liver Cancer (BCLC) classification and cirrhosis status,
extracted from narrative clinical reports in HIS [30]; and age and
gender, collected from the demographic database within HIS.
The classes of the data were as follows: 1) recurrence; and
2) no evidence of recurrence of HCC within one year after
receiving RFA therapy. The class of each patient was confirmed
by radiology reports or records of follow-up therapy.

B. Algorithm for Merging Multiple Features Based on Defined
Time Periods
The algorithm for merging multiple features based on time
periods is described in pseudocode in Table I, and its flowchart
is presented in Fig. 2. We used time periods of 7, 14, 21, 60, 90,
and 120 days. If the time interval between the earliest record
and the target event is 180 days, the total number of periods is
3 with 60-day periods or 2 with 90-day periods. After defining the length of period, there might be more than one value
of a feature in each period. For example, there might be more
than one ALT test performed in 60 days for following up a
patient’s status. The central idea of this merging algorithm is
to choose only one value to stand for a feature in one period.
Because the time of the target event, such as therapy for HCC,
was set as the key time with regard to data processing, the
value that is closer to event time could be more significant than
others. Therefore, the most recent value is selected to represent a feature in a period, and therefore some valuable information in the original data might be omitted by the merging
algorithm.
In the single-measurement phase of the experiment, features
were collected only once. If more than one relevant laboratory
report was available, the most recent one was selected. The
performance of prediction with single measurement was the
baseline of this research.

TSENG et al.: MULTIPLE-TIME-SERIES CLINICAL DATA PROCESSING FOR CLASSIFICATION WITH MERGING ALGORITHM

1039

D. Feature Selection
To remove redundant or irrelevant features from the dataset,
we used a feature-selection strategy based on random forest:
an ensemble classifier proposed by Breiman [32], comprising
many classification trees, the “bagging” idea, and random selection of features. The frequency of a feature’s appearance in
the classification trees represents the importance of the feature.
The library “randomForest” in R software was used for implementing the random forest feature-selection method [33], [34].
All the features were ranked according to the weight assigned
to them by random forest. To allow us to compare the performance of prediction by adding statistical measures with others,
we set the maximum number of features as 16, equal to the total
features in the dataset (not including statistical measures). The
top-ranked 16 features, i.e., with the highest weights, were selected as the input features. Combinations of these features were
then created by sequentially adding features, and were input into
classification algorithms to generate the prediction model. This
feature-selection approach is described in pseudocode in Table II.
E. Prediction Model Establishment

Fig. 2. Flowchart of multiple-time-series data-processing for classification
with multiple measurements merging algorithm and statistical measures. LIS:
laboratory information system, RIS: radiology information system, HIS: hospital information systems, AST: aspartate aminotransferase, ALT: alanine
transaminase, BCLC: Barcelona-Clinic Liver Cancer classification, SD: standard deviation.

C. Calculation of Statistical Measures
Statistical measures were calculated for describing the data
distribution in each period. There was a possibility that information in the original data, such as the tendency and the distribution
of the features, might disappear after data merging. To preserve
this information, we adopted the definitions of statistical measures that are shown in Supplementary Data 2. The maximum
and minimum are used for illustrating the extremes of the data.
Average is a method for deriving the central tendency of a sample space, and standard deviation is a widely used measurement
of variability or diversity. Pearson’s correlation coefficient is a
statistical technique that shows whether and how strongly pairs
of features are related, and expresses this relationship in values ranging between −1 and 1. The closer the absolute value
of the Pearson’s coefficient is to 1, the stronger the correlation
between the features is. A trend line represents the long-term
movement in time-series data, and it tells whether a particular
measure has increased or decreased in over the period of time
[31]. These statistical measures were used for expressing the
data distribution in a specific period, and the information lost
during data merging might be partly retained in them.

We used four data mining algorithms, including SVM and
random forest regression (RF) for single-measurement data and
MMSVM and MMRF for multiple-measurements data. The
SVM is a data-mining method that constructs a prediction model
for a binary class. It uses nonlinear mapping to transform the
data into a higher dimension. With an appropriate nonlinear
mapping to a sufficiently high dimension, data from two classes
are separated by a hyperplane [35]. The LIBSVM library [36]
was used for implementing the SVM classification method. The
most popular kernel function, RBF, was used for SVM model
establishment. For multiple measurements, the classification results were decided by a voting mechanism: where one or more
instances belonged to the same group (patient), the class with the
most votes in these instances was the final result of classification. The MMSVM is a tool we developed to enable LIBSVM to
conduct cross validation and prediction with multiple measurements’ results from the voting mechanism; the pseudocode for
this appears in Table III. In addition to SVM, an RF regression
was selected as a different algorithm of model establishment,
to increase the variety of evaluation. An averaging mechanism,
described in Table III, was also applied to MMRF for multiple
measurements data. Similar with voting mechanism, the averaging mechanism is where one or more instances belonged to
the same group (patient), the average of regression results of
these instances was the final result of regression.
F. Evaluation Methods
To evaluate the impact of using multiple measurements, we
compared the performance of HCC-recurrence prediction with
multiple measurements against its performance with single measurement. Using multiple measurements with statistical measures was evaluated in the same way. We conducted the experiments for four data mining algorithms using two-loop cross validation, where the inner loop optimized features and parameters

1040

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

TABLE II
PSEUDOCODE FOR MULTIPLE MEASUREMENTS PREDICTIVE MODEL ESTABLISHMENT, OPTIMIZATION AND EVALUATION, INCLUDING GRID SEARCH OF PREDICTIVE
MODEL PARAMETERS AND FEATURE SELECTION
BEGIN
M m = the merged records based on m days period //described in Table I
D m = splitting M m into 5 equal parts
Initialize P E R f i n a l m to zero //final performance of predictive model of the dataset M m
//the outer 5-fold cross validation for performance evaluation
FOR each ith part of merged data D m i in D m (i = 1, . . . , 5)
V m i = test dataset, D m i
T m i = training dataset, all the records in D m expect D m i
W F = the features’ weight from Random Forest algorithm, calculated from the single measurement, sorted in descending order
Initialize L O as the optimal feature list
Initialize P O as the optimal parameter set
Initialize P E R O to zero //the optimal performance indicator
Initialize P E R test i to zero
FOR each feature F k in W F (k = 1, . . . , 16)
//feature combination by sequentially adding features into L k
L k = feature list including F 1 , . . . , F k
T m i L k = training dataset T m i contains select features in L k
//only use the features in L k
If classification algorithm is SVM
FOR all gamma G from j power of 2 (j = −15, −13, −11, . . . , 1, 3)
//parameter optimization for SVM
FOR all cost C from n power of 2 (n = −5, −3, −1, . . . , 13, 15)
//parameter optimization for SVM
//inner 5-fold cross validation for model optimization including feature selection and parameter grid search
P E R t e m p = average of performance indicators of 5-fold cross validation using T m i L k and the parameters of SVM are G and C
If P E R O < P E R t e m p
P E RO = P E Rtem p
LO = Lk
P O = C and G
ENDFOR
ENDFOR
Else
//inner 5-fold cross validation for model optimization including feature selection
P E R t e m p = average of performance indicators of 5-fold cross validation using T m i L k
If P E R O < P E R t e m p
P E RO = P E Rtem p
LO = Lk
ENDFOR
PM O = predictive model built by using training dataset T m i contains select features in L O , and the parameters of SVM are P O (if applicable)
P E R test i = prediction performance of using P M O to predict V m i
//model evaluation, details were described in Section III-E
ENDFOR
P E R f i n a l m = the average of all P E R test i (i = 1, . . . , 5)
OUTPUT P E R f i n a l m
END

(cost and gamma for SVM and MMSVM) and the outer loop
evaluated prediction models. In the inner loop, the parameters
and features were optimized by using fivefold cross validation
with training data. The indicators that were used to select the
optimal setting of model establishment were balanced accuracy
(BAC) for MMSVM due to the unbalanced nature of the data and
area under the receiver operator characteristic curve (AUC) for
MMRF. We established the prediction model using the optimal
parameters. In the outer fivefold cross validation, the prediction
model from the inner loop was applied to test data, and the
average of the performance was set as the final result of the experiments. The performance indicators of evaluation, including
accuracy and BAC for MMSVM and AUC for MMRF, were
used to describe the performance of the HCC-recurrence prediction models. The pseudocode for model evaluation is given
in Table II.

IV. RESULTS
There were a total of 83 patients in the experiment dataset,
of whom 18 were recurrent patients, and 65 were nonrecurrent
patients. Among these patients, the number of reports from
time-related clinical laboratory tests dating from the 180-day
period prior to treatment was 1563. The largest number of these
pretreatment laboratory test reports (255) came from ALT. The
numbers and averages of the sampled laboratory test reports are
shown in Supplementary Data 3.
The classification performance for HCC-recurrence prediction using a single measurement, multiple measurements, and
multiple measurements with statistical measures was analyzed.
The optimal model established by MMSVM with RBF was using multiple measurements and a period of 120 days (accuracy
0.771, BAC 0.603) (see Table IV). The performance indicators
of this model were higher than those established by SVM with

TSENG et al.: MULTIPLE-TIME-SERIES CLINICAL DATA PROCESSING FOR CLASSIFICATION WITH MERGING ALGORITHM

TABLE III
PSEUDOCODE FOR THE VOTING MECHANISM OF CLASSIFICATION MODELS AND
THE AVERAGING MECHANISM OF REGRESSION MODEL
BEGIN
S m = the test dataset selected from the merged records based on m days period
//described in Table II
P V m = the patient list of test dataset S m
R m = the training dataset selected from the merged records based on m days period
//described in Table II
P M m = the predictive model established based on selected features in R m , and
imported parameters //described in Table II
FOR each patient P i in P V m
Initialize voting result of P i , V R i to zero
If the type of predictive model is classification
FOR each merged record P S m i of P i in period i in S m
R m i = prediction result of P S m i by using P M m
//recurrence = 1, non − recurrence = −1
VR i = Rm i + VR i
ENDFOR
If V R i > = 0
Predict P i as a positive case //recurrence
Else
Predict P i as a negative case //non-recurrence
Else If the type of predictive model is regression
V R i = the average of prediction result of all merged record of P i in period i in
S m by using P M m
Predict P i by V R i //regression result
ENDFOR
OUTPUT performance of P M m based on the prediction results
END

RBF using single measurement (accuracy 0.626, BAC 0.459,
both P < 0.01). After adding statistical measures to the multiple
measurements, the optimal model was established by multiple
measurements with statistical measures and a period of 120 days
(accuracy 0.721, BAC 0.572). Although its performance indicators were also significantly higher than those achieved by
single measurement (P < 0.05), the prediction performances
we achieved were lower than without them. Different from
MMSVM, the performance of MMRF was reported by AUC
(see Table V). The optimal model established by MMRF was
using multiple measurements with statistic measures divided
by 120 days periods, and the AUC of this model was higher
than using single measurement (P < 0.05). The details of the
performance are shown in Supplementary Data 4 and 5.
V. DISCUSSION
The multiple-time-series data-processing algorithm with period merging is an effective method for data processing before
classification. The results of HCC-recurrence prediction based
on: 1) MMSVM with RBF kernel and multiple measurements
and a period of 120 days; and 2) MMRF with multiple measurements and statistical measures and a period of 120 days
were both significantly better than with single measurement.
Using the multiple measurements with statistical measures and
MMSVM with RBF also yielded better classification results
than using the single measurement, but the averages of accuracy and BAC were lower than those of multiple measurements
without statistical measures. In other words, after data processing, the classification accuracy and BAC from MMSVM with
RBF kernel had increased 23.16% and 31.37%, respectively,
as compared to using a single measurement. Therefore, it is

1041

suggested that the proposed merging algorithm could improve
the prediction performance achievable using clinical data more
generally.
In the optimal MMSVM model derived from outer fivefold
cross validation, the most common selected features were ALT
and AST, which were selected in fourfolds. The second most
common features were platelet count and HBV, which were each
used in twofolds. ALT and AST are frequently used for liver
function testing in routine health examination. Furthermore, patients with liver disease usually have a decreased platelet count
(thrombocytopenia) because platelet production is regulated by
thrombopoietin, a hormone produced in the kidneys and liver
[37]. The presence of the hepatitis B e antigen is associated
with an increased risk of HCC [38], [39], and HBV viral load
is associated with HCC recurrence [40]–[42]. These four clinical features are all highly related to liver function and HCC,
and it is reasonable to assume that they might be useful predictors of HCC recurrence. In the optimal MMRF model, the
most common selected feature was AST, which were selected
in twofolds.
The optimal data-processing period was 120 days in the models built by MMSVM and MMRF, and it fitted the data characteristics described in Supplementary Data 3. Because the average number of reports per patient in the 180 days before
RFA treatment ranged from 1.72 to 3.07, data-processing periods that were shorter than 60 days might increase the rates of
missing values. The results of this paper indicate that merging
multiple-time-series data in a defined time period could transform the related time-series data into useful information. Analyzing multiple-time-series data separately might neglect the
overall situation in a specific time period, and thereby decrease
the reliability of analysis results.
Our data-processing algorithm for multiple measurements
provides a general method for generating valuable data for classification. It can be used not only with clinical data, but with
any kind of data that tallies with the targets of the multipletime-series data-processing algorithm, such as descriptions of
the condition of water and air, meteorological data, and financial data. Through this algorithm, integrated, time-dependent,
and useful data can be created.
Although our results suggest that the multiple-measurements
data processing algorithm was helpful in HCC-recurrence prediction, it was found to have several limitations. First, even
though the optimal accuracy and BAC of classification were obtained from the model using 120 days as a merging period, there
was no evidence that a 120-day period would be as useful when
dealing with other data sets. Also, the defined periods could not
be set automatically based on the characteristics of a dataset, and
it might therefore be possible that we missed the optimal time
period because it was not one of the six periods we had chosen to
examine; in other words, if a time period of 83 days or 114 days
is in fact better than a period of 120 days, our experimental
technique would not reveal this. Third, although the sensitivity
and positive predictive value of HCC-recurrence prediction using single measurement were increased by using our proposed
algorithm, the sensitivity and PPV were still low. The unbalanced data and small research population might be the reasons

1042

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

TABLE IV
PERFORMANCE OF HCC RECURRENCE PREDICTION BASED ON SINGLE
MEASUREMENT, MULTIPLE MEASUREMENTS, OR MULTIPLE MEASUREMENTS
WITH STATISTICAL MEASURES
Classification
algorithm

Measurement type

Periods (days)

ACCa

BACb

(MM)SVMc with
RBFd kernel

Single
measurement
Multiple
measurements
Multiple
measurements with
statistical measures

–

0.626

0.459

120

0.771

0.603

120

0.721

0.572

a

b
Accuracy = (TP + TN)/(TP + TN + FP + FN),
Balanced accuracy =
(Sensitivity + Specificity)/2,
Sensitivity = TP/(TP + FN),
Specificity =
TN/(TN + FP). c MMSVM: multiple measurements support vector machine, d RBF:
radial basis function. True positive (TP): a recurrent patient correctly identified as a
recurrent patient. False positive (FP): a non-recurrent patient wrongly identified as
a recurrent patient. True negative (TN): a non-recurrent patient correctly identified as
a non-recurrent patient. False negative (FN): a recurrent patient wrongly identified
as a nonrecurrent patient.

TABLE V
PERFORMANCE OF HCC RECURRENCE PREDICTION BY USING MMRF
REGRESSION BASED ON SINGLE MEASUREMENT, MULTIPLE MEASUREMENTS,
OR MULTIPLE MEASUREMENTS WITH STATISTICAL MEASURES
Classification algorithm

Measurement type

Periods (days)

AUCa

Multiple measurments
Random Forest

Single measurement

–

0.620

Multiple measurements
Multiple measurements
with statistical
measures

7
120

0.710
0.766

a

AUC = area under the receiver operator characteristic curve.

for this. Moreover, we analyzed the features by univariate analysis (data not shown), and only tumor size and HBV had significant results. Based on this, it can be said that HCC-recurrence
prediction using laboratory reports from before the beginning
of treatment is not easy, and could be improved through use of
the multiple-time-series data-processing algorithm.
VI. CONCLUSION
This study presents a merging algorithm for multiple-timeseries data with different sampling rates and data types, and
evaluates the effects of adding statistical measures to it. The
results show that the performance of HCC-recurrence prediction
was significantly improved through use of the algorithm, and,
as a corollary, that multiple measurements could provide more
useful information for HCC-recurrence prediction than single
measurement does.
ACKNOWLEDGMENT
The authors acknowledge the members of the research team
led by Prof. F. Lai of National Taiwan University for their contributions to this study.

REFERENCES
[1] J. Han, M. Kamber, and J. Pei, Data Mining: Concepts and Techniques,
2nd ed. San Mateo, CA, USA: Morgan Kaufmann, 2005.
[2] J. Blackburn, S. Brumby, S. Willder, and R. McKnight, “Intervening to
improve health indicators among Australian farm families,” J. Agromed.,
vol. 14, no. 3, pp. 345–356, 2009.
[3] E. Sobngwi, J.-C. Mbanya, N. C. Unwin, R. Porcher, A.-P. Kengne, L.
Fezeu, E. M. Minkoulou, C. Tournoux, J.-F. Gautier, and T. J. Aspray,
“Exposure over the life course to an urban environment and its relation
with obesity, diabetes, and hypertension in rural and urban Cameroon,”
Int. J. Epidemiol., vol. 33, no. 4, pp. 769–776, 2004.
[4] C. Scheidt-Nave, P. Kamtsiuris, A. Gößwald, H. Hölling, M. Lange,
M. A. Busch, S. Dahm, R. Dölle, U. Ellert, and J. Fuchs, “German health interview and examination survey for adults (DEGS)—
design, objectives and implementation of the first data collection wave,”
BMC Public Health, vol. 12, art. no. 730, 2012. [Online]. Available
http://www.biomedcentral.com/1471-2458/12/730
[5] S. Zhi, W. Sheng, and S. P. Levine, “National occupational health service
policies and programs for workers in small-scale industries in China,”
Amer. Ind. Hygiene Assoc., vol. 61, no. 6, pp. 842–849, 2000.
[6] J. Han and M. Kamber, Data Mining: Concepts and Techniques, 2nd ed.
San Francisco, CA, USA: Morgan Kaufmann, 2006
[7] M. A. Hernández and S. J. Stolfo, “Real-world data is dirty: Data cleansing
and the merge/purge problem,” Data Mining Knowl. Discovery, vol. 2,
no. 1, pp. 9–37, 1998.
[8] M. Lee, H. Lu, T. Ling, and Y. Ko, “Cleansing data for mining and
warehousing,” in Database and Expert Systems Applications, T. BenchCapon, G. Soda, and A. Tjoa, Eds. Berlin, Germany: Springer, 1999,
p. 807.
[9] W. Lup Low, M. Li Lee, and T. Wang Ling, “A knowledge-based approach for duplicate elimination in data cleaning,” Inf. Syst., vol. 26, no. 8,
pp. 585–606, 2001.
[10] M. Lenzerini, “Data integration: A theoretical perspective,” in Proc. 21st
ACM SIGMOD-SIGACT-SIGART Symp. Principles Database Syst., Madison, WI, USA, 2002, pp. 233–246.
[11] A. A. Hancock, E. N. Bush, D. Stanisic, J. J. Kyncl, and C. T. Lin, “Data
normalization before statistical analysis: Keeping the horse before the
cart,” Trends Pharmacol. Sci., vol. 9, no. 1, pp. 29–32, 1988.
[12] A. S. C. Ehrenberg, Data Reduction: Analysing and Interpreting Statistical
Data. New York, NY, USA: Wiley, 1975.
[13] M. Stacey and C. McGregor, “Temporal abstraction in intelligent clinical
data analysis: A survey,” Artif. Intell. Med., vol. 39, no. 1, pp. 1–24, 2007.
[14] M. Stacey, C. McGregor, and M. Tracy, “An architecture for multidimensional temporal abstraction and its application to support neonatal intensive care,” in Conf. Proc. IEEE Eng. Med. Biol. Soc., 2007,
pp. 3752–3756.
[15] M. Campos, J. Palma, and R. Marı́n, “Temporal data mining with temporal constraints artificial intelligence in medicine,” in Artificial Intelligence in Medicine, R. Bellazzi, A. Abu-Hanna, and J. Hunter, Eds. Berlin,
Germany: Springer, 2007, pp. 67–76.
[16] A. Juan Carlos, “Temporal reasoning for decision support in medicine,”
Artif. Intell. Med., vol. 33, no. 1, pp. 1–24, 2005.
[17] Z. Yin and J. Zhang, “Identification of temporal variations in mental workload using locally-linear-embedding-based EEG feature reduction and
support-vector-machine-based clustering and classification techniques,”
Comput. Methods Programs Biomed., vol. 115, no. 3, pp. 119–134,
2014.
[18] D. Liparas, S. I. Dimitriadis, N. A. Laskaris, A. Tzelepi, K. Charalambous,
and L. Angelis, “Exploiting the temporal patterning of transient VEP
signals: A statistical single-trial methodology with implications to brain–
computer interfaces (BCIs),” J. Neurosci. Methods, vol. 232, pp. 189–198,
2014.
[19] R. Sitaram, H. Zhang, C. Guan, M. Thulasidas, Y. Hoshi, A. Ishikawa,
K. Shimizu, and N. Birbaumer, “Temporal classification of multichannel
near-infrared spectroscopy signals of motor imagery for developing a
brain–computer interface,” NeuroImage, vol. 34, no. 4, pp. 1416–1427,
2007.
[20] M. F. Ghalwash and Z. Obradovic, “Early classification of multivariate temporal observations by extraction of interpretable shapelets,” BMC
Bioinformat., vol. 13, art. no. 195, 2012.
[21] I. Batal, H. Valizadegan, G. F. Cooper, and M. Hauskrecht, “A pattern mining approach for classifying multivariate temporal data,” in
Proc. IEEE Int. Conf. Bioinformat. Biomed., vol. 2011, Nov. 12, 2011,
pp. 358–365.

TSENG et al.: MULTIPLE-TIME-SERIES CLINICAL DATA PROCESSING FOR CLASSIFICATION WITH MERGING ALGORITHM

[22] R. Schmidt and L. Gierl, “A prognostic model for temporal courses that
combines temporal abstraction and case-based reasoning,” Int. J. Med.
Informat., vol. 74, nos. 2–4, pp. 307–315, 2005.
[23] R. Bellazzi, C. Larizza, P. Magni, and R. Bellazzi, “Temporal data mining
for the quality assessment of hemodialysis services,” Artif. Intell. Med.,
vol. 34, no. 1, pp. 25–39, 2005.
[24] R. Schmidt, B. Pollwein, and L. Gierl, “Medical multiparametric time
course prognoses applied to kidney function assessments,” Int. J. Med.
Informat., vol. 53, nos. 2/3, pp. 253–263, 1999.
[25] C. H. Lee, J. C. Chen, and V. S. Tseng, “A novel data mining mechanism
considering bio-signal and environmental data with applications on asthma
monitoring,” Comput. Methods Programs Biomed., vol. 101, no. 1, pp. 44–
61, Jan. 2011.
[26] V. S. Tseng and C.-H. Lee, “Effective temporal data classification by
integrating sequential pattern mining and probabilistic induction,” Expert
Syst. Appl., vol. 36, no. 5, pp. 9524–9532, 2009.
[27] T. Exarchos, M. Tsipouras, C. Papaloukas, and D. Fotiadis, “An optimized
sequential pattern matching methodology for sequence classification,”
Knowl. Inf. Syst., vol. 19, no. 2, pp. 249–264, 2009.
[28] D. Bargiel and S. Herrmann, “Multi-temporal land-cover classification of
agricultural areas in two European regions with high resolution spotlight
terraSAR-X data,” Remote Sens., vol. 3, no. 5, pp. 859–877, 2011.
[29] J. O. Sexton, D. L. Urban, M. J. Donohue, and C. Song, “Long-term
land cover dynamics by multi-temporal classification across the Landsat5 record,” Remote Sens. Environ., vol. 128, pp. 246–258, 2013.
[30] X. O. Ping, Y. J. Tseng, Y. Chung, Y. L. Wu, C. W. Hsu, P. M. Yang, G. T.
Huang, F. Lai, and J. D. Liang, “Information extraction for tracking liver
cancer patients’ statuses: From mixture of clinical narrative report types,”
Telemed. J. E Health, vol. 19, no. 9, pp. 704–710, Sep. 2013.
[31] S. Dowdy, S. Wearden, and D. Chilko, Statistics for Research, 3rd ed.
New York, NY, USA: Wiley, 2004, p. 640.
[32] L. Breiman, “Random forests,” Mach. Learning, vol. 45, no. 1, pp. 5–32,
2001.
[33] R Development Core Team, R: A Language and Environment for Statistical
Computing. Vienna, Austria: R Found. Statist. Comput., 2010.

1043

[34] A. Liaw and M. Wiener, “Classification and regression by randomforest,”
R News, vol. 2/3, pp. 18–22, 2002.
[35] C. Cortes and V. Vapnik, “Support-vector networks,” Mach. Learning,
vol. 20, no. 3, pp. 273–297, 1995.
[36] C.-C. Chang and C.-J. Lin, “LIBSVM: A library for support vector machines,” ACM Trans. Intell. Syst. Technol., vol. 2, no. 3, pp. 1–27, 2011.
[37] K. Kaushansky, “Thrombopoietin: The primary regulator of platelet production,” Blood, vol. 86, no. 2, pp. 419–431, 1995.
[38] H.-I. Yang, S.-N. Lu, Y.-F. Liaw, S.-L. You, C.-A. Sun, L.-Y. Wang, C. K.
Hsiao, P.-J. Chen, D.-S. Chen, and C.-J. Chen, “Hepatitis B e antigen and
the risk of hepatocellular carcinoma,” New Engl. J. Med., vol. 347, no. 3,
pp. 168–174, 2002.
[39] A. M. Di Bisceglie, “Hepatitis B and hepatocellular carcinoma,” Hepatology, vol. 49, no. S5, pp. S56–S60, 2009.
[40] M. Chuma, S. Hige, T. Kamiyama, T. Meguro, A. Nagasaka, K. Nakanishi,
Y. Yamamoto, M. Nakanishi, T. Kohara, T. Sho, K. Yamamoto, H. Horimoto, T. Kobayashi, H. Yokoo, M. Matsushita, S. Todo, and M. Asaka,
“The influence of hepatitis B DNA level and antiviral therapy on recurrence
after initial curative treatment in patients with hepatocellular carcinoma,”
J. Gastroenterol., vol. 44, no. 9, pp. 991–999, 2009.
[41] J.-C. Wu, Y.-H. Huang, G.-Y. Chau, C.-W. Su, C.-R. Lai, P.-C. Lee, T.-I.
Huo, I. J. Sheen, S.-D. Lee, and W.-Y. Lui, “Risk factors for early and late
recurrence in hepatitis B-related hepatocellular carcinoma,” J. Hepatol.,
vol. 51, no. 5, pp. 890–897, 2009.
[42] I. F. N. Hung, R. T. P. Poon, C.-L. Lai, J. Fung, S.-T. Fan, and M.-F. Yuen,
“Recurrence of hepatitis b-related hepatocellular carcinoma is associated
with high viral load at the time of resection,” Amer. J. Gastroenterol., vol.
103, no. 7, pp. 1663–1673, 2007.

Authors’ photographs and biographies not available at the time of publication.

