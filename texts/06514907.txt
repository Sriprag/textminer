2636

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 60, NO. 9, SEPTEMBER 2013

An Augmented Reality System for Epidural
Anesthesia (AREA): Prepuncture Identification
of Vertebrae
Hussam Al-Deen Ashab, Victoria A. Lessoway, Siavash Khallaghi, Alexis Cheng, Robert Rohling,
and Purang Abolmaesumi∗

Abstract—We propose an augmented reality system to identify
lumbar vertebral levels to assist in spinal needle insertion for epidural anesthesia. These procedures require careful placement of a
needle to ensure effective delivery of anesthetics and to avoid damaging sensitive tissue such as nerves. In this system, a trinocular
camera tracks an ultrasound transducer during the acquisition of
a sequence of B-mode images. The system generates an ultrasound
panorama image of the lumbar spine, automatically identifies the
lumbar levels in the panorama image, and overlays the identified
levels on a live camera view of the patient’s back. Validation is performed to test the accuracy of panorama generation, lumbar level
identification, overall system accuracy, and the effect of changes in
the curvature of the spine during the examination. The results from
17 subjects demonstrate the feasibility and capability of achieving
an error within clinically acceptable range for epidural anaesthesia.
Index Terms—Augmented reality, epidural anesthesia, image
guidance, interventional ultrasound, panorama ultrasound.

I. INTRODUCTION
PIDURAL anesthesia is an injection of local anesthetics
and antiinflammatory medication into the epidural space
near the spinal canal for pain management. Injection into the
lumbar region at the L2-L3 or L3-L4 is commonly used in obstetrics for pain relief of labor and delivery. Epidural anesthesia
can also be used as an alternative to general anesthesia [1]. To
effectively deliver anesthetics and/or antiinflammatory medication, a two-step procedure has to be successfully performed.

E

Manuscript received February 5, 2013; revised March 15, 2013; accepted
April 20, 2013. Date of publication May 13, 2013; date of current version August 16, 2013. Asterisk indicates corresponding author.
H. Al-Deen Ashab and S. Khallaghi are with the Department of Electrical and
Computer Engineering, University of British Columbia, Vancouver, BC V6T
1Z4, Canada (e-mail: hussama@ece.ubc.ca; siavashk@ece.ubc.ca).
V. A. Lessoway is with the British Columbia Women’s Hospital and Health
Centre, Department of Ultrasound, Vancouver, BC V6H 3V4, Canada (e-mail:
vickie@lessoway.ca).
A. Cheng is with the Department of Computer Science, Johns Hopkins University, Baltimore, MD 21218 USA (e-mail: acheng27@jhu.edu).
R. Rohling is with the Department of Electrical and Computer Engineering,
Department of Mechanical Engineering, University of British Columbia, Vancouver, BC V6T 1Z4, Canada (e-mail: rohling@ece.ubc.ca).
∗ P. Abolmaesumi is with the Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC V6T 1Z4, Canada
(e-mail: purang@ece.ubc.ca).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2013.2262279

The puncture site should be correctly selected at the desired
intervertebral space followed by appropriate selection of needle
trajectory to reach the target. Both of these steps are currently
done blindly with manual palpation. Identification of the vertebrae for the first step is only 30% accurate [2]. Therefore, 70%
of the procedures misidentify the desired intervertebral space
by one or more levels. This is undesirable for two reasons. First,
accidental needle overshoot is more likely to result in nerve
damage for higher vertebrae. Second, the effectiveness of the
anesthetics depends on the level [2].
Recent studies have shown that ultrasound can be used to
accurately identify the vertebral levels [3]–[6]. However, interpreting spinal ultrasound images remain a challenge, especially
for novice ultrasound operators (i.e., many anesthesiologists).
To alleviate this issue, our research team has previously proposed two techniques for automatic vertebral levels identification from panorama ultrasound images [7] and displaying the
level to the anesthesiologist in an ultrasound guidance system
with a camera mounted on the transducer [8]. However, there
are remaining challenges that need to be addressed to enable the
translation of ultrasound-guided epidural anesthesia in routine
clinical practice: 1) A system has to be developed to seamlessly
relate the identified vertebral levels to the patient’s skin while
accommodating some patient motion during the epidural procedure; and 2) there should be no disruption to the sterile field such
as modifying the ultrasound transducer by mounting a camera
system, as previously proposed [8].
This research makes two major contributions. First, a new,
efficient, and fully automatic lumbar level identification algorithm from panorama ultrasound images is developed. Second,
it proposes an augmented reality system for Epidural anesthesia
(hereafter referred to as AREA) that overlays the identified levels on a live video image of the patient’s back. The workflow of
AREA is as follows. 1) Initially, a sequence of ultrasound images is acquired from the patient’s back before needle insertion.
These images are used to generate a panorama image showing a
sagittal cross section of the spinal anatomy parallel to the main
spinal axis. 2) An automatic image processing technique identifies the lumbar levels in the panorama image. 3) An augmented
reality module converts the level location in the panorama image
relative to the camera’s view of the patient, and overlays virtual
markings of the levels on a live video display of the patient’s
back.
This workflow ensures minimum disruption in the current
clinical procedure. Furthermore, since a remote video camera

0018-9294 © 2013 IEEE

AL-DEEN ASHAB et al.: AUGMENTED REALITY SYSTEM FOR EPIDURAL ANESTHESIA (AREA): PREPUNCTURE IDENTIFICATION

Fig. 1.

2637

Workflow of AREA.

is used, the system does not interfere with the sterile field. The
original design and preliminary results on ten human subjects
have been reported previously [9]. This paper provides substantially more detail on the description and implementation of
the technique, and reports extensive validation of the system
for 17 subjects. It also compares the performance of vertebral
levels identification technique we propose with a competing
method previously reported by Kerby et al. [7]. The paper is organized as follows: Section II describes the materials and methods used in identifying the lumbar level. In particular, it includes
1) panorama image generation, 2) vertebral levels identification,
and 3) visualization. Section III describes the experiments and
results. Section IV provides a discussion, concluding remarks,
and future work.
II. MATERIALS AND METHODS
AREA consists of a SonixTOUCH ultrasound system (Ultrasonix Medical Corp., Richmond, Canada) equipped with a 6.6MHz linear array transducer, L14-5/38; imaging parameters:
depth 6.0 cm, dynamic range 56 dB, gain 50%, and 16 frames
per second) and a trinocular MicronTracker motion tracking
system (Claron Technology Inc., Toronto, ON, Canada) to track
two markers. The first one is placed on the transducer so it is
referred to as the “Transducer Marker.” The second marker is
affixed to the patient’s back approximately 50 mm lateral to L3,
which is close to the approximate puncture site, but outside the
sterilized area, and referred to as the “Patient Marker.”
A simplified workflow of spinal needle insertion with guidance from AREA is shown in Fig. 1. First, the system checks
if all markers are visible followed by a prompt for the sonographer to start. The transducer is initially placed in the parasagittal
plane, 10 mm away from the midline on the interspinous gap L5S1. As shown in Fig. 2, the sonographer moves the transducer
superiorly across the lamina from the interspinous gap L5-S1 to
the interspinous gap T12-L1 to acquire the set of images.1
Each image is recorded individually by pressing a foot pedal.
During the scan, the sonographer determines the suitability of
each image for the subsequent steps, if the image contains:
1) a wave-like pattern from the laminae surfaces;
1 N.B. the sonographer also used a curvilinear transducer (C5-2, Ultrasonix
Medical Corp., Richmond, Canada), which was capable of displaying two to
three vertebral lamina in a single ultrasound image. These images were used to
measure the vertebral height for the purpose of validation as described in detail
in Section III.

Fig. 2. Ultrasound B-mode images are acquired by placing the transducer in
the parasagittal plane 10 mm from the midline. The solid line shows the vertebral
level the system identifies and the dashed line shows the imaging plane acquired
by the sonographer.

2) bright echoes from the most superior surface of the laminae;
3) distinct shadows under the laminae;
4) 50–70% overlap with the previous image.
These criteria ensure that adjacent images contain similar
anatomical features that allow interslice registration when generating the panorama of the lumbar spine. Moreover, the 50–
75% overlap between images is a compromise between the accuracy of registration (large overlap) and speed of examination
(small overlap).
A. Panorama Generation
The position and orientation of the ultrasound images must
be known for AREA to identify and display the lumbar levels
accurately. Therefore, the N-wire calibration method integrated
within an open-source software library for ultrasound imaging
research (PLUS) [10] was used to calibrate the ultrasound image to the marker on the transducer. Using this calibrated transducer, a sequence of B-mode ultrasound images is acquired
while tracked by the MicronTracker in the camera coordinate
system. The stitching process then uses the estimated transformation between images from the tracker and a subsequent rigid
registration using the Insight Toolkit [11] to automatically register and create a panorama ultrasound image of consecutive
vertebrae B-mode images. To allow a smaller search space for
the alignment parameters and less likelihood of large misregistration errors, the tracking information provided by the MicronTracker is used as an initial guess for the feature alignment
followed by a standard normalized cross correlation with gradient descent optimizer, linear interpolation of image intensities
at a noninteger pixel position, and translation transformation for
the final alignment. Even though the MicronTracker has high

2638

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 60, NO. 9, SEPTEMBER 2013

Fig. 3. Example of two ultrasound panorama images. (a) Panorama obtained
in the parasagittal plane, showing L1, L2, L3, L4, L5, and S1 from left to right.
(b) The same panorama image showing the automatically identified levels L1,
L2, L3, L4, and L5 from left to right.

reported accuracy (marker tracking error of about 0.20 mm), it
is sensitive to illumination conditions, specular reflections, and
the orientation of a tracked tool, which affects the accuracy of
tracking of individual ultrasound frames. These problems were
also reported in a previous study by Maier-Hein et al. [12].
Therefore, to improve robustness in a clinical environment, we
used an optimization and image registration algorithm to refine
the tracking measurements. We used a gradient descent optimizer with normalized cross correlation as the image similarity
measure. Our experience with the system in preliminary testing suggested that the choice of the optimizer and similarity
measure did not affect the registration outcome. However, omitting the image registration step resulted in small but observable
misalignments of the sequential ultrasound images.
This registration technique may still be susceptible to errors
associated with accidental out-of-plane motions of the transducer, but with reasonable care during scanning, it generates
panorama images sufficient for the purpose of vertebral levels identification. An example of panorama image is shown
in Fig. 3. If the operator is unsatisfied with the quality of the
panorama, a new panorama can be generated since a panorama
can be acquired in less than 2 min. This primarily includes the
time the operator takes to find the proper imaging plane, as it
may be challenging in some cases to find a plane that clearly
displays the epidural space. The actual panorama generation
process, after acquiring all the ultrasound images, takes in the
order of seconds. After the panorama image is generated, an automatic image processing technique identifies the lumbar levels.
An identification example is shown in Fig. 3.
B. Vertebral Levels Identification
The challenge of identifying the lumbar levels arises from
speckle, low contrast, and shadowing in the ultrasound images.
These challenges come from the complex shape of the vertebrae
and the presence of multiple ligaments, muscle, and fat, all of

Fig. 4. Workflow of panorama image processing, thresholding, and vertebral
identification, with the final step showing the fusion of the identification results
with the original panorama image.

which generate echoes dependent on the angle of incidence of
the ultrasound beam. Therefore, several processing steps are
required for successful vertebral identification.
Filtering starts with a median filter over a window twice
the size of a resolution cell, which corresponds to the smallest resolvable detail. After that, a bilateral filter [13], which
smoothens images while preserving edges, is used to reduce the
interclass variance and maximize the outer class variance. The
closeness and similarity functions of the bilateral filter are both
Gaussian functions. We set the size of the filter window to 40
pixels and the spatial-domain standard deviation is chosen as 5
pixels. The intensity-domain standard deviation depends on the
standard deviation of image intensities. Fig. 4 shows an example
of the filtering.

AL-DEEN ASHAB et al.: AUGMENTED REALITY SYSTEM FOR EPIDURAL ANESTHESIA (AREA): PREPUNCTURE IDENTIFICATION

Ultrasound echoes are stronger from specular reflections,
such as bony surfaces, than they are from soft tissues. This
suggests a simple thresholding may be sufficient to separate the
bone surface from tissue. However, previous research [14], [15]
reports the difficulty of segmenting bone and tissue in ultrasound images with such simple thresholding. In AREA, we take
advantage of the unique signature of the vertebral images in the
ultrasound data (i.e., the shadow that appears under the lamina),
and aim to segment this signature from the panorama images.
Given the variable overall image intensity variations inherent between the ultrasound images from different subjects, we use an
automatic thresholding technique based on Otsu’s method [16].
This method assumes the image contains two classes of pixels: foreground (i.e., the soft tissue and lamina) and background
(i.e., the shadow underneath each lamina). Under this assumption, this method calculates the optimum threshold separating
those two classes so that intraclass variances are minimal.
The laminae in the lumbar spine appears as wave-like patterns
in the panorama image. This signature is used to convert the 2-D
panorama image to a 1-D signal. After thresholding the ultrasound panorama image, it is scanned along the echo direction
from the bottom of the image to the top of the image. Whenever
a value above Otsu’s threshold value from the previous step is
reached, the index value is used as a sampled point in the 1-D
signal as shown in Fig. 4. Then, a median filter is applied to the
signal followed by a peak detection technique to identify the
peaks in the signal. The peak detection technique starts from
left to right of the image, and when it detects a maximum followed by a minimum, it assigns a peak label. For each of the
peaks, a threshold equal to the height of the vertebrae is used
to remove any false peaks. Next, the thresholded peaks are considered as the middle sections of the laminae in the panorama
ultrasound image as shown in Fig. 4. Given that the scanning
starts at L5-S1, the vertebrae are labeled sequentially from L1
to L5.
C. Visualization
The MicronTracker is calibrated to extract coefficients of
projection ray equations that convert pixel locations in an image
into projection rays in the camera coordinate system. In the camera Software Development Kit (SDK) (Claron Technology Inc.,
Toronto, ON, Canada), the back projection ray is represented by
a point in space and its angular orientation from the image axes.
The projection equation coefficients are found by presenting to
the camera a 3-D grid of targets and tuning the projection equation coefficients to get the best match between the 3-D grids
projections in the image and the positions of the 3-D grids in
space. Calibration parameters are stored in a file [17].
To identify the markers, the MicronTracker processes the
images and matches them to the descriptors in the marker templates. Marker projections onto each image were found to always
exceed a minimum footprint diameter of 9–11 pixels within the
working space of our system. After identifying a marker in the
image, its 3-D position is calculated by triangulating the projection rays, obtained from the calibration file, associated with the
location in the image where the marker center is observed [17].

2639

Fig. 5. Graphical user interface developed using 3-D Slicer showing the vertebral levels (black lines) overlaid on the video image of the patient’s back.

We used a standard volume ray casting method [18] to overlay
the identified lumbar levels on the corresponding location in a
live video stream of the patient’s back from the MicronTracker.
A 3-D point coordinate in the camera space is transformed to a
2-D pixel location in the image plane using the MicronTracker
SDK and the calibration file. To label a live video image of the
patient’s back, the system finds 1) the anchor transform, which
is the transform between the location of the first ultrasound image and the camera and 2) the patient transform, which is the
transform between the patient marker and the camera. Using the
anchor and patient transforms, the system finds the transform
between the anchor position of the panorama image and patient
marker, which we will refer to as “Image-to-Patient” transform.
Then, for each identified vertebrae, a line in the coronal plane
across the vertebrae is transformed to the 3-D coordinates of
the camera using the Image-to-Patient and patient marker transforms. The intersection of the projection rays with imaging plane
of the MicronTracker center camera is used to calculate the location where the 3-D point will appear in the MicronTracker
image and the identified lines are overlaid on the live camera
view [17].
The image with the labels is transferred in real time to 3-D
Slicer [19] through OpenIGTLink and displayed to the anesthesiologist on a standard monitor (see Fig. 5). Given a small range
of patient motion, the positions of the overlaid lines are automatically updated as the camera tracks the changing position of
the patient’s marker.
III. EXPERIMENTS AND RESULTS
Experiments were carried out on 17 subjects following informed consent. Ethics approval for this study was obtained
from our institution’s Research Ethics Board. We conducted
four experiments as shown in Table I and took the following
measurements:
1) Measurements on single 2-D ultrasound images:
a) Curvilinear vertebral height. For each subject, the
sonographer measured from the superior margin of
one vertebral lamina to the superior margin of the
next vertebral lamina on images obtained with a
curvilinear transducer (C5-2, Ultrasonix Medical

2640

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 60, NO. 9, SEPTEMBER 2013

TABLE I
TYPES OF EXPERIMENTS PERFORMED, GOLD STANDARD USED, AND MEASUREMENTS/LABELS THAT HAVE BEEN DEFINED IN THIS PAPER

TABLE II
MEAN (STANDARD DEVIATION) OF CURVILINEAR VERTEBRAL HEIGHT, PANORAMA VERTEBRAL HEIGHT, 90TH PERCENTILE, AND 80TH PERCENTILE
OF THE ABSOLUTE ERROR CALCULATED AS THE DIFFERENCE BETWEEN THOSE TWO MEASUREMENTS

Corp., Richmond, Canada). This transducer was
used as it is capable of displaying two to three vertebral lamina in a single ultrasound image.
2) Measurements on the panorama image:
a) Panorama vertebral levels. The sonographer identified each vertebral levels on the panorama images.
She marked the midpoint of the shadow generated
by the posterior surfaces of the laminae.
b) AREA vertebral levels. AREA identified the vertebral levels on the panorama images.
c) Kerby vertebral levels. Kerby et al.’s algorithm [7]
was used to identify vertebral levels on the panorama
images. A brief description of this algorithm is provided later.
d) Panorama vertebral height. The sonographer determined the height of the vertebrae in the panorama
images, by measuring from the superior margin of
one vertebral lamina to the superior margin of the
next lamina.
e) AREA vertebral count. AREA was used to count the
number of vertebrae in the panorama image.
f) Kerby vertebral count. Kerby et al.’s algorithm
was used to count the number of vertebrae in the
panorama image.
3) Measurements on the skin:
a) Actual vertebral labels at the resting position. These
measurements were performed with each subject sitting in a comfortable upright position without purposefully arching the spine forward (i.e., sitting in
the “resting” position). The sonographer used the
linear array transducer to manually identify the five
lumbar vertebrae either by scanning up from the
sacrum or scanning down from the bottom rib and
labeled the midpoint of each lumbar vertebrae on
the subject’s skin with a felt pen.
b) Actual vertebral labels with arching forward. The
measurements above were repeated while each sub-

ject arched forward until the screw angle (see Section III-D. for the description of the screw angle) of
the patient marker, relative to the resting position,
was changed by 5◦ and 10◦ , respectively.
c) Actual vertebral count. The sonographer used the
linear array transducer to manually count the five
lumbar vertebrae either by scanning up from the
sacrum or scanning down from the bottom rib.
d) AREA vertebrae labels at the resting position. These
measurements were performed with each subject sitting in the resting position. The sonographer acquired a sequence of ultrasound images, and AREA
displayed virtual markings of the identified vertebral
levels on an augmented video of the subject’s back.
The vertebral levels, which appear on the monitor,
were used to label each subject’s back with a felt
pen.
e) AREA vertebrae labels with arching forward. The
measurements above were repeated while each subject arched forward until the screw angle of the patient marker, relative to the resting position, was
changed by 5◦ and 10◦ , respectively.
The experiments were divided into the following parts.
A. Accuracy of Vertebral Height in Panorama Image
This experiment tested the accuracy of generating panorama
images by AREA. The sonographer obtained the curvilinear
vertebral height and panorama vertebral height measurements,
then the absolute error was calculated between those two measurements. Measurement of vertebral height from the curvilinear probe as well as the panorama images and the difference
between those two measurements are reported in Table II. In
summary, two different transducers and two different scanning
methods (single image versus panorama) were used in order
to have two independent measurements of the vertebral height.
We used the nonparametric Mann–Whitney-U test to compare

AL-DEEN ASHAB et al.: AUGMENTED REALITY SYSTEM FOR EPIDURAL ANESTHESIA (AREA): PREPUNCTURE IDENTIFICATION

2641

TABLE III
MEAN (STANDARD DEVIATION) AND 90TH PERCENTILE OF THE ABSOLUTE ERROR BETWEEN AREA AND PANORAMA VERTEBRAL LEVELS, AND
BETWEEN KERBY AND PANORAMA VERTEBRAL LEVELS

TABLE IV
NUMBER OF FALSE AREA AND KERBY VERTEBRAL COUNTS (N = 82)

the measurements obtained with the two approaches. The test
fails to show statistically significant difference between the two
measurements (p > 0.05), except for L4 (p = 0.005). We also
report the 90th and 80th percentile of the error for each vertebra.

TABLE V
ACTUAL VERTEBRAL COUNT, AREA VERTEBRAL COUNT, AND
KERBY VERTEBRAL COUNT (N = 82)

TABLE VI
MEAN (STANDARD DEVIATION), 90TH, AND 80TH PERCENTILE OF THE
ABSOLUTE DIFFERENCE BETWEEN AREA ACTUAL VERTEBRAE LABELS
AT THE RESTING POSITION AND ACTUAL VERTEBRAE LABELS
AT THE RESTING POSITION MEASURED ON SUBJECT’S BACK

B. Accuracy of Vertebral Levels Identification
in Panorama Image
In order to evaluate the accuracy of AREA vertebral levels identification algorithm, we measured the distance between
panorama vertebral levels and AREA vertebral levels. We also
compared the performance of vertebral levels identification
technique proposed in this paper with a competing method previously developed by Kerby et al. [7]. Error was calculated as
the distances between panorama vertebral levels and Kerby vertebral levels identified in the panorama images. Kerby et al.’s
algorithm first applies a median filter with a window width and
height twice the ultrasound signal wavelength. Then, a linear
filter, which operates in the vertical and horizontal directions, is
used to highlight bone edges and enhance the periodic nature of
the vertebrae. After that, hard thresholding is used to set twothirds of pixels to zero, and at least squares parabolic is fit into
the image. For each parabolic fit into the image, the minimum
is identified as vertebra. More details can be found in the Kerby
et al.’s paper [7].
AREA and Kerby et al.’s algorithms were compared in terms
of the mean absolute error, number of the vertebrae identified,
and the number of false identification. The results are reported
in Tables III, IV, and V. The false identification reported in Table IV is mostly around the interspinous gaps because of low
image intensity at that location, which occasionally results in
inaccurate segmentation of the panorama image using Otsu’s
threshold, and subsequently, wrong identification at the interspinous gaps. The Mann–Whitney-U test comparing the absolute errors reported by AREA and Kerby et al.’s algorithms in

Table III fails to show statistically significant difference between
the two measurements (p > 0.05).
C. Accuracy of Vertebral Levels Identification on the Skin
To test the accuracy of identifying and overlaying vertebral
levels on a live video stream of the patient’s back, the error
was defined as the distance between AREA actual vertebrae
labels at the resting position and actual vertebrae labels at the
resting position. This error was measured on the skin of the
volunteer, and the mean absolute error and standard deviation
of this error are reported in Table VI. We also report the 90th
and 80th percentile errors for these measurements.
D. Accuracy of Spine Arching
In spinal needle insertion procedures, the patient is typically
asked to arch forward to increase the width of the window
to the epidural space. However, the patient may change their
arch after being imaged by AREA, and change the location of
vertebral levels with respect to the patient marker. After the
system identifies the vertebral levels at the resting position,
we asked each subject to arch further forward until the screw
angle of the marker was changed by 5◦ and 10◦ , respectively.
We use screw angle measurements to determine the relative

2642

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 60, NO. 9, SEPTEMBER 2013

TABLE VII
COMPARISON OF THE MEAN ABSOLUTE ERROR OF AREA FOR DIFFERENT
SPINE ARCHING ANGELS

rotation of the marker orientation between two arching positions
of the patient. All measurements are performed relative to the
orientation Φ of the patient marker in the resting position of the
subject and is calculated as in (2) in Spoor et al. [20]:
⎤
⎡
R11 R12 R13
(1)
R = ⎣ R21 R22 R23 ⎦
R31 R32 R33

Φ = sin−1 ( (R32 − R23 )2 + (R13 − R31 )2 + (R21 − R12 )2 )
(2)
where R is the rotation matrix around the screw axis.
For each subject, the volunteer is asked to arch forward until
the screw angle of the marker was changed by 5◦ with respect to
the resting position. Then, the distance between actual vertebrae
labels with 5◦ arching forward and AREA actual vertebrae labels
with 5◦ arching forward was measured on the volunteer’s back.
After that the volunteer is asked to arch further forward again
until the screw angle of the marker was changed by 10◦ with
respect to the resting position. Then, the distance between actual
vertebrae labels with 10◦ arching forward and AREA actual
vertebrae labels with 10◦ arching forward was measured on the
volunteer’s back. The mean absolute of these measurements for
each vertebral level are reported in Table VII.
IV. DISCUSSION
We presented a novel needle puncture site selection system
for reducing the risk associated with lumbar spine needle insertion. The new augmented reality system concept has been
successfully tested on 17 subjects, and results show the accuracy of identifying lumbar vertebral levels and overlaying the
information onto a live video stream of the patient’s back (mean
absolute error  21% of the vertebral height). Fig. 6 shows
simple transformation chain to illustrate the major factors contributing to the total system error. In the following sections, we
provide further descriptions of the various sources of the error
in each step. Note that the vertebral level is considered to be
identified correctly if the error is less than half the vertebral
height.
A. Accuracy of Vertebrae Height in Panorama Images
In this experiment, the mean absolute error between curvilinear vertebral height and panorama vertebral height was 7.1 mm.
However, this error indicates that the accuracy of generating
panorama images by the proposed system is accurate enough
for the purpose of vertebral levels identification (less than half
the vertebral height). The major factors contributing to this error include: ultrasound image calibration error ( 1 mm), patient

Fig. 6. Summary of major factors contributing to the overall error. Each arrow
indicates an error contributing to each of the modules in the system.

motion during the acquisition of tracked ultrasound images, acquiring images out of plane, MicronTracker localization error,
and MicronTracker calibration error.
Further improvements may be possible by using a 3-D transducer and an algorithm to automatically select optimal images
from each acquired ultrasound volume. This may improve the
generation of the panorama images which subsequently may
improve the overall system performance. Moreover, a more accurate tracking system could be used but at greater cost.
B. Accuracy of Vertebral Levels Identification
in Panorama Images
We also reported the accuracy of vertebral levels identification. This experiment shows the accuracy of AREA in identifying individual vertebra in the panorama images. As shown in
Tables III, IV, and V, the mean absolute error of vertebral levels
identification is 3.2 mm with an identification rate of 96% and
false identification rate of 3.7% (three false identifications). The
false negatives are due to weak reflection from the posterior surface of the lamina in the panorama images. The false positives
are mostly because of low image intensity at the interspinous
gaps which result in inaccurate segmentation of the panorama
image using Otsu’s threshold.

AL-DEEN ASHAB et al.: AUGMENTED REALITY SYSTEM FOR EPIDURAL ANESTHESIA (AREA): PREPUNCTURE IDENTIFICATION

In addition, AREA vertebral levels identification was compared to the Kerby et al.’s algorithm as shown in Table III.
The mean absolute error of AREA vertebral levels identification and Kerby et al.’s algorithm, as well as the 90th percentile
of those errors, are both less than half the vertebral height which
indicates that both methods can be used to identify the levels.
However, the AREA identification rate is 96% while the Kerby
et al.’s algorithm identification rate is only 89%.
As shown in Table V, AREA identified the L3 vertebrae, the
typical injection site, for all subjects while most of the Kerby
et al.’s algorithm false identifications were for L3. The false
identification rate of AREA is 3.7% (three false identifications)
compared to 1.2% (one false identification) of Kerby et al.’s
algorithm. This error is not expected to affect the outcome of
needle puncture site selection since the operator can visually
determine the false identification from the augmented lines on
the video of the patient’s back and the generated panorama
image.
The vertebral levels identification error of 3.2 mm may be
reduced by registering statistical shape model [21] of the lumbar
spine anatomy to the panorama image which, in turn, provides
more data for vertebra identification but at greater computational
expense. Moreover, using a more accurate tracking system will
also improve the outcome of panorama generation and vertebral
levels identification modules at higher cost.
C. Accuracy of Vertebral Levels Identification on the Skin
The overall system accuracy is shown in Table VI with a
total mean absolute error of 6.9 mm (shown in Table VII). As
shown in Table VII, the mean absolute error is less than half the
vertebral height except for L1 vertebra. This higher error for L1
is likely due to the fact that the L1 vertebra has low intensity and
a flat shape in ultrasound images; thus it is difficult to define the
midpoint of the shadow generated by the posterior surface of the
lamina. All the previous modules contributed to the error of this
stage. Specifically, this includes the errors from projecting the
identified lumber levels onto a live video of the patient’s back.
D. Accuracy of Spine Arching
In the arching accuracy experiment, given forward arching
of the subject up to 10◦ , the maximum mean absolute error
observed was 11.9 mm. Given that the marker was affixed to the
patient’s back close to L3, the error was highest for the vertebrae
farthest away, i.e., L1 and L5. The mean absolute error increases
with forward arching due to the increase of the distance away
from the patient marker. These errors are less significant because
L1 and L5 are farthest from the typical injection site that is
generally close to L3 (L3-L4 or L2-L3). If needed, the error
of L1 and L5 could be also reduced by using multiple tracking
markers on the skin of the patient that span the sacral, lumbar,
and thoracic region.
The proposed system introduces less than 2 min overhead to
the routine clinical examination process. This includes acquiring
tracked ultrasound images, vertebral levels identification, and
overlaying the identified levels on a live video image of the
patient’s back. One drawback of this system is the fact that

2643

missing vertebra will result in wrong labeling of the vertebrae
of the levels. Therefore, the system allows the operator to decide
the first and last vertebrae to be imaged and thereafter used to
count, label, overlay, and display those labels. In the future, the
system can be further developed to allow the operator to specify
the missing vertebral labels which will help in case there is any
missing vertebra other than L5 and L1.
Another possible drawback is the increase in intervening tissue in obese patients between the ultrasound probe and lamina
which may affect the image quality and results of lumbar identification. However, using the AREA vertebral levels identification algorithm, in which segmentation and vertebrae identification parameters are automatically chosen depending on the
properties of the panorama image, will have a minor effect on
the results compared to Kerby et al.’s algorithm which use simple threshold by zeroing two-thirds of the pixels. More tests on
obese patients are needed.
The performance of the panorama generation step will degrade in the presence of large transducer rotations. To analyze
the effect of such rotations, we performed an experiment where
we scanned a volunteer ten times from L5-S1 to T12-L1, and
successfully generated ten independent panorama images. We
measured the rotation of the scan planes relative to the first scan
plane in each generated panorama image. The extent of rotation
around the axial axis is 4.1◦ ± 5◦ , the extent of rotation around
the lateral axis is 0.9◦ ± 7.7◦ , and the extent of rotation around
the elevation axis is 9.5◦ ± 10.2◦ . These rotation angles indicate
the range of probe rotations during panorama acquisition, while
anatomically correct features are visible in the acquired ultrasound scans. We would like to emphasize that the acceptable
range is most likely operator and subject specific.
In conclusion, AREA provides an objective and consistent
measure for the identification of the vertebral levels based on
the panorama image depicting the entire lumbar region, as opposed to local vertebral identification using single ultrasound
image acquisitions at each level. Also, the method provides an
overlay of the plan onto the patient’s back, therefore minimizing the procedure variability due to the interpretation of the
sonographer. The accuracy of AREA is within the clinically acceptable range, which is less than half the vertebral height, for
L3 vertebra where most needle insertions are performed. This
system is designed to fit within the established clinical workflow
for epidural anesthesia. It could be used prior to performing the
needle insertion procedure without the requirement for special
patient preparation. Moreover, AREA is intended to be used
by a single operator without disrupting the sterile field since
the only computer interaction is via a foot pedal. This proof of
concept therefore is the first step before subsequent testing in
clinical practice.

ACKNOWLEDGMENTS
This work is jointly funded by grants from the Natural Sciences and Engineering Research Council of Canada and the
Canadian Institutes of Health Research.

2644

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 60, NO. 9, SEPTEMBER 2013

REFERENCES
[1] S. Liu, W. Strodtbeck, J. Richman, and C. Wu, “A comparison of regional
versus general anesthesia for ambulatory anesthesia: A meta-analysis of
randomized controlled trials,” Anesthesia Analgesia, vol. 101, pp. 1634–
16342, Dec. 2005.
[2] F. Reynolds, “Logic in the safe practice of spinal anaesthesia,” Anaesthesia, vol. 55, pp. 1045–1046, Nov. 2000.
[3] G. Furness, M. Reilly, and S. Kuchi, “An evaluation of ultrasound imaging
for identification of lumbar intervertebral level,” Anaesthesia, vol. 57,
pp. 277–280, Mar. 2002.
[4] H. Schlotterbeck, R. Schaeffer, W. Dow, Y. Touret, S. Bailey, and
P. Diemunsch, “Ultrasonographic control of the puncture level for lumbar
neuraxial block in obstetric anaesthesia,” Brit. J. Anaesthesia, vol. 100,
pp. 230–234, Feb. 2008.
[5] M. Yamauchi, E. Honma, M. Mimura, H. Yamamoto, E. Takahashi, and
A. Namiki, “Identification of the lumbar intervertebral level using ultrasound imaging in a post-laminectomy patient,” J. Anesthesia, vol. 20,
pp. 231–233, Aug. 2006.
[6] A. Rasoulian, J. Lohser, M. Najafi, H. Rafii-Tari, D. Tran, A. Kamani,
V. Lessoway, P. Abolmaesumi, and R. Rohling, “Utility of prepuncture
ultrasound for localization of the thoracic epidural space,” Can. J. Anesthesia J. Can. d’Anesthésie, vol. 58, pp. 1–9, Sep. 2011.
[7] B. Kerby, R. Rohling, V. Nair, and P. Abolmaesumi, “Automatic identification of lumbar level with ultrasound,” in Proc. Eng. Med. Biol. Conf.,
Vancouver, BC, Canada, Aug. 2008, pp. 2980–2983.
[8] H. Rafii-Tari, “Panorama ultrasound for navigation and guidance of epidural anesthesia” Master’s thesis, Univ. British Columbia, BC, Canada, 2011.
[9] H. Ashab, V. Lessoway, S. Khallaghi, A. Cheng, R. Rohling, and
P. Abolmaesumi, “Area: An augmented reality for epidural anaesthesia,” in Proc. Eng. Med. Biol. Conf., San Diego, CA, USA, Aug. 2012,
pp. 2659–2663.
[10] A. Lasso, T. Heffter, C. Pinter, T. Ungi, T. K. Chen, A. Boucharin, and
G. Fichtinger, “Plus: An open-source toolkit for developing ultrasoundguided intervention systems,” in Proc. 4th NCIGT NIH Image Guided
Therapy Workshop, Oct. 2011, vol. 4, p. 103.
[11] L. Ibanez, W. Schroeder, L. Ng, and J. Cates The ITK software guide: The
insight segmentation and registration toolkit, Kitware, Inc., NY, USA,
vol. 5, 2003.

[12] L. Maier-Hein, A. Franz, H. Meinzer, and I. Wolf, “Comparative assessment of optical tracking systems for soft tissue navigation with fiducial
needles,” in Proc. Med. Imag.: Vis. Imag. Guided Procedures Model., San
Diego, CA, USA, Mar. 2008, pp. 69181Z-1–69181Z-9.
[13] C. Tomasi and R. Manduchi, “Bilateral filtering for gray and color images,”
in Proc. 6th Intell. Conf. Comput. Vis., Bombay, India, Jan. 1998, pp. 839–
846.
[14] I. Hacihaliloglu, R. Abugharbieh, A. Hodgson, and R. Rohling, “Bone
surface localization in ultrasound using image phase-based features,” Ultrasound Med. Biol., vol. 35, pp. 1475–1487, Sep. 2009.
[15] A. Jain and R. Taylor, “Understanding bone responses in B-mode ultrasound images and automatic bone surface extraction using a bayesian
probabilistic framework,” in Proc. SPIE Med. Imag., Bellingham, WA,
USA, Apr. 2004, pp. 131–142.
[16] N. Otsu, “A threshold selection method from gray-level histograms,” IEEE
Trans. Syst. Man Cybern., vol. 9, no. 1, pp. 62–66, Jan. 1979.
[17] Microntracker developers manual MTC 3.6, Claron Technology, Inc.,
Toronto, ON, Canada, 2008.
[18] J. Udupa and G. Herman, 3D Imaging in Medicine. Boca Raton, FL,
USA: CRC Press, 1999.
[19] D. Gering, A. Nabavi, R. Kikinis, W. Grimson, N. Hata, P. Everett,
F. Jolesz, and W. Wells, “An integrated visualization system for surgical
planning and guidance using image fusion and interventional imaging,” in
Proc. 2nd Int. Med. Imag. Comput. Comput.-Assist. Intervent., Sep. 1999,
vol. 1679, pp. 809–819.
[20] C. Spoor et al., “Rigid body motion calculated from spatial co-ordinates
of markers,” J. Biomech., vol. 13, pp. 391–393, Feb. 1980.
[21] A. Rasoulian, R. Rohling, and P. Abolmaesumi, “Group-wise registration
of point sets for statistical shape models,” IEEE Trans. Med. Imag., vol. 31,
no. 11, pp. 2025–2034, Nov. 2012.

Authors’, photographs and biographies not available at the time of publication.

