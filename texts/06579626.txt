IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 1, JANUARY 2014

353

An Adaptable and Flexible Framework for Assistive
Living of Cognitively Impaired People
Hamdi Aloulou, Mounir Mokhtari, Thibaut Tiberghien, Jit Biswas, and Philip Yap

Abstract—On account of chronic neurocognitive disorders,
many people progressively lose their autonomy and become more
dependent on others, finally reaching the stage when they need
round-the-clock care from caregivers. Over time, as patients’ needs
increase with the evolution of their diseases, caregivers experience increasing levels of stress and burden. Therefore, an assistive
solution that is able to adapt to the changing needs of the endusers is needed. This need was considered as a major requirement
that emerged from our field work and deployment experience in
Singapore. In this paper, we focus on the technical aspects of our
deployment, where we were interested in solving the technical requirement of adaptability and extendibility of the framework that
has emerged from our predeployment analysis and discussions with
professional caregivers. We expose our approach for dynamic integration of assistive services with their related sensing technologies
and interaction devices and provide the technical results of the deployment of this solution. We also provide guidelines for real-world
deployment of assistive solutions.
Index Terms—Ambient assistive living (AAL), cognitive impairment, context aware services, dynamic and extendible frameworks.

I. INTRODUCTION
IFFERENT ambient assistive living (AAL) solutions have
been developed in order to support ageing persons with
cognitive decline. However, most of these solutions are usecase oriented; therefore, they only respond to some specific
end-users’ needs and do not evolve with the emergence of new
human requirements. In this paper, we emphasize the need for
a dynamic and extendible assistive living solution that is able

D

Manuscript received November 30, 2012; revised April 10, 2013 and July
25, 2013; accepted August 5, 2013. Date of publication August 15, 2013; date
of current version December 31, 2013. This work was supported by A*STAR
SERC, Singapore, under Smart Home 2015 programme through AMUPADH
project [25] and by Institute Mines-Télécom, France, under Quality of Life
Chair.
H. Aloulou is with the Montpellier Laboratory of Informatics, Robotics
and Microelectronics, CNRS UMR 5506, Montpellier 34392, France, and
also with the Institut Mines-Télécom, 75634 Paris Cedex, France (e-mail:
hamdi.aloulou@ipal.cnrs.fr).
M. Mokhtari is with the Image & Pervasive Access Laboratory, CNRS
UMI 2955, Singapore 138632, with the Montpellier Laboratory of Informatics, Robotics and Microelectronics, CNRS UMR 5506, Montpellier 34392,
France, and with the Institut Mines-Télécom, 75634 Paris Cedex, France
(e-mail: mounir.mokhtari@ipal.cnrs.fr).
T. Tiberghien is with the Image & Pervasive Access Laboratory, CNRS UMI
2955, Singapore 138632, and also with the Institut Mines-Télécom, 75634 Paris
Cedex, France (e-mail: thibaut.tiberghien@ipal.cnrs.fr).
J. Biswas is with the Institute for Infocomm Research, A*STAR, 138632
Singapore (e-mail: biswas@i2r.a-star.edu.sg).
P. Yap is with the Khoo Teck Puat Hospital, Alexandra Health, 768828
Singapore (e-mail: yap.philip.lk@alexandrahealth.com.sg).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2013.2278473

to integrate and provide new assistive services for the end-user
according to the evolution of his disease and to adapt to different deployment environments. This aspect represents one of the
major technical requirements we have identified during our deployment experience in Singapore [1]. We discuss the different
mechanisms that can be used in order to ensure the dynamic
aspect of an assistive framework and detail our proposed approach based on the use of the ontological representation [2].
Our developed framework was deployed and technically evaluated in three rooms of a nursing home with eight patients and
two caregivers.
II. RELATED WORK
AAL technologies can be used to assist people with cognitive decline and their caregivers. AAL consists of a set of
ubiquitous technologies—e.g., sensors, actuators, interaction
devices—embedded in the living space of the patient to monitor
and react to his contextual needs by providing computerized assistive services. Different AAL solutions have been developed
for specific scenarios to assist patients during different stages of
cognitive decline ranging from healthy ageing to severe cognitive impairment [3]–[5]. Furthermore, remote monitoring systems are used for mobility measurement to estimate disturbances
in motor activity of the patients to prevent risks of accident [6].
Some systems use video and audio recording for patient tracking
in order to analyze their activities [5], [7]. These solutions provide a set of predefined services and scenarios; therefore, they
are limited to specific use-cases and cannot respond to all the
patients’ requirements and needs. Some work in the literature
has contributed to the dynamism and adaptability of systems
in pervasive spaces and AAL environments. Existing research
on application polymorphism [8] has helped on the portability of applications through different devices. This approach is
based on the decomposition of the application into smaller components that can be independently adapted and recomposed to
obtain a semantically similar application on a specified device.
This method is considered complementary to our proposed approach, where we focus mainly on the detection of new devices
and their integration into our proposed framework. Some work
already exists allowing the discovery, and the interaction with
devices [9], [10]. However, in these approaches, no semantic
bindings are added between the devices and their environment;
thus, either they do not support any device selection or they
are only based on the devices intrinsic characteristics without
reasoning on the context. In our approach, we are interested
in binding the interaction devices to different assistive services
based on the end-user context. This allows the dynamism of
the framework in order to provide the assistive service using

2168-2194 © 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

354

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 1, JANUARY 2014

the appropriate interaction device. When it comes to sensors,
some work has contributed to wide-area sensors network selfconfiguration [11]. However, strong contributions are yet to be
found on context binding of newly discovered sensors. In another work supporting the dynamic integration of devices and
sensors [12], integrated devices and sensors are preconfigured
and predefined for specific functionalities; thus, provided services are only based on one sensor and the platform cannot provide assistive services based on multiple sensors. Our approach
is to bound assistive services to multiple context information.
Hence, our proposed framework authorizes the discovery and integration of different sensors and interaction devices, then attach
them to several assistive services. It also allows their reconfiguration, when needed, to be used for other assistive services.
The dynamic integration of entities based on the use of a middleware and some semantic representation was introduced in a
position paper by Helal [13]. We follow a similar approach based
on the use of the modular approach, the declarative approach,
and the device profile for web services (DPWS) communication
mechanism.
III. APPROACHES AND TECHNOLOGIES SUPPORTING THE
DYNAMISM OF AAL SOLUTIONS
In our approach, we provide an adaptable and dynamic platform that integrates new assistive services at runtime and enables
their binding to specific patients. It also allows new interaction
devices and sensors to be incorporated on the fly. This was realized using the modular and ontological approaches and different
technologies that we detail in this section.
A. System Modularity Through Service-Oriented Approach
As a base to enable the dynamic aspect of our system, we
chose to adopt a modular approach using the service-oriented
approach (SOA) [14]. This allows us to structure our framework in a modular way, permitting its flexibility, scalability,
reconfigurability, and ease of replication. Using this approach,
we have represented the different acts of assistance that should
be provided for a cognitive impaired patient as assistive services which can be integrated or removed from the framework
at runtime with smooth reconfigurations. The different sensing
technologies and interaction devices are also represented into
the framework as services (careful: not assistive services) that
can provide context information or display assistive services. If
a new act of assistance needs to be provided for the patient, we
just need to install the assistive service and bind the corresponding sensors and interaction devices to it. All these entities are
integrated into the framework at runtime.
As SOA is only a conceptual approach, we based our implementation on the Open Service Gateway initiative1 (OSGi),
which is one of the major specifications for SOA. It ensures the
establishment and management of systems composed of services and has been used in numerous projects for smart homes
development [15], [16]. An OSGi framework is basically a container running services called bundles in OSGi terminology.
1 http://www.osgi.org/

Assistive services, sensors’ services, and devices’ services are
packaged into bundles. These bundles can be started, stopped,
or updated independently at runtime without affecting other
components or without restarting the entire framework.
B. Declarative Approach
To implement the reasoning aspect into our service-oriented
framework, we could opt for a classical imperative approach,
which is very robust and requires only a short design phase.
However, this brings deep constraints in terms of reusability in
personalized environments and adaptability in dynamic environments. We consider that a declarative approach allows for a
more efficient separation between application logic and underlying models describing the peculiarities of the environment [17].
Although this choice represents an important tradeoff on the effort to be put at the design phase, it seems unavoidable to ensure
the dynamism of the framework, essentially when targeting a
large-scale deployment. To adopt the declarative approach, several options are available. Among them, semantic web technologies provide a state-of-the-art modeling syntax with reasoning
capacity and it is fitted by nature to highly dynamic and open
application domains. Therefore, we decided to use semantic
web technologies and, especially, a semantic reasoner to drive
our context-awareness. These technologies provide a level of
abstraction common to all entities and bring down to each entity
the possibility to understand newly discovered other entities and
to create bindings with the environment.
C. Technologies Supporting Sensors/Devices Plug&Play
The framework is supposed to perform an environment discovery to detect and connect with new sensors and interaction
devices deployed in the environment. This connection should
be realized at runtime and in total transparency, which means
without prior knowledge about the entities to be discovered.
Different mechanisms in the OSGi specification can be used to
achieve such a behavior, mainly the Distributed OSGi (DOSGi)
service invocation, the distributed event communication, and the
DPWS mechanism.
1) DOSGi Service Invocation: DOSGi [18] extends OSGi to
pervasive computing. It allows the communication between distributed containers with remote services invocation and service
discovery. In order to guarantee the remote services invocation
by service requesters, a service description (Service Interface)
describing the provided service should be installed on the container of each service requester.
The drawback of this technique is that it requires the modification of ordinary OSGi bundles to make functionalities (Service
Interfaces) provided by the environment’s entities available remotely. It also assumes that these functionalities are known by
service requesters beforehand at design phase in order to invoke
them, which is not the objective of our approach.
2) Distributed Event Communication: This mechanism is
based on the use of the publish/subscribe paradigm. In
OSGi, it could be achieved using ActiveMQ,2 an event-based
2 http://activemq.apache.org/

ALOULOU et al.: ADAPTABLE AND FLEXIBLE FRAMEWORK FOR ASSISTIVE LIVING OF COGNITIVELY IMPAIRED PEOPLE

communication broker. Using this mechanism, event producers send their events to ActiveMQ using specific topics, while
ActiveMQ forwards these events to all the event consumers
subscribed to the same topics.
The event communication approach gives more flexibility as
there are more transparency between the environment entities
and the framework. However, new topics need to be added each
time a new sensor or interaction device is integrated. In addition, there is no defined and standardized communication syntax
which may cause communication problems.
3) DPWS Mechanism: The DPWS [19] is a Web Service
(WS) standard. It is the successor of the Universal Plug’n’Play
mechanism as in essence it allows entities in the environment
to discover each other’s presence on the network and specifies
a protocol for interacting with services offered by these entities [20]. In this way, entities are able to communicate with each
other or with other DPWS enabled applications using a unified
and standardized protocol. DPWS includes support for entities
discovery and description as well as for secure messaging and
eventing. It is based on a dynamic network discovery mechanism
using the WS-Discovery standard. A specific driver3 was specified for DPWS to enable the discovery and control of DPWSbased entities from OSGi containers. An implementation of this
driver was used to enable the communication between isolated
OSGi frameworks [21].
This approach provides a completely flexible and dynamic
framework with the ability to add or remove sensors and devices
at runtime without the need to recode the framework. It also
allows attaching and configuring new assistive services with
their related sensors and interaction devices in total transparency
between the framework and the different entities.
IV. SPECIFIC TECHNICAL CONTRIBUTION
The technical contribution of this study consists mainly on the
semantic reasoning aspects and the semantic Plug&Play mechanism. We propose a model allowing the semantic representation
of different entities and contexts in a given environment. Based
on the evolution of this model using context information gathered from the sensors together with defined first-order logic
rules, our framework is able to perform some context understanding in order to select the assistive services needed by the
patient and the suitable interaction devices to provide these services. On the other hand, the semantic Plug&Play mechanism
allows the discovery of sensors and devices deployed in the
environment, their integration into the framework at runtime,
and then their inclusion into the service selection and provision process based on the provided semantic description. This
lets the framework integrate and provide new assistive services,
and adapt to its environment with simple reconfiguration and
without recoding or restarting the framework.

Fig. 1.

355

Environment semantic model.

activities, locations, assistive services, sensors, and devices)
and the relations between them. Fig. 1 represents the different classes we have in this model with the possible properties
linking between them.
Most properties between instances of these classes do not
exist in the initial state of the ontology as the system does not
have any information about the patients and their context. When
the system starts receiving events from sensors, the ontology is
automatically updated and a set of inference rules is applied
to infer the context of a patient, select the adequate assistive
service for the patient depending on his context, and select the
appropriate device of interaction. This is achieved using Euler
reasoning engine [17] with first-order logic rules.
As an example, the rule below ensures the selection of an
appropriate device for the patient depending on his location. It
could be enriched with more criteria related to the patient profile
and preferences:
∀ Resident r; Environment e; Device d
(r, detectedIn, e) ∧ (d, deployedIn, e)
⇒ (r, useDevice, d)
The second rule below is dedicated to the selection of an
appropriate assistive service to be provided for the patient, based
on abnormal behaviors we might detect:
∀ Resident r; Deviance dv; Service s
(r, believedT oDo, dv) ∧ (dv, needService, s)
⇒ (r, isInterestedIn, s)
B. Semantic Plug&Play Mechanism

A. Semantic Context Modeling and Reasoning
We provide a semantic model that represents the knowledge
about entities in the environment (including users and their
3 RFP

86 DPWS Discovery Base Driver, OSGi Alliance.

Our proposed architecture is composed of an assistive service
provider framework, and several gateways enabling the discovery and integration of sensors and devices in the environment.
The use of the DPWS communication mechanism provides a
base for the dynamic aspect of the system, through a Plug&Play

356

Fig. 2.

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 1, JANUARY 2014

Detailed architecture and process of our dynamic framework.

Fig. 3.

mechanism allowing the representation as a service of any sensor or device discovered in the environment at runtime. This
mechanism is detailed in Fig. 2.
The wireless sensor management system (WSMS) bundle
on the OSGi sensor gateway was developed to manage the
ZigBee communication [22] with sensors deployed in the environment. It automatically generates a DPWS-based bundle
representing each new sensor detected in the environment. The
generated bundle contains a description of the sensor and its
functionality—type, ID, events, etc. The type and ID information are deduced from the sensor’s packets received through
ZigBee. A similar process is also implemented on the OSGi
device gateway where the device management system (DMS)
communicates with devices through WiFi, 3G, or Bluetooth
and automatically generates DPWS-based bundles describing
these devices—type, ID, location, rendering capability (audio,
video, picture, text, light, etc.)—each time a new device is discovered. WSMS and DMS generate these bundles and start
them when new entities are discovered, then stop and remove
them when the corresponding entities are removed from the environment. The mechanical Plug&Play mechanism described
up to this point allows the integration and representation of
sensors and devices as services into the framework. However,
these entities are still not integrated into the reasoning process
as no information has been provided about their bindings to
the environment (who is using the device? where are the sensors actually deployed? etc.). Thus, it is not possible to use
them in the selection of the end-user service and the interaction
device.
To tackle the issue exposed above, we introduce the notion
of semantic Plug&Play. Newly generated bundles, representing sensors and devices, use the DPWS discovery protocol,
WS-discovery (arrow 2 in Fig. 2) to advertise themselves and
send their descriptions to the reasoning engine integrated in the
OSGi assistive service provider framework. A simple configuration tool in this framework displays newly detected entities
in the environment once it receives their description. It is in
charge of adding bindings between the discovered entities and
other objects in the environment in order to configure their use
in assistive services provision. As an example, Fig. 3 shows the
configuration of a newly detected ultrasound sensor. Assistive
services can also be integrated at runtime and included in the
reasoning process (arrow 4 in Fig. 2).

User interface for entities Plug&Play configuration.

The reasoning engine is in charge of adding all these entities’ semantic representation to the semantic model in order to
include them into the assistive service and interaction device selection process. Once a new assistive service and its related sensors and interaction devices are integrated in the environment,
the reasoning engine starts receiving events from the sensors
(arrow 3 in Fig. 2), assistive service and interaction device selection is performed, and the service is rendered on the selected
device (arrows 5, 6, and 7 in Fig. 2).
Next, we present the example of integrating a new assistive
service “Shower too long alert.” This service alerts the patient
and the nurses when the first is detected as showering for more
than a fixed period of time. We install and start the bundle
representing the assistive service “Shower too long alert” in
the framework; then, we attach a presence sensor to the shower
room ceiling and we put a vibrator sensor on the water pipe. The
semantic Plug&Play mechanism allows us to link the assistive
service to its related sensors: using the configuration tool, the
presence sensor is configured to detect the resident moving in
the shower room, while the vibrator sensor is configured to
detect the use of the shower. A set of first-order logic rules are
generated for the showering too long service:
∀ Sensor s1; Sensor s2

(s1 hasT ype P IR) ∧ (s1 deployedIn Shower) ∧
(s1 hasC urrentState on) ⇒ (resident detectedIn Shower)

(s2 hasT ype vibrator) ∧ (s1 deployedIn Shower) ∧
(s2 hasC urrentState unstationary)

⇒ (resident believedT oDo T akingShower)

(resident detectedIn Shower) ∧
(resident believedT oDo T akingShower) ∧
(resident inRoomF or duration) ∧ (duration notLessT han 3600)

⇒ (resident believedT oDo ShowerT ooLong)

ALOULOU et al.: ADAPTABLE AND FLEXIBLE FRAMEWORK FOR ASSISTIVE LIVING OF COGNITIVELY IMPAIRED PEOPLE

Fig. 4.

357

Ontology evolution after semantic Plug&Play integration of new assistive service.

Once these rules are trigged, the patient is considered as performing a deviant activity “ShowerTooLong.” Therefore, the
two rules provided in Section IV-A for service and device selection are activated. An alert is first sent to the patient through
a speaker in the shower to remind him to end his shower, then
to the nurses through their smartphones and a nursing console
if he is unable to solve his problem. Fig. 4 shows the evolution
of the ontology with the integration of the new assistive service
“ShowerTooLongAlert” and its related sensors and devices, and
then the provision of this service after a context change where
the patient is showering for too long.

TABLE I
SENSOR PLUG&PLAY AVERAGE TIME IN MILLISECONDS

TABLE II
CONTEXT UNDERSTANDING AND SERVICE PROVISION RESPONSE TIME IN
SECONDS

V. RESULTS
A. Validation of the Semantic Plug&Play Mechanism
The framework based on the semantic Plug&Play mechanism
was tested with low cost sensors, used in our deployment, such
as vibrator sensors, proximity sensors, and presence sensors. We
have calculated the response time needed due to the dynamic
aspect of the framework. The experiment starts when the sensor
is turned ON in the environment and end when it is turned
OFF. The time for semantic enrichment is calculated; however,
the time for the manipulation of the configuration tool was not
integrated as it differs depending on the user. Table I illustrates
our results.
In both the static and dynamic configurations, an average
time of 224 ms is needed for starting the real sensor and for the
ZigBee communication required to detect the sensor presence
by the framework. In addition, for the dynamic configuration,
we observed an additional average time of 413 ms needed to
represent a new sensor as a service in the framework. This is the

time required for generating and starting the bundle representing
the sensor on the gateway and for updating the semantic representation of the environment with the sensor information. The
average time for stopping and removing a sensor representation
from the gateway was about 74 ms. These results represent the
time difference between the static and dynamic configuration
for starting and stopping sensors. The time difference looks acceptable when we know that it allows us to add the dynamic
aspect to the framework.
Moreover, the time for context understanding, service selection, and service rendering was the same in both the static and
the dynamic configuration. Table II illustrates the results.
A load test experimentation for the validation of the semantic
Plug&Play approach has been realized through a progressive
augmentation of the number of sensors detected and integrated
into the framework on runtime. We have simulated the detection

358

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 1, JANUARY 2014

soning failure (12%), sensors problems (59%), and networking
problems (29%). The accuracy improvement related to reasoning failure was achieved based on rules verification with the use
of model checking techniques [23]. We have also conducted a
research work on uncertainty management and reasoning under
uncertainty in order to improve the framework accuracy related
to sensors failure and network problems.
B. Demonstration Guidelines

Fig. 5.

Semantic Plug&Play reasoning response time during load test.

of new sensors, the generation of their corresponding bundles,
and the update of the semantic representation with the newly detected sensors’ descriptions. The experimentation was realized
on a Windows XP machine running on an Intel Core i7 CPU,
with 4 GB of memory. We have analyzed the augmentation
of the semantic reasoning response time during the integration
of new sensors. We have used two semantic rules for this experimentation. The transition from 1 to 269 sensors caused an
increase in the number of instances in the ontology from 267 to
3000. We have reached the memory limit with 269 sensors.
As illustrated in Fig. 5, the reasoning response time regression
function shows a linear augmentation from 370 to 1100 ms. We
consider that the response time is acceptable even with 269
sensors plugged to the framework. The linear increase of the
semantic reasoner’s response time is also a very positive result
compared to other reasoners which are estimated to show an
exponential shape [17].
The framework was deployed during 17 months in three
rooms of a nursing home in Singapore with the participation
of eight patients and two caregivers [1]. Our on-field tests and
studies allowed us to raise different technical requirements, one
of the major requirement was the dynamism and adaptability
of the framework which was addressed in this paper. Other requirements are related to the privacy of the residents, multiple
people management, uncertainty handling, and design for failure. These requirements are not discussed in this paper and will
be the subject of other publications. The deployment has started
with a classical static framework with monolithic structure and
imperative reasoning to finally end with the dynamic and adaptive framework presented in this paper. Consequently, we have
moved from a period of three days needed for a team of two research engineers to install the system during the first phase of the
deployment, to only 2–3 h during the last phase. The use of the
dynamic aspect has shown some accuracy problems in activity
recognition and service provisioning. During the deployment,
the accuracy was improved from 71% during the first phase to
83% at the end of the deployment. The measurement of the accuracy was achieved based on the analysis of the system logs
and the ground truth of performed activities collected from the
caregivers. Most of the accuracy problems were related to rea-

The deployment of our framework in the nursing home was
preceded by an investigation period of one year. During this period, we have conducted several visits, observation sessions, and
group discussions in order to analyze the situation of the patients
and identify their needs with the help of the professional caregivers. From our study in the pilot site, we have deduced that the
residents should always be encouraged to solve their problems
on their own before the intervention of a caregiver. Therefore,
with caregivers, we have decided that reminders for patients
should be a reasonable and acceptable solution to encourage
them to solve their activities of daily life’s problems. Moreover,
if patients did not react to reminders after a given number of
times customized for each patient, a notification would be sent
to the caregivers to take action.
A set of assistive services required for the eight patients
participating in the trial has emerged from this investigation.
These services have been modeled and validated using the model
checker tool PAT based on formal methods. PAT has allowed
us to verify critical properties of safety and liveness requirements [24].
We have selected the top three assistive services which are
the most requested by the professional caregivers and which
are technically feasible. We have committed ourselves to use
only low-cost and nonintrusive sensor to preserve the privacy of
the nursing home’s residents and caregivers. The three assistive
services provided are 1) wandering at night, 2) showering for
too long, and 3) leaving the washroom tap on. These assistive
services will certainly change if we target patients other than
the group participating in our trial. The dynamic aspect proposed in this paper allows the integration into the framework
of other assistive services that can be identified. Table III illustrates the three assistive services we have provided during our
deployment:
Fig. 6 presents the deployed hardware. In each room, we have
deployed a compact fanless debian machine, mounted with a
500-MB RAM/500-Hz CPU, a 8-GB Compact Flash drive, the
whole consuming only 5 W. On this mini-server, the assistive
service provider framework, the Euler reasoning engine, and
the sensors management system are running. The three assistive
services were installed on the assistive service provider framework. Sensors related to these services have been deployed in
the shower and bedroom. They communicate with the sensors
management system through a Crossbow node connected via
serial port to the mini-server, serving as a gateway. The assistive
service provider framework sends reminders and notifications to
the nursing console using WiFi, to the tablets and smartphones
using 3G, and to the Bluetooth speakers using Bluetooth. The

ALOULOU et al.: ADAPTABLE AND FLEXIBLE FRAMEWORK FOR ASSISTIVE LIVING OF COGNITIVELY IMPAIRED PEOPLE

TABLE III
THREE ASSISTIVE SERVICES DEPLOYED IN THE NURSING HOME

359

of new assistive services and their related sensing technologies
on runtime. We also provide a demonstration guideline of our
deployment in a collaborating nursing home in Singapore.
ACKNOWLEDGMENT
The authors would like to express their gratitude to the residents and staff of the Peacehaven nursing home in Singapore,
for their precious involvement in our study.
REFERENCES

Fig. 6.

System hardware deployment.

nursing console also receives collected data from the mini-server
and then forwards them through 3G to a remote server in our
premises. The remote server is used for data collection and processing, and for hardware failure notifications.
VI. CONCLUSION
In this paper, we propose an approach allowing an adaptive
and extendible AAL solution that responds to the evolution of
cognitively impaired patients’ needs. This approach is based
on a semantic Plug&Play mechanism enabling the integration

[1] H. Aloulou, M. Mokhtari, T. Tiberghien, J. Biswas, C. Phua, J. H. K. Lin,
and P. Yap, “Deployment of assistive living technology in a nursing home
environment: Methods and lessons learned,” BMC Med. Informat. Decis.
Making, vol. 13, no. 1, p. 42, 2013.
[2] D. Fensel, Ontologies: A Silver Bullet for Knowledge Management and
Electronic-Commerce. Berlin, Germany: Springer-Verlag, 2000.
[3] M. Morris, J. Lundell, E. Dishman, and B. Needham, “New perspectives
on ubiquitous computing from ethnographic study of elders with cognitive
decline,” in UbiComp 2003: Ubiquitous Computing. New York, NY,
USA: Springer, 2003, pp. 227–242.
[4] T. Adlam, R. Faulkner, R. Orpwood, K. Jones, J. Macijauskiene, and
A. Budraitiene, “The installation and support of internationally distributed
equipment for people with dementia,” IEEE Trans. Inf. Technol. Biomed.,
vol. 8, no. 3, pp. 253–257, Sep. 2004.
[5] A. Mihailidis, J. Boger, T. Craig, and J. Hoey, “The coach prompting
system to assist older adults with dementia through handwashing: An
efficacy study,” BMC Geriatr., vol. 8, no. 1, p. 28, 2008.
[6] M. Chan, E. Campo, and D. Esteve, “Assessment of elderly mobility using
a remote multisensor monitoring system,” Stud. Health Technol. Informat.,
vol. 90, pp. 72–77, 2002
[7] A. Hauptmann, J. Gao, R. Yan, Y. Qi, J. Yang, and H. Wactlar, “Automated
analysis of nursing home observations,” IEEE Pervas. Comput., vol. 3,
no. 2, pp. 15–21, Apr./Jun. 2004.
[8] A. Ranganathan, C. Shankar, and R. Campbell, “Application polymorphism for autonomic ubiquitous computing,” Multiagent Grid Syst., vol. 1,
no. 2, pp. 109–129, 2005.
[9] M. Ghorbel, M. Mokhtari, and S. Renouard, “A distributed approach
for assistive service provision in pervasive environment,” in Proc. 4th Int.
Workshop Wireless Mobile Appl. Serv. WLAN Hotspots, 2006, pp. 91–100.
[10] C. Gouin-Vallerand, B. Abdulrazak, S. Giroux, and M. Mokhtari, “A
software self-organizing middleware for smart spaces based on fuzzy
logic,” in Proc. 12th IEEE Int. Conf. High Perform. Comput. Commun.,
2010, pp. 138–145.
[11] M. Pathan, K. Taylor, and M. Compton, “Semantics-based plug-and-play
configuration of sensor network services,” in Proc. 3rd Int. Workshop
Semant. Sens. Netw., 2010, pp. 1–16.
[12] D. López-de Ipiña, A. Almeida, U. Aguilera, I. Larizgoitia, X. Laiseca,
P. Orduña, A. Barbier, and J. Vazquez, “Dynamic discovery and semantic
reasoning for next generation intelligent environments,” in Proc. IET 4th
Int. Conf. Intell. Environments, 2008, pp. 1–10.
[13] S. Helal, “Programming pervasive spaces,” IEEE Pervas. Comput., vol. 4,
no. 1, pp. 84–87, Jan.–Mar. 2005.
[14] T. Erl, SOA Design Patterns. Englewood Cliffs, NJ, USA: Prentice–Hall,
2009.
[15] D. Han and J. Lim, “Design and implementation of smart home energy
management systems based on zigbee,” IEEE Trans. Consum. Electron.,
vol. 56, no. 3, pp. 1417–1425, Aug. 2010.
[16] T. Perumal, A. Ramli, C. Leong, K. Samsudin, and S. Mansor, “Interoperability among heterogeneous systems in smart home environment,” in
Web-Based Information Technologies and Distributed Systems. Atlantis
Press, Paris, France: 2010, pp. 141–157
[17] T. Tiberghien, M. Mokhtari, H. Aloulou, and J. Biswas, “Semantic reasoning in context-aware assistive environments to support ageing with
dementia,” in Proc. 11th Int. Semantic Web Conf., 2012, pp. 212–227.
[18] J. Domaschka, H. Schmidt, F. J. Hauck, R. Kapitza, and H. P. Reiser,
“Dosgi: An architecture for instant replication,” in Proc. Suppl. Proc.
39th Annu. IEEE/IFIP Int. Conf. Depend. Syst. Netw., 2009, pp. 1–2.
[19] F. Jammes, A. Mensch, and H. Smit, “Service-oriented device communications using the devices profile for web services,” in Proc. 3rd Int.
Workshop Middleware Pervas. Ad-Hoc Comput., 2005, pp. 1–8.
[20] D. Guinard, V. Trifa, S. Karnouskos, P. Spiess, and D. Savio, “Interacting
with the SOA-based internet of things: Discovery, query, selection, and

360

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 1, JANUARY 2014

on-demand provisioning of web services,” IEEE Trans. Serv. Comput.,
vol. 3, no. 3, pp. 223–235, Jul.–Sep. 2010.
[21] O. Dohndorf, J. Kruger, H. Krumm, C. Fiehe, A. Litvina, I. Luck, and
F. Stewing, “Towards the web of things: Using DPWS to bridge isolated
OSGi platforms,” in Proc. 8th IEEE Int. Conf. Pervas. Comput. Commun.
Workshop, 2010, pp. 720–725.
[22] P. Kinney, “Zigbee technology: Wireless control that simply works,” in
Proc. Commun. Design Conf., 2003, vol. 2, pp. 1–20.
[23] V. Lee, Y. Liu, X. Zhang, C. Phua, K. Sim, J. Zhu, J. Biswas, J.
Dong, and M. Mokhtari, “ACARP: Auto correct activity recognition rules
using process analysis toolkit (PAT),” Impact Analysis of Solutions for
Chronic Disease Prevention and Management. New York, NY, USA:
Springer, 2012, pp. 182–189

[24] Y. Liu, X. Zhang, J. Dong, Y. Liu, J. Sun, J. Biswas, and M. Mokhtari,
“Formal analysis of pervasive computing systems,” in Proc. 17th Int. Conf.
Eng. Complex Comput. Syst., 2012, pp. 169–178.
[25] J. Biswas, M. Mokhtari, J. Dong, and P. Yap, “Mild dementia care at home–
integrating activity monitoring, user interface plasticity and scenario verification,” Aging Friendly Technology for Health and Independence. New
York, NY, USA: Springer, 2010, pp. 160–170.

Authors’ photographs and biographies not available at the time of publication.

