1224

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

Predicting Days in Hospital Using Health
Insurance Claims
Yang Xie, Student Member, IEEE, Günter Schreier, Senior Member, IEEE, David C. W. Chang, Sandra Neubauer,
Ying Liu, Stephen J. Redmond, Senior Member, IEEE, and Nigel H. Lovell, Fellow, IEEE

Abstract—Health-care administrators worldwide are striving to
lower the cost of care while improving the quality of care given.
Hospitalization is the largest component of health expenditure.
Therefore, earlier identification of those at higher risk of being hospitalized would help health-care administrators and health insurers to develop better plans and strategies. In this paper, a method
was developed, using large-scale health insurance claims data, to
predict the number of hospitalization days in a population. We
utilized a regression decision tree algorithm, along with insurance
claim data from 242 075 individuals over three years, to provide
predictions of number of days in hospital in the third year, based
on hospital admissions and procedure claims data. The proposed
method performs well in the general population as well as in subpopulations. Results indicate that the proposed model significantly
improves predictions over two established baseline methods (predicting a constant number of days for each customer and using
the number of days in hospital of the previous year as the forecast
for the following year). A reasonable predictive accuracy (AUC
= 0.843) was achieved for the whole population. Analysis of two
subpopulations—namely elderly persons aged 63 years or older in
2011 and patients hospitalized for at least one day in the previous
year—revealed that the medical information (e.g., diagnosis codes)
contributed more to predictions for these two subpopulations, in
comparison to the population as a whole.
Index Terms—Australia, big data, health care, health insurance
claims, hospitalizations, predictive modeling.

I. INTRODUCTION
DENTIFYING and managing patients most at risk within
the health-care system is vital for governments, hospitals,
and health insurers but they use different metrics for identifying
patients they perceive to be at most risk [1]. Hospitals focus on
readmission rate [2], [3] and cumulative risk of death during
hospitalization [4]. Accurately predicting these indicators could
assist in allocating limited resources and, thus, improve the
hospital’s operational efficiency.
Health insurers are mostly concerned with insurance risk because they agree to reimburse health-related services in exchange for a fixed monthly premium. Poor risk measures would

I

Manuscript received October 18, 2014; revised January 16, 2015; accepted
February 6, 2015. Date of publication February 11, 2015; date of current version
July 23, 2015. This work was supported under the Australian Research Council’s
Linkage Projects funding scheme (project number LP0883728) and the HCF
Foundation.
Y. Xie, D. C. W. Chang, Y. Liu, S. J. Redmond, and N. H. Lovell are with
the Graduate School of Biomedical Engineering, University of New South
Wales, Sydney, N.S.W. 2052 Australia (e-mail: claire.yangxie@gmail.com;
z2274302@gmail.com; ying.liu@student.unsw.edu.au; s.redmond@unsw.edu.
au; n.lovell@unsw.edu.au).
G. Schreier and S. Neubauer are with the AIT Austrian Institute of Technology GmbH 8020, Graz Austria (e-mail: guenter.schreier@ait.ac.at; sandra.neubauer.fl@ait.ac.at).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2015.2402692

likely result in excessive reimbursements. Therefore, one of the
most obvious goals for health insurers is to identify high-risk
customers by predicting their health-care expenditure. Various
predictive models have been developed to identify high-risk customers by predicting health-care expenses [5]. Traditional prediction models have used demographic information and prior
costs to predict future costs [1]. More sophisticated models that
incorporate diagnoses [6], [7], drug claims [6], [7], and selfreported health status data [8] have been shown to improve
prediction performance. Zhao et al. [6] reported a coefficient
of determination (R2 ) of 0.168 when both drug and diagnosis
were used to estimate costs for the coming year. Bertsimas et al.
proposed two models: a decision tree model and a clustering
model [7] to improve the performance of an earlier model based
on classical regression models [6], [9].
Since hospitalization is usually the largest component of
health expenditure [10], a separate identification of subpopulations at higher hospitalization risk could improve current underwriting processes and pricing methodologies. Moreover, insurance companies also manage insurance risk by using specific
interventions in different subpopulations (especially high-risk
groups) to minimize the resources they require [11]. Programs
that use case and disease management have been developed
which target different subgroups of customers, such as aged
care programs, chronic disease programs, and more recently
telehealth programs, all of which have been shown to improve
health-care outcomes. Disease management programs were reported to improve health quality [12], while telehealth programs
reduced hospitalization expenditures and rehospitalization rate
[13], [14]. Therefore, if individuals who will be hospitalized frequently can be identified prior their episodes of high utilization,
they can be engaged in a care management program that would
help moderate their cost, while simultaneously improving their
quality of life [1].
In 2009 and 2010, hospitals comprised by far the largest
component of health expenditure in Australia, consuming 40%
of regular health spending [10]. Furthermore, the Australian
Productivity Commission, an independent research and advisory body of the Australian Government, pointed out (in their
report on government services in 2013) that around $3 billion
Australian dollars (AUD) were spent on unnecessary public
hospital admissions annually [15]. Earlier identification of those
at risk would also help reduce unnecessary hospitalizations
and potentially save taxpayers billions of dollars every year.
From various perspectives, better prediction of hospitalizations
will enable earlier intervention, reducing costs, and improving
quality of life.
The aim of this paper is to develop a model that predicts the
total number of days spent in hospital during a calendar year for

2168-2194 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

XIE et al.: PREDICTING DAYS IN HOSPITAL USING HEALTH INSURANCE CLAIMS

1225

TABLE I
SAMPLE DEMOGRAPHIC STATISTICS OF AGE AND GENDER IN YEAR 2010

individuals from a general population, using large-scale health
insurance claims data. Since insurance claims have strong socioeconomic characteristics, their power in predicting clinical
targets, such as hospitalizations, are seldom investigated. A relevant recent study has been performed by the authors in a data
mining competition called the “Heritage Health Prize (HHP).”
This competition also aimed to predict the number of days in
hospital (DIH) for a calendar year. It focused on reducing prediction error calculated in a given equation by optimizing the
predictive power of various sophisticated algorithms [16]. A
final ranking of 40 out of 1300+ teams [17] was achieved by
the authors, and—in terms of the measure for the quality of
prediction—the difference in performance (0.467) relative to
the best scores (0.461) was very small. For confidentiality reasons, the dataset was strongly pseudonymized and simplified,
with considerable details missing. For example, only hierarchy
groupings of diagnosis and procedure codes were provided and
limited information about services rendered at hospital were
included.
The key novelties of this current study are: 1) the dataset
that we were provided contained more details on the in-hospital
service level than that have typically been available in previous
research; 2) model performance was described using various
statistical parameters rather than summarizing the goodness of
prediction with only one measure; 3) in “Big Data” terms, we
should be able to deal not only with a dataset with a large “volume” of individuals but also with a high degree of “variability.”
This allowed us to investigate the predictive power of models
incorporating data from different domains (e.g., demographic
information, medical information etc.) and at the same time for
different demographic subpopulations.

∗
Amount charged for customers without hospitalization should ideally be $0. However,
136 out of 220 376 customers without hospitalization somehow had a nonzero amount
charged, which could be due to data error. This number is presented to depict the real
dataset.

II. METHODS

DIH in different bins. Both tables are based on data for the 2010
calendar year.

Age

Female

Male

Unknown
< 10
10–19
20–29
30–39
40–49
50–59
60–69
70–79
80+
All ages

9 563
10 936
11 500
10 259
16 727
18 957
14 152
9 847
5 012
4 844
111 797

6 390
11 341
11 972
8 882
13 818
16 650
13 101
9 359
5 009
3 903
100 425

Gender unknown
23 589
15
28
859
2 061
1 477
854
429
204
337
29 853

Total
39 542
22 292
23 500
20 000
32 606
37 084
28 107
19 635
10 225
9 084
242 075

TABLE II
DISTRIBUTION OF DIH IN DIFFERENT BINS IN YEAR 2010
DIH

0
1
2
3
4
5
6
7+

Customers

% customers

Average amount
charged per
customer (AUD)

Total amount
charged (AUD)

% total amount
charged

220 376
12 095
2 814
1 266
1 111
907
522
2 984

91.04
5.00
1.16
0.52
0.46
0.37
0.22
1.23

1
2 440
5 268
6 463
7 688
8 948
10 746
24 055

261 909*
29 475 430
14 823 047
8 181 616
8 541 859
8 115 858
5 609 287
71 779 707

0.18
20.08
10.10
5.57
5.82
5.53
3.82
48.90

A. Dataset and Summary Statistics
1) General Description of Data Source and Data Overview:
This study used health-care records generated when hospitals
send claims to a health insurance company to receive reimbursement for their services. Data were available for a total of three
years, with the periods from the initial two years (January 1,
2010–December 31, 2011) serving as a two-year observation
period and a one-year prediction period from January 1, 2012 to
December 31, 2012. Information from the two-year observation
period was used to predict outcomes in the third year.
This dataset included the hospital claims data for 242, 075
individuals from a private health insurer called Hospitals Contribution Fund of Australia (HCF), one of Australia’s largest
combined registered private health fund and life insurance organizations. The dataset included hospital admission administrative records and hospital procedure claims, as well as enrollment
information on the period an individual or his/her family was
covered by the insurance policy. The data also contained basic
demographic information of customers, such as age and gender
(the dataset was received after pseudonymization to prevent the
possibility of identifying individuals).
2) Summary Statistics: The following tables summarize the
basic statistics of the data. Table I shows the demographics,
including age and gender. Table II shows the distribution of

B. Data Manipulation and Aggregation
Before building a predictive model, the raw data were recoded and organized into a structure that allowed for efficient
computing.
1) Three Levels of Information: The data provided had three
levels of information: customer level, hospital admission level,
and hospital procedure claim level.
Customer level contained customer demographics (e.g., age
and gender) and information about the health insurance products customers buy. Every customer had at least one entry of
such information. Customers who updated their personal information during the study period could have duplicate records.
For the cases where multiple records for individual customers
were provided, only the first record was taken—the nearest to
the start of the study period.
Hospital admission level included hospital admission claims
that have detailed information about the customer and the
provider. Key data elements contained in hospital admission
claims include the primary diagnosis, primary procedure, secondary diagnosis, and the provider. Hospital admissions can
be categorized broadly as inpatient or outpatient. Since HCF
does not cover outpatient services, this part of the data was
not available. Inpatient claims are generated as a result of an

1226

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

admission to a facility involving same-day discharge or an
overnight stay. Because of the duration of inpatient admissions, there can be more than one admission claim record;
these records were aggregated to one unique entity for each
admission. When calculating DIH, both same-day admissions
and one-day overnight admissions were counted as one day. A
customer could have multiple admissions within each year, and
thus, have multiple entities at this level.
Hospital procedure claim level contains hospital services delivered during a hospital admission. It includs service item information such as item type (e.g., same-day accommodation,
overnight accommodation, prosthesis, theater, etc.). It also contains information on the cost of each procedure. Each procedure
claim is related to a hospital admission record, and a hospital admission record can be associated with multiple procedure
claims.
Only the services covered by HCF were included in this
database—in Australia, Medicare (Australia’s social health insurer) concurrently covers most nonhospital services, and these
data were not available.
2) Definition of Key Clinical Data Elements: There were five
data elements that contained medical information and involve
different coding schemes.
Primary diagnosis code: Each admission would be associated with a diagnosis or condition which was considered chiefly
responsible for the hospital admission. It was coded using ICD10-AM (International Statistical Classification of Diseases and
Related Health Problems, Tenth Revision, Australian Modification) codes [18]. ICD-10-AM is abbreviated as ICD-10 in the
text below for convenience.
Primary procedure code: Admissions also included a procedure code for the procedure that consumed the largest amount
of hospital resources. The coding scheme used was developed
by the Australian Classification of Health Interventions [19].
Diagnosis-related group: Codes for the Australian Refined
Diagnosis-Related Group (AR-DRG) were also associated with
hospital admissions [20]. This was the code used to classify
acute inpatients. It was based on the codes allocated to the
diagnoses and procedures for each episode of care.
Illness code: Most of the time, Medicare Benefits Schedule (MBS) codes were used here, which was a listing of the
Medicare services subsidized by the Australian government, including a wide range of consultations, procedures and tests, and
a schedule fee for each of these items [21]. If no MBS code
was found, other codes like ICD-10 and AR-DRG were used
instead. A reference table for illness codes existed, in which the
treatment type, illness group (an attempt to group illnesses sensibly, done by HCF), and specialty description could be found
and linked to each illness code.
Item code: Procedure items had various types, describing the
nature of the service delivered or procedure performed. Each
procedure item had an item code, which had a different format
according to the type of item. For example, for public and private
hospital accommodation claims, different characters indicated
different information, such as accommodation type, primary
patient classification, and hospital type. For theater, as a general
rule, the last two characters indicated the theater fee band, and
for prostheses, the first two characters indicated the supplier.
Secondary diagnosis codes were also associated with admissions, and were only used to compute the Charlson Index, which

Fig. 1. Data completeness measured using the method described in Section
II-B3. The numbers indicate percentage of completeness.

will be described in Section II-B4. Since only a small proportion of diagnoses codes could be used to generate the Charlson
Index, secondary diagnosis codes were not introduced as major
clinical elements here. Instead, they are displayed in the final
feature table (see Table III).
3) Data Completeness: Data completeness is an issue that
should not be ignored during data analysis. The completeness
was estimated by measuring indicators shown in Fig. 1. Out of
242 075 customers, 233 716 (96.55%) had eligibility for at least
one year from January 1, 2010 to December 31, 2010, 225 421
(93.12%) had eligibility for at least two complete years from
January 1, 2010 to December 31, 2011, and 217 111 (89.69%)
customers had eligibility extending also over the result period.
Naturally, the customer base was not constant due to customers
either entering the fund, or leaving (including as a result of
death). From a modeling perspective, an ideal situation would
be that all subjects stay in the fund for the whole three years
under analysis. However, since the customer cohort changes,
predictions may also be done for some customers who will no
longer be with the fund in the following year. Therefore, it is not
necessary for subjects to have a complete three-year full coverage. We only needed the customers to have enrolled from no later
than January 1, 2010. Moreover, as can be seen, 87.09% of customers had unique profile entities without duplicates. 87.67%
of customers had gender information and 93.41% had age information. Regarding the five medical data elements, 72.35% of
admissions had clear ICD-10 primary diagnosis codes, 74.11%
had DRG codes, 98.26% had illness codes, and 57.21% had
ICD-10 primary procedure codes. Nearly, 100% of hospital procedure claims were assigned item codes. The completeness of
DRG codes, primary diagnosis codes, and primary procedure
codes was not perfect because this information was not available to HCF (a private health insurer) for public hospital visits
and procedures claimed through Medicare, as HCF and Medicare do not share these data.
4) Feature Extraction: The source variables contained various types of data, such as dates, numeric, text; therefore, at the
beginning, source variables must be preprocessed before they
can be used for modeling. Numeric variables were kept in their
numeric format. For all the categorical variables, values were
replaced by integers for the purpose of making the entire feature
matrix numeric to ease computation. After making the feature
matrix purely numeric, the following steps were performed.
First, source variables were processed at their original information levels to generate additional features through processes
of computation and expansion.

XIE et al.: PREDICTING DAYS IN HOSPITAL USING HEALTH INSURANCE CLAIMS

1227

TABLE III
SUMMARY OF THE COMPOSITION OF THE FEATURE SET
Source variable

Level1

Type2

Computation3

Expansion4

Aggregation5

M

N

N/A

N/A

M
M
M

N
C
C

Age10; Age60
N/A
N/A

M
M
M

C
C
C

M
M
M
M
A

Number
of features

Feature
subsets

N/A

1

1

B (Age10)
B
B

N/A
N/A
N/A

16
5
6

1
1
1

N/A
N/A
N/A

N/A
B
B

N/A
N/A
N/A

1
10
14

1
1
1

C
C
C
C
N

N/A
N/A
N/A
N/A
Count

N/A
B
B
B
N/A

N/A
N/A
N/A
N/A
Sum

1
5
10
30
1

1
1
1
1
2

A

C

N/A

B

Ab

3

2

A
A

N
C

C
C
C
N
C
C
C
C
C

An
Ab (DRG_BASIC;
DRG_CC;
DRG_MDC;
DRG_subMDC)
Ab
Ab; Ac
Ab; Ac
An
Ab
Ab
Ab
Ac
Ab

2
2

A
A
A
A
A
A
A
A
A

N/A
B (DRG_BASIC;
DRG_CC;
DRG_MDC;
DRG_subMDC)
B
B; D
D
N/A
D
B
B
N/A
B

16
114

Type of hospital (public or private)
Primary diagnosis code
Primary procedure code
Actual days of the stay
Major disease category
Month of the hospital admission
Type of agreement between HCF and hospital
Type of care provider
Specific categorization of hospitals (depicting
hospital sizes)
Secondary diagnosis and procedure

N/A
DRG_BASIC;
DRG_CC; DRG_MDC;
DRG_TEXT;
DRG_subMDC
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A

3
367
54
18
25
15
6
4
11

2
2
2
3
2
2
2
2
2

A

C

N/A

An (Charlson
index)

18

2

Description of specialty group
Type of stay status in hospital (e.g., same-day,
overnight accommodation,...)
Type of treatment (e.g., surgical, obstetric,...)
Amount charged for each procedure
Benefit paid at basic rate for each procedure
(how much HCF paid)
Type of contract between care providers and
HCF
Benefit paid at supplementary rate for each
procedure
Type of hospital service item (e.g.,
accommodation, theatre, prosthesis,...)
Item code (code for procedure items)

A
A

C
C

Charlson index; Number
of secondary diagnoses;
Number of secondary
procedures
N/A
N/A

B
B

Ab
Ab

57
7

2
2

A
P
P

C
N
N

N/A
N/A
N/A

B
N/A
N/A

Ab
An
Sum

6
17
1

2
3
3

P

C

N/A

B

Ab

19

2

P

N

N/A

N/A

Sum

1

3

P

C

N/A

B

Ab

17

2

P

C

B
(IC_ACC_TYPE;
IC_PAT_CLASS)

Ab
(IC_ACC_TYPE;
IC_PAT_CLASS)

29

2

Count of hospital procedure claims for each
customer in each year
Patient classification code used to determine
hospital accommodation benefits
Multiple source elements used

P

N

IC_ACC_TYPE;
IC_PAT_CLASS;
IC_THEATRE;
IC_PROSTHESIS
Count

N/A

Sum

1

2

P

C

N/A

N/A

Sum

1

2

A&C

N; C

Admission moment
features; Number of
admissions in each year
times age; Day of the
admission (e.g.,
Monday, Tuesday,...)

N/A

Sum

5

4

Year of the occurrence of hospital admission
(2010, 2011 or 2012)
Age
Status of health policy held by customer
Type of membership (e.g., new customer,
previous dependent in health policy,...)
Post code of address
Health insurance product
Dependent relationship in policy held by
customer (e.g., policy holder, spouse,...)
Scale (family or single)
Gender
State code of address
Title code (e.g., Mr, Ms,...)
Number of admissions for each customer in
each year
Contract status (indicates if the procedure
claim was paid under an HCF arrangement)
DAYS2PREV: days to previous admission
Diagnosis-related group

1

Information level of source variable: customer (M), admission (A), procedure (P). 2 Type of source variable: numeric (N), categorical (C). 3 Computation methods refer to Section
II-B4. 4 Expansion method: binary expansion (B), dominant expansion (D), not applicable (N/A). 5 Aggregation method: aggregation of binary features (Ab), in which descriptive
statistical operator sum was employed; aggregation of numeric features (An), in which descriptive statistical operator employed included count of elements, sum, mean, standard error of
the mean, standard deviation, median, maximum and minimum values, range between maximum and minimum, median and the most recent element; aggregation of categorical features
(Ac), in which descriptive statistical operator used were sum, count of unique elements, the most frequent element, and the most recent element; not applicable (N/A); if not one of the
above, features were simply summed up when being aggregated. The four feature subset classes are: (1) demographic features; (2) medical features extracted from clinical information;
(3) prior cost/DIH features, and; (4) other miscellaneous features.

1228

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

Computation processes were applied to generate additional
features that needed further calculation. In addition to its numeric format, age was categorized into different age bins by
decade, and a categorical feature named “Age10” was generated.
A binary indicator of age greater than 60 years or not was also
used. Besides using numerical representations of the primary
AR-DRG codes (DRG_TEXT and DRG_BASIC), they were
decoded into additional features; e.g., major disease category
(DRG_MDC), major disease subcategories (DRG_subMDC),
and comorbidity or complication (DRG_CC) [20]. In addition
to the ICD-10-coded primary diagnosis, the list of ICD-10 coded
secondary diagnoses was available for each hospital admission.
From the secondary diagnoses, comorbidity scores were computed, utilizing the respective lookup tables that give weights
to certain ICD-10 diagnoses according to the original and the
updated Charlson Index [22], [23], respectively. Two “moment”
features were also computed that weight the number of admissions in a given month by the month’s count number; i.e.,
1–12 in a linear (first moment) or quadratic (second moment)
way, respectively. These features are supposed to capture the
notion that admissions are more likely to be followed by admissions in the next year, if they occurred closer to the end of
the previous year. For hospital accommodation items, features
of accommodation type (IC_ACC_TYPE) and patient classification (IC_PAT_CLASS) were extracted from accommodation
item codes. Features of theatre fee band (IC_THEATRE) and
supplier of prosthesis (IC_PROSTHESIS) were also extracted.
Expansion was applied to categorical variables. For those
categorical variables without too many unique categories, such
as “Age10” and gender, a “binary” expansion was performed
to generate additional binary grouping features. Each grouping
feature was a binary indicator with “1” indicating that entities
fell into this category and “0” indicating that they did not.
For some of those categorical variables with many unique
categories, additional features were developed to reduce the
number of categories into a moderate number using an external
hierarchy grouping scheme. Using the ICD-10 primary diagnosis code mentioned in Section II-B2 as an example, although
coding for medical claims starts with a clinician, it is most often completed and submitted by a separate dedicated billing
operator. Because of the inevitable variations in interpretations
introduced by these practices, and the aim of reducing the data
to a more manageable size, coding groups were used rather
than individual codes. By grouping into the 22 chapters according to body systems, etiology, or situations affecting the onset
of the conditions and then dividing them into blocks, which
contain a series of three-digit category codes that grouped conditions, the 6292 specific codes were reduced to 287 groups
[24]. Both the source variable containing specific codes and
newly developed hierarchy categorical variable containing reduced categories were kept. Afterward, a “binary” expansion
was also applied to the hierarchy categorical variable and 287
binary ICD-10 primary diagnosis grouping variables were added
to the feature matrix.
For those categorical variables with many unique categories,
a “dominant” expansion was also applied by selecting those
codes that appear frequently in the claims and using them
as grouping variables. For instance, the 50 most frequently

occurring ICD-10 primary diagnosis codes were chosen to be
expanded to 50 binary grouping features. These 50 specific
ICD-10 codes were selected by setting a criteria that each
selected code should have at least 100 hospital admissions associated with it. For other categorical variables with many unique
categories, but for which no suitable hierarchy grouping scheme
could be found, a “dominant” expansion was also performed.
Aggregation: As described in Section II-B1, three information levels exist. Since we predicted a number of DIH for each
customer in a particular year, the prediction would be performed
at the customer level. To further process the feature matrix, all
information from levels other than the customer level had to
be aggregated into the customer level and sorted into respective
year bins. When aggregating the numeric features extracted from
the admission and the procedure claim levels into the customer
level, such as prior cost information and prior DIH, descriptive
statistics operators were employed, including the sum, mean,
standard deviation, median, maximum and minimum values,
range between maximum and minimum, median, and the most
recent element. Binary grouping features generated at the expansion stage were summed when being aggregated into the
customer level. For those categorical variables not present at
the customer level when aggregating, the descriptive statistical
operators such as sum, count of unique elements, the most frequent element, and the most recent element, were used. If not
specified, other features were summed during aggregation. It
needs to be pointed out that aggregation of information at the
procedure level went directly up to customer level without going
through the admission level in the middle.
5) Summary of the Features Extracted: After the aforementioned process, a total of 915 features were present in the feature
matrix. Table III summarizes all the features used in this study.
All features were categorized into four subsets based on the type
of source variable it was extracted from. The four subsets are:
1) demographic features, including personal information and
enrollment information; 2) medical features, containing clinical
information as extracted from diagnosis or procedure codes; 3)
prior cost/DIH features and; 4) other miscellaneous features.
Fig. 2 demonstrates how the prediction model was built using
information from the two-year observation period to predict
outcomes in the third year.
C. Predictive Methods
1) Baseline Models: To make meaningful comparisons, two
methods were used as baselines so that meaningful comparisons
could be made between the prediction models developed. The
first baseline model predicted the same number of days for all
customers. The number of days selected for this constant was
chosen to optimize one of the performance measures—rootmean-square-error (RMSE), which will be described later in
Section II-D1. In the second baseline model, the DIH of the
second year (2011) of the observation period was used as the
forecast for the DIH in the prediction year (2012).
2) Bagged Trees: A predictive model was built using bagged
regression trees, which is quick to train on large datasets [25],
[26]. Every tree in the ensemble is grown on an independently
drawn bootstrap replica of the data. Observations not included in

XIE et al.: PREDICTING DAYS IN HOSPITAL USING HEALTH INSURANCE CLAIMS

1229

TABLE IV
PERFORMANCE MEASURES
Measure

Equation


1
N

RMSE

N
i= 1

1−

ρ

6

(l n (p i + 1 )−l n (a i + 1 )) 2 )

 +∞

AUC

−∞

Sens.

Ntp
Ntp +Nf n
Ntp +Ntn
N
P o −P e
1 −P e


2
(a i −p i ) 2
(a i −m )

|a i −p i |
1− 
1−

R2
|R|

D. Performance Measures
1) Performance Metrics: Table IV gives an overview of the
performance indicators used in this study. The main performance indicator is referred to as the RMSE, and is the rootmean-square of the difference between the logarithm of the
estimated DIH and the logarithm of the true number of days
[16]. The logarithm (offset by +1 to avoid a logarithm of zero)
was used to reduce the importance assigned to those with many
hospital days. Use of this measure allowed comparison between
this study and the HHP competition. In order to capture different
aspects of the goodness of predictability, additional performance
measures were also reported. Table IV lists the measures and
their equations. In addition to RMSE, the Spearman rank correlation coefficient ρ was also calculated between the predicted
and actual number of DIH.
Customers can be categorized into two categories, those without hospital days (0 hospital days) and those with hospital
days (at least one hospital day) per year. Therefore, binary
classification analysis was applicable to the result. By setting a
threshold for the predicted number of hospital days, statistics including accuracy (Acc.), specificity (Spec.), sensitivity (Sens.),
Cohen’s kappa (κ), and area under receiver operating characteristic curve (AUC) metrics were calculated. The optimal results
were obtained with a threshold of 0.3 days applied to the continuous output estimate from the bagged tree regression model.
When the predicted value was smaller than 0.3 days, it was con-

R t p (T )R f p (T )dT
Ntn
Ntn +Nf p

κ

this replica are “out-of-bag” samples for this tree. To compute a
prediction from an ensemble of trees for unseen data, it takes an
average of predictions from each individual tree in the ensemble. The out-of-bag observations are used as a validation dataset
to estimate the prediction error, which helps to avoid severe
overfitting. Here, a function named “treebagger” in the statistics
toolbox of MATLAB R2013b (MathWorks, Natick, MA, USA)
was used to implement the algorithm [27]. After tuning parameters, the number of trees used in the bagging ensemble was
100, and the minimum number of observations (customers) per
tree leaf was 5. Other parameters, if not specified, were default
MATLAB settings [27].

N (N 2 −1 )

Spec.

Acc.
Fig. 2. Customer demographics, admission, and procedure claim data for year
2010, along with 2011 DIH were used to train the model. Later, at the prediction
stage, customer demographics, hospital admission, and procedure claim data for
year 2011 were used to predict the number of DIH in 2012.

[ln(p i + 1) − ln(a i + 1)]2



|a i −m m e d i a n |

N is the total number of customers in the population; p i is the predicted number of DIH
for the ith person; a i is actual DIH, i ∈ [1, N ]; m is the average DIH for population;
m m e d i a n is the median value of DIH for population; R t p (T ) and R f p (T ) are the
true positive rate (sensitivity) and the false positive rate (equals to 1−specificity) for a
given threshold T in a binary classification model; N t p is the number of hospitalized
patients who were correctly predicted as having ≥ 1 DIH; N t n is the number of subjects
who were correctly predicted as having 0 DIH; N f p is the number of subjects who were
predicted as having ≥ 1 DIH, but actually had 0 DIH; N f n is the number of subjects
who were predicted as having 0 DIH, but actually had ≥ 1 DIH. P o is the ratio of the
N tp +N f n
); P e
N
N
+N tn
+ ( f pN
×

probability of observed agreement between observation and prediction (
is the probability of random agreement
N f n +N tn
N

N tp +N f n
(
N

×

N tp +N f p
N

)

).

sidered as a prediction of no hospital days and vice versa. The
choice of threshold was empirically based on the fact that using
0.3 days as threshold gave the best κ.
The coefficient of determination R2 [5] was also calculated to
show the ability of this model to explain the variation. Bertsimas
et al. [7] proposed a new measure of |R| adjusted from R2 .
R2 measures the ratio of the improvement of predictability (as
measured with the sum of the squares of the residuals) of a
regression line compared with a constant prediction (the mean
of actual values), while |R| measures the reduction in the sum of
absolute values of the residuals compared with another constant
prediction (the median of actual values).
The importance of features was also measured using one criteria (“OOBPermutedVarDeltaError”) in the MATLAB “treebagger” function. It gives a numeric array containing a measure
of importance for each feature. For any variable, the measure is
the increase in prediction error if the values of that variable
are permuted across the out-of-bag observations. This measure is computed for every tree, then averaged over the entire
ensemble and divided by the standard deviation over the entire
ensemble.
2) Performance on Different Subpopulations: The performance was measured on four different subpopulations. Group
1 included the whole population. Group 2 included customers
born in or after the year 1948, while Group 3 was composed of
customers born before the year 1948. These subgroupings were
chosen since the average number of DIH increased substantially
between the ages of 61 and 65 years, as Fig. 3 indicates, and the

1230

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

TABLE V
PERFORMANCE METRICS FOR THE PROPOSED METHOD, EVALUATED ON DIFFERENT POPULATIONS

All subjects

Subjects born in or after 1948

Subjects born before 1948

1+ days group (all ages)

Model/dataset

RMSE

ρ

AUC

Spec. (%)

Sens. (%)

Acc. (%)

Train*
Predict
Baseline 1
Baseline 2
Train
Predict
Baseline 1
Baseline 2
Train
Predict
Baseline 1
Baseline 2
Train
Predict
Baseline 1
Baseline 2

0.281
0.381
0.428
0.490
0.237
0.305
0.330
0.399
0.477
0.701
0.787
0.879
0.440
0.780
0.890
1.238

0.458
0.344
N/A
0.272
0.419
0.288
N/A
0.211
0.644
0.449
N/A
0.361
0.776
0.369
N/A
0.208

0.958
0.843
N/A
0.634
0.964
0.820
N/A
0.604
0.949
0.814
N/A
0.677
0.965
0.703
N/A
N/A

94.47
91.81
N/A
93.46
97.32
95.15
N/A
94.34
72.82
65.45
N/A
86.66
78.40
47.79
N/A
N/A

72.97
43.17
N/A
32.94
62.12
26.28
N/A
26.29
97.45
81.64
N/A
48.00
98.93
78.94
N/A
N/A

92.56
87.50
N/A
88.10
94.81
90.28
N/A
89.53
77.86
68.77
N/A
78.74
85.01
58.02
N/A
N/A

κ

R2

|R |

0.595
0.311
N/A
0.264
0.602
0.225
N/A
0.206
0.508
0.330
N/A
0.347
0.693
0.219
N/A
N/A

0.287
0.150
−0.007
−0.205
0.296
0.109
−0.003
−0.365
0.270
0.130
−0.023
−0.166
0.382
0.191
−0.032
−0.351

0.087
−0.092
−0.183
−0.462
0.009
−0.186
−0.361
−0.567
0.160
−0.023
−0.128
−0.372
0.276
0.013
−0.080
−0.904

∗The “Train” model was tested with the same training data that were used to train it to give a measure of fit, whereas the other three models are all tested
using data from the third year. Shown are the results for testing with the training data on the model after training (with the same data) and results when
validating the trained model with the prediction dataset. Performances of baseline models 1 and 2 are also displayed.

Fig. 3.
data.

Average DIH per person by age for each of the three years of HCF
Fig. 4. Scatter-plots for bagged regression tree results for customers born
before year 1948 (those aged 63 years or older when the model was trained in
2011).

median age of 63 years in year 2011 was taken, corresponding
to a birth year 1948 in this dataset. In the whole population, 85%
of customers were born in or after 1948 and 15% of customers
were born before 1948. In addition, the model was evaluated
on a subpopulation (Group 4) in which customers had at least
one day (1+ days) in hospital in the year before the prediction
year (2012). It should be noted that, different to the other three
groups, in the 1+ days group, the cohort of customers used for
training and prediction were different. In this group, training
was performed using those customers who had at least one day
in hospital in 2010 and prediction was performed on customers
who had at least one day in 2011. These two subsets of customers were not the same cohort, but there was overlap. In the
prediction dataset of the 1+ days group, 70% of customers were
born in or after 1948 and 30% of customers were born before
1948.
III. RESULTS
A. Performance on Different Subpopulations
Table V summarizes the performance of the various models
when trained and tested on all the four populations. The results

for training data and prediction data, along with results of the
two baseline methods are presented.
Fig. 4 shows scatter-plots of the regression results for the
group born before the year 1948. The subplot on the left is for
training and while the right subplot is for prediction.
B. Evaluation of Features
The models’ predictive capability was investigated using the
feature subsets mentioned in Section II-B5 independently and
compared the predictions to the results when the algorithm used
all features. These results are displayed in Table VI for algorithms using demographic, medical, and past cost and DIH
features separately. Since the miscellaneous features comprise
a small group of heterogeneous features only, this was not analyzed.
The top 200 features for the four subpopulations mentioned
in Section III-A were also examined. Table VII lists some interesting top features extracted from ICD-10 primary diagnosis
code derived on the 1+ days group. Age was used as a reference
feature for comparison.

XIE et al.: PREDICTING DAYS IN HOSPITAL USING HEALTH INSURANCE CLAIMS

1231

TABLE VI
PERFORMANCE METRICS FOR PREDICTIONS USING VARIOUS FEATURE CATEGORY SUBSETS ONLY

All subjects

Subjects born in or after 1948

Subjects born before 1948

1+ days group (all ages)

Feature subset

RMSE

ρ

AUC

Spec. (%)

Sens. (%)

Acc. (%)

κ

R2

|R |

Demographic
Medical
Cost and DIH
All
Demographic
Medical
Cost and DIH
All
Demographic
Medical
Cost and DIH
All
Demographic
Medical
Cost and DIH
All

0.393
0.396
0.400
0.381
0.315
0.312
0.315
0.305
0.725
0.723
0.729
0.701
0.839
0.801
0.825
0.780

0.337
0.273
0.272
0.344
0.284
0.210
0.209
0.288
0.415
0.365
0.362
0.449
0.283
0.319
0.248
0.369

0.838
0.635
0.635
0.843
0.816
0.604
0.604
0.820
0.793
0.679
0.678
0.814
0.653
0.676
0.632
0.703

90.07
95.61
95.44
91.81
94.23
97.47
97.34
95.15
58.20
86.99
86.95
65.45
36.56
38.24
39.69
47.79

45.80
28.00
27.18
43.17
26.85
17.25
15.76
26.28
89.58
47.27
47.15
81.64
81.56
81.99
75.85
78.94

86.15
89.60
89.39
87.50
89.46
91.79
91.57
90.28
64.64
78.85
78.79
68.77
51.34
52.61
51.57
58.02

0.295
0.268
0.256
0.311
0.208
0.191
0.170
0.225
0.306
0.346
0.344
0.330
0.141
0.159
0.124
0.219

0.030
0.136
0.093
0.150
0.019
0.100
0.088
0.109
0.011
0.126
0.069
0.130
0.013
0.183
0.110
0.191

−0.142
−0.135
−0.151
−0.092
−0.231
−0.235
−0.247
−0.186
−0.068
−0.045
−0.061
−0.022
−0.066
−0.001
−0.032
0.013

The three feature subsets tested are: demographic features, medical features, and prior cost/DIH features. Subset of miscellaneous features were not used.

TABLE VII
AN EXAMPLE OF INTERESTING ICD-10 PRIMARY DIAGNOSIS FEATURES

IV. DISCUSSION AND CONCLUSION
A. Analysis and Summary of Results

Feature
ICD10_PREGN_E_02 (Oedema, proteinuria and
hypertensive disorders in pregnancy, childbirth and
the puerperium)
ICD10_PRINC_DIAG_N979 (Female infertility,
unspecified)
ICD10_PRINC_DIAG_Z312 (In vitro fertilization)
ICD10_PRINC_DIAG_C61 (Malignant neoplasm of
prostate)

Measure of importance
1.188

0.883
0.673
0.402

Age was used as a reference feature with an importance measure of 0.702. The definition
of this importance measure was described in Section II-D1.

Fig. 5. Distribution of the top 200 features among the four feature subsets:
(a) in the whole population; (b) in subjects born on or after 1948; (c) in subjects
born before 1948; (d) in the 1+ days group; (e) shows the percentage of the four
subsets with respect to the full feature set of 915 features.

Fig. 5 shows how the top 200 features are distributed among
the four feature subsets. Subplot Fig. 5(a)–(d) display the
distribution of the top 200 features across the whole population, subjects born or after 1948, subjects born before 1948, and
1+ days group. Fig. 5(e) shows the proportion of all features
among the four subsets.

A method for predicting future DIH has been developed using
features extracted from customer demographics, past hospital
admission, and hospital procedure claim data. The model was
developed using data from an observation period of two years
and was later evaluated based on data from a third year. In summary, Table V indicates that: 1) the proposed method improves
predictions over both of the baseline methods (as described in
Section II-C1) by reducing the RMSE measure and increasing
R2 and |R|; 2) from the view of coefficient of determination,
R2 and |R|, this method achieved the best performance on the
1+ days group, with an R2 of 19.1% compared to 15.0% for all
subjects, 10.9% for the young subpopulation, and 13.0% for the
group of customers born in or before 1948.
Table V also shows that the model achieved a high specificity
(95.15%) and a relatively low sensitivity (26.28%) on the test
set of customers born in or after 1948. There could be a variety of reasons causing this low sensitivity. One of the possible
explanations may be that younger customers are more likely
to be hospitalized for acute conditions that are unpredictable
or unexpected; therefore, it may be inherently more difficult to
make true positive predictions for younger people. In contrast,
for the older group, a moderate specificity (65.45%) and high
sensitivity (81.64%) were obtained. The specificity dropped in
comparison to the younger group and the whole population. A
similar pattern was exhibited in the 1+ days group, with a lower
specificity (48.05%) and a relatively high sensitivity (78.52%).
The underlying reason may be that people with medical conditions in previous years were well controlled and, therefore, are
less likely to be hospitalized in the future. Therefore, although
the model predicts that the customer would be hospitalized, this
prediction does not eventuate. Reasons for this warrant further
investigation.
Table VI shows for 1+ days group, when the three feature
subsets were used independently, the medical feature subset
achieved the best RMSE, R2 , κ, and ρ. While for the other three
groups, the difference of the performances of the three feature

1232

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 4, JULY 2015

subsets was not as significant as for 1+ days group. However,
best results were always achieved when using all features. This
phenomenon could indicate the presence of a synergy of predictors from different subsets. Best prediction accuracy might
be achieved when they are used in conjunction with each other.
When evaluated on the 1+ days group, the importance measure for age was around 0.702 with a ranking of 22 out of
915. As shown in Table VII, the ICD-10 diagnosis code related to pregnancy with oedema, proteinuria and hypertensive
disorders in pregnancy, child birth, and the puerperium has a
surprisingly high importance of 1.188. ICD-10 diagnosis codes
N979 (female infertility, unspecified) and Z312 (in vitro fertilization) have importance measure values of 0.882 and 0.672,
while a diagnosis code about malignant neoplasm of prostate
(C61) also was ranked at 68 out of 915 (importance measure
value of 0.402). As mentioned in Section II-B4, an expansion of
the most frequent ICD-10 codes was performed. Fifty specific
codes were expanded to grouping variables, but only these three
came in the top 200. However, plotting similar regression figures
as Fig. 3 for these ICD-10 diagnosis features and DIH revealed
no strong linear correlations. A hypothesis for why these codes
are highly ranked could be that they are associated with rather
homogeneous patient groups without many comorbidities, and
therefore are more predictive.
Fig. 5 conveys the following information: 1) although prior
cost and DIH features only comprise 4% of all features, they
stably contribute 11% or more to the top 200 features for all
the four customer groups, which implies the strong predictive
value of such features; 2) from Fig. 5(b)–(d), the percentage of
demographic features gradually declines while the proportion of
medical features increases. This is congruent with the notion that
the density of medical information increases among the three
subpopulations. The 1+ days group has the densest medical
information; therefore, medical features greatly improved the
prediction for this group. For subpopulations where medical
information was not plentiful, such as the subjects born in or
after 1948, only 57% of the top features are medical features
and prediction relies more on demographic features, past cost,
and DIH features.

B. Comparison With Other Studies
Comparisons across studies that use different datasets are difficult because the average prediction error is highly dependent
on the dataset. Nevertheless, we compared the RMSE as obtained here to the RMSE reported by the top scoring teams in
HHP. The HHP dataset (insurance claims in USA) was similar
to that presented here. However, since it was made available to
the public, it had to be pseudonymized more severely, which
reduced the information content. At the final leader board of
the HHP competition, the top team achieved an RMSE of 0.461
[17], while an optimized constant value benchmark achieved an
RMSE of 0.491. As a comparison, using the dataset presented
in this paper, an optimized constant value benchmark (baseline
model 1) achieved an RMSE of 0.428 and the proposed model
achieved 0.381. Both cases are for the whole population. With
0.047 versus 0.03, the difference between the baseline model
(constant threshold) and the predictive model was considerably

larger for the proposed model. In part, this might be a consequence of the pseudonymization process. On the other hand,
it suggests that the data processing and modeling concept presented here is in fact able to take advantage of the more detailed
data structure in this dataset. Moreover, our experience using
both Australian and U.S. health insurance claims thus indicates
that our method could adapt to other countries and districts as
well.
We did not find any literature on other work using insurance
claims to forecast future hospitalization on a similar scale to
that reported here and in the HHP competition. However, there
has been research conducted using insurance claims to estimate
health-care costs. It is difficult to compare our work with this
research due to the different performance metrics used. However, a comparison of R2 would be useful to highlight aspects
of predictive power in insurance claim data and allow further
comparison. Zhao et al. [6] reported a coefficient of determination (R2 ) of 16.8% when estimating costs for the coming year.
Bertsimas et al. proposed one clustering model [7] that achieved
an R2 of 18.0% (without truncation). Our method achieved an
R2 of 15.0% on predicting DIH for the whole population, and
achieved an R2 of 19.1% on the 1+ days group.

C. Future Research
To further improve the prediction performance, the following
aspects are worthy of exploration in the future. DIH can be
further categorized into various graded categories, as this is
a good predictor for targeted interventions from an insurance
perspective. Other predictive models and algorithms could also
be utilized in the future to generate multiple candidate models.
A combination of the optimal set of candidate models usually
predicts more accurately.
Additional health domain knowledge could be incorporated
in the future. Although the Charlson index was calculated as a
feature here, indicating the ten-year mortality rate for a patient
who may have a range of comorbidities. For other health conditions not measured by the Charlson index, we did not assign an
index value. To capture the variety among these health conditions, the current method relies more on diagnosis code features.
In the HHP competition, one of the top scoring teams invented
a feature to estimate admission risk for each primary condition
group [16]. However, from their results and our experience of
using this feature, we found out that this specific feature did
not aid significantly in prediction. Therefore, appropriately incorporating domain knowledge is not straightforward and needs
further exploration.
Analysis of data with longer observation periods (i.e., data
from additional years) could also help in making more accurate predictions. In addition, general practitioner visits and
outpatient service data are likely to increase the accuracy of
predictions. Besides, if pathology/laboratory test data could be
acquired in the future, it would also be interesting to build models for specific disease types. Then, the general model developed here has considerable value as a benchmark against which
disease-specific models may be compared.
Since insurance claims are originally designed for reimbursement purposes, information such as procedure items and cost are

XIE et al.: PREDICTING DAYS IN HOSPITAL USING HEALTH INSURANCE CLAIMS

in nearly all cases complete. However, some clinical information, like diagnosis codes, can be missing, as Fig. 1 shows. This
is one of the drawbacks of health insurance claim data, which
could reduce predictive power. However, for models to be used
in practice, it is better to leave the data as it is and report the real
prediction results instead of idealized results. Our experience
of modeling indicates that incomplete data may have a significant impact on the prediction results. Therefore, although the
nature of data can not be changed, reporting its completeness
and quality is something which should be done when dealing
with big data. Besides the data completeness measure displayed
in Section II-B3, coding errors are also present in such data. For
instance, physicians may often code a diagnosis in the absence
of confirming tests results because a diagnosis is required for
claim reimbursement. This is often the case for rare diagnoses
as well as for emergency treatments [1]. Despite all of their
drawbacks, however, insurance claims data are invaluable due
to their availability and the rich information embedded within.
In the future, work could also investigate how data quality and
incompleteness would affect prediction accuracy.
Finally, we are also interested in forecasting DIH on shorter
time scales, such as by season or month. The accuracy of forecasting would greatly depend on the density of information
available. If the claim information is too sparse, the prediction
accuracy is expected to decrease when attempting shorter timescale forecasting. It would also be interesting to know what time
resolution can be supported by claim datasets. From this point of
view, telehealth data, such as physiological monitoring or selfreported data on a weekly or daily basis, would significantly
increase the temporal data density.
REFERENCES
[1] I. Duncan, “Mining health claims data for assessing patient risk,” in Data
Mining: Foundations and Intelligent Paradigms, ser. Intelligent Systems
Reference Library, vol. 25, D. E. Holmes and L. C. Jain, Eds. Berlin,
Germany: Springer, 2012, pp. 29–62.
[2] J. Donze, D. Aujesky, D. Williams, and J. L. Schnipper, “Potentially
avoidable 30-day hospital readmissions in medical patients: Derivation
and validation of a prediction model,” JAMA Internal Med., vol. 173, pp.
632–638, 2013.
[3] O. Hasan, D. O. Meltzer, S. A. Shaykevich, C. M. Bell, P. J. Kaboli, A. D.
Auerbach, T. B. Wetterneck, V. M. Arora, J. Zhang, and J. L. Schnipper,
“Hospital readmission in general medicine patients: A prediction model,”
J. Gen. Internal Med., vol. 25, pp. 211–219, 2010.
[4] E. Coiera, Y. Wang, F. Magrabi, O. P. Concha, B. Gallego, and W. Runciman, “Predicting the cumulative risk of death during hospitalization by
modeling weekend, weekday and diurnal mortality risks,” BMC Health
Services Res., vol. 14, p. 226, 2014.
[5] R. B. Cumming, D. Knutson, B. A. Cameron, and B. Derrick, “A comparative analysis of claims-based methods of health risk assessment for
commercial populations,” Society of Actuaries, Chicago, 2002.
[6] Y. Zhao, A. S. Ash, R. P. Ellis, J. Z. Ayanian, G. C. Pope, B. Bowen, and
L. Weyuker, “Predicting pharmacy costs and other medical costs using
diagnoses and drug claims,” Med. Care, vol. 43, pp. 34–43, 2005.
[7] D. Bertsimas, M. V. Bjarnadottir, M. A. Kane, J. C. Kryder, R. Pandey,
S. Vempala, and G. Wang, “Algorithmic prediction of health-care costs,”
Oper. Res., vol. 56, pp. 1382–1392, 2008.
[8] K. Pietz, C. M. Ashton, M. McDonell, and N. P. Wray, “Predicting healthcare costs in a population of veterans affairs beneficiaries using diagnosisbased risk adjustment and self-reported health status,” Med. Care, vol. 42,
pp. 1027–1035, 2004.

1233

[9] C. A. Powers, C. M. Meyer, M. C. Roebuck, and B. Vaziri, “Predictive
modeling of total healthcare costs using pharmacy claims data—A comparison of alternative econometric cost modeling techniques,” Med. Care,
vol. 43, no. 11, pp. 1065–1072, 2005.
[10] (2012). “How much do we spend on health?” Australian Institute
of Health and Welfare, Australian Government [Online]. Available:
http://www.aihw.gov.au/australias-health/2012/spending-on-health/
[11] H. G. Dove, I. Duncan, and A. Robb, “A prediction model for targeting
low cost, high-risk members of managed care organizations,” Amer. J.
Managed Care, vol. 9, no. 5, pp. 381–389, 2003.
[12] B. Fireman, J. Bartlett, and J. Selby, “Can disease management reduce
health care costs by improving quality?” Health Affairs, vol. 23, no. 6, pp.
63–75, 2004.
[13] E. Seto, “Cost comparison between telemonitoring and usual care of heart
failure: A systematic review,” Telemed. J. E-Health, vol. 14, no. 7, pp.
679–686, 2008.
[14] J. Polisena, D. Coyle, K. Coyle, and S. McGill, “Home telehealth for
chronic disease management: A systematic review and an analysis of
economic evaluations,” Int. J. Technol. Assessment Health Care, vol. 25,
no. 7, pp. 339–349, 2009.
[15] “Report on government services 2013 volume 2: Health; community
services; housing and homelessness,” Productivity Commission, Australian Government, Canberra, Australia, (2013). [Online]. Available:
http://www.pc.gov.au/research/recurring/report-on-government-services
[16] P. Brierley, D. Vogel, and R. Axelrod. (2013). Heritage provider network health prize round 1 milestone prize: How we did it—Team
‘Market Makers’ [Online]. Available: http://www.heritagehealthprize.
com/c/hhp/leaderboard/milestone1
[17] (2013). Heritage provider network health prize private leaderboard—
heritage health prize [Online]. Available: https://www.heritagehealthprize.
com/c/hhp/leaderboard
[18] (2005). “The international statistical classification of diseases and related health problems, 4th Ed. 10th revision, australian modification
(ICD-10-AM),” National Centre for Classification in Health, University of Sydney, Australia. [Online]. Available: http://meteor.aihw.gov.au/
content/index.phtml/itemId/325387/
[19] (2010). “The Australian classification of health interventions (ACHI)
seventh edition—tabular list of interventions and alphabetic index of interventions,” National Centre for Classification in Health
(NCCH), University of Sydney, Australia, [Online]. Available: http://
meteor.aihw.gov.au/content/index.phtml/itemId/391343/
[20] (2013). Australian refined diagnosis-related groups (AR-DRG) data
cubes. Australian Institute of Health and Welfare, Australian Government [Online]. Available: http://www.aihw.gov.au/hospitals-data/ar-drgdata-cubes/
[21] (2014, Sep.). Medicare benefits schedule (MBS) Department of Health,
Australian Government [Online]. Available: http://www.mbsonline.
gov.au/
[22] V. Sundararajan, T. Henderson, C. Perry, A. Muggivan, H. Quan, and
W. A. Ghali, “New ICD-10 version of the Charlson comorbidity index
predicted in-hospital mortality,” J. Clin. Epidemiol., vol. 57, no. 12, pp.
1288–1294, 2004.
[23] H. Quan, B. Li, C. M. Couris, K. Fushimi, P. Graham, P. Hider, J.-M.
Januel, and V. Sundararajan, “Updating and validating the Charlson comorbidity index and score for risk adjustment in hospital discharge abstracts using data from 6 countries,” Amer. J. Epidemiol., vol. 173, no. 6,
pp. 676–682, 2011.
[24] (2010). International statistical classification of diseases and related health
problems 10th revision. World Health Organization [Online]. Available:
http://apps.who.int/classifications/icd10/browse/2010/en
[25] L. Breiman, “Random forests,” Mach. Learn., vol. 45, no. 1, pp. 5–32,
2001.
[26] (2014, Sep.). “Random forests,” L. Breiman and A. Cutler [Online].
Available: http://www.stat.berkeley.edu/breiman/RandomForests/
[27] (2014, Sep.). “Treebagger,” The Mathworks [Online]. Available: http://
www.mathworks.com.au/help/stats/treebagger.html/

Authors’ photographs and biographies not available at the time of publication.

