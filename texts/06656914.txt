IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

1571

Tensor-Based Methods for Handling Missing Data
in Quality-of-Life Questionnaires
Lalit Garg, Member, IEEE, Justin Dauwels, Senior Member, IEEE, Arul Earnest, and Khai Pang Leong

Abstract—A common problem with self-report quality-of-life
questionnaires is missing data. Despite enormous care and effort to
prevent it, some level of missing data is common and unavoidable.
Missing data can have a detrimental impact on the data analysis. In this paper, a novel approach to imputing missing data
in quality-of-life questionnaires is proposed, based on matrix and
tensor decompositions. In order to illustrate and assess those methods, two datasets are considered: The first dataset contains the responses of 100 patients to a systemic lupus erythematosus-specific
quality-of-life questionnaire; the other contains the responses of
43 patients to a rhino-conjunctivitis quality-of-life questionnaire.
The two datasets contain almost no missing data, and for testing
purposes, data entries are removed at random to have missing
completely at random data. Several proportions of missing values are considered, and for each, the imputation error is assessed
through k-fold cross validation. We also evaluate different imputation methods for missing at random and missing not at randomdata. The numerical results demonstrate that the proposed
tensor factorization-based methods outperform standard methods
in terms of root mean square error with at least 4% improvement,
while the bias and variance are similar.
Index Terms—Health information management, medical information systems, missing data imputation, quality-of-life questionnaires, tensor decomposition.

I. INTRODUCTION
ELF-REPORT quality-of-life questionnaires are valuable
instruments for multiple purposes including assessment of
the quality of life (QOL) of a patient, disease progress, treatment and disease burden, treatment response and quality of care
to make better informed treatment decisions and determine best

S

Manuscript received May 13, 2013; revised August 30, 2013; accepted October 24, 2013. Date of publication November 6, 2013; date of current version
September 2, 2014. This work was supported in part by the Nanyang Institute
of Technology in Health and Medicine Seed Fund M4080150. This paper was
presented in part at the 2012 International Conference on Acoustics, Speech,
and Signal Processing, Kyoto, Japan, May 25–30, 2012.
L. Garg is with the University of Malta, Msida MSD 2080, Malta (e-mail:
lalit.grg@um.edu.mt).
J. Dauwels is with the School of Electrical and Electronic Engineering, Nanyang Technological University, 639798 Singapore (e-mail:
jdauwels@ntu.edu.sg).
A. Earnest is with the Centre for Quantitative Medicine, the Centre for
Quantitative Medicine, Saw Swee Hock School of Public Health, National
University of Singapore, 119077 Singapore, Singapore (e-mail: arul.earnest@
duke-nus.edu.sg).
K. P. Leong is with the Department of Rheumatology, Allergy
and Immunology, Tan Tock Seng Hospital, 308433 Singapore (e-mail:
khai_pang_leong@ttsh.com.sg).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2013.2288803

treatment options for the patient [1]. However, a common problem with such questionnaires is missing data [1].
The best possible method to deal with missing data is to avoid
the problem with careful planning and data collection [1], [2].
However, despite enormous care and effort to prevent it, some
level of missing data is common and unavoidable [1]–[3]. Such
missing data can have a detrimental impact on statistical analysis based on the questionnaires responses, including biased
parameter estimates and inflated standard errors [1], [2]. Moreover, most standard data analysis techniques are developed for
complete data, and they cannot directly be used with missing
data [1]. A variety of methods have been suggested for imputing
missing values in data [1], [4]. However, most of these methods
fail to fully exploit correlations in the data, and lead to unreliable
imputation of the missing values [5]. More research is desperately needed to assess and improve the reliability of missing
data handling methods [1].
In this paper, we propose novel approaches for handling missing data more effectively, specifically, matrix and tensor decomposition methods. We assess and illustrate these techniques
by means of two datasets. The first contains the responses of
100 patients to a systemic lupus erythematosus-specific qualityof-life (SLEQOL) questionnaire [6], [7]. The other contains
the responses of 43 patients to a rhino-conjunctivitis qualityof-life (RCQOL) questionnaire [8]. Both datasets contain
(almost) no missing data, and for testing purposes, we randomly remove data entries to have missing completely at random (MCAR) data [9]–[11]. We consider several proportions of
missing values, and for each we use leave-one-out cross validation (LOOCV) to assess the imputation error. We also evaluate
different imputation methods for missing at random (MAR) and
missing not at random (MNAR, also called not missing at random or NMAR) data [9]–[11]. In case of MAR, the probability
of missingness of a response (to a question) by a respondent
depends on his/her known response to another question. For example, we can take a scenario where the probability that patients
answer the question about their age depends on their gender. In
case of MNAR, the probability of missingness of a response (to
a question) by a respondent depends on the unknown response
itself. For example, we can take a scenario where the probability that patients answer the question about their age depends on
their age itself. We assess the proposed and standard imputation methods for quality-of-life questionnaires through several
measures, including root-mean-square error (RMSE), bias, and
variance. Our numerical results indicate that the tensor-based
methods provide the best performance in terms of RMSE, with
similar performance to standard methods in terms of bias and
variance.

2168-2194 © 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

1572

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

II. METHODS
The most popular among the early methods of handling missing data in quality-of-life questionnaires is to discard records
with missing data [12], [13]. Another popular approach is to
replace a missing response of a question by zero, the mean
or median of the responses [5] for the corresponding question [14]. More sophisticated common methods include matching imputation, hot-deck imputation [15], [16], multiple imputation (MI) [16], and maximum likelihood/EM algorithm [17].
However, most of these methods fail to fully exploit the correlation in the data, and lead often to unreliable imputation
of the missing values [5]. To better utilize the correlations in
the data for addressing missing data, recently a new family
of machine-learning methods has been developed, known as
collaborative filtering (CF) [18], [19]. CF provides automatic
predictions about a missing response by leveraging its correlation with related known responses [20]–[22]. CF has great
potential for medical applications, in particular, for inferring
missing data in quality-of-life questionnaires. In this setting, CF
makes automatic predictions (filtering) about the patients missing responses by collecting responses from many patients and
understanding the interrelation among respondents and questions. More advanced CF methods for handling missing data
are rooted in machine learning, e.g., weighted k-nearest neighbor (KNN) estimation [23], closest fit [24], collateral missing
value imputation [5], local least-squares fit [25], principal component analysis [26], iterated local least-squares imputation (ItrLLSimpute) [27], probabilistic matrix factorization (PMF) [28],
Bayesian PMF (BPMF) [29] and singular value decomposition
(SVD) [30]. We use tensor decomposition as a means of CF, in
order to impute missing data. More precisely, we consider the
Canonical Polyadic (CP) tensor decomposition [31], [32].
Here, we introduce some notation. Let a self-reported qualityof-life questionnaire x contain responses of N respondents for
M questions recorded for F follow-ups (i.e., from each respondent/patient, the responses to each question were collected at
F different times). We denote a known response by respondent
n for question m for follow-up f as xn m f . If the response is
missing, we denote it as x∗n m f , and xin m f stands for its imputed value. The vector xim f contains the imputed values for all
missing responses of question m in follow-up f .
A. Standard Methods
In the following, we briefly review standard data imputation
methods.
1) List-Wise or Case-Wise Deletion: In list-wise deletion, all
cases with missing data are eliminated [33]. For example, if one
or more of the responses from respondent n is missing (let x∗n m f
be missing), then all M F responses from the respondent n will
be excluded from further analysis. Although, this approach is
widely used, it sacrifices a large amount of data.
2) Pairwise Deletion: In pairwise deletion, we only delete
information from statistics that need the information. For example, let us assume that response x∗n m f from respondent n
to question m is missing, and all responses from the other respondents are available. In the case of pairwise deletion, not all

M F responses from respondent n are ignored in data analysis.
Instead respondent n is only ignored when question m is under
consideration. For instance, when computing the correlation between question m and question m , the respondent n would be
discarded. For all other pairs of questions, the responses from
respondent n would be incorporated in the calculations.
Pairwise deletion preserves data otherwise lost from list-wise
deletion. However, since different parts of the dataset are used
for each statistic (e.g., correlations and covariance), it leads to
inconsistencies in the computed statistic, and therefore, interpretation may become difficult.
3) Mean Substitution (MS): In mean substitution (MS), we
replace the missing value of a question with the mean:
xin m f =

1
N − Nm f

N


xj m f

(1)

j =0,j ∈Mm f

where Mm f is the set of missing responses to question m for
follow-up f , and Nm f is the corresponding number of missing
responses. MS preserves data and is easy to use. However, it
decreases the variance of variables (responses) since all missing
entries are replaced by the same value.
4) Weighted (KNN) Estimation: In the weighted KNN
method, we replace a missing response from a certain respondent n by the weighted sum of known responses from the K
most similar respondents (nearest neighbors) to respondent n.
Nearest neighbors are defined as respondents with similar responses to other questions. Weights are computed according to
the distance among respondents: if the distance of a respondent
n to respondent n is small, a large weight will be associated to
respondent n when imputing missing values for respondent n. A
popular distance measure for the KNN method is the Euclidean
distance.
The performance of weighted KNN method is highly dependent on the choice of K [5]. With small K, results may suffer
from outliers, while for large K, uncorrelated respondents start
to play a role in the predictions [6]. The value of K is calculated [27] by first removing a proportion of known responses,
and then imputing these responses using weighted KNN, where
the value of K ranges from 1 to the number of known values
in the question; the value of K with minimum prediction error
is eventually selected. We implemented KNN estimation with
Euclidean distance using the knnimpute function of the MATLAB Bioinformatics Toolbox [23].
5) Regression Imputation: In regression imputation, we impute the value of missing response by exploiting correlations
with other known responses. Cai et al. [27] proposed an
advanced regression imputation method called iterated local
least-squares method. We used an MATLAB implementation
(ItrLLSimpute) of their method. In order to impute the missing
response x∗n m f by the iterated local least-squares method, first
we substitute all missing responses for each question other than
question m by the mean response for each question. We determine KNN of question m similarly as in the weighted KNN
above. Assuming there are N  known responses for question
m, we form a matrix A of size N  × K consisting of responses
of each of the KNN questions corresponding to only known

GARG et al.: TENSOR-BASED METHODS FOR HANDLING MISSING DATA IN QUALITY-OF-LIFE QUESTIONNAIRES

responses of question m. Similarly, we form the (N − N  ) × K
matrix B that contains the responses of each of the KNN questions corresponding to the missing responses of question m.
We form a vector w of all known responses of question m. We
determine the vector x̂ of size K:
x̂ = arg min Ax − w2 .
x

(2)

Next we use x̂ to impute the missing responses xim f as follows:
xim f = Bx̂.

(3)

In (3), all missing values in question m are simultaneously
updated. We repeat the same procedure for all questions with
missing responses.
The iterated local least-squares method performs well with
data that contains local correlations, however, it fails to exploit
global collaborations (e.g., among follow-ups).
6) Multiple Imputation: MI [1], [16], [34]–[39] combines
multiple imputations of each of the missing responses in the
dataset. Multiple complete datasets are generated through multiple imputations of the missing responses. An imputation is
carried out by exploiting the dependence of missing responses
of a question to all known responses (of other questions) in the
dataset. We can for instance use one of the many regression
methods available for imputing a missing value such as linear,
logistic, or Poisson regression. We follow the following cycle:
We randomly select a question and impute all missing responses
to the question and replace missing responses by their imputations; then we randomly select another question and impute all
missing responses to the question and replace missing responses
by their imputations. We repeat the process until we have imputed the missing responses of all questions in the dataset. The
sequence of questions to be considered for imputation is random. We follow a different sequence in each MI iteration, each
leading to a different complete dataset.
For this paper, we applied MI by chained equations (MICE)
[35]–[39]. Concretely, we utilized the R package [40] MICE by
van Buuren and Groothuis-Oudshoorn [36]. The MICE algorithm first replaces all missing responses by MS (or following
some other distribution). Next, it randomly selects a question
and imputes all its missing responses using linear regression
(other regressions are also supported) considering the question
as dependent on all other questions. The missing responses in
the question are replaced by imputed values. The algorithm then
selects another question randomly and repeats these steps until
all questions are selected.
7) Bayesian Probabilistic Matrix Factorization: One of the
most popular collaborative filtering methods (primarily used for
recommendation systems) is probabilistic matrix factorization
(PMF) [28]. In the PMF method, a response Rij of a respondent
i to a question j is modeled by the inner product of the latent
(unobserved) respondent vector Ui and the latent question vector Vj , i.e., the observed response Matrix R is factored into a
low-rank matrix R̂ such that R̂ = (U ∗ VT ), where U is the
latent respondent matrix representing respondents preferences
and V is the latent question matrix. The prior distribution of
each of these latent vectors Ui and Vj are then individually

1573

modeled by Gaussian distributions. The model parameters are
called hyperparameters. A predicted response Rij is computed
as a product of prior distributions of Ui and VjT . The loss function is called factorization error or noise and calculated as the
sum of square difference between R and R̂. A gradient descent
method is used to minimizing the loss [28]. Bayesian PMF
(BPMF) implements Bayesian inference to improve the PMF
algorithm (and reduce the tuning requirements to avoid overfitting) [29]. The conditional distributions of hyperparameters
of latent matrices U and V are modeled as Gaussian–Wishart
distributions. Markov chain Monte Carlo (MCMC) methods
are implemented using the Gibbs sampling algorithm to apply
Bayesian inference [29]. For this paper, we utilize MATLAB
codes provided by Salakhutdinov [29]. These codes are primarily provided for the recommendation systems, to predict users’
recommendations for given items. In the case of the quality-oflife questionnaires, we can consider each question as “an item”
and each response as “a recommendation” in a recommender
system. However, recommendation systems are very large and
sparse [28], while, it is not the same with the quality-of-life
questionnaires.
B. Proposed Methods
We propose methods for missing data imputation that conduct
collaborative filtering (CF) through canonical polyadic (CP) tensor decomposition. Those methods predict missing responses in
repeated questionnaires by learning inherent collaborative relationship from known responses across different dimensions
(among questions, respondents, and follow-ups). We also consider SVD as a special case of CP for two-dimensional (2-D)
tensors (matrices).
1) Tensor: Tensors are multi-dimensional arrays, also called
hypermatrices or multiway arrays [41]. They can be used to represent and store multi-dimensional data [32]. An N -dimensional
tensor can be defined mathematically as [41]
χ ∈ RD 1 ×D 2 ×···×D N

(4)

where the size of the tensor is
size(χ) = D1 × D2 × · · · × DN

(5)

N is the order of the tensor, and Di is the size of its ith dimension.
We can naturally arrange a repeated questionnaire as a 3-D
tensor χ ∈ RN ×M ×F , where the dimensions N, M , and F are
the respondents, questions, and follow-ups, respectively.
2) Canonical Polyadic (CP) Decomposition: CP is a generalization of SVD to tensors. CP decomposes a tensor into
a minimal sum of rank-one tensors. A rank-one tensor ν ∈
RI 1 ×I 2 ×···×I N can we written as [31]
ν = v1 ◦ v2 ◦ · · · ◦ vN =

N


(◦vn )

(6)

n

where vm ∈ RI m is a vector and vi ◦ vj denotes the outer
product of vectors vi and vj . The CP decomposition of tensor

1574

Fig. 1.

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

CP decomposition of a 3-D tensor.

χ is defined as a sum of rank-one tensors [41]:
χ = ν1 + ν 2 + · · · + ν R =

R


νr

(7)

r =1

where the rank-1 tensor νr is the rth factor of tensor χ. The
number R of rank-1 tensors νr in the CP decomposition of a
tensor is equal to the rank of that tensor [31]. Substituting νr
from (6) into (7) leads to
χ=

R


v1r ◦ v2r ◦ · · · ◦ vN r =

N
R 

(◦vn r ).

(8)

r =1 n

r =1

Fig. 1 depicts a schematic representation of the CP factorization
of a 3-D tensor [31]. CP factorization is a nonpolynomial time
complex problem [31]. We compute CP factorization approximately by minimizing the reconstruction error:

2
I1
IN
N
R 



···
vn r i n
(9)
xi 1 ,...,i N −
ε=
i 1 =1

i N =1

r =1 n

where xi 1 ,...,i N is an element of tensor χ at position i1 , . . . , iN
and vn r i n is the in th element of vector Vn r .
3) Missing Data Imputation Using CP: In order to predict
missing data, CP learns the latent structure and collaborative relationships among the different dimensions of the tensor (rows,
columns, tubes). In medical questionnaire data, the dimensions
are questions, respondents, and follow-ups, respectively. CP is
very effective in capturing dependences in high-dimensional
datasets. Therefore, it can effectively be used for missing data
analysis. Acar et al. [31] proposed a tensor factorization model
for tensors with missing values. The tensor factorization is obtained by minimizing the following reconstruction error:

2
I1
IN
N
R 



···
γi 1 ,...,i N xi 1 ,...,i N −
vi n n r
.
ε=
i 1 =1

i N =1

r =1 n

(10)
Here, an incomplete data tensor χ is multiplied with a tensor γ
defined as

1 if xi 1 ,i 2 ,...,i N is known
(11)
γi 1 ,i 2 ,...,i N =
0 otherwise.
The optimization problem in (10) is a weighted least-squares
problem, which may be solved using nonlinear conjugate
gradient-based method [31]. We try different values of rank
R starting from 1 to min(ip iq ), where ip and iq are the pth and
qth dimension, respectively, of χ. We select the rank R which
minimizes the value of εγ R , computed by cross validation.

Fig. 2. Pearson correlation coefficient between follow-ups in SLEQOL
questionnaires (red and blue indicate strong correlation and anticorrelation,
respectively).

4) CP With Column Normalized Tensor: Since the data in a
tensor may be unbalanced, it is often recommended to normalize a tensor before decomposing it. In particular, the responses
might vary substantially across respondents. We therefore normalize each column (corresponding to responses to each question) by subtracting its mean. In order to impute missing values,
we add the corresponding mean value back after performing CP.
5) Two-Way CP (Equivalent to SVD): We also applied twoway CP, in which case the dataare organized as a matrix (twoway tensor). Note that two-way CP is equivalent to SVD. We
represent our dataset into a matrix by arranging the questions
at each follow-on in the same dimension. In other words, we
concatenate questions from different follow-ups, resulting in an
N × M F matrix. We apply both CP approaches (standard CP
and column normalized CP) for matrix decomposition.
6) Complexity: The computational complexity of CP is of
order O(n3 ) [31], where n is the size of each dimension of the
tensor. If one infers the rank of the given tensor (with missing
data) by testing all potential rank values, CP needs to be run
O(n2 ) times. In that case, the overall computational complexity of CP-based missing data imputation is of order O(n5 ). In
practice, one may test rank values up to a maximum Rm ax . The
complexity is then reduced to O(Rm ax n3 ).
III. DESIGN
A. Questionnaire Data
We consider two datasets to illustrate and assess the standard and proposed imputation methods. The first dataset consists of responses to the SLEQOL questionnaire with 40
questions [6], [7], completed by 100 systemic lupus erythematosus patients at three times (three follow-ups); there are hence
12 000 entries in total. The dataset is almost free of missing
data: it has only 255 missing values (2.1%). As shown in Fig. 2,
the different follow-ups in the SLEQOL repeated quality-of-life
questionnaires are highly correlated; the Pearson correlation for
the baseline with the first follow-up is 0.66, for the baseline
with the second follow-up it is 0.57, and for the first with the
second follow-up it is 0.72. The corresponding correlations are
statistically significant according to the Pearson correlation test
(p-value < 0.05). Furthermore, as shown in Fig. 3, there is a

GARG et al.: TENSOR-BASED METHODS FOR HANDLING MISSING DATA IN QUALITY-OF-LIFE QUESTIONNAIRES

1575

B. Cross-Validation With MCAR Data
For each proportion p of missing values, we apply k-fold
cross validation (CV) to assess the different imputation methods.
We randomly partition the real dataset into 1/p subsets of size
pN M F , where N M F is the total number of responses. In each
of the CV iterations, we remove all entries of one subset, and
apply the imputation methods to the resulting data, containing a
proportion p of missing values. Next, for the sake of validation,
the resulting imputed values are compared to the actual ones.
This step is repeated such that each entry in the dataset is used
once for validation.
Fig. 3. Pearson correlation coefficient between questions in SLEQOL questionnaires (red and blue indicate strong correlation and anticorrelation,
respectively).

Fig. 4. Pearson correlation coefficient between patients in SLEQOL questionnaires (red and blue indicate strong correlation and anticorrelation, respectively).

strong correlation among the different questions. Specifically,
98% of the correlations among pairs of questions are statistically significant (p-value < 0.05). Also, the correlations between
patients are strong (see Fig. 4), however, weaker than those between questions. Concretely, 54% of correlations between pairs
of patients are statistically significant (p-value < 0.05).
The second dataset contains responses to the RCQOL questionnaire [8] with 28 questions, completed by 43 rhinoconjunctivitis patients at four times; consequently, there are
4 816 entries in total. The different Follow-ups in the RCQOL
repeated quality-of-life questionnaires are weakly correlated;
the Pearson correlation for the baseline with the first, second,
and third follow-up is 0.49, 0.37, and 0.35, respectively; for the
first with the second and third follow-up the Pearson correlation is 0.57 and 0.53, respectively, and for the second with the
third follow-up it is 0.78. There is a strong correlation among
questions. All correlations between pairs of questions have
p-value less than 5%. Also, there is a strong correlation among
patients, but weaker than among questions: 61% of correlations
among patients are statistically significant (p-value < 0.05).
This dataset does not contain any missing values.
For this study, we consider datasets (almost) free of missing
data, since we need to know the ground truth for testing purposes. In order to have MAR data, we remove missing data at
random, for different proportions of missing values (e.g., 3%,
4%, . . ., 30%).

C. Cross Validation With MAR and MNAR Data
In order to have MAR and MNAR data, we used the algorithm proposed by Cismondi et al. [10]. For each proportion
p of missing values, we create datasets by selecting at least
50% of the missing values as MNAR and the remaining as
MAR. To create the MAR data, for each question mi , we randomly find a related question mj and randomly select its value
dm j such that ∀dm j , min(xm j ) ≤ dm j ≤ max(xm j ). Now, we
use Poisson distribution to randomly select Mi , the number of
missing responses to the question. Then, if the number of responses in the related question mj having response value dm j
is less than or equal to Mi , we consider all corresponding responses to the question mi as missing. Else, we randomly select
Mi responses of question mi among those having response
value for question mj equal to dm j . To create the MNAR data,
for each question mi , we randomly select its value dm i such
that ∀dm i , min(xm i ) ≤ dm i ≤ max(xm i ). Now, we use Poisson distribution to randomly select the number Mi of missing
responses to the question. Then, if the number of responses in
the question mi having response value dm i is less than or equal
to Mi , we consider all corresponding responses to the question
mi as missing. Else, we randomly select Mi responses of question mi among those having response value equal to dm i . This
step is repeated such that each entry in the dataset is used once
for validation.

D. Evaluating the Performance of Different Methods
We use three measures to assess the standard and proposed
methods: bias, RMSE, and variance. The bias is calculated as
the average difference between the imputed and true value of
the missing data. If this average is zero, the imputed values
are unbiased. The RMSE is computed as the square root of the
average squared difference between the imputed and true value
of the missing data. After imputing the missing data, we compute
the variance of the responses in the questionnaire (including the
actual and imputed responses), and compare it to the variance
of the responses in the original questionnaire (without missing
data). We separately calculate bias, RMSE, and variance for each
proportion of missing values. Already present missing entries in
SLEQOL dataset were excluded while computing bias, RMSE,
and variance for each method.

1576

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

TABLE I
COMPARISION OF STANDARD METHODS WITH CP-BASED METHODS FOR
SLEQOL DATASET WITH MCAR DATA

Fig. 5. Comparison of RMSE for different missing data techniques for
SLEQOL dataset with MCAR data. The error bars indicate 95% confidence
interval.

TABLE II
COMPARISION OF STANDARD METHODS WITH CP-BASED METHODS FOR
RCQOL DATASET WITH MCAR DATA
Fig. 6. Comparison of variance for different missing data techniques for
SLEQOL dataset with MCAR data. The variance of the original dataset equals
2.07.

Fig. 7. Comparison of RMSE for different missing data techniques for
RCQOL dataset with MCAR data. The error bars indicate 95% confidence
intervals.

IV. RESULTS
Our results (with MCAR data) are summarized in Tables I
and II, and Figs. 5–8. The error bars in Figs. 5 and 7 represent
the 95% confidence intervals, computed across the different trials in the leave-one-out cross validation. The variation among
the different trials of leave-one-out cross validation is negligible.
More precisely, the variation is less than 1.4% and 2.1%, respectively, for the SLEQOL and RCQOL datasets, for all methods
considered. In the following, we discuss the performance of the
different imputation methods.

Fig. 8. Comparison of variance for different missing data techniques for
RCQOL dataset with MCAR data. The variance of the original dataset equals
3.47.

GARG et al.: TENSOR-BASED METHODS FOR HANDLING MISSING DATA IN QUALITY-OF-LIFE QUESTIONNAIRES

Fig. 9. Predictability of different imputation methods for SLEQOL dataset
with MCAR data.

1577

Fig. 10. Predictability of different imputation methods for RCQOL dataset
with MCAR data.

A. Standard-CP Approach
The proposed standard-CP-based approach improves the imputation accuracy in terms of RMSE compared to standard methods, specifically, by about 2% for the SLEQOL dataset and about
5% for the RCQOL dataset. Although for both SLEQOL and
RCQOL datasets, the standard-CP-based approach results in a
larger bias compared to the standard methods, the bias remains
very small and negligible (<0.1%). The variance is also comparable with standard methods and very close to the actual variance
of the original datasets.
B. Column Normalized CP Approach
If we normalize the columns in the tensor before applying CP,
the improvement in RMSE over standard methods becomes substantial: about 13% for the SLEQOL dataset and about 12% for
the RCQOL dataset. The normalization of the tensor columns
also helps limiting the bias, to a level comparable to standard
methods. Interestingly, the bias remains more or less constant
with growing percentage of missing data. Compared to standard
CP, the column normalized CP approach improves the variance
significantly. For both datasets, the variance of the imputed data
is closer to the actual variance, and the column normalized
CP method also provides the best estimate of the variance. In
summary, for all proportion of missing values, the column normalized CP approach outshines the other approaches in all three
performance criteria: it yields significantly smaller RMSE than
the standard methods, a comparable (negligible) bias, and variance estimates that are more accurate than all standard methods.

Fig. 11. Comparison of different methods for their ability to predict with error
less than (plus or minus) one for SLEQOL dataset with MCAR data.

Fig. 12. Comparison of different methods for their ability to predict with error
less than (plus or minus) one for RCQOL dataset with MCAR data.

C. Two-Way CP Approaches (Equivalent to SVD)
The performance of both SVD (standard and with column
normalized matrix) was inferior to their corresponding tensor
(3-D)-based CP approaches, according to all three criteria. In
conclusion, it is helpful to organize the data as a tensor instead
of a matrix, for the purpose of imputation.
D. Predictability
The predictability is calculated as the proportion of missing values correctly imputed after rounding-off by replacing
each imputed value by its nearest integer. Fig. 9 shows the
predictability of imputation method for SLEQOL dataset and
Fig. 10 shows predictability of imputation method for RCQOL

dataset. Furthermore, Figs. 11 and 12, respectively, compare
different methods for their ability to predict with error less than
(plus or minus) one for SLEQOL and RCQOL datasets, respectively. From Figs. 9 to 12, we can clearly see that column
normalized CP provides better predictability than all other imputation methods considered here.
Overall, the proposed tensor-based methods yield a higher
performance gain for the RCQOL dataset compared to the
SLEQOL dataset. Most likely, that is due to the fact that the
follow-ups are more correlated in the former than in the latter. Only the tensor-based methods are capable of exploiting
the correlations among follow-ups, resulting in more accurate
imputation.

1578

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

TABLE III
COMPARISION OF STANDARD METHODS WITH CP-BASED METHODS FOR
SLEQOL DATASET WITH MAR AND MNAR DATA

extent MAR also) affects the column means as the response with
a particular value have more probability of being missing.
V. CONCLUSION

TABLE IV
COMPARISION OF STANDARD METHODS WITH CP-BASED METHODS FOR
RCQOL DATASET WITH MAR AND MNAR DATA

Our numerical results suggest that in the case of missing at
random (MCAR) data, the column normalized CP approach for
imputing missing data outperforms a large variety of standard
missing data methods in terms of RMSE. Also, in case of MAR
and MNAR cases, standard CP approach for imputing missing data outperforms a large variety of standard missing data
methods in terms of RMSE. The estimated variance from the
CP approaches is reliable and more accurate compared to standard methods. Moreover, the proposed CP approaches have very
small and negligible bias. Overall, the CP approaches can be
considered as effective approaches for handling missing values
in quality-of-life questionnaires irrespective of the proportion of
missing values. Presently, we are aiming to improve our results
by considering other tensor decomposition methods including
Tucker decomposition [42], PARAFAC2 [43], DEDICOM [44]
and variations of these [45]. Furthermore, for very large datasets
we are presently working on using fast, low complexity CP algorithms such as those proposed by Phan et al. [46], [47], Sorber
et al. [48], and Zhou et al. [49], [50], as for imputing missing
data in quality-of-life questionnaires.
Stand-alone executables for each of the standard and
proposed approaches can be downloaded from the website
http://lalitgarg.weebly.com/software.html (except for the MI approach, as we utilized the R package MICE [36]).
REFERENCES

E. Evaluating the Performance for MAR and MNAR Data
Our results (with MAR and MNAR data) are summarized
in Tables III and IV. The RMSE is presented with the 95%
confidence intervals, computed across the different trials in the
leave-one-out cross validation. The variation among the different trials of leave-one-out cross validation is negligible. More
precisely, the variation is less than 2.5% for both the datasets,
for all methods considered. In the case of MAR and MNAR data
also, proposed CP-based methods outperform standard methods
in terms of RMSE with at least 14% improvement, while the bias
and variance are similar. Here, the standard-CP-based method
performs better than Column normalized CP method in terms
of RMSE. The possible reason for that is MNAR (and, at some

[1] H. Peyre, A. Leplège, and J. Coste, “Missing data methods for dealing
with missing items in quality of life questionnaires. A comparison by
simulation of personal mean score, full information maximum likelihood,
multiple imputation, and hot deck techniques applied to the sf-36 in the
french 2003 decennial health survey,” Qual. Life Res., vol. 20, no. 2,
pp. 287–300, 2011.
[2] U. Müller-Bühl, B. Franke, K. Hermann, and P. Engeser, “Lowering missing item values in quality-of-life questionnaires: An interventional study,”
Int. J. Public Health, vol. 56, no. 1, pp. 63–69, 2011.
[3] P. Vercherin, C. Gutknecht, F. Guillemin, R. Ecochard, L. I. Mennen, and
M. Mercier, “Missing data mechanisms of the questionnaire sf-36’s items
in the su. vi. max. study,” Revue d’Epidmiologie et de SantÃ© Publique
(Epidemiol. Public Health), vol. 51, no. 5, pp. 513–526, 2003.
[4] P. L. Roth, “Missing data: A conceptual review for applied psychologists,”
Personn. Psychol., vol. 47, no. 3, pp. 537–560, 1994.
[5] M. S. B. Sehgal, I. Gondal, and L. S. Dooley, “Collateral missing value
imputation: A new robust missing value estimation algorithm for microarray data,” Bioinformatics, vol. 21, no. 10, pp. 2417–2423, 2005.
[6] K. P. Leong, K. O. Kong, B. Y. H. Thong, E. T. Koh, T. Y. Lian, C. L. Teh,
Y. K. Cheng, H. H. Chng, H. Badsha, W. G. Law, L. C. Chew, H. J. Ho,
L. Y. Pong, L. S. Hoi, N. Sangeetha, S. P. Chan, and H. S. Howe, “Development and preliminary validation of a systemic lupus erythematosusspecific quality-of-life instrument (sleqol),” Rheumatology, vol. 44, no. 10,
pp. 1267–1276, 2005.
[7] L. C. Doward, S. P. McKenna, D. Whalley, A. Tennant, B. Griffiths,
P. Emery, and D. J. Veale, “The development of the l-qol: A quality-oflife instrument specific to systemic lupus erythematosus,” Ann. Rheumat.
Diseases, vol. 68, no. 2, pp. 196–200, 2009.
[8] E. F. Juniper and G. H. Guyatt, “Development and testing of a new measure
of health status for clinical trials in rhinoconjunctivitis,” Clin. Exp. Allergy,
vol. 21, no. 1, pp. 77–83, 2006.
[9] D. B. Rubin, “Inference and missing data,” Biometrika, vol. 63, no. 3,
pp. 581–592, 1976.

GARG et al.: TENSOR-BASED METHODS FOR HANDLING MISSING DATA IN QUALITY-OF-LIFE QUESTIONNAIRES

[10] F. Cismondi, A. S. Fialho, S. M. Vieira, S. R. Reti, J. Sousa, and
S. N. Finkelstein, “Missing data in medical databases: Impute, delete or
classify?” Artif. Intell. Med., vol. 58, pp. 63–72, 2013.
[11] S. Fielding, P. M. Fayers, A. McDonald, G. McPherson, and
M. K. Campbell, “Simple imputation methods were inadequate for missing not at random (MNAR) quality of life data,” Health Qual. Life Outcomes, vol. 6, no. 57, pp. 1–57, 2008.
[12] R. E. Anderson, J. F. Hair, R. L. Tatham, and W. C. Black, Multivariate
Data Analysis. Noida, India: Pearson, 2006.
[13] J. F. Hair, R. E. Anderson, R. L. Tatham, and C. William, Multivariate
Data Analysis, 5th ed. Upper Saddle River, NJ, USA: Prentice-Hall,
1998.
[14] P. Fayers and D. Machin, Development and Testing of a New Measure
of Health Status for Clinical Trials in Rhinoconjunctivitis, 2nd ed. New
York, NY, USA: Wiley Blackwell, 2007.
[15] R. R. Andridge and R. J. A. Little, “A review of hot deck imputation for
survey non-response,” Int. Statist. Rev., vol. 78, no. 1, pp. 40–64, 2010.
[16] D. B. Rubin, Multiple Imputation for Nonresponse in Surveys. New
York, NY, USA: Wiley, 1987.
[17] A. P. Dempster, N. M. Laird, and D. B. Rubin, “Maximum likelihood
from incomplete data via the EM algorithm,” J. Roy. Statist. Soc. Series B
(Methodological), vol. 39, pp. 1–38, 1977.
[18] X. Su and T. M. Khoshgoftaar, “A survey of collaborative filtering techniques,” Adv. Artif. Intell., vol. 2009, Art. ID 421425, pp. 1–19, 2009.
[19] W. Xia, L. He, J. Gu, and K. He, “Effective collaborative filtering approaches based on missing data imputation,” in Proc. IEEE 5th Int. Joint
Conf. INC, IMS and IDC, p. 57, 2009, pp. 534–537.
[20] S. Fielding, P. M. Fayers, and C. R. Ramsay, “Investigating the missing
data mechanism in quality of life outcomes: A comparison of approaches,”
Health Qual. Life Outcomes, vol. 7, no. 57, pp. 1–10, 2009.
[21] J. S. Breese, D. Heckerman, and C. Kadie, “Empirical analysis of predictive algorithms for collaborative filtering,” in Proc. 14th Conf. Uncertainty
Arti. Intell., 1998, pp. 43–52.
[22] H. Ma, I. King, and M. R. Lyu, “Effective missing data prediction for
collaborative filtering,” in Proc. 30th Annu. Int. ACM SIGIR Conf. Res.
Development Inf. Retrieval, 2007, pp. 39–46.
[23] O. Troyanskaya, M. Cantor, G. Sherlock, P. Brown, T. Hastie,
R. Tibshirani, D. Botstein, and R. B. Altman, “Missing value estimation
methods for DNA microarrays,” Bioinformatics, vol. 17, no. 6, pp. 520–
525, 2001.
[24] J. W. Grzymala-Busse, W. J. Grzymala-Busse, and L. K. Goodwin, “Coping with missing attribute values based on closest fit in preterm birth data:
A rough set approach,” Computat. Intell., vol. 17, no. 3, pp. 425–434,
2001.
[25] H. Kim, G. H. Golub, and H. Park, “Missing value estimation for dna
microarray gene expression data: Local least squares imputation,” Bioinformatics, vol. 21, no. 2, pp. 187–198, 2005.
[26] M. Scholz, F. Kaplan, C. L. Guy, J. Kopka, and J. Selbig, “Non-linear PCA:
A missing data approach,” Bioinformatics, vol. 21, no. 20, pp. 3887–3895,
2005.
[27] Z. Cai, M. Heydari, and G. Lin, “Iterated local least squares microarray
missing value imputation,” J. Bioinformat. Computat. Biol., vol. 4, no. 05,
pp. 935–957, 2006.
[28] R. Salakhutdinov and A. Mnih, “Probabilistic matrix factorization,” Adv.
Neural Inf. Process. Syst., vol. 20, pp. 1257–1264, 2008.
[29] R. Salakhutdinov and A. Mnih, “Bayesian probabilistic matrix factorization using Markov chain Monte Carlo,” in Proc. 25th Int. Conf. Mach.
Learn., 2008, pp. 880–887.
[30] M. Brand, “Incremental singular value decomposition of uncertain data
with missing values,” Comput. Vis.—ECCV 2002, pp. 707–720.
[31] E. Acar, D. M. Dunlavy, T. G. Kolda, and M. Mørup, “Scalable tensor
factorizations for incomplete data,” Chemometr. Intell. Lab. Syst., vol. 106,
no. 1, pp. 41–56, 2011.
[32] J. Dauwels, K. Srinivasan, M. R. Reddy, and A. Cichocki, “Multi-channel
EEG compression based on matrix and tensor decompositions,” in Proc.
IEEE Int. Conf. Acoust., Speech Signal Process., 2011, pp. 629–632.
[33] P. D. Allison, Missing Data. Thousand Oaks, CA, USA: Sage, 2001.
[34] J. L. Schafer, “Multiple imputation: A primer,” Statist. Methods Med.
Res., vol. 8, no. 1, pp. 3–15, 1999.
[35] S. Van Buuren, H. C. Boshuizen, and D. L. Knook, “Multiple imputation
of missing blood pressure covariates in survival analysis,” Statist. Med.,
vol. 18, no. 6, pp. 681–694, 1999.
[36] S. Buuren and K. Groothuis-Oudshoorn, “Mice: Multivariate imputation
by chained equations in R,” J. Statist. Softw., vol. 45, no. 3, 2011.
[37] N. J. Horton and S. R. Lipsitz, “Multiple imputation in practice,” Amer.
Statistic., vol. 55, no. 3, pp. 244–254, 2001.

1579

[38] R. M. Yucel, “Dissemination of missing data techniques in medical,
biomedical and social research,” J. Biomet. Biostat., vol. 3, no. 1, pp. 1–2,
2012.
[39] R. M. Yucel, “State of the multiple imputation software,” J. Statist. Softw.,
vol. 45, no. 57, pp. 1–17, 2011.
[40] R. D. C. Team et al. (2011). “R: A language and environment for statistical
computing,” in Proc. R Found. Statist. Comput., Vienna, Austria. [Online].
Available: http://www. R-project.org
[41] M. Mørup, “Applications of tensor (multiway array) factorizations and
decompositions in data mining,” Wiley Interdiscipl. Rev.: Data Mining
Knowl. Discov., vol. 1, no. 1, pp. 24–40, 2011.
[42] L. R. Tucker, “Some mathematical notes on three-mode factor analysis,”
Psychometrika, vol. 31, no. 3, pp. 279–311, 1966.
[43] R. A. Harshman, “Parafac2: Mathematical and technical notes,” UCLA
Work. Papers Phonet., vol. 22, pp. 30–47, 1972.
[44] R. A. Harshman. (1978). “Models for analysis of asymmetrical relationships among n objects or stimuli,” in Proc. 1st Joint Meet. Psychometr. Soc.
Soc. Math. Psychol., McMaster University, Hamilton, Ontario. [Online].
Available: http://publish.uwo.ca/harshman/asym1978.pdf
[45] R. A. Harshman and M. E. Lundy, “Uniqueness proof for a family
of models sharing features of Tucker’s three-mode factor analysis and
parafac/candecomp,” Psychometrika, vol. 61, no. 1, pp. 133–154, 1996.
[46] A.-H. Phan, P. Tichavsky, and A. Cichocki, “Fast damped gauss-newton
algorithm for sparse and nonnegative tensor factorization,” in Proc. IEEE
Int. Conf. Acoust., Speech Signal Process., 2011, pp. 1988–1991.
[47] A.-H. Phan, P. Tichavsky, and A. Cichocki, “Low complexity damped
gauss–newton algorithms for candecomp/parafac,” SIAM J. Matrix Anal.
Appl., vol. 34, no. 1, pp. 126–147, 2013.
[48] L. Sorber, M. Van Barel, and L. De Lathauwer, “Optimization-based
algorithms for tensor decompositions: Canonical polyadic decomposition,
decomposition in rank-(l_r,l_r,1) terms, and a new generalization,” SIAM
J. Optimiz., vol. 23, no. 2, pp. 695–720, 2013.
[49] G. Zhou, Z. He, Y. Zhang, Q. Zhao, and A. Cichocki, “Canonical polyadic
decomposition: From 3-way to n-way,” in Proc. 8th IEEE Int. Conf. Computat. Intell. Security, 2012, pp. 391–395.
[50] G. Zhou, A. Cichocki, and S. Xie, “Accelerated canonical polyadic decomposition using mode reduction,” IEEE Trans. Neural Netw. Learn.
Syst., vol. 24, no. 12, pp. 2051–2062, 2013.
Lalit Garg (M’03) received the first degree in electronics and communication engineering from the
Barkatullah University, Bhopal, India, in 1999, and
the Postgraduate degree in information technology
from the ABV-Indian Institute of Information Technology and Management, Gwalior, India, in 2001. He
received the Ph.D. degree from the University of Ulster, Coleraine, U.K., in 2010.
He is currently a Lecturer in Computer Information Systems at the University of Malta, Msida, Malta.
He was a Researcher at the Nanyang Technological
University, Nanyang, Singapore, and at the University of Ulster, Londonderry,
U.K. His research interests include missing data handling, machine learning,
data mining, mathematical and stochastic modelling, and operational research,
and their applications especially in the healthcare domain. He has published
more than 60 technical papers in refereed journals and conferences.
Justin Dauwels (M’03–SM’12) received the Ph.D.
degree in electrical engineering at the Swiss Polytechnical Institute of Technology (ETH) in Zurich,
Zurich, Switzerland, in December 2005.
He is an Assistant Professor with the School of
Electrical and Electronic Engineering Nanyang Technological University (NTU) in Singapore. His research interests include Bayesian statistics, iterative
signal processing, and computational neuroscience.
He enjoys working on real-world problems, often in
collaboration with medical practitioners. He also tries
to bring real-world problems into the classroom. Prior to joining NTU, he was a
Research Scientist during 2008–2010 in the Stochastic Systems Group (SSG),
Massachusetts Institute of Technology, led by Prof. A. Willsky. He received
postdoctoral training during 2006–2007 under the guidance of Prof. S.-i. Amari
and Prof. A. Cichocki at the RIKEN Brain Science Institute in Wako-shi, Japan.
Dr. Dauwels is a member of the IMS. He has been a JSPS postdoctoral
fellow (2007), a BAEF fellow (2008), a Henri–Benedictus Fellow of the King
Baudouin Foundation (2008), and a JSPS invited fellow (2010). He has won
several Best Paper awards at international conferences on signal processing.

1580

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 5, SEPTEMBER 2014

Arul Earnest received the Ph.D. degree from the
Queensland University of Technology, Australia, in
March 2010.
He is an Associate Professor and the Centre Director with the Centre for Quantitative Medicine,
Saw Swee Hock School of Public Health, National University of Singapore, Singapore. He is
also an Adjunct Senior Lecturer (Biostatistics) at
the Sydney Medical School, Camperdown, N.S.W.,
Australia. His current research interest includes
Bayesian spatio-temporal models. He has developed
and applied these models on a number of diseases in Singapore and Australia.
For more than 15 years, he has provided consultative and collaborative methodological input to clinicians and hospital administrators. The outcome for some
of this work has been more than 100 publications in a variety of peer-reviewed
international medical journals, including BMC Health Services Research, BMJ,
and JAMA, more than 100 presentations, as well as several research awards. He
has secured several recent grants, including a large Australian ARC grant, as
well as an NMRC grant from Singapore. He has extensive experience in conducting talks on biostatistics and research methodology. He regularly reviews
articles for journals, including BMC Health Services Research and MJA.

Khai Pang Leong graduated from the National University of Singapore, Singapore, in 1987.
He is a Senior Consultant in the Department of
Rheumatology, Allergy, and Immunology, Tan Tock
Seng Hospital, Singapore. He also holds a concurrent
position as the Assistant Chairman Medical Board
(Research) in the same institution. He became a Fellow of the Academy of Medicine, Singapore, in 1998,
and of the Royal College of Physicians, Edinburgh in
2002. He has published scientific articles on clinical
research in systemic lupus erythematosus, rheumatoid arthritis, and drug allergy.

