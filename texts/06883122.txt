342

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

Information-Transmission Rates in Manual Control
of Unstable Systems With Time Delays
Mircea F. Lupu, Mingui Sun, Senior Member, IEEE, Fei-Yue Wang, Fellow, IEEE,
and Zhi-Hong Mao∗ , Senior Member, IEEE

Abstract—In analyzing the human–machine interaction (HMI),
a human-centered approach is needed to address the potential and
limitation of human control, especially in the control of high-order
or unstable systems. However, there is no quantitative measure of
the human performance or cognitive workload in these difficult
HMI tasks. We propose to characterize the HMI as information
flows quantified by the information-transmission rate in bits per
second (b/s). Using information- and control-theoretic approaches,
we derive the minimum rates of information transmission in manual control required by any deterministic controller to stabilize
the feedback system. Furthermore, we suggest a method adopted
from time-series analysis to estimate the information-transmission
rate from human experiments. We show that the relationship between the empirically estimated information rates and the minimum bounds allows for the quantitative indication of the potential
and limitation of human manual control. We illustrate our method
in the control of an inverted pendulum with time delays.
Index Terms—Entropy rate, human-in-the-loop control, information rate, time delay, unstable system.

I. INTRODUCTION
HE main goal of automation is to reduce human workload in various human-machine interactions (HMIs). The
responsibilities of human operators seem to have shifted from
active intervention to passive roles such as supervision and maintenance. However, a set of modern applications in control systems opens up new challenges for the human involvement in
an operating machinery. Examples can be found in a variety of
fields. In biomedical applications, such as telesurgery, the doctor performs surgery on a patient from a remote location. Since
the first transatlantic telesurgery from 2001 [1], investigations
in remote surgery focused mainly on introducing more sensory
information for the surgeon such as force feedback and reducing the impact of time delay of the communication channel

T

Manuscript received July 14, 2013; revised July 16, 2014; accepted August
15, 2014. Date of publication August 26, 2014; date of current version December
18, 2014. This work was supported in part by the National Science Foundation
under Grant CMMI-0953449 and the National Natural Science Foundation of
China under Grants 71232006 and 61233001. Asterisk indicates corresponding
author.
M. F. Lupu is with the Department of Electrical and Computer Engineering,
University of Pittsburgh, Pittsburgh, PA 15261 USA (e-mail: mil54@pitt.edu).
M. Sun is with the Department of Neurological Surgery, University of Pittsburgh, Pittsburgh, PA 15261 USA (e-mail: drsun@pitt.edu).
F.-Y. Wang is with the Institute of Automation, Chinese Academy of Sciences,
Beijing 100190, China (e-mail: feiyue@gmail.com).
∗ Z.-H. Mao is with the Department of Electrical and Computer Engineering and also with the Department of Bioengineering, University of Pittsburgh,
Pittsburgh, PA 15261 USA (e-mail: maozh@engr.pitt.edu).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2014.2352173

that bridges the surgeon and the patient [2], [3]. In industrial
applications, such as in underground mining, remotely controlled robots are used to explore and map inaccessible or dangerous locations for humans. In military applications, remotely
human-controlled robots have been successfully used in military
bomb detection and diffusion operations. In space exploration,
remote-controlled space vehicles were deployed to survey new
planets. Given the complexity of the HMI devices and the time
delay of the communication channel, human operators guide
these vehicles remotely from the Earth in order to get insights
of the harsh environment on these planets located far away in
our galaxy.
The complexity of the HMI has to be addressed in such applications because humans are no longer merely users but rather
indispensable active components of these systems. Therefore, it
is important to understand the human capabilities and to assess
their potential and limitations in such human-in-the-loop control systems. However, not much research has been conducted
on the capabilities of the human operator given the time delay
and the limited sensory information.
The interaction between human and machine can be modeled as information flows through bidirectional communication
channels [4], [5], where the human receives sensory information from the machine and sends command information back
to the machine. The interaction between human and machine
can then be characterized by dynamics of information exchange
measured in bits per second (b/s). Moreover, the informationtransmission rate from human to machine is expected to depend
on the complexity of the machine dynamics as well as human capabilities and limitations. We propose to investigate this
dependence in order to provide a quantitative measure of the
human performance and cognitive workload.
In this paper, using information- and control-theoretic approaches, we first derive the minimum information rate required
for the stabilization of a feedback control system. Then, we suggest an empirical method using Renyi entropies and correlation
sums to estimate the information-transmission rate generated
by human controllers when performing a 1-D manual control
task on an unstable system. A set of experiments are conducted
where human controllers maneuver a joystick to stabilize an
inverted pendulum simulation. Two scenarios are analyzed: 1)
when time delay affects the control system and 2) when the
degree of instability of the task is varied.
A comparison between the information-transmission rates required for feedback stabilization and the empirically estimated
rates can provide insight into both the assessment of the human performance and the prediction of its limitations. For

0018-9294 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

LUPU et al.: INFORMATION-TRANSMISSION RATES IN MANUAL CONTROL OF UNSTABLE SYSTEMS WITH TIME DELAYS

example, it will be possible to record the informationtransmission rates for different time delays and to estimate the
maximum amount of time delay beyond which the human cannot stabilize the system. Moreover, the maximum achievable
information-transmission rate can provide an estimation of the
capacity of human manual control.
A. Related Studies
Shannon developed the information theory to describe the
functionality of a communication system [6]. Our investigation
uses a similar analogy to the communication system, where the
human controller is assumed to be able to convey information
and to obey afferent limitations similar to a communication
channel.
The information theory has been applied to characterize the
performances of human sensory and motor systems since 1950s
[4], [5], [7], [8]. For movement control, Fitts proposed the famous Fitts law to address the speed and accuracy tradeoffs [9].
His data suggested that the information-processing rate in a 1-D
discrete movement was approximately 10 b/s [9]. In a set of
tracking experiments [10], [11], the observed maximum rate of
human information processing via 1-D movement was limited
by about 9 b/s for continuous tracking and 11 b/s for discrete
tracking.
These studies encourage the use of information rates for characterizing the human performance, especially in the interaction
with machines. However, the information rates were derived
for either specific simple discrete-movement tasks or tracking tasks where manual control was evaluated by the ability
to track some given signals. Instead, our investigation focuses
on estimating the information rate exchanged between the human operator and machine in a feedback control system. The
dynamics of the controlled system may be unstable and require the human operator to continuously generate control commands (e.g., piloting a plane through a turbulence zone). In
such interactive HMI tasks, the information rates delivered by
the human should depend on the complexity of machine dynamics. Our study aims to investigate this dependence quantitatively by analyzing the time series generated by the human
response.

343

function, then
I(x; y) =



Pxy (x, y) log

x∈X y ∈Y

Pxy (x, y)
.
Px (x)Py (y)

Throughout this study, we assume log to the base 2 such
that the mutual information is measured in bits. We adopt
the convention 0 log 0 = 0. The quantity H(x) = I(x; x)
is called the entropy, and it is a measure of uncertainty
about the random variable x.

H(x) = −
Px (x) log Px (x).
(2)
x∈X

2) If X = R and Y = R , and the probability densities px
and py and the joint probability density pxy are well defined, then
 
pxy (x, y)
I(x; y) =
dxdy.
pxy (x, y) log
p
x (x)py (y)
Rs Rq
(3)
Similarly, the entropy of continuous random variables,
h(x), also referred to as differential entropy, is defined as

h(x) = −
px (x) log px (x)dx.
(4)
q

s

Rq

Without loss of generality, we consider the case of continuous
random variables to define the joint entropy h(x, y) and the
conditional entropy h(x|y) as
 
h(x, y) = −
pxy (x, y) log pxy (x, y)dxdy
Rs


h(y|x) = −

Rq



pxy (x, y) log pxy (y|x)dxdy.
Rs

Rq

The entropy h(x) of continuous random variables can be
related to the entropy H(x) of discrete random variables. By
assuming that the range X can be divided into bins of length ,
then according to [12, Th 8.3.1, p. 248]:
H(x ) + log  → h(x),

as  → 0

(5)

where H(x ) is the entropy of the quantized version of the
continuous random variable x. The mutual information between
x and y can then be rewritten in different ways as follows:
I(x; y) = h(x) + h(y) − h(x, y)

II. TECHNICAL PRELIMINARIES

(1)

(6)

= h(x) − h(x|y)

A. Shannon’s Information Theory

≈ H(x ) + log  − H(x |y ) − log 

This section introduces the notation and definitions for the
information-theoretic terms that are used throughout the study.
The main references are [6] and[12].
Let x and y be random variables or vectors that take values in the ranges X and Y, respectively. We define the mutual
information between two random variables as the measure of
information that one random variable contains about the other.
Depending on the probability space, the mutual information and
the entropy can be expressed as follows.
1) If X and Y are countable, and Px and Py are probability mass functions and Pxy the joint probability mass

= H(x ) − H(x |y )
= I(x ; y ),

as  → 0.

(7)

The transmission of information over a communication channel is quantified by the mutual information, which estimates the
rate of bits per channel use that can be successfully transmitted
with an arbitrarily small probability of error [6].
The entropy, joint entropy, conditional entropy, and the mutual information are functionals of probability distributions and
do not depend on the specific values of x ∈ X and y ∈ Y. They
satisfy the following properties.

344

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

1) I(x; y) ≥ 0, with equality if only if x and y are
independent.
2) The entropy of a discrete random variable (2) is always
nonnegative.
3) The differential entropy (4) can be negative for certain
probability distributions.
4) The chain rule for the mutual information
I(x, y; z) = I(x; z) + I(y; z|x).

(8)

Fig. 1. Human-in-the-loop system: the manual command v generated by the
deterministic controller K is contaminated by the remnant d before delivery to
the plant P .

5) The data-processing inequality establishes
I(x; g(y)) ≤ I(x; y)

(9)

for any measurable function g(·) of the data y.
Given a time sequence of random variables xn −1 =
{x(0), x(1), ..., x(n − 1)}, which we refer to as a time series,
we are interested in determining the average sufficient information (in bits) to describe the sequence. For independent identically distributed (i.i.d.) random variables, the sequence of length
n can be described by n · H(x) bits of information if each x is a
discrete random variable and by n · h(x) bits of information if
x is continuous. However, if the random variables are not i.i.d.,
then the entropy of the sequence scales with n by the entropy
rate, which is defined as
H∞ (x) = lim sup
n →∞

H(xn −1 )
n

(10)

for a sequence of discrete random variables and as
h∞ (x) = lim sup
n →∞

h(xn −1 )
n

(11)

for a sequence of continuous random variables when the limit
exists.
The mutual information rate is defined as the rate at which
the mutual information scales with the length n of the time
sequences corresponding to two random variables
I∞ (x; y) = lim sup
n →∞

I(xn −1 ; yn −1 )
.
n

(12)

As a universal measure of the rate at which information is
transmitted reliably over an arbitrary communication medium,
the mutual information rate, also referred to as informationtransmission rate in our investigation, is used to assess the performance of the human controller in a feedback control system.
B. Renyi Entropies and Correlation Sums
We introduce the concepts of Renyi entropies and correlation sums [13], which will be used to estimate the informationtransmission rate numerically. Consider a time series of random variables, {u(t1 ), u(t2 ), ..., u(tm )}, measured at finitetime intervals τ , i.e., ti+1 = ti + τ . Assume that each u(ti ) is a
D-dimensional vector and the time series constitutes a trajectory
in the D-dimensional continuous phase space. If the phase space
c
of size
is covered by a partition P of disjoint cells {αk }nk =1
t1
t2
D
 , then the joint probability distribution P (αl 1 , αl 2 , ..., αltmm )
is defined as the probability that the time series successively visits the partition cells (αl 1 , αl 2 , ..., αl m ), with li ∈ {1, 2, ..., nc }
at times ti . In the particular case of a time series, where scalar

measurements are observed, the partitions are intervals on the
real axis. The order-q Renyi block entropy of block size m can
then be formulated as
Hq (m, ) =




1
log
P q αlt11 , αlt22 , ... , αltmm .
1−q

(13)

P

The order-q generalized entropy rate is defined as the information needed to predict in which cell the trajectory (time series)
will be at time tm +1 given the trajectory up to time tm
hq (m, ) = Hq (m + 1, ) − Hq (m, ).

(14)

Shannon’s entropy rate can be obtained by taking the limits
q → 1 and m → ∞ in (14). When hq (m, ) is evaluated relative
to the size of the partition cells , this entropy rate may be
invariant over a range of  values, also called plateau.
We now introduce correlation sum, which can be used to
numerically compute hq (m, ) for a time series of scalar random
variables, u(t1 ), u(t2 ), .... We first construct a time series of
“delay vectors” with the kth delay vector defined as
û(k) = [u(tk ), u(tk − τ ), ..., u(tk − (m − 1)τ )]T

(15)

where m is also called the embedding dimension and T means
transpose. Then, the order-q generalized correlation sum is used
to approximate the probability that two delay vectors of the
above constructed time series are closer than a threshold 
⎡
⎤q −1
M
M


⎣
Θ( − ||û(i) − û(j)||)⎦
Cq (m, ) = K
i=1

j =1,j 	= i

(16)



where K = 1/ M (M − 1)q −1 is a normalizing factor, M is
the length of the time series, || · || is the Euclidean norm, and
Θ(·) is the Heaviside step function: Θ(x) = 0, if x ≤ 0, and
Θ(x) = 1, otherwise. It can be derived [13] for the range of
-values in the plateau region of hq (m, ) as
hq (m, ) =

Cq (m, )
1
log
b/sample.
q−1
Cq (m + 1, )

(17)

In practice, the dimension m is estimated using the false
nearest neighbor algorithm [14]. The time lag τ between successive samples is an important parameter when over- or undersampling the data. Studies suggest that a good choice of the
lag τ is the 1\e-crossing of the normalized autocorrelation
function [13].

LUPU et al.: INFORMATION-TRANSMISSION RATES IN MANUAL CONTROL OF UNSTABLE SYSTEMS WITH TIME DELAYS

III. METHODS
Consider the human-in-the-loop system illustrated in Fig. 1,
where the human controls an unstable system or plant P . Assume that the dynamics of the plant can be described by the
discrete-time state-space equation
x(k + 1) = Ax(k) + Bu(k − rd )
y(k) = Cx(k)

(18)

where x is the state vector of the plant; u and y are the input
and output of the plant; rd represents any time delay included in
the plant dynamics (e.g., due to a transmission link in a network
channel); and A, B, and C are the state-, input-, and output
matrices, respectively.
The human controller is assumed to be a quasi-linear system
[15], [16], such that the control command u is based on two
components
u=v+d

(19)

where v represents the component that is linearly correlated
to the perceived sensory signals r and y; and d, also called
“remnant,” represents all the output content that cannot be described by the linear element. The sources of the remnant are
impossible to be identified uniquely. However, it was shown
[16] that it can be caused by multiple factors such as noise related to sensing capabilities and implementation of movement,
nonlinear operations, and nonsteady behavior such as learning
abilities. Without loss of generality, we assume the reference
signal of the feedback system r to be zero.
The human sensorimotor system is modeled as an information
channel, and the information-transmission rate from the human
to machine is characterized by the rate of information conveyed
from y to u and measured by I∞ (y; u).
A. Difficulties in Computing I∞ (y; u)
As a component of a feedback control system, the controller
is expected to generate command signals to ensure the stability of the closed-loop system. The capability of the controller
to convey information is measured by the mutual information
rate (12). By assuming that the input y and the output u of
the controller can be measured with an arbitrarily high sampling frequency (i.e., great resolution), the following difficulties
are encountered when computing the mutual information rate
numerically.
1) The joint probability distributions are unknown and difficult to be estimated from a limited number of data samples
obtained from the measurements.
2) The computation of infinite limits involves additional difficulties due to the limited number of data samples.
3) The time series is recorded at a fixed sampling frequency,
and the observed samples have to be assigned to the discrete sequences yn −1 and un −1 : if data are oversampled,
then even a large sequence may not contain enough information to characterize the system due to redundancies;
if the data are undersampled, then very important proper-

345

ties of the system may be lost when estimating the joint
probability distributions.
Instead of computing I∞ (y; u) with the aforementioned challenges, we take an indirect method to estimate a lower bound
and an upper bound for the information-transmission rate. The
lower bound is derived based on the connections between the
information-transmission rate and the degree of instability of
the system under control. The upper bound is estimated based
on the entropy rate of the manual control signal u as introduced
in Section II-B. We pursued this upper bound because we only
need to focus on one time series rather than two series (y and
u) and the numerical method to estimate the entropy rate of
u using the correlation sum formulation (17) has proven to be
a robust method in time series analysis [13]. Moreover, this
approach provides techniques to mitigate difficulties related to
both oversampling/undersampling and quantizing the recoded
time series.
B. Lower Bound for I∞ (y; u)
The following theorem establishes a connection between the
information rate I∞ (y; u) and the stability properties of the
plant in Fig. 1. This theorem is an immediate generalization of
some recent results on feedback control with communication
constraints (e.g., [17]–[21]). The unstable plant P is said to be
stabilized in the mean-square sense if, through feedback control,
the state vector x satisfies



(20)
sup E x(k)T x(k) < ∞
k

where E[·] is the expected value operator.
Theorem 1: For the human-in-the-loop control system indicated in Fig. 1, if the human controller stabilizes the unstable
plant in the mean-square sense, then
I∞ (y; u) ≥

p


log |λi |

(21)

i=1

where λi , i = 1, 2, ..., p, are the unstable eigenvalues of A, the
state matrix of the plant. The lower bound of the informationtransmission rate in a feedback system is thus shown to be
dependent on the degree of instability of the plant.
Proof: According to [19, Th. 4.2, p. 1608], the following
inequality holds for the feedback control system in Fig. 1:
I(x(0); un )
(22)
n →∞
n
where un = {u(0), ..., u(n)}. If the human controller stabilizes
the plant in the mean-square sense as defined by (20), then according to [21, Lemma 4.1, p. 61], the following is also satisfied:
h∞ (u) ≥ h∞ (d) + lim inf

I(x(0); un ) 
≥
log |λi |
n
i=1
p

lim inf
n →∞

(23)

where |λi |, i = 1, 2, ..., p, represents the magnitude of the unstable eigenvalues of A. As indicated in [19, Lemma 4.3, p. 1608],
the results of (22) and (23) can be summarized as
h∞ (u) ≥ h∞ (d) +

p

i=1

log |λi |.

(24)

346

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

Additionally, the information-transmission rate satisfies the
following inequalities:
I∞ (y; u) ≥ I∞ (v; u)

(25)

= h∞ (u) − h∞ (u|v)

(26)

= h∞ (u) − h∞ (v + d|v)

(27)

= h∞ (u) − h∞ (d|v)
≥ h∞ (u) − h∞ (d)

(28)

where the inequality (25) follows from (9): I∞ (v; u) =
I∞ (K(y); u) ≤ I∞ (y; u) according to the assumption that K
is causal and deterministic; (26) was obtained from the mutual
information rate formula (6); in (27), the command u was substituted according to (19); and in (28), we used the property
that conditioning reduces entropy: h(d|v) ≤ h(d). By following (24), we obtain (21).


Fig. 2.

Illustration of an upper bound for I∞ (y; u).

C. Upper Bound for I∞ (y; u)
To establish an upper bound for I∞ (y; u), we first consider the
relationship between the mutual information rate of continuous
random variables and their quantized version (7) as
I∞ (y; u) = lim I∞ (y ; u ).
→0

(29)

By quantizing a continuous random variable, we obtain a discrete random variable with a finite alphabet. The next theorem
provides an upper bound for the mutual information of discrete
random variables, I∞ (y ; u ).
Theorem 2:
I∞ (y ; u ) ≤ H∞ (u ).

(30)

Fig. 3. Coarse grained dynamical entropy h q (m, ) for a continuous stochastic signal (dotted line), deterministic signal (dashed line), and deterministic
signal with measurement noise (solid line). Figure adapted from [13].

Proof:
I∞ (y ; u ) = lim sup
n →∞

= lim sup
n →∞

≤ lim sup
n →∞

D. Numerical Computation of H∞ (u )

I(yn −1 ; un −1 )
n

As introduced in Section II-B, the generalized entropy rate
hq (m, ) can be used to estimate H∞ (u ) [13] as follows:

H(un −1 ) − H(un −1 |yn −1 )
n

H∞ (u ) = lim lim hq (m, ).
m →∞ q →1

H(un −1 )
n

= H∞ (u ).



Note that, as  → 0, the left side of (30) becomes I∞ (y; u),
but the right side turns to H∞ (u), which is infinity if u is
a continuous random variable, making H∞ (u) a trivial upper
bound of I∞ (y; u). Therefore, rather than considering the limiting situation  → 0, we can choose a sufficiently small , at
which I∞ (y ; u ) has reached the “plateau” (see Fig. 2) and
been very close to I∞ (y; u). As illustrated in Fig. 2, for any 
in the “plateau” region, H∞ (u ) has a finite value and can serve
as an upper bound for both I∞ (y ; u ) and I∞ (y; u).
I∞ (y; u) ≈ I∞ (y ; u ) ≤ H∞ (u ).

(31)

The next section discusses the computation of the upper bound
H∞ (u ) numerically.

(32)

Gaspard and Wang [22] referred to hq (m, ) as coarse-grained
dynamical entropy and -entropy per unit time based on its
scaling with the resolution . They emphasized the advantages
of evaluating hq (m, ) relative to different values of , such as
observing a convergence to a constant entropy rate (“plateau”)
over a range of -values (see Fig. 3). Recall from (17) that the
entropy rate can be computed using the correlation sum for the
range of -values that resemble a plateau.
Beyond the variation with  and m, hq (m, ) also depends
on q. Although taking q → 1 yields Shannon’s entropy rate,
the accuracy of this estimate is strongly dependent on the quality and the amount of data samples. Following the protocol of
Grassberger and Procaccia [23], we compute hq (m, ) using the
order q = 2, because it is by far the easiest to estimate: the correlation sum only requires the computation of the arithmetic average over the number of neighbors. Moreover, choosing q = 2
was shown to be numerically robust [13]. When a plateau can
be observed in the plot of h2 (m, ) versus , the value of this

LUPU et al.: INFORMATION-TRANSMISSION RATES IN MANUAL CONTROL OF UNSTABLE SYSTEMS WITH TIME DELAYS

347

the inverted-pendulum dynamics and derive its transfer function
for small θ as follows:
P (s) =

Fig. 4. Inverted pendulum restricted in a plane. (a) Computer simulation
adapted from [26]. (b) Definitions of variables.

plateau, h2 , is known to provide a good numerical approximation of Shannon’s entropy rate [22], [23].
The entropy rate h2 (m, ) can then be computed in terms of
bits per second as follows:
h2 (m, ) =

C2 (m, )
1
log
b/s
τ
C2 (m + 1, )

(33)

where τ is the lag in the delay vector and C2 (m, ) is defined by
(16), for q = 2. The computation of h2 (m, ) from the time series representing manual control actions was performed with the
help of the software package TISEAN (TIme SEries ANalysis)
[24].
Therefore, if h2 (m, ) plotted versus  scales to a plateau h2
for increasing m, then its value approximates an upper bound
for I∞ (y; u) as
I∞ (y; u) ≈ I∞ (y; u ) ≤ H∞ (u ) ≈ h2 .

(34)

E. Human Experiments
Among various HMI tasks, stabilizing unstable systems is
of special interest to researchers because this family of tasks
challenges the human sensorimotor system continuously. In our
investigation, the performance of the human operator is analyzed
when controlling an unstable system. In the human-in-the-loop
system shown in Fig. 1, the human subject balances a computersimulated inverted pendulum restricted in a plane. The manual
control of one degree of freedom is exerted using a joystick [see
Fig. 4(a)]. The equations of the inverted pendulum system [see
Fig. 4(b)] are described in [25].
mL2 d2 θ mL
d2 x
mgL
cos
θ
sin θ
+
=
3 dt2
2
dt2
2

(35)

where m is the mass of the pendulum (uniform rod), L is the
length of the pendulum, θ is the angle of the pendulum relative
to the vertical position, x is the displacement of the bottom tip
of the pendulum, and g = 9.81 m/s2 is the gravitational acceleration. The control variable or input of the inverted pendulum
system is the displacement x applied to the bottom tip of the
pendulum. The output of the inverted pendulum system is the
angle θ, which is to be kept as small as possible. We linearize

− αg s2
− α s2
Θ(s)
√ g
√
= 2
=
X(s)
s −α
(s + α)(s − α)

(36)

where α = 3g/(2L).
The linearized dynamics of the inverted pendulum system
yields two poles, one of which is real and positive. This unstable
pole
 varies inversely with the length of the pendulum: λu =
3g/(2L), and its magnitude reflects the degree of instability
of the system. The poles of a transfer function are equivalent
to the eigenvalues of the state matrix if the linear equation is
rewritten in the state-space representation. Therefore, these two
terms are used interchangeably because they refer to the same
quantity.
We investigate two representative scenarios of manual control
in which the difficulty of the control task is increased.
1) When introducing various time delays in the feedback
system: a pendulum length of 20 m will be used for the
following time delays: 0, 100, 200, 400, and 600 ms.
2) When changing the degree of instability of the control
task by varying the pendulum length without time delay:
20, 12, 8, 5, and 3 m.
Eighteen subjects were recruited to conduct the experiment.
They were instructed to keep the inverted pendulum as close
as possible to the vertical position, and that the deviation from
the upright position was the measure of the performance. The
subjects received a short practice session in order to be accommodated with the task. Afterward, ten trials were recorded for
each time delay and each pendulum length in a random order.
The maximum duration of a trial was 60 s when the subjects did
not drop the pendulum. The first 5 s of each trial were omitted
because some subjects tended not to generate a control movement before the inverted pendulum started to fall. Data were also
taken into consideration for shorter trials corresponding to the
situation when the pendulum was dropped before 60 s elapsed.
This is specific for scenarios that were difficult to control for
the human operator. However, the last 3 s were omitted in this
case because the subjects usually did not generate a control
signal while they were observing the inverted pendulum reach
the maximum deviation from the vertical position. Therefore,
the data from subjects that were not able to stabilize the inverted pendulum for longer than 8 s were discarded from the
calculations.
The trials corresponding to each time delay and pendulum
length following the preprocessing steps mentioned previously
were concatenated in order to obtain a larger time series for
each situation. These time series were used in formula (33) to
estimate the information-transmission rate.
IV. RESULTS
A. Lower bound of I∞ (y; u)
According to expression (21) from Theorem 1, a lower bound
of the information-transmission rate for any deterministic controller is dependent on the unstable poles of the plant. The
inverted pendulum system in our application has one unstable

348

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

TABLE I
ESTIMATED UPPER BOUNDS OF INFORMATION-TRANSMISSION RATES FOR
18 SUBJECTS
Pendulum length [m]

Fig. 5. Estimation of entropy rate h 2 for the control of an inverted pendulum
with no time delay. The curves correspond to the embedding dimensions m = 1
(circles) to 10 (stars).


pole, λu = 3g/(2L), so the minimum rate of information required to stabilize the feedback system can be derived as
p




log |λi | = log eλu Δ t  b/sample

20

12

8

5

3

Time delay [ms]

0

100

200

400

600

0

Subject A [b/s]
Subject B [b/s]
Subject C [b/s]
Subject D [b/s]
Subject E [b/s]
Subject F [b/s]
Subject G [b/s]
Subject H [b/s]
Subject I [b/s]
Subject J [b/s]
Subject K [b/s]
Subject L [b/s]
Subject M [b/s]
Subject N [b/s]
Subject O [b/s]
Subject P [b/s]
Subject Q [b/s]
Subject R [b/s]

6
3.8
2
2.8
2.7
2.4
4
3
3.2
2.6
2.5
2.8
2.9
2.3
6.3
2.4
2.3
2.1

5
2.9
2.5
3.1
2.2
2.3
3.9
3.4
3.1
3.2
2.7
2.7
3.2
2
4.5
2.2
1.9
2.3

6
2.1
2.6
2.8
2.5
2.5
4.4
3.4
2.6
2.6
2.2
2.8
2.5
4
4
1.8
1.7
2.7

2.6
2.7
2.3
2
2
3.2
2
2.5
2.6
3
2.7
1.7
2.7
3.7
2
1.7
2.2

5
2
2.5
2.8
1.7
1.3
1.5
1.5
2
2.1
1.6
1.9

5
5.4
3.8
3.5
3.8
3
4.7
3.8
4.5
4
4
4.5
3.2
5.7
6.4
3.9
2.4
3.5

7
5.5
4
6.7
4.2
3.8
6
4.1
5.3
6.2
4.1
6.2
4.9
3.9
8.1
4.3
3.3
4.6

5
7.6
5
5
6
6.8
7
5.8
6.6
7.2
7.5
9
5.5
6.7
5.5

7.8
8.5
8.5
8.6
6
7.1
8
5.7

Average [b/s]

3.12

2.95

2.96

2.45

2.16

4.17

5.12

6.41

7.53

i=1

= λu · Δt · log e b/sample
1
· λu · Δt · log e b/second
Δt

3g
=
· log e b/s
2L
=

where we used the unstable pole representation eλu Δ t corresponding to the discrete-time version of (36). The lower bound
of the information-transmission rate varies with the degree of
instability of the plant, which is inversely related to the pendulum length. Therefore, a smaller pendulum length implies a
larger degree of instability, and consequently, the controller is
required to deliver information at a higher rate to stabilize the
feedback system.
B. Upper bound of I∞ (y; u) from Experiments
We used h2 (m, ) defined in (33) to estimate an upper bound
of I∞ (y; u). The control signal, represented by the displacement
x of the bottom tip of the pendulum, was recorded with a sampling period of Δt = 0.01 s. In order to ensure the stationarity
of the time series, which is required for the entropy rate estimation, we applied a common method by using increments [13].
This procedure takes the difference between adjacent samples
of a time series: xd (k) = x(k + 1) − x(k), to render a new time
series that can be assumed stationary. Therefore, we computed
the entropy rate of the velocity of the generated joystick movements: un = {xd (k)}nk=0 . A maximum embedding dimension
of m = 10 was proven sufficient using the false nearest neighbors algorithm. The time delay τ from the delay vector (15)
was estimated by determining the first minimum of the delayed
mutual information according to [13].
Fig. 5 presents an example of h2 (m, ) plot for a human subject controlling a long pendulum (20 m) with no time delay. The

entropy rate h2 (m, ) is a function of the embedding dimension
m and the -scaling. With increasing m, the entropy rate settles
to a plateau for smaller values of . The value of this plateau
reflects the estimated entropy rate of the human control signal.
The estimated upper bounds of information-transmission
rates using the entropy rate method are listed in Table I for
successful readings from all subjects. We define a “successful
reading” when a plateau can be identified in the coarse-grained
entropy plot of h2 (m, ). Some subjects encountered difficulties balancing the inverted pendulum with large time delays or
high degrees of instability. In these situations, the pendulum was
dropped in less than 60 s, and the limited amount of recorded
data was not sufficient to generate a successful entropy-rate
reading. These situations were marked with “-” in Table I.
Fig. 6 illustrates the estimated upper bounds of the
information-transmission rates that were averaged over all subjects for each experimental scenario. The upper bound was observed to decrease with the amount of time delay in feedback
control [see Fig. 6(a)]. The curve that describes the variation
of the upper bound with time delay is always above the lower
bound set by Theorem 1 for any amount of time delay.
For manual control tasks with higher degrees of instability, the
minimum information-transmission rate required for feedback
stabilization established by Theorem 1 suggests that the human
controller should ramp up its capabilities to convey information
when the degree of instability increases (as the pendulum length
decreases). The estimated upper bounds of the informationtransmission rates reflect a similar tendency: the upper-bound
curve was observed to increase accordingly with the level of
instability of the plant [see Fig. 6(b)].
The statistical significance of the experimental results is illustrated in Tables II–IV via t-test. Table II summarizes the
statistical significance of the estimated upper bounds of the
information-transmission rates relative to the corresponding

LUPU et al.: INFORMATION-TRANSMISSION RATES IN MANUAL CONTROL OF UNSTABLE SYSTEMS WITH TIME DELAYS

349

TABLE III
ONE-TAILED t-TEST FOR TIME DELAY: α = 0.05;
H 0 : μ d e lay 1 − μ d e lay 2 = 0; H a : μ d e lay 1 − μ d e lay 2 > 0
Time delay
tc r it ic a l
ts t a t is t ic
p-value

μ0 − μ1 0 0

μ1 0 0 − μ2 0 0

μ2 0 0 − μ4 0 0

μ4 0 0 − μ6 0 0

μ0 − μ6 0 0

1.697
0.475
0.319

1.694
−0.02
0.493

1.706
1.803
0.041

1.746
0.916
0.187

1.703
2.357
0.013

TABLE IV
ONE-TAILED t-TEST FOR PENDULUM LENGTH: α = 0.05;
H 0 : μ le n g th 1 − μ le n g th 2 = 0; H a : μ le n g th 1 − μ le n g th 2 < 0
Pendulum length
tc r it ic a l
ts t a t is t ic
p-value

μ2 0 − μ1 2

μ1 2 − μ8

μ8 − μ5

μ5 − μ3

μ2 0 − μ3

1.692
2.838
0.004

1.694
2.429
0.010

1.696
2.987
0.005

1.753
2.209
0.022

1.761
8.865
2e-7

their respective lower bounds for all scenarios. Table III shows
the significance of the recorded information-transmission rates
decreasing with increasing time delay. Although the decrease
of information-transmission rates might not be significant for
a slight increase of time delay, e.g., from 0 to 100 ms or from
100 to 200 ms, there is a significant overall decrease in the
information-transmission rate as time delay increases from 0 to
600 ms. Finally, Table IV illustrates a significant increase of the
information-transmission rates with shorter pendulum lengths.
V. DISCUSSION

Fig. 6. Variation of the information-transmission rate (a) with time delay
and (b) with the pendulum length: estimated upper bound of the informationtransmission rate of the human controller (solid) and lower bound according to
Theorem 1 (dashed).

TABLE II
STATISTICAL SIGNIFICANCE OF ESTIMATED UPPER BOUND (μ U ) OF
INFORMATION-TRANSMISSION RATES BEING LARGER THAN THE LOWER
BOUND DERIVED IN THEOREM 1 (μ L )

Pendulum length [m]
Time delay [ms]
tc r it ic a l
ts t a t is t ic
p-value

20
0

100

200

12
400

600

8

5

3

0

1.74 1.74 1.74 1.75 1.79 1.74 1.74 1.76 1.9
6.52 8.58 6.88 9.22 3.21 10.96 10.13 13.2 10.69
3e-6 7e-8 1e-6 4e-8 0.004 2e-9 6e-9 1e-9 7e-6

One-Tailed t-test: α = 0.05; H 0 : μ U − μ L = 0; H a : μ U − μ L > 0

lower bounds given by Theorem 1. For each experimental condition, the observed tstatistic is larger than the critical value
tcritical in the one-tailed t-test at a significance level of 0.05,
implying that the null hypothesis is rejected or the alternative
hypothesis (the upper bound being greater than the lower bound)
is accepted with 95% confidence. Therefore, the upper bounds
of information-transmission rates are significantly larger than

The efficiency and limitation of the human performance
can be analyzed by associating the estimated upper bounds of
the information-transmission rates with the lower bounds (see
Fig. 6). The lower bound of the information-transmission rate
derived in this paper refers to the minimum rate of information required for the controller to stabilize an unstable plant.
If the plant yields unstable poles, the minimum informationtransmission rate required for the stabilization depends on both
the number and magnitude of the unstable poles [see Theorem
1, (21)]. Therefore, the derived lower bound is related to the
dynamics of the performed task. The upper bound of the
information-transmission rate used in this paper is the entropy
rate of the human control signal [see Theorem 2, (30)]. This
bound reflects an approximation of the actual human performance for a specific task and depends solely on the human
ability to perform the task. An upper bound is larger than a
lower bound, if the controller is able to stabilize the unstable
system.
When time delay is present in the system, the estimated upper
bound of the information-transmission rate decreases with the
amount of time delay. Consequently, the quality of the human
performance degenerates when time delay affects the control
task, and the estimated upper bound provides a quantitative measure of this effect. Particularly, the difference between the upper
bound and lower bound indicates whether the human controller
can stabilize the feedback system and how this performance
varies with time delay.

350

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

Except the quasi-linear assumption, our study does not require
the human controller to be modeled as a linear time-invariant
(LTI) controller. Actually, some studies have observed intermittency in human manual control of inverted pendulum [27],
and the intermittent control strategy has certain advantages over
continuous LTI control. For example, intermittent control can
1) temporarily eliminate the sensorimotor noise during the intermittent intervals, 2) probe the plant (controlled system) with
ballistic movements of the high bandwidth, and thus, gain more
information about the plant dynamics, and 3) enable computational and muscular recovery, which helps maintain the level
of attention and allows the fatigue-resistant control [27]. In future research, we will investigate the advanced nonlinear control
strategies acquired in the human motor control, and we believe
that information theoretic methods will complement the control
theory in addressing fundamental neural control problems.
VI. CONCLUSION
Our study proposed a framework combining informationand control-theoretic approaches to quantify (in terms of the
information-transmission rate) the human capability in the manual control of systems with complex dynamics. We derived that,
for a human operator to control an unstable system (plant),
the minimum information-transmission rate of manual control
required to stabilize the feedback system depends on the degree of instability of the plant. We also suggested a method
to estimate the information-transmission rate from human experiments based on time-series analysis. We found that this
quantity varied with the degree of instability of the plant and the
time delay present in the closed-loop system. Specifically, the
information-transmission rate human operators decreased with
time delay and increased with the degree of instability of the
plant. Our results were validated relative to other representative studies on the manual control. In future research, we will
also explore alternative approaches for estimating informationtransmission rates in the human manual control, validating and
potentially improving the results obtained in this paper.
ACKNOWLEDGMENT
The authors would like to thank the reviewers and editors for
their valued comments.

[7] H. Jacobson, “The informational capacity of the human ear,” Science,
vol. 112, no. 2901, pp. 143–144, Aug. 1950.
[8] G. A. Miller, “Human memory and storage of information,” IRE Trans.
Inf. Theory, vol. IT-2, no. 3, pp. 129–137, Sep. 1956.
[9] P. M. Fitts, “The information capacity of the human motor system in
controlling the amplitude of movement,” J. Exp. Psychol., vol. 47, no. 6,
pp. 381–391, Jun. 1954.
[10] T. O. Kvalseth, “Test of the 10 bits/sec channel-capacity hypothesis for
human tracking,” Appl. Math. Modeling, vol. 3, no. 4, pp. 307–308, Aug.
1979.
[11] J. I. Elkind and L. T. Sprague, “Transmission of information in simple
manual control systems,” IRE Trans. Human Factors Electron., vol. HFE2, no. 1, pp. 58–60, Mar. 1961.
[12] T. M. Cover and J. A. Thomas, Elements of Information Theory, 2nd ed.
New York, NY, USA: Wiley, 2006.
[13] H. Kantz and T. Schreiber, Nonlinear Time Series Analysis, 2nd ed.
Cambridge, U.K.: Cambridge Univ. Press, 2004.
[14] M. B. Kennel, R. Brown, and H. Abarbanel, “Determining embedding dimension for phase-space reconstruction using a geometrical construction,”
Phys. Rev. A, vol. 45, no. 6, pp. 3403–3411, Mar. 1992.
[15] D. T. McRuer and E. S. Krendel, “The man-machine system concept,”
Proc. IRE, vol. 50, pp. 1117–1123, May 1962.
[16] D. T. McRuer and H. R. Jex, “A review of quasi-linear pilot models,”
IEEE Trans. Human Factors Electron., vol. HFE-8, no. 3, pp. 231–249,
Sep. 1967.
[17] S. Tatikonda and S. Mitter, “Control under communication constraints,”
IEEE Trans. Autom. Control, vol. 49, no. 7, pp. 1056–1068, Jul. 2004.
[18] N. Elia, “When Bode meets Shannon: Control-oriented feedback communication schemes,” IEEE Trans. Autom. Control, vol. 49, no. 9,
pp. 1477–1488, Sep. 2004.
[19] N. C. Martins and M. A. Dahleh, “Feedback control in the presence
of noisy channels: ‘Bode-like’ fundamental limitations of performance,”
IEEE Trans. Autom. Control, vol. 53, no. 7, pp. 1604–1615, Aug. 2008.
[20] G. N. Nair and R. J. Evans, “Stabilization with data-rate-limited feedback:
tightest attainable bounds,” Syst. Control Lett., vol. 41, no. 1, pp. 49–56,
Sep. 2000.
[21] N. Martins, M. Dahleh, and J. Doyle, “Fundamental limitations of disturbance attenuation in the presence of side information,” IEEE Trans.
Autom. Control, vol. 52, no. 1, pp. 56–66, Jan. 2007.
[22] P. Gaspard and X.-J. Wang, “Noise, chaos and (,τ )-entropy per unit time,”
Phys. Reports, vol. 235, no. 6, pp. 291–343, Dec. 1993.
[23] P. Grassberger and I. Procaccia, “Estimation of the Kolmogorov entropy
from a chaotic signal,” Phys. Rev. A, vol. 28, no. 4, pp. 2591–2593, Oct.
1983.
[24] R. Hegger, H. Kantz, T. Schreiber, and E. Olbrich. (2007). TISEAN
(TIme SEries ANalysis). [Online]. Available: http://www.mpipksdresden.mpg.de/ tisean/Tisean_3.0.1
[25] H. K. Khalil, Nonlinear Systems. Upper Saddle River, NJ, USA: Prentice
Hall, 2002.
[26] M. Bodson, “Fun control experiments with MATLAB and a joystick,” in
Proc. 42nd IEEE Conf. Decision Control, vol. 3, Maui, HI, USA, Dec.
2003, pp. 2508–2513.
[27] I. D. Loram, H. Gollee, M. Lakie, and P. J. Gawthrop, “Human control
of an inverted pendulum: Is continuous control necessary? is intermittent control effective? is intermittent control physiological?” J. Physiol.,
vol. 589, no. 2, pp. 307–324, Jan. 2011.

REFERENCES
[1] J. Marescaux, J. Leroy, M. Gagner, F. Rubino, D. Mutter, M. Vix,
S. E. butner, and M. K. Smith, “Transatlantic robot-assisted telesurgery,”
Nature, vol. 413, pp. 379–380, May 2001.
[2] S. Butner and M. Ghodoussi, “Transforming a surgical robot for human
telesurgery,” IEEE Trans. Robot. Autom., vol. 19, no. 5, pp. 818–824, Oct.
2003.
[3] R. Muradore, D. Bresolin, L. Geretti, P. Fiorini, and T. Villa, “Robotic
surgery,” IEEE Robot. Autom. Mag., vol. 18, no. 3, pp. 24–32, Sep. 2011.
[4] Z.-H. Mao, H.-N. Lee, R. J. Sclabassi, and M. Sun, “Information capacity
of the thumb and the index finger in communication,” IEEE Trans. Biomed.
Eng., vol. 56, no. 5, pp. 1535–1545, May 2009.
[5] M. F. Lupu, M. Sun, R. Xia, and Z.-H. Mao, “Rate of information transmission in human manual control of an unstable system,” IEEE Trans.
Human-Mach. Syst., vol. 43, no. 2, pp. 259–263, Mar. 2013.
[6] C. E. Shannon, “A mathematical theory of communication,” Bell Syst.
Tech. J., vol. 27, pp. 379–423, Oct. 1948.

Mircea F. Lupu received the B.S. degree in automatic control and system engineering from the “Politehnica” University of Timisoara, Timisoara, Romania, in 2007, after completing the final project with
the Institute of Automation, University of Bremen,
Bremen, Germany, in 2007, and the M.S. and Ph.D.
degrees in electrical engineering from the University
of Pittsburgh, Pittsburgh, PA, USA, in 2010 and 2013,
respectively.
He worked as a Software Developer for the automotive company Hella, Timisoara, before attending
the University of Pittsburgh. In 2013, he joined Emerson Process Management
as a Senior Engineer. Since 2014, he has been an Adjunct Lecturer in the Department of Electrical and Computer Engineering, University of Pittsburgh. His
research interests include control theory, human-in-the-loop systems, information theory, networked control, and signal processing and analysis.

LUPU et al.: INFORMATION-TRANSMISSION RATES IN MANUAL CONTROL OF UNSTABLE SYSTEMS WITH TIME DELAYS

Mingui Sun (S’88–M’89–SM’05) received the B.S.
degree in instrumental and industrial automation from
Shenyang Chemical Engineering Institute, Shenyang,
China, in 1982, and the M.S. and Ph.D. degrees in
electrical engineering from the University of Pittsburgh, Pittsburgh, PA, USA, in 1986 and 1989, respectively.
In 1991, he joined the University of Pittsburgh,
where he is currently a Professor of neurosurgery,
electrical and computer engineering, and bioengineering. He is also the Director of Research at Computational Diagnostics, Inc., Pittsburgh. His current research interests include
advanced biomedical electronic devices, biomedical signal and image processing, sensors and transducers, biomedical instruments, artificial neural networks,
wavelet transforms, time-frequency analysis, and the inverse problem of neurophysiological signals. He has authored or coauthored more than 350 publications.
Dr. Sun is an elected Fellow of the American Institute for Medical and
Biological Engineering. He received the Novel Smart Engineering System Design Award at the International Conference on Artificial Neural Networks in
Engineering in 1999, the Best Paper Award at the International Symposium on
Uncertainty Modeling and Analysis in 2003, the Chancellor’s Innovation Award
of the University of Pittsburgh in 2007, 2008, 2010, and 2011, respectively, and
the Distinguished Lectureship of the IEEE Circuits and Systems Society in
2012.

Fei-Yue Wang (S’87–M’89–SM’94–F’03) received
the Ph.D. degree in computer and systems engineering from Rensselaer Polytechnic Institute, Troy, NY,
USA, in 1990.
He joined the University of Arizona, Tucson,
AZ, USA, in 1990 and became a Professor and
the Director of the Robotics Laboratory and Program in Advanced Research for Complex Systems.
In 1999, he founded the Intelligent Control and Systems Engineering Center, Chinese Academy of Sciences (CAS), Beijing, China, where since 2002, he
has been the Director of the Key Laboratory on Complex Systems and Intelligence Science. His current research interests include social computing, web
science, and intelligent control.
Dr. Wang is a Fellow of the International Council on Systems Engineering, the International Federation of Automatic Control, the American Society
of Mechanical Engineers, and the American Association for Advancement of
Science. He has served as a Chair of more than 20 IEEE, ACM, and Institute for
Operations Research and Management Sciences conferences. He was the President of the IEEE Intelligent Transportation Systems Society from 2005 to 2007,
the Chinese Association for Science and Technology in 2005, and the American
Zhu Kezhen Education Foundation from 2007 to 2008. From 1995 to 2000, he
was the Editor-in-Chief of the International Journal of Intelligent Control and
Systems and the World Scientific Series in Intelligent Control and Intelligent
Automation. He is currently the Editor-in-Chief of the IEEE TRANSACTIONS
ON INTELLIGENT TRANSPORTATION SYSTEMS. He received the National Prize in
Natural Sciences of China in 2007 and the Outstanding Scientist Award from
the ACM for his work in intelligent control and social computing.

351

Zhi-Hong Mao (S’96–M’05–SM’09) received the
dual B.S. degrees in automatic control and mathematics and the M.Eng. degree in intelligent control
and pattern recognition from Tsinghua University,
Beijing, China, in 1995 and 1998, respectively, the
S.M. degree in aeronautics and astronautics from
Massachusetts Institute of Technology, Cambridge,
MA, USA, in 2000, and the Ph.D. degree in electrical and medical engineering from the Harvard-MIT
Division of Health Sciences and Technology, Cambridge, in 2005.
He joined the University of Pittsburgh, Pittsburgh, PA, USA, as an Assistant
Professor in 2005 and became an Associate Professor of electrical engineering
and bioengineering in 2011 and William Kepler Whiteford Faculty Fellow in
2012. His research interests include human-in-the-loop control systems, networked control, and neural control and learning.
Dr. Mao received the Faculty Early Career Development (CAREER) Award
of National Science Foundation and the Andrew P. Sage Best Transactions Paper
Award of the IEEE Systems, Man and Cybernetics Society in 2010.

