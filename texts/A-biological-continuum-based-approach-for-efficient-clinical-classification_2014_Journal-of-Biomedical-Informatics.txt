Journal of Biomedical Informatics 47 (2014) 28–38

Contents lists available at ScienceDirect

Journal of Biomedical Informatics
journal homepage: www.elsevier.com/locate/yjbin

A biological continuum based approach for efﬁcient clinical
classiﬁcation
Darwin Tay a,b, Chueh Loo Poh b,⇑, Carolyn Goh a, Richard I. Kitney a
a
b

Department of Bioengineering, Imperial College London, UK
Division of Bioengineering, Nanyang Technological University, Singapore

a r t i c l e

i n f o

Article history:
Received 9 April 2013
Accepted 3 September 2013
Available online 12 September 2013
Keywords:
Classiﬁcation
Dimensionality reduction
Etiological network
Feature selection
Genetic algorithm
Support vector machine

a b s t r a c t
Clinical feature selection problem is the task of selecting and identifying a subset of informative clinical
features that are useful for promoting accurate clinical diagnosis. This is a signiﬁcant task of pragmatic
value in the clinical settings as each clinical test is associated with a different ﬁnancial cost, diagnostic
value, and risk for obtaining the measurement. Moreover, with continual introduction of new clinical features, the need to repeat the feature selection task can be very time consuming. Therefore to address this
issue, we propose a novel feature selection technique for diagnosis of myocardial infarction – one of the
leading causes of morbidity and mortality in many high-income countries. This method adopts the conceptual framework of biological continuum, the optimization capability of genetic algorithm for performing feature selection and the classiﬁcation ability of support vector machine. Together, a network of
clinical risk factors, called the biological continuum based etiological network (BCEN), was constructed.
Evaluation of the proposed methods was carried out using the cardiovascular heart study (CHS) dataset.
Results demonstrate a signiﬁcant speedup of 4.73-fold can be achieved for the development of MI classiﬁcation model. The key advantage of this methodology is the provision of a reusable (feature subset)
paradigm for efﬁcient development of up-to-date and efﬁcacious clinical classiﬁcation models.
Ó 2013 Elsevier Inc. All rights reserved.

1. Introduction
The efﬁcient development of accurate clinical classiﬁcation
models has been a challenge for many reasons. One problem that
is commonly encountered is the ‘curse of dimensionality’ [1], where
the linear growth of clinical features (i.e. predicators) results in an
exponential growth in the search space. This inevitably hinders
the development of classiﬁcation models as it becomes computationally expensive to investigate a plethora of clinical features
simultaneously using search heuristics that analyze features in
combinations (particularly, when performing multivariate analysis
based on wrapper approach). This situation is exacerbated by the
fact that up-to-date and sophisticated clinical classiﬁcation models
need to be constantly developed in order to continually improve the
quality of clinical diagnosis. Speciﬁcally, the clinical classiﬁcation
models need to be rebuilt whenever new clinical risk factors that
could potentially ameliorate the performance of the classiﬁcation
model are introduced. An example of such clinical effort is the
perpetual studies of different types of clinical risk factors and
approaches that could improve the ability to identify events of
⇑ Corresponding author. Address: 70 Nanyang Drive, N1.3-B2-09, Singapore
637457, Singapore. Fax: +65 6791 1761.
E-mail addresses: darwintay@imperial.ac.uk (D. Tay), CLPoh@ntu.edu.sg
(C.L. Poh), c.goh@imperial.ac.uk (C. Goh), r.kitney@imperial.ac.uk (R.I. Kitney).
1532-0464/$ - see front matter Ó 2013 Elsevier Inc. All rights reserved.
http://dx.doi.org/10.1016/j.jbi.2013.09.002

myocardial infarction (MI) [2,3]. This is of paramount importance
as MI is a leading cause of morbidity and mortality in many developed countries, such as the United States (US) and the United Kingdom (UK) [4–6]. Despite considerable advances in medicine, MI
approximately occurs every 34 s in the US and about 15% who experience MI will die from it [4]. Moreover, MI is difﬁcult to ascertain in
patients presenting to the emergency department with anterior
chest pain [2]. This advocates for the need of an efﬁcient approach
to develop up-to-date MI classiﬁcation models for performing accurate diagnosis.
Furthermore, investigation of the association between a range
of clinical observations (e.g. medical history, chemotherapy, stage
of disease, gene, etc.) and the disease at the human population
level is important as it has demonstrated promising potential for
improving disease classiﬁcation performance [7,8]. However, when
such an investigation is carried out on a larger scale, this would
involve a large amount of clinical features, making analysis
challenging and even computationally infeasible. Additionally, it
also hinders the ability for any machine learning method to
perform accurate disease classiﬁcation. One approach to mitigate
the aforementioned problems is through dimensionality reduction
– where signiﬁcant clinical risk factors are identiﬁed, reducing the
total number of predicators that need to be analyzed.
In this paper, we introduce a novel clinical feature selection
methodology for the development of MI classiﬁcation model. This

D. Tay et al. / Journal of Biomedical Informatics 47 (2014) 28–38

approach utilizes on the conceptual framework of biological continuum (BC) [9,10], the optimization capability of genetic algorithm (GA) [11] for performing feature selection and the
classiﬁcation ability of support vector machine (SVM) [12–14] for
dichotomizing patients experiencing a phenotypic manifestation
from healthy individuals. The BC is the hierarchy of the human
organism comprising body, systems, viscera, tissue, cells, proteins
and genes. In this study, it provided the biological paradigm necessary for segregating a range of available clinical features; offering
the advantage of reducing the number of clinical features that
needs to be analyzed concurrently. A GA based wrapper approach
using SVM, which selects signiﬁcant clinical features capable of
dichotomizing patients experiencing a phenotypic manifestation
from healthy individuals, was implemented. This hybrid algorithm
(called GA-SVM) was used to identify important clinical features at
each level of the BC and incrementally built a network of clinical
risk factors, called the biological continuum based etiological network (BCEN). The primary advantage of BCEN used for the construction of up-to-date clinical classiﬁcation model is that it
allows new clinical features to be considered for incorporation into
the classiﬁcation model without the need for a total reanalysis
from scratch.
The reliability of the constructed BCEN was assessed by
comparing the set of identiﬁed risk factors found in the (obesitysystem) sub-network, with the risk factors found in previous clinical studies. Promising results were obtained from this analysis. An
MI classiﬁcation model was subsequently developed based on the
clinical features identiﬁed and present in the BCEN. Signiﬁcant
reduction in the computational time required to develop the classiﬁcation model was achieved. It is noteworthy that comparable
classiﬁcation accuracy was obtained between the proposed method (i.e. pre-selection of clinical features using BCEN) and the baseline approach (i.e. no pre-selection was performed). The
Cardiovascular Health Study (CHS) [15] dataset was analyzed in
this study.
The rest of the paper is organized as follows. Section 2 provides
the background information on feature selection. In section 3, the
experimental methodology involved in the development of the
clinical feature selection technique and the clinical classiﬁcation
model is presented. The experimental results are presented in Section 4 and discussed in Section 5. Finally, conclusions are drawn in
Section 6.

2. Background
Conventionally, clinical predictions which provide the disease
diagnosis for an individual are based on expert knowledge. However, with the exponential growth of clinical data generated in
healthcare industries, this approach has become more and more
difﬁcult and costly. An approach to mitigate this challenge is to
process and analyze the large amount of clinical data, extracting
knowledge that enables support for cost-containment and decision
making [16]. Machine learning is one method that has been proposed to address this issue. It provides the techniques necessary
for the analysis of the data, discovery of hidden patterns and provides healthcare professionals with an additional source of knowledge for decision making. In the parlance of literature, machine
learning is deﬁned as a branch of artiﬁcial intelligence that postulates a set of computer-based methods for automatic analysis of
information and recognition of patterns through repeated learning
from the training data [17], and is a more powerful and sophisticated descendant of traditional statistical models. It is generally
model-free and is capable of efﬁciently detecting and modeling
the non-linear interactions in high dimensional datasets. Additionally, the associations or patterns detected by machine learning

29

methods tend to be logical and can be identiﬁed by human experts
if they analyze the problem carefully enough [18]. Clearly, this entails that machine learning is capable of saving both the time and
effort necessary for the discovery of underlying patterns.
Clinical prediction (e.g. diagnosis of cardiovascular disease)
based on machine learning approaches has gained popularity over
the years [2,16,19–24] and shown to be an extremely useful tool in
medical innovation [21]. It is often based on the patient’s unique
clinical, genetic and environmental characteristics and plays a signiﬁcant role in healthcare decision making and planni ng. Since
each clinical feature collected is associated with a different ﬁnancial cost, diagnostic value and risk [25], it is highly desirable to
reduce the number of clinical tests that need to be taken by a
patient. This would inevitably reduce the ﬁnancial cost, and the
time incurred on both the analysts and patients. One approach
commonly adopted by machine learning techniques to reduce
the number of clinical features while improving the diagnostic/
classiﬁcation accuracy is feature selection.
Feature selection is the process of selecting a subset of relevant
features for model construction and provides better insights into
the target concept of a real-world problem [21]. It differs from
other dimensionality reduction techniques like project and
compression where their original representation of the variables
is modiﬁed. Therefore, feature selection has the advantage of
preserving the original semantics of the features which enables
domain experts to interpret the selected features. Furthermore, it
has shifted from being an illustrative example to one of real prerequisite for developing classiﬁcation models [26]. This is, in part, because of the exponential increase in the dimensionality of the data
(e.g. in clinical and bioinformatics domains), the fact that most
classiﬁers were originally not designed to handle plethora of irrelevant features, and the need to generate more accurate classiﬁers
efﬁciently. In general, feature selection aims to identify a parsimonious subset of useful features (from a large set of features) that (1)
does not decrease the classiﬁcation accuracy, (2) reduces the computational time needed to learn a sufﬁciently accurate classiﬁcation model, (3) does not acutely changes the class distribution
while adequately representative for descripting the target concept,
and (4) reduces the amount of examples that need to be collected
in order to develop a classiﬁcation model with the desired accuracy
[27,28].
Feature selection algorithms typically fall under 4 categories
depending on how it is performed in relation to the classiﬁcation
algorithm. They include (1) selection based on expert knowledge,
(2) ﬁlter approach, (3) wrapper approach, and (4) embedded approach. Each has its own competitive advantages and drawbacks.
Selection based on expert knowledge (e.g. human domain expert
or referencing the scientiﬁc literature) offers a set of features with
high interpretability in relation to the target concept. However, its
major drawbacks are that it can be time consuming and human expert is required to perform the task. An illustration of this approach
is demonstrated in [25], where the number of interaction tests that
need to be performed can be limited with the use of experimental
knowledge of the biological network. More speciﬁcally, knowledge
extracted from protein interaction databases reduces the number
of interaction tests from 1.25  1011 to 7.1  104, allowing more
efﬁcient analysis of genome-wide studies to be carried out.
Filter methods, on the other hand, evaluate the relevance of
each feature by assessing only the intrinsic characteristics of the
data. Although this approach does not need a domain expert to
intervene, is simple, efﬁcient and can easily scale to very highdimensional datasets, it does not always guarantee improved performance [29] as it ignores the inductive bias associated with the
classiﬁer [30]. Examples of ﬁlter techniques include chi-square
test, t-test, information gain, correlation-based feature selection
and Markov blanket ﬁlter.

30

D. Tay et al. / Journal of Biomedical Informatics 47 (2014) 28–38

Wrapper methods embed the inductive bias associated with the
classiﬁer within the feature selection process. In this case, subsets
of features are generated and their performance is assessed by
training and testing them on a speciﬁc classiﬁcation algorithm.
The advantages of this approach are: (1) the freedom to choose
the desired classiﬁcation algorithm, (2) allowing interaction between feature selection and model selection, and (3) ensuring that
feature dependencies are taken into consideration (i.e. the need to
add or remove more than 1 feature at the same time in order to
improve the performance [25]). Consideration of feature dependencies is important, especially in the medical ﬁeld, as it has become evident that multiple genes collectively contribute to the
etiology and clinical manifestation of human diseases [31]. Hence,
important genotypic factors might be missed if they have been
examined in isolation or in a linear fashion – without allowing
for potential interactions. This situation would be exacerbated
when performing genome-wide association studies where hundreds of thousands of single nucleotide polymorphisms (SNPs)
need to be analyzed. Wrapper approach, on the downside, becomes
computationally intensive when the number of features grows
exponentially. This is because every feature subsets generated
need to be executed on the selected learning algorithm. Moreover,
it has a higher risk of over-ﬁtting the classiﬁer than ﬁlter approach.
Examples of this technique include sequential forward selection,
sequential backward selection, simulated annealing, genetic algorithm and estimation of distribution algorithm.
Finally, embedded approach integrates the process of identifying the optimal subset of features within the learning algorithm.
Based on this mechanism, it has the advantage of being more
computationally efﬁcient (compared to wrapper approach) while
maintaining interaction with the classiﬁer. Examples include
decision trees and weighted naïve Bayes.

3. Methodology
3.1. Dataset
The CHS dataset, as described in [15], is an epidemiology study
of the elderly (deﬁned as adults aged 65 and older). It comprises of
elderly subjects from four US communities, namely Forsyth
County, North Carolina; Sacramento County, California; Washington County, Maryland; and Pittsburgh, Pennsylvania. A total of
5888 individuals from urban and rural areas form the baseline
cohort of CHS. Eligible individuals were sampled from Medicare
eligibility lists in each area. Eligible participants included all individuals sampled from the Health Care Financing Administration
(HCFA) sampling frame – they were 65 years or older at the time
of examination, non-institutionalized, expected to remain in the
area for the next 3 years, able to give informed consent and do
not require a proxy respondent at baseline. Individuals who were
wheelchair-bound at home at baseline, receiving hospice treatment, radiation therapy or chemotherapy for cancer were
excluded. The eligible individuals were examined yearly from
1989 to 1999. Extensive physical and laboratory evaluations were
carried out to identify the presence and severity of cardiovascular
disease (CVD) risk factors – such as hypertension; hypercholesterolemia and glucose intolerance; subclinical disease, such as carotid
artery atherosclerosis; left ventricular enlargement; and transient
ischemia. Criteria for identiﬁcation of MI events include: observation of evolving Q-wave, cardiac pain and abnormal enzymes
together with an evolving ST-T pattern or new left bundle branch
block. A total of 355 clinical features related to the individual’s
health status were selected from the CHS dataset for this study.
The dataset was chosen because of (1) the relatively high
prevalence of coronary heart disease (CHD) among the elderly,

(2) worldwide demographic aging, (3) paucity of information
regarding risk factors for CHD among elderly, and (4) the changing
clinical characteristics of CHD with advancing age [4,15,32,33].
3.2. Biological continuum based etiological network (BCEN)
Several steps were taken to construct the BCEN for MI with the
canonical ﬂow illustrated in Fig. 1. A succinct description of the key
steps taken is given below while we dedicate separate sections for
the discussion of the details:
1. Sparse records were removed and missing entries in the dataset
were imputed to ensure good quality data is used to model the
risk factors associated with MI. This was performed with the
K-nearest neighbor (KNN) algorithm [34] – it calculates the
missing value by taking the K nearest training set vectors
(based on Euclidean distance) into consideration.
2. Healthy individuals, forming a large proportion of the dataset in
relation to the number of patient records, were sampled to
avoid jeopardizing the ability of SVM to learn and generalize.
This is carried out with Kohonen Self-Organizing Map (SOM)
[35], where a representative subset of the majority class (i.e.
healthy individuals) present in the CHS dataset was selected,
a process known as under-sampling.
3. Clinical features, such as blood pressure, electrocardiography
(EKG) readings, ultrasound data, hematology data, etc., were
segregated along the BC – the hierarchy of the human organism.
It comprises 7 levels, namely the body, system, viscera, tissue,
cell, protein and gene.
4. GA-SVM, a hybrid algorithm used to identify signiﬁcant clinical
features, was implemented. It is used repeatedly at each level of
the BC to identify signiﬁcant risk factors that are related to the
different phenotypic manifestations, and ultimately MI.
5. With the signiﬁcant risk factors identiﬁed at the different levels
of the BC, they were consolidated to construct a consensus network, known as the BCEN in this work. These risk factors, in
turn, were used to perform MI classiﬁcation using the GASVM algorithm.
3.2.1. Data Imputation
As with many datasets collected from real subjects and patients,
missing data is unavoidable. This may be due to various factors, e.g.
the refusal of respondents, malfunction of equipment, data not entered correctly and the death of patients [36]. Moreover, since the
quality of the results is largely determined by the quality of the
data used in the analysis, detailed consideration was given before
using the CHS dataset. It was found that the CHS dataset contains
a signiﬁcant percentage of missing information. Hence, data imputation was ﬁrst conducted.
Data imputation, the process of substituting missing values in a
dataset with plausible values, was performed using KNN. KNN
imputation was used because of its excellent performance in estimating missing values [37–40] and its ability to estimate both
qualitative and quantitative attributes. This makes it highly suitable for extrapolating the missing entries in the CHS dataset.
Firstly, individuals with unknown MI status were removed from
the analysis. Next, to foster more accurate data imputation, individuals and clinical features with high percentage of missing entries were removed. It is important to have low percentage of
missing values because the accuracy of the imputed result would
suffer if too little complete entries were available for KNN to reference when estimating the missing values [37,40,41]. Hence, individuals and clinical features with more than 20% and 4.5%
missing entries, respectively, were removed. Consequently, the
resultant dataset was normalized to unit variance before data
imputation was performed using KNN. This is important as it

31

D. Tay et al. / Journal of Biomedical Informatics 47 (2014) 28–38

Data Preprocessing

CHS
Dataset

N = 5888
F = 355

Removal of sparse
records and
interpolation of
missing values

N = 4612
F = 272

Balancing the number
of healthy individuals
and patients

N = 853
F = 272

Construction of
Biological
Continuum-based
Etiological
Network

Evaluation of clinical
features at adjacent
levels to identify
significant risk factors

N = 853
F = 174

Segregation of clinical
features into levels of
the biological
continuum

Fig. 1. Canonical ﬂow of the methods adopted to construct BCEN. ‘N’ denotes the number of instances and ‘F’ represents the number of features present in the dataset at
different stages.

ensures that variables with large scale do not dominate the
(Euclidean) distance measure [42].
The optimal value of K for each clinical feature was determined
by 10-fold cross-validation. After the value of K for each clinical
feature had been determined, data imputation for each missing
attribute was performed. The type of replacement method used
depends on the type of data present in each clinical feature. For
instance, if the data is categorical, a reliable choice is to use the
mode of the K nearest neighbors to assign the value for the missing
entries [34,38]. On the other hand, if the data is continuous, the
weighted-mean of the K nearest neighbor is used instead to
calculate the missing value. Weighted-mean estimation has been
demonstrated in [37,43] to be robust and accurate.

3.2.2. Class imbalance data problem
The class imbalance data problem is not uncommon in medical
datasets where the data is predominated by the healthy subjects
(i.e. controls), with only a small number of disease-affected subjects (i.e. cases). Consequently, this limited the effectiveness ability
of standard machine learning algorithms – where the algorithms
tend to be overwhelmed by the major class and ignore the minor
one. This, in turn, hinders performance [44,45]. This class imbalance data problem prevails in the CHS dataset as well. Therefore,
data balancing was performed before deploying the data to GASVM.
SOM, an unsupervised (neural network) learning algorithm, was
employed to under-sample the major class. This algorithm was
chosen because it is capable of generating high quality samples
that are representative of the original dataset [35] and it has been
shown in [46] that SOM outperforms random selection. Once the
imputed dataset was obtained, the SOM was trained in two phases;
namely, the ordering phase and the tuning phase. Two key adaptive parameters, neighborhood size and learning rate, were used
when training the SOM. Neighborhood size deﬁnes the number
of neurons that surround the winning neuron (i.e. most stimulated
neuron) at each epoch, while the learning rate controls the degree
of change for the adapting neurons.
During the ordering phase, large initial neighborhood size (i.e.
10) and learning rates (i.e. 0.9) were used. Conversely, small neighborhood size (i.e. 1) and learning rates (i.e. 0.02) were used during
the tuning phase – where the neighborhood size will shrink progressively to 1. This is to allow the SOM to adjust quickly to the input pattern during the ordering phase and to stabilize the feature
map during the tuning phase [35]. The following value for the
SOM parameters was determined experimentally and used in this
study: number of neurons: 21 by 21; topology function: hexagon;
distance function: Euclidean; epoch: 1000; ordering phase learning

rate: 0.9; tuning phase learning rate: 0.02; initial neighborhood
size: 10; ﬁnal neighborhood size: 1. The reason for using these values is because they have shown to provide reasonable performance.
3.2.3. Segregation of clinical features
The Biological Continuum was central to the development of
the BCEN. It was utilized in this case to provide the necessary biological paradigm to relate the disease mechanisms to the clinical
manifestations at various levels of the biological continuum. Upon
analyzing the clinical features, it was found that these features fall
under 4 key levels along the BC, namely: body, system, viscera and
protein level. Clinical features related to medication were removed
from the study as it was difﬁcult to adjudicate to which level of the
BC they belong. Categorization of the rest of the clinical features, in
relation to the levels of the BC, was undertaken using the following
guidelines:
 Body level – Contains clinical features related to individuals’ personal statistics (e.g. age, weight), lifestyle (e.g. smoking status,
exercise intensity) and cardiovascular events which that individual is experiencing.
 System level – Consists of clinical features related to individuals’
medical history (e.g. arthritis, diabetes), symptoms (e.g. hearing/vision problems) that the individual is experiencing and
blood pressure measurements.
 Visceral level – Clinical measurements, e.g. EKG, ultrasound data
and treatment speciﬁc to an organ were classiﬁed under this
level.
 Protein level – Clinical features related to hematology were
grouped under this level.
3.2.4. GA-SVM
GA-SVM, a hybrid algorithm that comprises of (1) SVM that
models the statistical properties necessary to distinguish healthy
individuals from patients experiencing a clinical phenotype, and
(2) GA that selects the signiﬁcant features that contribute to the
construction of an accurate SVM model, was implemented. In this
work, SVM uses radial basis function (RBF) as its kernel function
and is deﬁned as:

Kðxi ; xj Þ ¼ expðcjjxi  xj jj2 Þ

ð1Þ

where c is a variable used to adjust the width of the Gaussian
functions of the kernel. RBF is used due to its ability to solve nonlinearly separable problems, low complexity involved during model
selection and excellent performance. Two parameters, namely the
regularization cost and gamma (used in RBF) parameters, were
tuned over the recommended range [25, 213] and [215, 23]

32

D. Tay et al. / Journal of Biomedical Informatics 47 (2014) 28–38

respectively [47]. Optimization of SVM parameters were performed
by evaluating a set of cost-gamma combinations deﬁned using uniform design (UD) method [48]. UD is a technique that scatters a set
of points uniformly across the cost-gamma landscape, proposed to
alleviate the computational loads associated with the search for
the optimal cost-gamma pair [49]. This search process begins by
initializing a 30-points UD (global) search across the deﬁned
cost-gamma landscape. Next, it identiﬁes the top 5 most accurate
(global) cost-gamma pairs, where they form the centroid for
10-points UD (ﬁne) search. If improved accuracy was achieved,
the points will form the centroid for another 10-points UD search.
This process repeats until no further improvement is achieved.
Fig. 2 provides an illustration of this method.
Fig. 3 provides the schematic illustration of GA-SVM algorithm.
The ﬂow of the algorithm is as follow: GA ﬁrst (randomly) initializes a pool of clinical feature subsets (Fig. 3 – chromosome 1 to N)
from the CHS dataset (consisting of M clinical features). Each bit in
the chromosome is assigned with a value of either ‘1’ or ‘0’, indicating whether that feature is selected or eliminated from consideration by the classiﬁer, respectively. This produces a pool of
chromosomes representing different input features. Consequently,
each chromosome was evaluated by SVM (where optimization of
SVM parameters was performed independently for each chromosome) in an attempt to determine how informative and discriminative the clinical features are in relation to the associated clinical or
subclinical manifestation. This evaluation is conducted by performing a 10-fold stratiﬁed cross-validation. Subsequently, these
subsets of clinical features undergo natural selection, crossover
and mutation phases postulated by GA. The process repeats until
GA converges or the maximum number of generations has been
reached. GA is considered to have converged if the maximum ﬁtness value (i.e. balanced accuracy – the average of sensitivity and
speciﬁcity) does not improve after 20 consecutive generations.
Upon termination, the subset of clinical features that yielded the
highest balanced accuracy will be selected and considered as signiﬁcant risk factors. A consensus network was constructed if several combinations of clinical feature subset yielded the same
ﬁtness performance. The reason for doing this is to build a parsimonious model that maximizes the likelihood of the clinical features that are most inﬂuential to the development of the
phenotypic manifestation. It was derived by identifying clinical
features that existed in more than 75% of the highest-performing
clinical feature combinations. The parameters value used by GA
are as follow: population size: 250; maximum generation: 300;
natural selection: stochastic universal sampling; crossover type:

uniform crossover; crossover probability: 0.8; mutation probability: 0.01. These values were chosen because they provided satisfactory result when experimented over a range of values. The
algorithm was written in Matlab (MathWorks Inc., Natick, MA)
and executed in parallel using a high performance computer
(HPC) cluster.
3.2.5. Construction of BCEN
The underlying cause of MI is multifactorial and subtle, with
nonlinear causal dynamics. Moreover, with the plethora of clinical
predicators available, analysis of all of them becomes computationally impractical. In view of such challenges, GA-SVM, together
with the conceptual framework of the BC, were used to construct
the BCEN for MI.
Firstly, by segregating the clinical features into various levels
along the BC, the number of clinical features to be analyzed is
effectively reduced to the number of clinical features present at
each level (i.e. dimensionality reduction). Secondly, with the
employment of GA, which is capable of performing global heuristic
searches both effectively and efﬁciently, the computational burden
of discovering signiﬁcant risk factors is alleviated. Finally, facilitated by SVM, which outperforms popular technique like multifactor dimensionality reduction (MDR) [50], it ensures that accurate
estimation of the association between the clinical features at adjacent levels of the BC is being carried out.
At onset, clinical features grouped under the ‘‘body level’’ of the
BC were input into GA-SVM for investigation. This step aims to
identify clinical features that contribute signiﬁcantly to the development of an accurate inference model for MI. Consequently, signiﬁcant risk factors, deﬁned in this work as risk factors that can
potentially contribute to the manifestation of a clinical or subclinical risk, were identiﬁed - forming the top level of the BCEN. If any
of these identiﬁed risk factors are continuous, it is discretized
based on the extended v2 algorithm [51]. The reason for performing this step was to alleviate the associated computational complexity when analysis was performed with SVM.
Next, clinical features categorized under the ‘‘system level’’ of
the BC were input into GA-SVM for investigation. This, similar to
the earlier step, aims to identify clinical features that have a significantly impact to the inference of the phenotypic manifestation
previously identiﬁed at the ‘‘body level’’. The resultant output from
this step forms the ‘‘system level’’ of BCEN. This procedure is
repeated for the rest of the levels along the BC, constructing a probabilistic tree-structured BCEN at the end of this propagation. The
resultant BCEN is capable of scrutinizing how, for instance, clinical

Fig. 2. Graphical illustration of SVM parameter optimization using UD technique. 30-Point UD (Global) search is ﬁrst performed to determine regions with cost-gamma
combinations that would produce the optimal SVM model. Subsequently, 10-point UD (ﬁne) search is carried out to determine the optimal parameter set.

33

D. Tay et al. / Journal of Biomedical Informatics 47 (2014) 28–38

CHS Dataset
Next Generation Population
Clinical Features
1 2 3 4 5 …… M
1 ? ? ? ? ? ? ? ? ?
2 ? ? ? ? ? ? ? ? ?
3 ? ? ? ? ? ? ? ? ?
4 ? ? ? ? ? ? ? ? ?
…

…

…

…

…

…

…

…

…

…

N 1 1 0 1 0 0 0 1 1

Chromosomes

4 1 1 0 0 1 1 1 0 0

Uniform Crossover &
Mutation

3 0 1 0 1 0 1 1 0 0

Natural Selection via
Stochastic Universal Sampling

2 0 1 1 0 1 1 0 1 0

Fitness Evaluation with SVM

Clinical Features
1 2 3 4 5 …… M
1 1 0 0 1 0 1 0 0 1

Extraction of Clinical
Features from CHS Dataset

Chromosomes

Initial Population

N ? ? ? ? ? ? ? ? ?

No

Converge?

Yes

End

Fig. 3. A schematic illustration of clinical feature selection based on GA-SVM. A string of binary value in each chromosome (of size M) represent the present (value of 1) or
absent (value of 0) of a risk factor during evaluation. This set of chromosomes (of size N) is randomly generated at onset and undergo the selection process postulated by GA to
ﬁnd the set of risk factors that produce the highest ﬁtness value. Fitness evaluation is performed with SVM.

features at the visceral level are associated with those at the system level and, in turn, how these features at the system level are
associated with those at the body level. This concept is graphically
illustrated in Fig. 4.
3.3. MI classiﬁcation with BCEN
After the construction of BCEN for MI, the distinct risk factors
present in the network were used to develop an MI classiﬁcation
model. The performance (both classiﬁcation accuracy and computational time) yielded with this approach was compared with an
MI classiﬁcation model that uses all clinical features present in
the CHS dataset. GA-SVM was used as the classiﬁcation algorithm
for both the postulated approaches; hence, any beneﬁts or drawbacks of using this classiﬁer would prevail in both approaches.

instances and 272 clinical features, with less than 1% of missing
values (with respect to the entire dataset) and 40.8% of records
with complete entries. The training and query datasets thus have
1881 and 2731 instances (both with 272 features), respectively.
Subsequently, the K neighbor value for each clinical feature was
determined based on the normalized training dataset. This yielded
an average K value of 9.80, with standard deviation of 9.38. Data
imputation was next performed to impute the missing entries
found in the query dataset.
The imputed dataset obtained has a high fraction of controls
(i.e. without MI – 4200 instances) and a relatively small portion
of cases (i.e. with MI – 412 instances). SOM was thus employed
to resolve this class data imbalanced problem. Under-sampling
was performed on the major class (i.e. controls), yielding 441
instances. The ﬁnal dataset produced has 853 instances and 272
clinical features.

4. Experimental results
4.2. Segregation of clinical features
4.1. Data preprocessing
Records and clinical features with considerable missing entries
were removed. In addition, only records with known MI status
were selected. This resulted in a dataset comprising of 4612

The construction of a BCEN involved the segregation of the clinical features (173 diagnostic measurements and 1 MI status) along
the BC. These 173 clinical features (after excluding medication)
satisﬁed the characteristics of only 4 levels of the BC; namely,

Myocardial
Infarction

Body

…
…
…
…

Biological Continuum

System
Viscera
Tissue
Cell
Protein
Gene

…
…

Body
Features
System
Features
Viscera
Features
Tissue
Features

…
…
…
…
…
…
…
…

Cell
Features
Protein
Features
Gene
Features

Fig. 4. Graphical illustration of BCEN. The circles represent clinical feature that belong to the respective levels of the BC. The arrows linking the clinical features indicate that a
signiﬁcant correlationship was found between them.

34

D. Tay et al. / Journal of Biomedical Informatics 47 (2014) 28–38

body, system, viscera and protein. Among these clinical features,
38, 74, 41 and 20 belong to the body, system, viscera and protein
levels, respectively. A description of the segregated clinical features
is provided online as an Appendix at http://www.bg.ic.ac.uk/jtay/
web/chs_appendix.html. Readers may refer to the CHS data dictionary made available at the Biologic Specimen and Data Repository
Information Coordinating Center (BioLINCC) website for more
information (https://biolincc.nhlbi.nih.gov/studies/chs/).
4.3. Construction of BCEN and classiﬁcation of MI
Clinical features at the body level were ﬁrst deployed to
GA-SVM to determine the set of risk factors that were highly
correlated to MI (root node). A total of 11 risk factors, namely
ANGBASE (angina status at baseline), CHFBASE (congestive heart
failure at baseline), STRKBASE (stroke status at baseline), CBD
(self-reported stroke, transient ischemic attack (TIA) and cardiac
endarterectomy), SCORE03 (social support score), AMOUNT (cigarettes smoked per day), WGTEEN (teenage weight category),
OVRWT120 (obesity > 120% ideal), EDUC (education level), WAIST
(waist circumference – cm) and ALCOH (number of alcoholic beverages per week) were identiﬁed at the body level (note that these
modiﬁable risk factors are also identiﬁed in earlier reported clinical
studies [52,53]).
When extending the network, only clinical feature subsets
(child nodes) that yielded a balanced accuracy of at least 0.7 were
considered. This threshold was imposed to reﬂect only child nodes
that are highly correlated to their parent node. This resulted in 5
inner nodes at the body level – namely ANGBASE, CHFBASE, STRKBASE, CBD and OVRWT120. This criterion was applied to the rest of
the levels of the BC.
The resultant inner nodes identiﬁed at the system level include
ANBLMOD (angina modiﬁed at baseline status), CLBLMOD (claudication modiﬁed baseline status), SUPPUL16 (supine reading: 30 s
heart rate), CHSTPN (chest pain) and VISPROB (vision problem).
Table 1 provides the details of the best-performing clinical feature
subsets that satisfy the aforementioned criteria. Note that none of
the clinical features at the protein level correlated well with those
at the visceral level. The authors believe that this could be due to
the discontinuity in continuum along the BC (i.e. missing data at
the tissue and cell levels) when estimating the association between
the clinical features and phenotypic manifestation that resulted in
the low performance.

The resultant BCEN consists of 111 distinct nodes (Body level:
11; System Level: 63; Viscera Level: 37) in total, accounting for
64.1% of the original number of clinical features analyzed. The
complete BCEN for MI (created using prefuse toolkit [54]) is illustrated in Web Fig. 1 – available at http://www.bg.ic.ac.uk/jtay/
web/chsBCENFull.html. The BCEN provides a visual and interactive
etiological network for the user to visualize and comprehend the
relationship among the different risk factors along the BC for MI.
For our discussion here, a sub-network of the BCEN was analyzed
because of its complexity and numerous interrelated risk factors
present in the complete network. This sub-network is presented
in Fig. 5.
Referring to Fig. 5, it can be seen that obesity (OVRWT120), a
risk factor of MI, has 34 risk factors at the system level that are
highly correlated with it. These risk factors are related to rheumatology, physical function, oncology, pulmonology, thromboembolism, sleep disorder, ophthalmology, otolaryngology, cognitive
function and endocrinology. They account for 45.9% of the clinical
features analyzed at the system level. This suggests that not all
clinical features at the system level are good predictors of obesity
and it could be more fruitful to focus investigations on signiﬁcantly
contributing clinical features.
MI classiﬁcation, with GA-SVM algorithm, was next performed
with the 111 clinical features that were present in BCEN. Baseline
comparison was made with the original set of 173 clinical features
present in the imputed CHS dataset. Results, as shown in Table 2,
were obtained from averaging 3 runs of GA-SVM. For each method,
the best-performing clinical feature subset for the different runs is
the same. Comparable classiﬁcation performance was achieved for
both the methods. However, the computational time required by
the proposed method (i.e. deploying only risk factors present in
the BCEN to GA-SVM algorithm) to develop the MI classiﬁcation
model was much lower (approximately 14.7 h).
5. Discussion
To develop MI classiﬁcation models efﬁciently in high dimensional datasets, we introduced a novel methodology for the reduction of clinical features to be analyzed without compromising the
performance of the classiﬁcation model. Classiﬁcation (without
feature selection) conducted on a large number of clinical risk factors often produced low-performing classiﬁcation models, as the
performance is often jeopardized by the present of irrelevant or

Table 1
Details of best-performing clinical feature subsets.
Parent node

Child nodes

# Inner nodes

Total nodes

ACC

SN

SP

PR

FM

BA

MI Status

Clinical features at body level

5

6

11

0.828

0.786

0.866

0.846

0.815

0.826

Clinical features at system level

4
2
0
3
2

19
16
12
18
32

23
18
12
21
34

0.814
0.958
0.958
0.955
0.737

0.741
0.559
0.701
0.734
0.737

0.929
0.855
0.905
0.983
0.738

0.416
0.596
0.878
0.841
0.704

0.428
0.575
0.672
0.784
0.720

0.835
0.707
0.803
0.858
0.737

Clinical features at viscera level

0
0
0
0
0

25
18
9
16
21

25
18
9
16
21

0.785
0.955
0.828
0.717
0.829

0.562
0.426
0.865
0.794
0.667

0.931
0.991
0.749
0.609
0.981

0.841
0.767
0.834
0.695
0.568

0.673
0.548
0.849
0.741
0.609

0.746
0.709
0.807
0.702
0.824

Body level
ANGBASE
CHFBASE
STRKBASE
CBD
OVRWT120
System level
ANBLMOD
CLBLMOD
SUPPUL16
CHSTPN
VISPROB

# Leaf nodes

Column 1 provides the best-performing clinical features at different levels of the BC: ANGBASE = angina status at baseline; CHFBASE = congestive heart failure at baseline;
STRKBASE = stroke status at baseline; CBD = self-reported stroke, transient ischemic attack and cardiac endarterectomy; OVRWT120 = obesity > 120% ideal; ANBLMOD = angina modiﬁed at baseline status; CLBLMOD = claudication modiﬁed baseline status; SUPPUL16 = supine reading: 30 s heart rate; CHSTPN = chest pain; VISPROB = vision problem.
Columns 6 to 11 represent the various performance measurements: ACC = accuracy; SN = sensitivity; SP = speciﬁcity; PR = precision; FM = F-measure; BA = balanced
accuracy.

35

D. Tay et al. / Journal of Biomedical Informatics 47 (2014) 28–38

Viscera

System

Body

Fig. 5. Sub-network of BCEN for MI. Eleven clinical features at the body level were found to be potential etiological factors of MI. Obesity, one of the risk factor of MI, consists
of 34 highly correlated clinical features at the system level.

Table 2
Performance of classiﬁcation with and without BCEN.
Experiment

#Features
considered

#Gen

Time taken, hours
(Mean ± SD)

ACC

SN

SP

PR

FM

BA

Baseline method: classiﬁcation with original set of risk
factors
Proposed method: classiﬁcation with risk factors present
in BCEN

173

73

69.6 ± 0.136

0.941

0.993

0.893

0.897

0.942

0.943

111

21

14.7 ± 0.005

0.931

0.995

0.871

0.878

0.933

0.933

These experiments were executed in parallel over an 8-core computer server. The best-performing clinical feature subset is the same for the different runs. ‘#Gen’ denotes the
number of generations taken by GA before it converges.

36

D. Tay et al. / Journal of Biomedical Informatics 47 (2014) 28–38

redundant predicators. On the other hand, the development of
classiﬁcation models with feature selection (e.g. the baseline method used in this work) conducted on a large number of clinical risk
factors is usually computationally expensive. Therefore, pre-selection of clinical risk factors is vital to mitigate this problem contributed by the ‘curse of dimensionality’. This was performed by
segregating the clinical features along the various levels of the
BC. The segregation process effectively reduces the data dimension,
where its size is dependent on the number of clinical features
categorized under each level of the BC. In this study, for example,
analysis performed at the ‘‘body level’’ requires only 38 clinical
features to be considered at a time. This, in contrast to the initial
173 clinical features, offers a reduction of 4.55-fold in the data
dimension. Having to analyze a smaller number of clinical features
inevitably reduces the amount of computational time required to
develop the classiﬁcation model. Moreover, if prior knowledge is
available the data dimension can be further restricted. For instance,
Emily et al. [29] utilize knowledge from protein databases to reduce the search of SNPs to gene pairs that are known to interact
and reference. A similar concept can be applied to other levels of
the BC to alleviate the search effort required.
Although effort is required to construct the BCEN, the resultant
network has several advantages. Firstly, with the introduction of
new clinical risk factors the entire BCEN need not be reconstructed.
It provides a reusable framework where only the level of the BC, at
which the new clinical risk factor belong to, need to be redeveloped. If the newly introduced clinical risk factor is identiﬁed as
an etiological factor (i.e. risk factor contributing to the cause of
the disease), then starting with that clinical risk factor as the root
node, the network is extended for levels of the BC that is below
that of the newly inserted etiological factor. This approach thus
provides a signiﬁcant reduction in the time and effort required to
build up-to-date clinical classiﬁcation models. Secondly, the BCEN
provides an excellent paradigm for the illustration of the potential
biological pathways that underpin the different phenotypic
manifestations and has the signiﬁcant advantage of analyzing only
clinical risk factors that are biologically plausible. This not only
allows the identiﬁcation of signiﬁcant risk factors that can be used
for efﬁcient development of accurate classiﬁcation models, but,
also, (1) reveals relationships that are not readily apparent from
the study of individual disorders, (2) provide a global perspective
of the different risk factors and etiologic pathways associated with
the disease, and (3) identify new risk factors that could pave the
way to the development of novel diagnostic, preventive or
therapeutic strategies. Therefore, BCEN may be a simple etiological
network, but it has the potential to provide signiﬁcant insights into
the mechanisms of a disease.
The constructed BCEN was validated by comparing the identiﬁed inter-relationship among different risk factors with those
reported in previous clinical studies. All risk factors found at the
body level of BCEN were also identiﬁed in previous clinical studies.
Further, comparisons of a sub-network of BCEN (i.e. obesitysystem sub-network) have shown that there is a large overlap (of
82.4%) between the identiﬁed relationships and those found in previous work. A possible reason for the identiﬁcation of the additional inter-relationships is the employment of machine learning
techniques. Since previous clinical studies tend to use linear statistical models to perform the analysis, non-trivial and non-linear
relationships may go undetected. Therefore, the use of machine
learning techniques in this work could potentially identify the
non-trivial, non-linear and interacting etiological factors. This
enables one to better understand the underlying causes of the
disease, allowing more appropriate and focus interventions to be
recommended to the patients. Table 3 lists the risk factors found
to be highly associated with obesity and their presence in the
clinical literature.

Arthritis, for instance, has been reported previously to be more
prevalent among obese patients [55,56]. This is primarily due to
the presence of excess biomechanical stress, inducing deleterious
effect on the joints. Similarly, obese individuals have a higher risk
of cancer related to endometrium, prostate, colon, esophagus and
stomach [57,58]. Previously reported investigations have also
shown association between obesity and bronchitis, pneumonia,
emphysema, deep vein thrombosis, intermittent claudication,
duration of sleep, blindness, hearing impairment, activities of daily
living, pulmonary embolism, ankle-arm index, loss of balance,
walking capacity, cognitive function, unstable angina, stroke, transient ischemic attack, hypertension and diabetes [59–75].
This suggests that the BCEN is feasible and effective in characterizing a disease and identifying the possible etiological factors.
It is noteworthy that analysis of the obesity-system sub-network
identiﬁed 6 new clinical features that were not previously identiﬁed in previous work. This could indicate that these clinical
features are potential etiological factors of MI where further investigations could improve the understanding and treatment of the
disease. We hypothesize that the reconstruction of the etiologic
pathways is of major importance in healthcare as it would allow
a more proactive approach for providing medical interventions to
eradicate or delay the onset of a disease. This differs from the traditional reactive approach where individuals visit a physician only
when they are sick or in pain, which sometimes results in a situation where treatment is too late to achieve complete recovery.
Early medical interventions can be realized with BCEN by monitoring and controlling the risk factors (especially at the lower levels of
the BC) that contribute to the development of a disease (e.g. MI).

Table 3
Obesity-system level risk factors.

a

Variable

Description

ARTH01a
DIAG01a
BRONCHa
PNEUMONa
EMPHYSEMa
THROMBa
ROSEICa
GROGGYb
TRSLEEPa
WKERLYa
RECOGNa
TELEa
CONVERa
ADLa
IADLa
UESb
BLEED12b
CLOT12a
LTAAIa
SUPPUL16b
BIORES21a
BAL22b
LOSBAL22a
DIZZY22b
TIMEWLKa
DIGCORa
SCOR3510a
SCORE30a
ANBLMODa
CHBLMODa
STBLMODa
TIBLMODa
HYPERa
DIABADAa

Arthritis
Ever diagnosed with cancer
Bronchitis conﬁrmed by doctor
Pneumonia detected by doctor
Emphysema detected by doctor
Deep vein thrombosis
Intermittent claudication by rose questionnaire
Groggy in morning
Trouble falling asleep
Wake up far too early
See enough to recognize person
Hear enough to use phone
Hear enough to converse
Activities of daily living (ADL)
Instrumental ADL score
Upper extremity score
Bleed or bruise easily
Disorder related to blood clotting
Left ankle-arm index (%)
Supine reading: 30 s heart rate
Bioelectric impedance – resistance
Dizziness, loss of balance screen
Loss of balance
Dizzy/light-headed when stand up quickly
15 feet walk time-sec
Digit symbol score
Mini-mental score (35pt)
Mini-mental score (30pt)
Angina modiﬁed baseline status
CHF modiﬁed baseline status
Stroke modiﬁed baseline status
TIA modiﬁed baseline status
Calculated hypertension status
ADA guidelines diabetic status

Risk factors found in previous work.
Potential risk factors not found in previous studies (to the best of our
knowledge).
b

D. Tay et al. / Journal of Biomedical Informatics 47 (2014) 28–38

The employment of BCEN to reduce the number of clinical
features to be analyzed signiﬁcantly alleviated the computational
demands. Without acutely compromising the classiﬁcation performance, a speedup of approximately 4.73-fold was achieved. This
was possible due to the earlier convergence of GA, suggesting that
signiﬁcant risk factors are already identiﬁed and present in BCEN.
This facilitates the identiﬁcation of risk factors that contribute signiﬁcantly to the modeling of accurate MI classiﬁcation model.
This study has a few limitations. Firstly, only a single dataset (i.e.
CHS dataset) was used to build the etiological network for MI. This
inevitably limits the power to detect all the associated risks and
conclusively state that the BCEN has described the complete etiology of MI. Additionally, it limits the ability to state that the proposed method provides efﬁciency for all clinical classiﬁcation
problems. Nonetheless, it does shed some light to a novel approach
for investigating the etiology of MI and efﬁcient clinical classiﬁcation. Secondly, only a single classiﬁcation algorithm (i.e. SVM) has
been used to identify the association between the clinical features
and for developing MI classiﬁcation model. This may hinder the discovery of the underlying associations and the performance of the
classiﬁcation model, as no single machine learning technique or
statistical model is optimal for every problem. The reason for this
is because each method would have its own inductive bias [76].
Hence, it is suggested in [18] that comparison between multiple
machine learning techniques, traditional statistical models and expert-based schemes should be conducted in order to assess the suitability of each method for a particular problem. Finally, the CHS
dataset only contains risk factors that fall under the body, system,
visceral and protein levels. This hinders the construction of a complete BCEN, limiting the ability to provide a more comprehensive
illustration of the underlying etiology of a disease and the development of a more accurate classiﬁcation model.
Nevertheless, the constructed BCEN is potentially capable of
presenting the etiology of a disease in a biologically-structured
manner that could facilitate the understanding and management
of a disease. Moreover, it offers an effective and efﬁcient approach
for the development of MI classiﬁcation model.
6. Conclusions
In view of the high prevalence of MI worldwide, better ability to
characterize and classify the disease is both appropriate and necessary. In this paper we have presented an integrated approach to
build a single probabilistic network (i.e. BCEN which identiﬁes
and relates the etiological factors associated with MI) that aims
to provide an efﬁcient approach for the development of MI classiﬁcation model.
Validation of the constructed BCEN was conducted and our results indicate that the network is reliable and capable of identifying
signiﬁcant etiological factors. There is a large overlap between the
relationships identiﬁed by our approach and those found in previous work. Out of the 34 clinical features identiﬁed at the obesitysystem level, 28 (82.4%) of them were found in the previous clinical
studies. However, 6 new clinical features, that had not been identiﬁed previously, were found to be associated with obesity in this
study. These new clinical features could be probable risk factors
for MI. They indicate the need for further clinical investigations to
improve the understanding and treatment of the disease.
Based on the distinct risk factors identiﬁed and present in BCEN,
a classiﬁcation model for MI was developed. The classiﬁcation
model obtained demonstrated high balanced accuracy of 0.933. It
was developed at a rate of 4.73-fold faster than its counterpart that
does not adopt any pre-selection strategy. This suggests that BCEN
may be a desirable approach for developing clinical classiﬁcation
models when a large number of clinical features need to be
considered.

37

Although further validation of this methodology is necessary,
this approach may be valuable in exploring and identifying risk
factors that underpin a disease. To conclude, the BCEN is an etiological network that is simply built but profoundly useful. It has
the potential to provide insights, from a novel perspective, into
the characteristics of (current/new) diseases - allowing more
efﬁcient and effective understanding, analysis, management and
classiﬁcation to be undertaken. We look forward to a more comprehensive understanding of the disease etiology and eventually,
towards personalized medicine.
Acknowledgments
Darwin Tay would like to express his sincere gratitude for his
scholarship funding provided by the Nanyang Technological University-Imperial College London Joint PhD programme.
The authors would like to thank the National Heart, Lung and
Blood Institute (NHLBI) for providing the CHS dataset.
Professor Richard Kitney and Dr Carolyn Goh wish to acknowledge the support of The Engineering and Physical Science Research
Council (EPSRC) in this study.
Darwin Tay would also wish to thank EPSRC for partial support
at Imperial College.
References
[1] Bellman R. Adaptive control processes. Princeton New Jersey: Princeton
University Press; 1961. pp. 274.
[2] Baxt W, Skora J. Prospective validation of artiﬁcial neural network trained to
identify acute myocardial infarction. Lancet 1996;347(8993):12–5.
[3] Menown IBA, Mackenzie, Adgey AAJ. Optimizing the initial 12-lead
electrocardiographic diagnosis of acute myocardial infarction. Eur Heart J
2000;21(4):275–83.
[4] Roger V, Go A, Lloyd-Jones D, Adams R, et al. Heart disease and stroke
statistics-2011 update: a report from the American heart association.
Circulation; 2011.
[5] Wilson W, D’Agostino R, Levy D, Belanger A, et al. Prediction of coronary heart
disease using risk factor categories. Circulation 1998;32(18):560–5.
[6] British Heart Foundation Statistics Database. Coronary heart disease. <http://
www.bhf.org.uk/publications/view-publication.aspx?ps=1001546;
2012
[accessed 08.08.12].
[7] Hsia T, Chiang H, Chiang D, Hang L, et al. Prediction of survival in surgical
unresectable lung cancer by artiﬁcial neural networks including genetic
polymorphisms and clinical parameters. J Clin Lab Anal 2003;17(6):229–34.
[8] Pittman J, Huang E, Dressman H, Horng CF, et al. Integrated modeling of clinical
and gene expression information for personalized prediction of disease
outcomes. Natl Acad Sci USA 2004;101(22):8431–6.
[9] Kitney R, Poh CL. Geometric framework linking different levels of the biological
continuum. Engineering in Medicine and Biology Society, 2005. In: IEEE-EMBS
2005, 27th annual international conference of the; 2006.
[10] Poh CL, Kitney J, Shrestha R. Addressing the future of clinical information
systems - web-based multilayer visualization. IEEE Trans Inf Technol Biomed
2007:127–40.
[11] Holland J. Genetic algorithms. Sci Am 1992:66–72.
[12] Boser BE, Guyon IM, Vapnik VN. A training algorithm for optimal margin
classiﬁers. In: Proceedings of the ﬁfth annual workshop on computational
learning theory; 1992.
[13] Cortes C, Vapnik V. Support-vector networks. Mach Learn 1995;20(3):273–97.
[14] Vapnik V. An overview of statistical learning theory. IEEE Trans Neural
Networks 1999;10(5):988–99.
[15] Fried L, Borhani N, Enright P, Furberg C, et al. The cardiovascular health study:
design and rationale. Ann Epidemiol 1991;1(3):263–76.
[16] Bhatla Nidhi, Jyoti Kiran. An analysis of heart disease prediction using different
data mining techniques. Int J Eng Res Technol 2012;1(8):1–4.
[17] Roganb J, Franklina J, Stowb D, Millerc J, et al. Mapping land-cover
modiﬁcations over large areas: a comparison of machine learning
algorithms. Remote Sens Environ 2008;112(5):2272–83.
[18] Cruz JosephA, Wishart DavidS. Applications of machine learning in cancer
prediction and prognosis. Cancer Inform 2006;2:59–77.
[19] Eggers K, Ellenius J, Dellborg M, Groth T, et al. Artiﬁcial neural network
algorithms for early diagnosis of acute myocardial infarction and prediction of
infarct size in chest pain patients. Int J Cardiol 2007;114(3):366–74.
[20] Palaniappan S, Awang R. Intelligent heart disease prediction system using data
mining techniques. Comput Syst Appl 2008.
[21] Hossain Jafreen, FazlidaMohdSani Nor, Mustapha Aida, SurianiAffendey Lilly.
Using feature selection as accuracy benchmarking in clinical data mining. J
Comput Sci 2013;9(7):883–8.

38

D. Tay et al. / Journal of Biomedical Informatics 47 (2014) 28–38

[22] Latifoğlu F, Polat K, Kara S, Günesß S. Medical diagnosis of atherosclerosis from
carotid artery doppler signals using principal component analysis (PCA), k-NN
based weighting pre-processing and artiﬁcial immune recognition system
(AIRS). J Biomed Inform 2008;41(1):15–23.
[23] Ohlsson M. WeAidU-a decision support system for myocardial perfusion
images using artiﬁcial neural networks. Artif Intell Med 2004;30(1):49–60.
[24] Nilsson J, Ohlsson M, Thulin L, Höglund P, et al. Risk factor identiﬁcation and
mortality prediction in cardiac surgery using artiﬁcial neural networks. J
Thorac Cardiovasc Surg 2006;132(1):12–9.
[25] Yang J, Honavar V. Feature subset selection using a genetic algorithm. IEEE
Intell Syst Appl 1998;13(2):44–9.
[26] Kohavi Ron, Sommerﬁeld Dan. Feature subset selection using the wrapper
method: overﬁtting and dynamic search space topology. In: First international
conference on knowledge discovery and data mining; 1995.
[27] Saeys Yvan, Inza Inaki, Larranaga Pedro. A review of feature selection
techniques in bioinformatics. Bioinformatics 2007;23(19):2507–17.
[28] Dash M, Liu H. Feature selection for classiﬁcation. Intell Data Anal
1997;1(3):131–56.
[29] Emily M, Mailund T, Hein J, Schauser L, et al. Using biological networks to
search for interacting loci in genome-wide association studies. Eur J Hum
Genet 2009;17(10):1231–40.
[30] Chu C, Hsu A, Chou K, Bandettini P, et al. Does feature selection improve
classiﬁcation accuracy? Impact of Sample size and feature selection on
classiﬁcation using anatomical magnetic resonance images. Neuroimage
2012;60(1):59–70.
[31] Guyon I, Elisseeff A. An introduction to variable and feature selection. J Mach
Learn Res 2003;3:1157–82.
[32] Wiener J, Tilly J. Population ageing in the United States of America:
implications for public programmes. Int J Epidemiol 2002;31(4):776–81.
[33] Abbott R, Curb J, Rodriguez B, Masaki K, et al. Age-related changes in risk factor
effects on the incidence of coronary heart disease. Ann Epidemiol
2002;12(3):173–81.
[34] Cover T, Hart P. Nearest neighbor pattern classiﬁcation. IEEE Trans Inform
Theory 1967(1):21–7.
[35] Kohonen T. The self-organizing map. Proc IEEE 1990;78(9):1464–80.
[36] Batista G, Monard MC. A study of K-nearest neighbour as an imputation
method. In second international conference on Hybrid Intelligent Systems,
Santiago, Chile, Soft Computing Systems: design, management and
applications. IOS Press 2002:251–60.
[37] Troyanskaya O, Cantor M, Sherlock G, Brown P, et al. Missing value estimation
methods for DNA microarrays. Bioinformatics 2001;17(6):520–5.
[38] Acuña E, Rodriguez C. The treatment of missing values and its effect on
classiﬁer accuracy. In: Studies in classiﬁcation, data analysis, and, knowledge
organization, vol. 0; 2004. pp. 639–47.
[39] Batista G, Monard M. A study of K-nearest neighbor as an imputation method.
In: Second international conference on hybrid intelligent systems; 2002.
[40] Jerez J, Molina I, García-Laencina P, Alba E, et al. Missing data imputation using
statistical and machine learning methods in a real breast cancer problem. Artif
Intell Med 2010;50(2):105–15.
[41] Garcia-Laencina P, Vidal A, Sancho-Gomez JL. A robust approach for classifying
unknown data in medical diagnosis problems. IEEE World Auto Congress
(WAC) 2008.
[42] Minaei-Bidgoli B, Kashy D, Kortmeyer G, Punch W. Predicting student
performance. An application of data mining methods with an educational
web-based system. Frontiers in Education; 2003. FIE 2003. 33rd Annual, 2003.
[43] Dudani S. The distance-weighted k-nearest-neighbor rule. IEEE Trans Syst,
Man Cyber 1976;6(4):325–7.
[44] Japkowicz N. Learning from imbalanced data sets: a comparison of various
strategies. AAAI workshop on learning from imbalanced data sets; 2000.
[45] Li D, Liu C, Hu S. A learning method for the class imbalance problem with
medical data sets. Comput Biol Med 2010;40(5):509–18.
[46] Wua W, Walczaka1 B, Massarta D, Heuerdingb S, et al. Artiﬁcial neural
networks in classiﬁcation of NIR spectral data: design of the training set. Chem
Intell Labor Syst 1996;33(1):35–46.
[47] Chang CC, Lin C. LIBSVM: a library for support vector machines. <http://
www.csie.ntu.edu.tw/~cjlin/libsvm/>.
[48] Fang KT, Lin DKJ, Winker P, Zhang Y. Uniform design: theory and application.
Technometrics 2000;42(3).
[49] Chow Rick, Zhong Wei, Blackmon Michael, Stolz Richard, Dowell Marsha. An
efﬁcient SVM-GA feature selection model for large healthcare databases.
Genetic and evolutionary computation conference (GECCO); 2008.
[50] Chen SH, Sun J, Dimitrov L, Turner AR, et al. A support vector machine
approach for detecting gene-gene interaction. Genet Epidemiol
2008;32(2):152–67.

[51] Su CT, Hsu JH. An extended v2 algorithm for discretization of real value
attributes. Knowl Data Eng, IEEE Trans 2005(3):437–41.
[52] Yusuf S, Hawken S, Ounpuu S, Dans T, et al. Effect of potentially modiﬁable risk
factors associated with myocardial infarction in 52 countries (the INTERHEART
study): case-control study. Lancet 2004;364(9438):937–52.
[53] Rosengren A, Subramanian S, Islam S, Chow C, et al. Education and risk for
acute myocardial infarction in 52 high, middle and low-income countries:
INTERHEART case-control study. Heart 2009;95(24):2014–22.
[54] Heer J, Card SK, Landay JA. Prefuse: a toolkit for interactive information
visualization. In: Proceedings of the SIGCHI conference on Human factors in,
computing systems; 2005.
[55] Holliday K, McWilliams D, Maciewicz R, Muir K, et al. Lifetime body mass
index, other anthropometric measures of obesity and risk of knee or hip
osteoarthritis in the GOAL case-control study. Osteoarthr Cartilage
2011;19(1):37–43.
[56] Park H, Lee S. Association of obesity with osteoarthritis in elderly korean
women. Maturitas 2011;70(1):65–8.
[57] Kane C, Bassett W, Sadetsky N, Silva S, et al. Obesity and prostate cancer
clinical risk factors at presentation: data from CaPSURE. J Urol
2005;173(3):732–6.
[58] Yang P, Zhou Y, Chen B, Wan H, et al. Overweight, obesity and gastric cancer
risk: results from a meta-analysis of cohort studies. Eur J Cancer
2009;45(16):2867–73.
[59] Guerra S, Sherrill DL, Bobadilla A, Martinez FD, et al. The relation of body mass
index
to
asthma,
chronic
bronchitis,
and
emphysema.
Chest
2002;122(4):1256–63.
[60] Corrales-Medina V, Valayam J, Serpa J, Rueda A, et al. The obesity paradox in
community-acquired bacterial pneumonia. Int J Infect Diseas 2011;15(1).
[61] Samama M. An epidemiologic study of risk factors for deep vein thrombosis in
medical outpatients: the sirius study. Arch Intern Med 2000;160(22):3415–20.
[62] Golledge J, Leicht A, Crowther RG, Clancy P, et al. Association of obesity and
metabolic syndrome with the severity and outcome of intermittent
claudication. J Vasc Surgery 2007;45(1):40–6.
[63] Patel SR, Blackwell T, Redline S, Ancoli-Israel S, et al. The association between
sleep duration and obesity in older adults. Int J Obes 2008;32(12):1825–34.
[64] Patterson RE, Frank LL, Kristal AR, White E. A comprehensive examination of
health conditions associated with obesity in older adults. Am J Prev Med
2004;27(5):385–90.
[65] Habot-Wilner Z, Belkin M. Obesity is a risk factor for eye diseases. Harefuah
2005;144(11):805–9.
[66] Fransen E, Topsakal V, Hendrickx JJ, Laer LV, et al. Occupational noise, smoking,
and a high body mass index are risk factors for age-related hearing
impairment and moderate alcohol consumption is protective: a European
population-based multicenter study. JARO – J Assoc Res Otolaryngol
2008;9(3):264–76.
[67] Himes CL. Obesity, disease, and functional limitation in later life. Demography
2000;37(1):73–82.
[68] Stein PD, Beemath A, Olson RE. Obesity as a risk factor in venous
thromboembolism. Am J Med 2005;118(9):978–80.
[69] Tison GH, Ndumele CE, Gerstenblith G, Allison MA, et al. Usefulness of baseline
obesity to predict development of a high ankle brachial index (from the multiethnic study of atherosclerosis). Am J Cardiol 2011;107(9):1386–91.
[70] Gray D, Bray G, Gemayel N, Kaplan K. Effect of obesity on bioelectrical
impedance. Amer Soc Clin Nutr 1989;255–260:255–60.
[71] Corbeil P, Simoneau M, Rancourt D, Tremblay A, et al. Increased risk for falling
associated with obesity: mathematical modeling of postural control. IEEE
Trans Neur Syst Rehab Eng 2001(2):126–36.
[72] Hulens M, Vansant G, Claessens AL, Lysens R, et al. Predictors of 6-minute walk
test results in lean obese and morbidly obese women. Scandinavian J Med Sci
Sports 2003;13(2):98–105.
[73] Elias MF, Elias PK, Sullivan LM, Wolf PA, et al. Lower cognitive function in the
presence of obesity and hypertension: the framingham heart study. Int J Obes
2003;27(2):260–8.
[74] Wolk R, Berger P, Lennon R, Brilakis E, et al. Body mass index: a risk factor for
unstable angina and myocardial infarction in patients with angiographically
conﬁrmed coronary artery disease. Circulation 2003;108:2206–11.
[75] Winter Y, Rohrmann S, Linseisen J, Lanczik O, et al. Contribution of obesity and
abdominal fat mass to risk of stroke and transient ischemic attacks. Stroke
2008;39:3145–51.
[76] Freitas A, Timmis J. Revisiting the foundations of artiﬁcial immune systems for
data mining. IEEE Trans Evol Comput 2007;11(4):521–40.

