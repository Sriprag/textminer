IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

1253

Detecting Periods of Eating During Free-Living by
Tracking Wrist Motion
Yujie Dong, Jenna Scisco, Mike Wilson, Eric Muth, and Adam Hoover

Abstract—This paper is motivated by the growing prevalence of
obesity, a health problem affecting over 500 million people. Measurements of energy intake are commonly used for the study and
treatment of obesity. However, the most widely used tools rely upon
self-report and require a considerable manual effort, leading to
underreporting of consumption, noncompliance, and discontinued
use over the long term. The purpose of this paper is to describe
a new method that uses a watch-like configuration of sensors to
continuously track wrist motion throughout the day and automatically detect periods of eating. Our method uses the novel idea that
meals tend to be preceded and succeeded by the periods of vigorous wrist motion. We describe an algorithm that segments and
classifies such periods as eating or noneating activities. We also
evaluate our method on a large dataset (43 subjects, 449 total h of
data, containing 116 periods of eating) collected during free-living.
Our results show an accuracy of 81% for detecting eating at 1-s
resolution in comparison to manually marked event logs of periods
eating. These results indicate that vigorous wrist motion is a useful
indicator for identifying the boundaries of eating activities, and
that our method should prove useful in the continued development
of body-worn sensor tools for monitoring energy intake.
Index Terms—Accelerometer, activity recognition, body motion
tracking, energy intake, gyroscope, obesity.

I. INTRODUCTION
HIS study is motivated by the growing prevalence of obesity. The World Health Organization reports that in 2008,
1.4 billion adults (age 20+) were overweight (body mass index
(BMI)> 25) and 500 million adults were obese (BMI > 30) [1].
Reports for 2012 show that one in three adults and one in six
children in the United States were obese [2], [3]. Obesity is a
major risk factor for diabetes, heart disease, high blood pressure,
stroke, and cancer [4]. Deaths attributed to obesity continue to
increase [5], [6]; 65% of the world’s population lives in countries
where more people die from complications due to overweight
or obesity than from complications due to underweight [1].
Energy expenditure (EE) and energy intake (EI) are commonly used measurements in the study and treatment of obesity [7]. The former measures the energy cost of homeostasis

T

Manuscript received March 4, 2013; revised July 19, 2013; September 10,
2013; accepted September 12, 2013. Date of publication September 17, 2013;
date of current version June 30, 2014.
Y. Dong and A. Hoover are with the Department of Electrical and Computer
Engineering, Clemson University, Clemson, SC 29634 USA (e-mail:
dongyujie@gmail.com; ahoover@clemson.edu).
J. Scisco, M. Wilson, and E. Muth are with the Department of
Psychology, Clemson University, Clemson, SC 29634 USA (e-mail:
jenna.scisco@gmail.com; mlw2@g.clemson.edu; muth@clemson.edu).
Digital Object Identifier 10.1109/JBHI.2013.2282471

(body maintenance) plus physical activities, while as the latter measures consumption. Many studies have shown that selfreported estimates of EE suffer from bias [8]–[10]; body-worn
motion sensors provide more objective measurements with less
user burden at less cost [11]. Similarly, numerous studies have
shown that people tend to underreport their EI using self-report
methods, with estimates of underreporting ranging from 10–
30% for normal weight subjects to 20–50% for obese adults
and children [12]–[18]. The goal of our research is to develop
body-worn sensing methods that can objectively measure EI.
The need for such tools has been widely advocated within the
dietetics community [19], [20] and in funding programs from
the US National Science Foundation and National Institutes of
Health [21].
The purpose of this paper is to describe a new method that
uses a watch-like configuration of sensors to continuously track
wrist motion throughout the day and automatically detect the
periods of eating. The problem of using body-worn sensors to
automatically measure EI may be broken into two parts. The
first part is identifying the periods of consumption amongst all
the daily activities. The second part is estimating EI during
those periods. Previous research has focused on the second part
of the problem, such as counting the numbers of chews [22],
swallows [23], [24], drinks [25], bites [26], or specific eating
gestures [27], [28]. This paper is the first to describe a method
that detects entire periods of eating (e.g., meals and snacks)
during all-day tracking. It is also significant that we evaluated
our method on a dataset that was collected during free-living
as opposed to in a laboratory environment, so that our method
could be tested on unscripted eating behaviors.
II. METHODS
Our method assumes that a person is wearing a watch-like
configuration of accelerometers and gyroscopes, as depicted in
Fig. 1. The sensors track the linear and rotational motions of
the wrist. We have discovered that prior to an eating activity
(e.g., a meal/snack), there tends to be a period of larger wrist
motion energy, caused by things like bringing food to a table,
adjusting the position of utensils, opening food containers, and
unwrapping food. During an eating activity, the total wrist motion energy tends to be reduced. At the end of an eating activity,
there tends to be another period of larger wrist motion energy,
caused by things like putting remaining food away, washing
hands, standing up, and putting dishes away. We have designed
an algorithm that uses this idea to detect periods of eating. It calculates a continuous estimate of wrist motion energy and uses a
hysteresis-based peak detector to segment the periods of time inbetween vigorous motions. For each segmented period, features

2168-2194 © 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

1254

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

Fig. 1. Watch-like configuration of accelerometers and gyroscopes tracks
wrist motion continuously throughout the day (shown here on the right hand).

are calculated and used to classify the period as an eating or
noneating activity. We first describe the details of the algorithm.
We then describe the data collected and the evaluation metrics
used to determine the efficacy of this approach.
A. Algorithm
1) Preprocessing: Data from the sensors are first smoothed
to reduce the effects of noise:
St =

0


−t
exp( 2R
2 )
2

Rt+i N

x=0

i=−N

)
exp( −(x−N
)
2R 2
2

(1)

where Rt is the raw datum and St is the smoothed datum at
time t. Equation (1) implements a Gaussian-weighted window
centered on the current measurement, so that only half of a
Gaussian distribution is used for smoothing. The variable N is a
window size and R is the sigma of the Gaussian. The particular
values used for these variables will depend upon the quality of
the sensors used; we provide values for our testing device later.
Equation (1) is applied independently to the data from each
accelerometer and gyroscope axis.
2) Segmentation: The wrist motion energy can be characterized by the total amount of motion. We tested both the sum
of accelerometer readings and the sum of gyroscope readings,
finding similar results [29]. Because accelerometers use approximately one-tenth the power of gyroscopes [30], [31], it is
preferable to use accelerometers for continuous all-day monitoring. We therefore calculate wrist motion energy as

space). The start and stop times of the meals/snacks shown in
the figure were manually logged by the person being recorded. It
can be seen that all four eating activities show a pronounced peak
before and after eating. Of course, other peaks occur throughout
the day, so this feature alone cannot be used for classification.
But it does provide a reasonable mechanism for segmenting the
data.
To automatically identify peaks, we developed a custom-peak
detector using the concept of a hysteresis threshold [32]. Our detector identifies the peaks at local maxima that are sufficiently
pronounced while suppressing marginal local maxima. Pseudocode for the algorithm is given in Fig. 3. The algorithm
loops through the data from beginning to end, with each pass
through the two while loops identifying a single peak. The two
thresholds T 1 and T 2 are set equal to the value of the signal
(wrist motion energy) at the current index, and two times that
value. The first while loop iterates until the signal exceeds the
second (larger) threshold, in essence requiring the signal to go
2× above its previously observed minimum. During this search,
if a signal value is found that is lower than T 1, then the required
thresholds are recalculated. Once the signal has exceeded the
second threshold, the second while loop iterates until the signal
falls below the first (lower) threshold. The index of the peak
is taken as the location with the maximum signal value found
during the two while loops. Fig. 4 shows the result of the peak
detector on the first 2 h of data from Fig. 2.
The indices of the detected peaks are used to segment the
data. We have noted that sometimes, a meal/snack can have a
peak inside the period of eating. An example of this can be seen
in the period labeled “dinner” in Fig. 2. This is likely caused
by the person conducting activities like extended application
of condiments, or preparing a second course. Since the wrist
motion energy is calculated over a sliding 1-min window, brief
periods of intense motion such as single gestures will not trigger
our segmentation algorithm. In the case of a longer vigorous
activity, the result is that the period of eating is oversegmented.
If desired, this could be overcome by merging the consecutive
segmented periods after classification.
3) Features: We investigated numerous features for classification [29]; this paper reports on the four features found to be
the most useful. Each feature is calculated over each interpeak
segmented period. We refer to the first feature as manipulation.
It is calculated as

W

t+ 2

1
|Sx,t | + |Sy ,t | + |Sz ,t |
Et =
W +1
W
i=t−

(2)

f1,w =

W
1  |Sφ,t | + |Sθ ,t | + |Sψ ,t |
W
|Sx,t | + |Sy ,t | + |Sz ,t |

(3)

2

where Sx,t , Sy ,t , and Sz ,t are the smoothed acceleration readings
at time t. The parameter W is a window size; we have found a
sliding 1 min window to be sufficient for smoothing over brief
vigorous motions while still capturing longer vigorous motions
indicative of the boundaries of eating activities [29].
The following example demonstrates the presence of vigorous wrist motions before and after eating, and is helpful for
explaining the algorithm. Fig. 2 shows the wrist motion energy
of a person over a 12-h period (the y-axis is clipped to save

where W is the span of the segmented period, t is the index
that iterates across that span, and S is the smoothed datum
(φ, θ, ψ = yaw, pitch, roll). This feature measures the ratio of
rotational motion to linear motion. The second feature is linear
acceleration, and is calculated as

f2,w =

W
1 
|Sx,t | + |Sy ,t | + |Sz ,t |.
W

(4)

DONG et al.: DETECTING PERIODS OF EATING DURING FREE-LIVING BY TRACKING WRIST MOTION

Fig. 2.

Example of accelerometer-based wrist motion energy of a person over a 12 h period. Manually logged meal times are marked.

loop t (data index)
reset (T1,T2)
while (E[t] < T2)
t=t+1
if (E[t] < T1)
reset (T1,T2)
end while
while (E[t] > T1)
t=t+1
end while
end loop
Fig. 3.

1255

Pseudocode for the peak detector used to segment data.

calculation includes the time the wrist roll is at least 10◦ /s, plus
a period of 8 s after each occurrence of the wrist roll motion
falling below 10◦ /s. The latter two features are inspired by our
previous work [26] in which wrist roll was used to detect bites
during eating. The values 10◦ /s and 8 s were found to be optimal
for characterizing a typical bite motion and interval.
4) Classification: For classification, we used a naive Bayes
classifier [33]. The Bayesian approach to classification is to
assign the most probable class ci ∈ C, given feature values
f1 , f2 , . . . , fN . Using the naive assumption of independence of
features, the classification problem can be written as

P (fj |ci ).
(7)
ci = argmax P (ci )
C

Fig. 4. Detected peaks on the first 2 h of data from Fig. 2. Arrows indicate the
points used for segmentation, and lines above arrows indicate the spans of the
detected peaks.

The third feature is the amount of wrist roll motion, and is
calculated as
W
W
1 
1 
|Sψ ,t −
Sψ ,t |.
(5)
W
W
The fourth feature is the regularity of wrist roll motion, and is
calculated as

1
1 ∀ t ∈ [|Sψ ,t | > 10◦ . . . t + 8 s] . (6)
f4,w =
W W

f3,w =

This feature takes on a value between 0 and 1, representing
the percentage of time that the wrist is in roll motion. The

j

For our problem, there are only two classes, eating (c0 ) and
noneating (c1 ). We set each P (ci ) = 0.5. We modeled the
probabilities of each feature given each class using a normal
distribution:


1
(fj − μi,j )2
(8)
P (fj |ci ) = 
exp −
2
2σi,j
2πσ 2
i,j

2
where μi,j and σi,j
are the mean and variance of feature j for
class i.

B. Data collection
An iPhone 4 (Apple Inc., 1 Infinite Loop, Cupertino, CA
95014, http://www.apple.com/iPhone/) was used to collect data
to develop and evaluate our algorithm. This device was chosen
because it is programmable, equipped with the appropriate sensors, and has a sufficiently large memory (16 GB) and battery
(1420 mAh) to record continuous data for an entire day. Commercial activity monitors exist in the form of wrist watches, but
they only contain accelerometers (no gyroscopes), and so could

1256

Fig. 5.

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

Data collection using an iPhone 4 on the wrist.

not be used for this study. Although the iPhone is larger than a
watch, it is important to note that a much smaller device could
be constructed; this is discussed further in Section IV.
The iPhone was placed inside a pouch which could be
wrapped snugly around the forearm (see Fig. 5). The top of
the device was aligned with the wrist joint but positioned so
that it would not inhibit the movement of the wrist. A custom
program was written to run on the iPhone, recording the raw
data for later transfer to a computer through a USB port. Our
segmentation and classification algorithms were implemented
in the C programming language using a Win32 graphical user
interface to visualize the data and results. For smoothing sensor
data from the iPhone, we found that a window size N of 1 s
with a Gaussian sigma R of 10 produced good results.
The Clemson University Institutional Review Board approved
the data collection and each subject provided informed consent.
Subjects were given the device in a brief laboratory visit prior to
the day of their recording, and were instructed in its use. They
were asked to put the device on and start the custom program
soon after waking in the morning, and to conduct all activities
throughout the day as naturally as possible, while the device
continuously recorded their wrist motion. The subjects were
asked to remove the device only when engaging in activities that
could damage it, such as taking a shower. On the day following
recording, each subject returned the iPhone to the experimenter
for data download and review.
Data were collected in two separate batches. In the first batch,
30 subjects (12 male, 18 female, ages 18–32) were instructed
to manually write down the start and stop times of their actual
meals and snacks in a provided log book, using the time displayed on the device for reference. The iPhone program recorded
data at 60 Hz and drained the battery after approximately 8.5 h.
Subsequent to this batch, we learned that 15-Hz data were sufficient for our method, and were able to extend recording time to
approximately 12 h. We also learned that subjects had trouble
using the provided written log to record the times of eating. We
therefore discontinued using the manually written log and instead added an event marker button to the iPhone program that
subjects were instructed to press when they started and ended
meals or snacks. We also removed the function from the program that allowed participants to halt/resume recording, to avoid
confusion. In the second batch of data collection, 25 subjects (8
male, 17 female, ages 20–50) used the updated version of the
iPhone program.

During postreview, the experimenter interviewed each subject
to identify possible errors for exclusion. Out of the first batch of
30 recordings, 10 had to be discarded due to poor compliance
with keeping records. Two subjects forgot to write down start or
stop times for one or more meals/snacks. Three subjects stated
that they filled the log out at the end of the day based upon
memory, instead of writing down the start and stop times as
they occurred. Five subjects misinterpreted our instructions and
started/stopped the iPhone recording program for meals only.
These problems motivated the reprogramming of the iPhone
recording program to remove the halt/resume button, and to
include an event marker on the iPhone screen in place of using a
written time log. For the second batch of 25 recordings, button
press logs were reviewed with subjects the day after recording
to eliminate inadvertent markers. Out of 294 total marks, 172
recorded 86 discrete, verified eating activities with the event
marks at the actual start and stop boundaries as verified by the
participants. Most of the remaining 122 marks were identifiable
as inadvertent due to being single marks (as opposed to marks
that could be paired into start/stop sets). Given the sensitivity of
the iPhone touchscreen, the size of the event marker button (5 ×
2 cm), and the fact that each subject wore the device for a whole
day, this number of inadvertent presses was not surprising. Nine
marks were reported as intentional by the subjects to test that the
device was still recording, but were not associated with meals.
Six marks were identified as double presses of the button due to
being less than 10 s apart. Two subjects reported forgetting to
press the button at the end of one or more meals; these recordings
were discarded.
In total, our data collection yielded 449 h of data from 43
subjects, including a cumulative 22.4 h of eating over 116 total
meals/snacks. It is important to note that the goal of the data
collection was to capture a sample of eating activities covering
a variety of individuals, meals, environments, and times of day.
The purpose of the dataset was to enable the algorithm development for automatically detecting such periods. It was not a goal
of the data collection to capture total daily intake. We asked that
participants try to capture all their eating activities, but the goal
of this study was not contingent on meeting that criteria.
C. Evaluation
We used two sets of evaluation metrics. The first metrics evaluate the classifier by the total amount of time correctly classified,
and the second metrics evaluate the classifier by the total amount
of eating activities (segments) correctly classified. The boundaries of manually logged periods of eating were recorded at 1-s
resolution. The boundaries of automatically classified periods
of time were rounded to the nearest second.
For the first metrics, true positives (TP) were counted as the
number of seconds of time that were labeled as eating in the
manual logs and classified as eating. False positives (FP) were
counted as the number of seconds of time that were labeled as
noneating in the manual logs and classified as eating. True negatives (TN) and false negatives (FN) were counted similarly by
comparing the manual log labels to the data classified as noneating. Sensitivity and specificity were calculated as TP/(TP+FN)

DONG et al.: DETECTING PERIODS OF EATING DURING FREE-LIVING BY TRACKING WRIST MOTION

TABLE III
RESULTS USING LEAVE-ONE-OUT CROSS VALIDATION SEPARATELY ON EACH
OF THE TWO BATCHES OF DATA

TABLE I
AVERAGE FEATURE VALUES FOUND DURING TRAINING

TABLE IV
EVALUATION OF CLASSIFIER AT MAXIMUM ACCURACY USING 1:1 VERSUS 20:1
WEIGHTING OF TIME CORRECTLY CLASSIFIED AS EATING VERSUS NONEATING

TABLE II
RESULTS USING LEAVE-ONE-OUT CROSS VALIDATION ON ALL DATA

and TN/(TN+FP). Accuracy was calculated as
accuracy =

TP × 20 + TN
.
(TP + FN) × 20 + (TN + FP)

1257

(9)

The factor of 20 in (9) weights TP to TN at a ratio of 20:1.
This is used because eating occurs much less frequently than
noneating in general free-living. The importance of using 20:1
weighting during evaluation is demonstrated in our results and
further discussed in Section IV.
For the second metrics, consecutive segments that were labeled as eating by the classifier were merged into single whole
segments (see the end of Section II-A2). True detections were
counted as the number of manually logged entries that overlapped the segments that were labeled eating by the classifier.
Undetected eating activities were counted as the remainder of
the manually logged entries. False detections were counted as
the remainder of the segments that were labeled eating by the
classifier.
III. RESULTS
The classifier was trained using leave-one-out crossvalidation. Thus, for testing each of the 43 recordings (1 per
person), the classifier was trained using the other 42 recordings
to calculate the values for the classifier probabilities (μi,j and
σi,j ). Table I lists the average means and variances for the features for each class. We use the notation f1 to refer generically
to the feature manipulation [see (3)], and f1,w to refer to that
feature calculated over a specific window W . The probabilities
for the eating class were calculated as the average feature values for all the segments labeled as eating by the subjects. For
the noneating class, all the remaining data from the recordings
were broken into 5-min windows and the probabilities were calculated as the average feature values. As can be seen in Table I,
during eating there tends to be higher values for manipulation,
roll motion and roll regularity, and lower values for linear acceleration. The variances for all the features for the noneating
class are higher than those for eating, due to the variety of activities grouped together in this class. Two-tailed independent
t-tests comparing all the paired distributions showed that the
differences are statistically significant (all p’s < 0.001).
Table II shows the results of testing the classifier using leaveone-out cross validation combined across the two batches of data
collected. The accuracy achieved was 79%. Using just the first

two features (manipulation and linear acceleration) produced
the same accuracy as using all four features. However, since
our data were recorded in two batches, we also analyzed the
results using separate leave-one-out cross validation for each
batch. Specifically, for the 20 recordings in the first batch, each
was tested using the other 19 for training the classifier; for the
23 recordings in the second batch, each was tested using the
other 22 for training the classifier. Table III shows these results.
In this case, an accuracy of 81% was achieved, and the use of
all four features improved sensitivity, specificity, and accuracy.
We hypothesize that this is due to the different amounts of
data recorded in each batch. The first batch averaged 8.5 h per
recording, spanning 10 am to 6:30 pm on average. The second
batch averaged 12 h per recording, spanning 10 am to 10 pm on
average. Since the second set included more evening and night
activities, we suppose that the different training produced more
accurate feature values for the classifier.
The values P (c0), P (c1) in our classifier (see Section II-A4)
determine the likelihood of a segment being classified as an
eating or noneating activity. We tested across the range of
values P (c0), P (c1) = {0,1}, {0.05,0.95}, {0.1,0.9}, . . . , {1,0}
to find the maximum accuracy. Table IV shows the importance
of weighting accuracy at 20:1 for evaluating total time correctly
classified. Weighted at 1:1, our classifier achieves a maximum
accuracy of 95% but this occurs at a sensitivity of 0%, in other
words when all data are labeled as noneating. Weighted at 20:1,
our classifier achieves a maximum accuracy of 81% which is
less than 95%, but the sensitivity and specificity are balanced.
The accuracy per person ranged from 35–97%, with a median
of 82%. The accuracy was above 70% for 38 out of 43 people
(88%), with the five remaining having much lower accuracies.
This suggests that for most people, our method may be suitable
for detecting the eating activities, but that for some people our
method may not work. It could be that some people are less
likely to engage in vigorous wrist motions before and after eating activities. However, each subject was only recorded for a
single day, so this result may be more a function of the particular meals/snacks eaten on the day of recording than individual
habits.
We also evaluated our classifier at the segment level using the
second set of metrics described in Section II-C. The classifier
correctly detected 100 actual eating activities, missed 16, and
had 379 false detections. The average time between the start of
the manual log entries and correctly detected eating activities

1258

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

TABLE V
SUMMARY OF DISCUSSION COMPARING THIS WORK TO RELATED WORKS

was −0.6 min. The average time between the end of the manual
log entries and correctly detected eating activities was +1.5 min.
This suggests that the peaks detected by our method occur
slightly before and slightly after the actual eating begins and
ends, respectively.
IV. DISCUSSION
Table V summarizes the present study in comparison to related works. The first contribution of this paper is that it is
the first to describe a method to detect the entire periods of
eating (i.e., meals, snacks) as opposed to counting individual
swallows, chews, bites, or specific gestures during eating. For
example, Amft and colleagues studied the recognition of four
different gestures related to eating: using a fork and knife to
eat from a plate, using a spoon to eat from a bowl, using hands
to eat, and drinking from a glass [28], [34]. In a related work,
they recognized gestures specific to 11 food categories [27],
and in a recent study they detected drinking gestures (sip and
fetch motions) [25]. Sazonov and colleagues studied the recognition of chews [22] and swallows [24]. Päßler et al. developed
a method to recognize swallows associated with different types
of foods [23]. Our group developed a method to recognize and
count bites of food and sips of liquid taken during a meal [26].
All these methods make progress toward the goal of using bodyworn sensors to automatically measure EI. However, when operated all day, all these methods face the challenge of FP occurring
during noneating activities. The method described in this paper
could be used as an automated ON/OFF switch, activating any
of these methods only during a detected meal/snack. This has
the potential to greatly reduce the incidence of FP in all-day
automated EI measures.
A second contribution of this paper is that we tested our
method on data collected during free-living, as compared to
scripted eating activities in the lab. For example, most previous works used between 4 and 11 specific foods and directed
subjects through a scripted sequence of eating and rest activities [22]–[24], [27], [28], [34]. In one study designed to detect
drinking gestures, each subject was recorded in an approximately 1-h session that included scripted activities of office
work, gaming, and leisure [25]. In our previous work that studied an automated bite counting method, no restrictions were
placed on food or beverage types, but all data were still collected in a lab [26]. In contrast, for this study, each of our

subjects was recorded for a day (10.4 h on an average) during
normal daily free-living, and we placed no restrictions on eating
behavior. To our knowledge, this is the first study using bodyworn sensors to detect eating activities in free-living conditions.
Although lab studies offer a controlled environment in which
eating period detection could be objectively confirmed by video
recording or direct observation, body-worn sensors that detect
eating are designed with the ultimate intention of being used in
free-living. Free-living studies face the challenge of recording
the actual activities of subjects in order to evaluate the automated methods, as seen in this paper. However, event markers
are commonly used in the mobile physiological monitors, such
as Holter EKG monitors, for a wearer to note a significant event,
e.g., a panic attack. Hence, event markers are an accepted approach to identifying significant behavioral events from among
other free living activities. The advantage of studying eating in
free-living is that eating behaviors, schedules, and activities are
as natural as possible.
The third contribution of this paper is that we tested our
method on the largest dataset (449 total hours) that has been
reported in the related literature. This is partly due to the fact
that eating occurs much less frequently than noneating in freeliving. In our dataset, we observed 22.4 h of eating out of 449
total hours, a ratio of 1 to 20. In contrast, previous works that
used data collected in the lab were based on an unrealistic equal
ratio of eating and noneating data [23], [24], [28]. This confounds comparisons of accuracies between these methods and
the results reported in this paper. As shown in our results, using
equal weighting for eating and noneating data achieves 95%
accuracy for a classifier that blindly labels all data as noneating; this is obviously not desirable. We achieved 81% accuracy
classifying 1-s epochs as eating or noneating at a more realistic
20:1 weighting that more closely conforms to actual behavior.
Contrasting our results against previous works, Sazonov and
colleagues achieved 97% accuracy classifying 1.5-s epochs as
containing swallows or not, 85% accuracy detecting individual
swallows, and 81% accuracy classifying 30-s epochs as containing chews or not [22], [24]. Päßler et al., achieved 83% accuracy
detecting swallows and 79% accuracy recognizing the food type
swallowed [23]. Amft et al. achieved 80% accuracy recognizing 11 different foods being eaten by a single subject [27], and
94% precision with 84% recall recognizing drinking motions
of 6 subjects [25]. Our previous work achieved 86% sensitivity at 81% positive predictive value at detecting bites during

DONG et al.: DETECTING PERIODS OF EATING DURING FREE-LIVING BY TRACKING WRIST MOTION

meals [26]. However, we reiterate that all the related works
weighted the detection of the eating activities versus noneating
activities at a 1:1 ratio, whereas we weighted 20:1. It also bears
repeating that the related works limited eating conditions by
collecting data in the lab.
The envisioned embodiment of our device is a small watch
worn on the wrist. Compared to some related works, this configuration is simpler, and potentially less embarrassing (compared
for example to head-mounted sensors), which has implications
for long-term use in free-living. We used an iPhone to collect
data for algorithm development and evaluation so that we could
record a full day of raw data. However, in practice our method
would only need to store raw data until the current data segment
was classified, greatly reducing the needed memory. It would
also only need to power gyroscopes during the data segments
suspected of containing eating activity. This is important because a MEMS accelerometer uses approximately 10% of the
power of a MEMS gyroscope [30], [31]; a typical coin-sized
battery can power a single MEMS gyroscope for part of one
day, while it can power an accelerometer for over 1 week.
Another application for the method described in this paper is
the automated measurement of a daily pattern of eating activities. Daily patterns are known to be associated with variations
in EI [35]. For example, night eating syndrome (NES) is characterized by evening hyperphagia and morning anorexia [36].
Different studies have found varying links between NES and
obesity and other disorders [37]. One factor inhibiting study
is the difficulty of objectively quantifying and measuring diagnostic criteria involving eating patterns [38]. Binge eating
disorder [39] and eating disorders linked to night shift working [40] are other problems associated with temporal eating
patterns. The method described in this paper has the potential to
provide an objective eating activity calendar for studying these
types of problems.
A limitation of our evaluation is that the classifier was trained
at the group level. We hypothesize that individual-level training
could improve these results. However, we only recorded one
day of data per person, with an average of 116/43 = 2.7 periods
of eating per person. In future work, we would like to collect
free-living data from individuals over a longer duration (e.g.,
a week or more). This would allow the classifier to be trained
to the individual, perhaps improving performance. This would
also allow us to further explore the idea that our method may not
be suitable for some people who do not exhibit vigorous wrist
motion at the boundaries of eating activities. Another limitation
of our method is that it groups all noneating activities into a
single class. It may be that a multiclass approach with a more
sophisticated classifier would achieve a higher recognition accuracy. These ideas are all subjects for future work, for which
the current work provides the foundation that the detection of
eating boundaries is feasible based on a relatively simple wrist
sensor.
REFERENCES
[1] World Health Organization Media Center. (2013, Jan. 29). “Obesity and Overweight.” [Online]. Available: http://www.who.int/
mediacentre/factsheets/fs311/en/index.html

1259

[2] K. Flegal, M. Carroll, B. Kit, and C. Ogden, “Prevalence of obesity and
trends in the distribution of body mass index among US adults, 1999–
2010,” J. Amer. Med. Assoc., vol. 307 no. 5, pp. 491–497, 2012.
[3] C. Ogden, M. Carroll, B. Kit, and K. Flegal, “Prevalence of obesity and
trends in body mass index among US children and adolescents, 1999–
2010,” J. Amer. Med. Assoc., vol. 307, no. 5, pp. 483–490, 2012.
[4] N. Wellman and B. Friedberg, “Causes and consequences of adult obesity:
Health, social and economic impacts in the United States,” Asia Pacific J.
Clin. Nutrit., vol. 11, no. 667–751, pp. 705–709, 2002.
[5] K. Flegal, B. Graubard, D. Williamson, and M. Gail, “Excess deaths
associated with underweight, overweight, and obesity,” J. Amer. Med.
Assoc., vol. 293 no. 15, pp. 1861–1867, 2005.
[6] A. Mokdad, J. Marks, D. Stroup, and J. Gerberding, “Actual causes of
death in the United States, 2000,” J. Amer. Med. Assoc., vol. 291, no. 10,
pp. 1238–1245, 2004.
[7] E. Sazonov and S. Schuckers, “The energetics of obesity: A Review.
Monitoring energy intake and energy expenditure in humans,” IEEE Eng.
Med. Biol. Mag., vol. 29, no. 1, pp. 31–35, Jan./Feb. 2010.
[8] J. Conway, M. Irwin, and B. Ainsworth, “Estimating energy expenditure
from the Minnesota leisure time physical activity and Tecumseh occupational activity questionnaires—A doubly labeled water validation,” J.
Clin. Epidemiol., vol. 55 no. 4, pp. 293–299, 2002.
[9] S. Mahabir et al., “Comparison of energy expenditure estimates from 4
physical activity questionnaires with doubly labeled water estimates in
postmenopausal women,” Amer. J. Clin. Nutrit., vol. 84, no. 1, pp. 230–
236, 2006.
[10] E. Rush, M. Valencia, and L. Plank, “Validation of a 7-day physical activity
diary against doubly-labelled water,” Ann. Human Biol., vol. 35, no. 4,
pp. 416–421, 2008.
[11] K. Westerterp, “Assessment of physical activity: A critical appraisal,” Eur.
J. Appl. Physiol., vol. 105 no. 6, pp. 823–828, 2009.
[12] C. Champagne, G. Bray, A. Kurtz, J. Monteiro, E. Tucker, J. Volaufova,
and J. Delany, ”Energy intake and energy expenditure: A controlled study
comparing dieticians and non-dieticians,” J. Amer. Dietet. Assoc., vol. 102,
no. 10, pp. 1428–1432, 2002.
[13] K. Glanz, J. Brug, and P. van Assema, “Are awareness of dietary food
intake and actual fat consumption associated? A Dutch–American comparison,” Eur. J. Clin. Nutrit., vol. 51, pp. 542–547, 1997.
[14] S. Jonnalagadda, D. Mitchell, H. Smiciklas-Wright, K. Meaker, N. Heel,
W. Karmally, A. Ershow, and P. Mkris-Etherton, “Accuracy of energy
intake data estimated by a multiple-pass, 24-hour dietary recall technique,”
J. Amer. Dietetic Assoc., vol. 100, no. 3, pp. 303–311, 2000.
[15] S. Lichtman, K. Pisarska, E. Berman, M. Pestone, H. Dowling,
E. Offenbacher, H. Weisel, S. Heshka, D. Matthews, and S. Heymsfield,
“Discrepancy between self-reported and actual caloric intake and exercise
in obese subjects,” New Engl. J. Med., vol. 327, no. 27, pp. 1894–1898,
1992.
[16] L. Muhlheim, D. Allison, S. Heshka, and S. Heymsfield, “Do unsuccessful
dieters intentionally underreport food intake?,” Int. J. Eat. Disorders,
vol. 24, pp. 259–266, 1998.
[17] D. Schoeller, D. Thomas et al., “Self-report–based estimates of energy
intake offer an inadequate basis for scientific conclusions,” Amer. J. Clin.
Nutrit., vol. 97 no. 6, pp. 1413–1415, 2013.
[18] J. Tooze, A. Subaret, F. Thompson, R. Troiano, A. Schatzkin, and
V. Kipnis, “Psychosocial predictors of energy underreporting in a large
doubly labeled water study,” Amer. J. Clin. Nutrit., vol. 79, pp. 795–804,
2004.
[19] B. McCabe-Sellers, “Advancing the art and science of dietary assessment
through technology,” J. Amer. Dietetic Assoc., vol. 110, no. 1, pp. 52–54,
2010.
[20] F. Thompson, A. Subar, C. Loria, J. Reedy, and T. Baranowski, “Need for
technological innovation in dietary assessment,” J. Amer. Dietetic Assoc.,
vol. 110, no. 1, pp. 48–51, 2010.
[21] A. Ershow, A. Ortega, J. Baldwin, and J. Hill, “Engineering approaches
to energy balance and obesity: Opportunities for novel collaborations and
research: Report of a joint National Science Foundation and National
Institutes of Health workshop,” J. Diabetes Sci. Technol., vol. 1 no. 1, pp.
96–105, 2007.
[22] E. Sazonov and J. Fontana, “A sensor system for automatic detection of
food intake through non-invasive monitoring of chewing,” IEEE Sens. J.,
vol. 12 no. 5, pp. 1340–1348, May 2012.
[23] S. Päßler, M. Wolff, and W. Fischer, “Food intake monitoring: An acoustical approach to automated food intake activity detection and classification
of consumed food,” Physiol. Meas., vol. 33, no. 6, pp. 1073–1093, 2012.
[24] E. Sazonov, O. Makeyev, S. Schuckers, P. Lopez-Meyer, E. Melanson,
and M. Neuman, “Automatic detection of swallowing events by acoustical

1260

[25]
[26]
[27]
[28]
[29]
[30]
[31]
[32]
[33]

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 4, JULY 2014

means for applications of monitoring of ingestive behavior,” IEEE Trans.
Biomed. Eng., vol. 57, no. 3, pp. 626–633, Mar. 2010.
O. Amft, D. Bannach, G. Pirkl, M. Kreil, and P. Lukowicz, “Towards
Wearable Sensing-Based Assessment of Fluid Intake,” in Proc. IEEE 8th
Int. Conf. Pervas. Comput. Commun. Workshop, 2010, pp. 298–303.
Y. Dong, A. Hoover, J. Scisco, and E. Muth, “A new method for measuring meal intake in humans via automated wrist motion tracking,” Appl.
Psychophysiol. Biofeedback, vol. 37 no. 3, pp. 205–215, 2012.
O. Amft, M. Kusserow, and G. Troster, “Probabilistic parsing of dietary
activity events,” in Proc. Int. Workshop Wearable Implant. Body Sens.
Netw., 2007, pp. 242–247.
O. Amft and G. Troster, “Recognition of Dietary Activity Events Using
On-body Sensors,” Artif. Intell. Med., vol. 42, pp. 121–136, 2008.
Y. Dong, “Tracking wrist motion to detect and measure the eating consumption of free-living humans,” Ph.D. dissertation, Dept. Elect. Comput.
Eng., Clemson Univ., Clemson, SC, USA, 2012.
STMicroelectronics. “MEMS Inertial Sensor, LIS344ALH Accelerometer.” (2011, Dec. 5). [Online]. Available: http://www.st.com/internet/
analog/product/207281.jsp
STMicroelectronics. “MEMS Inertial Sensor, LPR410AL Gyroscope.” (2011, Dec. 5). [Online]. Available: http://www.st.com/internet/
analog/product/248621.jsp
M. Sonka, V. Hlavac, and R. Boyle, Image Processing, Analysis, and
Machine Vision, 2nd ed. Boston, MA, USA: PWS Publishing, 1999.
T. Mitchell, Machine Learning. New York, NY, USA: McGraw-Hill,
1997.

[34] H. Junker, O. Amft, P. Lukowicz, and G. Troster, “Gesture spotting with
body-worn inertial sensors to detect user activities,” Pattern Recognit.,
vol. 41, no. 6, pp. 2010–2024, 2008.
[35] J. Kerver, E. Yang, S. Obayashi, L. Bianchi, and W. Song, “Meal and
snack patterns are associated with dietary intake of energy and nutrients
in US adults,” J. Amer. Dietetic Assoc., vol. 106 no. 1, pp. 46–53, 2006.
[36] G. Birketvedt et al., “Behavioral and Neuroendocrine Characteristics of
the Night-Eating Syndrome,” J. Amer. Med. Assoc., vol. 282 no. 7, pp.
657–663, 1999.
[37] J. Cleator, J. Abbott, P. Judd, C. Sutton, and J. Wilding, “Night eating
syndrome: Implications for severe obesity,” Nutrit. Diabetes, vol. 2 no. 9,
p. e44, 2012.
[38] K. Allison et al., “Proposed diagnostic criteria for night eating syndrome,”
Int. J. Eat. Disord., vol. 43 no. 3, pp. 241–247, 2010.
[39] A. Harb et al., “Night eating patterns and chronotypes: A correlation with
binge eating behaviors,” Psychiatry Res., vol. 200, no. 2, pp. 489–493,
2012.
[40] J. Waterhouse, P. Buckley, B. Edwards, and T. Reilly, “Measurement of,
and some reasons for, differences in eating habits between night and day
workers,” Chronobiol. Int., vol. 20 no. 6, pp. 1075–1092, 2003.

Authors’ photographs and biographies not available at the time of publication.

