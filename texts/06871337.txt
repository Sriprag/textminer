IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

227

Simultaneously Optimizing Spatial Spectral Features
Based on Mutual Information for EEG Classification
Jianjun Meng, Lin Yao, Xinjun Sheng, Dingguo Zhang, and Xiangyang Zhu∗

Abstract—High performance of the brain–computer interface
(BCI) needs efficient algorithms to extract discriminative features
from raw electroencephalography (EEG) signals. In this paper, we
present a novel scheme to extract spatial spectral features for the
motor imagery-based BCI. The learning task is formulated by maximizing the mutual information between spatial spectral features
(MMISS) and class labels, by which a unique objective function
directly related to Bayes classification error is optimized. The spatial spectral features are assumed to follow a parametric Gaussian
distribution, which has been validated by the normal distribution
Mardia’s test, and under this assumption the estimation of mutual
information is derived. We propose a gradient based alternative
and iterative learning algorithm to optimize the cost function and
derive the spatial and spectral filters simultaneously. The experimental results on dataset IVa of BCI competition III and dataset
IIa of BCI competition IV show that the proposed MMISS is able
to efficiently extract discriminative features from motor imagerybased EEG signals to enhance the classification accuracy compared
to other existing algorithms.
Index Terms—Brain–computer interface (BCI), filter optimization, mutual information, spatial spectral feature.

I. INTRODUCTION
BRAIN–COMPUTER interface (BCI) provides a potential way for paralyzed patients to restore lost motor function, which has been impaired by devastating neuromuscular
disorders [1]. Motor imagery-based BCI is a promising implementation, in which users perform the imagination or mental
rehearsal of motor actions without actually moving [2]. During
the imagination of hand and foot movements, the suppression or
augmentation of cortical rhythmic activity shows distinct spatial asymmetry in the regions of motor or somatosensory cortex. This neurophysiological phenomenon called event-related
desynchronization (ERD) and event-related synchronization
(ERS) accompanying real and imagined body part movement
lays the foundation for classifying motor imagery EEG signals

A

Manuscript received May 2, 2013; revised June 25, 2014; accepted July 22,
2014. Date of publication August 5, 2014; date of current version December
18, 2014. This work was supported in parts by National Basic Research Program (973 Program) of China (2011CB013305), the National Natural Science
Foundation of China (51375296,51075265), and the Science and Technology
Commission of Shanghai Municipality (11JC1406000, 13430721600). Asterisk
indicates corresponding author.
J. Meng, L. Yao, X. Sheng, and D. Zhang are with the State Key Laboratory
of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai
200240, China (e-mail: mengjianjunxs008@gmail.com; ylin0liny@gmail.com;
xjsheng@sjtu.edu.cn; dgzhang@sjtu.edu.cn).
∗ X. Zhu is with the State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail:
mexyzhu@sjtu.edu.cn).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2014.2345458

[3]. However, the rhythm activity derived by noninvasive EEG
recorded from the scalp is blurred due to volume conduction
and is easily contaminated by other sources and artifacts [4].
Hence, advanced signal processing algorithms are required for
high performance of the BCI.
It is well known that feature extraction, including spatial filters and temporal/spectral filters, plays a vital role in distinguishing patterns of different motor imaginations. Common spatial
pattern (CSP) is a highly successful spatial filtering technique
for this purpose [5], [6]. This technique uses covariance analysis
to extremely amplify the class differences in spatial scale, but
neglects the frequency information, which is important for portraying rhythmic activities [3]. To compensate for this, wide or
narrow band temporal/spectral filters are often applied to the raw
EEG signals before spatial filtering. In this study, we consider
the bandpass temporal and spectral filters as the same filters and
choose to use the spectral filters for consistency.
However, the frequency band is generally subject specific. To
avoid the exhausting work of selecting a frequency band manually for each subject, the combined optimization of spatial and
spectral filters has gained much attention for improving the performance of a BCI system. In recent years, great effort has been
devoted to this area and can be categorized into three schemes. 1)
The first scheme contains the embedded solutions such as common spatial spectral pattern (CSSP) [7] and its improved version
of common sparse spectral spatial pattern (CSSSP) [8]. The core
of their ideas is that embed one and several time-delayed signals into raw EEG signals, and then, use the CSP algorithm to
optimize spatial and finite impulse response (FIR) filters simultaneously. Recently, Higashi et al. [9] proposed a new algorithm
of optimizing FIR filter banks and spatial patterns sequentially
(named DFBCSP). They designed several orthogonal spectral
filters and obtained local maximums of the cost function by
sequential optimization. 2) The second category optimizes the
bandpass filters equivalently in the frequency domain, and thus,
these filters are called spectral filters. Different cost functions
are used to optimize the spatial and spectral filters iteratively
by spectrally weighted common spatial pattern (SWCSP) [10].
Similarly, iterative spatial spectral pattern learning (ISSPL) [11]
optimizes the spectral filters by a classifier for the purpose of
good generalization performance. 3) The third scheme utilizes
several filter banks and selects a reduced set of features from
predefined narrow bands. The subband common spatial pattern
and filter bank common spatial pattern (FBCSP)[12], [13] belong to this category. This delicate algorithm (FBCSP) with
1 The bandpass filters applied or optimized in the time domain or frequency
domain are named as temporal and spectral filter, respectively, and they are
functionally equivalent in our context.

0018-9294 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

228

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

its multiclass extension achieved the best performance on both
datasets IIa and IIb in the BCI Competition IV [14], [15]. Later,
Zhang et al. [16] proposed an optimum spatio-spectral filtering network (OSSFN) to optimize spatial filters by maximizing
nonparametric-based mutual information , however, they still
adopt the filter bank strategy to select the bandpass filters. Thus,
their method falls into this category. Recently, a Bayesian framework is proposed to devise the arbitrary frequency bands that
are generated by a particle-based approximation method [17].
This method adopts a sampling algorithm to approximate the
posterior density and a weighted classification rule to output the
final decision. This meta-classification[18] is different from all
the algorithms we compared.
In this paper, we address the problem of designing optimal
spatial spectral features for EEG classification. Previously, raw
EEG signals conditioned on any given class were assumed to
follow Gaussian distribution to derive learning algorithms [19],
[20]. Instead of applying this hypothesis for raw EEG signals,
we assume that the spatial spectral features follow a parametric
Gaussian distribution, which is validated by the normal distribution Mardia’s test with the data of 14 subjects. Based on the
assumption, the mutual information between features and class
labels is estimated by the samples. In order to find the optimal
spatial spectral filters simultaneously, we propose to maximize
the mutual information by an iterative procedure and a gradient
method. Our proposed approach belongs to the second category
of spatial and spectral filtering, which has been described earlier,
because we optimize the spectral filter in the frequency domain.
The novel algorithm contributes to three primary aspects: first,
the objective function of maximizing mutual information has
a direct connection with minimal Bayesian classification error [19], [21]. By contrast, the technique of maximizing class
variance difference employed by other methods such as CSSP,
CSSSP, and DFBCSP does not preserve this characteristic; second, unlike SWCSP and ISSPL, maximizing mutual information
has a single cost function and guarantees monotonic convergence to a local maximum by iterative optimization. Third, our
method differs from OSSFN in two ways.
1) We combine the optimization of spatial and spectral filters
simultaneously rather than utilizing the filter bank and
feature selection strategy.
2) The spatial spectral features are treated as multivariate features to be optimized and assumed to follow parametric
Gaussian distribution. This assumption makes the computation efficient and effective.
This paper is organized as follows. Section I presents the estimation of mutual information between spatial spectral features
and class labels. Section II describes the experimental results of
the proposed algorithm compared to existing algorithms. The
discussion and conclusion are followed in Sections I and VI,
respectively.
II. BRIEF REVIEW OF RELATED WORKS
The prevalent CSP works effectively for feature extraction
of motor imagery-based EEG signals. As a benchmark method,
however, it does not consider the critical issue of frequency

TABLE I
SUMMARY OF SPATIAL AND TEMPORAL/SPECTRAL FILTERING TECHNIQUES
IN THE LITERATURE
Methods

Formulations and Notations

CSP

m ax E y ( i ) = 1 [σ 2 (w T X i )]
w

2


s.t.

E y ( i ) = ω [σ 2 (w T X i )] = 1

ω=1

m ax E y ( i ) = 1 [σ 2 (w T X τi )]

CSSP

w

CSSSP

m ax m ax
h

w



s.t.w T
where
DFBCSP

2


E y ( i ) = ω [σ 2 (w T X τi )] = 1
ω=1
τ
T
T T
2 M ×N
where
 X i = [X i , X i (τ ) ] ∈ R 
 P−τ

P−1
τ


w
wT
h(j )h(j + τ ) Σ1
τ =0
j= 1
s.t.

P−1


 P−τ


τ =0

j= 1



h(j )h(j + τ ) (Σ1τ + Σ2τ )
T

Σ τω

+



C
P

h1

w=1

Xi (τ )XiT ],

= E y ( i) = ω [Xi Xi (τ ) +
ω = 1, 2
and C is a nonnegative regularization coefficient
m ax

w j ,hj ,j = 1,...,F

s.t.

2

hT hk
j
h j h k 

E y (i )= 1 [σ 2 (X i , w j , h j )]

ω=1

E y (i )= ω [σ 2 (X i , w j , h j )]

= δ j , k , j, k = 1, . . . , F

where σ 2 (·) is a variance-based function of spatial
and temporal filter
SWCSP

Spatial filter: m ax
w

2

E y (i )= 1 [σ 2 (X i , w , b )]

ω=1

E y (i )= ω [σ 2 (X i , w , b )]

Spectral filter: Fisher’s criterion with constraint
Note: σ 2 (·) is a variance-based function of spatial
and spectral filter
ISSPL

Spatial filter: m ax
w

2

E y (i )= 1 [σ 2 (X i , w , b )]

ω=1

FBCSP

E y (i )= ω [σ 2 (X i , w , b )]

Spectral filter: maxi-margin classifier
{h 1 , . . . , h F }, m ax Ey ( i ) = 1 [σ 2 (w T Xi (h k ))]
s.t.

2


w

Ey (i) = ω [σ 2 (w T Xi (h k ))] = 1

ω=1

OSSFN

Select best features by feature selection method
Note: X i (h k )) means the block signal X i is filtered by
bandpass filter h k (the k th filter bank).
{h o p t , w o p t } = m ax I(A, Ω )
{h , w }

where I (A, Ω) is the mutual information between feature set A
and class label set Ω.
Note: σ 2 (·) means the variance of a feature vector or a variance-based function.
E y ( i ) = ω [·] means the expectation of a feature vector, the class label (y (i)) of
which is ω and i denotes the feature vector belongs to ith trial.

information. Classification of ERD/ERS patterns is sensitive to
frequency bands that are highly dependent on subjects and the
mental states of subjects. The spatial and spectral filters have
been extensively explored by many researchers. In this section,
the CSP method and other related works are comparatively reviewed.
A brief comparison of various algorithms is listed in Table I.
Throughout the paper, the spatial filter is denoted by the bold
lower-case letter w. Because in the previous researches, the
bandpass filters applied or optimized in the time domain and
frequency domain are explicitly or implicitly named as temporal
filters and spectral filters, respectively, they are denoted by the
bold lower-case letters h and b, accordingly. The element of a
temporal filter is denoted by h(j), where j is a positive integer.
Note that hj means the jth temporal filter (sometimes k is
used) rather than a component. A block of raw EEG signals
is organized in a matrix form and denoted as an upper case

MENG et al.: SIMULTANEOUSLY OPTIMIZING SPATIAL SPECTRAL FEATURES BASED ON MUTUAL INFORMATION FOR EEG CLASSIFICATION

letter (with a subscript) Xi ∈ RM ×N , where i means the block
belongs to ith trial, M is the number of channels, and N is the
number of samples in the block. The delayed signals are denoted
as Xi (τ ) ∈ RM ×N , which means the samples are delayed by
time τ . T is the transpose of a vector or a matrix. Other specific
notation is explained in the table.
CSP:Aim to maximize one class covariance while minimize
the other class covariance. Its equivalent optimization problem
is to maximize one specific class covariance with the normalization constraint of two class covariance. The solution is given
by the generalized eigenvalue decomposition [5], [6].
CSSP: Double the channels of raw EEG sample by concatenating its one time-delayed signals into the original ones. Similar to the CSP, the solution is also obtained by the generalized
eigenvalue decomposition. The CSSP derives both spatial filters
and several first-order FIR filters simultaneously [7].
CSSSP: Combine several time-delayed signals with raw EEG
sample. With the assumption that the signals are approximately
stationary in short time, the objective function is simplified and
the spatial filters and a common high-order FIR filter can be
solved simultaneously. In order to avoid overfitting, the regularization coefficient C is applied to this problem when the
number of coefficients in the FIR filter is relatively large. The
optimization technique like the gradient or line-search method
is suggested to solve this problem [8].
DFBCSP: Design high-order FIR filters for raw EEG signals,
and then, spatial filters are applied. The DFBCSP maximizes
the expectation of a variance-based feature for one specific class
under the normalization constraint of expectation of variancebased features for both classes. The optimization is conducted
by solving two subproblems of generalized eigenvalue decomposition sequentially and alternatively [9].
SWCSP: Transform the linear time-invariant bandpass filters
from the time domain to the frequency domain. The SWCSP
optimizes the spatial filters using the CSP algorithm and the
spectral filters by Fisher’s criterion (with positive coefficients
constraint) sequentially and iteratively [10].
ISSPL: Solve the bandpass filters in the frequency domain.
Similar to SWCSP, the ISSPL optimizes the spatial filters by the
CSP technique. However, the spectral filters are equivalently
solved by a max-margin machine. The algorithm of ISSPL iteratively solves the spatial and spectral filters until the stop
condition is satisfied [11].
FBCSP: Construct nonoverlapped filter banks and filter the
raw EEG signals by these multiple bandpass filters. Then, the
CSP algorithm is used to obtain spatial filters from each bandpass filtered EEG signals. Feature selection based on the best
individual mutual information is employed to select the best
subset of features [13].
OSSFN: Bandpass raw EEG signals by multiple filter banks
(similar to FBCSP) first. Derive the spatial filters by maximizing
the mutual information of features and class labels. The mutual
information is estimated by the nonparametric probability density function (kernel density estimation). Finally, the features in
the optimum frequency band are assumed to have the maximum
mutual information [16].

229

III. MAXIMIZING MUTUAL INFORMATION OF SPATIAL
SPECTRAL FEATURES (MMISS)
Although CSP is an efficient algorithm to extract discriminative features of two-class motor imagination, the direct connection between Bayes classification error and CSP is only established based on the assumption that the EEG signals conditioned on any class follow a Gaussian distribution recently [19].
Whether the combination of spatial and bandpass filters such
as CSSP, CSSSP, and DFBCSP hold the connection is still unknown. For SWCSP and ISSPL, experimental results show that
the iteration usually helps to improve the classification accuracy,
however, the convergence of iteration is not always guaranteed.
FBCSP and OSSFN take advantage of fixed filter banks, but the
flexibility of subject specific spectral filters might be lost at the
same time.
In this section, we introduce the MMISS to extract discriminative spatial and spectral features by maximizing mutual information, which is directly related to Bayes classification error.
Instead of solving a bandpass filter h in the time domain, we
compute it equivalently in the frequency domain like SWCSP
and ISSPL. The main purpose of this algorithm is to find the
spatial filter w and spectral filter b iteratively and simultaneously.
A. Design Optimization Formulation
In this study, we consider the log-power features based on
spatial and spectral filtered EEG signals. The procedure of
transforming raw EEG signals Xi = [xi (1), . . . , xi (N)] into
the feature vector ai and related cost function with respect to
spatial filters W and spectral filter b comprise the following
procedures.
1) Bandpass Filtering: Suppose B ∈ RN ×N is a linear timeinvariant bandpass filter (B is used instead of h introduced
before because B is a matrix here. The bandpass filter and
spectral filter are used interchangeably according to the meaning
of the context. ), which can be formulated as a circulant matrix.
To derive the interested rhythm activity of EEG signals, the
bandpass filter is necessarily applied to the raw EEG signals.
We then have the filtered signals
Zi = Xi B.

(1)

1) Spatial Filtering: A linear projection (named spatial filters)
is used to reduce the dimension of bandpass filtered EEG signals
Zi . The spatial and bandpass filtered EEG signal is formulated
as
Yi = W T Zi

(2)

where W = [w1 w2 · · · wnl ] ∈ RM ×nl , nl is the number of spatial filters.
3) Log-Power Feature: The mean power of a block EEG
signals after spatial and bandpass filtering is used as the logpower feature.

1

T
T
T
W Xi BB Xi W
(3)
ai = log diag
N

230

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

where the function of diag(·) returns a column vector formed by
the diagonal elements of “(·)” if it is a square matrix and returns
a diagonal matrix with the elements of “(·)” when it is a vector.
Note that the logarithm operation is used for numerical consideration. Since we use the assumption of Gaussian probability
density function in the following, the log operation moderates
the scalability of the exponential operation. On the other hand,
the similar log operation is adopted in the CSP algorithm to
approximate normal distribution of the data.
4) Fourier Transformed Log-Power Feature: As stated before,
we solve the bandpass filter in the frequency domain instead of
directly solving it in the time domain, therefore, we name this
bandpass filter as spectral filter. It is known that a circulant matrix can be diagonalized by the discrete Fourier transform [22].
For the bandpass filter B, which is circulant, the diagonalization
is achieved by
T

F B = diag([b1 , . . . , bN ])F

T

(4)

where F ∈ C N ×N is the Fourier matrix, C means the set of
all complex numbers, and denote b = [b1 , . . . , bN ]T . Then, the
spatial spectral feature is derived by

1

T
T
T
W Xi BB Xi W
ai = log diag
N


1
W T Xi F F T BB T F F T XiT W
= log diag
N


1
	i diag([b21 , . . . , b2N ])X
	iT W
WT X
= log diag
N
(5)
	i denotes the discrete Fourier transformed data matrix.
where X
5) Optimization Objective: Denote the set of feature vectors
and the set of class labels by A = {ai } and Ω = {ω}, respectively. Mutual information between the set of feature vectors
and class labels are used to formulate the objective function for
optimizing spatial and spectral filters.
max I(A, Ω) = H(A) −
W,b




H(A | ω)P (ω)

(6)

ω ∈Ω

where H(A) and H(A | ω) are the entropy of feature vector and
the conditional entropy of feature vector given a particular class
ω (e.g., ω = 1 or ω = 2 represents the left-hand or right-hand
motor imagery movement.), respectively.
The mutual information has been proved to have connection
with minimum Bayes classification error via lower and upper
bounds [23]. Maximizing the mutual information of A and Ω implies minimizing the error probability. Recently, studies of linear
feature extraction by maximizing mutual information show the
power of this method [21], [24]. Hence, we choose (6) to be our
objective function.
Since it is difficult to simultaneously find all parameters of
W and b, we consider two subproblems of optimizing spatial
and spectral filters alternatively and iteratively [25].

B. Optimize Spatial Filter
The first subproblem is to optimize W while fixing b. Define
	i diag([b2 , . . . , b2 ])X
	T .
	xi = X
R
1
N
i

(7)

Recall that W = [w1 w2 · · · wnl ] ∈ RM ×n l is a linear projection matrix that we want to find (also called spatial filters). Then,
the spatial spectral feature is written as

1

	 xi W
W TR
ai = log diag
.
(8)
N
We consider the mutual information between the feature vector
variable A and the class label variable Ω. Then, the objective
function (6) can be written as (fixing b)


H(A | ω)P (ω).
(9)
max I(A, Ω) = H(A) −
W

ω ∈Ω

In order to estimate H(A) and H(A | ω), we assume that the
spatial spectral features conditioned on any class p(a|ω) follow
the Gaussian distributions:
nl
1 T
1
−1
(10)
p(a|ω) = (2π)(− 2 ) |Ψω |− 2 e(− 2 r Ψ ω r )

n
ω
where r denotes the term a − aω , aω = n1ω
k =1 ak . Ψω =
n ω
1
T
k =1 (ak − aω )(ak − aω ) . nω is the number of trials in
nω
the training data belonging to class ω. aω and Ψω are the mean
vector and covariance matrix for specific class ω, respectively.
Since the number of samples for feature vector ai is often limited, Ψω usually takes a diagonal matrix form. Then, the entropy
of feature vector given class ω is expressed by

1
log((2πe)n l | Ψω |).
2
(11)
The marginal distribution p(a) , however,
does
not
follow
a

Gaussian distribution since p(a) = 2ω =1 P (ω)p(a | ω). It is a
mixture of Gaussian distribution. The entropy of feature vector
A can be viewed as an expectation of the function log(p(a))[26].
Then, the entropy can be estimated by samples of feature vector
a
H(A | ω) = −E[log(p(a | ω))] =

H(A) = −E[log(p(a))]  −

na
1 

log(p(ak ))
na

(12)

k =1

where na is the number of empirical samples of feature vector
2 a (usually equals to the number of trials) and p(ak ) =
ω =1 P (ω)p(ak | ω).
The gradient-based optimization technique is used to solve
the cost function of maximizing mutual information. Then, we
solve the gradient of mutual information I(A, Ω) with respect
to the spatial filter wl


w l I(A, Ω) = w l H(A) −
w l H(A | ω)P (ω) (13)
ω ∈Ω

2 Diagonal form of the covariance matrix for each class implies uncorrelation
among each element of feature vector a i . This operation is similar to the independence assumption for Naive Bayesian, which is one of the most effective
inductive learning.

MENG et al.: SIMULTANEOUSLY OPTIMIZING SPATIAL SPECTRAL FEATURES BASED ON MUTUAL INFORMATION FOR EEG CLASSIFICATION

w l H(A | ω) =

where
n l
1 log( j = 1 Ψ j , j )

∂ ( 12

log((2π e) n l

| Ψ ω | ))

∂ wl

=

∂Ψ

= 2Ψ1l , l ∂ wl ,l l , the last equality is due to
Ψj,j is a function of wl if and only if j = l. Then, we turn to
∂Ψ
solve ∂ wl ,l l
2

∂ wl

Ψl,l =

nω
1 

(ak ,l − aω ,l )2
nω

(14)

k =1

nω
∂Ψl,l
2 

∂(ak ,l − aω ,l )
=
(ak ,l − aω ,l )
∂wl
nω
∂wl

(15)

k =1

n ω ∂ a j , l
n ω 2 R	 x j
∂a
1
where ∂ wω ,l l = n1ω
j =1 ∂ w l = n ω
j =1 N e a j , l wl ; hence,
substitution of the aforementioned equalities to (15) gives
ω
∂Ψl,l
2 

=
(ak ,l − aω ,l )
∂wl
nω
k =1
⎛
⎞
nω


	xk
	xj
2
R
2
R
1
⎠ wl .
× ⎝ ak , l −
Ne
nω j =1 N ea j , l

n

Therefore
w l H(A | ω) =

nω
1 2 

(ak ,l − aω ,l )
2Ψl,l nω
k =1
⎛
⎞
nω


	
2Rxk
2Rxj ⎠
1
× ⎝ ak , l −
wl . (17)
Ne
nω j =1 N ea j , l

The derivation of w l H(A) is performed similarly. With
the gradient information, our iterative optimization algorithm
updates a spatial filter by
(iter +1)

wl

(iter )

= wl

+ λw l I(A, Ω)

(18)
(0)

where λ is the step size. Given a proper initial value of wl ,
the gradient-based iterative algorithm usually outputs a better
spatial filter after iteration steps. Note that, since the cost function of (9) is not usually a convex function, the gradient-based
optimization procedure may reach a local maximum instead of
(iter)
is
the global one. This implies that the initial value of wl
relatively important for the optimization problem. Here, we use
the spatial filters given by the CSP algorithm to be the initial
values.
One spatial filter can be obtained by the above procedure. For
simultaneous optimization of all the spatial filters in W , we propose a gradient-based method by considering partial derivatives
with respect to a joint vector, which is formed by concatenating all the spatial filters together. The details of the method are
provided in Appendix A.
C. Optimize Spectral Filter
The second subproblem is to optimize b while fixing W .
Similarly, the objective function (6) can be written as


H(A | ω)P (ω).
(19)
max I(A, Ω) = H(A) −
b

ω ∈Ω

Now consider the spatial spectral feature extractor (5)

1

T 	
2
2
T
	
W Xi diag([b1 , . . . , bN ])Xi W
.
ai = log diag
N
Let ai,l be a specific component of ai , which can be expressed
by


1 T	
2
2
T
	
w Xi diag([b1 , . . . , bN ])Xi wl
ai,l = log
N l


1

T 	
T
T
	
= log
diag(wl Xi (wl Xi )) β
N


1 T
b Λi,l b
(20)
= log
N
where the wave line · denotes the conjugate of a complex
value and the diag() function stands for the diagonal vector
of a matrix. Here, Λi,l is the diagonal matrix, where the diago
T X (wT X )). b = [b , . . . , b ]T and
nal elements are diag(w
i

l

(16)

231

l

i

1

N

β = diag(bbT ). From (20), we can see it has similar formulation to (8). Consequently, we can solve the spectral filter by
similar optimization algorithm. The gradient of mutual information I(A, Ω) with respect to spectral filter b is


b H(A | ω)P (ω)
(21)
b I(A, Ω) = b H(A) −
ω ∈Ω


n
∂ ( log((2π e) n l |Ψ ω |) )
log( l =l 1 Ψ l , l )
= 12
=
where b H(A|ω) =
∂
b
∂
b
n l
∂ Ψl , l
1 ∂ Ψl , l
l=1 2Ψ l , l ∂ b , Then, we turn to solve ∂ b .
⎞
⎛
nω
nω




∂Ψl,l
2Λj,l ⎠
2
2Λk ,l
1
=
b.
(ak ,l − aω ,l ) ⎝ a k , l −
∂b
nω
Ne
nω j =1 N ea j , l
1
2

k =1

(22)
The derivation of b H(A) is performed similarly. With the
gradient information, our iterative optimization algorithm updates a spectral filter by
b(iter +1) = b(iter) + λb I(A, Ω).

(23)

Note that, the coefficients of the spectral filter b are usually
formed in a high-dimensional vector. In order to make the solution robust and efficient, a regularization term can be introduced
to achieve the sparse solution [8] or the smooth solution [27].
To avoid the additional hyperparameter introduced by a regularization term, the similar subspace gradient-based learning
algorithm is used to solve the spectral filter b in this study. For
more details, please refer to Appendix B.
D. Iteration and Convergence
We alternatively optimize W and b by solving the optimization problem of (9) and (19), respectively. Given an initial value
(W (k ) , b(k ) ), the value of mutual information is denoted as
	 (k ) , b(k ) ) = I	1 (W (k ) | b(k ) ). Derive W (k +1) by maximizI(W
ing (9) and the value of mutual information is updated to be
I	1 (W (k +1) | b(k ) ). After optimizing the spatial filters, we sequentially optimize the spectral filter. Similarly, derive b(k +1)
by maximizing (19) when W (k +1) is fixed and the value of

232

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

mutual information is updated to be I	2 (b(k +1) | W (k +1) ). The
update of spatial filters W and spectral filters b are performed
sequentially and iteratively. The initial spectral filters for the
first iteration can be set to accommodate a broad frequency
band, e.g., 7–32 Hz. The stop criterion for iteration can be chosen by the user, e.g., stopping when the mutual information gain
between two consecutive iteration is less than a preset threshold
ε (ε = 1 × 10−4 ) or a maximum number of iterations has been
achieved. In this paper, we iterate the optimization of spatial and
spectral filters five times or until the mutual information gain
between I	1 and I	2 is less than ε.
Suppose C is an upper bound of I(A, Ω) in our problem. We
give the following convergence analysis of the cost function in
the alternating iteration. Because EEG signals are complex, the
cost function I(A, Ω) is usually sophisticated. In this case, we
make an assumption that an initial value (W (0) , b(0) ), which is
near the local maximum if it exists, has been given. Note that,
this can usually be achieved by the CSP algorithm, which has
been mentioned at the end of Section III B.
Proposition 1: If an initial value (W (0) , b(0) ) which is near
a uniquely local maximum is given, the cost function is monotonically increasing or remains the same by iterations until it
reaches the local maximum. That is
	 (k +1) , b(k +1) ) < C
	 (k ) , b(k ) ) ≤ I(W
0 ≤ I(W

(24)

where W (k ) and b(k ) are the spatial filters and spectral filter,
respectively, to be optimized at the kth iteration.
Proof: The upper bound of I(A, Ω) is derivedas following. I(A, Ω) = H(Ω) − H(Ω | A) ≤ H(Ω) = − 2ω =1 P (ω)
log2 P (ω) = 1 for the classification of a two-class motor imagination with equal probability. Hence, 1 ≤ C < +∞.
	 (k ) , b(k ) ) = I	1 (W (k ) | b(k ) ) = I	2 (b(k ) |
Note that, I(W
(k )
W ) ≥ 0. Derive W (k +1) by maximizing (9) when b(k )
is fixed. Given the initial value (W (0) , b(0) ) and the assumption of a unique local maximum, we can find a
uniquely attained maximum by solving (9) with an additional constraint that (9) is continuously differentiable with respect to W (k ) . Then, the relationship 0 ≤ I	1 (W (k ) | b(k ) ) ≤
I	1 (W (k +1) |b(k ) ) ≤ C hold, because the gradient-based learning algorithm for the first subproblem (9) achieves its local
maximum by W (k +1) . At the same time, it means the relation	 (k +1) , b(k ) ) ≤ C. Simi	 (k ) , b(k ) ) ≤ I(W
ship yields 0 ≤ I(W
larly, 0 ≤ I	1 (W (k +1) |b(k ) ) ≤ I	2 (b(k +1) |W (k +1) ) ≤ C can be
obtained by the gradient-based learning algorithm for the second
	 (k ) , b(k ) ) ≤
subproblem (19). As a result, it holds that 0 ≤ I(W
(k +1)
(k )
(k +1)
(k +1)
	
	
I(W
, b ) ≤ I(W
,b
) ≤ C (see [25, Sec.
2.7]). This completes the proof of Proposition 1.
IV. EXPERIMENTS AND RESULTS
In this section, experiments on two public datasets are performed: BCI Competition III Dataset IVa[28] and BCI Competition IV Dataset IIa. Comparison of the proposed algorithm
against the existing algorithms are presented. The same preprocessing and hyperparameters setting are applied to both datasets
for fair comparison.

A. Preprocessing and Selection of Hyperparameters
The implementations for each method are as follows. A homogeneous setting of channels, time window and the number of
spatial filters is adopted for all the comparative methods for fair
comparison. Other hyperparameters for each method are finely
tuned according to previous reports.
1) CSP: Fourth-order bandpass filter (Butterworth, 7–32 Hz)
is applied to raw EEG signals before the CSP algorithm is implemented. The two eigenvectors corresponding to eigenvalues
from both ends of the eigenvalue spectrum are used as spatial
filters.
2) CSSP: The raw EEG signals are bandpass filtered by a
7–32 Hz Butterworth filter as preprocessing. The time delay τ
is chosen out of {1, 2, . . . , 15}. It is optimized by using 10 × 10
CV in the training data. Here, the time interval of [0.5, 2.5]s is
inappropriate for the CSSP algorithm, since twice the channel
number is larger than the number of samples in the time window.
The covariance matrices consequently cause an ill-conditioned
eigenvalue problem. Hence, the time interval of [0.5, 3.5]s is
chosen for this method.
3) DFBCSP: Two spatial filters are derived by maximizing
the variance of filtered right-hand imagery EEG signals under
the constraint of normalization. The order of the FIR filter is set
to 40. The iteration stops when the error of the cost function
between successive iterations is less than 10−4 .
4) SWCSP: The iteration number in alternating optimization
is two since two iterations give good classification accuracy[10].
Similarly, two top eigenvectors corresponding to the largest and
smallest eigenvalues are used as spatial filters. The spectral
filter is designed according to Fisher’s criterion with positive
coefficient constraint. p	 = 0, q 	 = 1
5) ISSPL: Two spatial filters (one spatial filter per class) are
solved for ISSPL. The initial spectral filters for the first iteration
are set to a broad frequency range 7–32 Hz. The stop criterion
is set to two iterations of alternative optimizations according to
previous results[11]. The regularization parameter C is chosen
out of 20 candidates log-linearly spaced between 10−1 and 104
by 10 × 10 cross validation on the training set.
6) FBCSP: The filter banks are designed to cover the broad
frequency band of 4–40 Hz, which consists of nine nonoverlapping temporal bandpass filters that cover a bandwidth of 4 Hz
each. All filters are fourth-order Butterworth filters. We choose
two pairs of CSP features in each band to construct the pool of
CSP features (four eigenvectors corresponding to the two largest
and two smallest eigenvalues). According to the suggestions in
[14], two pairs of CSP features usually give high classification
accuracy. Then, these CSP features from multiple bands are
selected by the mutual information-based best individual feature algorithm. The number (k) of best individual features is set
to 1.
7) OSSFN: Construct the same nine nonoverlapping bandpass filters as FBCSP1 that covers the possible EEG rhythms
of motor imagery, then derive a discriminative spatial filter subspace from each band by the CSP algorithm (obtain initial values
for optimization of OSSFN). Optimize the two spatial filters in
each band by maximizing the mutual information proposed in

MENG et al.: SIMULTANEOUSLY OPTIMIZING SPATIAL SPECTRAL FEATURES BASED ON MUTUAL INFORMATION FOR EEG CLASSIFICATION

[16]. Select the optimal frequency band and spatial filters by the
maximum mutual information criterion.
8) MMISS: The feature vector defined in (5) is used. Two
spatial filters are derived by simultaneous optimization of all
spatial filters, i.e., (25) and (27). The subspace U is constructed
by the first two pairs of CSP spatial filters. The initial spectral
filter b is set to a broad frequency band 7–32 Hz. In our implementation, we perform the line search procedure to test the λ
values [in (18) and (23)] in the range of [−1,1] with an interval of 0.01 until a local maximum of I(A, Ω) is reached. The
iteration stops when the mutual information gain between two
successive alternative iterations becomes less than ε = 10−4 or
the number of alternative iterations is larger than 5.
B. BCI Competition III Dataset IVa
1) Data Description: The dataset IVa from BCI competition
III are used in our experiments[28]. These EEG datasets were
recorded from five healthy subjects (aa, al, av, aw, and ay). 118
electrodes were placed for each subject and the sampling rate
in this experiment was 1000 Hz. During each trial, the subject
was given visual cues for 3.5 s, during which the three motor
imageries should be performed: left hand, right hand, and right
foot. Only EEG trials for right-hand and right-foot movements
were provided for analysis. The presentation of target cues was
intermitted by periods of random length from 1.75 to 2.25 s.
During the random periods, the subject could relax. 140 trials
were collected for each subject and each task.
In our experiment, the EEG data are down-sampled to 100 Hz
for use. The signals in the time interval of [0.5, 2.5]s are analyzed
for each trial. The time when a visual cue is presented is the
beginning time (0 s).
2) Results: In this section, ten-fold cross validation is used to
assess the performance of extracted features. All the 280 trials of
dataset IVa for each subject are used to perform cross validation.
In each fold, nine parts of data are used for training data, the
remaining one part is left for testing data. Then ten-fold cross
validation is repeated ten times and the accuracies are averaged
to get the mean result of 10 × 10 fold cross validation. In order
to ensure a fair comparison among the competing algorithms,
the same training and testing partitions are used for evaluation
of each method in the cross validation.
First, classification accuracy of the proposed method is compared with the conventional methods described in Section II
Spatial filters for a particular example are illustrated to show the
consistency between the learned filters and prior neurophysiological knowledge. We then discuss the amplitude characteristic
of the spectral filter in each method. Finally, the behaviors of
convergence for the proposed alternative and iterative algorithm
in MMISS are presented.
a) Classification accuracy: In the following classification
experiment, discriminative features are extracted from EEG signals by each method separately. For simplicity and fair comparison, only one pair of spatial filters and one spectral filter are
solved by each method. Then, support vector machine (SVM)
with the best parameters is used to classify the feature vectors[29]. The Gaussian radial basis function (RBF) is chosen as

233

TABLE II
MEAN ACCURACIES OF THE 10 × 10-FOLD CROSSVALIDATION ON DATASET
IVA OF THE BCI COMPETITION III
Method

CSP
(S.D.)
CSSP
(S.D.)
DFBCSP
(S.D.)
SWCSP
(S.D.)
ISSPL
(S.D.)
FBCSP
(S.D.)
OSSFN
(S.D.)
MMISS
(S.D.)

Subject
aa

al

av

aw

ay

mean

76.1
7.6
78.9
7.5
86.4
6.8
82.5
6.4
87.6
6.2
90.4
4.7
77.8
13.2
88.8
6.2

88.7
5.1
97.6
3.1
95.4
4.1
90.6
5.8
97.1
2.7
98.0
2.7
91.1
5.4
97.9
2.6

68.3
10.2
68.6
10.9
70.3
9.6
69.5
9.9
49.3
12.2
70.9
8.4
65.5
9.5
77.3
8.6

86.4
10.4
97.8
5.8
92.3
13.6
92.1
8.6
94.3
4.5
87.5
6.1
83.9
7.8
94.6
4.5

91.0
5.9
93.4
4.8
94.6
4.4
95.9
3.5
90.3
6.1
95.3
4.3
75.1
9.5
94.9
4.3

82.1
11.8
87.3
13.5
87.8
12.6
86.1
11.8
83.7
18.9
88.4
11.0
78.7
12.7
90.7
9.2

the kernel function and the hyperparameters such as cost value
and parameter in kernel function are selected from {0.5, 1, 2,
4, 8} and {0.0625, 0.125, 0.25, 0.5, 1, 2} by the nested cross
validation. Note that more than one pair of features for each
method might further improve the classification accuracy, however, the simplification for comparison does not affect the major
conclusions.
The mean accuracy and standard deviation of the 10 × 10
CV for each subject and each method is listed in Table II. The
proposed method outperforms the conventional spatial spectral
methods in terms of mean classification accuracy under the same
comparative condition. The standard deviation of the CV test for
MMISS is almost the smallest (similar to FBCSP) on average
over five subjects.
The optimal spatial filters for each method are illustrated in
Fig. 1. We choose a specific example of subject “av” to show the
spatial filters of each method, which correspond to the smallest/largest eigenvalues. The coefficients of each filter are normalized to keep the sum of squares of the elements equal to one.
For this subject, the spatial filters obtained by MMISS exhibit
the most physiologically interpretable topography, in which the
near mid-central vertex and the left hemisphere discriminate the
foot and righ-hand imagery, respectively. This possibly explains
the higher classification accuracy than other algorithms. However, for other methods except FBCSP, the topography generally
disagrees with the prior physiological knowledge. For other subjects, most of the methods output similar topography, which is
not shown due to paper space requirements.
b) Spectral filters: To demonstrate differences among
spectral filters learned by all the comparative methods. One
specific training dataset of CV test is picked up for subject “aa.”
We show the normalized amplitude characteristics of the compared filters for this subject in Fig. 2. These filters are optimized
from the time domain [e.g., CSSP in Fig. 2(b) and DFBCSP in
Fig. 2(c)] or the frequency domain [e.g., SWCSP in Fig. 2(d),
ISSPL in Fig. 2(e) and the proposed MMISS in Fig. 2(h)]. Some
of them are picked up from an initial filter banks [e.g. FBCSP

234

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

Fig. 1. Most significant spatial filters extracted by each of the comparative
methods. The spatial filters are derived from a specific dataset of subject “av.”
(a) CSP (b) CSSP (c) DFBCSP (d) SWCSP (e) ISSPL (f) FBCSP (g) OSSFN (h)
MMISS.

in Fig. 2(f), and OSSFN in Fig. 2(g)]. All the methods have
extracted the important components of higher alpha (10–16 Hz)
rhythms for this specific example (the spectrum of the filter
selected by OSSFN concentrates on higher beta rhythm). This
implies that these methods can learn or select a bandpass spectral filter, which is effective for classification. However, there are
distinct differences among the shape of spectral filters, which
means different discriminative information is captured by different methods.
c) Convergence of MMISS: The behavior of the cost function (6) in the alternative and iterative optimization are illustrated in Fig. 3. Five random training datasets in the CV test are
chosen for each subject. The curve of mutual information estimate over each iteration shows that the cost function increases
monotonically and converges in about 25 iterations. Usually, the
apparent increase of mutual information estimate is observed in
the first few iterations. After that, the mutual information gain
between two consecutive iterations is relatively small. This implies a local maximum is obtained after several iterations. One
example of the optimization process for the spectral filter of
MMISS is illustrated in Fig. 4. The initial value of broad band
spectral filter is shown in Fig. 4(a). After several iterations (second, third, fourth, and fifth), the shape of the spectral filter is
close to the final spectral filter output by MMISS algorithm [see
Fig. 2(h)].
C. BCI Competition IV Dataset IIa
1) Data Description: These data consisted of EEG signals
recorded from nine subjects of four motor imagery task, including left and right hand, foot, and tongue. Two sessions were

Fig. 2. The amplitude characteristics of spectral filters designed by each of
the comparative methods. (a) CSP (b) CSSP (c) DFBCSP (d) SWCSP (e) ISSPL
(f) FBCSP (g) OSSFN (h) MMISS.

Fig. 3. Value of mutual information after each iteration in the alternative and
iterative optimizing for spatial filters W and spectral filter b. The five datasets
are randomly chosen from cross validation for each subject. (a) subject aa (b)
subject al (c) subject av (d) subject aw

conducted on two different days, comprising 288 trials for each
session. Altogether, each session contains 72 trials for each task.
The EEG data were sampled with 250 Hz and acquired by 22
electrodes. Because one channel contains invalid signals in session two for some subjects, only 21 out of 22 EEG channels are
used in this experiment. Additionally, for each subject, there are
different amounts of trials that are contaminated by artifacts.

MENG et al.: SIMULTANEOUSLY OPTIMIZING SPATIAL SPECTRAL FEATURES BASED ON MUTUAL INFORMATION FOR EEG CLASSIFICATION

Fig. 4. Normalized values of spectral filter in each iteration in the optimization
process for one specific dataset of subject “aa.” For each plot, the iteration
number of spectral filter is (a) initial value (b) first iteration (c) second iteration
(d) third iteration (e) fourth iteration (f) fifth iteration.

These trials are excluded from the data. We consider the signals between 0.5 and 2.5 s after the onset of the visual cue for
evaluation.
2) Results:
a) Cross-validation results of multiclass classification:
First of all, we combine data in two sessions into one, and thus,
there are more than 200 trials for each binary classification.
Five-fold cross validation is used to assess the performance of
all the algorithms for this dataset because some subjects contain
only about 200 valid trials for binary classification. Multiclass
extensions to all the algorithms are investigated and pairwise
approach, which discriminates the derived features by each pair
of classes is adopted in this experiment. For the four classes
of motor imagery in the dataset IIa, 4 × (4 − 1)/2 = 6 binary
classifiers are required to discriminate each pair of classes. The
preprocessing and selection of hyperparameters are the same as
those described in part A. The mean kappa values of the 5 × 5fold crossvalidation for each subject and the average kappa value
for all the nine subjects on this combined dataset of two sessions are shown in Table III. Note that only the classification
results during the time interval of [0.5,2.5]s are computed and
reported in this table. The results show that the MMISS with
pairwise approach yields the best performance in terms of averaged mean kappa value (0.573). The Wilcoxon signed ranks
test for comparison of two classifiers and the Friedman test
with the correspondingpost hoc tests for comparison of more
classifiers over multiple datasets are applied to perform the
statistical analysis. They are nonparametric equivalent of the
repeated measure ANOVA and do not need to assume the population of multiple datasets follows normal distribution [30],
[31]. Since the size of datasets in our experiments are small
(five subjects plus nine subjects), well below 30, the Friedman’s
test and Wilcoxon signed ranks test are more appropriate. Friedman’s test overpost hoc multiple comparisons indicates that the
six algorithms differ significantly in kappa value of multiclass
classification (p = 2.7 × 10(−5) ). Additional Wilcoxon signed
ranks test for each paired method show that the MMISS is

235

significantly better than all of the other methods in terms of
mean kappa value at the 5% level.
b) Session-to-session transfer results on unseen evaluation data: The session-to-session transfer is more challenging
since the property of brain signals on training data may change
substantially from that of brain signals on the evaluation data,
which may be recorded on different day. In order to further validate the effectiveness of the MMISS algorithm, we perform the
5 × 5-fold cross validation on the data of training session, and
then, use the derived spatial and spectral filters together with the
classifiers to label the data of the unseen evaluation session. This
operation can simulate the process of session-to-session transfer.
Hence, there are 5 × 5 classification results on the evaluation
data and this operation may stabilize the variation of results and
make the session-to-session transfer results statistically comparable. The mean kappa values of the 5 × 5-fold cross-validation
results on the training dataset and unseen evaluation dataset for
dataset IIa of the BCI competition IV are shown in Table V. The
MMISS achieves the best performance on both the training data
session and the unseen evaluation session in terms of the mean
kappa value. The transfer results decrease by all the methods
and this is in accordance with the previous reports [15].
MMISS performs best on the training data session, the statistical analysis (Friedman’s test, p = 0.002) for cross validation on the training dataset shows that the comparative methods
differ significantly in the classification accuracy. However, the
Wilcoxon signed ranks test for each paired method shows that
the MMISS is only significantly better than the CSP. This result
differs from that of Table III, because there are few trials on the
training data than trials on the combined dataset. Therefore, the
performance of all the methods decrease due to the decreasing
size of dataset. The statistical analysis shows that the six filtering algorithms differ significantly in the classification accuracy
of session-to-session transfer (Friedman’s test, p = 0.002). Additional Wilcoxon signed ranks test for each paired method indicate that the MMISS performs significantly better than two of
the comparative methods in terms of classification accuracy of
session-to-session transfer. However, the challenge of sessionto-session contains the problem of inherent nonstationary across
sessions and this might not be the main focus of the proposed
method. Whether the proposed method can be used to solve the
problem needs further investigation.
V. DISCUSSION
A. Statistical Analysis of Comparative Methods
For statistical analysis, we combine the average classification accuracy of dataset IVa (five persons, right hand versus
foot) and one of the binary classifications of dataset IIa (nine
persons, right hand versus foot) together into one group of samples (14 persons). The null hypothesis is that all the competing
algorithms together with MMISS yield the same mean classification accuracy. Friedman’s test indicates that the six filtering algorithms differ significantly in classification accuracy
(p = 9.8 × 10(−5) ). Additionally, Wilcoxon signed ranks test
for each paired method and the combination of two datasets are
shown in Table IV. The results indicate that the null hypothesis

236

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

TABLE III
MEAN KAPPA VALUE OF THE 5 × 5-FOLD CROSS-VALIDATION ON COMBINED TRAINING AND TESTING DATA FOR DATASET IIA OF THE BCI COMPETITION IV
Method

CSP
(S.D.)
CSSP
(S.D.)
SWCSP
(S.D.)
ISSPL
(S.D.)
FBCSP
(S.D.)
MMISS
(S.D.)

Subjects
S1

S2

S3

S4

S5

S6

S7

S8

S9

0.630
0.074
0.713
0.054
0.691
0.063
0.711
0.048
0.657
0.045
0.721
0.049

0.181
0.086
0.251
0.079
0.208
0.082
0.269
0.053
0.156
0.065
0.285
0.074

0.743
0.054
0.788
0.045
0.785
0.063
0.848
0.024
0.789
0.034
0.851
0.038

0.382
0.052
0.444
0.061
0.395
0.052
0.408
0.066
0.381
0.060
0.449
0.059

0.160
0.066
0.297
0.070
0.204
0.062
0.153
0.063
0.309
0.080
0.316
0.051

0.231
0.067
0.267
0.069
0.241
0.080
0.276
0.085
0.239
0.061
0.285
0.072

0.607
0.064
0.687
0.045
0.647
0.057
0.729
0.057
0.689
0.037
0.751
0.056

0.723
0.049
0.731
0.055
0.717
0.052
0.727
0.038
0.690
0.062
0.746
0.046

0.740
0.042
0.732
0.049
0.745
0.044
0.744
0.053
0.738
0.059
0.750
0.051

TABLE IV
RESULTS FOR THE STATISTICAL SIGNIFICANCE TEST (WILCOXON SIGNED
RANKS TEST FOR EACH PAIRED METHOD)

p-value

CSP

CSSP

SWCSP

ISSPL

FBCSP

MMISS

1.2 × 10 ( −4 )

0.035

0.079

0.002

0.005

-

can be rejected at the α = 0.05 level of significance. This means
the MMISS algorithm is significantly better than a majority of
the other methods in terms of mean classification accuracy. The
difference between MMISS and SWCSP is marginally insignificant (p = 0.079).
Results from Tables II, III, and V suggest that the MMISS algorithm can extract the discriminative features efficiently. Under
the same comparative condition, the mean classification accuracy of MMISS outperforms all the other comparative methods.
Note that the results in Table II are slightly different from the
previous reports [11], [13]. The reason is that the number of
best individual features is set to 4 for FBCSP in their computation. Considering a fair comparison, we choose only one pair
of spatial filters for each method, which explains the slight discrepancy. The classification performance of ISSPL is closely
related to the time window and electrodes to be selected, which
were not reported in their research. Therefore, the deterioration
for subject “av” is reasonable under the parameter setting of the
current study. In our applications, deterioration of performance
happens to the OSSFN and ISSPL algorithms on some subjects.
Note that, the OSSFN is proposed to deal with the motor imagery
classification for self-paced BCI and the number of channels is
far less than 118 in their implementation. Hence, the OSSFN
is efficient in that scenario since the nonparametric estimation
of probability density function (pdf) might catch more sophisticated rhythmic activity in self-paced BCI. However, in our
implementation, we aim to discover the discriminative information by simple assumption rather than recovering the underlying
probability density of rhythmic activity, which is relatively hard
to achieve. To elaborate on this point, we draw the scatter plot
of the CSP features for one specific subject “aw” in Fig. 5.

Mean

p-value(2.7 × 10 ( −5 ) )

0.488
0.244
0.546
0.222
0.515
0.243
0.541
0.253
0.516
0.236
0.573
0.228

0.004
0.004
0.004
0.004
0.004
-

The marginal pdf, which is estimated from the nonparametric
method and parametric Gaussian distribution, respectively, is
plotted alongside the scatter plot for each class. Clearly, the
nonparametric method has the flexibility to describe a rather
complex distribution. By contrast, the Gaussian distribution, a
unimodal function, seems to sacrifice flexibility. However, it is
more robust for cue-based motor imagery if only limited samples are provided since few parameters have to be estimated.
B. Advantage of the Proposed Method
To validate whether the Gaussian distribution is reasonable
[32], we evaluate the similarity between the distribution of logpower features [see (3)] and the multivariate normal distribution.
The null hypothesis is that the distribution of log-power features
conditioned on one class is similar to the normal distribution.
Mardia’s test [33], [34] is applied to the datasets of 14 persons
(right-hand class) and the results are shown in Table VI. The
results show that the distribution of log-power features for nine
of fourteen persons is not significantly different from the normal
distribution at the α = 0.05 level of significance. Although the
underlying distribution might be more complex than the multivariate normal distribution especially for some subjects, it is
more difficult to derive the gradient of the object function (6) if
we use a more complex distribution.By relying on the Gaussian
model assumption, only the mean and variance need to be estimated. Hence, we can estimate the parameters more efficiently
with lower variance compared to nonparametric estimation [35].
Consequently, the MMISS algorithm outperforms the OSSFN
greatly. Similarly, the ISSPL, which outputs the weight coefficients of the spectrum by a classifier, might be overfitting when
the number of channels is large and separability of the subject’s
data is low, e.g., subject “av,” The performance of all the methods
could be further improved by choosing several pairs of spatial
filters and spectral filters [4] or by selecting an optimal channel
configuration [36]. We find that the average classification accuracy of subjects “aa” and “aw” achieve to be 91.2 ± 4.9 and
97.5 ± 3.2 by the MMISS algorithm if only part of the channels are used while the constraint of one pair of spatial filters
and one spectral filter is maintained. However, how to tune the

MENG et al.: SIMULTANEOUSLY OPTIMIZING SPATIAL SPECTRAL FEATURES BASED ON MUTUAL INFORMATION FOR EEG CLASSIFICATION

237

TABLE V
MEAN KAPPA VALUE OF THE 5 × 5-FOLD CROSS-VALIDATION RESULTS ON THE TRAINING DATASET AND (FILTERS AND CLASSIFIERS DERIVED IN THE TRAINING
SESSION ARE DIRECTLY APPLIED TO) UNSEEN EVALUATION DATASET FOR DATASET IIA OF THE BCI COMPETITION IV
Method

CSP
(S.D.)
CSSP
(S.D.)
SWCSP
(S.D.)
ISSPL
(S.D.)
FBCSP
(S.D.)
MMISS
(S.D.)

Subjects(training session)
S1

S2

S3

S4

S5

S6

S7

S8

S9

0.602
0.077
0.661
0.071
0.678
0.062
0.706
0.074
0.672
0.085
0.658
0.065

0.265
0.095
0.300
0.092
0.273
0.096
0.244
0.093
0.198
0.087
0.282
0.084

0.713
0.067
0.775
0.064
0.785
0.058
0.817
0.060
0.759
0.058
0.826
0.050

0.339
0.083
0.398
0.084
0.409
0.069
0.336
0.080
0.200
0.076
0.373
0.078

0.128
0.085
0.332
0.069
0.209
0.084
0.151
0.087
0.440
0.094
0.470
0.089

0.142
0.118
0.218
0.123
0.169
0.091
0.204
0.084
0.131
0.088
0.226
0.109

0.531
0.087
0.679
0.083
0.571
0.071
0.635
0.078
0.724
0.066
0.658
0.074

0.716
0.083
0.747
0.066
0.740
0.062
0.691
0.077
0.678
0.073
0.713
0.083

0.646
0.090
0.632
0.078
0.742
0.077
0.713
0.074
0.717
0.072
0.748
0.066

Method

CSP
(S.D.)
CSSP
(S.D.)
SWCSP
(S.D.)
ISSPL
(S.D.)
FBCSP
(S.D.)
MMISS
(S.D.)

Subjects(unseen evaluation session)
S1

S2

S3

S4

S5

S6

S7

S8

S9

0.596
0.038
0.628
0.039
0.677
0.034
0.690
0.015
0.578
0.030
0.656
0.040

0.194
0.034
0.211
0.033
0.196
0.031
0.219
0.039
0.140
0.049
0.257
0.025

0.665
0.015
0.698
0.016
0.701
0.022
0.744
0.022
0.685
0.026
0.781
0.037

0.432
0.033
0.451
0.048
0.414
0.033
0.431
0.033
0.308
0.054
0.407
0.039

0.047
0.036
0.073
0.037
0.136
0.043
0.084
0.032
0.228
0.024
0.295
0.038

0.153
0.042
0.168
0.056
0.180
0.051
0.177
0.055
0.171
0.049
0.195
0.055

0.577
0.038
0.620
0.030
0.637
0.043
0.628
0.028
0.509
0.050
0.662
0.032

0.610
0.031
0.642
0.025
0.599
0.035
0.602
0.040
0.558
0.037
0.584
0.040

0.548
0.019
0.553
0.030
0.597
0.043
0.599
0.031
0.542
0.075
0.608
0.049

parameters (such as the number of spatial and/or spectral filters, the length of time window and the channel configuration)
with nested cross validation or other methods to achieve the best
results is not the research focus of this paper.
Previous research suggests that CSP is a decomposition technique especially powerful for motor imagery-based feature extraction rather than a direct classification technique. A postprocessing classifier such as linear discriminant analysis or SVM is
necessary to get the classification results. Usually some spatial
patterns derived by CSP are neurophysiologically interpretable.
However, these spatial filters derived by CSP are not always
optimal for the classification problem [37], [38]. Sometimes the
eigenvectors corresponding to the extreme eigenvalue spectrum
will concentrate on the strong power, which might be contaminated by artifacts [see the spatial filters in Fig. 1(a)]. A recent
paper discusses the relationship between information theoretic
feature extraction and the CSP algorithm [19]. However, the
mutual information has only been used as a criterion to select
spatial filters in their implementation. We propose to use the mutual information as an unique objective for feature extraction.
The optimization of spatial and spectral filters is achieved by
maximizing the mutual information, which is a function of spatial and spectral filters. The results obtained by MMISS suggest
that the mutual information might be an alternative objective
for extracting spatial and spectral features of the ERD/ERS
activity. It should be noted that the estimation of mutual information relies on the assumption of Gaussian distribution of

Mean

p-value(0.022)

0.454
0.241
0.527
0.217
0.509
0.245
0.500
0.259
0.502
0.259
0.550
0.220

0.008
0.734
0.25
0.098
0.055
-

mean

p-value(0.002)

0.425
0.221
0.449
0.227
0.460
0.222
0.464
0.235
0.413
0.196
0.494
0.202

0.020
0.203
0.164
0.250
0.004
-

Fig. 5. Scatter plot and marginal pdf of CSP features for two classes of motor
imagination from one specific subject “aw.” Note that the CSP features are
log transformed values. The marginal pdf is estimated from (a) nonparametric
(kernel density estimation) method and (b) parametric Gaussian distribution,
respectively.

spatial spectral features. This assumption, however, is not robust
enough to outliers, since the EEG data contains outliers sometimes [4]. Whether the more robust distribution like Student’s
t-distribution will perform better in this case is worthy of future
investigation.
C. Limitations
In the current study, we propose to optimize the spatial and
spectral filters simultaneously in a unified mutual informationbased framework. The optimizing algorithm is realized by
solving the spatial filters and spectral filters separately and

238

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

TABLE VI
STATISTICAL SIGNIFICANCE TEST (P-VALUE) OF MARDIA’S MULTIVARIATE
SKEWNESS AND KURTOSIS FOR THE MOST SIGNIFICANT LOG-POWER
FEATURES (RIGHT-HAND CLASS)
Subject

aa

al

av

aw

ay

S1

S2

skewness
kurtosis
Subject
skewness
kurtosis

0.00
0.01
S3
0.10
0.09

0.35
0.36
S4
0.13
0.64

0.00
0.33
S5
0.48
0.40

0.31
0.05
S6
0.08
0.30

0.00
0.00
S7
0.01
0.85

0.10
0.41
S8
0.52
0.08

0.00
0.05
S9
0.87
0.37

MMISS algorithm achieves classification accuracy of 90.7% on
average over five subjects on the dataset IVa of BCI competition
III and yields better mean accuracies for multiclass classification over nine subjects on the dataset IIa of BCI competition
IV. The classification results together with the statistical significance tests show that the proposed algorithm perform well in
classification for multiclass and session-to-session transfer and
these demonstrates the effectiveness of the proposed method as
compared with other algorithms.
APPENDIX A
SIMULTANEOUS OPTIMIZATION OF ALL SPATIAL FILTERS

iteratively. Due to the mutual information-based cost function is
usually complex and nonconvex, it is difficult to find the global
optimum by the available optimization methods. Our algorithm
proceed until I(A, Ω) attains its local maximum. We have to
point out the following facts. First, it may happen that the convergence of cost function is slow by the gradient search method
and this is closely related to the geometric property of designed
cost function and the EEG dataset. In this situation, advanced
gradient algorithms could help to improve the efficiency. The
maximum number of iterations can be used alternatively in this
situation and this is a common step to guarantee the algorithm
stops appropriately. Second, the initial point is important to the
optimization algorithm. In the proposed solution, we suggest the
CSP-learned spatial filters to be a good starting point. However,
this is difficult to prove in theory. Some different initial values
can usually be tried to get a better local maximum. Nevertheless,
our experiments on the BCI competition datasets show that the
proposed solution usually gives good results. The other algorithms proposed in the literature may also provide alternative
starting point for the MMISS. Note that, the results reported in
Tables III and V are lower than the winner of dataset IIa on
BCI competition IV. Because we use a homogenous parameter
setting for all the methods such as the same time window, the
same number of spatial filters, which are not optimized for each
method. Additionally, we only calculated the classification accuracy during the time interval of [0.5,2.5]s rather than picked
up the maximum kappa value from the entire continuous output
of classification accuracy from the onset of the fixation cross to
the end of motor imagery in the competition. These cause the
discrepancy between our results and the results published on the
website of BCI competition IV. The statistical results have to
be interpreted with care in the study due to the discrepancy and
the limitations .
VI. CONCLUSION
In this study, we have presented the MMISS algorithm for
optimizing spatial and spectral filters simultaneously. In the proposed framework, the learning of spatial and spectral filters are
formulated as a maximizing mutual information problem. The
alternative and iterative optimization approach is adopted to
solve the problem. Additionally, the subspace gradient learning
approach, in which spatial and spectral filters are parameterized
by lower dimensional vectors, is applied to make the solution
robust and efficient. Under the same comparative condition, the

A joint vector, which is formed by concatenating all the spatial
filters together, is considered in order to optimize all the spatial
filters simultaneously. That is
	 = [w1T , . . . , wlT , . . . , wnT l ]T .
w

(25)

Due to the assumption of diagonal covariance matrix for each
class ω, each element ai,l of feature vector ai is only a function
of wl . Then, the derivative of mutual information I(A, Ω) with
	 can be derived by concatenating
respect to the joint vector w
the derivatives with respect to each single spatial filter wl (i.e.,
w l I(A, Ω)). Therefore
w	 I(A, Ω) = [w 1 I(A, Ω)T , . . . , w n l I(A, Ω)T ]T .

(26)

The multiple spatial filters for multichannel EEG signals are
high-dimensional vectors. However, practical issues arise for
gradient-based optimization in the high-dimensional space. To
address the problem, we use a similar trick to Zhang et al. [16].
The subspace optimization approach is employed to reduce the
dimensionality of optimization problem.
Let U be a nu -dimensional (nu 
 M ) subspace, which is linearly spanned by the M -dimensional column vectors. Denote
U = [u1 , . . . , uk , . . . , un u ] ∈ RM ×n u , where uk ∈ RM ×1 is
the kth basis vector of U . Hence, any spatial filter wl in the
subspace U can be expressed by
wl =

nu



mlk uk = U ml

(27)

k =1

where ml is a coefficient vector that uniquely determines wl
with respect to U .
In the subspace U , optimization of the spatial filter wl is
equivalent to optimization of the coefficient vector ml . Then,
	
simultaneous optimization of the concatenated spatial filters w
is reformulated as optimization of the concatenated coefficient
vectors
	 = [mT1 , . . . , mTl , . . . , mTn l ]T .
m

(28)

Now consider the partial derivatives of I(A, Ω) with respect
to ml . Substitute (27) into (8), then the element ai,l of feature
vector ai is


1 T 	
wl Rxi wl
ai,l = log
N


1
T 	
(U ml ) Rxi (U ml ) .
(29)
= log
N

MENG et al.: SIMULTANEOUSLY OPTIMIZING SPATIAL SPECTRAL FEATURES BASED ON MUTUAL INFORMATION FOR EEG CLASSIFICATION

Similar to (13), differentiating I(A, Ω) with respect to ml gives


m l I(A, Ω) = m l H(A) −
m l H(A | ω)P (ω). (30)
ω ∈Ω

Here, the derivative of H(A | ω) with respect to ml is given by
m l H(A | ω) =

nω
1 2 

(ak ,l − aω ,l )
2Ψl,l nω
k =1
⎛
⎞
nω


2Rxk
2Rxj ⎠
1
× ⎝ ak , l −
U ml . (31)
Ne
nω j =1 N ea j , l

The derivation of m l H(A) is performed similarly and omitted here. Then, we have m
	 I(A, Ω) by concatenating all the
derivatives of m l I(A, Ω), l = 1, . . . , nl .
The remaining problem is how to construct the subspace U .
This is an important problem for practical computation, however, we do not study the initialization problem in this paper.
We simply use the spatial filters obtained by the CSP algorithm
as the subspace basis vectors.
APPENDIX B
SUBSPACE GRADIENT-BASED LEARNING
FOR SPECTRAL FILTERS
For a specific dataset, the dimensionality of a spectral filter is determined by the sampling rate and the length of the
time window. To reduce the dimension of the spectral filter, a similar subspace optimization technique is used. Let
V be a nv -dimensional (nv < N ) subspace, which is linearly spanned by the N -dimensional column vectors. Denote
V = [v1 , . . . , vk , . . . , vn v ] ∈ RN ×n v , where vk ∈ RN ×1 is the
kth basis vector of V . Hence, any spectral filter b in the subspace
V can be expressed by
b=

nv



d k vk = V d

(32)

k =1

where d is a coefficient vector that uniquely determines b with
respect to V .
Similarly, in the subspace V , optimization of the spatial filter
b is equivalent to optimization of the coefficient vector d. The
derivation of d I(A, Ω) is straightforward according to (21)
and is omitted here. In this study, we use a simple method
to construct the subspace V , i.e., several spectral weights in
consecutive frequency bins are set to be the same value; hence,
the spectrum in the neighborhood are flat. This simple operation
degrades the dramatic changes of spectral coefficients.
ACKNOWLEDGMENT
The authors would like to thank the Berlin BCI group for
sharing their datasets and P. Shull for help suggestions of writing
the manuscript. They also like to thank H. Higashi from the
Tokyo University of Agriculture and Technology for helpful
discussion of the DFBCSP method, and W. Wu from Tsinghua
University for helpful discussion of the ISSPL method.

239

REFERENCES
[1] J. Wolpaw, N. Birbaumer, D. McFarland, G. Pfurtscheller, and T. Vaughan,
“Brain–computer interfaces for communication and control,” Clinical
Neurophysiol., vol. 113, no. 6, pp. 767–791, 2002.
[2] G. Pfurtscheller, C. Neuper, D. Flotzinger, and M. Pregenzer, “EEG-based
discrimination between imagination of right and left hand movement,”
Electroencephalography Clinical Neurophysiol., vol. 103, no. 6, pp. 642–
651, 1997.
[3] G. Pfurtscheller and F. Lopes da Silva, “Event-related EEG/MEG synchronization and desynchronization: Basic principles,” Clinical Neurophysiol.,
vol. 110, no. 11, pp. 1842–1857, 1999.
[4] B. Blankertz, R. Tomioka, S. Lemm, M. Kawanabe, and K. R. Müller,
“Optimizing spatial filters for robust EEG single-trial analysis,” IEEE
Signal Process. Mag., vol. 25, no. 1, pp. 41–56, 2008.
[5] J. Müller-Gerking, G. Pfurtscheller, and H. Flyvbjerg, “Designing optimal
spatial filters for single-trial EEG classification in a movement task,”
Clinical neurophysiology, vol. 110, no. 5, pp. 787–798, 1999.
[6] H. Ramoser, J. Müller-Gerking, and G. Pfurtscheller, “Optimal spatial
filtering of single trial EEG during imagined handmovement,” IEEE Trans.
Rehabil. Eng., vol. 8, no. 4, pp. 441–446, Dec. 2000.
[7] S. Lemm, B. Blankertz, G. Curio, and K. R. Müller, “Spatio-spectral filters
for improving the classification of single trial EEG,” IEEE Trans. Biomed.
Eng., vol. 52, no. 9, pp. 1541–1548, Sep. 2005.
[8] G. Dornhege, B. Blankertz, M. Krauledat, F. Losch, G. Curio, and
K. R. Müller, “Combined optimization of spatial and temporal filters
for improving brain-computer interfacing,” IEEE Trans. Biomed. Eng.,
vol. 53, no. 11, pp. 2274–2281, Nov. 2006.
[9] H. Higashi and T. Tanaka, “Simultaneous design of fir filter banks and
spatial patterns for EEG signal classification,” IEEE Trans. Biomed. Eng.,
vol. 60, no. 4, pp. 1100–1110, Apr. 2013.
[10] R. Tomioka, G. Dornhege, G. Nolte, B. Blankertz, K. Aihara, and K. R.
Müller, “Spectrally weighted common spatial pattern algorithm for single
trial eeg classification,” Dept. Math. Eng., Univ. Tokyo, Tokyo, Japan,
Tech. Rep. 40, 2006.
[11] W. Wu, X. Gao, B. Hong, and S. Gao, “Classifying single-trial EEG
during motor imagery by iterative spatio-spectral patterns learning (ISSPL),” IEEE Trans. Bio-med. Eng., vol. 55, no. 6, pp. 1733–1743,
Jun. 2008.
[12] Q. Novi, C. Guan, T. Dat, and P. Xue, “Sub-band common spatial pattern
(SBCSP) for brain-computer interface,” in Proc. 3rd Int. IEEE/EMBS
Conf. Neural Eng., 2007, pp. 204–207.
[13] K. K. Ang, Z. Chin, H. Zhang, and C. Guan, “Filter bank common spatial
pattern (FBCSP) in brain-computer interface,” in Proc. IEEE Int. Joint
Conf. Neural Netw., Jun. 2008, pp. 2390–2397.
[14] K. K. Ang, Z.Y. Chin, H. Zhang, and C. Guan, “Mutual information-based
selection of optimal spatial-temporal patterns for single-trial EEG-based
BCIs,” Pattern Recog., vol. 45, no. 6, pp. 2137–2144, 2012.
[15] K. K. Ang, Z. Y. Chin, C. Wang, C. Guan, and H. Zhang, “Filter bank
common spatial pattern algorithm on BCI competition IV datasets 2a and
2b,” Frontiers Neurosci., vol. 6, pp. 1–9, 2012.
[16] H. Zhang, Z. Chin, K. K. Ang, C. Guan, and C. Wang, “Optimum spatiospectral filtering network for brain-computer interface,” IEEE Trans. Neural Netw., vol. 22, no. 1, pp. 52–63, Jan. 2011.
[17] H. Suk and S. Lee, “A novel Bayesian framework for discriminative feature
extraction in brain-computer interfaces,” IEEE Trans. Pattern Anal. Mach.
Intell., vol. 35, no. 2, pp. 286–299, Feb. 2013.
[18] P. S. Hammon and V. R. de Sa, “Preprocessing and meta-classification for
brain-computer interfaces,” IEEE Trans. Biomed. Eng., vol. 54, no. 3, pp.
518–525, Mar. 2007.
[19] M. Grosse-Wentrup and M. Buss, “Multiclass common spatial patterns
and information theoretic feature extraction,” IEEE Trans. Biomed. Eng.,
vol. 55, no. 8, pp. 1991–2000, Aug. 2008.
[20] H. Wang, “Multiclass filters by a weighted pairwise criterion for EEG
single-trial classification,” IEEE Trans. Biomed. Eng., vol. 58, no. 5,
pp. 1412–1420, May 2011.
[21] S. Petridis and S. J. Perantonis, “On the relation between discriminant
analysis and mutual information for supervised linear feature extraction,”
Pattern Recog., vol. 37, no. 5, pp. 857–874, 2004.
[22] G. Strang and T. Nguyen, Wavelets and Filter Banks. Cambridge, MA,
USA: Cambridge Univ. Press, 1996.
[23] T. M. Cover and J. A. Thomas, Elements of Information Theory. New
York, NY, USA: Wiley-interscience, 2006.
[24] J. M. Leiva-Murillo and A. Artes-Rodriguez, “Maximization of mutual
information for supervised linear feature extraction,” IEEE Trans. Neural
Netw., vol. 18, no. 5, pp. 1433–1441, Sep. 2007.

240

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 1, JANUARY 2015

[25] D. P. Bertsekas, Nonlinear Programming. Belmont, MA, USA: Athena
Scientific, 1999.
[26] P. Viola and W. M. Wells III, “Alignment by maximization of mutual
information,” Int. J. Comput. Vis., vol. 24, no. 2, pp. 137–154, 1997.
[27] D. Model and M. Zibulevsky, “Learning subject-specific spatial and temporal filters for single-trial EEG classification,” NeuroImage, vol. 32,
no. 4, pp. 1631–1641, 2006.
[28] B. Blankertz, K. R. Müller, D. J. Krusienski, G. Schalk, J. R. Wolpaw, A. Schlogl, G. Pfurtscheller, J. R. Millan, M. Schroder, and N.
Birbaumer, “The BCI competition III: Validating alternative approaches
to actual BCI problems,” IEEE Trans. Neural Syst. Rehabil. Eng.,
vol. 14, no. 2, pp. 153–159, Jun. 2006.
[29] C.-C. Chang and C.-J. Lin, “LIBSVM: A library for support vector machines,” ACM Trans. Intell. Syst. Technol., vol. 2, pp. 27-1–27-27, 2011.
[30] F. Lotte and C. Guan, “Regularizing common spatial patterns to improve
BCI designs: Unified theory and new algorithms,” IEEE Trans. Biomed.
Eng., vol. 58, no. 2, pp. 355–362, Feb. 2011.
[31] J. Demšar, “Statistical comparisons of classifiers over multiple data sets,”
J. Mach. Learning Res., vol. 7, pp. 1–30, 2006.
[32] S. Park, E. Serpedin, and K. Qaraqe, “Gaussian assumption: The least
favorable but the most useful [lecture notes],” IEEE Signal Process. Mag.,
vol. 30, no. 3, pp. 183–186, May 2013.

[33] K. V. Mardia, “Measures of multivariate skewness and kurtosis with applications,” Biometrika, vol. 57, no. 3, pp. 519–530, 1970.
[34] A. Trujillo-Ortiz and R. Hernandez-Walls, (2003). Mskekur: Mardia’s multivariate skewness and kurtosis coefficients and its hypotheses testing. A MATLAB file. Available from MATLAB Central File Exchange. [Online]. Available: URL: http://www. mathworks.
com/matlabcentral/fileexchange
[35] T. Hastie, R. Tibshirani, and J. J. H. Friedman, The Elements of Statistical
Learning. New York, NY, USA: Springer, 2001, vol. 1.
[36] J. Meng, G. Huang, D. Zhang, and X. Zhu, “Optimizing spatial spectral
patterns jointly with channel configuration for brain-computer interface,”
Neurocomputing, vol. 104, pp. 115–126, 2013.
[37] R. Tomioka, K. Aihara, and K. R. Müller, “Logistic regression for single
trial EEG classification,” Advances Neural Inf. Process. Syst., vol. 19,
pp. 1377–1384, 2007.
[38] R. Tomioka, and K.-R. Müller, “A regularized discriminative framework
for EEG analysis with application to brain–computer interface,” Neuroimage, vol. 49, no. 1, pp. 415–432, 2010.

Authors’ photographs and biographies not available at the time of publication.

