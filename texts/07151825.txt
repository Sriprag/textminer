260

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 2, FEBRUARY 2016

Tracked “Pick-Up” Ultrasound for Robot-Assisted
Minimally Invasive Surgery
Caitlin Schneider∗ , Student Member, IEEE, Christopher Nguan, Member, IEEE, Robert Rohling, Member, IEEE,
and Septimiu Salcudean, Fellow, IEEE

Abstract—Goal: We present a novel “pick-up” ultrasound
transducer for intraabdominal robot-assisted minimally invasive
surgery. Such a “pick-up” ultrasound transducer is inserted
through an abdominal incision at the beginning of the procedure
and remains in the abdominal cavity throughout, eliminating the
need for a dedicated port or a patient bedside surgical assistant.
The transducer has a handle that can be grasped in a repeatable
manner using a da Vinci Prograsp tool, allowing the transducer
to be accurately manipulated by the surgeon using the da Vinci
Robot. This is one way to enable 3-D tracking of the transducer,
and, thus, mapping of the vasculature. The 3-D vascular images can
be used to register preoperative CT to intraoperative camera images. Methods: To demonstrate the feasibility of the approach, we
use an ultrasound vessel phantom to register a CT surface model to
extracted ultrasound vessel models. The 3-D vascular phantom images are generated by segmenting B-mode images and tracking the
pick-up ultrasound transducer with the da Vinci kinematics, internal electromagnetic sensor, or visible fiducials suitable for camera
tracking. Results: Reconstruction results using da Vinci kinematics
for tracking give a target registration error of 5.4 ± 1.7 mm.
Index Terms—Intraoperative ultrasound, surgical robotics, vessel registration.

I. INTRODUCTION
INIMALLY invasive laparoscopic surgery (MIS) has become the first line surgical approach for many abdominal
operations. Benefits for the patient include lower morbidity and
faster recovery time. However, MIS surgery is more technically
challenging for the surgeon, and this has historically limited the
widespread adoption of laparoscopic approaches for complex
surgical procedures such as partial nephrectomy, during which
the segmental removal of a tumor from a kidney is performed.
This operation is compounded by pressures, including time constraints, restricted visualization, and elevated risks of bleeding.
During partial nephrectomy, the main renal artery and main
renal vein must be located before the resection of the tumor can
begin. Caution must be used during the initial dissection because
the surgeon must work in close proximity to the patient’s aorta,
vena cava, and other critical high-flow vessels. The renal arteries
carry approximately 25% of cardiac output or about 1.5 L/min.

M

Manuscript received March 25, 2015; revised June 11, 2015; accepted June
27, 2015. Date of publication July 7, 2015; date of current version January 16,
2016. Asterisk indicates corresponding author.
* C. Schneider is with the Electrical and Computer Engineering Department,
University of British Columbia, Vancouver, BC V6T 1Z4, Canada (e-mail:
caitlins@ece.ubc.ca).
C. Nguan, R. Rohling, and S. Salcudean are with the Univeristy of British
Columbia.
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2015.2453173

Knowledge of the vessels’ location during the procedure would
assist the surgeon in conducting a safer and more efficient dissection. Our center performs about 150 open or laparoscopic
partial nephrectomy procedures per year, and five to ten robotic
procedures, and we expect that a surgical navigational adjunct,
as proposed here, will increase surgeon confidence, improve
patient safety, and decrease dissection time required for this
operation.
Robotic technology, such as the da Vinci surgical system
(Intuitive Surgical Inc., Sunnyvale, CA), is increasingly used in
a variety of surgical procedures. The da Vinci surgical system
has highly dexterous tools and a high-quality stereo endoscopic
camera, which combine to make laparoscopic surgery simpler,
easier, and more accessible to surgeons. The da Vinci robot
allows surgeons to use small laparoscopic incisions and still
work in a manner that is similar to open surgery. Due to its
stereoscopic display within the surgeon’s console, the da Vinci
system provides a platform to include 3-D image guidance, such
as from ultrasound imaging.
Traditional laparoscopic intraoperative ultrasound is currently used for a variety of procedures, including the resection
of gallbladders [1], liver cancer [2], and kidney cancer [3].
Intraoperative ultrasound can provide high-quality real-time
intraoperative imaging for the assessment of tumour margins,
vessel localization, and locating tumour resection planes.
Våpenstad et al. present a survey on the current use of
laparoscopic ultrasound [4].
Although traditional laparoscopic ultrasound instrumentation
is a valuable imaging tool in many types of surgery manoeuvrability, and, thus, imaging ability is limited. Furthermore,
during robotic procedures, laparoscopic ultrasound probes are
typically controlled by the patient bedside surgical assistant
instead of the operating surgeon. Additionally, the ultrasound
instrument requires a dedicated laparoscopic port, meaning that
another instrument must be removed from the surgical field
and the operation must halt while scanning is taking place.
It is well established that ultrasound is highly user-dependent
modality in two main ways. First, the quality of the ultrasound
image views depends on the experience of the user. Second,
only some users have the ability to make 3-D connections
between the images and the actual anatomy. Manipulating the
transducer allows the surgeon’s natural hand-eye coordination
to aid in the interpretation of the 3-D anatomy from a series of
2-D cross-sectional images.
In order to provide the operating surgeon with control of the
transducer and to integrate intraoperative ultrasound into robotic
surgery, an ultrasound transducer that is controlled directly from
the da Vinci surgeon’s console was proposed [5]. Later, another

0018-9294 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

SCHNEIDER et al.: TRACKED “PICK-UP” ULTRASOUND FOR ROBOT-ASSISTED MINIMALLY INVASIVE SURGERY

transducer was designed and modeled after a typical da Vinci
5-mm tool and had greater mobility inside the patient [6]. However, both of these combined ultrasound/da Vinci tools still require a dedicated port or da Vinci tool changes, and this version
of the 5-mm da Vinci tool is more limited in its range orientation
than a typical 8-mm da Vinci tool.
The first “pick-up” style probe was developed for cardiac
procedures. A 13-MHz Aloka (Hitachi Aloka Medical, Wallingford, CT, USA) minitransducer (15 × 9×6 mm) has been used
for characterization of the coronary arteries during thoracic laparoscopic surgery [7], [8]. This transducer was outfitted with
a small fin that allowed the da Vinci needle drivers to grasp and
manoeuvre the transducer.
Two commercial products have recently been introduced, one
by Aloka (Wallingford, CT, USA), and one by Analogic Ultrasound (named the ProArt) (Peabody, MA, USA). Both these
ultrasound transducers are designed with a fin on the ventral
proximal surface that fits the da Vinci Prograsp tool (model
420 093). The fin is placed in such a way that the long axis
of the transducer and the jaws of the tool are parallel. They fit
through a standard sized trocar and use the TilePro display in
the da Vinci S and Si. Both transducers are high frequency, and
thus, have high resolution with relatively low penetration depth.
The Aloka model is a linear array transducer, and the ProArt
uses a curved array for wider visibility.
The grasping fin designs of the three transducers mentioned
above do not enable a repeatable stable grasp by a da Vinci
tool, such as the ProGrasp forceps. The ProGrasp forceps is a
very commonly used dissection tool, and its slotted shape is
conducive to holding onto an ultrasound transducer. While the
fin design of [7], [8] makes it easy to grasp the device, the
location of the grasp is not well defined. A stable repeatable
grasp is needed for 3-D tissue reconstruction or localization
with respect to the da Vinci coordinate system.
An important application of ultrasound reconstruction and
localization is mapping of the vasculature. Localized vessels
can be used to define surgical planes and to register intraoperative images to preoperative scans. Vessels have been previously used to register intraoperative data to preoperative CT
and magnetic resonance imaging scans [9]–[11]. For example,
the cortical vessels of the brain were used to orient the surgeon
and account for brain deformation during image-guided surgery
through video tracking of the vessels [9] or tracked ultrasound
[11]. Image guidance during liver surgery is another application
in which vessels were used for registration [12], [13]. The vessels of the liver are prominent features in surgical navigation for
tumour resection. In addition, in complicated structures, such
as the liver, hierarchical methods of vessel registration were
also implemented [14]. Previous work on vessel extraction and
registration have involved voxel-based registration [13], imageto-model registration [15], model-to-model registration [11],
and the integration of landmark and intensity information [12].
Model-to-model registration methods typically use a modified
version of the iterative closest point algorithm [16] applied to the
vessel centerlines. Other methods use Doppler images to create
a model from the US images with region growing segmentation
[17] or color-based segmentation [11].

261

Fig. 1. Example ultrasound images created with the intraoperative “pick-up”
transducer of the carotid artery and vein. Left: B-mode image. Right: Doppler
image of the arteries after bifurcation.

In this paper, we describe a novel custom-designed intraoperative “pick-up” ultrasound transducer. We show that the device
offers greater flexibility and integration potential than other intraoperative ultrasound transducers. We demonstrate that it can
create 3-D ultrasound volumes via transducer tracking methods,
and that the volumes can be used for preoperative imaging registration. A preliminary study of the “pick- up” transducer was
presented using a one tracking method [18]. In this paper, we
study the accuracy of each of the three tracking methods used
with this novel transducer and the potential for vessel reconstruction with each tracking method.
In particular, for registration, the 2-D contours are combined
to create a 3-D model of the vessels and branches. The surface
representations which are extracted from both the ultrasound
images and preoperative models can be registered. Due to the
potential advantages that the transducer could bring to robotassisted partial nephrectomy, this is the primary application discussed in this paper.
II. METHODS
A. Intraoperative “Pick-Up” Transducer for
Robotic Procedures
In order to integrate intraoperative ultrasound into robotic
surgery and take full advantage of the dexterity of the da Vinci
tools, an intraoperative ultrasound transducer for abdominal
surgery was designed that can be easily picked up and manoeuvred by the da Vinci ProGrasp forceps.
The transducer:
1) is small enough to be manoeuvred inside the patient;
2) has a small enough diameter to fit through a surgical incision;
3) has a consistent and self-aligning interface with the da
Vinci grasper;
4) has no sharp or breakable components;
5) can be tracked via multiple modalities; and
6) can be sterilized using standard methods.
The transducer is made of 128 elements spaced over an imaging face of 28 mm and has a center frequency of 10 MHz.
These are similar characteristics to other commercially available intraoperative transducers, which provide high-resolution
imaging to a depth of 4 to 6 cm. Pin connections are currently
compatible with Ultrasonix ultrasound machines (Ultrasonix
Medical Corp., Richmond, Canada). Examples of the B-mode
and Doppler images are displayed in Fig. 1.

262

Fig. 2.

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 2, FEBRUARY 2016

Rendered images of the da Vinci interface.

Unique to this transducer, and different from the commercially available transducers, is the specially designed interface
between the transducer and the da Vinci ProGrasp forceps. This
metal interface was designed such that it forms a locking-type
grasp with the ProGrasp tool (see Fig. 2). A groove (see Fig. 2),
shown in blue (A), was built to match the width of the ProGrasp. A small pin, shown in red (B), was designed to catch in
the end of the tool slot and prevent the tool from sliding off.
The walls of the groove are angled, shown in green (C, D), to
increase the capture range. One wall is slanted to the floor of
the groove, while the other ends just short, shown in yellow
(E). The solid wall helps us to constrain the motion between
the transducer and the tool, while the fully slanted wall prevents
the tool from ever becoming jammed into the groove. The angle
between the two sides of the groove matches that of the ProGrasp when the tool is completely closed on to the metal walls.
This allows for a fixed transformation between the da Vinci
tool and the transducer, which in turn transfers all the degrees
of freedom and range of motion available to the da Vinci tool
to the transducer. The jointed wrist of the da Vinci and direct
connection to the transducer makes manipulation easier than
traditional hand-held laparoscopic transducers [19]. The transducer was manufactured by Vermon (Vermon, Tours, France)
and is approved for STERRAD (ASP, Irvine, CA, USA) sterilization methods that are commonly used in hospitals to sterilize
ultrasound transducers.
Another unique aspect of this transducer is the inclusion of
an electromagnetic (EM) sensor inside the body of the transducer (see Fig. 3). A Model 180 (Ascension, Milton, VT, USA)
six degree of freedom sensor is used and compatible with the
software of the Ultrasonix Ultrasound GPS system.
As an alternative, a flat checkerboard for visual tracking can
be placed on the flat section of the transducer, which is approximately 24 mm × 10 mm. An example of this checkerboard
is shown in Fig. 3, and can be used, as described later, for 3-D
tracking with a stereo camera. The checkerboard is surgical identification tape (Key Surgical Inc., Eden Prairie, MN, USA) that
is approved for human use and repeated sterilization cycles [20].
B. Tracking
Localization and tracking of the ultrasound transducer can,
therefore, be achieved using several different methods: robot
kinematics [6], EM tracking [21], [22], and optical tracking
[23]. In addition, it is possible to create 3-D volumes without any

Fig. 3. Top: diagram showing the cross section of the “pick-up” transducer,
and the location of the EM sensor and crystal stack. Bottom: a photograph of
the ultrasound transducer, with checkerboards used for camera tracking.

external tracking equipment, using such techniques as speckle
decorrelation [24], [25].
For the “pick-up” transducer described in this paper, three
methods are used to track the transducer while inside the body:
robotic kinematics, embedded EM tracker, and stereoscopic vision. For this transducer, all of these methods minimize the
lever arm effects, which can multiply error in calibration and
tracking because the tracked sensor/element is very close to the
ultrasound linear array and associated imaging plane.
Previous literature states that the expected accuracy of the
da Vinci kinematics is approximately 1 mm, when tracking the
activated joints of a single da Vinci arm [26]. In this situation,
that accuracy compares favourably to other tracking techniques.
The transducer can be grasped in a repeatable manner so that
the transformation from robot to tool is fixed and known a
priori. This is important because it would be impractical to do
a calibration to calculate the transformation during surgery.
To test the repeatability of grasping and to perform the optical
tracking ultrasound calibration, a wide-baseline stereo camera
was used. A checkerboard with 3.175-mm squares was placed
on the transducer and instrument jaws and was tracked by the
camera. The checkerboard was tracked using the wide-baseline

SCHNEIDER et al.: TRACKED “PICK-UP” ULTRASOUND FOR ROBOT-ASSISTED MINIMALLY INVASIVE SURGERY

camera, which has a 75-mm baseline and consists of two Flea2
cameras (Point Grey Research, Richmond, Canada), each with
a resolution of 1280 × 960 [27]. The intrinsic and extrinsic
parameters of the wide-baseline camera and the location of the
checkerboard on the tools within the camera frame were found
using the Caltech camera calibration toolbox [28].
Some studies claim that EM sensors have an accuracy of about
1% of the workspace [29], which, in this case, is approximately
0.5 mm. We expect larger errors due to the large metal objects
in the operating room (OR). In particular, the operating table
and the da Vinci interfere with the EM sensor readings. The
six degrees of freedom EM sensor is located within the body
of the transducer as seen in Fig. 3. It is close to the center
of the transducer to minimize lever arm effects and maximize
tracking accuracy with respect to the image plane. This sensor
also does not interfere with the sterilization process as the sensor
is approved for use with the STERRAD system as well.
Another approach is to optically track the ultrasound transducer using the laparoscopic camera image(s). This has been
done previously with a monolaparoscope tracking, a checkerboard pattern on an ultrasound transducer to create an augmented reality laparoscopic ultrasound system [23]. We used
a stereo laparoscope and larger checkerboard pattern to do the
same type of tracking. Specifically, we used a wide-angle NTSC
da Vinci stereo laparoscope from the da Vinci surgical system (Standard). It has a baseline of 5 mm and a resolution of
720 × 486 pixels. The 6 × 2 checkerboard pattern on the pick-up
ultrasound transducer had 3.175-mm squares. Camera calibration was performed using the Caltech camera calibration toolbox
[28]. The checkerboard tracking and stereo triangulation functions from the same calibration toolbox were also used to track
the checkerboard on the ultrasound transducer. This includes
locating the checkerboard corners with a Harris corner detector
and using the known geometry of the checkerboard to accurately
determine the checkerboard pose. For each camera frame, the
user selected the four extreme corners of the checkerboard to
initialize the software.
In order to track the ultrasound image, a calibration must be
completed to determine where the ultrasound plane is located
relative to the respective sensor (da Vinci kinematics, EM sensor,
or stereo camera) [30].
N-wire calibration was used to calibrate the EM sensor and
checkerboard to the ultrasound image. We used the PLUS framework for the EM sensor calibration [31] and a similar implementation in MATLAB for the checkerboard calibration. EM sensor
to US image calibration was completed away from large metal
objects and other interference. The calibration of the stereo camera tracking to the ultrasound image was completed using the
wide-baseline stereo camera setup previously described. Because locating an N-wire phantom within the reference frame
of the da Vinci kinematics was particularly difficult, the transformation from the ultrasound image to the da Vinci tool was
found through calibration using a single-wall phantom [32].
C. Tracking Tests
Several tests will be undertaken to determine the accuracy of
the different tracking methods.

263

Fig. 4. Grasping repeatability testing. The transducer was picked up 30 independent times, and the transformation between the checkerboard on the tool
jaws and on the transducer was calculated.

First, before the da Vinci kinematics can be used for tracking, the grasping repeatability must be tested. The same widebaseline camera system that was described above was used to
test the repeatability, so the error of the wide-baseline camera
system and checkerboard tracking also needed to be determined.
To test this camera system error, two checkerboards were placed
in a fixed relative position. These checkerboards were the same
3.175-mm square pattern used for tracking the transducer. The
Harris corner detection methods of extraction from the Caltech
camera toolbox used on the transducer and da Vinci tools were
applied to these fixed checkerboards. Thirty images of the two
fixed checkerboards in different poses were used to determine
the camera repeatability.
For testing the grasping repeatability, the transducer was
picked up 30 independent times (released and picked up again)
using the robotic instrument. Images were saved from the stereo
camera, and the transformation between the tool and transducer
was determined for each of the 30 trials (see Fig. 4).
To understand the errors present in the different tracking
methods, we performed hand-eye calibration using the Kronecker product implementation [33], solving the system AX =
ZB. Using the EM sensor and da Vinci robot as an example, A is
the set of 4 × 4 matrix transforms corresponding to the location
and orientations of the EM sensor with respect to its transmitter
base, and B is the collection of homogenous transformations of
the tool tip with respect to the robot base. We then solve for X,
the transform between the tool tip and the EM sensor and Z, the
transformation between the robot base and the EM transmitter
base. Z is subject to change with changes in the experimental
setup, but X should be consistent as the transformation between
the da Vinci tool tip and the EM sensor inside the ultrasound
transducer is repeatable as described above. The position error
is defined as the Cartesian distance between points in B and in
the points defined by the transform: Z −1 AX.
We use the optotrak certus motion capture system (NDI Measurement Systems, Ontario, Canada), as the ground truth during
these experiments because it is a tracking system that uses active
IR LED’s, has an accuracy of 0.1 mm, and resolution of 0.01
mm over its working volume [34]. A rigid body with four active
infrared markers was attached to the transducer, and the transducer was moved through 75 to 100 poses while grasped by the

264

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 2, FEBRUARY 2016

TABLE I
STANDARD DEVIATIONS OF THE FIXED CHECKERBOARDS, USED TO
DETERMINE THE REPEATABILITY OF THE WIDE-BASELINE OPTICAL CAMERA
TRACKING SYSTEM

Angles (deg)

Roll
0.13

Pitch
0.15

Yaw
0.07

Translation (mm)

X
0.012

Y
0.010

Z
0.02

Fig. 5. Vessel Phantom. Top-left: B-mode, top-right: CT, bottom-left: power
Doppler, and bottom-right: phantom photo.

da Vinci. Three sets of data were collected with slightly different
experimental setups and for each set, X and Z were calculated.
Three hand-eye calibrations were completed with this data, the
da Vinci and EM sensor, both with respect to the Optotrak and
the da Vinci to the EM sensor. Finally, because of differences
in the experimental setup, we compared the tracking accuracy
of the da Vinci stereo camera tracking to the Optotrak. In order
to complete this, a rigid body of Optotrak markers was created
surrounding a checkerboard of the same size and dimensions as
the one attached to the transducer. Two sets of data of 100 poses
were collected.
D. Image Processing and Vessel Identification
The contours of the vessels within the ultrasound images of
the reconstructed volume were segmented manually for each of
the 18 volumes (six da Vinci kinematics, six EM, and six stereo
camera) after reconstruction. Once the contours from each image are found, a surface was created from the points on the
surface of vessels using regularized marching tetrahedra [35].
Segmentations were all completed by the same person. This surface structure was then used for registration with a previously
created surface representation of the vessel structure created
from preoperative imaging. In this case, preoperative CT scans
of the phantom were used and contours were created through
manual segmentation. A custom designed flow phantom (Blue
Phantom, Redmond, WA, USA) was used during the experiments (see Fig. 5). This phantom consists of a single vessel,
which branches once midway through the phantom. The vessel
diameter varies from 4 to 6 mm.
The surface-to-surface registration was completed using principal component analysis (PCA) [36]. Ball bearings were placed
under the vessel phantom during the CT scans and subsequent
ultrasound scans. To validate the reconstructions, the distances
between the ball bearings in the CT scan (#1 to #2, #1 to #3,
etc.) were compared to the distances between the bearings in
the ultrasound volumes. To verify the registrations, the distance
between corresponding ball bearings was calculated, and the
Dice coefficient [37] and volume error were also calculated.
The distance between corresponding ball bearings is defined as
the target registration error (TRE). In addition, the average distance was calculated between every point on the CT surface and
its closest counterpart on the reconstructed surface.

Fig. 6. Grasping Repeatability. The mean-centered components (centered at
zero) of the transformation between the tool jaws and the transducer computed
using stereo tracking (see Fig. 4).

III. RESULTS
A. Grasping Repeatability
First, the tracking error of the wide-baseline camera system
needed to be determined. The standard deviations for the three
Euler angles and Cartesian components of the transforms resulting from testing two fixed checkerboards are shown in Table I.
From the 30 release and capture trials, a transformation between the tool jaws and the ultrasound transducer was calculated
using the position of the checkerboard markers in the frame
of the stereo camera (see Fig. 4). The transformations were
converted to rotations and positions and centered on the mean
values. The distributions of these values are shown in Fig. 6.
The grasping repeatability results demonstrate repeatability
better than the accuracy of the da Vinci kinematics and the
EM tracking and approaches the accuracy of the checkerboard
tracking itself.
B. Calibration
The results for the ultrasound calibration using the da Vinci
kinematics, EM sensor calibration, and stereo camera laparoscope tracking are described in turn. For each sensor, a slightly

SCHNEIDER et al.: TRACKED “PICK-UP” ULTRASOUND FOR ROBOT-ASSISTED MINIMALLY INVASIVE SURGERY

TABLE II
POSITION ERRORS FOR HAND-EYE CALIBRATION BETWEEN THE DA VINCI
(DV), EM SENSOR AND OPTOTRAK
Dataset

Calibration Data Error (mm)

Test Data Error (mm)

1

dV to Optotrak
EM to Optotrak
dV to EM

2.6 ± 1.8
5.6 ± 2.9
7.9 ± 3.1

2.5 ± 1.9
5.5 ± 3.3
7.7 ± 3.5

2

dV to Optotrak
EM to Optotrak
dV to EM

3.5 ± 2.5
6.8 ± 3.2
10.7 ± 4.6

3.7 ± 2.6
6.9 ± 3.5
10.8 ± 5.1

dV to Optotrak
EM to Optotrak
dV to EM

3.2 ± 2.3
5.9 ± 2.9
10.1 ± 4.2

3.3 ± 2.4
5.9 ± 3.2
10.6 ± 4.4

3

TABLE III
POSITION ERRORS FOR THE HAND-EYE CALIBRATION OF THE OPTOTRAK AND
DA VINCI STEREO CAMERA
Dataset

Mean and Standard Deviation (mm)

different measure of calibration accuracy was used. For the da
Vinci kinematics calibration, the residual error using a singlewall phantom was 2.2 mm, averaged over three calibrations
using 60–65 images. For the EM sensor calibration, the reprojection error for EM sensor calibration using the N-wire phantom
was 0.94 mm, using 200 calibration images. The reprojection
error is the difference in position of the N-wires, projected using
the calibration matrix compared to the segmented N-wires in the
ultrasound images. For the stereo camera to ultrasound image
calibration, the pinhead point reconstruction accuracy (PRA)
was 1.3 mm. The PRA is the Euclidean distance from the average
of the estimated pinhead location to the actual pinhead location.
The estimated pinhead location was determined by segmenting
the pinhead from the ultrasound image and transforming that
point to the stereo laparoscopic coordinate system. The actual
location is the location of the pin, as seen by the stereo laparoscope, after the fluid in the ultrasound imaging bath is drained.
During calibration, Edgcumbe et al. used a wide-baseline camera to track the ultrasound transducer, an N-wire phantom for
ultrasound calibration, and the da Vinci stereo laparoscope was
used to determine the accuracy of the calibration [27]. Thirty
and 22 transducer poses were used for ultrasound calibration
and calculating the PRA, respectively.
Since there is a significant unknown amount of error between
the EM sensor measurements and the da Vinci kinematic measurements, both were compared to the NDI Certus Optotrak.
Table II shows the mean position errors and standard deviations
for three calibration setups using 50, 75, and 75 poses for the
calibration data, respectively, and 15, 25, and 25 separate unique
poses for the test data. The results presented are mean and standard deviations of 50 randomized iterations of the calibrations
and tests, such that the poses in each dataset were randomly
assigned to calibration or test sets.
One-hundred poses of a rigid body were also collected with
both the da Vinci stereo camera and the Optotrak. The data were
separated randomly into 75 poses to be used for the hand-eye
calibration and 25 poses to be used for testing. Fifty iterations
of the hand-eye calibration were completed, in which the poses
were randomly assigned to either the calibration or test sets. The
average results of the 50 iterations are shown in Table III.

265

1
2

Calibration Data Error (mm)

Test Data Error (mm)

1.58 ± 0.92
0.78 ± 0.54

1.62 ± 0.94
0.82 ± 0.54

C. Three-Dimensional Reconstructions and Registration
We created 3-D ultrasound reconstructions of a vessel phantom using the EM senor, da Vinci kinematics, and stereo camera
tracking systems. With each system, six volumes were reconstructed and registered to the CT scan of the same phantom.
The contours in each image were segmented manually using
B-mode images. The ball-bearing fiducials were located and the
distance between each fidicial was calculated and compared to
the distances from the CT volume. The mean error and standard deviations between the bearing locations for each tracking
modality are shown in Tables IV–VI. This error is a representation of reconstruction accuracy, while the TRE, the mean distance between corresponding fiducial bearings, represents the
registration error.
The errors between the CT volumes and volumes created
from the three sensors were also calculated. The volume error,
the difference in the volumes of the CT and the sensor-based
reconstructions, was calculated, as it was seen that the volume
segmented from the ultrasound images was typically smaller
than that of the CT scan. The relative volume error reported in
Tables IV–VI is the ratio of the volume of the CT reconstruction
and the reconstruction from the respective sensor. To find a measure of registration error, we used the Dice coefficient, which is
twice the volume overlap divided by the sum of the two volumes.
Note that the Dice coefficients drop very quickly with errors in
registration. For example, a misregistration of 1 mm along the
x-axis of the CT volume with itself results in a coefficient of 0.8.
Tables IV–VI outline the results from these volumes. Note that
the volumes collected and reconstructed with each method correspond, i.e., volume 1 from the da Vinci and volume 1 from the
EM sensor are the same volume collected at the same time, while
the camera volume was collected separately and correspond to
volumes 7–12.
The vessel surfaces were registered using PCA and visual
inspection was completed to verify that the surfaces were correctly registered and reconstructed. Fig. 7 shows examples of
the reconstructions using each tracking method and examples
of the registration with a vessel reconstructed using the da Vinci
tracking.
IV. DISCUSSION
We have presented an ultrasound transducer that is suitable
for use in humans during MIS. The three methods for tracking
the transducer have been validated for a vessel phantom. The
camera tracking has been independently validated by Edgcumbe
et al. [27]. The transducer follows all the guidelines for intraoperative use and discussions with several surgeons have

266

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 2, FEBRUARY 2016

TABLE IV
RECONSTRUCTION AND REGISTRATION ERRORS FOR THE VOLUMES COLLECTED WITH THE DA VINCI AS A TRACKER
Volume

Mean Target Spacing Error (mm)

Mean TRE (mm)

Dice Coefficient

Relative Volume Error (ratio)

Mean Closest Surface Point (mm)

1
2
3
4
5
6
Average

2.8 ± 1.12
2.7 ± 0.98
2.8 ± 1.28
0.8 ± 0.64
2.68 ± 0.74
3.60 ± 1.37
2.56 ± 1.02

5.35 ± 1.88
5.45 ± 1.16
4.91 ± 1.25
5.97 ± 1.49
5.01 ± 2.74
5.73 ± 1.87
5.40 ± 1.73

0.41
0.42
0.49
0.41
0.54
0.33
0.43

0.60
0.55
0.57
0.53
0.51
0.54
0.55

1.33 ± 0.94
1.31 ± 0.87
1.18 ± 0.79
1.33 ± 0.93
1.01 ± 0.63
1.66 ± 1.29
1.30± 0.91

TABLE V
RECONSTRUCTION AND REGISTRATION ERRORS FOR THE VOLUMES COLLECTED WITH THE EM SENSOR AS A TRACKER
Volume

Mean Target Spacing Error (mm)

Mean TRE (mm)

Dice Coefficient

Relative Volume Error (ratio)

Mean Closest Surface Point (mm)

1
2
3
4
5
6
Averages

2.00 ± 1.20
1.49 ± 1.12
1.03 ± 1.05
1.38 ± 0.40
1.44 ± 0.33
1.41 ± 1.34
1.46 ± 0.91

8.05 ± 2.94
8.03 ± 1.97
6.9 ± 2.11
6.16 ± 1.95
6.09 ± 1.90
4.06 ± 1.33
6.55 ± 2.03

0.25
0.23
0.23
0.21
0.23
0.35
0.25

0.67
0.86
0.64
0.61
0.64
0.55
0.66

2.08 ± 1.53
2.49 ± 2.15
2.30 ± 1.96
2.48 ± 1.91
2.19 ± 1.68
1.71 ± 1.25
2.21 ± 1.75

TABLE VI
RECONSTRUCTION AND REGISTRATION ERRORS FOR THE VOLUMES COLLECTED WITH THE STEREO CAMERA AS THE TRACKER
Volume

Mean Target Spacing Error (mm)

Mean TRE (mm)

Dice Coefficient

Relative Volume Error (ratio)

Mean Closest Surface Point (mm)

7
8
9
10
11
12
Averages

2.30 ± 0.68
5.09 ± 1.16
2.47 ± 0.80
5.18 ± 2.76
5.53 ± 2.34
2.48 ± 0.80
3.84 ± 1.42

5.15 ± 1.49
8.52 ± 2.15
7.38 ± 2.54
6.39 ± 2.97
7.81 ± 1.60
4.59 ± 1.91
6.64 ± 2.11

0.29
0.37
0.43
0.41
0.45
0.39
0.39

0.49
0.37
0.57
0.35
0.27
0.27
0.39

1.92 ± 1.44
1.50 ± 1.22
1.65 ± 1.59
1.37 ± 1.03
1.36 ± 1.01
1.45 ± 1.06
1.54 ± 1.23

Fig. 7. Top: Examples of the vessel phantom reconstructed from each modality, from left to right, the CT scan, the da Vinci kinematics, the EM sensor,
and the stereo camera tracking. The blue stars represent the locations of the
ball-bearing targets for each of the sensor-based reconstructions. Bottom: An
example of the CT volume registered with a volume reconstructed using the
da Vinci kinematics. The red mesh and stars represent the surface of the CT
volume and the ball-bearing targets, while the blue mesh and stars represent the
da Vinci reconstructed volume.

confirmed that this is a transducer they would like to use during
their surgeries.
We were able to test the repeatability of grasping the transducer with the da Vinci tool and found that errors introduced
by variations in the grasping were much smaller than the tracking errors introduced by the robot kinematics. In fact, the errors that were found between the tool jaws and the ultrasound
transducer are close to those that were found between the fixed
checkerboards, indicating that the grasping of the transducer is
repeatable.
The results of the hand-eye calibrations are particularly interesting as they give a good indication of the errors introduced
by the different tracking methods. The errors for the calibration
between the EM and the da Vinci averaged 9.7 mm. It is not
clear though, which tracking method is closer to the ground
truth. When the two tracking methods were then compared to
the Optotrak, which has much lower and known tracking error,
the errors in the EM sensor calibration had an average of 6.1
mm, while the errors between the da Vinci and the Optotrak
had an average of 3.2 mm. The larger errors in the EM sensors
could be related to the metal within the environment. In such
situations, the OR table and the da Vinci itself could contribute
to warping of the EM fields.

SCHNEIDER et al.: TRACKED “PICK-UP” ULTRASOUND FOR ROBOT-ASSISTED MINIMALLY INVASIVE SURGERY

The da Vinci camera tracking was also compared to the Optotrak and the average error between the Optotrak and the stereo
camera positions was 1.22 mm. The data for this comparison
were collected within the optimal distance range for the da Vinci
cameras, so larger errors are expected as the checkerboard is
moved further from the camera.
The vessel reconstructions with the da Vinci had an interfiducial spacing error that was within the tracking errors of the robot
and ultrasound calibration. Visually, the reconstructions looked
correct, without major distortions in the vessel structure. The
surfaces were well matched, as seen by the low closest point
distances. The registration errors may decrease with a more rigorous registration method, or a more complicated vessel surface.
The blood vessel phantom used for the experiments is Y-shaped,
and does not well constrain all the degrees of freedom, presenting a challenging but anatomically realistic model.
The EM sensor had similar results for the reconstruction of
the vessel phantom. The mean target spacing error was slightly
lower than with the da Vinci, but the correspondence errors
were larger. However, visual inspections of the volumes reveal
larger distortions in the vessel structure than was seen with the da
Vinci volumes. This is partly attributed to the larger closest point
means and the large variations. The larger distortions are due
to the EM environment around the da Vinci, as reconstructions
performed in a metal-free environment did not display these
distortions and were more consistent. Additional testing needs
to be completed to determine the primary cause of the EM
field warping. Warping of the EM field by the OR table is
static and warping from the moving da Vinci arms is dynamic.
In the case of static warping, it would be possible to correct
the distortions using one of the other tracking methods, either
camera or kinematics with methods described by Kindratenko
[38]. In the case of warping from the OR table, the use of a
flat-panel EM transmitter would negate some of the effects.
The reconstruction using the stereo camera had the largest
mean spacing error and TRE. The reconstructed trajectory of the
ultrasound and associated blood vessel path has several unexpected jumps that were caused by inaccurate optical tracking of
the ultrasound transducer. These jumps are visible in the stereo
camera reconstruction in Fig. 7. Specifically, at the extreme ends
of the vessel there are visible distortions. This is likely because
the distance between the camera and transducer was outside the
optimal distance for the stereo camera tracking. At one end of
the vessel, it was inside the focal distance of the cameras and
in the extreme lower corner of the images. At the far end, the
checkerboard was very small in the images, limiting the accuracy of the corner detection. The distance between the camera
and transducer (z) was between 50 to 200 mm, and the camera
had a narrow baseline of 5 mm. Thus, the depth to baseline ratio
ranged from 10 to 40 during the experiment. The range of depth
is significant because the 3-D stereo localization error scales in
a nonlinear manner (z 2 ) according to the following formula:
δz =

−z 2
m
fB

(1)

where f is the focal length (pixels), B is the stereo baseline
(mm), and m is the uncertainty in disparity (pixels). In Section
II-C, for a checkerboard at a depth of 10 cm from the camera,

267

we calculated the accuracy of stereo point localization was
0.8 mm. If we assume that all the error was caused by the
uncertainty in disparity, then the point localization error is 0.2
and 3.2 mm at depths of 50 and 200 mm, respectively. This
corresponds with the range of error that was observed for the
blood vessel surface reconstruction.
The three tracking methods each have advantages and disadvantages. The stereo camera tracking gives high tracking accuracy, while the transducer is close to the camera, and has the
benefit of being tracked directly in the camera frame, making
integration of augmented and virtual reality relatively simple.
However, it has the disadvantages that the markers must be visible in the camera and clean. This will be most accurate early
in the surgery, but may become obscured later. Another disadvantage is the limited angle for which they can be seen by the
camera; the markers on the transducer can only be accurately
tracked when they are facing the camera. There will be times
during the procedure in when the markers will not be visible.
As we have seen, one disadvantage of the EM sensor is that
it may be warped by the EM fields and metal objects in the
surgical environment. On the other hand, it has the advantage
that the transducer can be tracked anywhere in the surgical field,
even when out of view of the camera. We hypothesize that it can
be used to direct the surgeon to the location of the transducer,
through the use of on-screen cues, if the transducer was to be
placed somewhere outside the camera’s view.
The robot kinematics has high accuracy and can be used
throughout the surgery without any degradation in tracking accuracy. It should be noted that this accuracy is only valid for
the activated joints on a single arm; the errors in the setup joints
of the da Vinci can be very large as different types of potentiometers are used in these joints. In order to use the kinematic
tracking (or the EM sensor) for augmented reality, the tracking
coordinate frames need to by registered at the beginning of the
surgery, likely using a hand-eye calibration method. We may be
able to use the stereo markers to calibrate the other trackers to the
camera frame and unwarp the inconsistencies in the EM field.
By appropriate decision making throughout the surgery to
determine which tracking methods to use, on their own or in
combination, we will provide the surgeon with the best possibly
localized ultrasound image.
V. CONCLUSION
Using intraoperative ultrasound for surgical guidance with
the da Vinci robot can be safe, fast, and effective. This can be
particularly useful during procedures in which the underlying
anatomy is extremely delicate.
The transducer presented in this paper can be easily grasped,
aligned, and released. In addition, the grip on the transducer is
stable and repeatable, less than 0.1 mm and 0.2◦ , enabling the
use of the robot kinematics to track the transducer and create
accurate 3-D ultrasound volumes and be easily manoeuvred
inside a patient. This has an additional advantage for future
3-D augmented reality, as the ultrasound image will be in the
robotic frame of reference. The three tracking methods allow
for accurate volume reconstruction, and accurate display of the
images and volumes with respect to the da Vinci stereo camera.

268

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 63, NO. 2, FEBRUARY 2016

The transducer has received approval for human trials, and
we are planning clinical trials at our center. We will be testing
the accuracy of the tracking within the surgical environment,
completing 3-D reconstructions on the vessel structures of the
kidney. From a preoperative CT, the vessels can be segmented
and used for registration. We will be able to use the anatomical
landmarks such as the vessel bifurcation locations and vessel
direction vectors as targets for the registration.
The method in which the information is displayed is critical
for both surgeon acceptance and the proper interpretation of the
information [39]. In the future, we have several goals. We would
like to begin clinical trials using the new ultrasound transducer,
focusing first on urological surgeries and then expanding to
include gynaecological and abdominal procedures. We would
like to explore the methods of display and test these in a more
realistic surgical environment.
ACKNOWLEDGMENT
The authors would like to thank R. Singla for his work with
the integration of the da Vinci and PLUS. They would also like
to thank P. Edgcumbe for his help in data collection.
REFERENCES
[1] J. Catheline, “A comparison of laparoscopic ultrasound versus cholangiography in the evaluation of the biliary tree during laparoscopic cholecystectomy,” Eur. J. Ultrasound, vol. 10, no. 1, pp. 1–9, 1999.
[2] D. Barbot, “Improved staging of liver tumors using laparscopic intraoperative ultrasound,” J. Surg. Oncol., vol. 64, pp. 63–67, 1997.
[3] T. Polascik et al., “Intraoperative sonography for the evaluation and management of renal tumors: Experience with 100 patients,” J. Urol., vol. 154,
no. 5, pp. 1676–1680, 1995.
[4] C. Våpenstad et al., “Laparoscopic ultrasound: A survey of its current and
future use, requirements, and integration with navigation technology,”
Surg. Endosc., vol. 24, pp. 1–10, 2010.
[5] J. Leven et al., “da Vinci canvas: A telerobotic surgical system with integrated, robot-assisted, laparoscopic ultrasound capability,” Med. Image
Comput. Comput.-Assisted Intervention Conf., 2005, pp. 811–818.
[6] C. Schneider et al., “Robot-assisted laparoscopic ultrasound,” in Proc. Inf.
Process. Comput.-Assisted Intervention Conf., 2010, pp. 67–80.
[7] R. Budde et al., “Endoscopic localization and assessment of coronary
arteries by 13 MHz epicardial ultrasound,” Ann. Thoracic Surg., vol. 77,
no. 5, pp. 1586–1592, 2004.
[8] R. Budde et al., “Robot-assisted 13MHz epicardial ultrasound for endoscopic quality assessment of coronary anastomoses,” Interactive Cardiovasc. Thoracic Surg., vol. 3, no. 4, pp. 616–6120, 2004.
[9] S. Ding et al., “Tracking of vessels in intra-operative microscope video
sequences for cortical displacement estimation,” IEEE Trans. Biomed.
Eng., vol. 58, no. 7, pp. 1985–1993, Jul. 2011.
[10] G. Penney et al., “Registration of freehand 3D ultrasound and magnetic
resonance liver images,” Med. Image Anal., vol. 8, no. 1, pp. 81–91, 2004.
[11] I. Reinertsen et al., “Validation of vessel-based registration for correction
of brain shift,” Med. Image Anal., vol. 11, no. 4, pp. 374–388, 2007.
[12] T. Lange et al., “3D ultrasound-CT registration of the liver using combined
landmark-intensity information,” Int. J. Comput. Assisted Radiol. Surg.,
vol. 4, no. 1, pp. 79–88, 2009.
[13] D. Lee et al., “Non-rigid registration between 3D ultrasound and CT
images of the liver based on intensity and gradient information,” Phys.
Med. Biol., vol. 56, no. 1, pp. 117–137, 2011.
[14] E. M. V. Osorio et al., “Accurate CT/MR vessel-guided nonrigid registration of largely deformed livers,” Med. Phys., vol. 39, no. 5, pp. 2463–2477,
2012.
[15] J. Jomier and S. Aylward, “Rigid and deformable vasculature-to-image
registration: A hierarchical approach,” in Proc. Med. Image Comput.
Comput.-Assisted Intervention Conf., 2004, pp. 829–836.

[16] P. Besl and N. McKay, “A method for registration of 3-D shapes,” IEEE
Trans. Pattern Anal. Mach. Intell., vol. 14, no. 2, pp. 239–256, Feb. 1992.
[17] T. Lange et al., “Augmenting intraoperative 3D ultrasound with preoperative models for navigation in liver surgery,” Med. Image Comput. Comput.Assisted Intervention Conf., 2004, pp. 534–541.
[18] C. Schneider et al., “Intra-operative ‘pick-up’ ultrasound for robot assisted surgery with vessel extraction and registration: A feasibility
study,” in Proc. Inf. Process. Comput.-Assisted Interventions Conf., 2011,
pp. 122–132.
[19] C. M. Schneider et al., “Ultrasound probe for laparoscopy,” U.S. Patent
13/525183, 2012.
[20] P. Edgcumbe et al., “Pico lantern: A pick-up projector for augmented
reality in laparoscopic surgery,” in Proc. Med. Image Comput. Comput.Assisted Intervention Conf., 2014, pp. 432–439.
[21] M. Feuerstein et al., “Magneto-optic tracking of a flexible laparoscopic
ultrasound transducer for laparoscope augmentation,” in Proc. Med. Image
Comput. Comput.-Assisted Intervention Conf., 2007, pp. 458–466.
[22] K. Konishi et al., “A real-time navigation system for laparoscopic surgery
based on three-dimensional ultrasound using magneto-optic hybrid tracking configuration,” Int. J. Comput. Assisted Radiol. Surg., vol. 2, no. 1,
pp. 1–10, 2007.
[23] P. Pratt et al., “Intraoperative ultrasound guidance for transanal endoscopic microsurgery,” in Proc. Med. Image Comput. Comput.-Assisted
Intervention Conf., 2012, pp. 463–470.
[24] A. H. Gee et al., “Sensorless freehand 3D ultrasound in real tissue: Speckle
decorrelation without fully developed speckle,” Med. Image Anal., vol. 10,
no. 2, pp. 137–149, 2006.
[25] N. Afsham et al., “A generalized correlation-based model for out-ofplane motion estimation in freehand ultrasound,” IEEE Trans. Med. Imag.,
vol. 33, no. 1, pp. 186–199, Jan. 2014.
[26] D. Kwartowitz et al., “Toward image-guided robotic surgery: Determining
intrinsic accuracy of the da Vinci robot,” Int. J. Comput. Assisted Radiol.
Surg., vol. 1, no. 3, pp. 157–165, 2006.
[27] P. Edgcumbe et al., “Calibration and stereo tracking of a laparoscopic ultrasound transducer for augmented reality in surgery,” in Proc. Augmented
Reality Environ. Med. Imag. Comput.-Assisted Interventions Conf., 2013,
pp. 258–267.
[28] J.-Y. Bouguet, “Camera calibration toolbox for MATLAB,” (2004). [Online]. Available: http://www.vision.caltech.edu/bouguetj/calib_doc
[29] S. Hughes et al., “Volume estimation from multiplanar 2D ultrasound
images using a remote electromagnetic position and orientation sensor,”
Ultrasound Med. Biol., vol. 22, no. 5, pp. 561–572, 1996.
[30] L. Mercier et al., “A review of calibration techniques for freehand 3-D
ultrasound systems,” Ultrasound Med. Biol., vol. 31, no. 2, pp. 143–165,
2005.
[31] A. Lasso et al. (2014, May). Plus: Open-source toolkit for ultrasoundguided intervention systems. IEEE Trans Biomed. Eng. [Online].
61(10), pp. 2527–2537. Available: http://dx.doi.org/10.1109/TBME.
2014.2322864
[32] R. Prager et al., “Rapid calibration for 3-D freehand ultrasound,” Ultrasound Med. Biol., vol. 24, no. 6, pp. 855–869, 1998.
[33] M. Shah, “Solving the robot-world/hand-eye calibration problem using
the kronecker product,” J. Mech. Robot., vol. 5, no. 3, pp. 031007-1–
031007-7, 2013.
[34] R. Rohling et al., “Comparison of relative accuracy between a mechanical
and an optical position tracker for image-guided neurosurgery,” Comput.
Aided Surg., vol. 1, no. 1, pp. 30–34, 1995.
[35] G. Treece et al., “Regularised marching tetrahedra: Improved ISO-surface
extraction,” Comput. Graph., vol. 23, no. 4, pp. 583–598, 1999.
[36] M. Audette et al., “An algorithmic overview of surface registration techniques for medical imaging,” Med. Image Anal., vol. 4, no. 3, pp. 201–217,
2000.
[37] S.-H. Cha, “Comprehensive survey on distance/similarity measures between probability density functions,” Int. J. Math. Models Methods Appl.
Sci., vol. 4, pp. 300–307, 2007.
[38] V. Kindratenko, “A survey of electromagnetic position tracker calibration
techniques,” Virtual Reality, vol. 5, no. 3, pp. 169–182, 2000.
[39] T. Sielhorst et al., “Advanced medical displays: A literature review of
augmented reality,” J. Display Technol., vol. 4, no. 4, pp. 451–467, 2008.

Authors’ photographs and biographies not available at the time of publication.

