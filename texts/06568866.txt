56

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 1, JANUARY 2014

Privacy-Preserving Clinical Decision Support System
Using Gaussian Kernel-Based Classification
Yogachandran Rahulamathavan, Member, IEEE, Suresh Veluru, Raphael C.-W. Phan,
Jonathon A. Chambers, Fellow, IEEE, and Muttukrishnan Rajarajan, Senior Member, IEEE

Abstract‚ÄîA clinical decision support system forms a critical capability to link health observations with health knowledge to influence choices by clinicians for improved healthcare. Recent trends
toward remote outsourcing can be exploited to provide efficient and
accurate clinical decision support in healthcare. In this scenario,
clinicians can use the health knowledge located in remote servers
via the Internet to diagnose their patients. However, the fact that
these servers are third party and therefore potentially not fully
trusted raises possible privacy concerns. In this paper, we propose
a novel privacy-preserving protocol for a clinical decision support
system where the patients‚Äô data always remain in an encrypted
form during the diagnosis process. Hence, the server involved in
the diagnosis process is not able to learn any extra knowledge
about the patient‚Äôs data and results. Our experimental results on
popular medical datasets from UCI-database demonstrate that the
accuracy of the proposed protocol is up to 97.21% and the privacy
of patient data is not compromised.
Index Terms‚ÄîClassification, clinical decision support, encryption, privacy, support vector machine (SVM).

I. INTRODUCTION
CLINICAL decision support system is a computerized
medical diagnosis process for enhancing health-related
decisions and actions with pertinent, organized healthcare
knowledge and patient data to improve health and healthcare
delivery [1]. Artificial intelligence in machine learning together with biomedical engineering revamp the available clinical
dataset into healthcare knowledge to build the clinical decision
support system [2]‚Äì[5]. The current approach uses locally available clinical datasets to build a clinical decision-support system.
However, the accuracy of the system depends on the availability
of sufficiently valid clinical datasets but these are not always
accessible. As an example, a particular general practitio ner
surgery does not generally have sufficient number of samples
for all the diseases. Hence, making a correct diagnosis using
limited samples is unlikely to be successful.

A

Manuscript received January 22, 2013; revised June 12, 2013; accepted July
17, 2013. Date of publication July 25, 2013; date of current version December
31, 2013.
Y. Rahulamathavan, S. Veluru, and M. Rajarajan are with the School
of Engineering and Mathematical Science, City University London, London EC1V 0HB, U.K. (e-mail: Yogachandran.Rahulamathavan.1@city.ac.uk;
Suresh.Veluru.1@city.ac.uk; R.Muttukrishnan@city.ac.uk).
R. C.-W. Phan is with the Faculty of Engineering, Multimedia University,
Cyberjaya 63100, Malaysia (e-mail: raphael@mmu.edu.my).
J. A. Chambers is with the Advanced Signal Processing Group, School
of Electronic, Electrical and Systems Engineering, Loughborough University,
Leicestershire LE11 3TU, U.K. (e-mail: J.A.Chambers@lboro.ac.uk).
Digital Object Identifier 10.1109/JBHI.2013.2274899

The recent advances in remote outsourcing techniques (i.e.,
cloud computing) can be exploited in healthcare to provide efficient and accurate decision support as a service. This service
could be utilized by any clinician in a flexible manner such as
on-demand or pay-per use [6]. Within this context, let us consider the following scenario: a third party server builds a clinical
decision support system using the existing clinical dataset (i.e.,
assume that the server has a rich clinical dataset for a particular disease). Now clinicians, who want to verify whether their
patients are affected by that particular disease, could send the
patient data to the server via the Internet to perform diagnosis
based on the healthcare knowledge at the server. This new notion
overcomes the difficulties that would be faced by the clinicians,
such as having to collect a large number of samples (i.e., a rich
clinical dataset), and requiring high computational and storage
resources to build their own decision support system.
However, there is now a risk that the third party servers are
potentially untrusted servers. Hence, releasing the patient data
samples owned by the clinician or revealing the decision to
the untrusted server raises privacy concerns. This drawback can
affect the adoption of outsourcing techniques in healthcare [7],
[8]. Furthermore, the server may not wish to disclose the features
of the clinical decision support system even if it offers the service
to the clinicians. Hence, in this paper we propose a privacypreserving clinical decision support system which preserves the
privacy of the patient data, the decision and the server side
clinical decision support system parameters, so that the benefits
of the emerging outsourcing technology can also be enjoyed in
the healthcare sector.
In particular, we consider a decision support system that was
developed using a support vector machine (SVM), which is one
of the machine learning tools which has been widely used to predict various diseases in biomedical engineering [9]‚Äì[11]. Typically, using an SVM consists of two different phases, namely
training and testing. During the training phase, a classifier will
be trained using features of the training dataset belonging to different classes. In the testing phase, any unlabeled data sample
can be classified and labeled to the corresponding matched class
using the trained classifier. In the current setting, the available
clinical dataset can be used to train a classifier and the trained
classifier can be used as a clinical decision support system during the testing phase to make the decision for the patient data.
Depending on the separability of the available training data,
the SVM uses particular kernel functions such as linear and
nonlinear kernels. If the number of features is larger than the
number of instances, it is not necessary to map the data into
higher dimensional space [12]. It is because nonlinear mapping

2168-2194 ¬© 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

RAHULAMATHAVAN et al.: PRIVACY-PRESERVING CLINICAL DECISION SUPPORT SYSTEM

Fig. 1.

Overview of a privacy-preserving clinical decision support system.

does not improve the performance. Since medical datasets, in
general, have less number of features than the number of instances, it is possible to get better classification results with
nonlinear kernel-based SVM. Polynomial and Gaussian kernels are nonlinear kernels. The polynomial kernel-based model
is parametric, while the Gaussian kernel-based model is nonparametric. In a way, a nonparametric model means that the
complexity of the model is infinite, its complexity grows with
number of instances. In contrast a parametric model‚Äôs size is
fixed, so after a certain point, the model become saturated, and
giving more and more instances will not help. It means that the
accuracy is dependent on the chosen degree of the polynomial.
However, the Gaussian kernel finds the best polynomial function in the infinite dimension for the given dataset. Hence, we
consider the Gaussian kernel-based classification in this paper.
To the best of our knowledge, we present the first known
privacy-preserving clinical decision support system for a Gaussian kernel-based SVM. In order to preserve privacy, we redesign the conventional Gaussian kernel-based SVM algorithm
as an encrypted-domain algorithm using the Paillier homomorphic encryption technique as one of its building blocks [14].
Since the Paillier encryption supports only integers and the system variables are continuous and the Gaussian kernel involves
exponentiation of negative values, crucially we develop a novel
technique to scale the variables, which overcomes these barriers
without deteriorating the privacy and performance.
In the system, as shown in Fig. 1, a clinician sends the patient data sample in the encrypted format to the server over
the Internet. Then, the server exploits the Paillier homomorphic
encryption properties to perform the operations directly on the
encrypted data, or if there are any operations that cannot be handled by homomorphic properties, then there will be a limited
amount of interaction between the clinician and the server based
on two-party secure computation protocols [15]. We assume that
both the parties will execute the protocol correctly to maintain
their reputation; hence, we assume that they will behave in a
semihonest manner, i.e., they are honest but curious, so privacy
is a real issue.
The rest of this paper is organized as follows: in Section II, we
describe the conventional SVM, i.e., the steps involved in training the SVM and classification in the plaindomain. Particular
focus is placed on the Gaussian kernel method. In Section III,
we first briefly describe one of the building blocks, i.e., the homomorphic encryption, and show how the SVM classification
can be extended to work in the encrypted domain. Hence, the

57

patient data can remain encrypted even when it is being processed by the server. In particular, the novel technique for scaling variables without deteriorating the performance and privacy
is described in Section III-B. We analyze the performance of
this encrypted-domain method in Section IV. We review related
works in Section V. Conclusions are discussed in Section VI.
Notation: We use boldface upper and lower case letters for
matrices and vectors, respectively; (.) denotes the transpose operator; .2 the Euclidean norm; [[m]] the encryption of message
m; and sign(m) denotes sign of the number m. The modular
reduction operator is denoted by mod.
II. SUPPORT VECTOR MACHINE
SVMs have been widely used in machine learning for data
classification [16], [17]. They have a high generalization ability which provides high reliability in real-world applications
such as image processing, computer vision, text mining, natural language processing, biomedical engineering, and many
more [18]‚Äì[21]. The goal of an SVM is to separate classes by
a classification function, which is obtained by training with the
data samples. We describe the classification function of an SVM
in the following section. This classification function is crucial to
derive the privacy-preserving decision support system proposed
in Section III.
A. In-Plain Domain
We start with a training set of samples xÃÉi ‚àà Rn , i = 1, . . . , N
where each sample xÃÉi belongs to one of the two classes denoted
by a label yi ‚àà {‚àí1, +1}, i = 1, . . . , N . Using these training
data samples we can train an SVM to classify an unlabeled
test sample. Before training an SVM, the training data needs
to be normalized. Normalization keeps the numeric values of
training samples on the same scale and prevents samples with
a large original scale from biasing the solution. Let us denote
the normalized training data samples as xi ‚àà Rn , i = 1, . . . , N
where,
xi =

xÃÉi ‚àí xÃÑ
œÉ2

‚àÄi

(1)

where xÃÑ and œÉ denote the mean and standard deviation of the
training data samples, respectively. Depending on the separability of the training data, this problem is further divided into
either a linear classification problem or a nonlinear classification
problem.
1) Linear Classification Problem: The goal of linear classification is to obtain two parallel hyperplanes as shown in Fig. 2,
w x + b = ‚àí1 and w x + b = +1, where w and b are classification parameters obtained during the training process. Both
hyperplanes separate the training data of the two classes such
that the distance between those hyperplanes is maximized.
After the training stage we can classify an unlabeled test
sample, tÃÉ ‚àà Rn . Before the classification, the test sample is
normalized similar to (1) as
t=

tÃÉ ‚àí xÃÑ
.
œÉ2

(2)

58

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 1, JANUARY 2014

Fig. 3. Nonlinear classification problem converted into a linear classification
problem after the kernel mapping.

Fig. 2. Training data samples for two different classes are denoted by + and
‚àí signs.

Now, the normalized test sample t can be substituted into the
following classification function:



Œ±s ys xs t + b
(3)
f (t) = sign(w t + b) = sign
s‚ààS

where f (t) ‚àà {‚àí1, +1}, Œ±i , i = 1, . . . , N are Lagrangian variables [22] and xs , s = 1, . . . , N are support vectors. If f (t) =
+1, then the test sample tÃÉ belongs to the +ve class, else it belongs to the ‚àíve class. Please note, that a decision function d(t)
can be extracted from (3) as

Œ±s ys xs t + b
(4)
d(t) = w t + b =
s‚ààS

where w x + b = 0 denotes the decision hyperplane which lies
between the two hyperplanes (i.e., w x + b = ‚àí1 and w x +
b = +1)
2) Nonlinear Classification Problem: In the previous section, we discussed the classification problem where the training data samples were linearly separable. However, it has been
proven in the literature that a similar approach can be used for
a nonlinear classification problem using kernel methods [23].
Hence, the nonlinear classification algorithm is formally similar
to the linear classification algorithms except that the dot product between the data samples (i.e., xi xj ) is replaced by various
nonlinear kernel functions. These kernel functions transform
the nonlinear classification problem into a linear classification
problem by mapping data samples into a higher dimensional
feature space (see Fig. 3). In this study, we consider only a
Gaussian function as kernel, where the dot product between the
data samples xs and t in (3) and (4) can be replaced as
xs t ‚áí K(xs , t) = e‚àíŒ≥ x s ‚àít2
2

(5)

where Œ≥ > 0. Hence, the classification function in (3) can be
modified as



‚àíŒ≥ x s ‚àít22
f (t) = sign
Œ±s ys e
+b .
(6)


s‚ààS


decision function



Without encryption the server would use (6) to make a decision on the basis of the patient data. We propose a new technique
to reformulate (6), in the next section, which will preserve the
privacy of patient data, decision, and server side parameters
without compromising the classification performance.
III. PRIVACY-PRESERVING DECISION SUPPORT SYSTEM
In this section, we develop an algorithm which utilizes the
healthcare knowledge available in the remote location via the
Internet while preserving privacy. Hence, we consider a client‚Äì
server scenario where the remote server uses (6) as a decision
making tool. As shown in Fig. 1, a clinician sends the patient
data t over the Internet and obtains support from the server to
make a decision. However, the clinician is reluctant to reveal the
patient data or the decision to the server due to privacy concerns.
At the same time the server desires not to leak any parameter
values of the classification function as this would be a breach of
privacy of the training clinical data samples which relate to other
patients. In this section, we show how to preserve the privacy
of the patient data t and the decision from the server and the
server side parameters from the clinician. First, let us explain
the required building blocks in the next section.
A. Homomorphic Encryption
One of the building blocks of our technique is homomorphic
encryption. For concreteness and without loss of generality,
our descriptions are based on the Paillier cryptosystem [14] although any other homomorphic encryption schemes could be
used. The Paillier cryptosystem is an additively homomorphic
public-key encryption scheme, whose provable semantic security is based on the decisional composite residuosity problem: it is mathematically intractable to decide whether an integer z is an n-residue modulo n2 for some composite n, i.e.,
whether there exists some y ‚àà Z‚àón 2 such that z = y n mod n2 .
Let n = pq, where p and q are two large prime numbers. A
message m ‚àà Zn can be encrypted using the Paillier cryptosystem as [[m]] = g m rn mod n2 , where g ‚àà Z‚àón 2 and r ‚àà Z‚àón .
The Paillier cryptosystem is said to be an additively homomorphic cryptosystem because for some given encryptions [[m1 ]]
and [[m2 ]], the encryption [[m1 + m2 ]] of the sum m1 + m2 in
the plain domain and the encryption [[m1 .Œ±]] of the product of
m1 with a constant Œ± in the plain domain can, respectively,

RAHULAMATHAVAN et al.: PRIVACY-PRESERVING CLINICAL DECISION SUPPORT SYSTEM

TABLE I
OVERVIEW OF VARIABLES WHICH ARE KNOWN TO CLINICIAN AND/OR TO
SERVER (KNOWN-, UNKNOWN-X )

59

and since ‚àíŒ≥xs ‚àí t22 = ‚àíŒ≥xs xs ‚àí Œ≥t t + 2Œ≥xs t, it can be
modified as




c3
‚àíŒ≥ x s x s ‚àíŒ≥ t  t+2Œ≥ x s t
d(t) = c2 e
Œ±s ys e
e
+b
=



s‚ààS






(c2 Œ±s ys e‚àíŒ≥ x s x s )(ec 3 e‚àíŒ≥ t t+2Œ≥ x s t ) + (c2 ec 3 b).

s‚ààS

(10)
Let us define c3 = c4,s + c5,s + c6,s , where c4,s , c5,s , c6,s ‚àà
R+ . Hence, (10) can be modified as




d(t) =
(c2 Œ±s ys e‚àíŒ≥ x s x s ec 4 , s ) √ó (ec 5 , s ec 6 , s ‚àíŒ≥ t t+2Œ≥ x s t )

be computed efficiently in the encrypted domain as

s‚ààS

[[m1 + m2 ]] = [[m1 ]][[m2 ]], [[m1 .Œ±]] = [[m1 ]]Œ± .

(7)

In the setting considered in this paper, the clinician distributes
a public key to the server while keeping his private key secret.
The server is able to perform encryptions under this public
key and exploits the homomorphic properties of the Paillier
cryptosystem to perform the required linear operations in the
encrypted domain. However, only the clinician is able to decrypt
any encrypted messages using his corresponding private key.

+ (c2 ec 3 b)


(c2 Œ±s ys e‚àíŒ≥ x s x s ec 3 ‚àíc 5 , s ‚àíc 6 , s )
=
s‚ààS




√ó (ec 5 , s ec 6 , s ‚àíŒ≥ t t+2Œ≥ x s t ) + (c2 ec 3 b)
and we define


d1,s = (c2 ec 3 ‚àíc 5 , s ‚àíc 6 , s )Œ±s ys e‚àíŒ≥ x s x s , s ‚àà S
d2,s = (ec 5 , s )ec 6 , s ‚àíŒ≥ t

B. Decision Support Function in the Encrypted Domain
In (6), the server knows Œ±s , ys , Œ≥, xs , s ‚àà S, and b in the
plain domain (refer to Table I for the other variables). The
clinician encrypts each element of the patient data using the
public key and sends the encrypted data and the corresponding
public key to the server. Note, that because the encryption is
performed with the clinician‚Äôs public key, no one including the
server could decrypt this to obtain the values of the elements;
thus, the patient data are protected against being revealed even
to the server taking part in this process. Since the server only has
the encrypted patient data, it has to compute (6) in the encrypted
domain using homomorphic and two-party secure computation
properties.
Generally, the variables associated with (6) are continuous
data. Since the Paillier cryptosystem only supports integers, all
the variables in (6) will be quantized to the nearest integer value
during the computation in the encrypted domain, which will
potentially lead to the deterioration of performance [24], [25].
Hence, it is crucial to reformulate (6) into a form which is
suitable for encrypted domain operations. To address this issue,
we propose a novel technique for scaling each variable in (6) by
a positive large number. More specifically, let us multiply the
decision function in (6) by c2 ec 3 > 0 as
	




c3
‚àíŒ≥ x s ‚àít22
f (t) = sign c2 e
Œ±s ys e
+b
(8)
s‚ààS

where c2 , c3 ‚àà R+ ; hence, the solutions of (6) and (8) are equal.
Let us define the scaled decision function in (8) as




c3
‚àíŒ≥ x s ‚àít22
Œ±s ys e
+b
(9)
d(t) = c2 e
s‚ààS

(11)



t+2Œ≥ x s

t

,s ‚àà S

c3

d3 = (c2 e )b

(12)
(13)
(14)

so that (11) and (8) can be replaced as

d(t) =
d1,s d2,s + d3

(15)

s‚ààS

and
f (t) = sign {d(t)} .
c 3 ‚àíc 5 , s ‚àíc 6 , s

c3

(16)

Note that, c2 e
, c5,s , and c2 e have, respectively,
been used to scale the variables associated in (12)‚Äì(14). Variable
c6,s in (13) has been used to mask the value ‚àíŒ≥t t + 2Œ≥xs t.
We generate fresh random values of c6,s in the range of xs xs
for different s values. This masking can be used to preserve the
privacy of variables computed by the server. We explain this in
detail later in this section. All the variables associated in this
section are given in Table I for convenience.
Now, the server needs to compute (15) followed by (16) to
complete the decision-making process. The server knows all
the variables associated with (12) and (14) in the plain domain;
hence, it can easily compute (12) and (14) without interacting
with the clinician. In order to obtain the whole decision function in (15), the server also needs to compute (13). Since the
patient data, t in (13), are available to the server only in the encrypted domain, the server cannot directly compute (13) in the
plain domain. To proceed, the server needs to normalize the patient data, then compute c5,s + c6,s ‚àí Œ≥t t + 2Œ≥xs t and finally
the exponentiation. Let us explain each step in the following
sections.
1) Normalizing the Test Sample: Before computing (13), the
server needs to normalize the patient data as in (2). Denote
the patient data at the clinician as tÃÉ = [tÃÉ1 , . . . , tÃÉn ] . The clinician scales each element of tÃÉ by c1 > 0 to avoid quantization

60

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 1, JANUARY 2014

c31 c6,s in (21) in the plain domain. Since c1 t is available at
the server only in the encrypted domain [i.e., (20)], the server
needs to exploit the homomorphic properties to compute the
term (2c21 Œ≥xs ) (c1 t) in (21) in the encrypted domain. Let us
define xs = [xs,1 , . . . , xs,n ] , s ‚àà S. Now, the server computes
the term (2c21 Œ≥xs ) (c1 t) in (21) in the encrypted domain as


 n


2

2
(2c1 Œ≥xs,i )(c1 ti ) ,
[[(2c1 Œ≥xs ) (c1 t)]] =
i=1

=

n


2

[[c1 ti ]]2c 1 Œ≥ x s , i .

(22)

i=1

Fig. 4. Privacy-preserving decision support system based on an SVM. The
clinician supplies patient data in the encrypted format to the server.

errors during the encryption. Then, the
 the
 clinician encrypts
scaled patient data and sends [[c1 tÃÉ]] = [[c1 tÃÉ1 ]], . . . , [[c1 tÃÉn ]] and
the corresponding public key to the server (see Fig. 4). Now, the
server will obtain the scaled and normalized patient data in the
encrypted domain using (2) and homomorphic properties as

 

c1 tÃÉ ‚àí c1 xÃÑ
c1 tÃÉ c1 xÃÑ
‚àí 2 .
=
(17)
[[c1 t]] =
œÉ2
œÉ2
œÉ


Let us define a mean vector xÃÑ = [xÃÑ1 , . . . , xÃÑn ] and normalized
patient data as t = [t1 , . . . , tn ] . Hence, each element of (17) is
given by


c1 tÃÉi
c1 xÃÑi
‚àí 2
‚àÄi.
(18)
[[c1 ti ]] =
œÉ2
œÉ
Since the server knows the vector xÃÑ, and scalars c1 (assuming
both the server and clinician know c1 ) and œÉ in the plain domain,
the server can easily compute the values ‚àí cœÉ1 x2¬Øi = (‚àí1). cœÉ1 x2¬Øi ‚àÄi
and encrypt each of its components by exploiting homomorphic
properties [[(‚àí1). cœÉ1 x2¬Øi ]] = [[ cœÉ1 x2¬Øi ]](‚àí1) , ‚àÄi. Similarly, encryption
1
of cœÉ1 2tÃÉ i can be obtained as [[ cœÉ1 2tÃÉ i ]] = [[c1 tÃÉi ]] œÉ 2 ‚àÄi. Hence, the
scaled and normalized value of the patient data in (18) can be
obtained in the encrypted domain as follows:


 c xÃÑ (‚àí1)
1
c1 tÃÉi
c1 xÃÑi
1 i
œÉ2 .
‚àí
]]
‚àÄi.
tÃÉ
=
[[c
[[c1 ti ]] =
1 i
œÉ2
œÉ2
œÉ2
(19)
Note that every computation in (19) can be performed by the
server without interacting with the clinician. Now, the server
can use the encrypted, normalized, and scaled patient data
[[c1 t]] = [[[c1 t1 ]], . . . , [[c1 tn ]]]

(20)

to compute (13).
2) Computing (c5,s + c6,s ‚àí Œ≥t t + 2Œ≥xs t) in (13): To do
this, let us raise the power of (13) by c31 to yield




(d2,s )c 1 = ec 1 (c 5 , s +c 6 , s ‚àíŒ≥ t t+2Œ≥ x s t) , s ‚àà S,
3

3

3

3

2



= ec 1 c 5 , s +c 1 c 6 , s +(2c 1 Œ≥ x s ) (c 1 t)‚àí(c 1 Œ≥ )
√ó (c1 t) (c1 t), s ‚àà S.

(21)

In (21), the server knows c1 , c5,s , c6,s , Œ≥, and xs , s ‚àà S in the
plain domain. Hence, the server can compute the term c31 c5,s +

Unfortunately, the server cannot compute the term
‚àí(c1 Œ≥)(c1 t) (c1 t) in (21) without interacting with the clinician. Hence, the server additively blinds the scaled and normalized patient data with uniformly distributed random vector
r = [r1 , . . . , rn ] to obtain [[tÃÇ]] = [[c1 t + r]] = [[c1 t]].[[r]]. Then,
the server sends [[tÃÇ]] to the clinician. The clinician decrypts the
received [[tÃÇ]] and obtains tÃÇ in the plain domain. Then, the clinician calculates tÃÇ tÀÜ, and encrypts and sends [[tÃÇ tÃÇ]] back to the
server. Now, the server extracts [[(c1 t) (c1 t)]] from [[tÃÇ tÃÇ]] using
homomorphic properties as follows:
[[(c1 t) (c1 t)]] = [[tÃÇ tÃÇ ‚àí 2c1 t r ‚àí r r]],
= [[tÃÇ tÃÇ]].[[‚àír r]].

n


[[c1 ti ]]‚àí2r i .

(23)

i=1

The server then computes [[‚àí(c1 Œ≥)(c1 t) (c1 t)]] using (23) and
the scalar ‚àíc1 Œ≥ as
[[‚àí(c1 Œ≥)(c1 t) (c1 t)]] = [[(c1 t) (c1 t)]]‚àíc 1 Œ≥ .

(24)

After obtaining all the terms, the server can compute the whole
term c31 c5,s + c31 c6,s + (2c21 Œ≥xs ) (c1 t) ‚àí (c1 Œ≥)(c1 t) (c1 t) in
(21) in the encrypted domain using the homomorphic properties
as
[[c31 c5,s + c31 c6,s + (2c21 Œ≥xs ) (c1 t) ‚àí (c1 Œ≥)(c1 t) (c1 t)]]
= [[c31 c5,s + c31 c6,s ]].[[(2c21 Œ≥xs ) (c1 t)]].[[‚àí(c1 Œ≥)(c1 t) (c1 t)]].
(25)
3) Exponentiation Using Secure Two-Party Computations:
The only part left is exponentiation of c31 c5,s + c31 c6,s +
(2c21 Œ≥xs ) (c1 t) ‚àí (c1 Œ≥)(c1 t) (c1 t) to obtain (21). Since (25)
is in the encrypted domain, the server cannot do the exponentiation as in (21) and thus will interact with the clinician to complete this exponentiation. The server sends (25) to the clinician,
who decrypts and obtains c31 c5,s + c31 c6,s + (2c21 Œ≥xs ) (c1 t) ‚àí
(c1 Œ≥)(c1 t) (c1 t). Then, the clinician divides the decrypted component by c31 and obtains c5,s + c6,s + (2Œ≥xs ) (t) ‚àí (Œ≥)(t) (t).
It is worth noting that the values c5,s and c6,s have been used
as a scaling factor and masking factor, respectively, to protect (2Œ≥xs ) (t) ‚àí (Œ≥)(t) (t). Note that c5,s + c6,s < c3 and the
range of c6,s must be the same as the range of xi xj , ‚àÄi, j. Since
the range c6,s is the same as the range of xs t (i.e., xs xs ),
the clinician cannot extract any useful information from the
decrypted c5,s + c6,s + (2Œ≥xs ) (t) ‚àí (Œ≥)(t) (t). Note, that for

RAHULAMATHAVAN et al.: PRIVACY-PRESERVING CLINICAL DECISION SUPPORT SYSTEM

every component of (13) a fresh random value c6,s must be
generated.
Now,
the
clinician
computes
and
encrypts


ec 5 , s +c 6 , s +(2Œ≥ x s ) (t)‚àí(Œ≥ )(t) (t) and returns it to the server.
The server has received (13) in the encrypted domain (i.e.,


[[ec 5 , s +c 6 , s +(2Œ≥ x s ) (t)‚àí(Œ≥ )(t) (t) ]], s ‚àà S), so it can compute (15)
in the encrypted domain as










[d(t)]] =
d1,s d2,s + d3 = [d3 ]
d1,s d2,s ,
s‚ààS

= [d3 ]



s‚ààS

[d1,s d2,s ] = [d3 ]



s‚ààS

[d2,s ]d 1 , s .

(26)

s‚ààS

In order to complete the classification, the server needs to compute (16). Since d(t) is in the encrypted domain [i.e., (26)],
the server needs to obtain the sign of an encrypted number to
complete this.
4) Obtaining the Sign of an Encrypted Value: Let us denote
two strings yes and no to represent the decision. Assume that
if the sign of d(t) is positive, then the decision for the given
patient data is yes and if the sign of d(t) is negative, then the
decision for the given patient data is no. Since the server has
the value of d(t) in the encrypted domain as in (26), we show
in this section how to obtain the decision for the patient data in
the encrypted domain. Let us assume that | d(t) |< 10l , l ‚àà Z
in the plain domain. Note that since the training and test data
samples are normalized, the value of l can be determined using
the scale factor c2 ec 3 used in (8).
Now, the server computes a new variable in the encrypted
domain as
  

(27)
[z]] = 10l + d(t) = 10l . [d(t)]] .
Since |d(t)| < 10l , the most significant digit of z is either 1
(i.e., if d(t) > 0) or 0 (i.e., if d(t) > 0). Let us denote the most
significant digit of z as zÃÉ ‚àà {1, 0}. Hence, the decision (Dec),
can be obtained as
Dec = zÃÉ.(yes ‚àí no) + no.

(28)

The most significant digit zÃÉ could be computed using the following linear operation:


(29)
zÃÉ = 10‚àíl . z ‚àí (z mod 10l )
where subtraction sets the least significant digits of z to 0 while
the multiplication shifts the most significant digit down. Since
the z in (27) is in the encrypted domain the server needs to obtain
the zÃÉ in (29) in the encrypted domain. This can be performed as
follows:



[zÃÉ]] = 10‚àíl . z ‚àí (z mod 10l ) ,

 ‚àí1 10 ‚àíl

.
(30)
= [z]] . z mod 10l
However the z available at the server is encrypted, thus similar to
the process leading to the server being able to compute (26), the
server engages the clinician in a secure two-party computation
protocol to compute [[z mod 10l ]].

61

The server blinds [[z]] using a uniformly distributed random
value r as [[zr ]] = [[z + r]] = [[z]].[[r]], and this is sent to the clinician who decrypts [[zr ]] and reduces zr mod 10l . The result i.e.,
[[zr mod 10l ]] is then encrypted and returned to the server who
retrieves [[z mod 10l ]] as

 
 
 ‚àí1 10 l
z mod 10l = z + r mod 10l . r mod 10l
[Œª]]
where Œª ‚àà {0, 1} is used to avoid underflow (i.e., Œª = 0
if z + r mod 10l > r mod 10l or Œª = 1 if z + r mod 10l <
r mod 10l ). The server knows z + r mod 10l in the plain domain while the clinician knows r mod 10l in the plain domain.
Comparing two integers in encrypted domain has been widely
studied in the literature [26]. Now, the server can compute [[zÃÉ]]
using (30). The obtained [[zÃÉ]] can be used in (28) to obtain the
decision for the patient data in the encrypted domain, as follows:
[ Dec]] = [zÃÉ.(yes ‚àí no) + no]] = [zÃÉ]](y es‚àín o) . [no]] .

(31)

Now [[ Dec]] can be returned to the clinician who decrypts it to
find the decision of the patient data (see Fig. 4).
C. Information Leakage
In the proposed algorithm, the private key resides at the
clinician side; hence, it is not possible for the remote server
which participates in this classification operation to decrypt
the test sample or the classification result. However, the remote server interacts with the clinician when the homomorphic
properties of Paillier cryptography are not sufficient to complete the task. During the interaction any encrypted values sent
by the server could be decrypted by the clinician. It is possible to formally analyze whether this interaction can reveal any
server side parameters to the clinician. The server first interacts with the clinician to compute [[(c1 t) (c1 t)]] from [[(c1 t)]]
[see between (22) and (23)]. If the server sends [[(c1 t)]] without
any preprocessing, then it may become possible for the clinician to infer the normalization parameters using (17). However, the sever sends only [[tÃÇ]] = [[c1 t + r]], where the addition
of random variables r = [r1 , . . . , rn ] makes it infeasible for
the clinician to extract any information about the normalization parameters from tÃÇ. Second, the server interacts with the
clinician to exponentiate the encrypted value as described in
Section III-B3, where the server adds a random value c6,s in
c5,s + c6,s + (2Œ≥xs ) (t) ‚àí (Œ≥)(t) (t) and the range of c5,s is
the same as the range of (Œ≥xs ) (xs ). Note that for every support vector, c6,s is generated freshly. Hence, this randomization
makes it infeasible for the clinician to extract any server side
parameters. However, this interaction reveals the number of
support vectors used for classification. Since there is no relation between the size of the dataset and the number of support
vectors used for classification, this leakage is not a breach to
privacy of the dataset used in the training phase. Finally, the
server interacts with the clinician for modulo reduction in order
to obtain the sign of the decision function d(t) [see between
(27) and (31)]. Since, d(t) is included in z in (27), revealing
z may leak the decision function value to the clinician. Hence,
the server adds a random value r to z before sending it to the
clinician. Again, this randomization makes it infeasible for the

62

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 1, JANUARY 2014

TABLE II
SOME EXAMPLES OF NORMALIZED TRAINING SAMPLES OF THE WBC AND PID DATASETS

TABLE III
CLASSIFICATION RESULTS FOR THE WBC DATASET FOR DIFFERENT VALUES OF Œ≥ IN THE PLAIN DOMAIN

TABLE IV
CLASSIFICATION RESULTS FOR THE PID DATASET FOR DIFFERENT VALUES OF Œ≥ IN THE PLAIN DOMAIN

clinician to extract any server side information. Overall, our
proposed method not only preserves the privacy of the patient
information but also the server side classification parameters.

conduct an experiment in the plain domain. Later, we do the
same experiment in the encrypted domain for various scaling
factors.
A. Experiments in the Plain Domain

IV. PERFORMANCE ANALYSIS
In this section, we analyze the performance of the proposed encrypted-domain algorithm. We compare the accuracy
of the proposed encrypted-domain method with the conventional plain-domain method. For the experiment, we consider
two datasets from the UCI machine learning repository called
the Wisconsin Breast Cancer (WBC) and Puma Indian Diabetic
(PID) datasets [13], [27]. The WBC dataset contains 681 samples where 444 samples are benign (noncancerous) and 237
samples are malignant (cancerous), while the PID dataset contains 768 samples where 500 samples are malignant and 268
samples are benign. The number of features for each sample
in WBC and PID datasets are nine and eight, respectively (excluding class label attribute). Table II shows some examples of
training samples after normalization from the WBC and PID
datasets.
For evaluation, we used a leave-one-out approach [28], that
is, one sample is removed from the dataset and all the remaining
samples are used for training the SVM. The removed sample
will be used as patient data. This procedure will be repeated
for a different left-out sample each time until all the samples
are used. In order to analyze the proposed methods, we first

In all experiments, we assume that the training data are not
linearly separable and therefore we use the Gaussian kernel
method as in (6). Initially, we need to determine empirically an
appropriate value for Œ≥ in (6). Hence, we have obtained Tables III
and IV for the WBC and PID datasets, respectively, in the plain
domain using the method described in Section II. These tables
show the classification accuracy for various Œ≥ values. Let us
explain the sixth result column (i.e., Œ≥ = 10) in Table III. When
Œ≥ = 10, the total number of correctly classified benign samples
is 433 out of 444 (97.52%) and that of malignant samples is
229 out of 237 (90.72%). In total, 662 samples were correctly
classified out of 681 (97.21%). Similarly, when Œ≥ = 15 for PID
dataset as in Table IV, the total number of correctly classified
benign samples is 482 out of 500 (96.40%) and that of malignant
samples is 239 out of 268 (89.17%). In total 721 samples were
correctly classified out of 768 (93.88%). Since Œ≥ = 10 for WBC
dataset and Œ≥ = 15 for PID dataset provide higher accuracy than
other values in this experiment, without loss of generality, we
use Œ≥ = 10 for WBC dataset and Œ≥ = 15 for PID dataset for
the experiments in the encrypted domain. We also noted that
the average number of support vectors used for WBC and PID
datasets are 205 and 535, respectively.

RAHULAMATHAVAN et al.: PRIVACY-PRESERVING CLINICAL DECISION SUPPORT SYSTEM

TABLE V
CLASSIFICATION RESULTS FOR THE WBC AND PID DATASETS IN THE
ENCRYPTED DOMAIN WHEN c3 = 10

63

TABLE VI
CONVERSION TABLE FOR c5 , s

when the classification is conducted in the encrypted domain
for appropriate scaling factors.
C. Analysing the Factors Related to Accuracy

B. Experiments in the Encrypted Domain
We have now evaluated our algorithm with 2048-bit key size.
We tested our proposed privacy-preserving algorithm in a computer with 3.40 GHz processor and 8 GB of RAM running on
Windows 64-bit operating system. The algorithm is written in
C++ using GNU GMP library version 4.2.4. Both the server and
clinician were modeled as different threads of a single program,
which passes variables to each other.
As we mentioned in Section III-B, the scaling factors
c1 , c2 , c3 , and c5,s have influence on the classification accuracy in the encrypted domain due to the fact that the Paillier
cryptosystem only encrypts integers. When we set c1 = 1, c2 =
1, c3 = 0, and c5,s = 0, the classification accuracy reduced to
0%, which shows the importance of the scaling factor in the
encrypted domain.
Scalar c1 is a linear scalar and has been used to scale the
patient data in (20). We noted that each element of the normalized training samples of the WBC and PID datasets are in the
range of ¬±10‚àí4 (see Table II); hence, we have chosen c1 = 104 .
Scalar c2 is also a linear scalar and it has been used in (12) and
(14). In order to get six decimal-point accuracy, we have chosen c2 = 106 in all the experiments. Scalar c3 is an exponential
scalar and used in (12) and (14). The Paillier cryptosystem only
encrypts integers in Zn ; hence, 0 < c3 < loge (n). The scalar
c5,s must be chosen such that c5,s + c6,s < c3 , where c6,s is a
masking factor in the range of xi xj ‚àÄi, j. Next, we obtain a
classification accuracy for different values of scaling factors.
Table V shows the accuracies in the encrypted domain for
different values of c5,s when c3 = 10. The scalar c5,s can take
any value between 0 and c3 and is not necessarily an integer. For
the WBC dataset, the classification accuracy in the encrypted
domain is equal to the classification accuracy in the plain domain when 5 ‚â§ c5,s ‚â§ 9 (i.e., Œ≥ = 10; see column in Table III).
Similarly, for the PID dataset, the classification accuracy in the
encrypted domain is equal to the classification accuracy in the
plain domain when 7 ‚â§ c5,s ‚â§ 9 (i.e. Œ≥ = 15; see column in Table IV). However, the performance of the encrypted-domain algorithm deteriorates when c5,s > 3 (c5,s > 5) for WBC dataset
(PID dataset) due to the quantization effect of the Paillier encryption. Hence, the decision function becomes independent of
the patient data and provides infeasible results. Overall, the proposed method does not degrade the classification accuracy even

Equation (6) clearly shows that the classification function
only depends on the number of support vectors (i.e., |S|) and
the corresponding Œ±s ‚àÄs and b. Hence, after the training phase,
the classification task becomes independent of the size of the
dataset.
In the encrypted-domain classification equation, d1,s ‚àÄs and
d3 can be calculated by the server in the plain domain. Since the
test sample t given to the server is in the encrypted format, d2,s
‚àÄs need to be computed by the server in the encrypted domain
by interacting with the clinician. Hence, let us closely look at




d2,s = ec 5 , s ec 6 , s ‚àíŒ≥ t t+2Œ≥ x s t = ec 5 , s +c 6 , s ‚àíŒ≥ t t+2Œ≥ x s t , where the
server computes c5,s + c6,s ‚àí Œ≥t t + 2Œ≥xs t in the encrypted
domain. Since the Paillier cryptography approximates the values
to integers (floor values) before encryption, it is crucial to scale
the values in the test sample t and support vectors xs . Scalar c1
has been used to scale the test sample and c5,s has been used to
scale the c6,s ‚àí Œ≥t t + 2Œ≥xs t. Scalar c2 has been used to avoid
the approximation errors in d1,s and d3 . Hence, classification
errors due to integer replacements during the Paillier encryption
are solely dependent on choices of these scalars in the encrypted
domain.
The choice of c1 depends on values in the test sample and support vectors. Table II shows that these values are in the range of
¬±10‚àí4 and that there was no significant improvement in the performance when we used more than four decimal points. Hence,
the error is dependent on how many decimal points would be
enough to get a good accuracy. Which means, if there is no significant increment in the performance then using more decimal
points in values will not be useful. Since there is no significant
improvement in the performance beyond four decimal points c1
has chosen to be 104 .
As shown in Section III-B3, ec 5 , s has been used to scale
c 6 , s ‚àíŒ≥ t  t+2Œ≥ x s t
. Hence, the classification error is dependent on
e
the value ec 5 , s too. Table VI depicts the required c5,s for various
decimal value accuracy (i.e., e2.3026 = 101 ).
In our experiment, there is no improvement in performance
beyond three decimal point accuracy for c5,s (i.e., c5,s > 6.9).
Similarly, c2 has been fixed to 106 . Overall, there will not be significant improvement in the accuracy even if we increase these
scalars beyond the values mentioned earlier. However, from (6)
and (8), it is obvious that the accumulated error of the decision
function (i.e., d(t)) due to the wrong choice of c1 (i.e., if c1 =
102 ) is proportional to the number of support vectors √ó
edim ension of data and the accumulated error in the decision function due to the wrong choice of c2 and c5,s being proportional
to the number of support vectors.

64

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 1, JANUARY 2014

D. Communication Complexity
The communication cost of the proposed algorithm depends
highly on the size of Paillier cryptography; in our implementation the size of an encrypted sample is 2048 bits long. Sending
an encrypted test sample with N number of features consumes
2.048N kbits of bandwidth in the communication channel. In
the proposed algorithm, the server interacts with the clinician
for three times. During the second interaction (i.e., for exponentiation) the server sends |S| number of encrypted values (i.e.,
equal to the total number of support vectors), while in the first
and last interaction the server sends only one value. Hence,
the communication cost for our algorithm is upperbounded by
the second interaction which requires 2.048|S|kbits of bandwidth. Since the number of support vectors should be less
than the size of the dataset, the worse case bandwidth requirement for both WBC and PID datasets are 0.174 and 0.197MB,
respectively.
E. Computation Complexity
We measure the computation complexity in terms of the average runtime required for the proposed algorithm when the
size of the security parameter N = 2048. The average time required for WBC and PID datasets are 41 and 92 s, respectively.
It is noted that the average time is increasing linearly, with the
number of support vectors used for the classification.
V. RELATED WORK
In general, data classification is a combination of two phases:
training phase and testing phase. The first phase, training a
classifier, requires a large collection of data. There are various
organizations which publish their customers‚Äô data for research
and monetary purposes. Publishing person-specific dataset (e.g.,
data related to patients of a cancer hospital) may reveal an individual‚Äôs identity and breach the privacy of patients. However,
there are various privacy preserving techniques (i.e., anonymization techniques and data perturbation techniques) have been well
studied in the literature to preserve the privacy of individuals
in the datasets (see [29]‚Äì[31] and references therein). However,
the proposed study in this paper considers the privacy in the
second phase of the data classification task, where clinicians
only require to send the test data of their patient to the remote
server where the classifier is already established. Since the proposed method preserves the privacy of the training dataset, it is
possible for any organization with large data to provide a classification as a service to anybody through the Internet rather than
anonymize and publish the dataset in a plain domain. Hence,
our method is different from the data anonymization and data
perturbation-based methods.
An SVM has been used in biomedical engineering to diagnose
various diseases in the plain domain ( [9]‚Äì[11] and references
therein). Note that, any algorithm in the plain domain cannot
be used to provide decision support via the Internet due to the
privacy issue. Recently, Mathew and Obradovic proposed a privacy preserving framework for clinical decision support using a
decision tree-based machine learning technique [32]. The study

in [32] supports the prevention of personally identifiable information leakage. However, the authors in [32] only considered
the privacy of the training dataset by assuming that the training
data is available from more than one location. In our study, we
are not only preserving the privacy of the training dataset, but
also the patient data and the result. Moreover, the algorithm developed for the decision tree cannot be directly extended to an
SVM.
Let us review some of the privacy-preserving SVM algorithms developed in the data mining literature. The majority of
studies in datamining were developed for the distributed setting
[33]‚Äì[36]. More specifically, in [33]‚Äì[36], the researchers assumed that different parties hold parts of the training datasets.
Hence, they developed protocols to securely train a common
classifier without each party needing to disclose its own training data to other parties. After the training, each party holds a
part of the classification parameters and support vectors. In order to classify new data, each party has to be involved, equally,
to compute a part of the kernel matrix, and then all parties together or the trusted third party will classify the new data. The
works in [34]‚Äì[36] exploited the secure multiparty integer summation to cooperatively compute the kernel matrix. Basically,
each party generates the Gramm matrix using scalar products of
the training and new data samples. This Gramm matrix is later
revealed to the trusted third party which will compute the kernel
matrix and then classify the new data. Revealing the Gramm
matrix may leak the private data and therefore privacy cannot
be entirely preserved.
The study in [33] proposed, for the first time, a strong privacyenhanced protocol for a polynomial kernel-based SVM using
cryptographic primitives; where the authors assumed that the
training data are distributed. Hence, to preserve privacy, they developed a protocol to perform secure kernel sharing, prediction,
and training using secret sharing and homomorphic encryption
techniques. At the end of the training each party will hold a share
of the secret. In the testing phase, all parties collaboratively perform the classification using their shared secrets. At the end of
the protocol each party will hold a share of the predicted class
label. Since the work is based on secret sharing, all the parties
must be involved in every operation of calculating the kernel
values and predicting the class. Hence, it is suitable only for
the distributed scenario and not for the client-server model considered in this paper. In the client-server model, the client just
sends the new data in the encrypted domain and is minimally
involved in interactions with the server during the classification
process. Moreover, the method developed in [33] considered
only the polynomial kernel and so it cannot be modified directly
to work with the Gaussian kernel-based SVM considered in this
paper as these kernel functions are of different forms.
The recent study in [37] discusses the issue of releasing the
trained SVM classifier without violating the privacy of support
vectors. While the Gaussian kernel was considered, a Taylor
series was exploited to approximate the infinite dimension of
the Gaussian kernel into finite dimension subject to negligible
performance loss. Since this works purely in the plain domain,
it cannot be modified to the clinician-server scenario considered
in this paper.

RAHULAMATHAVAN et al.: PRIVACY-PRESERVING CLINICAL DECISION SUPPORT SYSTEM

VI. CONCLUSION
In this paper, we have proposed a privacy-preserving decision support system using a Gaussian kernel based SVM. Since
the proposed algorithm is a potential application of emerging
outsourcing techniques such as cloud computing technology,
rich clinical datasets (or healthcare knowledge) available in remote locations could be used by any clinician via the Internet
without compromising privacy, thereby enhancing the decisionmaking ability of healthcare professionals. We have exploited
the homomorphic properties of the Paillier cryptosystem within
our algorithm, where the cryptosystem only encrypts integer
values. Hence, we proposed a novel technique to scale the continuous variables involved in the process without compromising
the performance and privacy. To validate the performance, we
have evaluated our method on two medical datasets and the results showed that the accuracy is up to 97.21%. Importantly,
the benefit of our encrypted-domain method is that patient data
need not be revealed to the remote server as they can remain in
encrypted form at all times, even during the diagnosis process.
REFERENCES
[1] A. X. Garg, N. J. Adhikari, H. McDonald, M. P. Rosas-Arellano,
P. J. Devereaux, J. Beyene, J. Sam, and R. B. Haynes, ‚ÄúEffects of computerized clinical decision support systems on practitioner performance and
patient outcomes: A systematic review,‚Äù J. Amer. Med. Assoc., vol. 293,
no. 10, pp. 1223‚Äì1238, 2005.
[2] E. R. Carson, D. G. Cramp, A. Morgan, and A. V. Roudsari, ‚ÄúClinical
decision support, systems methodology, and telemedicine: Their role in
the management of chronic disease,‚Äù IEEE Trans. Inf. Technol. Biomed.,
vol. 2, no. 2, pp. 80‚Äì88, Jun. 1998.
[3] P. J. Lisboa and A. F. G. Taktak, ‚ÄúThe use of artificial neural networks in
decision support in cancer: A systematic review,‚Äù Neural Netw., vol. 19,
pp. 408‚Äì415, 2006.
[4] V. Baskaran, A. Guergachi, R. K. Bali, and R. N. G. Naguib, ‚ÄúPredicting
breast screening attendance using machine learning techniques,‚Äù IEEE
Trans. Inf. Technol. Biomed., vol. 15, no. 2, pp. 251‚Äì259, Mar. 2011.
[5] H. Shin and M. K. Markey, ‚ÄúA machine learning perspective on the development of clinical decision support systems utilizing mass spectra of
blood samples,‚Äù J. Biomed. Informat., vol. 39, no. 2, pp. 227‚Äì248, 2006.
[6] S. Sundareswaran, A. C. Squicciarini, and D. Lin, ‚ÄúEnsuring distributed
accountability for data sharing in the cloud,‚Äù IEEE Trans. Dependable
Secure Comput., vol. 9, no. 4, pp. 555‚Äì567, Jul./Aug. 2012.
[7] S. Pearson and A. Charlesworth, ‚ÄúAccountability as a way forward for
privacy protection in the cloud,‚Äù in Proc. 1st Int. Conf. Cloud Comput.,
Beijing, China, 2009, pp. 131‚Äì144.
[8] S. Pearson, Y. Shen, and M. Mowbray, ‚ÄúA privacy manager for cloud
computing,‚Äù in Proc. Int. Conf. Cloud Comput., Beijing, China, 2009,
pp. 90‚Äì106.
[9] N. Barakat, A. P. Bradley, and M. N. H. Barakat, ‚ÄúIntelligible support
vector machines for diagnosis of diabetes mellitus,‚Äù IEEE Trans. Inf.
Technol. Biomed., vol. 14, no. 4, pp. 1114‚Äì1120, Jul. 2010.
[10] P. O. Ajemba, L. Ramirez, N. G. Durdle, D. L. Hill, and V. J. Raso, ‚ÄúA
support vectors classifier approach to predicting the risk of progression of
adolescent idiopathic scoliosis,‚Äù IEEE Trans. Inf. Technol. Biomed., vol. 9,
no. 2, pp. 276‚Äì282, Jun. 2005.
[11] I. Guler and E. D. Ubeyli, ‚ÄúMulticlass support vector machines for EEGsignals classification,‚Äù IEEE Trans. Inf. Technol. Biomed., vol. 11, no. 2,
pp. 117‚Äì126, Mar. 2007.
[12] C.-W. Hsu, C.-C. Chang, and C.-J. Lin, ‚ÄúA practical guide to support vector
classification,‚Äù Dept. Comp. Sci., Nat. Taiwan Univ., Taipei, Taiwan, 2010.
[13] K. Bache, and M. Lichman. (2013). UCI Machine Learning Repository,
Available: http://archive.ics.uci.edu/ml. Irvine, CA: University of California, School of Information and Computer Science.

65

[14] P. Paillier, ‚ÄúPublic-key cryptosystems based on composite degree residuosity classes.‚Äù in Advances in Cryptology‚ÄîEUROCRYPT‚Äô99. Springer,
Berlin, Heidelberg, 1999.
[15] O. Goldreich, ‚ÄúSecure Multiparty Computation,‚Äù (working draft), Sep.
1998. Available: http://www.wisdom.weizmann.ac.il/‚àºoded/pp.html
[16] C. Cortes and V. Vapnik, ‚ÄúSupport-vector networks,‚Äù Mach. Learn.,
vol. 20, no. 3, pp. 273‚Äì297, 1995.
[17] V. Vapnik, ‚ÄúAn overview of statistical learning theory,‚Äù IEEE Trans. Neural Netw., vol. 10, no. 5, pp. 988‚Äì999, Sep. 1999.
[18] S. Tong and D. Koller, ‚ÄúSupport vector machine active learning with
applications to text classification,‚Äù J. Mach. Learn. Res., vol. 2, pp. 45‚Äì
66, 2002.
[19] I. Kotsia and I. Pitas, ‚ÄúFacial expression recognition in image sequences
using geometric deformation features and support vector machines,‚Äù IEEE
Trans. Image Process., vol. 16, no. 1, pp. 172‚Äì187, Jan. 2007.
[20] S. Bergsma, D. Lin, and D. Schuurmans, ‚ÄúImproved natural language
learning via variance-regularization support vector machines,‚Äù in Proc.
14th Conf. Comput. Natural Lang. Learn., Stroudsburg, PA, USA, 2010,
pp. 172‚Äì181.
[21] A. Ben-Hur, C. Ong, S., S. Sonnenburg, B. Scholkopf, and G. Ratsch,
‚ÄúSupport vector machines and kernels for computational biology,‚Äù PLoS
Comput. Biol., vol. 4, no. 10, pp. 1‚Äì10, 2008.
[22] S. Boyd and L. Vandenberghe, Convex Optimization. Cambridge, U.K.:
Cambridge Univ. Press, 2004.
[23] V. Vapnik, The Nature of Statistical Learning Theory. New York, NY,
USA: Springer-Verlag, 1995.
[24] Z. Erkin, M. Franz, J. Guajardo, S. Katzenbeisser, I. Lagendijk, and T. Toft,
‚ÄúPrivacy-preserving face recognition,‚Äù in Proc. 9th Int. Symp. Privacy
Enhanc. Technol., Seattle, WA, USA, 2009, pp. 235‚Äì253.
[25] Y. Rahulamathavan, R. C.-W. Phan, J. A. Chambers, and D. J. Parish,
‚ÄúFacial expression recognition in the encrypted domain based on local
fisher discriminant analysis,‚Äù IEEE Trans. Affect. Comput., vol. 4, no. 1,
pp. 83‚Äì92, Jan.‚ÄìMar. 2013.
[26] I. DamgaÃärd, M. Geisler, and M. Kr√∏igaard, ‚ÄúEfficient and secure comparison for online auctions,‚Äù in Proc. 12th Australias Conf. Inf. Security
Privacy, Townsville, Australia, 2007, pp. 416‚Äì430.
[27] O. L. Mangasarian, W. N. Street, and W. H. Wolberg, ‚ÄúBreast cancer diagnosis and prognosis via linear programming,‚Äù Oper. Res., vol. 43, pp. 570‚Äì
577, Jul./Aug. 1995.
[28] G. C. Cawley and N. L. C. Talbot, ‚ÄúEfficient leave-one-out crossvalidation of kernel fisher discriminant classifiers,‚Äù Pattern Recognit.,
vol. 36, no. 11, pp. 2585‚Äì2592, 2003.
[29] X.-B. Li and S. Sarkar, ‚ÄúA tree-based data perturbation approach for
privacy-preserving data mining,‚Äù IEEE Trans. Knowl. Data Eng., vol. 18,
no. 9, pp. 1278‚Äì1283, Sep. 2006.
[30] B. C. M. Fung, K. Wang, and P. S. Yu, ‚ÄúAnonymizing classification data
for privacy preservation,‚Äù IEEE Trans. Knowl. Data Eng., vol. 19, no. 5,
pp. 711‚Äì725, May 2007.
[31] M. Yuan, L. Chen, P. S. Yu, and T. Yu, ‚ÄúProtecting sensitive labels in social
network data anonymization,‚Äù IEEE Trans. Knowl. Data Eng., vol. 25,
no. 3, pp. 633‚Äì647, Mar. 2013.
[32] G. Mathew and Z. Obradovic, ‚ÄúA privacy-preserving framework for distributed clinical decision support,‚Äù in Proc. IEEE 1st Int. Conf. Comput.
Adv. Bio. Med. Sci., 2011, pp. 129‚Äì134.
[33] H. Lipmaa, S. Laur, and T. Mielikainen, ‚ÄúCryptographically private
support vector machines,‚Äù in Proc. 12th ACM SIGKDD Int. Conf.
Knowl. Discov. Data Mining. Philadelphia, PA, USA, Aug. 2006, pp.
618‚Äì624.
[34] H. Yu, X. Jiang, and J. Vaidya, ‚ÄúPrivacy-preserving support vector machine
using nonlinear kernels on horizontally partitioned data,‚Äù in Proc. ACM
Symp. Appl. Comput., Dijon, France, 2006, pp. 603‚Äì610.
[35] H. Yu, J. Vaidya, and X. Jiang, ‚ÄúPrivacy-preserving SVM classification
on vertically partitioned data,‚Äù in Proc. 10th Pacific-Asia Conf. Knowl.
Discov. Data Mining, Singapore, 2006, pp. 647‚Äì656.
[36] K. Chen and L. Liu, ‚ÄúPrivacy preserving data classification with rotation
perturbation,‚Äù in Proc. 5th IEEE Int. Conf. Data Mining, Washington, DC,
USA, 2005, pp. 589‚Äì592.
[37] K.-P. Lin and M.-S. Chen, ‚ÄúOn the design and analysis of the privacypreserving SVM classifier,‚Äù IEEE Trans. Knowl. Data Eng., vol. 23, no. 11,
pp. 1704‚Äì1717, Nov. 2011.

66

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 18, NO. 1, JANUARY 2014

Yogachandran Rahulamathavan (S‚Äô08‚ÄìM‚Äô12) received the B.Sc. degree (with first-class Hons.) in
electronic and telecommunication engineering from
the University of Moratuwa, Moratuwa, Sri Lanka, in
2008, and the Ph.D. degree in mathematical optimization techniques for signal processing from Loughborough University, Leicestershire, U.K., in 2011.
He is currently a Research Fellow with the Information Security Group, School of Engineering
and Mathematical Sciences, City University London,
London, U.K. From April 2008 to September 2008,
he was an Engineer with Sri Lanka Telecom, Sri Lanka, and from November
2011 to March 2012, he was a Research Assistant with the Advanced Signal
Processing Group, School of Electronic, Electrical and Systems Engineering,
Loughborough University. His research interests include signal processing, machine learning, and information security and privacy.
Dr. Rahulamathavan received a scholarship from Loughborough University
to pursue the Ph.D. degree.

Suresh Veluru received the Ph.D. degree in computer science from the Indian Institute of Technology,
Guwahati, India, in 2009.
He is currently a Research Fellow with the School
of Engineering and Mathematical Sciences, City University London, London, U.K. Prior to this, he was
a Research Fellow with the Department of Computer
Science, University of York, Yorkshire, U.K., and
the University of New Brunswick, NB, Canada. His
research interests include pattern recognition, data
mining, natural language processing, artificial intelligence, and privacy preserving data mining.

Raphael C.-W. Phan received the Ph.D. (Eng) degree in cryptography.
He is currently a Professor of Engineering with
Multimedia University, Cyberjaya, Malaysia. Before
taking up his current position he was with Swinburne
University of Technology, Ecole Polytechnique Federale de Lausanne, Switzerland, and Loughborough
University, Leicestershire, U.K. His research interests include security and privacy, privacy preservation, and processing of data in the encrypted domain.
Dr. Phan is with the Editorial Board of Cryptologia, and the Cryptology and Information Security Series of IOS Press. He has
been the General Chair of Mycrypt 05 and Asiacrypt 07, Program Chair of
ISH 05, and has been serving in Technical Program Committees of International Conferences since 2005. He is a Codesigner of BLAKE, one of the five
hash functions in the final of the NIST SHA-3 competition.

Jonathon A. Chambers (S‚Äô83‚ÄìM‚Äô90‚ÄìSM‚Äô98‚ÄìF‚Äô11)
received the Ph.D. degree in signal processing from
the Imperial College of Science, Technology and
Medicine, Imperial College London, London, U.K.,
in 1990.
In 2007, he joined the Department of Electronic
and Electrical Engineering, Loughborough University, Loughborough, U.K., where he currently heads
the Advanced Signal Processing Group and serves as
the Associate Dean Research with the School of Electronic, Electrical, and Systems Engineering. From
1991 to 1994, he was a Research Scientist with Schlumberger Cambridge Research Center, Cambridge, U.K. In 1994, he returned to Imperial College London
as a Lecturer in Signal Processing and was promoted as a Reader (Associate
Professor) in 1998. From 2001 to 2004, he was the Director of the Centre for
Digital Signal Processing and a Professor of Signal Processing with the Division
of Engineering, King‚Äôs College London, London, U.K. From 2004 to 2007, he
was a Cardiff Professorial Research Fellow with the School of Engineering,
Cardiff University, Wales, U.K. He is a coauthor of the books Recurrent Neural Networks for Prediction: Learning Algorithms, Architectures, and Stability
(New York, NY, USA: Wiley, 2001) and EEG Signal Processing (New York,
NY, USA: Wiley, 2007). He has advised more than 50 researchers through their
Ph.D. Graduation and published more than 400 conference proceedings and
journal articles, many of which are in IEEE journals. His research interests
include adaptive and blind signal processing and their applications.
Dr. Chambers is a Fellow of the Royal Academy of Engineering, U.K., and
the Institution of Electrical Engineers. He was the Technical Program Chair of
the 15th International Conference on Digital Signal Processing (2007) and the
2009 IEEE Workshop on Statistical Signal Processing, both held in Cardiff,
U.K., and a Technical Program Cochair for the 36th IEEE International Conference on Acoustics, Speech, and Signal Processing (2011), Prague, Czech
Republic. He has received the first QinetiQ Visiting Fellowship in 2007 ‚Äúfor
his outstanding contributions to adaptive signal processing and his contributions to QinetiQ‚Äù as a result of his successful industrial collaboration with the
international defense systems company QinetiQ. He has served on the IEEE
Signal Processing Theory and Methods Technical Committee for six years and
is currently a member of the IEEE Signal Processing Society Awards Board and
the European Signal Processing Society Best Paper Awards Selection Panel. He
has also served as an Associate Editor of the IEEE TRANSACTIONS ON SIGNAL
PROCESSING for three terms over the periods 1997‚Äì1999, 2004‚Äì2007, and 2011(and is currently an Area Editor).

Muttukrishnan Rajarajan (M‚Äô02‚ÄìSM‚Äô05) received
the B.Eng. and Ph.D. degrees from City University
London, London, U.K., in 1994 and 1999, respectively.
He joined City University London in 2002, where
he is currently a Full Professor and also the Head
of the Information Security Research Group. He was
with City University London, as a Postdoctoral Research Fellow on a research project funded by the
Ministry of Defence . He moved to Logica, Reading,
U.K., in 2000 as a Network Security Consultant. He
acts as an Advisor to the Government of India Research Laboratories in the area
of cyber security. He is a Visiting Scientist at the British Telecommunications
Security Innovation Laboratories, U.K.He has been involved in several recent
policy debates in the area of cyber security. He has published more than 150
journal and conference papers and has recently published a book entitled Mobile Security and Privacy (Saarbruken, Germany: VDM Pub. Dr. Muller, Dec.
1, 2010). His research interests include privacy preserving techniques, mobile
security, and cloud security.
He is a member of the Academic Advisory Board of theInstitute of Information Security Professionals . He is in the advisory board of several startup companies in the area of cloud security and identity assurance. He serves
on several journal editorial boards and international conferences programme
committees.

