IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

1061

Semantic Normalization and Query Abstraction
Based on SNOMED-CT and HL7: Supporting
Multicentric Clinical Trials
Sergio Paraiso-Medina, David Perez-Rey, Anca Bucur, Brecht Claerhout, and Raul Alonso-Calvo

Abstract—Advances in the use of omic data and other biomarkers are increasing the number of variables in clinical research. Additional data have stratified the population of patients and require
that current studies be performed among multiple institutions. Semantic interoperability and standardized data representation are
a crucial task in the management of modern clinical trials. In
the past few years, different efforts have focused on integrating
biomedical information. Due to the complexity of this domain and
the specific requirements of clinical research, the majority of data
integration tasks are still performed manually. This paper presents
a semantic normalization process and a query abstraction mechanism to facilitate data integration and retrieval. A process based
on well-established standards from the biomedical domain and
the latest semantic web technologies has been developed. Methods
proposed in this paper have been tested within the EURECA EU
research project, where clinical scenarios require the extraction of
semantic knowledge from biomedical vocabularies. The aim of this
paper is to provide a novel method to abstract from the data model
and query syntax. The proposed approach has been compared with
other initiatives in the field by storing the same dataset with each of
those solutions. Results show an extended functionality and query
capabilities at the cost of slightly worse performance in query execution. Implementations in real settings have shown that following
this approach, usable interfaces can be developed to exploit clinical
trial data outcomes.
Index Terms—Clinical trials, data integration, HL7 and
SNOMED, omics, semantic interoperability.

I. INTRODUCTION
N THE past few years, research to enhance clinical practice
has been largely focused on introducing biomarkers in traditional guidelines. After designing omic-based clinical trials
[1], these studies are executed within international networks of
institutions, mainly due to a higher stratification of the population. In addition to a legal and political framework [2], such

I

Manuscript received January 9, 2014; revised June 16, 2014 and August
20, 2014; accepted August 31, 2014. Date of publication September 17, 2014;
date of current version May 7, 2015. This work was supported in part by the
European Commission through the INTEGRATE (FP7-ICT-2009-6-270253)
and the EURECA (FP7-ICT-2011-7-288048) project, and also by the Ministry
of Health of the Spanish Government under Grant PI13/02020.
S. Paraiso-Medina, D. Perez-Rey, and R. Alonso-Calvo are with the
Biomedical Informatics Group, DIA & DLSIIS, Universidad Politécnica
de Madrid, Madrid 28040, Spain (e-mail: sparaiso@infomed.dia.fi.upm.es;
dperez@infomed.dia.fi.upm.es; ralonso@infomed.dia.fi.upm.es).
A. Bucur is with Philips Research Europe, Eindhoven 5656 AE, The
Netherlands (e-mail: anca.bucur@philips.com).
B. Claerhout is with Custodix, Sint-Martens-Latem 9830, Belgium (e-mail:
brecht.claerhout@custodix.com).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2357025

multicentric settings require advanced methods to facilitate the
exploitation of clinical trial data obtained among heterogeneous
sources: Clinical Trial Management Systems, Electronic Health
Records (EHR) and Laboratory Management Systems, among
others. Purely central architectures are usually not applicable
within sustainable solutions [3], and legal constraints frequently
prevent data from leaving the clinical institution [4]. In practice,
although some data are stored in an electronic format, data capturing and transformation in current clinical trials are mainly
manually performed.
In this paper, a novel method to integrate and retrieve clinical data from different systems and institutions participating in
modern clinical trials is presented. Based on semantic interoperability standards and vocabularies, a distributed architecture to
integrate data sources is developed. The proposed normalization
approach aims to benefit from synergies between data models
and vocabularies. Knowledge stored within clinical vocabularies
and ontologies is exploited by a query abstraction mechanism
to facilitate data retrieval. The normalization process is based
on the most informative version to represent each concept.

II. BACKGROUND
Current advances in clinical research and care have increased
their separation, hindering the detection of patient safety issues [5], [6]. The main barriers are the lack of interoperability,
common standards, and terminologies [7]. In this context, previous projects on health research have been focused on heterogeneous biomedical integration such as Observational Medical
Outcomes Partnership (OMOP) [8], informatics for Integrating
Biology and the Bedside (i2b2) [9], cancer Biomedical Informatics Grid (caBIG) [10], INTEGRATE [11], and EURECA
[12], among others.
OMOP is a public–private initiative for monitoring drugs, devices, and procedures with the aim of improving patient care.
OMOP is based on an observational data model that stores patient information concerning adverse drug reactions. OMOP has
a wide community that offers an Extract, Transform and Load
(ETL) library, which allows for loading data from EHR systems.
The main advantage of OMOP is its simple data model.
I2b2 is a framework based on the Research Patient Data Registry developed at the Massachusetts General Hospital. I2b2
aims to enable researchers to use clinical data for knowledge
discovery. The architecture of the i2b2 approach is designed as
a set of services denominated cells that fit together in an integrated environment called hive. Every cell is defined by their

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

1062

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

function on the hive, i.e., a file repository cell, an ontology
management cell, data repository, etc. The data repository cell
is designed as the data warehouse to provide information to
users. I2b2 also includes an ontology cell responsible for the
management of the vocabulary.
caBIG is an open information network deployed in 2003 to
share data on cancer research. It is based on Open Grid Services
Architectures (OGSA) and OGSA-Data Access Integration [13].
Developed applications are heavily dependent on the GRIDbased infrastructure designed for caBIG, which makes it difficult
to reuse applications outside the caBIG environment.
The projects described previously have obtained valuable results, but there are still additional interoperability standards and
semantic web mechanisms that are not being fully exploited.
From this context emerged the EU research projects INTEGRATE “Driving excellence in integrative cancer research”
(FP7-ICT-2009-6-270253) and EURECA “Enabling information re-Use by linking clinical Research and CAre” (FP7-ICT2012-6-270253). Both projects aim to facilitate semantic interoperability among applications and tools to achieve data sharing
for breast cancer clinical trials.
These projects have a strong focus on maintainability and
use existing standards oriented to clinical research users. INTEGRATE and EURECA are based on the data source federation
following a Common Data Model (CDM) [14]. Data owners
maintain control of their own information, avoiding the high
complexity and costs of a purely distributed database approach
[3]. The CDM defines the schema of data stored on each node.
For this reason, there are several alternatives to represent clinical information, such as openEHR [15], Biomedical Research
Integrated Domain Group (BRIDG) [16], Clinical Data Interchange Standards Consortium (CDISC) [17], and Health Level
7 Reference Information Model (HL7 RIM) [18].
openEHR is an open standard that provides a common model
for management and data storing for health care. The main
goal of openEHR is to create open semantic systems that are
durable over time and economically viable. BRIDG is a “domain model representing protocol-driven biomedical/clinical research.” It was developed with the collaborative effort of clinical
trial experts from CDISC, US National Institute of Health (NIH),
Health Level 7 and others. The purpose of BRIDG is to support
the development of data interchange standards and technology
solutions in the healthcare area. CDISC, a Standard Development Organization, focuses on clinical research and supports
global, platform-independent data standards that enable information system interoperability to improve medical research and
related areas of healthcare.
HL7 [19] is an international organization focused on the standardization of the clinical and administrative domain providing
standards for interoperability on health care. HL7 RIM includes
most common healthcare domains and works as a general data
model for healthcare and clinical information. HL7 RIM is the
core of the HL7 v3 standard, defined as a class diagram aiming
to cover healthcare needs. The reference model is composed
of three main classes: Entity, Act, and Role and relationships
between these classes, Act Relationship and Participation. Any
clinical information, such as the diagnosis of a patient by a clin-

Fig. 1.

Proposed semantic solution approach in the EURECA project.

ician, is represented using these classes and relationships, e.g.,
two entities, participate in an observation act, playing the role
of clinician and patient.
Significant effort has been put forth to develop medical vocabularies for the semantic representation of the health domain
[18], [20]. One of the most relevant vocabularies is SNOMEDCT [21], a clinical vocabulary focused on recording health care
encounters and the associated electronic health information exchange. SNOMED-CT is a clinical vocabulary with over of
311 000 active medical concepts, nearly a million descriptions
and over a million relationships. SNOMED-CT also provides
mechanisms to identify postcoordinated concepts and to add
new expressions (e.g., it is possible to use the precoordinate
concept “Neoplasm of breast (disorder)” or the postcoordinated
“Neoplasm (morphologic abnormality)” and “Breast structure
(body structure)” with the same meaning). Due to the high generality of SNOMED-CT, more specific medical vocabularies are
required to fully cover data from clinical trials, such as Hugo
Gene Nomenclature Committee (HGNC) [22] and Logical Observation Identifiers Names and Codes (LOINC) [23]. One of
the main issues in this area is the development and maintenance
of large amounts of concepts present in medical vocabularies,
i.e., new concept versus postcoordination, overlapping hierarchy (branches), relationships of a new concept, etc. The union
of these ontologies is required for a complete medical vocabulary [24] that can be used within the ETL process [25] for data
annotation and HL7 v3 message generation.
In the following sections, the proposed semantic interoperability approach of the EURECA project, as well as a comparison with other models, is described.
III. METHODS
The proposed solution to homogenize access among clinical
systems is based on widely adopted standards that facilitate uniform access to legacy systems. Fig. 1 depicts the interfaces of
the proposed semantic interoperability layer with different applications and data hosting (Proprietary and local IM). In order
to achieve data normalization, a common information model
(CIM) has been defined.

PARAISO-MEDINA et al.: SEMANTIC NORMALIZATION AND QUERY ABSTRACTION BASED ON SNOMED-CT AND HL7

Fig. 2.

1063

Semantic normalization process.

The proposed CIM provides a common data representation
for storing and querying clinical data used within clinical trials.
Three main components are required for the CIM: 1) CDM;
2) Core Dataset; and 3) Terminology Binding. The CDM is
based on the HL7 RIM to define the schema storing data in the
proposed solution. The Core Dataset contains medical concepts
(and their relations) describing the semantics of the data sources.
The Core Dataset is mainly based on SNOMED-CT and is extended with LOINC and HGNC for laboratory tests and gene
names, respectively. The Terminology Binding is the link between the CDM and Core Dataset, i.e., Core Dataset concept to
CDM class-attribute.
To provide a semantically uniform access to the data stored in
the CIM, a two-phase normalization process has been proposed:
1) data normalization (semantic normalization pipeline); and 2)
query normalization (abstraction). Both phases use the semantic
knowledge of the Core Dataset to normalize data in the CDM
and to subsequently retrieve data.
A. Semantic Normalization Pipeline
CDMs in complex areas such as biomedicine usually allow
various representations of the same information. Such ambiguity is mainly produced by vocabularies used to annotate data
sources. To provide a homogeneous data representation across
data sources involved in clinical trials, a normalization process should be performed. This proposed normalization involves
transformations of the data following guidelines from widely
adopted standards.
Fig. 2 describes the normalization pipeline process used for
data normalization. The Data Push service triggers the Semantic
Normalization Pipeline. First, concepts encoded in vocabularies not present in the Core Dataset, such as ICD [26] or NCI
Thesaurus [27], are translated/mapped into Core Dataset concepts. A Terminology Linking Service based on BioPortal [28]
is responsible for this translation. Because coverage of such terminology linking services to SNOMED-CT is not perfect, as
it is only approximately 60–80% accurate [25], the remaining
translations need to be manually curated by knowledge experts.
After all concepts are coded using SNOMED-CT, LOINC or
HGNC, the normalization process transforms concepts into their
normal form. The normal form is the most informative representation version of a concept, i.e., a SNOMED-CT representation
of a “Trocar Biopsy” (SNOMED-CT code 5337005) is transformed into the method concept “Biopsy” (code 129314006)
and the device involved “Trocar” (code 118418003). The final

Fig. 3.

Query abstraction process.

step is performed by the Terminology Binding following HL7
guidelines [29], where normalized expressions of concepts are
linked to fields of the RIM-based CDM.
This proposed semantic normalization process generates implicit information contained in the data sources. At the same
time, the traceability of the original data is preserved by storing
original codes before the normalization process.
B. Query Abstraction
One of the main goals of the proposed solution is to provide
homogeneous access for retrieving information from the CDM.
For that purpose, a service that encapsulates data model schema
and query syntax has been developed.
The query abstraction process, shown in Fig. 3, includes a
Query Template Library (QTL) that retrieves data related to
Core Dataset concepts. The QTL is defined by a set of SPARQL
query templates based on the CDM domain. These templates
cover every possible expression stored in the CDM. Five types
of queries are identified: 1) observation; 2) procedure; 3) substance administration; 4) entity (devices, products, genes); and
5) demographic information. The query abstraction service receives a Core Dataset concept as input and returns the corresponding SPARQL template. Each template is generated from
a basic query and includes the normalized form of the concept. The proposed templates also contain a set of optional
filters and attributes to operations, such as value comparison or
adding more restrictions to the query, including a target site,
method or interpretation code on the original query. Once the
final query is produced, the CIM Access Service exploits the semantic knowledge contained in the Core Dataset by expanding
the SPARQL query with hierarchical relationships from medical
vocabularies.
The query abstraction approach proposed in this paper follows the same processes of the semantic normalization pipeline:
1) generation of SNOMED-CT Normal form of the concept;
2) matching of the Normal Form and the CDM following
Terminology Binding information; and finally 3) selection of
the required query template to retrieve information from the
CDM.

1064

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

IV. EVALUATION AND RESULTS
In this section, we have performed a qualitative and a quantitative evaluation of the proposed solution by comparing the
same data source and different semantic solutions. The target
data source contains 80 patients based on a postgenomic multicentric clinical trial (the TOP clinical trial) [30] with 511 observations, including gene expressions information following St.
Gallen International Breast Cancer guidelines [31].
Data have been stored and queried from the following: 1)
HL7 RIM without normalization (INTEGRATE); 2) OMOP; 3)
i2b2; and 4) HL7 RIM-based CDM with semantic normalization pipeline (the proposed solution). HL7 RIM without normalization was implemented without any semantic transformation,
while OMOP and i2b2 instances of the common data source
were implemented following the guidelines described in each
project.
The qualitative evaluation includes a set of general characteristics regarding the functional capabilities of each approach.
1) Data ambiguity: refers to different representations of the
same information in the data model.
2) Security access: refers to the system’s ability to filter
data depending on user permission.
3) Query languages used: refers to query language used for
accessing the data.
4) Temporal queries: refers to the capabilities of retrieving
information with temporal restrictions.
5) Traceability: refers to the storage of the original information from data sources.
6) Inferring vocabulary knowledge: refers to the exploitation of hierarchical and synonym information from domain vocabularies.
7) Query abstraction from data model: refers to the possibility of building queries agnostic to the data model
schema.
8) Multimedia information: refers to the ability of storing
related information to other observations.
9) Genetic information: refers to the ability of storing genetic information in the data model.
Finally, in the quantitative evaluation, a set of characteristics that can be measured with the same test data has
been defined. A performance evaluation was also made
with different queries extracted from the eligibility criteria (EC) of the TOP trial:
10) The presence of redundant data with the same dataset.
11) Execution time.
EC queries range from retrieving general information about
a patient to previous diagnostics, images related to a diagnosis, treatments of substance administrations, and gene expression related to a patient. Queries were built to match EC
from the TOP trial on different models and to retrieve information about patients related to genes such as HER2, Ki-67 or
PgR.
1) Inclusion criterion 1: Age of patient ࣘ70 years.
2) Inclusion criterion 2: Female patient.
3) Inclusion criterion 3: Patients with fixed samples from the
primary tumor.

4) Inclusion criterion 4: Patients who signed the informed
consent.
5) Inclusion criterion 5: Patients with ANCࣙ 1500 mm3 .
6) Inclusion criterion 6: Patients with GOTࣘ1.5 N.
7) Inclusion criterion 7: Patients with GPTࣙ 1.5 N.
8) Exclusion criterion 1: Patients with metastatic breast cancer.
9) Exclusion criterion 2: Patients with previous treatment
with anthracyclines.
All these queries can be accessed on the bitbucket public
repository in SPARQL version for HL7 models and SQL for the
OMOP model.
A. HL7 Without Semantic Normalization
This approach uses the CIM comprised of a CDM and a
Core Dataset, as mentioned previously. Regarding the qualitative evaluation, using this model, it is possible to find the same
information represented in different places. This depends on
the data source and the ETL process. If the original data include
normalized and not normalized SNOMED-CT expressions, they
will be stored on different HL7 RIM classes.
With regard to other characteristics, using this approach, it is
possible to add security access at the application level. The HL7
RIM can store the trial provenance of every act for traceability.
SPARQL is the query language used, but it is also possible to
use SQL, although this will not exploit the semantic capabilities
of the approach. It is also possible to make temporal queries
because every act has an effective time.
A method to infer semantic knowledge of the Core Dataset
on the CDM is accessible at the query level, allowing the possibility of using SNOMED-CT synonyms. HL7 RIM provides
options to store related images and documents related to other
acts (diagnoses or procedures). HL7 RIM also defines that gene
information has to be stored as an observation related to a patient, depending on the medical vocabulary used.
While flexibility is one of the main important features of HL7
RIM, it is also one of its main disadvantages, as querying a HL7
RIM-based model requires users to be aware of both model
schema and data representation. Although a query abstraction
service can be provided, it does not cover all of the possible
results due to lack of data normalization.
Regarding quantitative evaluation, it is important to note that
every EC is translated as one SPARQL query. This approach
uses query expansion to extract Core Dataset knowledge, and
SPARQL is translated to SQL. These processes directly impact
performance by increasing execution time, as can be observed
in Table I.
B. OMOP
Following the guidelines facilitated by OMOP, a relational
database was created and populated with the dataset from TOP
trial and including gene expressions. EC queries were then translated to SQL language to test the OMOP model. Compared to
the previous approach, similar results were obtained in different points: data ambiguity (a), security access (b) and temporal

PARAISO-MEDINA et al.: SEMANTIC NORMALIZATION AND QUERY ABSTRACTION BASED ON SNOMED-CT AND HL7

1065

TABLE I
EVALUATION OF THE DIFFERENT APPROACHES
Measure

HL7 RIM w/o Normalization

OMOP

i2b2

HL7 RIM with Normalization

a

Yes, it depends on the data
sources and ETL process

Yes, it depends on the data
sources and ETL process

Yes, it depends on the structure
tree defined for displaying data

b

Yes, at application and data level
(fine-grained security)
SPARQL
Yes, effective times are stored in
the model
Yes, information is not
transformed

Yes, at application level

Yes, at application level as
another hive service
SQL
Yes, each data has its own
associated date
No, it depends on the ETL for
creating the tree

f

Yes, with the query expansion of
the Core Dataset

Manually, using a vocabulary
table as a dictionary

No, semantic normalization
process avoids ambiguous data
representation
Yes, at application and data level
(fine-grained security)
SPARQL
Yes, effective times are stored in
the CDM
Yes, it is transformed and the
original data are also stored in
the same location
Yes, with the query expansion of
the Core Dataset

g

No, it is necessary to know the
CDM for building queries

h

Yes, metadata and linked images
can be stored as an “act”
related to another “act”
Yes, it depends on the
representation vocabulary used
Yes (i.e. Breast cancer versus
Infiltrating Duct Carcinoma
located on a Breast finding)
300–600 ms

No, it is necessary to know the
OMOP model for building
queries
No, there is not a table for storing
relations between observations
or procedures
No, it is necessary to modify the
model to add this information
No, vocabulary concepts are
mapped on a table avoiding
this issue
20–250 ms

c
d
e

i
j

k

SQL
Yes, dates are stored in the model
No, it depends on the ETL process

queries (d). The main differences appear concerning the medical
vocabulary. Using this approach, inference using implicit vocabulary knowledge has to be performed manually on queries. The
exploitation of information about synonyms, which is present
in vocabulary tables of the OMOP model, should be included
manually in the queries.
Building SQL queries for retrieving information from the
OMOP model requires data model and SQL knowledge. Genetic
information can be partially stored on the model for laboratory
tests. However, this is only possible if the required vocabulary
concepts are present in mappings facilitated by OMOP.
Regarding the quantitative evaluation, it is important to note
that it produces better results with respect to time, due to queries
executed using SQL directly on a relational database [14]. The
main drawback of this approach is that it is necessary to manually extend queries with vocabulary tables to use semantic
knowledge from the medical domain. In fact, all concepts from
medical vocabularies such as SNOMED-CT or LOINC are
mapped in these vocabulary tables.

C. I2b2
An instance of an i2b2 data repository implemented as a
relational database was deployed to compare this with the rest of
the approaches. The main difficulty populating the repository is
that the i2b2 data model is very generic. Thus, as recommended
by i2b2 Clinical Research Chart guidelines, the research dataset
has been modeled ad hoc for the current study. This means that
a hierarchical model representing the study should be defined
inside the i2b2 database. Values of diagnosis and laboratory tests
are coded using standard vocabularies such as SNOMED-CT.
The defined tree structure only includes string labels (separated
by “\” characters); thus, most of the semantic information is

It is a manual process with no
semantic knowledge, only for
retrieving the same strings
No, it is necessary to know the
i2b2 model for building queries
No, relations available are only
those defined in data tree
Yes, i2b2 model supports clinical
data and genomic data
Yes, i2b2 could have redundant
data because it depends on the
vocabulary tree.
300–650 ms

Yes, the query abstraction process
facilitates a SPARQL template
for building queries
Yes, metadata and linked images
can be stored as an “act”
related to another “act”
Yes, it depends on the
representation vocabulary used
No, the semantic normalization
pipeline avoid this issue
400–750 ms

lost. Additionally, it is important to remark that searches will
depend on ad hoc tree definitions.
D. HL7 With Semantic Normalization and Query Abstraction
This is the approach adopted in the EURECA project. The
main differences with the other approaches are as follows: 1)
the semantic normalization pipeline for storing normalized data;
and 2) the query abstraction process to obtain SPARQL templates for building CDM queries.
This approach shares certain advantages with the first HL7
model. Therefore, (b), (c), (d), (f), (h), and (i) have the same
results. Regarding data ambiguity (a), there is no ambiguity
in this model due to the normalization pipeline transforming
and standardizing data storage to avoid different representations
of the same information on CDM (e). Regarding the usability
for building queries on this model (g), the query abstraction,
following the same normalization pipeline, facilitates a template
for querying the CDM without any knowledge about the model.
Quantitative results are very similar to the first approach.
Performance is slightly worse due to the automatic query expansion and the query abstraction mechanism to build queries.
In this approach, redundant data are avoided as a result of the
normalization process.
The semantic interoperability solution described in this paper, namely the CDM RDF dump and the QTL, is freely available at http://bitbucket.org/sparaiso/semantic-normalizationand-query-abstraction-based-on-snomed.
V. CONCLUSION
Interoperability among systems involved in modern clinical
trials is still one of the main bottlenecks in information management for clinical research. Most of the tasks are currently

1066

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 3, MAY 2015

performed manually, so the sustainability of studies including
omic information is especially dependent on advanced methods
to automate certain procedures. Even more important, however,
is to exploit semantic knowledge inferred from clinical vocabularies that has been developed in recent years.
The method proposed in this paper tackles such challenges
within the environment built within two EU research projects.
A semantic normalization pipeline to homogenize the representation of clinical data by using normalization mechanisms from
the HL7 interoperability standard and SNOMED-CT vocabulary
was developed. An additional query abstraction mechanism to
facilitate the information retrieval by applications in this environment has also been created. This mechanism encapsulates
the data model and the query syntax, allowing the creation of
complex SPARQL queries required by the clinical scenarios.
A qualitative and quantitative evaluation has been performed
to compare the proposed method with other state of the art implementations such as OMOP or i2b2. Results have shown additional query capabilities that exploit knowledge extracted from
biomedical vocabularies and follow the latest semantic technologies and healthcare information management standards. Although slightly worse performance has been found, applications
using the proposed approach have produced usable graphical
user interfaces.
There are plans to extend the proposed solution to other areas
in oncology and beyond, while there are also research efforts to
automate certain tasks in the data annotation and ETL-related
tasks. This work describes a valuable effort with the aim of improving and streamlining clinical research execution and translating current omics-related findings into clinical practice.
REFERENCES
[1] L. M. McShane, M. M. Cavenagh, T. G. Lively, D. A. Eberhard, W. L.
Bigbee, P. M. Williams, and B. A. Conley, “Criteria for the use of omicsbased predictors in clinical trials,” Nature, vol. 502, no. 7471, pp. 317–320,
2013.
[2] J. G. Hodge Jr., L. O. Gostin, and P. D. Jacobson, “Legal issues concerning
electronic health information,” J. Amer. Med. Assoc., vol. 282, no. 15,
pp. 1466–1471, 1999.
[3] A. Anguita, L. Martı́n, D. Pérez-Rey, and V. Maojo, “A review of methods
and tools for database integration in biomedicine,” Curr. Bioinformat.,
vol. 5, pp. 253–269, 2010.
[4] B. Claerhout, N. Forgó, T. Krügel, M. Arning, and G. De Moor, “A data
protection framework for trans-European genetic research projects,” Stud.
Health Technol. Informat., vol. 141, pp. 67–72, 2008.
[5] K. C. Oeffinger, J. S. Ford, C. S. Moskowitz, L. R. Diller, M. M. Hudson,
J. F. Chou, and L. L. Robison, “Breast cancer surveillance practices among
women previously treated with chest radiation for a childhood cancer,”
J. Amer. Med. Assoc., vol. 301, no. 4, pp. 404–414, 2009.
[6] S. Pakhomov, S. A. Weston, S. J. Jacobsen, C. G. Chute, R. Meverden, and
V. L. Roger, “Electronic medical records for clinical research: Application
to the identification of heart failure,” Amer. J. Managed Care, vol. 13,
no. 6 Part 1, pp. 281–288, 2007.
[7] W. R. Hersh, “Adding value to the electronic health record through secondary use of data for quality assurance, research, and surveillance,” Clin.
Pharmacol. Therapeutics, vol. 81, pp. 126–128, 2007.
[8] P. E. Stang, P. B. Ryan, J. A. Racoosin, J. M. Overhage, A. G. Hartzema,
C. Reich, and J. Woodcock, “Advancing the science for active surveillance:
Rationale and design for the observational medical outcomes partnership,”
Ann. Internal Med., vol. 153, no. 9, pp. 600–606, 2010.
[9] S. N. Murphy, G. Weber, M. Mendis, V. Gainer, H. C. Chueh, S. Churchill,
and I. Kohane, “Serving the enterprise and beyond with informatics for integrating biology and the bedside (i2b2),” J. Amer. Med. Informat. Assoc.,
vol. 17, no. 2, pp. 124–130, 2010.

[10] S. Oster, S. Langella, S. Hastings, D. Ervin, R. Madduri, J. Phillips, and
J. Saltz, “Cagrid 1.0: An enterprise grid infrastructure for biomedical
research,” J. Amer. Med. Informat. Assoc., vol. 15, no. 2, pp. 138–149,
2008.
[11] Fp7-integrate.eu. (Dec. 31, 2013). Driving Excellence in Integrative Cancer Research [Online]. Available: http://www.fp7integrate.eu/index.php/project
[12] eurecaproject.eu. (Dec. 31, 2013). Enabling Information Re-Use
by Linking Clinical Research and Care [Online]. Available from:
http://eurecaproject.eu/
[13] M. Antonioletti, M. Atkinson, R. Baxter, A. Borley, N. P. Chue Hong,
B. Collins, and M. Westhead, “The design and implementation of grid
database services in OGSA-DAI,” Concurrency Comput.: Practice Experience, vol. 17, nos. 2–4, pp. 357–376, 2005.
[14] J. M. Moratilla, R. Alonso-Calvo, G. Molina-Vaquero, S. Paraiso-Medina,
D. Perez-Rey, and V. Maojo, “A data model based on semantically enhanced HL7 RIM for sharing patient data of breast cancer clinical trials,”
Stud. Health Technol. Informat., vol. 192, pp. 971–971, 2012.
[15] D. Kalra, T. Beale, and S. Heard, “The openEHR foundation,” Stud. Health
Technol. Informat., vol. 115, pp. 153–173, 2005.
[16] D. B. Fridsma, J. Evans, S. Hastak, and C. N. Mead, “The BRIDG
project: A technical report,” J. Amer. Med. Informat. Assoc., vol. 15, no. 2,
pp. 130–137, 2008.
[17] W. Kuchinke, J. Aerts, S. C. Semler, and C. Ohmann, “CDISC standardbased electronic archiving of clinical trials,” Methods Inf. Med., vol. 48,
no. 5, pp. 408–413, 2009.
[18] T. Benson, Principles of Health Interoperability HL7 and SNOMED. New
York, NY, USA: Springer, 2012.
[19] G. W. Beeler, “HL7 Version 3—An object-oriented methodology for collaborative standards development,” Int. J. Med. Informat., vol. 48, no. 1,
pp. 151–161, 1998.
[20] S. Aso, D. Perez-Rey, R. Alonso-Calvo, A. Rico-Diez, A. Bucur,
B. Claerhout, and V. Maojo, “Analyzing SNOMED CT and HL7 terminology binding for semantic interoperability on post-genomic clinical
trials,” Stud. Health Technol. Informat., vol. 192, pp. 980–980, 2012.
[21] L. Bos, “SNOMED-CT: The advanced terminology and coding system for
eHealth,” Stud. Health Technol. Informat., vol. 121, pp. 279–290, 2006.
[22] R. L. Seal, S. M. Gordon, M. J. Lush, M. W. Wright, and E. A. Bruford,
“Genenames.org: The HGNC resources in 2011,” Nucleic Acids Res., vol.
39, suppl 1, pp. D514–D519, 2011.
[23] C. J. McDonald, S. M. Huff, J. G. Suico, G. Hill, D. Leavelle, R. Aller,
and P. Maloney, “LOINC, a universal standard for identifying laboratory
observations: A 5-year update,” Clin. Chem., vol. 49, no. 4, pp. 624–633,
2003.
[24] S. Paraiso-Medina, D. Perez-Rey, R. Alonso-Calvo, B. Claerhout, K. de
Schepper, P. Hennebert, J. Lhaut, J. Van Leeuwen, and A. Bucur, “Semantic interoperability solution for multicentric breast cancer trials at the
integrate EU project,” in Proc. Int. Conf. Health Informat., 2013, no. 1,
pp. 34–41.
[25] A. Bucur, J. van Leeuwen, D. Perez-Rey, R. A. Calvo, B. Claerhout, and
K. de Schepper, “Identifying the semantics of eligibility criteria of clinical
trials based on relevant medical ontologies,” in Proc. IEEE 12th Int. Conf.
Bioinformat. Bioeng., Nov. 2012, pp. 413–421.
[26] The ICD-10 Classification of Mental and Behavioural Disorders: Clinical Descriptions and Diagnostic Guidelines, World Health Organization,
Geneva, Switzerland, vol. 1, 1992.
[27] N. Sioutos, S. D. Coronado, M. W. Haber, F. W. Hartel, W. L. Shaiu, and
L. W. Wright, “NCI thesaurus: A semantic model integrating cancerrelated clinical and molecular information,” J. Biomed. Informat., vol. 40,
no. 1, pp. 30–43, 2007.
[28] N. F. Noy, N. H. Shah, P. L. Whetzel, B. Dai, M. Dorf, N. Griffith, and
M. A. Musen, “BioPortal: Ontologies and integrated data resources at the
click of a mouse,” Nucleic Acids Res., vol. 37, suppl 2, pp. W170–W173,
2009.
[29] E. H. Cheetham, R. Dolin, D. Markwell, J. Curry, D. Gabriel, R. Hausam,
B. Knight, A. Rector, K. Spackman, and I. Townend, Using SNOMED CT
in HL7 v3 Implementation Guide, Release 1.5, 2008.
[30] TOP, Jules Bordet Institute. (Dec. 31, 2013). Topoisomerase II Alpha Gene Amplification and Protein Overexpression Predicting Efficacy of Epirubicin (TOP) [Online]. Available: http://clinicaltrials.
gov/ct2/show/NCT00162812
[31] A. Goldhirsch, W. C. Wood, A. S. Coates, R. D. Gelber, B. Thürlimann,
and H. J. Senn, “Strategies for subtypes—Dealing with the diversity of
breast cancer: Highlights of the St Gallen International Expert Consensus on the Primary Therapy of Early Breast Cancer 2011,“ Ann. Oncol.,
vol. 22, no. 8, pp. 1736–1747, 2011.

PARAISO-MEDINA et al.: SEMANTIC NORMALIZATION AND QUERY ABSTRACTION BASED ON SNOMED-CT AND HL7

Sergio Paraiso-Medina received the Master’s degree in computer science and the Master’s degree in
artificial intelligence from Universidad Politécnica of
Madrid (UPM), Madrid, Spain. He is currently working toward the Ph.D. degree in computer science.
During the last three years, he has been a member of the Biomedical Informatics Group, UPM. His
research interests are mainly focused on database integration, semantic technologies and reasoning methods. He has been involved on various European
projects such as EURECA and INTEGRATE.

David Perez-Rey received the Ph.D. degree in computer science from the Universidad Politécnica of
Madrid (UPM), Madrid, Spain.
He was a Visiting Researcher at Rutgers University, USA, and University of Utah, USA. In 2007, he
was a Collaborating Professor at Universidad Francisco de Vitoria, and since 2008, he has been with the
Departamento de Inteligencia Artificial, Facultad de
Informatica, UPM, where he is currently an Assistant Professor. For the last nine years, he has been a
member of the Biomedical Informatics Group, UPM,
working on several EU research projects. His research interests are mainly focused on semantic interoperability, information retrieval and search engines in
biomedicine.
Dr. Perez-Rey has published research papers in journals such as Bioinformatics, BMC Bioinformatics, Journal of Biomedical Informatics, Methods of
Information in Medicine and Computers in Biology and Medicine.

Anca Bucur received the Ph.D. degree in computer science from the Delft University of Technology, Delft, The Netherlands, and the Master’s degree
from the Technical University of Bucharest, Bucuréti,
Romania.
She is currently a Senior Scientist with Philips Research Europe, Eindhoven, The Netherlands. She has
led several industrial research projects in the healthcare domain related to clinical information systems,
medical imaging, and computational genomics, with
a main customer being Philips Healthcare. She is the
Coordinator of the FP7 projects INTEGRATE and EURECA (Enabling information re-Use by linking clinical Research and Care) and leads Philips’ contribution to the FP7 projects p-Medicine (from data sharing and integration via
VPH models to personalized medicine) and Computational Horizons in Cancer.

1067

Brecht Claerhout received the Master’s degree in
electronics engineering.
He has previously been active in FOSS development as an author of a major network security
tool (Sniffit). He was with the Interuniversity Microelectronics Center and Research in Advanced Medical Informatics and Telematics research groups. He
is currently leading Custodix, Sint-Martens-Latem,
Belgium, one of the first Trust Service Providers in
the world focusing on data protection, and he has
been actively involved in a large number of European
research projects mainly dealing with the health data integration. Recent projects
include EHR4CR, INTEGRATE and EURECA. He has published several conference and journal papers on the subject of security and privacy protection and
semantic integration of clinical data.

Raul Alonso-Calvo received the Ph.D. degree in
computer science from the Universidad Politécnica
of Madrid (UPM), Madrid, Spain.
For the last 11 years, he has been a member of the
Biomedical Informatics Group at UPM, working on
different research projects related to data integration,
semantic interoperability, and biomedical image processing. He was a Visitor Researcher at the bioinformatics group of the Universidade de Aveiro, Portugal.
He has also been working on different IT projects in
private companies since 2005 as a Consultant and
currently as an IT Manager. Since 2009, he has been a Part-Time Professor in
the Departamento de Lenguajes y Sistemas e Ingenierı́a de Software, Facultad
de Informatica, UPM.

