IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 1, JANUARY 2015

151

On the Blind Recovery of Cardiac
and Respiratory Sounds
Ghafoor Shah, Student Member, IEEE, Peter Koch, and Constantinos B. Papadias, Fellow, IEEE

Abstract—We present a method for smart auscultation by
proposing a novel blind recovery of the original cardiac and respiratory sounds from a single observation mixture, in the framework
of nonnegative matrix factorization (NMF). The method learns the
basis spectra of the mixing sources in unsupervised or semisupervised fashion depending upon the applications. A modified NMF
technique is proposed, which enforces the spectral structure of the
target sources in mixture factorization, resulting in good separation
of target sources, even in the presence of nonstationary noise. Moreover, data is processed in small batches which 1) enables dynamic
bases spectra update technique to mitigate the spectral variations
of the mixing sources, and 2) reduces computational complexity.
The analytical work is verified through simulations using synthetic
as well as actual clinical data collected from different subjects in
different clinical sittings. The proposed smart auscultation method
demonstrates excellent results even in noisy clinical environments.
Index Terms—Auscultation, blind source separation (BSS), cardiac and respiratory sounds, clinical data, nonnegative matrix
factorization (NMF).

I. INTRODUCTION
USCULTATION, i.e., listening to cardiac/respiratory
sounds, is a noninvasive and low-cost early diagnostic
procedure. In a clinical setting, the clinicians perform auscultation by exploiting the bioacoustics information of the target
sounds. However, the cardiac sound interferes with the respiratory sound in the time domain as well as in its spectral contents
[1], which compromises the effectiveness of auscultation. Moreover, certain environmental noise conditions, for instance, busy
emergency rooms or in the field where certain noises disrupt the
clinician attention further, hamper the auscultation procedure.
It is, therefore, essential to develop smart auscultation methods (such as recovering clean cardiac and respiratory sounds)
that enhance the listening utility and assist clinicians in their

A

Manuscript received January 15, 2014; revised July 26, 2014; accepted August
8, 2014. Date of publication August 18, 2014; date of current version December
30, 2014. This work was supported in part by ELPEN (www.elpen.gr) and was
also supported in part by the eWALL Research Project funded by the European
Commission under FP7 (www.ewallproject.eu). The opinions expressed in this
work do not necessarily reflect those of the supporters.
G. Shah is with the Department of Electronic Systems, Aalborg University, 9220 Aalborg, Denmark, and also with the Broadband Wireless and Sensor Networks Group, Athens Information Technology, 19002 Athens, Greece
(e-mail: ghs@es.aau.dk).
P. Koch is with the Department of Electronic Systems, Aalborg University,
9220 Aalborg, Denmark (e-mail: pk@es.aau.dk).
C. B. Papadias is with the Broadband Wireless and Sensor Networks Group,
Athens Information Technology, 19002 Athens, Greece (e-mail: papadias@
ait.edu.gr).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/JBHI.2014.2349156

practice and rescue the gradually dying art of auscultation [2].
The recovery of the cardiac and respiratory sound problem has
been investigated as a blind source separation (BSS) problem in
[3] and [4], where two or more observation mixtures are used
for the recovery of two signals. However, most of the modern stethoscopes used for chest sound auscultation can provide
only a single observation mixture of the cardiac and respiratory
sounds. Conventional time-domain filtering alone cannot completely separate the two sources from their single observation
mixture, because of their overlap in spectral content especially
below 200 Hz [1]. In [5], 15 different adaptive methods developed for separating the cardiac sound from respiratory sound
are reviewed, and the filtering techniques are categorized as linear adaptive filters (AFs) and filters employing time-frequencybased methods. Adaptive filtering does not completely suppress
the cardiac sound segments in respiratory sound because of the
high nonstationarity of the cardiac sound, which makes time
alignment of the primary and reference signal difficult in real
scenarios. Recently, separation of the respiratory sound from
the cardiac sound using wavelet transform-based filtering has
been proposed (see, e.g., [6] and [7]). In wavelet transformbased filtering, the selection of the decomposition and threshold
levels are quite challenging in real scenarios. Cardiac sound
cancellation in respiratory sound recording by exploiting cyclostationarity using cyclic frequency spectrum (CFS) is proposed
in [8]. The singular spectrum analysis (SSA) technique is used
in [9], which localizes only the cardiac sound in the chest sound
recordings. All the studies discussed above were based on the
data acquired under ideal conditions, while the potential usefulness of any method rests on its ability to perform in real clinical
settings. It is clear from the above that the recovery of both cardiac and respiratory sounds from a single observation mixture
is a challenging task that needs further investigation.
A matrix decomposition technique denoted nonnegative matrix factorization (NMF) [10] has been widely used in the singlechannel BSS of audio streams, drum transcriptions, and musical
data [11], [12]. The NMF is applied to the magnitude spectrogram in order to produce a low-dimensional approximation of
the original data, in the form of two nonnegative factors: one
matrix having the spectral basis vectors and the second matrix
containing time-variant gain information for each basis vector.
Different versions of NMF, which have been proposed during
the last decade, are reviewed in [13] and [14]. To learn the basis
spectra (BS) of the individual sources, supervised approaches
have been used in the literature [15], which require complete
training data of the individual sources. These approaches cannot
be used where the complete training data are unavailable. The
semisupervised approach [16] is useful where partial training

2168-2194 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

152

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 1, JANUARY 2015

data are available. Recently, nonnegative matrix partial cofactorization is used in the recovery of drum source (in ideal noise
free conditions), where a drum-only matrix a priori and a music matrix (mixture) are simultaneously decomposed by sharing
some factors [17].
In this paper, we address the separation of cardiac and respiratory sounds from a single observation mixture in different
scenarios. In the first scenario, we propose a semisupervised
BSS technique by exploiting a priori the cardiac-only sound
signal, which can be generally acquired (i.e., by holding breath
or extracting during the pauses in breathing [18]). We extend the
idea of cofactorization to separate three sources, by enforcing
the spectral structure of the target sources through jointly factorizing multiple matrices with some common factors. In a scenario, where, training data of the cardiac-only sound signal are
not available (e.g., in case of children, mentally challenged patients, etc.), we propose an unsupervised BSS technique. Here,
we extend the idea of unsupervised and dynamic BS learning
[19]. We use a double clustering approach: 1) initial clustering
using traditional NMF which results in a part-based decomposition of the mixture into basis vectors, and 2) clustering the basis
vectors with a high degree of similarity within each cluster and a
low degree of similarity between different clusters, to estimate
the complete BS of the individual sources. The unsupervised
basis spectra learning (UBSL) phase is performed dynamically
over a small batch of data and can be repeated after regular
intervals depending upon the application. For instance, in applications where BS varyover time, the UBSL phase can also
be repeated more frequently, in order to achieve better recovery.
The main contributions of this research work can be summarized
as follows.
1) A semisupervised BSS method with a modified NMF
which we denote as NMF-with shared factors (NMFSF). NMF-SF enforces the spectral structure of the target
sources in the factorization and achieves good separation
even in the presence of nonstationary noise.
2) An unsupervised BSS method which does not require any
training data.
3) Small batch processing, i.e., data are processed in small
batches, which can be used for both online and offline data
processing.
4) BS are learned dynamically over a small batch of data and
can be repeated at regular intervals, depending upon the
application and computational cost.
The rest of the paper is organized as follows.
The proposed semisupervised and unsupervised BSS techniques are explained in Section II Section III discusses the simulation results, and Section IV concludes the work.
II. BLIND SOURCE RECOVERY METHODS
A. Mixing Model and Signal Representation
In our method, we adopt the following mixing model:
x[m] =

I

i

ai si [m] + ηw [m] + η[m]

Fig. 1. Simplified overview of the proposed system, illustrating the noise
model and BSS.

where x[m] represents the discrete-time observation mixture
signal and si [m], ai represent the ith source and its amplitude,
respectively. ηw [m], η[m], and I represent the white Gaussian
noise (arise during signal acquisition etc.), the nonstationary
noise, and the total number of sources, respectively. For simplicity, in our mixing model (1), we assume that cardiorespiratory signals and noise sources combine linearly [20]. First, we
discuss our method for the BSS of the cardiac and respiratory
sounds, which can be generalized to other sources having similar
characteristics. In our work, i ∈ {c, r}, where c and r represent
the cardiac and respiratory sound signal domains, respectively.
We use NMF, which can be applied to the magnitude spectrogram of the mixed signal. A simple method of spectrogram generation is short-time discrete Fourier transform (STFT), where a
time-domain signal is divided into small frames using a suitable
window function, and a discrete Fourier transform is performed
on each frame. X[t, f ]: = STFT{x[m]} denotes the complex
spectrogram of the signal x[m], t and f represent time index
and frequency bin, respectively. X = ||X[t, f ]|| represents the
magnitude spectrogram of the signal x[m]. In our method, we
assume 1) mixing sources exhibit cyclo-stationary properties,
and 2) mixing sources are approximately windowed-disjoint orthogonal. For these assumptions, we argue that the cardiac and
respiratory sounds exhibit cyclo-stationarity [8] and also exhibit
approximate windowed-disjoint orthogonality [21].
B. Nonnegative Matrix Factorization
NMF is a useful tool that is employed in a variety of signal processing applications. NMF gives parts-based decomposition and imposes the only constraint of nonnegativity. Efficient algorithms for NMF computations have been developed in
[10]. NMF decomposes a nonnegative matrix X ∈ RF ×T into
two nonnegative factors W ∈ RF ×K and H ∈ RK ×T , where
K < min{F, T }, that is
X + = W+ H + + E

(2)

where V+ indicates that the matrix V is nonnegative and E
represents reconstruction error. Different cost functions are used
for minimizing the reconstruction error. We use a cost function,
which is the squared Euclidean distance between X and W H
being defined as

(Xtf − (W H)tf )2 (3)
DEUD = ||X − W H||2F =
tf

(1)

where || · ||2F denotes Frobenius norm, and t and f represent time
index and frequency bin, respectively. The lower bound of the
measure (3) is zero and it is optimized if X = W H or E = 0.

SHAH et al.: ON THE BLIND RECOVERY OF CARDIAC AND RESPIRATORY SOUNDS

153

The corresponding multiplicative updates which converge to
local minima are given as
W ←W

WT X
XH T
,
H
←
H

W HH T
WT WH

(4)

where D  E denotes element-wise multiplication, and D
E denotes element-wise division.
In general, training data of individual source are used to learn
the BS first. Then with fixed BS, the time varying gain information is learned from the mixture. The original sources are
estimated by combining the time varying gain information with
their respective BS. This approach is called supervised BS learning [15] and summarized in Algorithm 1.

C. NMF-SF
We propose a semisupervised BSS method where we exploit a priori, i.e., a cardiac-only sound signal X1 = Sc + ηw
and the mixture of the cardiac and respiratory sounds X2 =
Sc + Sr + ηw , where Sc , Sr denote the magnitude spectrograms
of cardiac and respiratory sounds, respectively. Prior to factorization, we remove the white Gaussian noise (ηw ) using classical
time-frequency denoising techniques (e.g., Wiener postprocessing, block thresholding, overlapping group shrinkage (OGS)
[22], etc.). We mainly focus on removing the nonstationary
noise (η), which we treat as a third source in our factorization
model. We extend the idea of cofactorization proposed in [17] to
separate three sources (i.e., Sc , Sr , and η). In [17], two sources
were recovered by jointly factorizing the two matrices in ideal
noise free condition. We jointly factorize the three matrices X1 ,
X2 , and X simultaneously with some common factors in the
following factorization models:
X1 ≈ Wc Hc1

(5)

X2 ≈ Wc Hc2 + Wr Hr 2

(6)
(7)

Fig. 2 illustrates the idea of NMF-SF. By sharing the common
basis vector Wc in (5) and (6) which denotes the spectral characteristics of the cardiac sound, the term Wc Hc2 in (6) approximates Sc from the mixture X2 , which shares similar spectral
characteristics to the one in (5). The second term Wr Hr 2 in
(6) represents Sr . In a similar way, by sharing the common
bases Wc and Wr in (6) and (7), the first two terms Wc Hc and
Wr Hr in (7), partially reconstruct the cardiac and respiratory
sounds, respectively. The third term Wη Hη in (7) is devoted to

Illustration of matrix decomposition model using NMF-SF.

partially reconstruct the nonstationary noise sources. Therefore,
we minimize the following objective function:
Δ

Algorithm 1: NMF-based BSS-supervised approach.
1: Find NMF for each individual source k using training
 k . Store W
k ≈ W
k H
k and discard H
k
data, X

2: Concatenate the BS Wk of the sources into a single
 = [W
1 , . . . W
K ]
matrix, W
 as X ≈ W
H
3: Find NMF of the mixture with fixed W
4: Estimate the magnitude of the kth original source as
k Hk
X(k ) = W

X ≈ Wc Hc + Wr Hr + Wη Hη .

Fig. 2.

γ2
γ1
||X1 − Wc Hc1 ||2F + ||X2 − Wc Hc2 − Wr Hr 2 ||2F
2
2
1
+ ||X − Wc Hc − Wr Hr − Wη Hη ||2F
(8)
2

where Wc , Wr , Wη , Hc , Hr , and Hη represent the required BS
and time varying gain information (weighting coefficients) of
Sc , Sr , and η, respectively. The parameters γ1 and γ2 control
the weights of the shared factors.
1) Update Rules: We derive the multiplicative updates for
Wc , Wr , Wη , Hc , Hr , Hη , Hc2 , Hr 2 , and Hc1 which iteratively minimize the objective function (8) with nonnegativity
constraints. The gradients of the objective function with the
above factors are given in the following:
∂Δ
= −XHcT + Wc Hc HcT + Wr Hr HcT + Wη Hη HcT
∂Wc


T
T
T
+ γ2 −X2 Hc2
+ Wc Hc2 Hc2
+ Wr Hr 2 Hc2


T
T
(9)
+ Wc Hc1 Hc1
+ γ1 −X1 Hc1
∂Δ
= −XHrT + Wc Hc HrT + Wr Hr HrT + Wη Hη HrT
∂Wr


+ γ2 −X2 HrT2 + Wc Hc2 HrT2 + Wr Hr 2 HrT2 (10)
∂Δ
= −XHηT + Wc Hc HηT + Wr Hr HηT + Wη Hη HηT
∂Wη
(11)
∂Δ
∂Hc

= −WcT X + WcT Wc Hc + WcT Wr Hr + WcT Wη Hη
(12)

∂Δ
∂Hr

= −WrT X + WrT Wc Hc + WrT Wr Hr + WrT Wη Hη
(13)

∂Δ
∂Hη

= −WηT X + WηT Wc Hc + WηT Wr Hr + WηT Wη Hη
(14)

∂Δ
∂Hc2

= −WcT X2 + WcT Wc Hc2 + WcT Wr Hr 2

(15)

∂Δ
∂Hr 2

= −WrT X2 + WrT Wc Hc2 + WrT Wr Hr 2

(16)

154

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 1, JANUARY 2015

∂Δ
∂Hc1

= −WcT X1 + WcT Wc Hc1 .

(17)

In our derivations, we follow the approach used in [11], where
the gradient of the objective function is decomposed as

	+ 
	−
∂Δ
∂Δ
∂Δ
=
−
(18)
∂Φ
∂Φ
∂Φ

 +

 −
where ∂∂ Δ
> 0 and ∂∂ Δ
> 0. The multiplicative updates
Φ
Φ
for Φ is given by

 ∂ Δ −
Φ ← Φ  
 ∂ Φ + .
∂Δ

(19)

∂Φ

Using (18) and (19), we get the following update rules: (20),
(21) shown in bottom of page
Wη ← Wη 
Hc ← H c 
Hr ← H r 
Hη ← H η 

XHηT
Wc Hc HηT + Wr Hr HηT + Wη Hη HηT

(22)

WcT X
(23)
WcT Wc Hc + WcT Wr Hr + WcT Wη Hη
WrT

WrT X
(24)
Wc Hc + WrT Wr Hr + WrT Wη Hη

WηT X
(25)
WηT Wc Hc + WηT Wr Hr + WηT Wη Hη

Hc2 ← Hc2 

WcT X2
WcT Wc Hc2 + WcT Wr Hr 2

(26)

Hr 2 ← H r 2 

WrT X2
WrT Wc Hc2 + WrT Wr Hr 2

(27)

Hc1 ← Hc1 

WcT X1
.
WcT Wc Hc1

(28)

Algorithm 2: Proposed semisupervised BSS method.
1: Compute magnitude spectrograms X1 , X2 , and X
2: Initialize the matrices Wc , Wr , Wη , Hc , Hr , Hη , Hc2 ,
Hr 2 , and Hc1 with random nonnegative values
3: Iteratively update each matrix using (20)–(28) for a
predefined number of iterations
4: Estimate magnitude spectrogram of the ith source as
X(i) = Wi Hi
The semisupervised BSS method is summarized in Algorithm
2. It is important to mention that NMF-SF provides nearly perfect separation for the windowed disjoint orthogonal sources.

Fig. 3. Generic clustering example. (a) shows a mixture of two sources having
spectral overlap, (b) clustering with K = 2, divides the mixture into highand low-frequency components, and (c) clustering with K = 10, form small
clusters, which needs further clustering to estimate the original sources.

However, real-life signals are not completely windowed disjoint orthogonal, and therefore, approximate separability can be
considered.
D. Unsupervised BSS
In scenarios where training data are not available, we propose UBSL without the use of training data. During the UBSL
phase, we assume only the white Gaussian noise in the mixing model, i.e., X2 = Sc + Sr + ηw . Again, prior to separation,
we remove the white Gaussian noise by applying the classical
time-frequency denoising techniques (e.g., Wiener postprocessing, block thresholding, OGS [22], etc.). The UBSL phase dynamically learns the BS of the mixing sources, where we use a
hierarchical clustering approach: 1) clustering of mixture into
underlying basis vectors using NMF, and 2) clustering of the
basis vectors to form the complete BS of the individual sources.
1) NMF-Based Clustering: The first clustering is achieved
by decomposing a small batch of the mixture into various basis
vectors using standard NMF (discussed in Section II-B). We
select the length of the small batch , T sb equal to one complete
cycle of a mixing source with lowest cyclic frequency. The
reason for this is twofold 1) to capture spectral structure of all
the mixing sources in one cycle, and 2) to reduce computation
cost as compared to full-batch approach. We choose a large K
provided K < min{F, T sb }, such that we separate all the basis
in the mixture. It must be noted that by choosing K equal to
the number of sources (such as proposed in [23]), we cannot
completely separate the sources that have spectral overlap such
as shown in Fig. 3.
2) BS Clustering: In our method, we exploit a priori knowledge of the number of sources and the structure of the sources.
The second clustering is the grouping of similar basis vectors,
to form the complete BS of the sources. We denote the proposed
BS clustering technique as BS clustering. The BS-clustering
can be viewed as hierarchical clustering. Unlike the k-means
clustering algorithm [24], the BS-clustering, groups the already
clustered basis vectors of the sources. The NMF provides a partbased decomposition. The basis vectors, i.e., the columns of W

W c ← Wc 

T
T
+ γ1 X1 Hc1
XHcT + γ2 X2 Hc2
T + W H HT ) + γ W H HT
Wc Hc HcT + Wr Hr HcT + Wη Hη HcT + γ2 (Wc Hc2 Hc2
r r 2 c2
1 c c1 c1

(20)

Wr ← Wr 

XHrT + γ2 X2 HrT2
Wc Hc HrT + Wr Hr HrT + Wη Hη HrT + γ2 (Wc Hc2 HrT2 + Wr Hr 2 HrT2 )

(21)

SHAH et al.: ON THE BLIND RECOVERY OF CARDIAC AND RESPIRATORY SOUNDS

give different parts of the complete BS of the original sources.
The measure of similarity between basis vectors are discussed
in Section II-D3). Like the k-means clustering algorithm, we
also need a reference basis spectrum (RBS) of the individual
sources. The RBS selection is discussed in Section II-D4). The
BS-clustering technique is summarized in Algorithm 3.
Algorithm 3: BS-clustering.
1: Select initial RBS for all the mixing sources
2: Assign the closest basis vector to each RBS
3: Compute the new RBS by adding the newly assign basis
to the previous RBS
4: Repeat the Steps 2 and 3, until all basis vectors are
assigned
5: Return the final RBS as complete BS of the sources
3) Similarity Metrics: Various metrics can be used to calculate the similarity between the basis vectors. We define a general
correlation formula as

fk gk
(29)
cor = Cor (fk , gk ) = 

fk 2
gk 2
where fk and gk are vectors having equal lengths. cor ∈ [0, 1]
and cor = 1 shows maximum correlation, whereas cor = 0 dictates that fk and gk are uncorrelated.
4) RBS Selection: This step is similar to the centroid selection of the k-means clustering algorithm. In the specific application of the cardiac and respiratory sounds separation, we exploit
the fact that below 100 Hz and above 300 Hz, the mixture is
dominant by the cardiac and respiratory sounds, respectively
[25]. This is also shown in the magnitude spectrogram of the
clinical mixture through Fig. 6(f). These two regions are used to
select the RBS. Based on (29), we calculate a kind of correlation,
which we call spectral correlation . The spectral correlation is
defined as


(30)
cf = Cor Wk , Wiref
where cf is the correlation between the basis vectors of the
mixed and reference regions and cf ∈ [0, 1]. For reference basis
selection we maximize the function defined in (30).
5) Dynamic BS Updates: In certain critical applications, i.e.,
cardiac and respiratory sounds separation, the spectral characteristics of the sources may change overtime. In such a scenario,
static BS will result in poor separation. To mitigate this problem, we propose a dynamic BS update technique. We exploit
the cyclo-stationary property of the source. Analyzing online
clinical data of the cardiac and respiratory sounds given in [26],
we calculate their approximate cyclic frequency. We choose the
optimum length of small batch to be equal to the duration of
the respiratory cyclic period, in order to capture the complete
spectral structure in one cycle.
6) Summary of the Unsupervised BSS Algorithm: The various steps of the proposed unsupervised BSS technique are summarized in Algorithm 4. It should be noted that the steps 1–4
are used for dynamic UBSL. Now, analyzing the computational
complexity of Algorithm 4 and comparing with Algorithm 1,

155

if we choose to learn the BS once and do not update as done
in Algorithm 1, the computational complexities of Algorithm
4 and Algorithm 1 are almost the same. For dynamic spectral
update, the steps from 1 to 4 of the proposed Algorithm 4 must
be repeated according to the update frequency. In this scenario,
the computational cost of Algorithm 4 is increased by a factor
equal to the frequency of update. To summarize, our proposed
algorithm exhibits the classic tradeoff between performance and
computational cost.
Algorithm 4: Proposed unsupervised BSS method.
1: Find NMF of a small batch X2sb of the mixture X2 , with
I < K < min{T sb , F }, where T sb corresponds to the
length of the small batch X sb ≈ W sb H sb
2

2: Select Wiref , with 2 ≤ i ≤ I (a reference for each
source)
3: Cluster basis vectors, i.e., columns of W sb to form the
BS of all the sources using Algorithm 3
4: Concatenate the BS W BS of the sources into a single
 = [W BS , . . . W BS ]
matrix, W
1
I
 , X2 ≈ W
H
5: Find NMF of the mixture with fixed W
6: Estimate magnitude spectrogram of the ith source as
X2(i) = WiB S Hi

E. Reconstruction
Once the magnitude spectrogram is approximated into original sources, the corresponding phases can also be approximated
using the original spectrogram. We generate a time-frequency
mask for each source and apply the corresponding mask to
the original spectrogram, to recover the original sources. We
construct a time-frequency mask as

1 ∀ X(i) > X(j ) , j ∈ {r, c}, j = i
Mi =
(31)
0, otherwise.
The idea of time-frequency masking is based on the assumption that cardiac and respiratory sound signals are sparse [21],
which means that over a small time-frequency region only one
source dominates. The time-frequency mask (31) is applied to
the spectrogram of the mixture (1) to recover the original sources
as
Si [t, f ] = Mi  X[t, f ].

(32)

The inverse short-time Fourier transform is used to convert the
original sources back into the time domain.
III. RESULTS AND DISCUSSIONS
A. Experimental Setup
To measure the performance of the method, we define as
performance metric the normalized mean squared error (NMSE)

(s[m] − ŝ[m])2
(33)
NMSE = 10log10

s[m]2

156

IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 19, NO. 1, JANUARY 2015

TABLE I
COMPARISON WITH IMPORTANT EXISTING TECHNIQUES
Method
[8]
[20]
[9]
[23]
Traditional-NMF
Our Method

No. of Subjects

Signal Conditioning

Interference Model

Data Type

Processing Tools

Performance

6 healthy
6 healthy
5 healthy
6
6
8 healthy

Fs = 2 kHz
Fs = 2.5 kHz
Fs = 4 kHz, 44 kHz
Fs = 4 kHz, 44.1 kHz

sc
η w and s c
η w and s c
sc
sc
η w , η , and s c

clinical
clinical
synthetic and clinical
synthetic
synthetic
synthetic and clinical

CFS
AF
SSA
NMF
NMF
NMF

84.2%
79.6%
94.3%

Fig. 4. BSS of cardiac and respiratory sounds using the proposed semisupervised BSS method. (a)–(c) show the original cardiac, respiratory, and nonstationary sound sources, respectively. (d)–(f) show the recovered cardiac, respiratory,
and nonstationary noise sound sources, respectively. (g) and (h) compare a
segment of the recovered (solid red) and original (dot-dash blue) cardiac and
respiratory sounds, whereas (i) shows the observation mixture. The cardiac
sound components S1 and S2 are also labeled in (g).

Fig. 6. BSS of cardiac and respiratory sounds using the proposed unsupervised BSS method. (a)–(c) show the recovered cardiac, respiratory sounds, and
clinical mixture in the time domain, respectively. (d)–(f) show spectrograms
of the recovered cardiac, respiratory sounds, and clinical mixture, respectively.
(g) and (h) compare the recovered (solid red) and original (dot-dash blue) cardiac and respiratory sounds, respectively, while (i) shows separated respiratory
sound using traditional NMF. The cardiac sound components S1 and S2 are also
labeled in (g).

diac and respiratory sounds are nonstationary. However, these
sources exhibit cyclo-stationary characteristics. Using the data
sample given in [26], we calculate the average cyclic period of
the respiratory sound as 3.2 s, which we use as the length of the
small batch.
Fig. 5. NMSE performance of the proposed semisupervised BSS. The graphs
illustrate the NMSE of various recovered sources versus number of iterations.

where s[m] and ŝ[m] represent the original and recovered signals, respectively. In our experiments, for STFT representation,
a Hanning window of length 23.2 ms with 50% overlap was
used. The parameter K = {15, 20, 30} was used with the unsupervised algorithm; however, the best results were obtained
with K = 20 as shown in Fig. 6. The parameters γ1 = 1, γ2 = 1
were used in the experiments. The maximum number of iterations used for NMF-SF and NMF was 100 and 130, respectively.
MATLAB was used for simulations.
B. Clinical Data
The data samples taken from [26] were obtained from different subjects, in noisy clinical settings, using a digital stethoscope, with a data sampling frequency of 4 kHz. A data sample
is a real mixture of cardiac and respiratory sounds. The car-

C. Smart Auscultation
To evaluate the BSS performance of the semisupervised
method, we synthetically mix the real cardiac and respiratory
sounds with nonstationary noise. The nonstationary noises η
were recorded in the actual clinical environment (which includes men talking, mobile ringing, and little machine noises).
Fig. 4 illustrates the BSS performance of the semisupervised
technique, where good separation is achieved, even in the presence of nonstationary noise sources. Fig. 5 shows the NMSE
of various sources versus number of iterations. A significantly
better separation is achieved as compared to [17], even after few
iterations.
The proposed unsupervised BSS method can be applied 1)
as offline to recorded clinical data, and 2) as online to the real
time short recordings. In our experiments, we applied the BSS
method offline to the recorded data discussed in Section III-B.
The data are collected in actual clinical setting. Fig. 6 shows

SHAH et al.: ON THE BLIND RECOVERY OF CARDIAC AND RESPIRATORY SOUNDS

the cardiac and respiratory sounds recovery from their clinical mixture using the proposed BSS method. Fig. 6 also shows
the different sound signals in the time domain, as well as in
the time-frequency domain. We compare our proposed BSS
method with traditional NMF-based BSS. In traditional NMFbased BSS without training data, we select K = 2, i.e., the
number of sources (such as proposed in [23]). Fig. 6(i) illustrates the recovered respiratory sounds using traditional NMF.
Interference of the cardiac sound in the recovered respiratory
sound is visible in Fig. 6(i), whereas this interference is highly
minimized in the proposed unsupervised BSS method illustrated
in Fig. 6(b), (e), and (h). In the BSS shown in Fig. 6, BS of the
sources were learned 1) over each individual small batch , and
2) over the first small batch which was used for the rest of the
data. The results are compared in Fig. 6(g) and (h) with the original signals, showing a close match. Our algorithms do not affect
the magnitude and phase of the recovered signals significantly.
D. Comparison With Existing Techniques
A comparison between some important existing methods is
given in Table I. For a quantitative comparison between similar
(NMF-based) methods, we use performance metric defined in
[23]. It is worth mentioning that none of the existing methods
discussed assume nonstationary noise in the interference (noise)
model, whereas we do.
IV. CONCLUSION
In this paper, blind recovery of cardiac and respiratory sounds
has been addressed. Two novel BSS methods are proposed in the
framework of NMF. The semisupervised BSS method recover
the original sources, even in the presence of nonstationary noise
sources. The unsupervised BSS method can be applied to the
scenarios, where training data are not available. The BS of the
mixing sources are learned directly from the mixture in unsupervised fashion. Furthermore, to mitigate the spectral variations of
the sources, a dynamic BS update technique is also introduced.
The data are processed in small batches, which enables dynamic
spectral update and reduces the computational complexity. The
proposed BSS methods are successfully applied to the BSS of
the cardiac and respiratory sounds mixtures using clinical as
well as synthetic data and compared against important existing methods. To the best of our knowledge, our method shows
significantly better results even for the noisy clinical data and
outperforms similar NMF-based existing methods.
REFERENCES
[1] N. Gavriely, M. Nissan, A. E. Rubin, and D. W. Cugell, “Spectral characteristics of chest wall breath sounds in normal subjects,” Thorax, vol. 50,
pp. 1292–1300, Dec. 1995.
[2] T. Rice, “Learning to listen: Auscultation and the transmission of auditory
knowledge,” J. Roy. Anthropol. Inst., vol. 16, pp. s41–s61, 2010.
[3] B. Makkiabadi, D. Jarchi, and S. Sanei, “A new time domain convolutive
BSS of heart and lung sounds,” in Proc. IEEE Int. Conf. Acoust., Speech
Signal Process., 2012, pp. 605–608.
[4] F. L. Hedayioglu, M. G. Jafari, S. S. Mattos, M. D. Plumbley, and M.
T. Coimbra, “Separating sources from sequentially acquired mixtures of
heart signals,” in Proc. IEEE Int. Conf. Acoust., Speech Signal Process.,
Prague, Portugal, May 2011, pp. 653–656.

157

[5] J. Gnitecki and Z. Moussavi, “Separating heart sounds from lung
sounds—accurate diagnosis of respiratory disease depends on understanding noises,” IEEE Eng. Med. Biol. Mag., vol. 26, no. 1, pp. 20–29,
Jan. 2007.
[6] A. Misal and G. R. Sinha, “Separation of lung sound from PCG signals using wavelet transform,” J. Basic Appl. Phys., vol. 1, pp. 57–61,
Aug. 2012.
[7] T. E. A. Khan and P. Vijayakumar, “Separating heart sound from lung
sound using labview,” Int. J. Comput. Electr. Eng., vol. 2, no. 3, pp. 526–
533, Jun. 2010.
[8] T. Li, H. Tanga, T. Qiua, and Y. Park, “Heart sound cancellation from
lung sound record using cyclostationarity,” Med. Eng. Phy., vol. 35, pp.
1831–1836, May 2013.
[9] F. Ghaderi, H. R. Mohseni, and S. Sanei, “Localizing heart sounds in
respiratory signals using singular spectrum analysis,” IEEE Trans. Biomed.
Eng., vol. 58, no. 12, pp. 3360–3367, Dec. 2011.
[10] D. D. Lee and H. S. Seung, “Learning the parts of objects by non-negative
matrix factorization,” Nature, vol. 401, pp. 788–791, 1999.
[11] T. Virtanen, “Monaural sound source separation by nonnegative matrix
factorization with temporal continuity and sparseness criteria,” IEEE
Trans. Audio, Speech, Lang. Process., vol. 15, no. 15, pp. 1066–1074,
Mar. 2007.
[12] J. Paulus and T. Virtanen, “Drum transcription with non-negative spectrogram factorization,” in Proc. 13th Eur. Signal Process. Conf., Antalya,
Turkey, Sep. 2005, pp. 4–8.
[13] Y. Wang and Y. J. Zhang, “Nonnegative matrix factorization: A comprehensive review,” IEEE Trans. Knowl. Data Eng., vol. 25, no. 6,
pp. 1336–1353, Jun. 2013.
[14] Z. Huang, A. Zhou, and G. Zhang, “Non-negative matrix factorization: A
short survey on methods and applications,” in Computational Intelligence
and Intelligent Systems (Communications in Computer and Information
Science), Z. Li, X. Li, Y. Liu, and Z. Cai, Eds. Berlin, Germany: Springer,
2012, pp. 331–340.
[15] B. Wang and M. Plumbley, “Investigating single-channel audio source
separation methods based on non-negative matrix factorization,” in Proc.
ICA Res. Netw. Int. Workshop, Sep. 2006, pp. 17–20.
[16] H. Laurberg, M. N. Schmidt, M. G. Christensen, and S. H. Jensen, “Structured non-negative matrix factorization with sparsity patterns,” in Proc.
42nd Asilomar Conf. Signals, Syst. Comput., Oct. 2008, pp. 1693–1697.
[17] M. Kim, J. Yoo, K. Kang, and S. Choi, “Nonnegative matrix partial cofactorization for spectral and temporal drum source separation,” IEEE J.
Sel. Topics Signal. Process., vol. 5, no. 6, pp. 1192–1204, Oct. 2011.
[18] S. Charleston and M. R. A. Sadjadi, “Reduced order Kalman filter for the
enhancement of respiratory sounds,” IEEE Trans. Biomed. Eng., vol. 43,
no. 4, pp. 421–424, Apr. 1996.
[19] G. Shah and C. Papadias, “Blind recovery of cardiac and respiratory sounds
using non-negative matrix factorization & time-frequency masking,” in
Proc. IEEE 13th Int. Conf. BioInformat. BioEng., Crete, Greece, Nov.
2013, pp. 1–5.
[20] L. J. Hadjileontiadis and S. M. Panas, “Adaptive reduction of heart sound
from lung sounds using fourth-order statistics,” IEEE Trans. Biomed. Eng.,
vol. 44, no. 7, pp. 642–648, Jul. 1997.
[21] G. Shah and C. Papadias, “Separation of cardiorespiratory sounds using
time-frequency masking and sparsity,” in Proc. 18th Int. Conf. Dig. Signal
Process., Greece, Jul. 2013, pp. 1–6.
[22] P. Y. Chen and I. W. Selesnick, “Translation-invariant shrinkage/thresholding of group sparse signals,” Signal Process., vol. 94,
pp. 476–489, Jan. 2014.
[23] C. Lin and E. Hasting, “Blind source separation of heart and lung sounds
based on nonnegative matrix factorization,” in Proc. Int. Symp. Intell.
Signal Process. Commun. Syst., Nov. 2013, pp. 731–736.
[24] J. B. MacQueen, “Some methods for classification and analysis of multivariate observations,” in Proc. 5th Berkeley Symp. Math. Stat. Probab.,
Berkeley, CA, USA, 1967, pp. 281–297.
[25] M. T. Pourazad, Z. Moussavi, F. Farahmand, and R. K. Ward, “Heart
sounds separation from lung sounds using independent component analysis,” in Proc. IEEE-EMBS, 27th Annu. Int. Conf. Eng. Med. Biol., Shanghai, China, Jan. 2006, pp. 2736–2739.
[26] P. Bentley, G. Nordehn, M. Coimbra, and S. Mannor, The PASCAL
Classifying Heart Sounds Challenge (CHSC2011) Results,
Standard, 2011. [Online]. Available: http://www.peterjbentley.com
/heartchallenge/index.html.

Authors’ photographs and biographies not available at the time of publication.

