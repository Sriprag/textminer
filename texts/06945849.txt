IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 4, APRIL 2015

1077

Robotic System for MRI-Guided
Stereotactic Neurosurgery
Gang Li† , Student Member, IEEE, Hao Su†∗ , Member, IEEE, Gregory A. Cole, Member, IEEE,
Weijian Shang, Student Member, IEEE, Kevin Harrington, Alex Camilo, Julie G. Pilitsis,
and Gregory S. Fischer, Member, IEEE

Abstract—Stereotaxy is a neurosurgical technique that can take
several hours to reach a specific target, typically utilizing a mechanical frame and guided by preoperative imaging. An error in any
one of the numerous steps or deviations of the target anatomy from
the preoperative plan such as brain shift (up to 20 mm), may affect
the targeting accuracy and thus the treatment effectiveness. Moreover, because the procedure is typically performed through a small
burr hole opening in the skull that prevents tissue visualization,
the intervention is basically “blind” for the operator with limited
means of intraoperative confirmation that may result in reduced
accuracy and safety. The presented system is intended to address
the clinical needs for enhanced efficiency, accuracy, and safety of
image-guided stereotactic neurosurgery for deep brain stimulation
lead placement. The study describes a magnetic resonance imaging (MRI)-guided, robotically actuated stereotactic neural intervention system for deep brain stimulation procedure, which offers
the potential of reducing procedure duration while improving targeting accuracy and enhancing safety. This is achieved through
simultaneous robotic manipulation of the instrument and interactively updated in situ MRI guidance that enables visualization
of the anatomy and interventional instrument. During simultaneous actuation and imaging, the system has demonstrated less than
15% signal-to-noise ratio variation and less than 0.20% geometric
distortion artifact without affecting the imaging usability to visualize and guide the procedure. Optical tracking and MRI phantom
experiments streamline the clinical workflow of the prototype system, corroborating targeting accuracy with three-axis root mean
square error 1.38 ± 0.45 mm in tip position and 2.03 ± 0.58◦
in insertion angle.
Index Terms—Deep brain stimulation, image-guided therapy,
magnetic resonance imaging (MRI)-compatible robotics, robotassisted surgery, stereotactic neurosurgery.

Manuscript received January 12, 2014; revised October 29, 2014; accepted
October 30, 2014. Date of publication November 4, 2014; date of current version March 17, 2015. This work was supported in part by the National Institutes of Health R01CA166379 and Congressionally Directed Medical Research
Program W81XWH-09-1-0191. †indicates shared first authorship. Asterisk indicates corresponding author.
∗ H. Su is with the Philips Research North America, Briarcliff Manor, NY
10510 USA (e-mail: haosu.ieee@gmail.com).
G. Li, W. Shang, K. Harrington, A. Camilo, and G. S. Fischer are with the
Automation and Interventional Medicine Laboratory, Worcester Polytechnic
Institute, Worcester, MA 01609 USA .
G. A. Cole is with the Philips Research North America, Briarcliff Manor, NY
10510 USA .
J. G. Pilitsis is with the Neurosurgery Group, Albany Medical Center, Albany,
NY 12208 USA .
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2014.2367233

I. INTRODUCTION
TEREOTACTIC neurosurgery enables surgeons to target
and treat diseases affecting deep structures of the brain,
such as through stereotactic electrode placement for deep brain
stimulation (DBS). However, the procedure is still very challenging and often results in nonoptimal outcomes. This procedure is very time-consuming, and may take 5–6 h with hundreds
of steps. It follows a complicated workflow including preoperative MRI (typically days before the surgery), preoperative
computed tomography (CT), and intraoperative MRI-guided intervention (where available). The procedure suffers from tool
placement inaccuracy that is related to errors in one or more
steps in the procedure, or is due to brain shift that occurs
intraoperatively. According to [1], the surface of the brain is
deformed by up to 20 mm after the skull is opened during
neurosurgery, and not necessarily in the direction of gravity.
The lack of interactively updated intraoperative image guidance
and confirmation of instrument location renders this procedure
nearly “blind” without any image-based feedback.
DBS, the clinical focus of this paper, is a surgical implant
procedure that utilizes a device to electrically stimulate specific
structures. DBS is commonly used to treat the symptoms of motion disorders such as Parkinson’s disease, and has shown effective for various other disorders including obsessive-compulsive
disorder and severe depression. Unilateral lead is implanted
to the subthalamic nucleus (STN) or globus pallidus interna
(GPi) for Parkinson’s disease and dystonia. While bilateral leads
are implanted to the ventral intermediate nucleus of the thalamus (VIM). Recently, improvement in intervention accuracy has
been achieved through direct MR guidance in conjunction with
manual frames such as the NexFrame (Medtronic, Inc., USA)
[2] and Clearpoint (MRI Interventions, Inc., USA) [3] for DBS.
However, four challenges are still not addressed. First, manual
adjustment of the position and orientation of the frame is nonintuitive and time-consuming. Moreover, the clinician needs to
mentally solve the inverse kinematics to align the needle. Second, manually-operated frames have limited positioning accuracy, inferior to a motorized closed-loop control system. Third,
the operational ergonomics, especially the hand–eye coordination, is awkward during the procedure (the operator has to reach
about 1 m inside the scanner) while observing the MRI display
(outside of the scanner). Fourth, most importantly, real-time
confirmation of the instrument position is still lacking.
To address these issues, robotic assistants, especially that
are compatible inside MRI environment have been studied.
Non-MRI compatible NeuroMate robot (Renishaw Inc., United

S

0018-9294 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

1078

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 4, APRIL 2015

Kingdom) had a reported accuracy of 1.7 mm for DBS electrode placement in 51 patients, although many cases required
several insertion attempts and errors due to brain shift led to
sufficient accuracy in only 37 of 50 targets [4]. Masamune et al.
[5] designed an MRI-guided robot for neurosurgery with ultrasonic motors (USR30-N4, Shinsei Corporation, Japan) inside
low field strength scanners (0.5 T) in 1995. Yet, stereotaxy requires high-field MRI (1.5–3 T) to achieve adequate precision.
Sutherland et al. [6] developed NeuroArm robot, a manipulator
consisting of dual dexterous arms driven by piezoelectric motors
(HR2-1N-3, Nanomotion Ltd., Israel) for operation under MR
guidance. Since this general purpose neurosurgery robot aims
to perform both stereotaxy and microsurgery with a number of
tools, the cost could be formidably high. Ho et al. [7] developed a
shape-memory-alloy driven finger-like neurosurgery robot. This
technology shows promise, however, it is still in the early development and requires high temperature intracranially with very
limited bandwidth. Comber et al. [8] presented a pneumatically
actuated concentric tube robot for MRI-guided neurosurgery.
However, the inherent nonlinearity and positioning limitation
of pneumatic actuation, as demonstrated in [9], present significant design challenge. Augmented reality has also been shown
effectiveness to improve the MRI-guided interventions by Liao
et al. [10]and Hirai et al. [11].
There is a critical unmet need for an alternative approach
that is more efficient, more accurate, and safer than traditional
stereotactic neurosurgery or manual MR-guided approaches. A
robotic solution can increase the accuracy over the manual approach, however its inability to visualize the anatomy and instrument during intervention due to incompatibility with the
MR scanner limits the safety and accuracy. Simultaneous precision intervention and interactively updated imaging is critical to guide the procedure either for brain shift compensation
or target confirmation. However, there have been great challenges in developing actuation approaches appropriate for use
in the MRI environment. Piezoelectric and pneumatic actuators
are the mainstay approaches for robotic manipulation inside
MRI. Piezoelectric actuators can offer nanometer level accuracy without overshooting, but typically cause 26–80% SNR
loss with commercial off-the-shelf motor driver during motor
operation even with motor shielding [12]. Pneumatic actuators,
either customized pneumatic cylinders from our group [13] or
novel pneumatic steppers [14] tend to be difficult to control, especially in a dynamic manner. The one developed by Yang et al.
[9] demonstrated 2.5–5 mm steady-state error due to oscillations for a single axis motion. Reviews of MRI-guided robotics
about piezoelectric and pneumatic actuation can be found
in [15]–[17].
To address these unmet clinical needs, this paper proposes
a piezoelectrically-actuated cannula placement robotic assistant that allows simultaneous imaging and intervention without negatively impacting MR image quality for neurosurgery,
specifically for DBS lead placement. In previous publications,
the mechanism concept of this robot was explored [18], [19],
whereas the detailed mechanical design of the robot, electrical
design of the motor control system, control software or accuracy
evaluation was not developed. This paper presents the complete

Fig. 1. Workflow comparison of manual frame-based approach and MRIguided robotic approach for unilateral DBS lead placement. (a) Workflow of a
typical lead placement with measured average time per step. (b) Workflow of
an MRI-guided robotic lead placement with estimated time per step.

electromechanical design, system integration, MRI compatibility and accuracy evaluation of a fully functional prototype system. The mechanism is the first robotic embodiment that is
kinematically equivalent to traditionally used manual stereotactic frames such as the Leksell frame (Elekta AB, Sweden). The
primary contributions of the paper include: 1) a novel design
of an MRI-guided robot that is kinematically equivalent to a
Leksell frame; 2) a piezoelectric motor control system that allows simultaneous robot motion and imaging without affecting
the imaging usability to visualize and guide the procedure; 3)
robot-assisted workflow analysis demonstrating the potential to
reduce procedure time; and 4) imaging quality and accuracy
evaluation of the robotic system.
II. CLINICAL WORKFLOW OF MRI-GUIDED
ROBOTIC NEUROSURGERY
The current typical workflow for DBS stereotactic neurosurgery involves numerous steps. The following list describes
the major steps as illustrated in Fig. 1(a):
1) Acquire MR images prior to day of surgery;
2) Perform preoperative surgical planning;
3) Surgically attach fiducial frame;
4) Interrupt procedure to acquire CT images;
5) Fuse preoperative MRI-based plan to preoperative CT;
6) Use stereotactic frame to align the cannula guide and place
the cannula;
7) Optionally confirm placement with nonvisual approach
such as microelectrode recording (MER, a method that
uses electrical signals in the brain to localize the surgical
site) and/or visual approach such as fluoroscopy which
can localize the instrument but not the target anatomy.
During the workflow, there are hundreds of points where errors could be introduced, these errors are categorized as three
main subtypes : 1) those associated with planning, 2) with the

LI et al.: ROBOTIC SYSTEM FOR MRI-GUIDED STEREOTACTIC NEUROSURGERY

frame, and 3) with execution of the procedure. Our approach,
especially the new workflow, as shown in Fig. 1(b), addresses all
these three errors. First, error due to discrepancies between the
preoperative plan and the actual anatomy (because of brain shift)
may be attenuated through the use of intraoperative MR imaging. Second, closed-loop controlled robotic needle alignment
eliminates the mental registration between image and actual
anatomy, while provides precise motion control in contrast to
the inaccurate manual frame alignment. Third, errors that arise
with execution would be compensated with intraoperative interactively updated MR image feedback. To sum up, by attenuating
all three error sources, these advantages enabled by the robotic
system could potentially improve interventional accuracy and
outcomes.
The procedure duration is potentially reduced significantly
from two aspects: 1) avoiding a CT imaging session and corresponding image fusion and registration, and 2) using direct image guidance instead of requiring additional steps using MER.
As shown in Fig. 1(b): 1) The proposed approach completely
removes the additional perioperative CT imaging session potentially saving about one hour of procedure time and the complex logistics of breaking up the surgical procedure for CT
imaging. 2) During the electrode placement, the current guidance and confirmation method relies on microelectrode recording, a one-dimensional signal to indirectly localize the target.
MER localization takes about 40 min in an optimal scenario,
and could take one hour more if not. In contrast to the indirect,
iterative approach with MER, the proposed system utilizes MR
imaging to directly visualize placement. Eliminating the need
for MER may reduce about one hour of procedure time per electrode, and in the typical DBS procedure with bilateral insertion
this would result in a benefit of two hours. Therefore, for a bilateral insertion, the benefit in reduced intraoperative time could
potentially be as great as three hours, on top of the benefits of
improved planning and accurate execution of that plan.
III. ELECTROMECHANICAL SYSTEM DESIGN
This section presents the electromechanical design of the
robotic system. The configuration of this system in the MR
scanner suite is illustrated in Fig. 2. Planning is performed on
preprocedure MR images or preoperative images registered to
the intraoperative images. The needle trajectories required to
reach these desired targets are evaluated, subject to anatomical
constraints, as well as constraints of the needle placement mechanism. The desired targets selected in the navigation software
3D Slicer [20] are sent to the robot control software through
OpenIGTLink communication protocol [21], wherein resolved
to the motion commands of individual joints via kinematics.
The commands are then sent to the custom MRI robot controller, which can provide high precision closed-loop control of
piezoelectric motors, to drive the motors and move the robot to
the desired target positions. The actual needle position is fed
back to the navigation software in image space for verification
and visualization.
To increase clinician comfort operating the device, as well
as limit the system’s complexity, cost and training required to

1079

Fig. 2. Configuration of the MRI-guided robotic neurosurgery system. The
stereotactic manipulator is placed within the scanner bore and the MRI robot
controller resides inside the scanner room. The robot controller communicates
with the control computer within the Interface Box through a fiber optic link.
The robot control software running on the control computer communicates with
3D Slicer navigation software through OpenIGTLink.

operate and maintain the equipment, the robot mechanism is
designed to be kinematically equivalent to the clinically used
manual stereotactic device Leksell stereotactic surgical frame.
Electrically, some research groups have utilized methods to reduce MRI artifact by avoiding operating electromechanical actuation during live imaging, such as interleaving robot motion and
MR imaging as demonstrated by Krieger et al. [12], or utilizing
less precise but reliable pneumatic actuation methods demonstrated by Fischer et al. [22]. In contrast to these approaches,
we have developed a custom piezoelectric motor control system
that induces no visually observable image artifact.
A. Actuators and Sensors for Applications in MRI
Environment
As has been discussed earlier, the harsh electromagnetic environment of the scanner bore poses a great challenge to the
construction of MRI compatible robotic systems. American Society for Testing and Materials (ASTM) and U.S. Food and Drug
Administration defined that “MR Safe” as an item that poses no
known hazard in all MRI environments. “MR Safe” items are
nonconducting, nonmetallic, and nonmagnetic. This definition
is about safety, while neither image artifact nor proper functioning of a device is covered. From the perspective of interventional mechatronics, the term “MRI-compatibility” is defined
[23] such that all components inside scanner room have been
demonstrated
1) not to pose any known hazards in its intended configuration (corresponding to the ASTM definition of MR
conditional),
2) not to have its intended functions deteriorated by the MRI
system,
3) not to significantly affect the quality of the diagnostic
information,
in the context of a defined application, imaging sequence and
configuration within a specified MRI environment.
The interference of a robotic system with the MR scanner is
attributed to its mechanical (primarily material) and electrical

1080

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 4, APRIL 2015

properties. From a materials perspective, ferromagnetic materials must be avoided entirely, though nonferrous metals such
as aluminum, brass, nitinol and titanium, or composite materials can be used with caution. In this robot, all electrical and
metallic components are isolated from the patient’s body. Nonconductive materials are utilized to build the majority of the
components of the mechanism, i.e., base structure are made of
3D-printed plastic materials and linkages are made out of high
strength, bio-compatible plastics including Ultem and PEEK.
From an electrical perspective, conductors passing through the
patch panel or wave guide could act as antennas, introducing
stray RF noise into scanner room and thus resulting in image
quality degradation. For this reason, the robot controller is designed to be placed inside scanner room and communicate with
a computer in the console room through fiber optic medium.
Even in this configuration, however, electrical interference from
the motors’ drive system can induce significant image quality
degradation including SNR loss. There are two primary types of
piezoelectric motors, harmonic and nonharmonic. Harmonic
motors, such as Nanomotion motors (Nanomotion Ltd., Israel)
and Shinsei motors (Shinsei Corporation, Japan), are generally driven with fixed frequency sinusoidal signal. Nonharmonic
motors, such as PiezoLegs motors (PiezoMotor AB, Sweden),
require a complex-shaped waveform on four channels generated with high precision at fixed amplitude. Both have been
demonstrated to cause interference within the scanner bore with
commercially available drive systems. The SNR reduction is
up to 80% [12] and 26% [24] for harmonic and nonharmonic
motors, respectively.
In this presented system, nonharmonic PiezoLegs motors
have been selected. PiezoLegs motor has the required torque
(50 mNm) but with small footprint ( 23 × 34 mm). NanoMotion (HR2-1-N-10, Nanomotion Ltd., Israel) only offers linear
motor with large footprint (40.5 mm × 25.7 mm × 12.7 mm)
that has to be used in opposing pairs [12] for either linear or
rotary motion. Shinsei motors (USR60-E3N, Shinsei Corporation, Japan) has bulky footprint ( 67 × 45 mm) with torque
0.1 Nm.
Optical encoders (US Digital, Vancouver, WA) EM1-0500-I linear (0.0127 mm/count) and EM1-1-1250-I rotary
(0.072◦ /count) encoder modules are used. The encoders are
placed on the joint actuators and reside in the scanner bore.
Differential signal drivers sit on the encoder module, and the
signals are transmitted via shielded twisted pairs cables to the
controller. The encoders have been incorporated into the robotic
device and perform without any evidence of stray or missed
counts.
B. Mechanism Design
The robotic manipulator is designed to be kinematically
equivalent to the commonly used Leksell stereotactic frame,
and configured to place an electrode within a confined standard
3-T Philips Achieva scanner bore with 60 cm diameter. The
manual frame’s x-, y-, and z-axis set the target position, and θ4
and θ5 align the orientation of the electrode as shown in Fig. 3
(left). A preliminary design for the robotic manipulator based

Fig. 3. Equivalence of the degrees of freedom of a traditional manual stereotactic frame (left) and the proposed robotic system (right). Translation DOF in
red, rotational DOF in green.

upon these requirements is described in our early study [18]
where neither the actuator, motion transmission nor the encoder
design was covered. The current study presents the first fullydeveloped functional prototype of this robot that has five-axis
motorized and encoded motion.
To mimic the functionality and kinematic structure of the
manual stereotactic frame, a combination of a 3-DOF prismatic
Cartesian motion base module and a 2-DOF remote center of
motion (RCM) mechanism module are employed, as shown in
Fig. 3 (right). The robot provides three prismatic motions for
Cartesian positioning (DOF #1 – DOF #3), two rotary motions corresponding to the arc angles (DOF #4 and DOF #5),
and a manual cannula guide (DOF #6). To maintain good stiffness of the robot in spite of the plastic material structure, three
approaches have been implemented. 1) Parallel mechanism is
used for the RCM linkage and Scott–Russell vertical motion
linkages to take advantage of the enhanced stiffness due to the
closed-chain structure; 2) High strength plastic Ultem [stiffness 1 300 000 pounds per square inch (PSI)] is machined to
construct the RCM linkage. The Cartesian motion module base
is primarily made of 3D-printed ABS plastic (stiffness 304 000
PSI); 3) Nonferrous aluminum linear rails constitute mechanical
backbone to maintain good structural rigidity.
1) Orientation Motion Module: As portrayed in Fig. 4, the
manipulator allows 0◦ − 90◦ rotation motion in the sagittal
plane. The neutral posture is defined when the cannula/electrode
(1) inside the headstock (2) is in vertical position. In the transverse plane, the required range of motion is ±45◦ about the
vertical axis as specified in Table I. A mechanically constrained
RCM mechanism, in the form of a parallelogram linkage (3) was
designed. In order to reduce backlash, rotary actuation of RCM
DOF are achieved via Kevlar reinforced timing belt transmissions (7), which are loaded via eccentric locking collars (11),
eliminating the need for additional tension pulleys. The primary
construction material for this mechanism is polyetherimide
(Ultem), due to its high strength, machinability, and suitability
for chemical sterilization. This module mimics the arc angles of
the traditional manual frame.
2) Cartesian Motion Module: As shown in Fig. 5, linear travel through DOF #2 and #3 is achieved via direct
drive where a linear piezoelectric motor (PiezoLegs LL1011C,

LI et al.: ROBOTIC SYSTEM FOR MRI-GUIDED STEREOTACTIC NEUROSURGERY

Fig. 4. Exploded view of the RCM orientation module, showing (1) instrument/electrode, (2) headstock with cannula guide, (3) parallel linkage mechanism, (4) manipulator base frame, (5) flange bearings, (6) pulleys, (7) timing
belts, (8) rotary encoders, (9) encoder housings, (10) pulleys, (11) eccentric
locking collars, (12) rotary piezoelectric motors, (13) manipulator base.
TABLE I
JOINT SPACE KINEMATIC SPECIFICATIONS OF THE ROBOT
Axis
1
2
3
4
5
6

Motion

Robot

y
x
z
Sagittal plane angle
Transverse plane angle
Needle insertion

±35 mm
±35 mm
±35 mm
0−90◦
±45◦
0−75 mm

1081

Fig. 6. Reachable workspace of the stereotactic neurosurgery robot overlaid
on a representative human skull. The red ellipsoid represents the typical DBS
treatment target, i.e., the basal ganglia area.

illustrated in Table I, the range of motion for placement of the
robot’s center of rotation is ±35, ±35 and ±35 mm in x-, y-,
and z-axes, respectively. With respect to this neutral posture, the
robot has 0◦ − 90◦ rotation motion in the sagittal plane and ±45◦
in the transverse plane. For an electrode with 75-mm insertion
depth, the reachable workspace of the robot for target locations
is illustrated in Fig. 6 with respect to a representative skull
model based on the head and face anthropometry of adult U.S.
civilians [25]. The 95% percentile male head breath, length, and
stomion to top of head measurements are 16.1, 20.9 and 19.9
cm, respectively. This first prototype of the robot is able to cover
the majority of brain tissue inside the skull. Since basal ganglia
area is the typical DBS treatment target, which is approximated
as an ellipsoid in Fig. 6. Although the workspace is slightly
smaller than the skull, all typical targets and trajectories for
the intended application of DBS procedures are reachable. The
current robot workspace is also smaller than the Leksell frame
since the later is a generic neurosurgery mechanism, while this
robot is primarily tailored for DBS which has a much smaller
workspace requirement.
C. Piezoelectric Actuator Motion Control System

Fig. 5. Exploded view of the Cartesian motion module, showing (14) Scott–
Russell scissor mechanism, (15) lead-screw, (16) nut, (17) motor coupler, (18)
motor housing, (19) linear encoder, (20) linear piezoelectric motor, (21) linear
guide, (22) horizontal motion stage, (23) lateral motion stage.

PiezoMotor AB, Sweden), providing 6-N holding force and
1.5-cm/s speed, controls each decoupled 1-DOF motion. DOF
#1 is actuated via scissor lift mechanism (known as Scott–
Russell mechanism) driven by a rotary actuator (PiezoLegs,
LR80, PiezoMotor AB, Sweden) and an aluminum-anodized
lead screw (2-mm pitch). This mechanism is compact and attenuates structural flexibility due to plastic linkages and bearings.
3) Workspace Analysis: The range of motion of the robot
was designed to cover the clinically required set of targets and
approach trajectories (STN, GPi and VIM of the brain). As

A key reason that commercially available piezoelectric motor drivers affect image quality is due to the high frequency
switching signal. While a low-pass filter may provide benefit, it has not been effective in eliminating the interference
and often significantly degrades motor performance. To address
this issue, our custom motor controller utilize linear regulators
and direct digital synthesizers (DDS) to produce the driving
signal in combination with analog π filters. The control system comprises of four primary units as illustrated in Fig. 7:
1) the power electronics unit, 2) the piezoelectric driver unit
which directly interfacing with the piezoelectric motors, 3)
backplane controller unit, an embedded computer which translates high level motion information into device level commands,
and 4) an interface box containing the fiber optic Ethernet

1082

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 4, APRIL 2015

TABLE II
SCAN PARAMETERS FOR COMPATIBILITY EVALUATION
Protocol

T1W-FFE
T2W-TSE
T2W-TSE-Neuro

Fig. 7. Block diagram of the MRI robot control system. The power electronics
and piezoelectric actuator drivers are contained in a shielded enclosure and
connected to an interface unit in the console room through a fiber optic Ethernet
connection.

TE (ms)

TR (ms)

FA (deg)

Slice (mm)

Bandwidth
(Hz/pixel)

2.3
115
104

225
3030
4800

75
90
90

2
3
3

1314
271
184

low-voltage differential signaling (LVDS) receivers that connect
to two quadrature encoders (one of which may be replaced with
differential home and limit sensors). The motor control card
has a microcontroller (PIC32MX460F512L, Microchip Tech.,
USA) that loads a predefined waveform image from a secure
digital card into the FPGA’s DDS and then operates a feedback loop using the encoder output. The motor control cards are
interconnected via serial peripheral interface (SPI) bus to one
backplane controller which communicates over fiber optic 100FX Ethernet to the interface box in the room where a control PC
running the user interface is connected.
IV. EXPERIMENTAL EVALUATION AND RESULTS

Fig. 8. Block diagram showing the key components of a piezoelectric motor
driver card-based module.

communication hardware. The power electronics unit, piezoelectric drive unit and backplane controller unit are enclosed
in an electro-magnetic interference-shielded enclosure. A user
workstation, connected to the interface box in the console room,
which operates the navigation software 3D Slicer is the direct
interface for the physician.
The robot controller contains piezoelectric motor driver modules plugged into a backplane. The corresponding power electronics consists of cascaded regulators. The primary regulator
(F48-6-A+, SL Power Electronics, USA) converting from the
isolated, grounded 120-V ac supply in the MR scanner room
to 48-V dc is a linear regulator chosen for its low noise. Two
switching regulators modified to operate at ultra low frequencies with reduced noise generate the 5-V dc and 12-V dc (QS4805CBAN, OSKJ, USA) power rails that drive the logic and
analog preamplifiers of the control system, respectively. The
48-V dc from the linear regulator directly feeds the linear power
amplifiers for the motor drive signals (through a safety circuit).
An innovation of the custom-developed motor driver is to
use linear power amplifiers for each of the four drive channels
of the piezoelectric motors and a field-programmable gate array (FPGA, Cyclone EP2C8Q208C8, Altera Corp., USA)-based
DDS as a waveform generator to fundamentally avoid these high
frequency signals. As shown in Fig. 8, each motor control card
module of the piezoelectric driver unit, consists of four DDS
waveform generators. These generators output to two dualchannel high speed (125 million samples per second) digitalto-analog converters (DAC2904, Texas Instruments, USA) and
then connect to four 48-V linear power amplifiers (OPA549,
Texas Instruments, USA). The motor control card also has two

Two primary sets for experiments were run to assess imaging
compatibility with the MRI environment and positioning accuracy of the system. The effect of the robot on image quality was
assessed through quantitative SNR analysis, quantitative geometric distortion analysis and qualitative human brain imaging.
Targeting accuracy of this system was assessed in free space test
using an optical tracking system (OTS), and image-guided targeting accuracy was assessed in a Philips Achieva 3-T scanner.
A. Quantitative and Qualitative Evaluation of Robot-Induced
Image Interference
To understand the impact of the robotic system to the imaging
quality, SNR analysis based on the National Electrical Manufacturers Association (NEMA) standard (MS1-2008) is utilized as a
metric to quantify noise induced by the robot. Furthermore, even
with sufficiently high SNR, geometric distortion might exist due
to factors including eddy current and magnetic susceptibility effects. Geometric distortion of the image is characterized based
on the NEMA standard (MS2-2008). The analysis utilized a periodic image quality test phantom (Philips, Netherlands) that has
complex geometric features, including cylindrical cross section,
arch and pin section. To mimic the actual scenario of the robot
and control position, the robot is placed 5 mm away from the
phantom. The controller was placed approximately 2 m away
from the scanner bore inside the scanner room (in a configuration
similar to that shown in Fig. 2). In addition to the quantitative
analysis, a further experiment qualitatively compared the image
quality of a human brain under imaging with the robot in various
configurations.
1) Signal-to-Noise Ratio-Based Compatibility Analysis: To
thoroughly evaluate the noise level, three clinically applied imaging protocols were assessed with parameters listed
in Table II. The protocols include: 1) diagnostic imaging

LI et al.: ROBOTIC SYSTEM FOR MRI-GUIDED STEREOTACTIC NEUROSURGERY

1083

Fig. 9. MRI of the homogeneous section of the phantom in four configurations with two imaging protocols demonstrating visually unobservable image
artifacts.

T1-weighted fast field echo (T1W-FFE), 2) diagnostic imaging
T2-weighted turbo spin echo for needle/electrode confirmation
(T2W-TSE), and 3) a typical T2-weighted brain imaging sequence (T2W-TSE-Neuro). All sequences were acquired with
field of view (FOV) 256 mm × 256 mm, 512 × 512 image
matrix and 0.5 mm × 0.5 mm pixel size. The first two protocols
were used for quantitative evaluation, while the third was used
for qualitative evaluation with a human brain.
Five configurations of the robot were assessed to identify the
root cause of image quality degradation: baseline with phantom
only inside scanner, robot present but unpowered, robot powered, robot running during imaging, and then a repeated baseline
with phantom only. Fig. 9 illustrates the representative images of
SNR test with T1W-FFE and T2W-TSE images in the first four
configurations. For the quantitative analysis, SNR is calculated
as the mean signal in the center of the phantom divided by the
noise outside the phantom. Mean signal is defined as the mean
pixel intensity in the region of interest. The noise is defined as
the average mean signal intensity in the four corners divided
by 1.25 [26]. Fig. 10 shows the boxplot of the SNR for five
robot configurations under these two scan protocols. The results
from this plot are indicative of three primary potential sources
of image artifact, namely materials of the robot (difference between baseline and robot present but unpowered), power system
and wiring (difference between robot present but unpowered
and robot powered), and drive electronics (difference between
robot powered and robot running). The mean SNR reduction
from baseline for these three differences are 2.78%, 6.30%, and
13.64% for T1W-FFE and 2.56%, 8.02% and 12.54% for T2WTSE, respectively. Note that Fig. 9 shows this corresponding to
visually unobservable image artifacts.
Elhawary et al. [24] demonstrated that SNR reduction for the
same PiezoLegs motor (nonharmonic motor) using a commercially available driver is 26% with visually observable artifact.
In terms of harmonic piezoelectric motors, Krieger et al. [12]
showed that the mean SNR of baseline and robot motion using NanoMotion motors under T1W imaging reduced approximately from 250 to 50 (80%) with striking artifact. Though
the focus of this paper is on the use of nonharmonic PiezoLegs
motors for this application, we also demonstrated the control
system capable of generating less than 15% SNR reduction
for NanoMotion motors in our previous study [27]. Our sys-

Fig. 10. Boxplots showing the range of SNR values for each of five robot
configurations evaluated in two clinically appropriate neuro imaging protocols
(T1W FFE and T2W TSE). The configurations include baseline (no robotic
system components present in room), robot (robot presented but not powered),
powered (robot connected to power on controller), running (robot moving during
imaging), and a repeated baseline with no robotic system components present.

tem shows significant improvement with PiezoLegs motor over
commercially available motor drivers when the robot is in motion. Even though there is no specific standard about SNR and
image usability, the visually unobservable image artifact in our
system is a key differentiator with that of [24] which used the
same motors but still showed significant visual artifact.
2) Geometric Distortion-Based Compatibility Analysis:
The NEMA standard (MS2-2008) defines 2-D geometric distortion as the maximum percent difference between measured
distances in an image and the actual corresponding phantom
dimensions. Eight pairs of radial measurements (i.e., between
points spanning the center of the phantom), are used to characterize the geometric distortion as shown in Fig. 11 for T1W-FFE
and T2W-TSE protocols.
With the known geometry of the pins inside the phantom, the
actual pin distance is readily available. The distance is measured
on the image, and then are compared to the actual corresponding
distances in the phantom as shown in Table III for T1W-FFE
protocol. The maximum difference between baseline image acquired with no robot and actual distance is less than 0.31% as
shown in the third column of the table. The measured maximum
distortion percentage for images acquired while the robot was
running was 0.20%. This analysis demonstrates negligible geometric distortion of the acquired images due to the robot running
during imaging.

1084

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 4, APRIL 2015

Fig. 11. Geometric patterns of the nonhomogeneous section of the phantom
filled with pins and arches for the two extreme robot configurations and the same
two imaging protocols. The overlaid red line segments indicates the measured
distance for geometric distortion evaluation.

Fig. 12. Qualitative analysis of image quality. Top: Patient is placed inside
scanner bore with supine position and robot resides on the side of patient head.
Bottom: T2-weighted sagittal images of brain taken with three configurations.
No robot in the scanner (bottom-left), controller is powered but motor is not
running (bottom-middle) and robot is running (bottom-right).

TABLE III
GEOMETRIC DISTORTION EVALUATIONS UNDER SCAN PROTOCOL T1W
Line segment

ai
bj
ck
dl
em
fn
go
hp

Actual distance (mm)

158.11
150.00
158.11
141.42
158.11
150.00
158.11
141.42

Measured distance (difference %)
Baseline

Robot running

158.46 (0.22)
158.46 (0.31)
158.48 (0.23)
141.51 (0.07)
157.97 (0.09)
149.92 (0.05)
158.16 (0.03)
141.65 (0.16)

158.39 (0.17)
150.24 (0.16)
158.03 (0.05)
141.14 (0.20)
157.85 (0.17)
149.89 (0.07)
158.24 (0.08)
141.65 (0.16)

3) Qualitative Imaging Evaluation: In light of the quantitative SNR results of the robot system, the image quality is
further evaluated qualitatively by comparing brain images acquired with three different configurations under the previously
defined T2W imaging sequence. Fig. 12 shows the experimental
configuration and the corresponding brain images of a volunteer
placed inside scanner bore with the robot. There is no visible
loss of image quality (noise, artifacts, or distortion) in the brain
images when controller and robot manipulator are running.
The capability to use the scanner’s real-time continuous imaging capabilities in conjunction with the robot to monitor needle
insertion was further demonstrated. In one example qualitatively
demonstrating this capability, a 21 Gauge Nitinol needle was inserted into a gelatin phantom under continuous updated images
(700 ms per frame). The scan parameters including the repetition rate can be adapted as required for the particular application
to balance speed, FOV, and image quality. As shown in Fig. 13,
the needle is clearly visible and readily identifiable in the MR
images acquired during needle insertion, and these images are

Fig. 13. Example of real-time MR imaging capabilities at 1.4 Hz during needle
insertion. Shown at (a) initial position, (b) 25 mm depth, (c) 45 mm depth, and
(d) 55 mm insertion depth into a phantom.

available in real time for visualization and control. The small
blobs observed near the needle tip in these images are most
likely due to the shape of the needle tip geometry.
B. Robotic System Accuracy Evaluation
Assessing system accuracy was undertaken in two main
phases: 1) benchtop free-space system accuracy and 2) MR
image-guided system accuracy. Free-space accuracy experiment
utilized an OTS to calibrate and verify accuracy, while imageguided analysis utilized MR images. Three metrics are utilized
for analyzing system error as summarized in Table IV from
both experiments, i.e., tip position, insertion angle and distance
from RCM intersection point to needle axes. Tip position error
is a measure of the distance between a selected target and the
actual location of the tip of the inserted cannula. Insertion angle
error is measured as an angular error between the desired insertion angle and the actual insertion angle. Distance from RCM
intersection point to needle axes represents an analysis of the
mechanisms performance as an RCM device. For these measurements a single RCM point is targeted from multiple angles,
and the minimum average distance from a single point of all

LI et al.: ROBOTIC SYSTEM FOR MRI-GUIDED STEREOTACTIC NEUROSURGERY

1085

TABLE IV
ANALYSIS OF OTS AND IMAGE-GUIDED ACCURACY STUDIES

Optical Tracker
Maximum Error
Minimum Error
rms Error
Standard Deviation
MRI-Guided
Maximum Error
Minimum Error
rms Error
Standard Deviation

Tip Position
(mm)

Distance from
Needle Axes
(mm)

Insertion Angle
(Degree)

1.56
0.48
1.09
0.28

0.44
0.22
0.33
0.05

3.07
0.90
2.06
0.76

2.13
0.51
1.38
0.45

0.59
0.47
0.54
0.05

2.79
0.85
2.03
0.58

Fig. 15. Configuration of the robotic device within scanner bore for the MR
image-guided accuracy study.

Fig. 14. Coordinate frames of the robotic system for registration of robot to
MR image space.

the insertion axes is determined via least squares analysis. The
actual tip positions, as determined via the OTS system during
the benchtop experiment and image analysis for the MRI guided
experiments, are registered to desired targets with point cloud
based registration to isolate the robot accuracy from registrationrelated errors in the experiments.
A fiducial-based registration is used to localize the base of
the robot in the MRI scanner. To register the robot to the image
space, the serial chain of homogeneous transformations is used,
as shown in Fig. 14.
RAS
Z
Base
Rob
= TZRAS · TBase
· TRob
· TTip
TTip

(1)

RAS
where TTip
is the needle tip in the RAS (right, anterior, superior) patient coordinate system, TZRAS is the Z-shaped fiducial’s
coordinate in RAS coordinates, which is localized in 6 DOF
from MR images via a Z-frame fiducial marker based on multiimage registration method as described in more detail by Shang
and Fischer in [28]. The fiducial is rigidly fixed to the base and
positioned near the scanner isocenter; once the robotic system is
registered, this device is removed. Since the robot base is fixed
in scanner coordinates, this registration is only necessary once.
Z
is is a fixed calibration of the robot base with respect to
TBase
Base
is the constant offset between robot
the fiducial frame, TRob
Rob
is the
origin and a frame defined on the robot base, and TTip
needle tip position with respect to the robot origin, which is
obtained via the robot kinematics.
1) Robot Accuracy Evaluation With OTS: A Polaris OTS
(Northern Digital Inc., Canada) is utilized, with a passive

6-DOF tracking frame attached to the robot base, and an active tracking tool mounted on the end-effector.
The experiment is a two step procedure, consisting of robot
RCM mechanism calibration and robot end-effector positioning evaluation. The first procedure was performed by moving
the mechanism through multiple orientations while keeping the
Cartesian base fixed, and performing a pivot calibration to determine tool tip offset (rms error of this indicates RCM accuracy).
After successfully calibrating the RCM linkage, the robot is
moved to six targets locations, with each target consisting of
five different orientations. Three groups of data were recorded:
desired needle tip transformation, reported needle transformation as calculated with kinematics based on optical encoders
readings, and measured needle transformation from OTS. Analysis of experimental data indicates that the tip position error (1.09 ± 0.28 mm), orientation error (2.06 ± 0.76◦ ), and
the error from RCM intersection point to needle axes (0.33 ±
0.05 mm) as can be seen in Table IV.
2) Robot Accuracy Evaluation Under MR Image-Guidance:
The experimental setup utilized to assess system level accuracy within the scanner is shown in Fig. 15. An 18-gauge ceramic needle (to limit paramagnetic artifacts) was inserted into
a gelatin phantom and imaged with a high resolution 0.5 mm3 ,
T2-weighted turbo spin echo imaging protocol (T2W-TSE) to
assess robot instrument tip position. This experiment reflects the
effectiveness with which the robotic system can target an object
identified within MR images. The experimental procedure is as
follows:
1) Initialize robot and image Z-frame localization fiducial;
2) Register robot base position with respect to RAS patient
coordinates;
3) Remove fiducial frame and home robot;
4) Translate base to move RCM point to target location;
5) Rotate RCM axes to each of five insertion trajectories,
insert ceramic needle, and image;
6) Retract needle and translate base axes to move RCM point
to each of the new locations, and repeat.
The insertion pathway (tip location and axis) of each needle
insertion was manually segmented and determined from the MR

1086

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 4, APRIL 2015

Fig. 16. Plot of intersection of multiple insertion pathways at a given target
location based on segmentation of the MRI data. Each axis is 40 mm in length.
Inset: MRI image of phantom with inserted ceramic cannula.

image volumes, as seen in Fig. 16 for one representative target
point. The best fit intersection point of the five orientations for
each target location was found, both to determine the effectiveness of the RCM linkage as well as to analyze the accuracy of
the system as whole. The results demonstrated an rms tip position error of approximately 1.38 mm and an angular error of
approximately 2.03◦ for the six targets, with an error among the
varing trajectories from RCM intersection point to needle axes
of 0.54 mm.
V. DISCUSSION AND CONCLUSION
This paper presents the first of its kind MRI-guided stereotactic neurosurgery robot with piezoelectric actuation that enables
simultaneous imaging and intervention without affecting the
imaging functionality. The contributions of this paper include:
1) novel mechanism design of a stereotactic neurosurgery robot,
2) piezoelectric motor control electronics that implements direct
digital synthesis for smooth waveform generation to drive piezoelectric motors, 3) an integrated actuation, control, sensing and
navigation system for MRI-guided piezoelectric robotic interventions, 4) image quality benchmark evaluation of the robotic
system, and 5) targeting accuracy evaluation of the system in
free space and under MR guidance.
Evaluation of the compatibility of the robot with the MRI
environment in a typical diagnostic 3-T MRI scanner demonstrates the capability of the system of introducing less than 15%
SNR variation during simultaneous imaging and robot motion
with no visually observable image artifact. This indicates the
capability to visualize the tissue and target when the robot operates inside MRI scanner bore, and enables future fully-actuated
system to control insertion depth and rotation while acquiring
real-time images. Geometric distortion analysis demonstrated
less than 0.20% image distortion which was no worse than that
of baseline images without the robot present. Targeting accuracy
was evaluated in free space through benchtop studies and in a
gelatin phantom under live MRI-guidance. The plastic material
and manufacturing-induced errors result in the axes not being
in perfect alignment relative to each other, and thus resulting in
system error. 3D-printed materials utilized in the construction
of this device are very useful to rapidly create a mechanism for

initial analysis, though upon disassembly, plastic deformation of
the pivot locations for the parallelogram linkage were observed,
and thought to have added to system inaccuracies; these parts
would be machined from PEEK or Ultem in the clinical version
of this system to improve stiffness and precision. In addition,
large transmission distances on the two belt drive axes may be
associated with angular inaccuracies.
This study aims to address three unmet clinical needs, namely,
efficiency, accuracy and safety. In terms of the efficiency, we
compared the workflow of the current manual-frame approach
and the MRI-guided robotic approach, revealing the potential
to save 2–3 h by avoiding an additional CT imaging session
with associated CT-MRI fusion and the time-consuming localization method (i.e., microelectrode recording). In terms of
the accuracy, MRI-guided needle placement accuracy experiment demonstrated three-axis rms error 1.38 ± 0.45 mm. The
accuracy of traditional frame-based stereotaxy DBS with MRI
guidance is 3.1 ± 1.41 mm for 76 stimulators implantation in
human [2]. It is premature to corroborate the accuracy advantage
of robotic approach due to the lack of clinical human trials. However, it shows the potential of the robotic approach to improve
accuracy, by postulating that motorized solution is superior to
the manual method. In terms of the safety, since the intraoperative brain anatomy, targets, and interventional tool are all visible
with MR during the intervention, this enables compensation for
brain shift and complete visualization of the interventional site
during the procedure. Qualitatively, image-guidance is empowered with the obvious advantages over the indirect method (i.e.,
microelectrode recording) which is iterative, time-consuming,
and unable to visualize any anatomy.
The currently intended application of the system is for DBS
electrode placement. But as a generic MRI-compatible motion
control system, this platform has the capability to be extended
for other neurosurgical procedures (e.g., brain tumor biopsy
and ablation) with different interventional tools. Further experiments include validation of the procedure time and targeting
errors with cadaver and animal studies, aiming to improve the
patient outcome as the final goal.

REFERENCES
[1] T. Hartkens, D. Hill, A. Castellano-Smith, D. Hawkes, C. Maurer,
A. Martin, H. Liu, and C. Truwit, “Measurement and analysis of brain
deformation during neurosurgery,” IEEE Trans. Med. Imag., vol. 22,
no. 1, pp. 82–92, Jan. 2003.
[2] P. A. Starr, A. J. Martin, J. L. Ostrem, P. Talke, N. Levesque, and
P. S. Larson, “Subthalamic nucleus deep brain stimulator placement using
high-field interventional magnetic resonance imaging and a skull-mounted
aiming device: Technique and application accuracy,” J. Neurosurgery,
vol. 112, no. 3, pp. 479–490, 2010.
[3] P. Larson, P. A. Starr, J. L. Ostrem, N. Galifianakis, M. S. L. Palenzuela, and A. Martin, “203 application accuracy of a second generation
interventional MRI stereotactic platform: Initial experience in 101 DBS
electrode implantations,” Neurosurgery, vol. 60, p. 187, 2013.
[4] T. Varma, P. Eldridge, A. Forster, S. Fox, N. Fletcher, M. Steiger,
P. Littlechild, P. Byrne, A. Sinnott, K. Tyler, and S. Flintham, “Use of
the NeuroMate stereotactic robot in a frameless mode for movement disorder surgery,” Stereotactic Functional Neurosurgery, vol. 80, no. 1–4,
pp. 132–135, 2004.
[5] K. Masamune, E. Kobayashi, Y. Masutani, M. Suzuki, T. Dohi, H. Iseki,
and K. Takakura, “Development of an MRI-compatible needle insertion

LI et al.: ROBOTIC SYSTEM FOR MRI-GUIDED STEREOTACTIC NEUROSURGERY

[6]
[7]
[8]
[9]

[10]

[11]
[12]

[13]

[14]

[15]
[16]

[17]
[18]
[19]
[20]

[21]

[22]

[23]
[24]

[25]
[26]

manipulator for stereotactic neurosurgery,” J. Image Guided Surg., vol. 4,
pp. 242–248, 1995.
M. Lang, A. Greer, and G. Sutherland, “Intra-operative robotics: NeuroArm,” Intraoperative Imag., vol. 109, pp. 231–236, 2011.
M. Ho, A. McMillan, J. Simard, R. Gullapalli, and J. Desai, “Toward a
meso-scale SMA-actuated MRI-compatible neurosurgical robot,” IEEE
Trans. Robot., vol. 28, no. 1, pp. 213–222, Feb. 2012.
D. B. Comber, E. J. Barth, and R. J. Webster, “Design and control of
an magnetic resonance compatible precision pneumatic active cannula
robot,” J. Med. Devices, vol. 8, no. 1, pp. 011003-1–011003-7, 2014.
B. Yang, U.-X. Tan, A. McMillan, R. Gullapalli, and J. Desai, “Design
and control of a 1-DOF MRI-compatible pneumatically actuated robot
with long transmission lines,” IEEE Trans. Mechatron., vol. 16, no. 6,
pp. 1040–1048, Dec. 2011.
H. Liao, T. Inomata, I. Sakuma, and T. Dohi, “3-D augmented reality
for MRI-guided surgery using integral videography autostereoscopic image overlay,” IEEE Trans. Biomed. Eng., vol. 57, no. 6, pp. 1476–1486,
Jun. 2010.
N. Hirai, A. Kosaka, T. Kawamata, T. Hori, and H. Iseki, “Image-guided
neurosurgery system integrating AR-based navigation and open-MRI
monitoring,” Comput. Aided Surg., vol. 10, no. 2, pp. 59–72, 2005.
A. Krieger, S.-E. Song, N. Cho, I. Iordachita, P. Guion, G. Fichtinger,
and L. Whitcomb, “Development and evaluation of an actuated MRIcompatible robotic system for MRI-guided prostate intervention,” IEEE
Trans. Mechatron., vol. 18, no. 1, pp. 273–284, Feb. 2013.
G. S. Fischer, I. Iordachita, C. Csoma, J. Tokuda, S. P. DiMaio,
C. M. Tempany, N. Hata, and G. Fichtinger, “MRI-compatible pneumatic robot for transperineal prostate needle placement,” IEEE Trans.
Mechatron., vol. 13, no. 3, pp. 295–305, Jun. 2008.
D. Stoianovici, C. Kim, G. Srimathveeravalli, P. Sebrecht, D. Petrisor,
J. Coleman, S. Solomon, and H. Hricak, “MRI-safe robot for endorectal
prostate biopsy,” IEEE Trans. Mechatron., vol. 19, no. 4 pp. 1289–1299,
Aug. 2014.
K. Chinzei and K. Miller, “MRI guided surgical robot,” in Proc. Australian
Conf. Robot. Autom., 2001, pp. 50–55.
N. Tsekos, A. Khanicheh, E. Christoforou, and C. Mavroidis, “Magnetic
resonance-compatible robotic and mechatronics systems for image-guided
interventions and rehabilitation: A review study,” Annu. Rev. Biomed.
Eng., vol. 9, pp. 351–387, 2007.
R. Gassert, E. Burdet, and K. Chinzei, “Opportunities and challenges in
MR-compatible robotics,” Eng. Med. Biol., vol. 3, pp. 15–22, 2008.
G. A. Cole, J. G. Pilitsis, and G. S. Fischer, “Design of a robotic system for
MRI-guided deep brain stimulation electrode placement,” in Proc. IEEE
Int. Conf. Robot. Autom., May 2009, pp. 4450–4456.
G. Cole, K. Harrington, H. Su, A. Camilo, J. Pilitsis, and G. Fischer,
“Closed-loop actuated surgical system utilizing real-time in-situ MRI
guidance,” in Proc. Int. Symp. Exp. Robot., 2010, pp. 785–798.
N. Hata, S. Piper, F. A. Jolesz, C. M. Tempany, P. M. Black, S. Morikawa,
H. Iseki, M. Hashizume, and R. Kikinis, “Application of open source
image guided therapy software in MR-guided therapies,” in Proc. Int.
Conf. Med. Image Comput. Assisted Intervention, 2007, pp. 491–498.
J. Tokuda, G. S. Fischer, X. Papademetris, Z. Yaniv, L. Ibanez, P. Cheng,
H. Liu, J. Blevins, J. Arata, A. J. Golby, T. Kapur, S. Pieper, E. C.
Burdette, G. Fitchtinger, C. M. Tempany, and N. Hata, “Openigtlink: An
open network protocol for image-guided therapy environment,” Int. J.
Med. Robot. Comput. Assisted Surg., vol. 5, no. 4, pp. 423–434, 2009.
G. Fischer, I. Iordachita, C. Csoma, J. Tokuda, S. DiMaio, C. Tempany, N.
Hata, and G. Fitchinger, “MRI-compatible pneumatic robot for transperineal prostate needle placement,” IEEE Trans. Mechatron., vol. 13, no. 3,
pp. 295–305, Jun. 2008.
N. Yu, R. Gassert, and R. Riener, “Mutual interferences and design principles for mechatronic devices in magnetic resonance imaging,” Int. J.
Comput. Assisted Radiol. Surg., vol. 6, no. 4, pp. 473–488, 2011.
H. Elhawary, A. Zivanovic, M. Rea, B. Davies, C. Besant, D. McRobbie,
N. de Souza, I. Young, and M. Lamprth, “The feasibility of MR-image
guided prostate biopsy using piezoceramic motors inside or near to the
magnet isocentre,” in Proc. Int. Conf. Med. Image Comput. Assisted Intervention, 2006, pp. 519–526.
J. W. Young, “Head and face anthropometry of adult US civilians,” Tech.
Inform. Center Document, Federal Aviation Admin., Civil Aeromedical
Inst., Oklahoma City, OK, USA, Tech. Rep. DOT/FAA/AM-931 10, 1993.
Determination of Signal-to-Noise Ratio in Diagnostic Magnetic Resonance Imaging,NEMA Standard MS 1-2008, 2008.

1087

[27] G. Fischer, G. Cole, and H. Su, “Approaches to creating and controlling
motion in MRI,” in Proc. Annu. Int. Conf. IEEE Eng. Med. Biol. Soc.,
2011, pp. 6687–6690.
[28] W. Shang and G. S. Fischer, “A high accuracy multi-image registration
method for tracking MRI-guided robots,” in Proc. SPIE Med. Imag.,
Feb. 2012, pp. 83161V-1–83161V-8.

Gang Li (S’14) received the B.S. and M.S. degrees
in mechanical engineering from the Harbin Institute
of Technology, Harbin, China, in 2008 and 2011, respectively.
He is currently a Doctoral Candidate at the Department of Mechanical Engineering, Worcester Polytechnic Institute, Worcester, MA, USA. His research
interests include medical robotics, robot mechanism
design, MRI-guided percutaneous intervention, and
needle steering.

Hao Su (M’12) received the B.S. degree from the
Harbin Institute of Technology, Harbin, China, the
M.S. degree from the State University of New York
University, Buffalo, NY, USA, and the Ph.D. degree
from the Worcester Polytechnic Institute, Worcester,
MA, USA.
His current research interests include surgical
robotics and haptics. He is currently a Research Scientist at Philips Research North America, Briarcliff
Manor, NY, USA.
Dr. Su was a recipient of the Link Foundation Fellowship and Richard Schlesinger Award from the American Society for Quality.

Gregory A. Cole (M’12) received the B.S. and M.S.
degrees in mechanical engineering, and the Ph.D. degree in robotic engineering, all from Worcester Polytechnic Institute,Worcester, MA, USA.
He was a George I. Alden Research Fellow at
Automation and Interventional Medicine Laboratory,
Worcester Polytechnic Institute. He is currently a Research Scientist at Philips Research North America,
Briarcliff Manor, NY, USA.

Weijian Shang (S’12) received the B.S. degree in
mechanical engineering from Tsinghua University,
Beijing, China, in 2009. He also received the M.S.
degree in mechanical engineering from Worcester
Polytechnic Institute, Worcester, MA, USA, in 2012.
He is currently working toward the Ph.D. degree in
mechanical engineering.
He is currently a Graduate Research Assistant
at Automation and Interventional Medicine Laboratory, Worcester Polytechnic Institute. His research
interests include development of teleoperated MRIguided medical robot, force sensing and registration method.

Kevin Harrington received the B.S. degree in
robotic engineering from Worcester Polytechnic Institute, Worcester, MA, USA.
His research interests include embedded systems,
software system architecture, and programming.

1088

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 4, APRIL 2015

Alex Camilo received the B.S. degree in electrical and computer engineering from the Worcester
Polytechnic Institute of Technology, Worcester, MA,
USA, in 2010.
His research interests include embedded communications protocols, MRI-guided robot, and PCB Design.

Julie G. Pilitsis graduated from Albany Medical College, Albany, NY, USA. She completed her residency
at Wayn State University, Detroit, MI, USA, during
which time she also received the Ph.D. degree in neurophysiology.
She then served as the Director of functional
neurosurgery at UMass Memorial Medical Center,
Worcester, MA, USA, but has recently returned to Albany Medical College as an Associate Professor. Her
research interests include functional neurosurgery, including DBS for chronic pain.

Gregory S. Fischer (M’03) received the B.S. degree
in electrical and mechanical engineering from Rensselaer Polytechnic Institute, Troy, NY, USA, in 2002,
and the M.S.E. degree in electrical engineering from
Johns Hopkins University, Baltimore, MD, USA, in
2004. He received the Ph.D. degree in mechanical engineering from the Johns Hopkins University in 2008.
He is currently an Associate Professor of mechanical engineering with appointments in biomedical and
robotics engineering at Worcester Polytechnic Institute, Worcester, MA, USA. He is the Director of the
WPI Automation and Interventional Medicine Laboratory, Worcester, where
his research interests include development of robotic systems for image-guided
surgery, haptics and teleoperation, robot mechanism design, surgical device instrumentation, and MRI-compatible robotic systems.

