IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 2, FEBRUARY 2015

501

A Sticky Weighted Regression Model for
Time-Varying Resting-State Brain
Connectivity Estimation
Aiping Liu, Xun Chen∗ , Martin J. McKeown, and Z. Jane Wang, Senior Member, IEEE

Abstract—Despite recent progress on brain connectivity modeling using neuroimaging data such as fMRI, most current approaches assume that brain connectivity networks have timeinvariant topology/coefficients. This is clearly problematic as the
brain is inherently nonstationary. Here, we present a time-varying
model to investigate the temporal dynamics of brain connectivity networks. The proposed method allows for abrupt changes in
network structure via a fused least absolute shrinkage and selection operator (LASSO) scheme, as well as recovery of time-varying
networks with smoothly changing coefficients via a weighted regression technique. Simulations demonstrate that the proposed
method yields improved accuracy on estimating time-dependent
connectivity patterns when compared to a static sparse regression
model or a weighted time-varying regression model. When applied
to real resting-state fMRI datasets from Parkinson’s disease (PD)
and control subjects, significantly different temporal and spatial
patterns were found to be associated with PD. Specifically, PD subjects demonstrated reduced network variability over time, which
may be related to impaired cognitive flexibility previously reported
in PD. The temporal dynamic properties of brain connectivity in
PD subjects may provide insights into brain dynamics associated
with PD and may serve as a potential biomarker in future studies.
Index Terms—Brain connectivity network, dynamic, functional
magnetic resonance imaging (fMRI), Parkinson’s disease (PD),
time varying.

I. INTRODUCTION
N addition to examining relative changes in blood-oxygenlevel-dependent (BOLD) signals as a result of ongoing brain
activity, brain connectivity patterns reveal cooperation between
different brain regions. Inferring brain connectivity networks
from functional magnetic resonance imaging (fMRI) data have
been increasingly important for understanding brain functioning
both normally, and in disease states.

I

Manuscript received April 14, 2014; revised July 22, 2014; accepted September 9, 2014. Date of publication September 19, 2014; date of current version
January 16, 2015. This work was supported in parts by the PPRI/UBC Chair
in Parkinson’s Disease (MJM) and Canadian Natural Sciences and Engineering
Research Council Grants. Asterisk indicates corresponding author.
A. Liu and Z. J. Wang are with the Department of Electrical and Computer Engineering, University of British Columbia, Vancouver BC V6T 1Z4,
Canada (e-mail: aipingl@ece.ubc.ca, zjanew@ece.ubc.ca).
∗ X. Chen is with the Department of Biomedical Engineering, School of
Medical Engineering, Hefei University of Technology, Hefei 230009, China
(e-mail: xunchen@ece.ubc.ca).
M. J. McKeown is with the Department of Medicine (Neurology) and Pacific
Parkinson’s Research Centre, University of British Columbia, Vancouver BC
V6T 1Z4, Canada (e-mail: martin.mckeown@ubc.ca).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TBME.2014.2359211

Many mathematical methods have been developed for brain
connectivity modeling. Correlation, mutual information and coherence are among the most straightforward bivariate analysis
approaches [1]. Linear decomposition methods such as principal
component analysis and independent component analysis (ICA)
have also been widely employed to explore coactivations among
brain regions [2]. Structural equation modeling (SEM) [3], dynamic causal models [4], and regression-based approaches [5]
are popular graphical models, which are suitable for modeling
brain connectivity networks because their graphical nature assists in the biomedical interpretation of the learned connectivity
patterns. To make inference of brain connectivity networks in
a sample or even a population, several group level approaches
have been proposed, such as Bayesian model selection [6], group
covariance estimation [7], group PCf dr algorithm [8], and the
prior information guided group network modeling approach [9].
However, most current approaches assume that the connectivity structure is time invariant, i.e., without considering temporal
variations of the underlying neural activity, and thus, the inferred brain connectivity possibly represents a temporally averaged connectivity pattern [10]. Assessing the temporal dynamics
of connectivity patterns may, therefore, represent an additional
dimension to assess brain activity [11].
Several strategies have thus far been proposed to investigate brain connectivity dynamics. Lagged interaction-based approaches, such as dynamic Bayesian network modeling [12]
and autoregressive (AR) models [13], examine brain interactions simultaneously and over adjacent time steps. Since these
methods assume the lagged interactions themselves are time invariant, they technically can be considered as stationary models.
State-space-model-based approaches, by combining lagged interaction and filtering theory, estimate nonstationary brain connectivity at each time point [14]. In addition, time–frequencybased approaches, such as wavelet-transform-based coherence
analysis, infer resting-state dynamic brain connectivity from
places in the time–frequency plane [15]. Wavelet-based timevarying Granger causality analysis has also been used to produce evolving brain connectivity maps that are modulated by
task performance [16].
If brain connectivity networks can be assumed to change
slowly and smoothly over time, a sliding window approach is
appropriate. By specifying a fixed window length and shifting the window by a given number of data samples, different
network learning methods such as correlation [17]–[19], covariance [20], and ICA [21], [22] have been applied to estimate
the time-dependent interactions within each window. However,

0018-9294 © 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

502

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 2, FEBRUARY 2015

determining the appropriate window length is critical and difficult: with a too small window length, estimated connectivity
patterns suffer from large fluctuations due to noise, and thus,
may not truly reflect the underlying dynamic properties of brain
activity; in contrast, a too large window will result in insensitivity to possibly important brain state changes. In order to
avoid the assumption that changes occur slowly over time, several studies have reported that functional networks inferred by
stationary approaches may be unduly influenced by changes at
a few critical time points [10]. These critical time points can be
used to segment the entire signal into quasi-stationary sections
for the purposes of brain connectivity estimation [10], [23],
[24]. Nevertheless, change point detection may be particularly
susceptible to artifacts (e.g., due to head motion) in the data.
Another important characteristic of both sliding window and
change point detection multivariate models is that they assume
that different brain regions have temporal variations at the same
time scale so that the entire brain dynamics are assumed to
switch simultaneously, while in practice, different pairs of brain
regions may interact at different temporal scales [11].
Beyond the specific area of fMRI brain connectivity modeling, several time-varying frameworks have been proposed to
discover multivariate interactions over time. These include timevarying regularized graphical structural estimation [25], linear
regression-based Bayesian network (BN) approaches [26]–[28],
and change point detection approaches [29]. In a BN framework,
both network structure and parameter changes are treated as random processes whose values at each time epoch are modeled
via a BN approach. In one change-point detection model, a
fused penalty used in a preliminary linear regression model is
used to detect change points, and then, multivariate regression is
separately applied to each segment [29]. Another change-point
detection approach uses penalized regression and Gaussian mixture models [30].
Based on the aforementioned discussion, it is clear that modeling brain dynamics often requires fairly strict assumptions be
made, such as assuming the networks change smoothly, change
suddenly, or change in a piece-wise stationary fashion [11].
Moreover, learning dynamic changes in brain interactions may
be complicated by factors such as head movement, measurement noise, and other randomized fluctuations. To reduce the
influence of random noise, it is reasonable to assume that brain
connectivity patterns mostly change smoothly except at critical
change points. Based on this assumption, temporally adjacent
networks are more likely to share common patterns than temporally distant networks, as assumed in a weighted time-varying
(WTV) regression model [26], yet abrupt changes can still occur
at specific change points.
Therefore, in this paper, we propose a sticky weighted timevarying (SWTV) model that estimates the nonstationary process of brain interactions in a temporally penalized, weighted
regression fashion. We incorporate a fused penalty [31] into
the weighted regression model [26]. The fused penalty is added
into a weighted regression model in which we can estimate both
smooth changing coefficients and abrupt changing structures
so that the change point detection problem will not be separated from the network estimation problem. More importantly,

the proposed method allows different pairs of brain regions to
exhibit fluctuations at different time scales, as illustrated in simulations in Section III. Finally, we assume connections between
spatially disparate brain regions are relatively sparse to facilitate
meaningful biological interpretation.
In the remainder of this paper, we will introduce the SWTV
model in Section II, and perform simulations to validate the
proposed method in Section III. Also, in Section IV, the proposed SWTV model is applied to resting-state fMRI datasets
from both Parkinson’s disease (PD) and control subjects, and
significant different temporal and spatial patterns are found to
be associated with the disease state.
II. METHODS
In this section, we will briefly introduce regression models
used in the brain connectivity network modeling at the single
subject level, and then, we will present the proposed SWTV
model to estimate dynamic interactions between different brain
regions in the resting state.
A. SWTV Model
Multivariate linear regression models have been widely used
to infer neural interactions. For instance, SEM estimates the
brain interactions at zero lag [3]. The multivariate autoregressive
model focuses on the lagged interactions between different brain
ROIs [32]. With a sparsity assumption, least absolute shrinkage
and selection operator (LASSO), group LASSO and elastic net
models try to discover the sparse map of the brain interactions
with high computational efficiency [9], [33]. In the regression
model used in our paper, the fMRI time course of a region
of interest (ROI) is regarded as the response variable, and is
predicted from the time courses of all other ROIs at zero lag as
Y = Xβ + e

(1)

where vector Y with length T means the time course of one brain
ROI, X is T × K predictor matrix based on the time courses
of all other ROIs with K + 1 representing the entire number of
ROIs, β is the coefficient vector, and e is the Gaussian noise
term. Due to the nonstationary nature of the brain activity, the
time-dependent regression model becomes
Yt = Xt β t + e

(2)

where t represents the time index and we need to estimate the
regression coefficient vector at each time point, respectively. Yt
is the response sample at time point t and Xt is the tth sample
row in the predictor matrix. In order to make the connections
sparse, one could use an l1 penalty on the regression coefficients.
However, with only one sample point, the estimator of coefficients would be extremely unstable. Thus, in order to estimate
time-varying structures/coefficients, yet still allow sparsity, we
assume that the underlying networks are changing smoothly
over time. Following prior work [26], we could estimate the
coefficients for each time point separately in a WTV model as
∗

β̂ t = argmin
β

t∗

T

t=1

∗

∗

∗

W t (t)(Yt − Xt β t )2 + λβ t l 1

(3)

LIU et al.: STICKY WEIGHTED REGRESSION MODEL FOR TIME-VARYING RESTING-STATE BRAIN CONNECTIVITY ESTIMATION

503

TABLE I
IMPLEMENTATION OF SWTV MODEL

Input: Y ∈ R T , X ∈ R T ×K , regularization parameters λ , γ , and bandwidth h
Step 1: Weighting the response vector Y and the predictor matrix X .
∗
h , calculate W t (t) according to (4), for t = 1, 2, . . . , T , t∗ = 1, 2, . . . , T .
1. Based on

∗
∗
2. Y tt ← W t (t)Y t , t = 1, 2, . . . , T , t∗ = 1, 2, . . . , T ,
∗
∗
∗
∗
and Y t = (Y 1t , Y 2t , . . . , Y Tt ) .
∗
3. X tt ← W t ∗ (t)X t , t = 1, 2, . . . , T , t∗ = 1, 2, . . . , T ,
∗
∗
∗
∗ 
and X t = (X 1t , X 2t , . . . , X Tt ) .
Step 2: Constructing the objective function.



1. Ỹ ← (Y 1 , Y 2 , . . . , Y T ) .
1
2
2. X̃ ← diag(X , X , . . . , X T ).
3. Construct a sparse matrix C ∈ R (T −1 )K ×T K as,
C ((T − 1) ∗ (i − 1) + j, K ∗ (j − 1) + i) ← −1 ,
C ((T − 1) ∗ (i − 1) + j, K ∗ j + i) ← 1 , i = 1, 2, . . . , K , j = 1, 2, . . . , T − 1 .
4. Formulate the objective function as in (6) by inputting Ỹ , X̃ , β̃ , C , λ, γ .
 


Step 3: Estimating time-varying coefficients β̃ = (β 1 , β 2 , . . . , β T ) .
Apply SPG toolbox [34] to solve the optimization problem in (6) and obtain the estimated
time-varying coefficients β̃ .
 


Output: Time-varying coefficients β̃ = (β 1 , β 2 , . . . , β T ) .

∗







where β t is the coefficient vector we need to estimate at time
∗
∗
t∗ , β̂ t is the estimator of β t , and λ is the parameter for the
∗
l1 penalty. W t (t) is the weighting of observations from time t
∗
when we estimate the coefficients at time t∗ . In general, W t (t)
can be defined as any normalized kernel function. In this paper,
∗
W t (t) is defined as

β̃ = (β 1 , β 2 , . . . , β T ) is the concatenated time-varying coefficient vector with length T K. Each β t corresponds to the
coefficient vector at time point t. The objective function can be
formulated as

exp(−(t − t∗ )2 /h)
∗
.
W t (t) = T
∗ 2
t=1 exp(−(t − t ) /h)

where C is a sparse (T − 1)K × T K matrix with two
nonzero elements in each row. More specifically, C((T −
1) ∗ (i − 1) + j, K ∗ (j − 1) + i) = −1 and C((T − 1) ∗ (i −
1) + j, K ∗ j + i) = 1, i = 1, 2, . . . , K, j = 1, 2, . . . , T − 1.
By this formulation, it becomes a generalized fused LASSO
problem, which can be solved using the smoothing proximal
gradient (SPG) method [34]. SPG is one efficient algorithm
with the convergence rate of O( 1 ), where  is the precision of
the algorithm; Per-iteration complexity of SPG is linear with the
number of nonzero elements of the constructed sparse network
C [34]. In this paper, we use the SPG optimization toolbox [34],
and the implementation of the SWTV model is described in
Table I.

(4)

This is a normalized Gaussian radial basis function kernel,
with h representing the kernel bandwidth. Note that this model
is essentially a sparse weighted regression model that allows
us to estimate the coefficients at each time point separately
by reweighing the observations. With the smoothly changing
assumption, temporally adjacent coefficients are more likely to
be similar than temporally distant coefficients.
A “sticky” WTV model is, therefore, introduced as
minimize
∗
β t ,t ∗ ∈R T

T
T 

t ∗ =1 t=1

T

 t∗ 

∗
∗ 2
β 
W t (t) Yt − Xt β t
+λ
l1

minimize Ỹ − X̃ β̃2F + λβ̃l 1 + γC β̃l 1

(6)

β̃

t ∗ =1

+γ

T

 t∗

β − β t ∗ −1 
l1

B. Model Selection
(5)

t ∗ =2

where γ is the parameter to control the fused penalty and serves
to keep the coefficients temporally consistent except at (possibly
several) abrupt change points.
To efficiently solve this optimization problem, we can
∗
rewrite
vector
and predictor matrix as Ytt =

 ∗ the response
∗
∗
∗
∗
∗
W t (t)Yt and Xtt = W t (t)Xt . Let Y t = (Y1t , Y2t , . . . ,
∗
∗
∗
∗ 
t∗ 
YT ) , X t = (X1t , X2t , . . . , XTt ) , then the weights can be
incorporated into the square loss function directly. We can
further simplify the objective function by expressing them in



a matrix format. Suppose Ỹ = (Y 1 , Y 2 , . . . , Y T ) is a re1
2
sponse vector with length T T , X̃ = diag(X , X , . . . , X T )
is a block diagonal matrix with dimension T T × T K, and

The parameters of stationary regression model are usually
determined by cross validation (CV), which separates the data
into training and testing sets. However, the standard CV approach cannot be employed directly in our time-varying case,
since each sample corresponds to a specific time point and the
structures and coefficients may be different across time.
Therefore, in order to apply CV, we first up-sample the data
by a factor of two: the odd samples represent the original data
points and even samples are the interpolated data points. For the
purpose of model selection, we assume that the corresponding
even samples have the same temporal properties as those of odd
samples. In the following simulation studies, by treating the odd
samples as the training set and even samples as the testing set,
we can select optimal parameters of the model.

504

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 2, FEBRUARY 2015

For each fixed set of parameters λ, γ and the band width
h, we can estimate time-varying coefficients as described in
Table I and use the CV to select the optimal values. However,
for large scale datasets, CV can be time consuming, and it may
not be feasible for the large scale problems. Instead, the gradient descent approach can be applied to iteratively update each
parameter as described in [35] and [36]. It sequentially applies
three line searches along each descent direction to minimize the
corresponding mean square error of current CV until the error
convergences. For the static sparse regression model used in
the simulation part, we utilize the stability selection approach,
which is proved to enhance selection accuracy [37].
C. Brain Connectivity Network Modeling
and Statistical Analysis
To perform inference of brain connectivity networks, we utilize a linear regression approach. We treat each ROI in turn as
the response vector and all other ROIs as constituting the predictor matrix. This corresponding coefficient vector would give
the strength of connectivity from all other ROIs to the response
ROI, which are the estimated directed connections. In this way,
the time-varying coefficient vector for each ROI is estimated
one by one until we obtain the whole brain network.
To quantify and compare the temporal variability of the inferred networks, we define the network variation as
1 
G(t) − G(t − 1)2F
T − 1 t=2
T

V =

(7)

where t represents the time index and G(t) represents the brain
connectivity network, which is a matrix estimated using SWTV
model as described before at time point t. Network variation
calculates the average of distance between two brain connectivity networks at adjacent time points. It quantifies the changes of
network structures as well as connectivity strengths. This metric
measures the ability of switching or oscillation of the networks
across the time. While a relatively simple measure, we found V
an intuitive way to quantify and compare the temporal changes
of brain connectivity networks: with a fixed γ, a higher V implies higher moment-to-moment variability in the networks (see
Fig. 4).
III. SIMULATION
To validate the proposed method, we performed simulations
to compare the performance of the SWTV model with both
that of the WTV model and a static sparse regression model.
We considered different simulation settings where the different variables changed in the same time scale with and without
autocorrelation, and also when they changed in different time
scales.
In brief, the simulated data were generated from a Gaussian
model with changing structures and coefficients as Yt = Xt β t +
et . X t was a randomly generated sample row at time point t with
K variables (i.e., a 1 × K row vector), β t was a time-dependent
coefficient vector with same length K (K = 20) and et was white
Gaussian noise.

More specifically
1) We first generated the changing coefficients β t . In the first
and second simulations, we assumed that all the variables
changed in the same time scale as N and the total length of
sample size was T = 3 × N [an example of this is shown
in Fig. 1(a)]. In the third simulation, different coefficients
could have different time scales as shown in Fig. 2(a). The
averaged time scale and sample size were set to N and
T = 3 × N , respectively.
2) The design matrix X was randomly generated containing T observations and K predictors. The error vector e
was Gaussian noise ∼N (0, 1). The response vector Y was
generated by Y t = X t β t + et with t = 1, . . . , T . In the
second simulation, to generate the autocorrelation structures on data, the Gaussian smooth filter with variance 1
was applied on X and Y separately.
We compared the proposed SWTV model with the WTV
model [26] and the static LASSO model. The CV was used for
parameter selection in the SWTV and WTV models as discussed
before, and stability selection was used for the static LASSO
model.
In the simulations, we tested the performance of the algorithms as a function of the number of time scales N . For reliable
assessment, each procedure was repeated 50 times and the averaged performance of the different algorithms were compared.
Examples of results for three simulations were shown in Figs. 1
and 2. The true model, and models learned by static LASSO,
WTV, and SWTV methods were compared. The time index was
along the x-axis, the variable index was along the y-axis and
the color bar represented the coefficients’ strength. The results
demonstrated that the variables had both slowly changing coefficients as well as abrupt changing structures along the time.
Note that while the smallest time scale was N , some coefficients
may remain constant over a longer epoch such as variable 20 in
Fig. 1(a). As expected, the recovered coefficients by the static
model were indeed determined in part by the critical samples,
and larger fluctuations were observed in the estimated coefficients in the WTV model when compared with those of the
SWTV model in all the simulations.
The F1 score was employed to quantitatively evaluate the
general performance by considering both the Type I and Type II
error rates
F1 =

2 ∗ TP
2 ∗ TP + FP + FN

(8)

where TP represents True positive, FP represents the False positive, and FN represents the False negative.
As shown in Fig. 3, we compared F1 scores at the time scale
(or averaged time scale) N = 15, 20, 30, 50, and 70, respectively. The results demonstrated that with the increasing of time
scales, the proposed SWTV and WTV models had better accuracy in recovering time-varying structures. When the time
scale was smaller than 15 time points, it may be unreliable to
estimate the true changing structures. Compared with the other
two methods, the simulation results demonstrated that the proposed SWTV model yields higher accuracy in recovering timedependent structures in all the simulations. After adding the

LIU et al.: STICKY WEIGHTED REGRESSION MODEL FOR TIME-VARYING RESTING-STATE BRAIN CONNECTIVITY ESTIMATION

505

Fig. 1. Results for the first and second simulations. (a) True Model. (b)–(d) Models learned by static LASSO, WTV, and SWTV models, respectively, in the
first simulation. (e)–(g) Models learned by static LASSO, WTV, and SWTV models, respectively, in the second simulation. The time index is along the x-axis, the
variable index is along the y-axis and the color bar represents the coefficients’ strength.

autocorrelation structures into the data in the second simulation, we observed that the accuracy of recovering the underlying
time-varying structures decreased compared with those of data
without autocorrelation. In the third simulation, although the
averaged time scale was fixed, the structures may change within
a shorter time period. As a result, the F1 scores were lower compared with those of first simulation. By having the capability of
estimating both smoothly changing and abrupt changes, the proposed SWTV model more accurately estimated the underlying
time-varying brain connectivity patterns.

IV. APPLICATION
In this section, we apply the proposed method to a real restingstate fMRI dataset and study the dynamic properties of brain
connectivity networks in subjects with PD. We first estimate the
time-varying brain connectivity networks for each subject, and

then, compare the temporal and spatial patterns of the inferred
connectivity networks.
A. Subjects and fMRI Resting-State Dataset
Twelve PD subjects and ten healthy control subjects were
recruited from Pacific Parkinson’s Research Center at the University of British Columbia (UBC). All the experiments were
approved by the Ethics Board at UBC, and all the subjects provided informed consent prior to experiment participation.
A 3-T scanner (Philips Gyroscan Intera 3.0T; Philips Medical
Systems, Netherlands) equipped with a head coil was used to
collect data in the resting state. Before scanning, all the subjects
were instructed to lie on their back in the scanner and have several minutes to acclimatize themselves to the scanner environment with eyes closed. BOLD contrast echo-planar (EPI) T2*weighted images were taken with the following specifications
with a repetition time of 1985 ms, echo time of 37 ms, flip

506

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 2, FEBRUARY 2015

Fig. 2. Results for the third simulation. (a) True Model. (b)–(d) Models learned by static LASSO, WTV, and SWTV models, respectively. The time index is
along the x-axis, the variable index is along the y-axis and the color bar represents the coefficients’ strength.

Fig. 3. Simulation Results. (a) F1 scores of the first simulation. (b) F1 scores of the second simulation. (c) F1 scores of the third simulation. Red lines represent
the F1 scores of the proposed method, blue lines represent the F1 scores of the WTV model and the green lines represent the F1 scores of the static model.

angle 90◦ , field of view (FOV) 240.00 mm, matrix size 128 ×
128, with pixel size 1.9 mm × 1.9 mm. The duration of each
functional run was 4 min during which we obtained 36 axial
slices with 3-mm thickness and 1-mm gap thickness. The FOV
was set to include the cerebellum ventrally and also include the
dorsal surface of the brain. 48 Freesurfer-derived ROIs in total
were chosen in this study as shown in Table II.

B. Results
To apply the proposed method on the subjects with PD
and control subjects, we need to choose the bandwidth h, the
sparse penalty parameter λ, and the fused penalty parameter
γ in the SWTV model. We conducted parameter selection using gradient descent approach for each subject. The optimal
parameters for each subject varied across a broad range of

LIU et al.: STICKY WEIGHTED REGRESSION MODEL FOR TIME-VARYING RESTING-STATE BRAIN CONNECTIVITY ESTIMATION

507

TABLE II
INDEX AND NAME OF 48 SELECTED BRAIN ROIS.
Index

Name

Index

Name

L1
L2
L3
L4
L5
L6
L7
L8
L9
L10
L11
L12
L13
L14
L15
L16
L17
L18
L19
L20
L21
L22
L23
L24

L-Cerebellum
L-PMd
L-PMv
L-Pre-SMA
L-SMA-proper
L-ACC
L-Caudate
L-Cerebellum-Cortex
L-PFC
L-Pallidum
L-Putamen
L-Somatosensory
L-Thalamus-Proper
ctx-L-caudalmiddle-frontal
ctx-L-cuneus
ctx-L-inferiorparietal
ctx-L-inferiortemporal
ctx-L-lateraloccipital
ctx-L-middletemporal
ctx-L-precentral
ctx-L-precuneus
ctx-L-superiorparietal
ctx-L-superiortemporal
ctx-L-supramarginal

R1
R2
R3
R4
R5
R6
R7
R8
R9
R10
R11
R12
R13
R14
R15
R16
R17
R18
R19
R20
R21
R22
R23
R24

R-Cerebellum
R-PMd
R-PMv
R-Pre-SMA
R-SMA-proper
R-ACC
R-Caudate
R-Cerebellum-Cortex
R-PFC
R-Pallidum
R-Putamen
R-Somatosensory
R-Thalamus-Proper
ctx-R-caudalmiddle-frontal
ctx-R-cuneus
ctx-R-inferiorparietal
ctx-R-inferiortemporal
ctx-R-lateraloccipital
ctx-R-middletemporal
ctx-R-precentral
ctx-R-precuneus
ctx-R-superiorparietal
ctx-R-superiortemporal
ctx-R-supramarginal

Fig. 4. (a) Averaged number of detected connections within the networks as
sparsity parameter λ increases, with a fixed fused penalty parameter γ = 0.5.
The blue line represents the averaged number of detected connections as a
function of λ. The red dashed line represents the averaged number of common
connections with network detected by a smaller λ. For example, the first point of
the red line is the number of averaged common connections between networks
with λ = 0.1 and λ = 0. (b) Network variations of networks as fused penalty
parameter γ increases, with a fixed λ = 0.5.

“L” represents the brain left side and “R” represents the brain right side.

values (h = 38.9091s ± 26.1769s, λ = 0.5117 ± 0.4382, γ =
1.5341 ± 0.8308). Using the optimal values, the density of
learned connectivity networks varied from 0.0294 to 0.3326,
making it difficult to compare two groups. To fairly compare
the connectivity patterns of patient and control groups, we chose
fixed parameters/densities for all the subjects in this paper.
Although a few studies have been conducted on time variation
in connectivity networks, the exact time scale of brain activities
is unclear, and varies between subjects. This is especially true in
resting-state studies where subjects are asked to lie quietly and
not think of anything in particular, so the exact temporal patterns of brain activity may vary across the population. Similar to
the choice of sliding window length, a small bandwidth h will
suffer from large fluctuations while a large bandwidth h may
reduce sensitivity to fluctuations in the signal. Following prior
work [18] as well as our preliminary studies, we set the bandwidth to 32s (16 points). A comprehensive comparisons of brain
connectivity variation scales will be conducted in future work.
Fig. 4(a) demonstrates the relationship between the averaged
number of connections and the sparsity parameter λ as applied to one control subject. Suppose λ0 = 0, λ1 = 0.1, λ2 =
0.2, . . . , λ20 = 2, it is apparent that the averaged number of
connections decreases with sparsity parameter λ increasing. We
compare the averaged common connections between the inferred networks with λi and λi−1 (i = 2, . . . , 20), as shown
in Fig. 4(a). Reassuringly, we observed that the connectivity
inferred with a larger λ is mostly contained in the estimated networks with a smaller λ. In other words, important connections
will always be selected. In our study, we learned the networks
with a fixed sparsity parameter λ of 0.5 for a fair comparison
at the population level. We also compared the temporal patterns

Fig. 5. Time-varying brain connectivity networks learned with fixed parameters (h = 32s, λ = 0.5, γ = 1.5) for one typical control subject at (a) t = 70 s
(35 points), (b) t = 80 s (40 points) and (c) t=90 s (45 points). The blue lines
and red lines represent the positive and negative coefficients, respectively. The
thicknesses of the lines represent the absolute values of the coefficients.

with fixed sparsity (0.1) across all the subjects. Fig. 4(b) demonstrates the relationship between the value of network variation
and the fused penalty parameter γ when applied to one control
subject. The network variation generally decreases with increasing values of γ. However, since we are interested in the relative
differences between control and patient groups, we set γ = 1.5
for all subjects. We also compared the connectivity networks
between two groups when γ = 0.5.
Figs. 5 and 6 demonstrate the examples of time-varying brain
connectivity networks of typical normal and PD subjects at

508

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 2, FEBRUARY 2015

Fig. 8. Comparison of averaged time period between the normal and PD group
with either (a) fixed sparsity penalty parameter (λ = 0.5) or (b) fixed sparsity
(0.1).

Fig. 6. Time-varying brain connectivity networks learned with fixed parameters (h = 32s, λ = 0.5, γ = 1.5) for one typical PD subject at (a) t = 70 s (35
points), (b) t = 80 s (40 points) and (c) t = 90 s (45 points). The blue lines
and red lines represent the positive and negative coefficients respectively. The
thicknesses of the lines represent the absolute values of the coefficients.

Fig. 7. Comparison of network variation between the normal and PD group
with either (a) fixed sparsity penalty parameter (λ = 0.5) or (b) fixed sparsity
(0.1).

different time points where the networks are learned with fixed
parameters h = 32s, λ = 0.5, γ = 1.5. The proposed method
could estimate the brain connectivity networks with both changing structures and coefficients. When compared with the normal
subject, we note that the PD subject shows a sparser network.
In addition, the PD subject has more distributed connections
while the normal control subject tends to incorporate more hub
regions in brain connectivity networks.
To measure temporal properties of the learned time-varying
brain connectivity networks, we compared the network variations between control and PD groups in Fig. 7. The averaged
network variations were significantly lower in the PD group,
whether or not the sparsity parameter λ = 0.5 [see Fig. 7(a)]
or fixed sparsity (0.1) [see Fig. 7(b)]. Fig. 8 compares the av-

Fig. 9. Comparison of switching ratio between the normal and PD group with
either (a) fixed sparsity penalty parameter (λ = 0.5) or (b) fixed sparsity (0.1).

eraged time period, defined as the duration of nonzero values,
between control and PD groups. We note that the PD group has
a larger time period with different parameters compared with
that of control group. If we consider “switching ratio,” defined
as number of time points with switching from zero to nonzero
states to the total length of time points, we note that the PD
group had a significantly smaller switching ratio as shown in
Fig. 9.
We have also investigated the spectrum properties of the inferred brain connectivity networks. We note that the most dominant low-frequency connectivity fluctuations are below 0.02 Hz,
and specifically at around 0.005 and 0.015 Hz, which are consistent with previous studies [20]. While we found no significant
differences between groups in the mean frequency, we suspect
this could be due to the relatively small subject size in our study.
In addition to the temporal dynamics, we also studied the
spatial patterns learned by the fixed sparsity (0.1) by examining “consistent” connections over time. We define consistent
connections as those connections that appear at least once at
one time point in all subjects within a given group. As shown
in Fig. 10, the PD group has fewer cortico-basal ganglia connections and more cortico-cortical connections compared to the
control group. The alterations in cortico-cortical and corticobasal connectivity may reflect compensatory connections to
ameliorate the effects of the diseased basal ganglia [38]–[40].
V. DISCUSSION AND CONCLUSION
It is clear that the brain is inherently nonstationary. Therefore,
studying dynamic properties of brain connectivity networks

LIU et al.: STICKY WEIGHTED REGRESSION MODEL FOR TIME-VARYING RESTING-STATE BRAIN CONNECTIVITY ESTIMATION

509

variability of the network, this could be expanded in future work.
A previous study has suggested that larger brain regions tend to
show greater connectivity variability, while the smaller regions
are more stable [11]. Nevertheless the disease-related changes
of the time-varying patterns in brain connectivity such as we
observed might be the potential biomarker for future studies
[22], [41].
REFERENCES

Fig. 10. Connections that consistently appear in at least one time point in all
subjects in (a) control group and (b) PD group.

could extend our understanding of brain functioning. In this
paper, a penalized weighted regression model is presented to
estimate both smooth and abrupt changes in the time-dependent
brain connectivity patterns. Compared with previous multivariate time-varying approaches introduced for fMRI brain connectivity modeling, the proposed SWTV model is more flexible and
allows different pairs of brain regions to have different dynamic
time scales. While the proposed method is designed for the time
evolving networks estimation, when the underlying models are
static, the proposed method could still accurately estimate networks with appropriate parameters.
When applied to real fMRI resting-state data consisting of 12
subjects with PD and 10 control subjects, PD subjects had significantly reduced network variation, likely related to impaired
cognitive flexibility in PD. This highlights the importance of
establishing dynamic properties in PD subjects.
While the proposed method appears promising, there are a
number of limitations. We had to estimate certain parameters,
such as sparsity and temporal bandwidth. Further work will
be required to more comprehensively investigate time-varying
brain connectivity patterns over a broad range of time scales.
Resting-state data are particularly challenging in this regard,
as different subjects will undoubtedly have different temporal
patterns. We used a very simple metric to estimate temporal

[1] S. M. Smith, K. L. Miller, G. Salimi-Khorshidi, M. Webster, C. F.
Beckmann, T. E. Nichols, J. D. Ramsey, and M. W. Woolrich, “Network
modelling methods for fMRI,” NeuroImage, vol. 54, no. 2, pp. 875–891,
2011.
[2] M. J. McKeown, S. Makeig, G. G. Brown, T.-P. Jung, S. S. Kindermann,
A. J. Bell, and T. J. Sejnowski, “Analysis of fMRI data by blind separation
into independent spatial components,” Human Brain Mapping, vol. 6,
pp. 160–188, 1998.
[3] A. McIntosh, C. Grady, L. Ungerleider, J. Haxby, S. Rapoport, and
B. Horwitz, “Network analysis of cortical visual pathways mapped with
pet,” J. Neurosci., vol. 14, no. 2, pp. 655–666, 1994.
[4] K. Friston, L. Harrison, and W. Penny, “Dynamic causal modelling,”
NeuroImage, vol. 19, no. 4, pp. 1273–1302, 2003.
[5] V. Oikonomou, K. Blekas, and L. Astrakas, “A sparse and spatially constrained generative regression model for fMRI data analysis,” IEEE Trans.
Biomed. Eng., vol. 59, no. 1, pp. 58–67, Jan. 2012.
[6] K. E. Stephan, W. D. Penny, J. Daunizeau, R. J. Moran, and K. J. Friston,
“Bayesian model selection for group studies,” NeuroImage, vol. 46, no. 4,
pp. 1004–1017, 2009.
[7] G. Varoquaux, A. Gramfort, J. B. Poline, and B. Thirion, “Brain covariance
selection: Better individual functional connectivity models using population prior.” Adv. Neural Inform. Process. Syst., vol. 23, pp. 2334–2342,
2010.
[8] A. Liu, J. Li, Z. J. Wang, and M. J. McKeown, “A computationally efficient,
exploratory approach to brain connectivity incorporating false discovery
rate control, a priori knowledge, and group inference,” Comput. Math.
Methods Med., vol. 2012, pp. 967380-1–967380-14, 2012.
[9] A. Liu, X. Chen, Z. Wang, Q. Xu, S. Appel-Cresswell, and M. McKeown,
“A genetically informed, group fMRI connectivity modeling approach:
Application to schizophrenia,” IEEE Trans. Biomed. Eng., vol. 61, no. 3,
pp. 946–956, Mar. 2014.
[10] X. Liu and J. H. Duyn, “Time-varying functional network information
extracted from brief instances of spontaneous brain activity,” Proc. Nat.
Academy Sci., vol. 110, no. 11, pp. 4392–4397, 2013.
[11] R. M. Hutchison, T. Womelsdorf, E. A. Allen, P. A. Bandettini, V. D.
Calhoun, M. Corbetta, S. D. Penna, J. H. Duyn, G. H. Glover, J. GonzalezCastillo, D. A. Handwerker, S. Keilholz, V. Kiviniemi, D. A. Leopold, F. de
Pasquale, O. Sporns, M. Walter, and C. Chang. (2013). Dynamic functional
connectivity: Promise, issues, and interpretations. NeuroImage. 80(0),
pp. 360–378. [Online]. Available: http://www.sciencedirect.com/science/
article/pii/S105381191300579X
[12] J. Li, Z. J. Wang, S. J. Palmer, and M. J. McKeown, “Dynamic Bayesian
network modeling of fMRI: A comparison of group-analysis methods,”
NeuroImage, vol. 41, no. 2, pp. 398–407, 2008.
[13] R. Goebel, A. Roebroeck, D. Kim, and E. Formisano, “Investigating directed cortical interactions in time-resolved fMRI data using vector autoregressive modeling and Granger causality mapping,” Magn. Reson. Imag.,
vol. 21, pp. 1251–1261, 2003.
[14] J. Kang, L. Wang, C. Yan, J. Wang, X. Liang, and Y. He, “Characterizing
dynamic functional connectivity in the resting brain using variable parameter regression and Kalman filtering approaches,” NeuroImage, vol. 56,
no. 3, pp. 1222–1234, 2011.
[15] C. Chang and G. H. Glover, “Time-frequency dynamics of resting-state
brain connectivity measured with fMRI,” NeuroImage, vol. 50, no. 1,
pp. 81–98, 2010.
[16] J. R. Sato, E. A. Junior, D. Y. Takahashi, M. de Maria Felix, M. J. Brammer,
and P. A. Morettin, “A method to produce evolving functional connectivity
maps during the course of an fMRI experiment using wavelet-based timevarying Granger causality,” NeuroImage, vol. 31, no. 1, pp. 187–196,
2006.
[17] R. M. Hutchison, T. Womelsdorf, J. S. Gati, S. Everling, and R. S. Menon,
“Resting-state networks show dynamic functional connectivity in awake
humans and anesthetized macaques,” Human Brain Mapping, vol. 34,
pp. 2154–2177, 2012.

510

IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 62, NO. 2, FEBRUARY 2015

[18] D. A. Handwerker, V. Roopchansingh, J. Gonzalez-Castillo, and P. A.
Bandettini. (2012). Periodic changes in fMRI connectivity. NeuroImage.
63(3), pp. 1712–1719. [Online]. Available: http://www.sciencedirect.com/
science/article/pii/S1053811912007124
[19] G. J. Thompson, M. E. Magnuson, M. D. Merritt, H. Schwarb, W.-J. Pan,
A. McKinley, L. D. Tripp, E. H. Schumacher, and S. D. Keilholz, “Shorttime windows of correlation between large-scale functional brain networks
predict vigilance intraindividually and interindividually,” Human Brain
Mapping, vol. 34, pp. 3280–3298, 2012.
[20] E. A. Allen, E. Damaraju, S. M. Plis, E. B. Erhardt, T. Eichele, and
V. D. Calhoun, “Tracking whole-brain connectivity dynamics in the resting
state,” Cerebral Cortex, 2012. DOI: 10.1093/cercor/bhs352
[21] U. Sakoglu, G. D. Pearlson, K. A. Kiehl, Y. M. Wang, A. M. Michael,
and V. D. Calhoun, “A method for evaluating dynamic functional network
connectivity and task-modulation: Application to schizophrenia,” Magn.
Reson. Mater. Phys., Biol. Med., vol. 23, no. 5-6, pp. 351–366, 2010.
[22] D. T. Jones, P. Vemuri, M. C. Murphy, J. L. Gunter, M. L. Senjem, M. M.
Machulda, S. A. Przybelski, B. E. Gregg, K. Kantarci, D. S. Knopman
et al., “Non-stationarity in the resting brain modular architecture,” PloS
one, vol. 7, no. 6, p. e39731, 2012. DOI: 10.1371/journal.pone.0039731
[23] M. A. Lindquist, C. Waugh, and T. D. Wager, “Modeling state-related
fMRI activity using change-point theory,” NeuroImage, vol. 35, no. 3,
pp. 1125–1141, 2007.
[24] I. Cribben, R. Haraldsdottir, L. Y. Atlas, T. D. Wager, and M. A.
Lindquist. (2012). Dynamic connectivity regression: Determining staterelated changes in brain connectivity. NeuroImage, 61(4), pp. 907–
920. [Online]. Available: http://www.sciencedirect.com/science/article/
pii/S1053811912003515
[25] S. Zhou, J. Lafferty, and L. Wasserman. (2010). Time varying undirected graphs. Mach. Learn., 80(2-3), pp. 295–319. [Online]. Available:
http://dx.doi.org/10.1007/s10994-010-5180-0
[26] L. Song, M. Kolar, and E. P. Xing, “Time-varying dynamic Bayesian
networks,” Adv. Neural Inform. Process. Syst., vol. 22, pp. 1732–1740,
2009.
[27] Z. Wang, E. Kuruoglu, X. Yang, Y. Xu, and T. Huang, “Time varying
dynamic Bayesian network for nonstationary events modeling and online
inference,” IEEE Trans. Signal Process., vol. 59, no. 4, pp. 1553–1568,
Apr. 2011.
[28] J. W. Robinson and A. J. Hartemink, “Learning non-stationary dynamic
Bayesian networks,” J. Mach. Learn. Res., vol. 9999, pp. 3647–3680, Dec.
2010.
[29] M. Kolar, L. Song, and E. P. Xing, “Sparsistent learning of varyingcoefficient models with structural changes,” in Proc. Adv. Neural Inform.
Process. Syst., 2009, pp. 1006–1014.
[30] D. Precup and P. Bachman, “Improved estimation in time varying models,”
Proc. 29th Int. Conf. Mach. Learn., 2012, pp. 1735–1742.

[31] R. Tibshirani, M. Saunders, S. Rosset, J. Zhu, and K. Knight, “Sparsity
and smoothness via the fused lasso,” J. Roy. Stat. Soc. B, Stat. Methodol.),
vol. 67, no. 1, pp. 91–108, Feb. 2005.
[32] P. A. Valdes-Sosa, J. M. Sanchez-Bornot, A. Lage-Castellanos, M. VegaHernandez, J. Bosch-Bayard, L. Melie-Garcia, and E. Canales-Rodriguez,
“Estimating brain functional connectivity with sparse multivariate autoregression,” Philos. Trans. Roy. Soc. B, Biol. Sci., vol. 360, no. 1457,
pp. 969–981, 2005.
[33] S. Ryali, T. Chen, K. Supekar, and V. Menon, “Estimation of functional
connectivity in fMRI data using stability selection-based sparse partial
correlation with elastic net penalty,” NeuroImage, vol. 59, no. 4, pp. 3852–
3861, 2012.
[34] X. Chen, Q. Lin, S. Kim, J. G. Carbonell, and E. P. Xing, “Smoothing
proximal gradient method for general structured sparse regression,” Ann.
Appl. Stat., vol. 6, no. 2, pp. 719–752, 2012.
[35] S. Kim and E. P. Xing, “Statistical estimation of correlated genome associations to a quantitative trait network,” PLoS Genet, vol. 5, no. 8,
p. e1 000 587, 2009. DOI: 10.1371/journal.pgen.1000587
[36] X. Chen, X. Shi, X. Xu, Z. Wang, R. E. Mills, C. Lee, and J. Xu, “A
two-graph guided multi-task lasso approach for EQTL mapping,” in Proc.
Int. Conf. Artif. Intell. Stat., 2012, pp. 208–217.
[37] N. Meinshausen and P. Buhlmann. (2010). Stability selection. J. Roy.
Stat. Soc. B, Stati. Methodol.. 72(4), pp. 417–473. [Online]. Available:
http://dx.doi.org/10.1111/j.1467-9868.2010.00740.x
[38] S. Palmer, L. Eigenraam, T. Hoque, R. McCaig, A. Troiano, and
M. McKeown, “Levodopa-sensitive, dynamic changes in effective connectivity during simultaneous movements in Parkinson’s disease,” Neuroscience, vol. 158, no. 2, pp. 693–704, 2009.
[39] S. J. Palmer, B. Ng, R. Abugharbieh, L. Eigenraam, and M. J.
McKeown, “Motor reserve and novel area recruitment: Amplitude and
spatial characteristics of compensation in Parkinsons disease,” Eur. J.
Neurosci., vol. 29, no. 11, pp. 2187–2196, 2009.
[40] S. Palmer, J. Li, Z. Wang, and M. McKeown, “Joint amplitude and connectivity compensatory mechanisms in Parkinson’s disease,” Neuroscience,
vol. 166, no. 4, pp. 1110–1118, 2010.
[41] X. Li, D. Zhu, X. Jiang, C. Jin, X. Zhang, L. Guo, J. Zhang, X. Hu,
L. Li, and T. Liu, “Dynamic functional connectomics signatures for characterization and differentiation of PTSD patients,” Human Brain Mapping,
vol. 35, pp. 1761–1778, 2013.

Authors’ photographs and biographies not available at the time of publication.

